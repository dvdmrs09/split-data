{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_columns(\n        self, max_na_values: int = None, max_unique_values: int = None\n    ):\n        \"\"\"\n        When max_na_values was informed, remove columns when the proportion of\n        total NA values more than max_na_values threshold.\n\n        When max_unique_values was informed, remove columns when the proportion\n        of the total of unique values is more than the max_unique_values\n        threshold, just for columns with type as object or category.\n\n        :param max_na_values: proportion threshold of max na values\n        :param max_unique_values:\n        :return:\n        \"\"\"\n        step = {}\n\n        if max_na_values is not None:\n            step = {\n                'data-set': self.iid,\n                'operation': 'drop-na',\n                'expression': '{\"max_na_values\":%s, \"axis\": 1}' % max_na_values\n            }\n        if max_unique_values is not None:\n            step = {\n                'data-set': self.iid,\n                'operation': 'drop-unique',\n                'expression': '{\"max_unique_values\":%s}' % max_unique_values\n            }\n        self.attr_update(attr='steps', value=[step])", "response": "Drop columns when the proportion of the total NA values is more than max_na_values threshold."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndrop the missing elements from the sequence.", "response": "def dropna(self):\n        \"\"\"\n        :return:\n\n        \"\"\"\n        step = {\n            'data-set': self.iid,\n            'operation': 'drop-na',\n            'expression': '{\"axis\": 0}'\n        }\n\n        self.attr_update(attr='steps', value=[step])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog a message to the log file", "response": "def log(self, message: str):\n        \"\"\"\n        @deprecated\n\n        :param message:\n        :return:\n\n        \"\"\"\n        dset_log_id = '_%s_log' % self.iid\n\n        if dset_log_id not in self.parent.data.keys():\n            dset = self.parent.data.create_dataset(\n                dset_log_id, shape=(1,),\n                dtype=np.dtype([\n                    ('dt_log', '<i8'),\n                    ('message', 'S250')\n                ])\n            )\n        else:\n            dset = self.parent.data[dset_log_id]\n\n        timestamp = np.array(\n            datetime.now().strftime(\"%s\")\n        ).astype('<i8').view('<M8[s]')\n\n        dset['dt_log'] = timestamp.view('<i8')\n        dset['message'] = message\n        self.parent.data.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summary(self, compute=False) -> pd.DataFrame:\n        if compute or self.result is None:\n            self.compute()\n        return summary(self.result)", "response": "Returns a DataFrame with the summary of the result of the method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serve(request, server):\n\n    request_ = Request('/'.join(request.postpath),\n        request.content.read() if not request.method == 'GET' else '',\n        request.args, request.args, {})\n\n    response = server.process_request(request_)\n\n    request.setHeader('Content-Type', response.content_type)\n    request.setResponseCode(get_http_response_code_num(response))\n\n    return response.text", "response": "This function is a Twisted Web adapter. It is a pyws request object and the server object is passed to the Twisted web server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_sorted_dependencies(service_model):\n    app_models = list(service_model._meta.app_config.get_models())\n    dependencies = {model: set() for model in app_models}\n    relations = (\n        relation\n        for model in app_models\n        for relation in model._meta.related_objects\n        if relation.on_delete in (models.PROTECT, models.CASCADE)\n    )\n    for rel in relations:\n        dependencies[rel.model].add(rel.related_model)\n    return stable_topological_sort(app_models, dependencies)", "response": "Returns list of application models in topological order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the instance fields based on imported from backend data.", "response": "def update_pulled_fields(instance, imported_instance, fields):\n    \"\"\"\n    Update instance fields based on imported from backend data.\n    Save changes to DB only one or more fields were changed.\n    \"\"\"\n    modified = False\n    for field in fields:\n        pulled_value = getattr(imported_instance, field)\n        current_value = getattr(instance, field)\n        if current_value != pulled_value:\n            setattr(instance, field, pulled_value)\n            logger.info(\"%s's with PK %s %s field updated from value '%s' to value '%s'\",\n                        instance.__class__.__name__, instance.pk, field, current_value, pulled_value)\n            modified = True\n    error_message = getattr(imported_instance, 'error_message', '') or getattr(instance, 'error_message', '')\n    if error_message and instance.error_message != error_message:\n        instance.error_message = imported_instance.error_message\n        modified = True\n    if modified:\n        instance.save()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling a resource not found error.", "response": "def handle_resource_not_found(resource):\n    \"\"\"\n    Set resource state to ERRED and append/create \"not found\" error message.\n    \"\"\"\n    resource.set_erred()\n    resource.runtime_state = ''\n    message = 'Does not exist at backend.'\n    if message not in resource.error_message:\n        if not resource.error_message:\n            resource.error_message = message\n        else:\n            resource.error_message += ' (%s)' % message\n    resource.save()\n    logger.warning('%s %s (PK: %s) does not exist at backend.' % (\n        resource.__class__.__name__, resource, resource.pk))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_resource_update_success(resource):\n    update_fields = []\n    if resource.state == resource.States.ERRED:\n        resource.recover()\n        update_fields.append('state')\n\n    if resource.state in (resource.States.UPDATING, resource.States.CREATING):\n        resource.set_ok()\n        update_fields.append('state')\n\n    if resource.error_message:\n        resource.error_message = ''\n        update_fields.append('error_message')\n\n    if update_fields:\n        resource.save(update_fields=update_fields)\n    logger.warning('%s %s (PK: %s) was successfully updated.' % (\n        resource.__class__.__name__, resource, resource.pk))", "response": "Handle the update success of a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmarking the instance as erred and save error message", "response": "def set_instance_erred(self, instance, error_message):\n        \"\"\" Mark instance as erred and save error message \"\"\"\n        instance.set_erred()\n        instance.error_message = error_message\n        instance.save(update_fields=['state', 'error_message'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmap a language to a language code.", "response": "def map_language(language, dash3=True):\n    \"\"\" Use ISO 639-3 ?? \"\"\"\n    if dash3:\n        from iso639 import languages\n    else:\n        from pycountry import languages\n\n    if '_' in language:\n        language = language.split('_')[0]\n    if len(language) == 2:\n        try: return languages.get(alpha2=language.lower())\n        except KeyError: pass\n    elif len(language) == 3:\n        if dash3:\n            try: return languages.get(part3=language.lower())\n            except KeyError: pass\n        try: return languages.get(terminology=language.lower())\n        except KeyError: pass\n        try: return languages.get(bibliographic=language.lower())\n        except KeyError: pass\n    else:\n        try: return languages.get(name=language.title())\n        except KeyError: pass\n        if dash3:\n            try: return languages.get(inverted=language.title())\n            except KeyError: pass\n        for l in re.split('[,.;: ]+', language):\n            try: return languages.get(name=l.title())\n            except KeyError: pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_task_signature(cls, instance, serialized_instance, **kwargs):\n        cleanup_tasks = [\n            ProjectResourceCleanupTask().si(\n                core_utils.serialize_class(executor_cls),\n                core_utils.serialize_class(model_cls),\n                serialized_instance,\n            )\n            for (model_cls, executor_cls) in cls.executors\n        ]\n\n        if not cleanup_tasks:\n            return core_tasks.EmptyTask()\n\n        return chain(cleanup_tasks)", "response": "Returns a task signature for the given instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an OrderedDict ordered by key names from the unsorted_dict", "response": "def sort_dict(unsorted_dict):\n    \"\"\"\n    Return a OrderedDict ordered by key names from the :unsorted_dict:\n    \"\"\"\n    sorted_dict = OrderedDict()\n    # sort items before inserting them into a dict\n    for key, value in sorted(unsorted_dict.items(), key=itemgetter(0)):\n        sorted_dict[key] = value\n    return sorted_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting time_and_value_list to time segments", "response": "def format_time_and_value_to_segment_list(time_and_value_list, segments_count, start_timestamp,\n                                          end_timestamp, average=False):\n    \"\"\"\n    Format time_and_value_list to time segments\n\n    Parameters\n    ^^^^^^^^^^\n    time_and_value_list: list of tuples\n        Have to be sorted by time\n        Example: [(time, value), (time, value) ...]\n    segments_count: integer\n        How many segments will be in result\n    Returns\n    ^^^^^^^\n    List of dictionaries\n        Example:\n        [{'from': time1, 'to': time2, 'value': sum_of_values_from_time1_to_time2}, ...]\n    \"\"\"\n    segment_list = []\n    time_step = (end_timestamp - start_timestamp) / segments_count\n    for i in range(segments_count):\n        segment_start_timestamp = start_timestamp + time_step * i\n        segment_end_timestamp = segment_start_timestamp + time_step\n        value_list = [\n            value for time, value in time_and_value_list\n            if time >= segment_start_timestamp and time < segment_end_timestamp]\n        segment_value = sum(value_list)\n        if average and len(value_list) != 0:\n            segment_value /= len(value_list)\n\n        segment_list.append({\n            'from': segment_start_timestamp,\n            'to': segment_end_timestamp,\n            'value': segment_value,\n        })\n    return segment_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing Django model instance into a string.", "response": "def serialize_instance(instance):\n    \"\"\" Serialize Django model instance \"\"\"\n    model_name = force_text(instance._meta)\n    return '{}:{}'.format(model_name, instance.pk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef instance_from_url(url, user=None):\n    # XXX: This circular dependency will be removed then filter_queryset_for_user\n    # will be moved to model manager method\n    from waldur_core.structure.managers import filter_queryset_for_user\n\n    url = clear_url(url)\n    match = resolve(url)\n    model = get_model_from_resolve_match(match)\n    queryset = model.objects.all()\n    if user is not None:\n        queryset = filter_queryset_for_user(model.objects.all(), user)\n    return queryset.get(**match.kwargs)", "response": "Restore instance from URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses this transaction. If this transaction is the base transaction in a begin/commit nesting, the transaction will rollback(). Otherwise, the method returns. This is used to cancel a Transaction without affecting the scope of an enclosing transaction.", "response": "def close(self):\n        \"\"\"\n        Close this transaction.\n\n        If this transaction is the base transaction in a begin/commit\n        nesting, the transaction will rollback().  Otherwise, the\n        method returns.\n\n        This is used to cancel a Transaction without affecting the scope of\n        an enclosing transaction.\n        \"\"\"\n        if not self._connection or not self._parent:\n            return\n        if not self._parent._is_active:\n            # pragma: no cover\n            self._connection = None\n            # self._parent = None\n            return\n        if self._parent is self:\n            yield from self.rollback()\n        else:\n            self._is_active = False\n        self._connection = None\n        self._parent = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an app config for the given name.", "response": "def _get_app_config(self, app_name):\n        \"\"\"\n        Returns an app config for the given name, not by label.\n        \"\"\"\n\n        matches = [app_config for app_config in apps.get_app_configs()\n                   if app_config.name == app_name]\n        if not matches:\n            return\n        return matches[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_app_version(self, app_config):\n\n        base_name = app_config.__module__.split('.')[0]\n        module = __import__(base_name)\n        return getattr(module, '__version__', 'N/A')", "response": "Get the version of the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_quick_access_info(self):\n        quick_access_links = []\n\n        # add custom links\n        quick_access_links.extend(settings.FLUENT_DASHBOARD_QUICK_ACCESS_LINKS)\n\n        for model in (structure_models.Project,\n                      structure_models.Customer,\n                      core_models.User,\n                      structure_models.SharedServiceSettings):\n            quick_access_links.append(self._get_link_to_model(model))\n\n        return quick_access_links", "response": "Returns a list of ListLink items to be added to Quick Access tab."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_erred_shared_settings_module(self):\n        result_module = modules.LinkList(title=_('Shared provider settings in erred state'))\n        result_module.template = 'admin/dashboard/erred_link_list.html'\n        erred_state = structure_models.SharedServiceSettings.States.ERRED\n\n        queryset = structure_models.SharedServiceSettings.objects\n        settings_in_erred_state = queryset.filter(state=erred_state).count()\n\n        if settings_in_erred_state:\n            result_module.title = '%s (%s)' % (result_module.title, settings_in_erred_state)\n            for service_settings in queryset.filter(state=erred_state).iterator():\n                module_child = self._get_link_to_instance(service_settings)\n                module_child['error'] = service_settings.error_message\n                result_module.children.append(module_child)\n        else:\n            result_module.pre_content = _('Nothing found.')\n\n        return result_module", "response": "Returns a LinkList based module which contains link to shared service setting instances in ERRED state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of links to resources which are in ERRED state and linked to a shared service settings.", "response": "def _get_erred_resources_module(self):\n        \"\"\"\n        Returns a list of links to resources which are in ERRED state and linked to a shared service settings.\n        \"\"\"\n        result_module = modules.LinkList(title=_('Resources in erred state'))\n        erred_state = structure_models.NewResource.States.ERRED\n        children = []\n\n        resource_models = SupportedServices.get_resource_models()\n        resources_in_erred_state_overall = 0\n        for resource_type, resource_model in resource_models.items():\n            queryset = resource_model.objects.filter(service_project_link__service__settings__shared=True)\n            erred_amount = queryset.filter(state=erred_state).count()\n            if erred_amount:\n                resources_in_erred_state_overall = resources_in_erred_state_overall + erred_amount\n                link = self._get_erred_resource_link(resource_model, erred_amount, erred_state)\n                children.append(link)\n\n        if resources_in_erred_state_overall:\n            result_module.title = '%s (%s)' % (result_module.title, resources_in_erred_state_overall)\n            result_module.children = children\n        else:\n            result_module.pre_content = _('Nothing found.')\n\n        return result_module"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serve(request, tail, server):\n\n    if request.GET:\n        body = ''\n    else:\n        try:\n            body = request.body\n        except AttributeError:\n            body = request.raw_post_data\n\n    request = Request(\n        tail,\n        body,\n        parse_qs(request.META['QUERY_STRING']),\n        parse_qs(body),\n        request.COOKIES,\n    )\n\n    response = server.process_request(request)\n\n    return HttpResponse(\n        response.text, content_type=response.content_type,\n        status=get_http_response_code_num(response))", "response": "This function serves a Django application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the index of the given item in the list.", "response": "def index(self, nurest_object):\n        \"\"\" Get index of the given item\n            Args:\n                nurest_object (bambou.NURESTObject): the NURESTObject object to verify\n\n            Returns:\n                Returns the position of the object.\n\n            Raises:\n                Raise a ValueError exception if object is not present\n        \"\"\"\n        for index, obj in enumerate(self):\n            if obj.equals(nurest_object):\n                return index\n\n        raise ValueError(\"%s is  not in %s\" % (nurest_object, self))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering the fetcher for a served object.", "response": "def fetcher_with_object(cls, parent_object, relationship=\"child\"):\n        \"\"\" Register the fetcher for a served object.\n\n            This method will fill the fetcher with `managed_class` instances\n\n            Args:\n                parent_object: the instance of the parent object to serve\n\n            Returns:\n                It returns the fetcher instance.\n        \"\"\"\n\n        fetcher = cls()\n        fetcher.parent_object = parent_object\n        fetcher.relationship = relationship\n\n        rest_name = cls.managed_object_rest_name()\n        parent_object.register_fetcher(fetcher, rest_name)\n\n        return fetcher"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the headers for the given request based on the filter and order_by parameters.", "response": "def _prepare_headers(self, request, filter=None, order_by=None, group_by=[], page=None, page_size=None):\n        \"\"\" Prepare headers for the given request\n\n            Args:\n                request: the NURESTRequest to send\n                filter: string\n                order_by: string\n                group_by: list of names\n                page: int\n                page_size: int\n        \"\"\"\n\n        if filter:\n            request.set_header('X-Nuage-Filter', filter)\n\n        if order_by:\n            request.set_header('X-Nuage-OrderBy', order_by)\n\n        if page is not None:\n            request.set_header('X-Nuage-Page', str(page))\n\n        if page_size:\n            request.set_header('X-Nuage-PageSize', str(page_size))\n\n        if len(group_by) > 0:\n            header = \", \".join(group_by)\n            request.set_header('X-Nuage-GroupBy', 'true')\n            request.set_header('X-Nuage-Attributes', header)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch all managed class objects from the server.", "response": "def fetch(self, filter=None, order_by=None, group_by=[], page=None, page_size=None, query_parameters=None, commit=True, async=False, callback=None):\n        \"\"\" Fetch objects according to given filter and page.\n\n            Note:\n                This method fetches all managed class objects and store them\n                in local_name of the served object. which means that the parent\n                object will hold them in a list. You can prevent this behavior\n                by setting commit to False. In that case, the fetched children\n                won't be added in the parent object cache.\n\n            Args:\n                filter (string): string that represents a predicate filter\n                order_by (string): string that represents an order by clause\n                group_by (string): list of names for grouping\n                page (int): number of the page to load\n                page_size (int): number of results per page\n                commit (bool): boolean to update current object\n                callback (function): Callback that should be called in case of a async request\n\n            Returns:\n                tuple: Returns a tuple of information (fetcher, served object, fetched objects, connection)\n\n            Example:\n                >>> entity.children.fetch()\n                (<NUChildrenFetcher at aaaa>, <NUEntity at bbbb>, [<NUChildren at ccc>, <NUChildren at ddd>], <NURESTConnection at zzz>)\n        \"\"\"\n\n        request = NURESTRequest(method=HTTP_METHOD_GET, url=self._prepare_url(), params=query_parameters)\n\n        self._prepare_headers(request=request, filter=filter, order_by=order_by, group_by=group_by, page=page, page_size=page_size)\n\n        if async:\n            return self.parent_object.send_request(request=request, async=async, local_callback=self._did_fetch, remote_callback=callback, user_info={'commit': commit})\n\n        connection = self.parent_object.send_request(request=request, user_info={'commit': commit})\n        return self._did_fetch(connection=connection)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching objects has been done", "response": "def _did_fetch(self, connection):\n        \"\"\" Fetching objects has been done \"\"\"\n\n        self.current_connection = connection\n        response = connection.response\n        should_commit = 'commit' not in connection.user_info or connection.user_info['commit']\n\n        if connection.response.status_code >= 400 and BambouConfig._should_raise_bambou_http_error:\n            raise BambouHTTPError(connection=connection)\n\n        if response.status_code != 200:\n\n            if should_commit:\n                self.current_total_count = 0\n                self.current_page = 0\n                self.current_ordered_by = ''\n\n            return self._send_content(content=None, connection=connection)\n\n        results = response.data\n        fetched_objects = list()\n        current_ids = list()\n\n        if should_commit:\n            if 'X-Nuage-Count' in response.headers and response.headers['X-Nuage-Count']:\n                self.current_total_count = int(response.headers['X-Nuage-Count'])\n\n            if 'X-Nuage-Page' in response.headers and response.headers['X-Nuage-Page']:\n                self.current_page = int(response.headers['X-Nuage-Page'])\n\n            if 'X-Nuage-OrderBy' in response.headers and response.headers['X-Nuage-OrderBy']:\n                self.current_ordered_by = response.headers['X-Nuage-OrderBy']\n\n        if results:\n            for result in results:\n                nurest_object = self.new()\n                nurest_object.from_dict(result)\n                nurest_object.parent = self.parent_object\n\n                fetched_objects.append(nurest_object)\n\n                if not should_commit:\n                    continue\n\n                current_ids.append(nurest_object.id)\n\n                if nurest_object in self:\n                    idx = self.index(nurest_object)\n                    current_object = self[idx]\n                    current_object.from_dict(nurest_object.to_dict())\n                else:\n                    self.append(nurest_object)\n\n            if should_commit:\n                for obj in self:\n                    if obj.id not in current_ids:\n                        self.remove(obj)\n\n        return self._send_content(content=fetched_objects, connection=connection)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, filter=None, order_by=None, group_by=[], page=None, page_size=None, query_parameters=None, commit=True, async=False, callback=None):\n        return self.fetch(filter=filter, order_by=order_by, group_by=group_by, page=page, page_size=page_size, query_parameters=query_parameters, commit=commit)[2]", "response": "Fetch object and directly return them\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_first(self, filter=None, order_by=None, group_by=[], query_parameters=None, commit=False, async=False, callback=None):\n        objects = self.get(filter=filter, order_by=order_by, group_by=group_by, page=0, page_size=1, query_parameters=query_parameters, commit=commit)\n        return objects[0] if len(objects) else None", "response": "Fetch object and directly return the first one\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count(self, filter=None, order_by=None, group_by=[], page=None, page_size=None, query_parameters=None, async=False, callback=None):\n        request = NURESTRequest(method=HTTP_METHOD_HEAD, url=self._prepare_url(), params=query_parameters)\n\n        self._prepare_headers(request=request, filter=filter, order_by=order_by, group_by=group_by, page=page, page_size=page_size)\n\n        if async:\n            return self.parent_object.send_request(request=request, async=async, local_callback=self._did_count, remote_callback=callback)\n\n        else:\n            connection = self.parent_object.send_request(request=request)\n            return self._did_count(connection)", "response": "This method returns the total count of objects that can be fetched according to filter\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_count(self, filter=None, order_by=None, group_by=[], page=None, page_size=None, query_parameters=None):\n        return self.count(filter=filter, order_by=order_by, group_by=group_by, page=page, page_size=page_size, query_parameters=query_parameters, async=False)[2]", "response": "Get the total count of objects that can be fetched according to filter\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when count is finished", "response": "def _did_count(self, connection):\n        \"\"\" Called when count if finished \"\"\"\n\n        self.current_connection = connection\n        response = connection.response\n        count = 0\n        callback = None\n\n        if 'X-Nuage-Count' in response.headers:\n            count = int(response.headers['X-Nuage-Count'])\n\n        if 'remote' in connection.callbacks:\n            callback = connection.callbacks['remote']\n\n        if connection.async:\n            if callback:\n                callback(self, self.parent_object, count)\n\n                self.current_connection.reset()\n                self.current_connection = None\n        else:\n\n            if connection.response.status_code >= 400 and BambouConfig._should_raise_bambou_http_error:\n                raise BambouHTTPError(connection=connection)\n\n            return (self, self.parent_object, count)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _send_content(self, content, connection):\n\n        if connection:\n\n            if connection.async:\n                callback = connection.callbacks['remote']\n\n                if callback:\n                    callback(self, self.parent_object, content)\n\n                    self.current_connection.reset()\n                    self.current_connection = None\n            else:\n                return (self, self.parent_object, content)", "response": "Send a content array from the connection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the current configuration and the consumption details.", "response": "def update_configuration(self, new_configuration):\n        \"\"\" Save how much consumables were used and update current configuration.\n\n            Return True if configuration changed.\n        \"\"\"\n        if new_configuration == self.configuration:\n            return False\n        now = timezone.now()\n        if now.month != self.price_estimate.month:\n            raise ConsumptionDetailUpdateError('It is possible to update consumption details only for current month.')\n        minutes_from_last_update = self._get_minutes_from_last_update(now)\n        for consumable_item, usage in self.configuration.items():\n            consumed_after_modification = usage * minutes_from_last_update\n            self.consumed_before_update[consumable_item] = (\n                self.consumed_before_update.get(consumable_item, 0) + consumed_after_modification)\n        self.configuration = new_configuration\n        self.last_update_time = now\n        self.save()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consumed_in_month(self):\n        month_end = core_utils.month_end(datetime.date(self.price_estimate.year, self.price_estimate.month, 1))\n        return self._get_consumed(month_end)", "response": "How many resources were consumed in the month"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the number of consumables that were used by resource until given time.", "response": "def _get_consumed(self, time):\n        \"\"\" How many consumables were (or will be) used by resource until given time. \"\"\"\n        minutes_from_last_update = self._get_minutes_from_last_update(time)\n        if minutes_from_last_update < 0:\n            raise ConsumptionDetailCalculateError('Cannot calculate consumption if time < last modification date.')\n        _consumed = {}\n        for consumable_item in set(list(self.configuration.keys()) + list(self.consumed_before_update.keys())):\n            after_update = self.configuration.get(consumable_item, 0) * minutes_from_last_update\n            before_update = self.consumed_before_update.get(consumable_item, 0)\n            _consumed[consumable_item] = after_update + before_update\n        return _consumed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the number of minutes from last update to given time", "response": "def _get_minutes_from_last_update(self, time):\n        \"\"\" How much minutes passed from last update to given time \"\"\"\n        time_from_last_update = time - self.last_update_time\n        return int(time_from_last_update.total_seconds() / 60)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets list of all price list items that should be used for a given resource.", "response": "def get_for_resource(resource):\n        \"\"\" Get list of all price list items that should be used for resource.\n\n            If price list item is defined for service - return it, otherwise -\n            return default price list item.\n        \"\"\"\n        resource_content_type = ContentType.objects.get_for_model(resource)\n        default_items = set(DefaultPriceListItem.objects.filter(resource_content_type=resource_content_type))\n        service = resource.service_project_link.service\n        items = set(PriceListItem.objects.filter(\n            default_price_list_item__in=default_items, service=service).select_related('default_price_list_item'))\n        rewrited_defaults = set([i.default_price_list_item for i in items])\n        return items | (default_items - rewrited_defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of available extensions for a given class.", "response": "def get_extensions(cls):\n        \"\"\" Get a list of available extensions \"\"\"\n        assemblies = []\n        for waldur_extension in pkg_resources.iter_entry_points('waldur_extensions'):\n            extension_module = waldur_extension.load()\n            if inspect.isclass(extension_module) and issubclass(extension_module, cls):\n                if not extension_module.is_assembly():\n                    yield extension_module\n                else:\n                    assemblies.append(extension_module)\n        for assembly in assemblies:\n            yield assembly"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ellipsis(source, max_length):\n    if max_length == 0 or len(source) <= max_length:\n        return source\n    return source[: max(0, max_length - 3)] + \"...\"", "response": "Truncates a string to be at most max_length long."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap for str that catches exceptions and returns an ellipsis string.", "response": "def safe_str(source, max_length=0):\n    \"\"\"Wrapper for str() that catches exceptions.\"\"\"\n    try:\n        return ellipsis(str(source), max_length)\n    except Exception as e:\n        return ellipsis(\"<n/a: str(...) raised %s>\" % e, max_length)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef safe_repr(source, max_length=0):\n    try:\n        return ellipsis(repr(source), max_length)\n    except Exception as e:\n        return ellipsis(\"<n/a: repr(...) raised %s>\" % e, max_length)", "response": "Wrapper for repr that catches exceptions and returns an ellipsis string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an object with the key - value pairs in source as attributes.", "response": "def dict_to_object(source):\n    \"\"\"Returns an object with the key-value pairs in source as attributes.\"\"\"\n    target = inspectable_class.InspectableClass()\n    for k, v in source.items():\n        setattr(target, k, v)\n    return target"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshallowing copies all public attributes from source_obj to dest_obj.", "response": "def copy_public_attrs(source_obj, dest_obj):\n    \"\"\"Shallow copies all public attributes from source_obj to dest_obj.\n\n    Overwrites them if they already exist.\n\n    \"\"\"\n    for name, value in inspect.getmembers(source_obj):\n        if not any(name.startswith(x) for x in [\"_\", \"func\", \"im\"]):\n            setattr(dest_obj, name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef object_from_string(name):\n    if six.PY3:\n        if not isinstance(name, str):\n            raise TypeError(\"name must be str, not %r\" % type(name))\n    else:\n        if isinstance(name, unicode):\n            name = name.encode(\"ascii\")\n        if not isinstance(name, (str, unicode)):\n            raise TypeError(\"name must be bytes or unicode, got %r\" % type(name))\n\n    pos = name.rfind(\".\")\n    if pos < 0:\n        raise ValueError(\"Invalid function or class name %s\" % name)\n    module_name = name[:pos]\n    func_name = name[pos + 1 :]\n    try:\n        mod = __import__(module_name, fromlist=[func_name], level=0)\n    except ImportError:\n        # Hail mary. if the from import doesn't work, then just import the top level module\n        # and do getattr on it, one level at a time. This will handle cases where imports are\n        # done like `from . import submodule as another_name`\n        parts = name.split(\".\")\n        mod = __import__(parts[0], level=0)\n        for i in range(1, len(parts)):\n            mod = getattr(mod, parts[i])\n        return mod\n\n    else:\n        return getattr(mod, func_name)", "response": "Creates a Python class or function object from its fully qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef catchable_exceptions(exceptions):\n    if isinstance(exceptions, type) and issubclass(exceptions, BaseException):\n        return True\n\n    if (\n        isinstance(exceptions, tuple)\n        and exceptions\n        and all(issubclass(it, BaseException) for it in exceptions)\n    ):\n        return True\n\n    return False", "response": "Returns True if the given exceptions can be caught in the except clause."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_object_action(self, action_name, obj=None):\n        action_method = getattr(self, action_name)\n        if not getattr(action_method, 'detail', False) and action_name not in ('update', 'partial_update', 'destroy'):\n            # DRF does not add flag 'detail' to update and delete actions, however they execute operation with\n            # particular object. We need to enable validation for them too.\n            return\n        validators = getattr(self, action_name + '_validators', [])\n        for validator in validators:\n            validator(obj or self.get_object())", "response": "Execute validation for actions that are related to particular object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef row_dict(self, row):\n        d = {}\n        for field_name,index in self.field_map.items():\n            d[field_name] = self.field_value(row, field_name)\n        return d", "response": "returns dictionary version of row using keys from self. field_map"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning detected dialect of filepath and sets self. has_header if not passed in __init__ kwargs Arguments : filepath (str ) - path to target csv file", "response": "def _dialect(self, filepath):\n        \"\"\"returns detected dialect of filepath and sets self.has_header\n        if not passed in __init__ kwargs\n        Arguments:\n            filepath (str): filepath of target csv file\n        \"\"\"\n        with open(filepath, self.read_mode) as csvfile:\n            sample = csvfile.read(1024)\n            dialect = csv.Sniffer().sniff(sample)\n            if self.has_header == None:\n                # detect header if header not specified\n                self.has_header = csv.Sniffer().has_header(sample)\n            csvfile.seek(0)\n        return dialect"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_content_type_queryset(models_list):\n    content_type_ids = {c.id for c in ContentType.objects.get_for_models(*models_list).values()}\n    return ContentType.objects.filter(id__in=content_type_ids)", "response": "Get list of services content types"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_registered(self, request):\n        created_items = models.DefaultPriceListItem.init_from_registered_resources()\n\n        if created_items:\n            message = ungettext(\n                _('Price item was created: %s.') % created_items[0].name,\n                _('Price items were created: %s.') % ', '.join(item.name for item in created_items),\n                len(created_items)\n            )\n            self.message_user(request, message)\n        else:\n            self.message_user(request, _('Price items for all registered resources have been updated.'))\n\n        return redirect(reverse('admin:cost_tracking_defaultpricelistitem_changelist'))", "response": "Create default price list items for each registered resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencrypt the given message", "response": "def encrypt(self, message):\n        \"\"\" Encrypt the given message \"\"\"\n\n        if not isinstance(message, (bytes, str)):\n            raise TypeError\n        \n        return hashlib.sha1(message.encode('utf-8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, *args, **kwargs):\n        try:\n            prev_instance = self.__class__.objects.get(pk=self.pk)\n        except self.DoesNotExist:\n            prev_instance = None\n\n        if prev_instance is None or (not prev_instance.is_active and self.is_active or\n                                     self.schedule != prev_instance.schedule):\n            self.update_next_trigger_at()\n\n        super(ScheduleMixin, self).save(*args, **kwargs)", "response": "Updates next_trigger_at field of the record if the record is not already active and the record is new."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_version_fields(self):\n        options = reversion._get_options(self)\n        return options.fields or [f.name for f in self._meta.fields if f not in options.exclude]", "response": "Get the fields that are tracked in object history versions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_version_duplicate(self):\n        if self.id is None:\n            return False\n        try:\n            latest_version = Version.objects.get_for_object(self).latest('revision__date_created')\n        except Version.DoesNotExist:\n            return False\n        latest_version_object = latest_version._object_version.object\n        fields = self.get_version_fields()\n        return all([getattr(self, f) == getattr(latest_version_object, f) for f in fields])", "response": "Check if this object is a duplicate of another object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all unique instance ancestors", "response": "def get_ancestors(self):\n        \"\"\" Get all unique instance ancestors \"\"\"\n        ancestors = list(self.get_parents())\n        ancestor_unique_attributes = set([(a.__class__, a.id) for a in ancestors])\n        ancestors_with_parents = [a for a in ancestors if isinstance(a, DescendantMixin)]\n        for ancestor in ancestors_with_parents:\n            for parent in ancestor.get_ancestors():\n                if (parent.__class__, parent.id) not in ancestor_unique_attributes:\n                    ancestors.append(parent)\n        return ancestors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the connection has succeed.", "response": "def has_succeed(self):\n        \"\"\" Check if the connection has succeed\n\n            Returns:\n                Returns True if connection has succeed.\n                False otherwise.\n\n        \"\"\"\n        status_code = self._response.status_code\n\n        if status_code in [HTTP_CODE_ZERO, HTTP_CODE_SUCCESS, HTTP_CODE_CREATED, HTTP_CODE_EMPTY, HTTP_CODE_MULTIPLE_CHOICES]:\n            return True\n\n        if status_code in [HTTP_CODE_BAD_REQUEST, HTTP_CODE_UNAUTHORIZED, HTTP_CODE_PERMISSION_DENIED, HTTP_CODE_NOT_FOUND, HTTP_CODE_METHOD_NOT_ALLOWED, HTTP_CODE_CONNECTION_TIMEOUT, HTTP_CODE_CONFLICT, HTTP_CODE_PRECONDITION_FAILED, HTTP_CODE_INTERNAL_SERVER_ERROR, HTTP_CODE_SERVICE_UNAVAILABLE]:\n            return False\n\n        raise Exception('Unknown status code %s.', status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_response_for_connection(self, should_post=False):\n\n        status_code = self._response.status_code\n        data = self._response.data\n\n        # TODO : Get errors in response data after bug fix : http://mvjira.mv.usa.alcatel.com/browse/VSD-2735\n        if data and 'errors' in data:\n            self._response.errors = data['errors']\n\n        if status_code in [HTTP_CODE_SUCCESS, HTTP_CODE_CREATED, HTTP_CODE_EMPTY]:\n            return True\n\n        if status_code == HTTP_CODE_MULTIPLE_CHOICES:\n            return False\n\n        if status_code in [HTTP_CODE_PERMISSION_DENIED, HTTP_CODE_UNAUTHORIZED]:\n\n            if not should_post:\n                return True\n\n            return False\n\n        if status_code in [HTTP_CODE_CONFLICT, HTTP_CODE_NOT_FOUND, HTTP_CODE_BAD_REQUEST, HTTP_CODE_METHOD_NOT_ALLOWED, HTTP_CODE_PRECONDITION_FAILED, HTTP_CODE_SERVICE_UNAVAILABLE]:\n            if not should_post:\n                return True\n\n            return False\n\n        if status_code == HTTP_CODE_INTERNAL_SERVER_ERROR:\n\n            return False\n\n        if status_code == HTTP_CODE_ZERO:\n            bambou_logger.error(\"NURESTConnection: Connection error with code 0. Sending NUNURESTConnectionFailureNotification notification and exiting.\")\n            return False\n\n        bambou_logger.error(\"NURESTConnection: Report this error, because this should not happen: %s\" % self._response)\n        return False", "response": "Check if the response has a success or not and set the response attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when a response is received", "response": "def _did_receive_response(self, response):\n        \"\"\" Called when a response is received \"\"\"\n        try:\n            data = response.json()\n        except:\n            data = None\n\n        self._response = NURESTResponse(status_code=response.status_code, headers=response.headers, data=data, reason=response.reason)\n\n        level = logging.WARNING if self._response.status_code >= 300 else logging.DEBUG\n\n        bambou_logger.info('< %s %s %s [%s] ' % (self._request.method, self._request.url, self._request.params if self._request.params else \"\", self._response.status_code))\n        bambou_logger.log(level, '< headers: %s' % self._response.headers)\n        bambou_logger.log(level, '< data:\\n%s' % json.dumps(self._response.data, indent=4))\n\n        self._callback(self)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _did_timeout(self):\n\n        bambou_logger.debug('Bambou %s on %s has timeout (timeout=%ss)..' % (self._request.method, self._request.url, self.timeout))\n        self._has_timeouted = True\n\n        if self.async:\n            self._callback(self)\n        else:\n            return self", "response": "Called when a request has timeout."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a synchronous request.", "response": "def _make_request(self, session=None):\n        \"\"\" Make a synchronous request \"\"\"\n\n        if session is None:\n            session = NURESTSession.get_current_session()\n\n        self._has_timeouted = False\n\n        # Add specific headers\n        controller = session.login_controller\n\n        enterprise = controller.enterprise\n        user_name = controller.user\n        api_key = controller.api_key\n        certificate = controller.certificate\n\n        if self._root_object:\n            enterprise = self._root_object.enterprise_name\n            user_name = self._root_object.user_name\n            api_key = self._root_object.api_key\n\n        if self._uses_authentication:\n            self._request.set_header('X-Nuage-Organization', enterprise)\n            self._request.set_header('Authorization', controller.get_authentication_header(user_name, api_key))\n\n        if controller.is_impersonating:\n            self._request.set_header('X-Nuage-ProxyUser', controller.impersonation)\n\n        headers = self._request.headers\n        data = json.dumps(self._request.data)\n\n        bambou_logger.info('> %s %s %s' % (self._request.method, self._request.url, self._request.params if self._request.params else \"\"))\n        bambou_logger.debug('> headers: %s' % headers)\n        bambou_logger.debug('> data:\\n  %s' % json.dumps(self._request.data, indent=4))\n\n        response = self.__make_request(requests_session=session.requests_session, method=self._request.method, url=self._request.url, params=self._request.params, data=data, headers=headers, certificate=certificate)\n\n        retry_request = False\n\n        if response.status_code == HTTP_CODE_MULTIPLE_CHOICES:\n            self._request.url += '?responseChoice=1'\n            bambou_logger.debug('Bambou got [%s] response. Trying to force response choice' % HTTP_CODE_MULTIPLE_CHOICES)\n            retry_request = True\n\n        elif response.status_code == HTTP_CODE_AUTHENTICATION_EXPIRED and session:\n            bambou_logger.debug('Bambou got [%s] response . Trying to reconnect your session that has expired' % HTTP_CODE_AUTHENTICATION_EXPIRED)\n            session.reset()\n            session.start()\n            retry_request = True\n\n        if retry_request:\n            response = self.__make_request(requests_session=session.requests_session, method=self._request.method, url=self._request.url, params=self._request.params, data=data, headers=headers, certificate=certificate)\n\n        return self._did_receive_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n\n        # TODO : Use Timeout here and _ignore_request_idle\n        from .nurest_session import NURESTSession\n        session = NURESTSession.get_current_session()\n\n        if self.async:\n            thread = threading.Thread(target=self._make_request, kwargs={'session': session})\n            thread.is_daemon = False\n            thread.start()\n            return self.transaction_id\n\n        return self._make_request(session=session)", "response": "Start the HTTP request with a specific method"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the connection to the original state.", "response": "def reset(self):\n        \"\"\" Reset the connection\n\n        \"\"\"\n        self._request = None\n        self._response = None\n        self._transaction_id = uuid.uuid4().hex"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new ConsumptionDetailsQuerySet for the given price estimate.", "response": "def create(self, price_estimate):\n        \"\"\" Take configuration from previous month, it it exists.\n            Set last_update_time equals to the beginning of the month.\n        \"\"\"\n        kwargs = {}\n        try:\n            previous_price_estimate = price_estimate.get_previous()\n        except ObjectDoesNotExist:\n            pass\n        else:\n            configuration = previous_price_estimate.consumption_details.configuration\n            kwargs['configuration'] = configuration\n        month_start = core_utils.month_start(datetime.date(price_estimate.year, price_estimate.month, 1))\n        kwargs['last_update_time'] = month_start\n        return super(ConsumptionDetailsQuerySet, self).create(price_estimate=price_estimate, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_fields(self):\n        fields = super(BaseHookSerializer, self).get_fields()\n        fields['event_types'] = serializers.MultipleChoiceField(\n            choices=loggers.get_valid_events(), required=False)\n        fields['event_groups'] = serializers.MultipleChoiceField(\n            choices=loggers.get_event_groups_keys(), required=False)\n        return fields", "response": "Returns a dict of all the fields that are required to serialize the log entries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing PriceEstimateSerializer to serialize estimate children", "response": "def build_nested_field(self, field_name, relation_info, nested_depth):\n        \"\"\" Use PriceEstimateSerializer to serialize estimate children \"\"\"\n        if field_name != 'children':\n            return super(PriceEstimateSerializer, self).build_nested_field(field_name, relation_info, nested_depth)\n        field_class = self.__class__\n        field_kwargs = {'read_only': True, 'many': True, 'context': {'depth': nested_depth - 1}}\n        return field_class, field_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreparing the exception for re - raising with reraise method.", "response": "def prepare_for_reraise(error, exc_info=None):\n    \"\"\"Prepares the exception for re-raising with reraise method.\n\n    This method attaches type and traceback info to the error object\n    so that reraise can properly reraise it using this info.\n\n    \"\"\"\n    if not hasattr(error, \"_type_\"):\n        if exc_info is None:\n            exc_info = sys.exc_info()\n        error._type_ = exc_info[0]\n        error._traceback = exc_info[2]\n    return error"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reraise(error):\n    if hasattr(error, \"_type_\"):\n        six.reraise(type(error), error, error._traceback)\n    raise error", "response": "Re - raises the error that was processed by prepare_for_reraise earlier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(*args, **kwargs):\n    if args and callable(args[0]):\n        raise ConfigurationError(\n            'You might have tried to decorate a function directly with '\n            '@register which is not supported, use @register(...) instead')\n    def registrator(origin):\n        try:\n            server = SERVERS[kwargs.pop('to')]\n        except KeyError:\n            server = SERVERS.default\n        server.add_function(\n            NativeFunctionAdapter(origin, *args, **kwargs))\n        return origin\n    return registrator", "response": "Returns a registrator that is being called with a function as the only\n    argument and registers it to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rest_name(cls):\n        if cls.__name__ == \"NURESTRootObject\" or cls.__name__ == \"NURESTObject\":\n            return \"Not Implemented\"\n\n        if cls.__rest_name__ is None:\n            raise NotImplementedError('%s has no defined name. Implement rest_name property first.' % cls)\n\n        return cls.__rest_name__", "response": "Represents a singular REST name of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrepresent the resource name of the class.", "response": "def resource_name(cls):\n        \"\"\" Represents the resource name\n        \"\"\"\n        if cls.__name__ == \"NURESTRootObject\" or cls.__name__ == \"NURESTObject\":\n            return \"Not Implemented\"\n\n        if cls.__resource_name__ is None:\n            raise NotImplementedError('%s has no defined resource name. Implement resource_name property first.' % cls)\n\n        return cls.__resource_name__"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _compute_args(self, data=dict(), **kwargs):\n\n        for name, remote_attribute in self._attributes.items():\n            default_value = BambouConfig.get_default_attribute_value(self.__class__, name, remote_attribute.attribute_type)\n            setattr(self, name, default_value)\n\n        if len(data) > 0:\n            self.from_dict(data)\n\n        for key, value in kwargs.items():\n            if hasattr(self, key):\n                setattr(self, key, value)", "response": "Compute the arguments for the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef children_rest_names(self):\n\n        names = []\n\n        for fetcher in self.fetchers:\n            names.append(fetcher.__class__.managed_object_rest_name())\n\n        return names", "response": "Gets the list of all possible children ReST names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_resource_url(self):\n\n        name = self.__class__.resource_name\n        url = self.__class__.rest_base_url()\n\n        if self.id is not None:\n            return \"%s/%s/%s\" % (url, name, self.id)\n\n        return \"%s/%s\" % (url, name)", "response": "Get resource complete url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the current object attributes and store errors in errors dict.", "response": "def validate(self):\n        \"\"\" Validate the current object attributes.\n\n            Check all attributes and store errors\n\n            Returns:\n                Returns True if all attibutes of the object\n                respect contraints. Returns False otherwise and\n                store error in errors dict.\n\n        \"\"\"\n        self._attribute_errors = dict()  # Reset validation errors\n\n        for local_name, attribute in self._attributes.items():\n\n            value = getattr(self, local_name, None)\n\n            if attribute.is_required and (value is None or value == \"\"):\n                self._attribute_errors[local_name] = {'title': 'Invalid input',\n                                                      'description': 'This value is mandatory.',\n                                                      'remote_name': attribute.remote_name}\n                continue\n\n            if value is None:\n                continue  # without error\n\n            if not self._validate_type(local_name, attribute.remote_name, value, attribute.attribute_type):\n                continue\n\n            if attribute.min_length is not None and len(value) < attribute.min_length:\n                self._attribute_errors[local_name] = {'title': 'Invalid length',\n                                                      'description': 'Attribute %s minimum length should be %s but is %s' % (attribute.remote_name, attribute.min_length, len(value)),\n                                                      'remote_name': attribute.remote_name}\n                continue\n\n            if attribute.max_length is not None and len(value) > attribute.max_length:\n                self._attribute_errors[local_name] = {'title': 'Invalid length',\n                                                      'description': 'Attribute %s maximum length should be %s but is %s' % (attribute.remote_name, attribute.max_length, len(value)),\n                                                      'remote_name': attribute.remote_name}\n                continue\n\n            if attribute.attribute_type == list:\n                valid = True\n                for item in value:\n                    if valid is True:\n                        valid = self._validate_value(local_name, attribute, item)\n            else:\n                self._validate_value(local_name, attribute, value)\n\n        return self.is_valid()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexposes a local_name as remote_name_nuremote_attribute", "response": "def expose_attribute(self, local_name, attribute_type, remote_name=None, display_name=None, is_required=False, is_readonly=False, max_length=None, min_length=None, is_identifier=False, choices=None, is_unique=False, is_email=False, is_login=False, is_editable=True, is_password=False, can_order=False, can_search=False, subtype=None, min_value=None, max_value=None):\n        \"\"\" Expose local_name as remote_name\n\n            An exposed attribute `local_name` will be sent within the HTTP request as\n            a `remote_name`\n\n        \"\"\"\n        if remote_name is None:\n            remote_name = local_name\n\n        if display_name is None:\n            display_name = local_name\n\n        attribute = NURemoteAttribute(local_name=local_name, remote_name=remote_name, attribute_type=attribute_type)\n        attribute.display_name = display_name\n        attribute.is_required = is_required\n        attribute.is_readonly = is_readonly\n        attribute.min_length = min_length\n        attribute.max_length = max_length\n        attribute.is_editable = is_editable\n        attribute.is_identifier = is_identifier\n        attribute.choices = choices\n        attribute.is_unique = is_unique\n        attribute.is_email = is_email\n        attribute.is_login = is_login\n        attribute.is_password = is_password\n        attribute.can_order = can_order\n        attribute.can_search = can_search\n        attribute.subtype = subtype\n        attribute.min_value = min_value\n        attribute.max_value = max_value\n\n        self._attributes[local_name] = attribute"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the current user owns the object", "response": "def is_owned_by_current_user(self):\n        \"\"\" Check if the current user owns the object \"\"\"\n\n        from bambou.nurest_root_object import NURESTRootObject\n        root_object = NURESTRootObject.get_default_root_object()\n        return self._owner == root_object.id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parent_for_matching_rest_name(self, rest_names):\n\n        parent = self\n\n        while parent:\n            if parent.rest_name in rest_names:\n                return parent\n\n            parent = parent.parent_object\n\n        return None", "response": "Return parent that matches a rest name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef genealogic_types(self):\n\n        types = []\n        parent = self\n\n        while parent:\n            types.append(parent.rest_name)\n            parent = parent.parent_object\n\n        return types", "response": "Get genealogic types Returns a list of all parent types"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all genealogic ids in the current object", "response": "def genealogic_ids(self):\n        \"\"\" Get all genealogic ids\n\n            Returns:\n                 A list of all parent ids\n        \"\"\"\n\n        ids = []\n        parent = self\n\n        while parent:\n            ids.append(parent.id)\n            parent = parent.parent_object\n\n        return ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the creation date with a given format. Default is %b %d %H:%I:%S", "response": "def get_formated_creation_date(self, format='%b %Y %d %H:%I:%S'):\n        \"\"\" Return creation date with a given format. Default is '%b %Y %d %H:%I:%S' \"\"\"\n\n        if not self._creation_date:\n            return None\n\n        date = datetime.datetime.utcfromtimestamp(self._creation_date)\n        return date.strftime(format)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_child(self, child):\n\n        rest_name = child.rest_name\n        children = self.fetcher_for_rest_name(rest_name)\n\n        if children is None:\n            raise InternalConsitencyError('Could not find fetcher with name %s while adding %s in parent %s' % (rest_name, child, self))\n\n        if child not in children:\n            child.parent_object = self\n            children.append(child)", "response": "Add a child to the parent object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_child(self, child):\n\n        rest_name = child.rest_name\n        children = self.fetcher_for_rest_name(rest_name)\n\n        target_child = None\n\n        for local_child in children:\n            if local_child.id == child.id:\n                target_child = local_child\n                break\n\n        if target_child:\n            target_child.parent_object = None\n            children.remove(target_child)", "response": "Removes a child from the list of children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the child with the given one.", "response": "def update_child(self, child):\n        \"\"\" Update child \"\"\"\n\n        rest_name = child.rest_name\n        children = self.fetcher_for_rest_name(rest_name)\n\n        index = None\n\n        for local_child in children:\n            if local_child.id == child.id:\n                index = children.index(local_child)\n                break\n\n        if index is not None:\n            children[index] = child"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dict(self):\n\n        dictionary = dict()\n\n        for local_name, attribute in self._attributes.items():\n            remote_name = attribute.remote_name\n\n            if hasattr(self, local_name):\n                value = getattr(self, local_name)\n\n                # Removed to resolve issue http://mvjira.mv.usa.alcatel.com/browse/VSD-5940 (12/15/2014)\n                # if isinstance(value, bool):\n                #     value = int(value)\n\n                if isinstance(value, NURESTObject):\n                    value = value.to_dict()\n\n                if isinstance(value, list) and len(value) > 0 and isinstance(value[0], NURESTObject):\n                    tmp = list()\n                    for obj in value:\n                        tmp.append(obj.to_dict())\n\n                    value = tmp\n\n                dictionary[remote_name] = value\n            else:\n                pass  # pragma: no cover\n\n        return dictionary", "response": "Converts the current object into a dictionary using all exposed ReST attributes and their values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(self, dictionary):\n\n        for remote_name, remote_value in dictionary.items():\n            # Check if a local attribute is exposed with the remote_name\n            # if no attribute is exposed, return None\n            local_name = next((name for name, attribute in self._attributes.items() if attribute.remote_name == remote_name), None)\n\n            if local_name:\n                setattr(self, local_name, remote_value)\n            else:\n                # print('Attribute %s could not be added to object %s' % (remote_name, self))\n                pass", "response": "Sets all the exposed ReST attributes from the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes object and call given callback in case of call.", "response": "def delete(self, response_choice=1, async=False, callback=None):\n        \"\"\" Delete object and call given callback in case of call.\n\n            Args:\n                response_choice (int): Automatically send a response choice when confirmation is needed\n                async (bool): Boolean to make an asynchronous call. Default is False\n                callback (function): Callback method that will be triggered in case of asynchronous call\n\n            Example:\n                >>> entity.delete() # will delete the enterprise from the server\n        \"\"\"\n        return self._manage_child_object(nurest_object=self, method=HTTP_METHOD_DELETE, async=async, callback=callback, response_choice=response_choice)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate object and call given callback in case of asynchronous call", "response": "def save(self, response_choice=None, async=False, callback=None):\n        \"\"\" Update object and call given callback in case of async call\n\n            Args:\n                async (bool): Boolean to make an asynchronous call. Default is False\n                callback (function): Callback method that will be triggered in case of asynchronous call\n\n            Example:\n                >>> entity.name = \"My Super Object\"\n                >>> entity.save() # will save the new name in the server\n        \"\"\"\n        return self._manage_child_object(nurest_object=self, method=HTTP_METHOD_PUT, async=async, callback=callback, response_choice=response_choice)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a request to the NUREST server.", "response": "def send_request(self, request, async=False, local_callback=None, remote_callback=None, user_info=None):\n        \"\"\" Sends a request, calls the local callback, then the remote callback in case of async call\n\n            Args:\n                request: The request to send\n                local_callback: local method that will be triggered in case of async call\n                remote_callback: remote moethd that will be triggered in case of async call\n                user_info: contains additionnal information to carry during the request\n\n            Returns:\n                Returns the object and connection (object, connection)\n        \"\"\"\n\n        callbacks = dict()\n\n        if local_callback:\n            callbacks['local'] = local_callback\n\n        if remote_callback:\n            callbacks['remote'] = remote_callback\n\n        connection = NURESTConnection(request=request, async=async, callback=self._did_receive_response, callbacks=callbacks)\n        connection.user_info = user_info\n\n        return connection.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _manage_child_object(self, nurest_object, method=HTTP_METHOD_GET, async=False, callback=None, handler=None, response_choice=None, commit=False):\n        url = None\n\n        if method == HTTP_METHOD_POST:\n            url = self.get_resource_url_for_child_type(nurest_object.__class__)\n        else:\n            url = self.get_resource_url()\n\n        if response_choice is not None:\n            url += '?responseChoice=%s' % response_choice\n\n        request = NURESTRequest(method=method, url=url, data=nurest_object.to_dict())\n        user_info = {'nurest_object': nurest_object, 'commit': commit}\n\n        if not handler:\n            handler = self._did_perform_standard_operation\n\n        if async:\n\n            return self.send_request(request=request, async=async, local_callback=handler, remote_callback=callback, user_info=user_info)\n        else:\n            connection = self.send_request(request=request, user_info=user_info)\n            return handler(connection)", "response": "Low level child management. Sends given HTTP method with given nurest_object to given ressource of current object and returns the object and connection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when a response is received from the connection.", "response": "def _did_receive_response(self, connection):\n        \"\"\" Receive a response from the connection \"\"\"\n\n        if connection.has_timeouted:\n            bambou_logger.info(\"NURESTConnection has timeout.\")\n            return\n\n        has_callbacks = connection.has_callbacks()\n        should_post = not has_callbacks\n\n        if connection.handle_response_for_connection(should_post=should_post) and has_callbacks:\n            callback = connection.callbacks['local']\n            callback(connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _did_retrieve(self, connection):\n\n        response = connection.response\n\n        try:\n            self.from_dict(response.data[0])\n        except:\n            pass\n\n        return self._did_perform_standard_operation(connection)", "response": "Callback called after fetching the object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd given nurest_object to the current object and return the object and connection.", "response": "def create_child(self, nurest_object, response_choice=None, async=False, callback=None, commit=True):\n        \"\"\" Add given nurest_object to the current object\n\n            For example, to add a child into a parent, you can call\n            parent.create_child(nurest_object=child)\n\n            Args:\n                nurest_object (bambou.NURESTObject): the NURESTObject object to add\n                response_choice (int): Automatically send a response choice when confirmation is needed\n                async (bool): should the request be done asynchronously or not\n                callback (function): callback containing the object and the connection\n\n            Returns:\n                Returns the object and connection (object, connection)\n\n            Example:\n                >>> entity = NUEntity(name=\"Super Entity\")\n                >>> parent_entity.create_child(entity) # the new entity as been created in the parent_entity\n        \"\"\"\n\n        # if nurest_object.id:\n        #     raise InternalConsitencyError(\"Cannot create a child that already has an ID: %s.\" % nurest_object)\n\n        return self._manage_child_object(nurest_object=nurest_object,\n                                         async=async,\n                                         method=HTTP_METHOD_POST,\n                                         callback=callback,\n                                         handler=self._did_create_child,\n                                         response_choice=response_choice,\n                                         commit=commit)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _did_create_child(self, connection):\n\n        response = connection.response\n        try:\n            connection.user_info['nurest_object'].from_dict(response.data[0])\n        except Exception:\n            pass\n\n        return self._did_perform_standard_operation(connection)", "response": "Callback called after adding a new child nurest_object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassigning a list of objects into the current resource.", "response": "def assign(self, objects, nurest_object_type, async=False, callback=None, commit=True):\n        \"\"\" Reference a list of objects into the current resource\n\n            Args:\n                objects (list): list of NURESTObject to link\n                nurest_object_type (type): Type of the object to link\n                callback (function): Callback method that should be fired at the end\n\n            Returns:\n                Returns the current object and the connection (object, connection)\n\n            Example:\n                >>> entity.assign([entity1, entity2, entity3], NUEntity) # entity1, entity2 and entity3 are now part of the entity\n        \"\"\"\n\n        ids = list()\n\n        for nurest_object in objects:\n            ids.append(nurest_object.id)\n\n        url = self.get_resource_url_for_child_type(nurest_object_type)\n        request = NURESTRequest(method=HTTP_METHOD_PUT, url=url, data=ids)\n        user_info = {'nurest_objects': objects, 'commit': commit}\n\n        if async:\n            return self.send_request(request=request,\n                                     async=async,\n                                     local_callback=self._did_perform_standard_operation,\n                                     remote_callback=callback,\n                                     user_info=user_info)\n        else:\n            connection = self.send_request(request=request,\n                                           user_info=user_info)\n\n            return self._did_perform_standard_operation(connection)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomparing objects REST attributes", "response": "def rest_equals(self, rest_object):\n        \"\"\" Compare objects REST attributes\n\n        \"\"\"\n        if not self.equals(rest_object):\n            return False\n\n        return self.to_dict() == rest_object.to_dict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompares with another object.", "response": "def equals(self, rest_object):\n        \"\"\" Compare with another object \"\"\"\n\n        if self._is_dirty:\n            return False\n\n        if rest_object is None:\n            return False\n\n        if not isinstance(rest_object, NURESTObject):\n            raise TypeError('The object is not a NURESTObject %s' % rest_object)\n\n        if self.rest_name != rest_object.rest_name:\n            return False\n\n        if self.id and rest_object.id:\n            return self.id == rest_object.id\n\n        if self.local_id and rest_object.local_id:\n            return self.local_id == rest_object.local_id\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ip_address(request):\n    if 'HTTP_X_FORWARDED_FOR' in request.META:\n        return request.META['HTTP_X_FORWARDED_FOR'].split(',')[0].strip()\n    else:\n        return request.META['REMOTE_ADDR']", "response": "Returns the first IP address from the request. META."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_estimates_without_scope_in_month(self, customer):\n        estimates = self.get_price_estimates_for_customer(customer)\n        if not estimates:\n            return []\n\n        tables = {model: collections.defaultdict(list)\n                  for model in self.get_estimated_models()}\n\n        dates = set()\n        for estimate in estimates:\n            date = (estimate.year, estimate.month)\n            dates.add(date)\n\n            cls = estimate.content_type.model_class()\n            for model, table in tables.items():\n                if issubclass(cls, model):\n                    table[date].append(estimate)\n                    break\n\n        invalid_estimates = []\n        for date in dates:\n            if any(map(lambda table: len(table[date]) == 0, tables.values())):\n                for table in tables.values():\n                    invalid_estimates.extend(table[date])\n        print(invalid_estimates)\n        return invalid_estimates", "response": "Returns price estimates that are not scopeable in the given customer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a default value of the attribute_type", "response": "def get_default_value(self):\n        \"\"\" Get a default value of the attribute_type \"\"\"\n\n        if self.choices:\n            return self.choices[0]\n\n        value = self.attribute_type()\n\n        if self.attribute_type is time:\n            value = int(value)\n\n        elif self.attribute_type is str:\n            value = \"A\"\n\n        if self.min_length:\n            if self.attribute_type is str:\n                value = value.ljust(self.min_length, 'a')\n            elif self.attribute_type is int:\n                value = self.min_length\n\n        elif self.max_length:\n            if self.attribute_type is str:\n                value = value.ljust(self.max_length, 'a')\n            elif self.attribute_type is int:\n                value = self.max_length\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the minimum value of the attribute", "response": "def get_min_value(self):\n        \"\"\" Get the minimum value \"\"\"\n\n        value = self.get_default_value()\n\n        if self.attribute_type is str:\n            min_value = value[:self.min_length - 1]\n\n        elif self.attribute_type is int:\n            min_value = self.min_length - 1\n\n        else:\n            raise TypeError('Attribute %s can not have a minimum value' % self.local_name)\n\n        return min_value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_max_value(self):\n\n        value = self.get_default_value()\n\n        if self.attribute_type is str:\n            max_value = value.ljust(self.max_length + 1, 'a')\n\n        elif self.attribute_type is int:\n            max_value = self.max_length + 1\n\n        else:\n            raise TypeError('Attribute %s can not have a maximum value' % self.local_name)\n\n        return max_value", "response": "Get the maximum value of the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a basic root view.", "response": "def get_api_root_view(self, api_urls=None):\n        \"\"\"\n        Return a basic root view.\n        \"\"\"\n        api_root_dict = OrderedDict()\n        list_name = self.routes[0].name\n        for prefix, viewset, basename in self.registry:\n            api_root_dict[prefix] = list_name.format(basename=basename)\n\n        class APIRootView(views.APIView):\n            _ignore_model_permissions = True\n            exclude_from_schema = True\n\n            def get(self, request, *args, **kwargs):\n                # Return a plain {\"name\": \"hyperlink\"} response.\n                ret = OrderedDict()\n                namespace = request.resolver_match.namespace\n                for key, url_name in sorted(api_root_dict.items(), key=itemgetter(0)):\n                    if namespace:\n                        url_name = namespace + ':' + url_name\n                    try:\n                        ret[key] = reverse(\n                            url_name,\n                            args=args,\n                            kwargs=kwargs,\n                            request=request,\n                            format=kwargs.get('format', None)\n                        )\n                    except NoReverseMatch:\n                        # Don't bail out if eg. no list routes exist, only detail routes.\n                        continue\n\n                return Response(ret)\n\n        return APIRootView.as_view()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_default_base_name(self, viewset):\n        queryset = getattr(viewset, 'queryset', None)\n\n        if queryset is not None:\n            get_url_name = getattr(queryset.model, 'get_url_name', None)\n            if get_url_name is not None:\n                return get_url_name()\n\n        return super(SortedDefaultRouter, self).get_default_base_name(viewset)", "response": "Attempt to automatically determine base name using get_url_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef change_customer_nc_users_quota(sender, structure, user, role, signal, **kwargs):\n    assert signal in (signals.structure_role_granted, signals.structure_role_revoked), \\\n        'Handler \"change_customer_nc_users_quota\" has to be used only with structure_role signals'\n    assert sender in (Customer, Project), \\\n        'Handler \"change_customer_nc_users_quota\" works only with Project and Customer models'\n\n    if sender == Customer:\n        customer = structure\n    elif sender == Project:\n        customer = structure.customer\n\n    customer_users = customer.get_users()\n    customer.set_quota_usage(Customer.Quotas.nc_user_count, customer_users.count())", "response": "Modify nc_user_count quota usage on structure role grant or revoke"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete not shared service settings without services", "response": "def delete_service_settings_on_service_delete(sender, instance, **kwargs):\n    \"\"\" Delete not shared service settings without services \"\"\"\n    service = instance\n    try:\n        service_settings = service.settings\n    except ServiceSettings.DoesNotExist:\n        # If this handler works together with delete_service_settings_on_scope_delete\n        # it tries to delete service settings that are already deleted.\n        return\n    if not service_settings.shared:\n        service.settings.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete all service settings that are located in the VM that are located in the given scope.", "response": "def delete_service_settings_on_scope_delete(sender, instance, **kwargs):\n    \"\"\" If VM that contains service settings were deleted - all settings\n        resources could be safely deleted from NC.\n    \"\"\"\n    for service_settings in ServiceSettings.objects.filter(scope=instance):\n        service_settings.unlink_descendants()\n        service_settings.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the URL of the API endpoint that contains the data.", "response": "def url(self, url):\n        \"\"\" Set API URL endpoint\n\n            Args:\n                url: the url of the API endpoint\n        \"\"\"\n        if url and url.endswith('/'):\n            url = url[:-1]\n\n        self._url = url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the authentication string to place in Authorization Header", "response": "def get_authentication_header(self, user=None, api_key=None, password=None, certificate=None):\n        \"\"\" Return authenication string to place in Authorization Header\n\n            If API Token is set, it'll be used. Otherwise, the clear\n            text password will be sent. Users of NURESTLoginController are responsible to\n            clean the password property.\n\n            Returns:\n                Returns the XREST Authentication string with API Key or user password encoded.\n        \"\"\"\n\n        if not user:\n            user = self.user\n\n        if not api_key:\n            api_key = self.api_key\n\n        if not password:\n            password = self.password\n\n        if not password:\n            password = self.password\n\n        if not certificate:\n            certificate = self._certificate\n\n        if certificate:\n            return \"XREST %s\" % urlsafe_b64encode(\"{}:\".format(user).encode('utf-8')).decode('utf-8')\n\n        if api_key:\n            return \"XREST %s\" % urlsafe_b64encode(\"{}:{}\".format(user, api_key).encode('utf-8')).decode('utf-8')\n\n\n        return \"XREST %s\" % urlsafe_b64encode(\"{}:{}\".format(user, password).encode('utf-8')).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset(self):\n\n        self._is_impersonating = False\n        self._impersonation = None\n\n        self.user = None\n        self.password = None\n        self.api_key = None\n        self.enterprise = None\n        self.url = None", "response": "Reset the controller to its initial state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef impersonate(self, user, enterprise):\n\n        if not user or not enterprise:\n            raise ValueError('You must set a user name and an enterprise name to begin impersonification')\n\n        self._is_impersonating = True\n        self._impersonation = \"%s@%s\" % (user, enterprise)", "response": "Impersonate a user in an enterprise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying if the current controller corresponds to the current one.", "response": "def equals(self, controller):\n        \"\"\" Verify if the controller corresponds\n            to the current one.\n\n        \"\"\"\n        if controller is None:\n            return False\n\n        return self.user == controller.user and self.enterprise == controller.enterprise and self.url == controller.url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a WSGI application that can be used with a single WSGI server.", "response": "def create_application(server, root_url):\n    \"\"\"\n    WSGI adapter. It creates a simple WSGI application, that can be used with\n    any WSGI server. The arguments are:\n\n    #. ``server`` is a pyws server object,\n    #. ``root_url`` is an URL to which the server will be bound.\n\n    An application created by the function transforms WSGI environment into a\n    pyws request object. Then it feeds the request to the server, gets the\n    response, sets header ``Content-Type`` and returns response text.\n    \"\"\"\n\n    def serve(environ, start_response):\n\n        root = root_url.lstrip('/')\n\n        tail, get = (util.request_uri(environ).split('?') + [''])[:2]\n        tail = tail[len(util.application_uri(environ)):]\n        tail = tail.lstrip('/')\n\n        result = []\n\n        content_type = 'text/plain'\n        status = '200 OK'\n        if tail.startswith(root):\n\n            tail = tail[len(root):]\n\n            get = parse_qs(get)\n            method = environ['REQUEST_METHOD']\n\n            text, post = '', {}\n            if method == 'POST':\n                text = environ['wsgi.input'].\\\n                    read(int(environ.get('CONTENT_LENGTH', 0)))\n                post = parse_qs(text)\n\n            response = server.process_request(\n                Request(tail, text, get, post, {}))\n\n            content_type = response.content_type\n            status = get_http_response_code(response)\n            result.append(response.text)\n\n        headers = [('Content-type', content_type)]\n        start_response(status, headers)\n\n        return result\n\n    return serve"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_engine(\n        database,\n        minsize=1,\n        maxsize=10,\n        loop=None,\n        dialect=_dialect,\n        paramstyle=None,\n        **kwargs):\n    \"\"\"\n    A coroutine for Engine creation.\n\n    Returns Engine instance with embedded connection pool.\n\n    The pool has *minsize* opened connections to sqlite3.\n    \"\"\"\n    coro = _create_engine(\n        database=database,\n        minsize=minsize,\n        maxsize=maxsize,\n        loop=loop,\n        dialect=dialect,\n        paramstyle=paramstyle,\n        **kwargs\n    )\n    return _EngineContextManager(coro)", "response": "Create an engine and return a context manager."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef release(self, conn):\n        if conn.in_transaction:\n            raise InvalidRequestError(\n                \"Cannot release a connection with \"\n                \"not finished transaction\"\n            )\n        raw = conn.connection\n        res = yield from self._pool.release(raw)\n        return res", "response": "Revert back a connection to the pool."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn how much consumables are used by resource with current configuration.", "response": "def get_configuration(cls, resource):\n        \"\"\" Return how much consumables are used by resource with current configuration.\n\n            Output example:\n            {\n                <ConsumableItem instance>: <usage>,\n                <ConsumableItem instance>: <usage>,\n                ...\n            }\n        \"\"\"\n        strategy = cls._get_strategy(resource.__class__)\n        return strategy.get_configuration(resource)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the underlying DBAPI cursor corresponding to the execution.", "response": "def close(self):\n        \"\"\"Close this ResultProxy.\n        Closes the underlying DBAPI cursor corresponding to the execution.\n        Note that any data cached within this ResultProxy is still available.\n        For some types of results, this may include buffered rows.\n        If this ResultProxy was generated from an implicit execution,\n        the underlying Connection will also be closed (returns the\n        underlying DBAPI connection to the connection pool.)\n        This method is called automatically when:\n        * all result rows are exhausted using the fetchXXX() methods.\n        * cursor.description is None.\n        \"\"\"\n\n        if not self._closed:\n            self._closed = True\n            yield from self._cursor.close()\n            # allow consistent errors\n            self._cursor = None\n            self._weak = None\n        else:\n            # pragma: no cover\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nobtains the version number", "response": "def get_version():\n    \"\"\"Obtain the version number\"\"\"\n    import imp\n    import os\n    mod = imp.load_source(\n        'version', os.path.join('skdata', '__init__.py')\n    )\n    return mod.__version__"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef accept(self, request, uuid=None):\n        invitation = self.get_object()\n\n        if invitation.state != models.Invitation.State.PENDING:\n            raise ValidationError(_('Only pending invitation can be accepted.'))\n        elif invitation.civil_number and invitation.civil_number != request.user.civil_number:\n            raise ValidationError(_('User has an invalid civil number.'))\n\n        if invitation.project:\n            if invitation.project.has_user(request.user):\n                raise ValidationError(_('User already has role within this project.'))\n        elif invitation.customer.has_user(request.user):\n            raise ValidationError(_('User already has role within this customer.'))\n\n        if settings.WALDUR_CORE['VALIDATE_INVITATION_EMAIL'] and invitation.email != request.user.email:\n            raise ValidationError(_('Invitation and user emails mismatch.'))\n\n        replace_email = bool(request.data.get('replace_email'))\n        invitation.accept(request.user, replace_email=replace_email)\n        return Response({'detail': _('Invitation has been successfully accepted.')},\n                        status=status.HTTP_200_OK)", "response": "Accept an invitation for current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes all resources in the order they belong to.", "response": "def scope_deletion(sender, instance, **kwargs):\n    \"\"\" Run different actions on price estimate scope deletion.\n\n        If scope is a customer - delete all customer estimates and their children.\n        If scope is a deleted resource - redefine consumption details, recalculate\n                                         ancestors estimates and update estimate details.\n        If scope is a unlinked resource - delete all resource price estimates and update ancestors.\n        In all other cases - update price estimate details.\n    \"\"\"\n\n    is_resource = isinstance(instance, structure_models.ResourceMixin)\n    if is_resource and getattr(instance, 'PERFORM_UNLINK', False):\n        _resource_unlink(resource=instance)\n    elif is_resource and not getattr(instance, 'PERFORM_UNLINK', False):\n        _resource_deletion(resource=instance)\n    elif isinstance(instance, structure_models.Customer):\n        _customer_deletion(customer=instance)\n    else:\n        for price_estimate in models.PriceEstimate.objects.filter(scope=instance):\n            price_estimate.init_details()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _resource_deletion(resource):\n    if resource.__class__ not in CostTrackingRegister.registered_resources:\n        return\n    new_configuration = {}\n    price_estimate = models.PriceEstimate.update_resource_estimate(resource, new_configuration)\n    price_estimate.init_details()", "response": "Recalculate consumption details and save resource details"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resource_update(sender, instance, created=False, **kwargs):\n    resource = instance\n    try:\n        new_configuration = CostTrackingRegister.get_configuration(resource)\n    except ResourceNotRegisteredError:\n        return\n    models.PriceEstimate.update_resource_estimate(\n        resource, new_configuration, raise_exception=not _is_in_celery_task())\n    # Try to create historical price estimates\n    if created:\n        _create_historical_estimates(resource, new_configuration)", "response": "Update resource consumption details and price estimate if its configuration has changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates resource consumption details and price estimate if its configuration has changed", "response": "def resource_quota_update(sender, instance, **kwargs):\n    \"\"\" Update resource consumption details and price estimate if its configuration has changed \"\"\"\n    quota = instance\n    resource = quota.scope\n    try:\n        new_configuration = CostTrackingRegister.get_configuration(resource)\n    except ResourceNotRegisteredError:\n        return\n    models.PriceEstimate.update_resource_estimate(\n        resource, new_configuration, raise_exception=not _is_in_celery_task())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate historical consumption details and price estimates for the given resource and configuration.", "response": "def _create_historical_estimates(resource, configuration):\n    \"\"\" Create consumption details and price estimates for past months.\n\n        Usually we need to update historical values on resource import.\n    \"\"\"\n    today = timezone.now()\n    month_start = core_utils.month_start(today)\n    while month_start > resource.created:\n        month_start -= relativedelta(months=1)\n        models.PriceEstimate.create_historical(resource, configuration, max(month_start, resource.created))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef IPYTHON_MAIN():\n    import pkg_resources\n\n    runner_frame = inspect.getouterframes(inspect.currentframe())[-2]\n    return (\n        getattr(runner_frame, \"function\", None)\n        == pkg_resources.load_entry_point(\"ipython\", \"console_scripts\", \"ipython\").__name__\n    )", "response": "Decide if the Ipython command line is running code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_model(cls, model):\n\n        rest_name = model.rest_name\n        resource_name = model.resource_name\n\n        if rest_name not in cls._model_rest_name_registry:\n            cls._model_rest_name_registry[rest_name] = [model]\n            cls._model_resource_name_registry[resource_name] = [model]\n\n        elif model not in cls._model_rest_name_registry[rest_name]:\n            cls._model_rest_name_registry[rest_name].append(model)\n            cls._model_resource_name_registry[resource_name].append(model)", "response": "Register a model class according to its remote name\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the first model corresponding to a rest_name", "response": "def get_first_model_with_rest_name(cls, rest_name):\n        \"\"\" Get the first model corresponding to a rest_name\n\n            Args:\n                rest_name: the rest name\n        \"\"\"\n\n        models = cls.get_models_with_rest_name(rest_name)\n\n        if len(models) > 0:\n            return models[0]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_first_model_with_resource_name(cls, resource_name):\n\n        models = cls.get_models_with_resource_name(resource_name)\n\n        if len(models) > 0:\n            return models[0]\n\n        return None", "response": "Returns the first model with the given resource name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n        while not self._stoped:\n            self._tx_event.wait()\n            self._tx_event.clear()\n            try:\n                func = self._tx_queue.get_nowait()\n                if isinstance(func, str):\n                    self._stoped = True\n                    self._rx_queue.put('closed')\n                    self.notice()\n                    break\n            except Empty:\n                # pragma: no cover\n                continue\n            try:\n                result = func()\n                self._rx_queue.put(result)\n            except Exception as e:\n                self._rx_queue.put(e)\n            self.notice()\n        else:\n            # pragma: no cover\n            pass", "response": "run - Runs the thread - specific tasks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_layout(self, dset_id: str):\n        all_fields = list(self.get_data(dset_id=dset_id).keys())\n\n        try:\n            field_reference = self.skd[dset_id].attrs('target')\n        except:\n            field_reference = all_fields[0]\n\n        fields_comparison = [all_fields[1]]\n\n        # chart type widget\n        self.register_widget(\n            chart_type=widgets.RadioButtons(\n                options=['individual', 'grouped'],\n                value='individual',\n                description='Chart Type:'\n            )\n        )\n\n        # bins widget\n        self.register_widget(\n            bins=IntSlider(\n                description='Bins:',\n                min=2, max=10, value=2,\n                continuous_update=False\n            )\n        )\n\n        # fields comparison widget\n        self.register_widget(\n            xs=widgets.SelectMultiple(\n                description='Xs:',\n                options=[f for f in all_fields if not f == field_reference],\n                value=fields_comparison\n            )\n        )\n\n        # field reference widget\n        self.register_widget(\n            y=widgets.Dropdown(\n                description='Y:',\n                options=all_fields,\n                value=field_reference\n            )\n        )\n        # used to internal flow control\n        y_changed = [False]\n\n        self.register_widget(\n            box_filter_panel=widgets.VBox([\n                self._('y'), self._('xs'), self._('bins')\n            ])\n        )\n\n        # layout widgets\n        self.register_widget(\n            table=widgets.HTML(),\n            chart=widgets.HTML()\n        )\n\n        self.register_widget(vbox_chart=widgets.VBox([\n            self._('chart_type'), self._('chart')\n        ]))\n\n        self.register_widget(\n            tab=widgets.Tab(\n                children=[\n                    self._('box_filter_panel'),\n                    self._('table'),\n                    self._('vbox_chart')\n                ]\n            )\n        )\n\n        self.register_widget(dashboard=widgets.HBox([self._('tab')]))\n\n        # observe hooks\n        def w_y_change(change: dict):\n            \"\"\"\n            When y field was changed xs field should be updated and data table\n            and chart should be displayed/updated.\n\n            :param change:\n            :return:\n            \"\"\"\n            # remove reference field from the comparison field list\n            _xs = [\n                f for f in all_fields\n                if not f == change['new']\n            ]\n\n            y_changed[0] = True  # flow control variable\n            _xs_value = list(self._('xs').value)\n\n            if change['new'] in self._('xs').value:\n                _xs_value.pop(_xs_value.index(change['new']))\n                if not _xs_value:\n                    _xs_value = [_xs[0]]\n\n            self._('xs').options = _xs\n            self._('xs').value = _xs_value\n\n            self._display_result(y=change['new'], dset_id=dset_id)\n\n            y_changed[0] = False  # flow control variable\n\n        # widgets registration\n\n        # change tab settings\n        self._('tab').set_title(0, 'Filter')\n        self._('tab').set_title(1, 'Data')\n        self._('tab').set_title(2, 'Chart')\n\n        # data panel\n        self._('table').value = '...'\n\n        # chart panel\n        self._('chart').value = '...'\n\n        # create observe callbacks\n        self._('bins').observe(\n            lambda change: (\n                self._display_result(bins=change['new'], dset_id=dset_id)\n            ), 'value'\n        )\n        self._('y').observe(w_y_change, 'value')\n        # execute display result if 'y' was not changing.\n        self._('xs').observe(\n            lambda change: (\n                self._display_result(xs=change['new'], dset_id=dset_id)\n                if not y_changed[0] else None\n            ), 'value'\n        )\n        self._('chart_type').observe(\n            lambda change: (\n                self._display_result(chart_type=change['new'], dset_id=dset_id)\n            ), 'value'\n        )", "response": "Builds the layout for the given dset_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef display(self, dset_id: str):\n        # update result\n        self.skd[dset_id].compute()\n        # build layout\n        self.build_layout(dset_id=dset_id)\n        # display widgets\n        display(self._('dashboard'))\n        # display data table and chart\n        self._display_result(dset_id=dset_id)", "response": "displays the data table and chart for the given dset_id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to find the spec and use the underscore starring syntax to identify potential matches.", "response": "def find_spec(self, fullname, target=None):\n        \"\"\"Try to finder the spec and if it cannot be found, use the underscore starring syntax\n        to identify potential matches.\n        \"\"\"\n        spec = super().find_spec(fullname, target=target)\n\n        if spec is None:\n            original = fullname\n\n            if \".\" in fullname:\n                original, fullname = fullname.rsplit(\".\", 1)\n            else:\n                original, fullname = \"\", original\n\n            if \"_\" in fullname:\n                files = fuzzy_file_search(self.path, fullname)\n                if files:\n                    file = Path(sorted(files)[0])\n                    spec = super().find_spec(\n                        (original + \".\" + file.stem.split(\".\", 1)[0]).lstrip(\".\"), target=target\n                    )\n                    fullname = (original + \".\" + fullname).lstrip(\".\")\n                    if spec and fullname != spec.name:\n                        spec = FuzzySpec(\n                            spec.name,\n                            spec.loader,\n                            origin=spec.origin,\n                            loader_state=spec.loader_state,\n                            alias=fullname,\n                            is_package=bool(spec.submodule_search_locations),\n                        )\n        return spec"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_resource_url(self):\n\n        name = self.__class__.resource_name\n        url = self.__class__.rest_base_url()\n\n        return \"%s/%s\" % (url, name)", "response": "Get resource complete url"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the user and perform the callback method", "response": "def save(self, async=False, callback=None, encrypted=True):\n        \"\"\" Updates the user and perform the callback method \"\"\"\n\n        if self._new_password and encrypted:\n            self.password = Sha1.encrypt(self._new_password)\n\n        controller = NURESTSession.get_current_session().login_controller\n        controller.password = self._new_password\n        controller.api_key = None\n\n        data = json.dumps(self.to_dict())\n        request = NURESTRequest(method=HTTP_METHOD_PUT, url=self.get_resource_url(), data=data)\n\n        if async:\n            return self.send_request(request=request, async=async, local_callback=self._did_save, remote_callback=callback)\n        else:\n            connection = self.send_request(request=request)\n            return self._did_save(connection)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when the save has been successfully executed", "response": "def _did_save(self, connection):\n        \"\"\" Launched when save has been successfully executed \"\"\"\n\n        self._new_password = None\n\n        controller = NURESTSession.get_current_session().login_controller\n        controller.password = None\n        controller.api_key = self.api_key\n\n        if connection.async:\n            callback = connection.callbacks['remote']\n\n            if connection.user_info:\n                callback(connection.user_info, connection)\n            else:\n                callback(self, connection)\n        else:\n            return (self, connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches all information about the current object in the system.", "response": "def fetch(self, async=False, callback=None):\n        \"\"\" Fetch all information about the current object\n\n            Args:\n                async (bool): Boolean to make an asynchronous call. Default is False\n                callback (function): Callback method that will be triggered in case of asynchronous call\n\n            Returns:\n                tuple: (current_fetcher, callee_parent, fetched_bjects, connection)\n\n            Example:\n                >>> entity = NUEntity(id=\"xxx-xxx-xxx-xxx\")\n                >>> entity.fetch() # will get the entity with id \"xxx-xxx-xxx-xxx\"\n                >>> print entity.name\n                \"My Entity\"\n        \"\"\"\n        request = NURESTRequest(method=HTTP_METHOD_GET, url=self.get_resource_url())\n\n        if async:\n            return self.send_request(request=request, async=async, local_callback=self._did_fetch, remote_callback=callback)\n        else:\n            connection = self.send_request(request=request)\n            return self._did_retrieve(connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef retired(self):\n\n        def gen():\n            import csv\n            import re\n            from datetime import datetime\n            from pkg_resources import resource_filename\n\n            with open(resource_filename(__package__, 'iso-639-3_Retirements.tab')) as rf:\n                rtd = list(csv.reader(rf, delimiter='\\t'))[1:]\n                rc = [r[0] for r in rtd]\n                for i, _, _, m, s, d in rtd:\n                    d = datetime.strptime(d, '%Y-%m-%d')\n                    if not m:\n                        m = re.findall('\\[([a-z]{3})\\]', s)\n                    if m:\n                        m = [m] if isinstance(m, str) else m\n                        yield i, (d, [self.get(part3=x) for x in m if x not in rc], s)\n                    else:\n                        yield i, (d, [], s)\n\n            yield 'sh', self.get(part3='hbs')  # Add 'sh' as deprecated\n\n        return dict(gen())", "response": "Returns a dictionary of code and description for retired languages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self, request, *args, **kwargs):\n        return super(CustomerViewSet, self).list(request, *args, **kwargs)", "response": "This method is used to get a list of customers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve(self, request, *args, **kwargs):\n        return super(CustomerViewSet, self).retrieve(request, *args, **kwargs)", "response": "This method is used to retrieve the related customer record sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, request, *args, **kwargs):\n        return super(CustomerViewSet, self).create(request, *args, **kwargs)", "response": "A custom create method that returns a new customer with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, request, *args, **kwargs):\n        return super(ProjectViewSet, self).list(request, *args, **kwargs)", "response": "Returns a list of projects that are currently connected to the current user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve(self, request, *args, **kwargs):\n        return super(ProjectViewSet, self).retrieve(request, *args, **kwargs)", "response": "This method is used to retrieve the related resource class information."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, request, *args, **kwargs):\n        return super(ProjectViewSet, self).create(request, *args, **kwargs)", "response": "A new project can be created by users with staff privilege or customer owners."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef destroy(self, request, *args, **kwargs):\n        return super(ProjectViewSet, self).destroy(request, *args, **kwargs)", "response": "This method is used to delete a project instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange a user s password", "response": "def password(self, request, uuid=None):\n        \"\"\"\n        To change a user password, submit a **POST** request to the user's RPC URL, specifying new password\n        by staff user or account owner.\n\n        Password is expected to be at least 7 symbols long and contain at least one number\n        and at least one lower or upper case.\n\n        Example of a valid request:\n\n        .. code-block:: http\n\n            POST /api/users/e0c058d06864441fb4f1c40dee5dd4fd/password/ HTTP/1.1\n            Content-Type: application/json\n            Accept: application/json\n            Authorization: Token c84d653b9ec92c6cbac41c706593e66f567a7fa4\n            Host: example.com\n\n            {\n                \"password\": \"nQvqHzeP123\",\n            }\n        \"\"\"\n        user = self.get_object()\n\n        serializer = serializers.PasswordSerializer(data=request.data)\n        serializer.is_valid(raise_exception=True)\n\n        new_password = serializer.validated_data['password']\n        user.set_password(new_password)\n        user.save()\n\n        return Response({'detail': _('Password has been successfully updated.')},\n                        status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproject permissions expresses connection of user to a project. User may have either project manager or system administrator permission in the project. Use */api/project-permissions/* endpoint to maintain project permissions. Note that project permissions can be viewed and modified only by customer owners and staff users. To list all visible permissions, run a **GET** query against a list. Response will contain a list of project users and their brief data. To add a new user to the project, **POST** a new relationship to */api/project-permissions/* endpoint specifying project, user and the role of the user ('admin' or 'manager'): .. code-block:: http POST /api/project-permissions/ HTTP/1.1 Accept: application/json Authorization: Token 95a688962bf68678fd4c8cec4d138ddd9493c93b Host: example.com { \"project\": \"http://example.com/api/projects/6c9b01c251c24174a6691a1f894fae31/\", \"role\": \"manager\", \"user\": \"http://example.com/api/users/82cec6c8e0484e0ab1429412fe4194b7/\" }", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"\n        Project permissions expresses connection of user to a project.\n        User may have either project manager or system administrator permission in the project.\n        Use */api/project-permissions/* endpoint to maintain project permissions.\n\n        Note that project permissions can be viewed and modified only by customer owners and staff users.\n\n        To list all visible permissions, run a **GET** query against a list.\n        Response will contain a list of project users and their brief data.\n\n        To add a new user to the project, **POST** a new relationship to */api/project-permissions/* endpoint specifying\n        project, user and the role of the user ('admin' or 'manager'):\n\n        .. code-block:: http\n\n            POST /api/project-permissions/ HTTP/1.1\n            Accept: application/json\n            Authorization: Token 95a688962bf68678fd4c8cec4d138ddd9493c93b\n            Host: example.com\n\n            {\n                \"project\": \"http://example.com/api/projects/6c9b01c251c24174a6691a1f894fae31/\",\n                \"role\": \"manager\",\n                \"user\": \"http://example.com/api/users/82cec6c8e0484e0ab1429412fe4194b7/\"\n            }\n        \"\"\"\n        return super(ProjectPermissionViewSet, self).list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of SSH keys for the current user.", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"\n        To get a list of SSH keys, run **GET** against */api/keys/* as authenticated user.\n\n        A new SSH key can be created by any active users. Example of a valid request:\n\n        .. code-block:: http\n\n            POST /api/keys/ HTTP/1.1\n            Content-Type: application/json\n            Accept: application/json\n            Authorization: Token c84d653b9ec92c6cbac41c706593e66f567a7fa4\n            Host: example.com\n\n            {\n                \"name\": \"ssh_public_key1\",\n                \"public_key\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDDURXDP5YhOQUYoDuTxJ84DuzqMJYJqJ8+SZT28\n                               TtLm5yBDRLKAERqtlbH2gkrQ3US58gd2r8H9jAmQOydfvgwauxuJUE4eDpaMWupqquMYsYLB5f+vVGhdZbbzfc6DTQ2rY\n                               dknWoMoArlG7MvRMA/xQ0ye1muTv+mYMipnd7Z+WH0uVArYI9QBpqC/gpZRRIouQ4VIQIVWGoT6M4Kat5ZBXEa9yP+9du\n                               D2C05GX3gumoSAVyAcDHn/xgej9pYRXGha4l+LKkFdGwAoXdV1z79EG1+9ns7wXuqMJFHM2KDpxAizV0GkZcojISvDwuh\n                               vEAFdOJcqjyyH4FOGYa8usP1 jhon@example.com\",\n            }\n        \"\"\"\n        return super(SshKeyViewSet, self).list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all service settings owned by this user.", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"\n        To get a list of service settings, run **GET** against */api/service-settings/* as an authenticated user.\n        Only settings owned by this user or shared settings will be listed.\n\n        Supported filters are:\n\n        - ?name=<text> - partial matching used for searching\n        - ?type=<type> - choices: OpenStack, DigitalOcean, Amazon, JIRA, GitLab, Oracle\n        - ?state=<state> - choices: New, Creation Scheduled, Creating, Sync Scheduled, Syncing, In Sync, Erred\n        - ?shared=<bool> - allows to filter shared service settings\n        \"\"\"\n        return super(ServiceSettingsViewSet, self).list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the service settings.", "response": "def update(self, request, *args, **kwargs):\n        \"\"\"\n        To update service settings, issue a **PUT** or **PATCH** to */api/service-settings/<uuid>/* as a customer owner.\n        You are allowed to change name and credentials only.\n\n        Example of a request:\n\n        .. code-block:: http\n\n            PATCH /api/service-settings/9079705c17d64e6aa0af2e619b0e0702/ HTTP/1.1\n            Content-Type: application/json\n            Accept: application/json\n            Authorization: Token c84d653b9ec92c6cbac41c706593e66f567a7fa4\n            Host: example.com\n\n            {\n                \"username\": \"admin\",\n                \"password\": \"new_secret\"\n            }\n        \"\"\"\n        return super(ServiceSettingsViewSet, self).update(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self, request, *args, **kwargs):\n\n        return super(ResourceSummaryViewSet, self).list(request, *args, **kwargs)", "response": "Return a list of resources with SLA attached to the resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count(self, request):\n        queryset = self.filter_queryset(self.get_queryset())\n        return Response({SupportedServices.get_name_for_model(qs.model): qs.count()\n                         for qs in queryset.querysets})", "response": "Count resources by type. Example output :\n            Count resources by type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters services by type", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"\n        Filter services by type\n        ^^^^^^^^^^^^^^^^^^^^^^^\n\n        It is possible to filter services by their types. Example:\n\n          /api/services/?service_type=DigitalOcean&service_type=OpenStack\n        \"\"\"\n        return super(ServicesViewSet, self).list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nallow to execute action only if shared settings are not set.", "response": "def _require_staff_for_shared_settings(request, view, obj=None):\n        \"\"\" Allow to execute action only if service settings are not shared or user is staff \"\"\"\n        if obj is None:\n            return\n\n        if obj.settings.shared and not request.user.is_staff:\n            raise PermissionDenied(_('Only staff users are allowed to import resources from shared services.'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlink with Waldur resource.", "response": "def link(self, request, uuid=None):\n        \"\"\"\n        To get a list of resources available for import, run **GET** against */<service_endpoint>/link/*\n        as an authenticated user.\n        Optionally project_uuid parameter can be supplied for services requiring it like OpenStack.\n\n        To import (link with Waldur) resource issue **POST** against the same endpoint with resource id.\n\n        .. code-block:: http\n\n            POST /api/openstack/08039f01c9794efc912f1689f4530cf0/link/ HTTP/1.1\n            Content-Type: application/json\n            Accept: application/json\n            Authorization: Token c84d653b9ec92c6cbac41c706593e66f567a7fa4\n            Host: example.com\n\n            {\n                \"backend_id\": \"bd5ec24d-9164-440b-a9f2-1b3c807c5df3\",\n                \"project\": \"http://example.com/api/projects/e5f973af2eb14d2d8c38d62bcbaccb33/\"\n            }\n        \"\"\"\n\n        service = self.get_object()\n\n        if self.request.method == 'GET':\n            try:\n                backend = self.get_backend(service)\n                try:\n                    resources = backend.get_resources_for_import(**self.get_import_context())\n                except ServiceBackendNotImplemented:\n                    resources = []\n\n                page = self.paginate_queryset(resources)\n                if page is not None:\n                    return self.get_paginated_response(page)\n\n                return Response(resources)\n            except (ServiceBackendError, ValidationError) as e:\n                raise APIException(e)\n\n        else:\n            serializer = self.get_serializer(data=request.data)\n            serializer.is_valid(raise_exception=True)\n\n            try:\n                resource = serializer.save()\n            except ServiceBackendError as e:\n                raise APIException(e)\n\n            resource_imported.send(\n                sender=resource.__class__,\n                instance=resource,\n            )\n\n            return Response(serializer.data, status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unlink(self, request, uuid=None):\n        service = self.get_object()\n        service.unlink_descendants()\n        self.perform_destroy(service)\n\n        return Response(status=status.HTTP_204_NO_CONTENT)", "response": "Unlink all related resources service project link and service itself."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, request, *args, **kwargs):\n        return super(BaseServiceProjectLinkViewSet, self).list(request, *args, **kwargs)", "response": "This method is used to get a list of all available service - service connections."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching ancestors quotas that have the same name and are registered as aggregator quotas.", "response": "def get_aggregator_quotas(self, quota):\n        \"\"\" Fetch ancestors quotas that have the same name and are registered as aggregator quotas. \"\"\"\n        ancestors = quota.scope.get_quota_ancestors()\n        aggregator_quotas = []\n        for ancestor in ancestors:\n            for ancestor_quota_field in ancestor.get_quotas_fields(field_class=AggregatorQuotaField):\n                if ancestor_quota_field.get_child_quota_name() == quota.name:\n                    aggregator_quotas.append(ancestor.quotas.get(name=ancestor_quota_field))\n        return aggregator_quotas"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new event handler.", "response": "def subscribe(self, handler):\n        \"\"\"Adds a new event handler.\"\"\"\n        assert callable(handler), \"Invalid handler %s\" % handler\n        self.handlers.append(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsubscribes to the specified event.", "response": "def on(self, event, handler):\n        \"\"\"Attaches the handler to the specified event.\n\n        @param event: event to attach the handler to. Any object can be passed\n                      as event, but string is preferable. If qcore.EnumBase\n                      instance is passed, its name is used as event key.\n        @param handler: event handler.\n        @return: self, so calls like this can be chained together.\n\n        \"\"\"\n        event_hook = self.get_or_create(event)\n        event_hook.subscribe(handler)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef off(self, event, handler):\n        event_hook = self.get_or_create(event)\n        event_hook.unsubscribe(handler)\n        return self", "response": "Detaches the handler from the specified event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trigger(self, event, *args):\n        event_hook = self.get_or_create(event)\n        event_hook.trigger(*args)\n        return self", "response": "Triggers the specified event by invoking EventHook. trigger under the hood."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_trigger(self, event, *args):\n        event_hook = self.get_or_create(event)\n        event_hook.safe_trigger(*args)\n        return self", "response": "Safely triggers the specified event by invoking EventHook. safe_trigger under the hood."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_or_create(self, event):\n        if isinstance(event, EnumBase):\n            event = event.short_name\n        return self.__dict__.setdefault(event, EventHook())", "response": "Gets or creates a new event hook for the specified event."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pseudo_abi_for_input(s, timeout=None, proxies=None):\n        sighash = Utils.bytes_to_str(s[:4])\n        for pseudo_abi in FourByteDirectory.get_pseudo_abi_for_sighash(sighash, timeout=timeout, proxies=proxies):\n            types = [ti[\"type\"] for ti in pseudo_abi['inputs']]\n            try:\n                # test decoding\n                _ = decode_abi(types, s[4:])\n                yield pseudo_abi\n            except eth_abi.exceptions.DecodingError as e:\n                continue", "response": "Given a 4bytes. directory return a list of pseudo abi for the input."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the contract json abi for sighash lookups and fast access", "response": "def _prepare_abi(self, jsonabi):\n        \"\"\"\n        Prepare the contract json abi for sighash lookups and fast access\n\n        :param jsonabi: contracts abi in json format\n        :return:\n        \"\"\"\n        self.signatures = {}\n        for element_description in jsonabi:\n            abi_e = AbiMethod(element_description)\n            if abi_e[\"type\"] == \"constructor\":\n                self.signatures[b\"__constructor__\"] = abi_e\n            elif abi_e[\"type\"] == \"fallback\":\n                abi_e.setdefault(\"inputs\", [])\n                self.signatures[b\"__fallback__\"] = abi_e\n            elif abi_e[\"type\"] == \"function\":\n                # function and signature present\n                # todo: we could generate the sighash ourselves? requires keccak256\n                if abi_e.get(\"signature\"):\n                    self.signatures[Utils.str_to_bytes(abi_e[\"signature\"])] = abi_e\n            elif abi_e[\"type\"] == \"event\":\n                self.signatures[b\"__event__\"] = abi_e\n            else:\n                raise Exception(\"Invalid abi type: %s - %s - %s\" % (abi_e.get(\"type\"),\n                                                                    element_description, abi_e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndescribes the input bytesequence s based on the loaded contract abi definition", "response": "def describe_constructor(self, s):\n        \"\"\"\n        Describe the input bytesequence (constructor arguments) s based on the loaded contract\n         abi definition\n\n        :param s: bytes constructor arguments\n        :return: AbiMethod instance\n        \"\"\"\n        method = self.signatures.get(b\"__constructor__\")\n        if not method:\n            # constructor not available\n            m = AbiMethod({\"type\": \"constructor\", \"name\": \"\", \"inputs\": [], \"outputs\": []})\n            return m\n\n        types_def = method[\"inputs\"]\n        types = [t[\"type\"] for t in types_def]\n        names = [t[\"name\"] for t in types_def]\n\n        if not len(s):\n            values = len(types) * [\"<nA>\"]\n        else:\n            values = decode_abi(types, s)\n\n        # (type, name, data)\n        method.inputs = [{\"type\": t, \"name\": n, \"data\": v} for t, n, v in list(\n            zip(types, names, values))]\n        return method"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef describe_input(self, s):\n        signatures = self.signatures.items()\n\n        for sighash, method in signatures:\n            if sighash is None or sighash.startswith(b\"__\"):\n                continue  # skip constructor\n\n            if s.startswith(sighash):\n                s = s[len(sighash):]\n\n                types_def = self.signatures.get(sighash)[\"inputs\"]\n                types = [t[\"type\"] for t in types_def]\n                names = [t[\"name\"] for t in types_def]\n\n                if not len(s):\n                    values = len(types) * [\"<nA>\"]\n                else:\n                    values = decode_abi(types, s)\n\n                # (type, name, data)\n                method.inputs = [{\"type\": t, \"name\": n, \"data\": v} for t, n, v in list(\n                    zip(types, names, values))]\n                return method\n        else:\n            method = AbiMethod({\"type\": \"fallback\",\n                                \"name\": \"__fallback__\",\n                                \"inputs\": [], \"outputs\": []})\n            types_def = self.signatures.get(b\"__fallback__\", {\"inputs\": []})[\"inputs\"]\n            types = [t[\"type\"] for t in types_def]\n            names = [t[\"name\"] for t in types_def]\n\n            values = decode_abi(types, s)\n\n            # (type, name, data)\n            method.inputs = [{\"type\": t, \"name\": n, \"data\": v} for t, n, v in list(\n                zip(types, names, values))]\n            return method", "response": "Describe the input bytesequence s based on the loaded contract abi definition\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new AbiMethod object from an input stream containing the input stream s.", "response": "def from_input_lookup(s):\n        \"\"\"\n        Return a new AbiMethod object from an input stream\n        :param s: binary input\n        :return: new AbiMethod object matching the provided input stream\n        \"\"\"\n        for pseudo_abi in FourByteDirectory.get_pseudo_abi_for_input(s):\n            method = AbiMethod(pseudo_abi)\n            types_def = pseudo_abi[\"inputs\"]\n            types = [t[\"type\"] for t in types_def]\n            names = [t[\"name\"] for t in types_def]\n\n            values = decode_abi(types, s[4:])\n\n            # (type, name, data)\n            method.inputs = [{\"type\": t, \"name\": n, \"data\": v} for t, n, v in list(\n                zip(types, names, values))]\n            return method"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise an AssertionError if expected is not actual.", "response": "def assert_is(expected, actual, message=None, extra=None):\n    \"\"\"Raises an AssertionError if expected is not actual.\"\"\"\n    assert expected is actual, _assert_fail_message(\n        message, expected, actual, \"is not\", extra\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises an AssertionError if expected is actual.", "response": "def assert_is_not(expected, actual, message=None, extra=None):\n    \"\"\"Raises an AssertionError if expected is actual.\"\"\"\n    assert expected is not actual, _assert_fail_message(\n        message, expected, actual, \"is\", extra\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise an AssertionError if value is not an instance of types.", "response": "def assert_is_instance(value, types, message=None, extra=None):\n    \"\"\"Raises an AssertionError if value is not an instance of type(s).\"\"\"\n    assert isinstance(value, types), _assert_fail_message(\n        message, value, types, \"is not an instance of\", extra\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_eq(expected, actual, message=None, tolerance=None, extra=None):\n    if tolerance is None:\n        assert expected == actual, _assert_fail_message(\n            message, expected, actual, \"!=\", extra\n        )\n    else:\n        assert isinstance(tolerance, _number_types), (\n            \"tolerance parameter to assert_eq must be a number: %r\" % tolerance\n        )\n        assert isinstance(expected, _number_types) and isinstance(\n            actual, _number_types\n        ), (\n            \"parameters must be numbers when tolerance is specified: %r, %r\"\n            % (expected, actual)\n        )\n\n        diff = abs(expected - actual)\n        assert diff <= tolerance, _assert_fail_message(\n            message, expected, actual, \"is more than %r away from\" % tolerance, extra\n        )", "response": "Raises an AssertionError if expected!= actual."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assert_dict_eq(expected, actual, number_tolerance=None, dict_path=[]):\n    assert_is_instance(expected, dict)\n    assert_is_instance(actual, dict)\n\n    expected_keys = set(expected.keys())\n    actual_keys = set(actual.keys())\n    assert expected_keys <= actual_keys, \"Actual dict at %s is missing keys: %r\" % (\n        _dict_path_string(dict_path),\n        expected_keys - actual_keys,\n    )\n    assert actual_keys <= expected_keys, \"Actual dict at %s has extra keys: %r\" % (\n        _dict_path_string(dict_path),\n        actual_keys - expected_keys,\n    )\n\n    for k in expected_keys:\n        key_path = dict_path + [k]\n        assert_is_instance(\n            actual[k],\n            type(expected[k]),\n            extra=\"Types don't match for %s\" % _dict_path_string(key_path),\n        )\n        assert_is_instance(\n            expected[k],\n            type(actual[k]),\n            extra=\"Types don't match for %s\" % _dict_path_string(key_path),\n        )\n\n        if isinstance(actual[k], dict):\n            assert_dict_eq(\n                expected[k],\n                actual[k],\n                number_tolerance=number_tolerance,\n                dict_path=key_path,\n            )\n        elif isinstance(actual[k], _number_types):\n            assert_eq(\n                expected[k],\n                actual[k],\n                extra=\"Value doesn't match for %s\" % _dict_path_string(key_path),\n                tolerance=number_tolerance,\n            )\n        else:\n            assert_eq(\n                expected[k],\n                actual[k],\n                extra=\"Value doesn't match for %s\" % _dict_path_string(key_path),\n            )", "response": "Asserts that two dictionaries are equal producing a custom message if they are not."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assert_gt(left, right, message=None, extra=None):\n    assert left > right, _assert_fail_message(message, left, right, \"<=\", extra)", "response": "Raises an AssertionError if left_hand < = right_hand."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nraises an AssertionError if left_hand < right_hand.", "response": "def assert_ge(left, right, message=None, extra=None):\n    \"\"\"Raises an AssertionError if left_hand < right_hand.\"\"\"\n    assert left >= right, _assert_fail_message(message, left, right, \"<\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nraises an AssertionError if left_hand < right_hand.", "response": "def assert_lt(left, right, message=None, extra=None):\n    \"\"\"Raises an AssertionError if left_hand >= right_hand.\"\"\"\n    assert left < right, _assert_fail_message(message, left, right, \">=\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise an AssertionError if left_hand > right_hand.", "response": "def assert_le(left, right, message=None, extra=None):\n    \"\"\"Raises an AssertionError if left_hand > right_hand.\"\"\"\n    assert left <= right, _assert_fail_message(message, left, right, \">\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising an AssertionError if obj is not in seq.", "response": "def assert_in(obj, seq, message=None, extra=None):\n    \"\"\"Raises an AssertionError if obj is not in seq.\"\"\"\n    assert obj in seq, _assert_fail_message(message, obj, seq, \"is not in\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nraise an AssertionError if obj is in iter.", "response": "def assert_not_in(obj, seq, message=None, extra=None):\n    \"\"\"Raises an AssertionError if obj is in iter.\"\"\"\n    # for very long strings, provide a truncated error\n    if isinstance(seq, six.string_types) and obj in seq and len(seq) > 200:\n        index = seq.find(obj)\n        start_index = index - 50\n        if start_index > 0:\n            truncated = \"(truncated) ...\"\n        else:\n            truncated = \"\"\n            start_index = 0\n        end_index = index + len(obj) + 50\n        truncated += seq[start_index:end_index]\n        if end_index < len(seq):\n            truncated += \"... (truncated)\"\n        assert False, _assert_fail_message(message, obj, truncated, \"is in\", extra)\n    assert obj not in seq, _assert_fail_message(message, obj, seq, \"is in\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising an AssertionError if obj is not in seq using assert_eq cmp.", "response": "def assert_in_with_tolerance(obj, seq, tolerance, message=None, extra=None):\n    \"\"\"Raises an AssertionError if obj is not in seq using assert_eq cmp.\"\"\"\n    for i in seq:\n        try:\n            assert_eq(obj, i, tolerance=tolerance, message=message, extra=extra)\n            return\n        except AssertionError:\n            pass\n    assert False, _assert_fail_message(message, obj, seq, \"is not in\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assert_is_substring(substring, subject, message=None, extra=None):\n    assert (\n        (subject is not None)\n        and (substring is not None)\n        and (subject.find(substring) != -1)\n    ), _assert_fail_message(message, substring, subject, \"is not in\", extra)", "response": "Raises an AssertionError if substring is not a substring of subject."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nraising an AssertionError if substring is a substring of subject.", "response": "def assert_is_not_substring(substring, subject, message=None, extra=None):\n    \"\"\"Raises an AssertionError if substring is a substring of subject.\"\"\"\n    assert (\n        (subject is not None)\n        and (substring is not None)\n        and (subject.find(substring) == -1)\n    ), _assert_fail_message(message, substring, subject, \"is in\", extra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assert_unordered_list_eq(expected, actual, message=None):\n    missing_in_actual = []\n    missing_in_expected = list(actual)\n    for x in expected:\n        try:\n            missing_in_expected.remove(x)\n        except ValueError:\n            missing_in_actual.append(x)\n\n    if missing_in_actual or missing_in_expected:\n        if not message:\n            message = (\n                \"%r not equal to %r; missing items: %r in expected, %r in actual.\"\n                % (expected, actual, missing_in_expected, missing_in_actual)\n            )\n        assert False, message", "response": "Raises an AssertionError if the objects contained\n    in expected are not equal to the objects contained\n    in actual without regard to their order."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes function only if one of input parameters is not empty", "response": "def _execute_if_not_empty(func):\n    \"\"\" Execute function only if one of input parameters is not empty \"\"\"\n    def wrapper(*args, **kwargs):\n        if any(args[1:]) or any(kwargs.items()):\n            return func(*args, **kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreparing the elasticsearch query for elasticsearch query", "response": "def prepare_search_body(self, should_terms=None, must_terms=None, must_not_terms=None, search_text='', start=None, end=None):\n        \"\"\"\n        Prepare body for elasticsearch query\n\n        Search parameters\n        ^^^^^^^^^^^^^^^^^\n        These parameters are dictionaries and have format:  <term>: [<value 1>, <value 2> ...]\n        should_terms: it resembles logical OR\n        must_terms: it resembles logical AND\n        must_not_terms: it resembles logical NOT\n\n        search_text : string\n            Text for FTS(full text search)\n        start, end : datetime\n            Filter for event creation time\n        \"\"\"\n        self.body = self.SearchBody()\n        self.body.set_should_terms(should_terms)\n        self.body.set_must_terms(must_terms)\n        self.body.set_must_not_terms(must_not_terms)\n        self.body.set_search_text(search_text)\n        self.body.set_timestamp_filter(start, end)\n        self.body.prepare()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(cls, instance, async=True, countdown=2, is_heavy_task=False, **kwargs):\n        cls.pre_apply(instance, async=async, **kwargs)\n        result = cls.apply_signature(instance, async=async, countdown=countdown,\n                                     is_heavy_task=is_heavy_task, **kwargs)\n        cls.post_apply(instance, async=async, **kwargs)\n        return result", "response": "Execute high level - operation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_signature(cls, instance, async=True, countdown=None, is_heavy_task=False, **kwargs):\n        serialized_instance = utils.serialize_instance(instance)\n\n        signature = cls.get_task_signature(instance, serialized_instance, **kwargs)\n        link = cls.get_success_signature(instance, serialized_instance, **kwargs)\n        link_error = cls.get_failure_signature(instance, serialized_instance, **kwargs)\n\n        if async:\n            return signature.apply_async(link=link, link_error=link_error, countdown=countdown,\n                                         queue=is_heavy_task and 'heavy' or None)\n        else:\n            result = signature.apply()\n            callback = link if not result.failed() else link_error\n            if callback is not None:\n                cls._apply_callback(callback, result)\n\n        return result.get()", "response": "Serialize input data and apply signature"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a description in format for the given entity.", "response": "def get_entity_description(entity):\n    \"\"\"\n    Returns description in format:\n    * entity human readable name\n     * docstring\n    \"\"\"\n\n    try:\n        entity_name = entity.__name__.strip('_')\n    except AttributeError:\n        # entity is a class instance\n        entity_name = entity.__class__.__name__\n\n    label = '* %s' % formatting.camelcase_to_spaces(entity_name)\n    if entity.__doc__ is not None:\n        entity_docstring = formatting.dedent(smart_text(entity.__doc__)).replace('\\n', '\\n\\t')\n        return '%s\\n * %s' % (label, entity_docstring)\n\n    return label"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_validators_description(view):\n    action = getattr(view, 'action', None)\n    if action is None:\n        return ''\n\n    description = ''\n    validators = getattr(view, action + '_validators', [])\n    for validator in validators:\n        validator_description = get_entity_description(validator)\n        description += '\\n' + validator_description if description else validator_description\n\n    return '### Validators:\\n' + description if description else ''", "response": "Returns a string describing the validators in the order they appear in the view."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_actions_permission_description(view, method):\n    action = getattr(view, 'action', None)\n    if action is None:\n        return ''\n\n    if hasattr(view, action + '_permissions'):\n        permission_types = (action,)\n    elif method in SAFE_METHODS:\n        permission_types = ('safe_methods', '%s_extra' % action)\n    else:\n        permission_types = ('unsafe_methods', '%s_extra' % action)\n\n    description = ''\n    for permission_type in permission_types:\n        action_perms = getattr(view, permission_type + '_permissions', [])\n        for permission in action_perms:\n            action_perm_description = get_entity_description(permission)\n            description += '\\n' + action_perm_description if description else action_perm_description\n\n    return description", "response": "Returns the description of the actions permissions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_permissions_description(view, method):\n    if not hasattr(view, 'permission_classes'):\n        return ''\n\n    description = ''\n    for permission_class in view.permission_classes:\n        if permission_class == core_permissions.ActionsPermission:\n            actions_perm_description = get_actions_permission_description(view, method)\n            if actions_perm_description:\n                description += '\\n' + actions_perm_description if description else actions_perm_description\n            continue\n        perm_description = get_entity_description(permission_class)\n        description += '\\n' + perm_description if description else perm_description\n\n    return '### Permissions:\\n' + description if description else ''", "response": "Returns a string with the description of the permissions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_validation_description(view, method):\n    if method not in ('PUT', 'PATCH', 'POST') or not hasattr(view, 'get_serializer'):\n        return ''\n\n    serializer = view.get_serializer()\n    description = ''\n    if hasattr(serializer, 'validate') and serializer.validate.__doc__ is not None:\n        description += formatting.dedent(smart_text(serializer.validate.__doc__))\n\n    for field in serializer.fields.values():\n        if not hasattr(serializer, 'validate_' + field.field_name):\n            continue\n\n        field_validation = getattr(serializer, 'validate_' + field.field_name)\n\n        if field_validation.__doc__ is not None:\n            docstring = formatting.dedent(smart_text(field_validation.__doc__)).replace('\\n', '\\n\\t')\n            field_description = '* %s\\n * %s' % (field.field_name, docstring)\n            description += '\\n' + field_description if description else field_description\n\n    return '### Validation:\\n' + description if description else ''", "response": "Returns the validation description in format for a given view and method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_field_type(field):\n    if isinstance(field, core_filters.MappedMultipleChoiceFilter):\n        return ' | '.join(['\"%s\"' % f for f in sorted(field.mapped_to_model)])\n    if isinstance(field, OrderingFilter) or isinstance(field, ChoiceFilter):\n        return ' | '.join(['\"%s\"' % f[0] for f in field.extra['choices']])\n    if isinstance(field, ChoiceField):\n        return ' | '.join(['\"%s\"' % f for f in sorted(field.choices)])\n    if isinstance(field, HyperlinkedRelatedField):\n        if field.view_name.endswith('detail'):\n            return 'link to %s' % reverse(field.view_name,\n                                          kwargs={'%s' % field.lookup_field: \"'%s'\" % field.lookup_field})\n        return reverse(field.view_name)\n    if isinstance(field, structure_filters.ServiceTypeFilter):\n        return ' | '.join(['\"%s\"' % f for f in SupportedServices.get_filter_mapping().keys()])\n    if isinstance(field, ResourceTypeFilter):\n        return ' | '.join(['\"%s\"' % f for f in SupportedServices.get_resource_models().keys()])\n    if isinstance(field, core_serializers.GenericRelatedField):\n        links = []\n        for model in field.related_models:\n            detail_view_name = core_utils.get_detail_view_name(model)\n            for f in field.lookup_fields:\n                try:\n                    link = reverse(detail_view_name, kwargs={'%s' % f: \"'%s'\" % f})\n                except NoReverseMatch:\n                    pass\n                else:\n                    links.append(link)\n                    break\n        path = ', '.join(links)\n        if path:\n            return 'link to any: %s' % path\n    if isinstance(field, core_filters.ContentTypeFilter):\n        return \"string in form 'app_label'.'model_name'\"\n    if isinstance(field, ModelMultipleChoiceFilter):\n        return get_field_type(field.field)\n    if isinstance(field, ListSerializer):\n        return 'list of [%s]' % get_field_type(field.child)\n    if isinstance(field, ManyRelatedField):\n        return 'list of [%s]' % get_field_type(field.child_relation)\n    if isinstance(field, ModelField):\n        return get_field_type(field.model_field)\n\n    name = field.__class__.__name__\n    for w in ('Filter', 'Field', 'Serializer'):\n        name = name.replace(w, '')\n    return FIELDS.get(name, name)", "response": "Returns the field type and possible values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_disabled_action(view):\n    if not isinstance(view, core_views.ActionsViewSet):\n        return False\n\n    action = getattr(view, 'action', None)\n    return action in view.disabled_actions if action is not None else False", "response": "Checks whether Link action is disabled."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_allowed_methods(self, callback):\n        if hasattr(callback, 'actions'):\n            return [method.upper() for method in callback.actions.keys() if method != 'head']\n\n        return [\n            method for method in\n            callback.cls().allowed_methods if method not in ('OPTIONS', 'HEAD')\n        ]", "response": "Return a list of the HTTP methods that can be used for this endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a callback method request return an actual view instance.", "response": "def create_view(self, callback, method, request=None):\n        \"\"\"\n        Given a callback, return an actual view instance.\n        \"\"\"\n        view = super(WaldurSchemaGenerator, self).create_view(callback, method, request)\n        if is_disabled_action(view):\n            view.exclude_from_schema = True\n\n        return view"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_description(self, path, method, view):\n        description = super(WaldurSchemaGenerator, self).get_description(path, method, view)\n\n        permissions_description = get_permissions_description(view, method)\n        if permissions_description:\n            description += '\\n\\n' + permissions_description if description else permissions_description\n\n        if isinstance(view, core_views.ActionsViewSet):\n            validators_description = get_validators_description(view)\n            if validators_description:\n                description += '\\n\\n' + validators_description if description else validators_description\n\n        validation_description = get_validation_description(view, method)\n        if validation_description:\n            description += '\\n\\n' + validation_description if description else validation_description\n\n        return description", "response": "Determine a link description."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of coreapi. Field instances corresponding to any applet entry in the request body.", "response": "def get_serializer_fields(self, path, method, view):\n        \"\"\"\n        Return a list of `coreapi.Field` instances corresponding to any\n        request body input, as determined by the serializer class.\n        \"\"\"\n        if method not in ('PUT', 'PATCH', 'POST'):\n            return []\n\n        if not hasattr(view, 'get_serializer'):\n            return []\n\n        serializer = view.get_serializer()\n        if not isinstance(serializer, Serializer):\n            return []\n\n        fields = []\n        for field in serializer.fields.values():\n            if field.read_only or isinstance(field, HiddenField):\n                continue\n\n            required = field.required and method != 'PATCH'\n            description = force_text(field.help_text) if field.help_text else ''\n            field_type = get_field_type(field)\n            description += '; ' + field_type if description else field_type\n            field = coreapi.Field(\n                name=field.field_name,\n                location='form',\n                required=required,\n                description=description,\n                schema=schemas.field_to_schema(field),\n            )\n            fields.append(field)\n\n        return fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete error message if instance state changed from erred", "response": "def delete_error_message(sender, instance, name, source, target, **kwargs):\n    \"\"\" Delete error message if instance state changed from erred \"\"\"\n    if source != StateMixin.States.ERRED:\n        return\n    instance.error_message = ''\n    instance.save(update_fields=['error_message'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind version string in the file", "response": "def find_version(*file_paths):\n    \"\"\"\n    read __init__.py\n    \"\"\"\n    file_path = os.path.join(*file_paths)\n    with open(file_path, 'r') as version_file:\n        line = version_file.readline()\n        while line:\n            if line.startswith('__version__'):\n                version_match = re.search(\n                    r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\",\n                    line,\n                    re.M\n                )\n                if version_match:\n                    return version_match.group(1)\n            line = version_file.readline()\n    raise RuntimeError('Unable to find version string.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trace(enter=False, exit=True):\n\n    def decorate(fn):\n        @inspection.wraps(fn)\n        def new_fn(*args, **kwargs):\n            name = fn.__module__ + \".\" + fn.__name__\n            if enter:\n                print(\n                    \"%s(args = %s, kwargs = %s) <-\" % (name, repr(args), repr(kwargs))\n                )\n            try:\n                result = fn(*args, **kwargs)\n                if exit:\n                    print(\n                        \"%s(args = %s, kwargs = %s) -> %s\"\n                        % (name, repr(args), repr(kwargs), repr(result))\n                    )\n                return result\n            except Exception as e:\n                if exit:\n                    print(\n                        \"%s(args = %s, kwargs = %s) -> thrown %s\"\n                        % (name, repr(args), repr(kwargs), str(e))\n                    )\n                raise\n\n        return new_fn\n\n    return decorate", "response": "This decorator prints entry and exit message when the decorated method is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_value(self, value):\n        member = self.__new__(self, value)\n        member.__init__(value)\n        return member", "response": "Instantiates an arbitrary value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, name, members):\n        NewEnum = type(name, (cls,), {})\n\n        if isinstance(members, dict):\n            members = members.items()\n        for member in members:\n            if isinstance(member, tuple):\n                name, value = member\n                setattr(NewEnum, name, value)\n            elif isinstance(member, EnumBase):\n                setattr(NewEnum, member.short_name, member.value)\n            else:\n                assert False, (\n                    \"members must be either a dict, \"\n                    + \"a list of (name, value) tuples, \"\n                    + \"or a list of EnumBase instances.\"\n                )\n\n        NewEnum.process()\n\n        # needed for pickling to work (hopefully); taken from the namedtuple implementation in the\n        # standard library\n        try:\n            NewEnum.__module__ = sys._getframe(1).f_globals.get(\"__name__\", \"__main__\")\n        except (AttributeError, ValueError):\n            pass\n\n        return NewEnum", "response": "Creates a new enum type based on this one and adds members to the newly created subclass of cls."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses an enum member name or value into an enum member.", "response": "def parse(cls, value, default=_no_default):\n        \"\"\"Parses an enum member name or value into an enum member.\n\n        Accepts the following types:\n        - Members of this enum class. These are returned directly.\n        - Integers. If there is an enum member with the integer as a value, that member is returned.\n        - Strings. If there is an enum member with the string as its name, that member is returned.\n        For integers and strings that don't correspond to an enum member, default is returned; if\n        no default is given the function raises KeyError instead.\n\n        Examples:\n\n        >>> class Color(Enum):\n        ...     red = 1\n        ...     blue = 2\n        >>> Color.parse(Color.red)\n        Color.red\n        >>> Color.parse(1)\n        Color.red\n        >>> Color.parse('blue')\n        Color.blue\n\n        \"\"\"\n        if isinstance(value, cls):\n            return value\n        elif isinstance(value, six.integer_types) and not isinstance(value, EnumBase):\n            e = cls._value_to_member.get(value, _no_default)\n        else:\n            e = cls._name_to_member.get(value, _no_default)\n        if e is _no_default or not e.is_valid():\n            if default is _no_default:\n                raise _create_invalid_value_error(cls, value)\n            return default\n        return e"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a string or integer into a Flags instance.", "response": "def parse(cls, value, default=_no_default):\n        \"\"\"Parses a flag integer or string into a Flags instance.\n\n        Accepts the following types:\n        - Members of this enum class. These are returned directly.\n        - Integers. These are converted directly into a Flags instance with the given name.\n        - Strings. The function accepts a comma-delimited list of flag names, corresponding to\n          members of the enum. These are all ORed together.\n\n        Examples:\n\n        >>> class Car(Flags):\n        ...     is_big = 1\n        ...     has_wheels = 2\n        >>> Car.parse(1)\n        Car.is_big\n        >>> Car.parse(3)\n        Car.parse('has_wheels,is_big')\n        >>> Car.parse('is_big,has_wheels')\n        Car.parse('has_wheels,is_big')\n\n        \"\"\"\n        if isinstance(value, cls):\n            return value\n        elif isinstance(value, int):\n            e = cls._make_value(value)\n        else:\n            if not value:\n                e = cls._make_value(0)\n            else:\n                r = 0\n                for k in value.split(\",\"):\n                    v = cls._name_to_member.get(k, _no_default)\n                    if v is _no_default:\n                        if default is _no_default:\n                            raise _create_invalid_value_error(cls, value)\n                        else:\n                            return default\n                    r |= v.value\n                e = cls._make_value(r)\n        if not e.is_valid():\n            if default is _no_default:\n                raise _create_invalid_value_error(cls, value)\n            return default\n        return e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all available price list items.", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"\n        To get a list of price list items, run **GET** against */api/price-list-items/* as an authenticated user.\n        \"\"\"\n        return super(PriceListItemViewSet, self).list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, request, *args, **kwargs):\n        return super(PriceListItemViewSet, self).create(request, *args, **kwargs)", "response": "Create a new price list item."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, request, *args, **kwargs):\n        return super(PriceListItemViewSet, self).update(request, *args, **kwargs)", "response": "Update the item with the given request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete the current item and all its children.", "response": "def destroy(self, request, *args, **kwargs):\n        \"\"\"\n        Run **DELETE** request against */api/price-list-items/<uuid>/* to delete price list item.\n        Only customer owner and staff can delete price items.\n        \"\"\"\n        return super(PriceListItemViewSet, self).destroy(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of available price list items for the current user.", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"\n        To get a list of default price list items, run **GET** against */api/default-price-list-items/*\n        as authenticated user.\n\n        Price lists can be filtered by:\n         - ?key=<string>\n         - ?item_type=<string> has to be from list of available item_types\n           (available options: 'flavor', 'storage', 'license-os', 'license-application', 'network', 'support')\n         - ?resource_type=<string> resource type, for example: 'OpenStack.Instance, 'Oracle.Database')\n        \"\"\"\n        return super(DefaultPriceListItemViewSet, self).list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self, request, *args, **kwargs):\n        return super(MergedPriceListItemViewSet, self).list(request, *args, **kwargs)", "response": "Returns a list of merged price list items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Remote(path=None, loader=Notebook, **globals):\n\n    class Remote(RemoteMixin, loader):\n        ...\n\n    return Remote(path=path, **globals)", "response": "A remote notebook finder."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget permission checks that will be executed for current action.", "response": "def get_permission_checks(self, request, view):\n        \"\"\"\n        Get permission checks that will be executed for current action.\n        \"\"\"\n        if view.action is None:\n            return []\n        # if permissions are defined for view directly - use them.\n        if hasattr(view, view.action + '_permissions'):\n            return getattr(view, view.action + '_permissions')\n        # otherwise return view-level permissions + extra view permissions\n        extra_permissions = getattr(view, view.action + 'extra_permissions', [])\n        if request.method in SAFE_METHODS:\n            return getattr(view, 'safe_methods_permissions', []) + extra_permissions\n        else:\n            return getattr(view, 'unsafe_methods_permissions', []) + extra_permissions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_function(self, function):\n        #noinspection PyTypeChecker\n        if not len(self.settings.FUNCTION_MANAGERS):\n            raise ConfigurationError(\n                'Where have the default function manager gone?!')\n        self.settings.FUNCTION_MANAGERS[0].add_function(function)", "response": "Adds a function to the default fixed function manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat a raw field as a string.", "response": "def format_raw_field(key):\n    \"\"\"\n    When ElasticSearch analyzes string, it breaks it into parts.\n    In order make query for not-analyzed exact string values, we should use subfield instead.\n\n    The index template for Elasticsearch 5.0 has been changed.\n    The subfield for string multi-fields has changed from .raw to .keyword\n\n    Thus workaround for backward compatibility during migration is required.\n    See also: https://github.com/elastic/logstash/blob/v5.4.1/docs/static/breaking-changes.asciidoc\n    \"\"\"\n    subfield = django_settings.WALDUR_CORE.get('ELASTICSEARCH', {}).get('raw_subfield', 'keyword')\n    return '%s.%s' % (camel_case_to_underscore(key), subfield)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a decorator function that applies the decorator_cls that was passed in.", "response": "def decorate(decorator_cls, *args, **kwargs):\n    \"\"\"Creates a decorator function that applies the decorator_cls that was passed in.\"\"\"\n    global _wrappers\n\n    wrapper_cls = _wrappers.get(decorator_cls, None)\n    if wrapper_cls is None:\n\n        class PythonWrapper(decorator_cls):\n            pass\n\n        wrapper_cls = PythonWrapper\n        wrapper_cls.__name__ = decorator_cls.__name__ + \"PythonWrapper\"\n        _wrappers[decorator_cls] = wrapper_cls\n\n    def decorator(fn):\n        wrapped = wrapper_cls(fn, *args, **kwargs)\n        _update_wrapper(wrapped, fn)\n        return wrapped\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deprecated(replacement_description):\n\n    def decorate(fn_or_class):\n        if isinstance(fn_or_class, type):\n            pass  # Can't change __doc__ of type objects\n        else:\n            try:\n                fn_or_class.__doc__ = \"This API point is obsolete. %s\\n\\n%s\" % (\n                    replacement_description,\n                    fn_or_class.__doc__,\n                )\n            except AttributeError:\n                pass  # For Cython method descriptors, etc.\n        return fn_or_class\n\n    return decorate", "response": "A decorator that marks a class as deprecated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retry(exception_cls, max_tries=10, sleep=0.05):\n\n    assert max_tries > 0\n\n    def with_max_retries_call(delegate):\n        for i in xrange(0, max_tries):\n            try:\n                return delegate()\n            except exception_cls:\n                if i + 1 == max_tries:\n                    raise\n                time.sleep(sleep)\n\n    def outer(fn):\n        is_generator = inspect.isgeneratorfunction(fn)\n\n        @functools.wraps(fn)\n        def retry_fun(*args, **kwargs):\n            return with_max_retries_call(lambda: fn(*args, **kwargs))\n\n        @functools.wraps(fn)\n        def retry_generator_fun(*args, **kwargs):\n            def get_first_item():\n                results = fn(*args, **kwargs)\n                for first_result in results:\n                    return [first_result], results\n                return [], results\n\n            cache, generator = with_max_retries_call(get_first_item)\n\n            for item in cache:\n                yield item\n\n            for item in generator:\n                yield item\n\n        if not is_generator:\n            # so that qcore.inspection.get_original_fn can retrieve the original function\n            retry_fun.fn = fn\n            # Necessary for pickling of Cythonized functions to work. Cython's __reduce__\n            # method always returns the original name of the function.\n            retry_fun.__reduce__ = lambda: fn.__name__\n            return retry_fun\n        else:\n            retry_generator_fun.fn = fn\n            retry_generator_fun.__reduce__ = lambda: fn.__name__\n            return retry_generator_fun\n\n    return outer", "response": "Decorator for retrying a function if it throws an exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a context manager into a decorator.", "response": "def decorator_of_context_manager(ctxt):\n    \"\"\"Converts a context manager into a decorator.\n\n    This decorator will run the decorated function in the context of the\n    manager.\n\n    :param ctxt: Context to run the function in.\n    :return: Wrapper around the original function.\n\n    \"\"\"\n\n    def decorator_fn(*outer_args, **outer_kwargs):\n        def decorator(fn):\n            @functools.wraps(fn)\n            def wrapper(*args, **kwargs):\n                with ctxt(*outer_args, **outer_kwargs):\n                    return fn(*args, **kwargs)\n\n            return wrapper\n\n        return decorator\n\n    if getattr(ctxt, \"__doc__\", None) is None:\n        msg = \"Decorator that runs the inner function in the context of %s\"\n        decorator_fn.__doc__ = msg % ctxt\n    else:\n        decorator_fn.__doc__ = ctxt.__doc__\n    return decorator_fn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the quota change of an object is exceeded.", "response": "def validate_quota_change(self, quota_deltas, raise_exception=False):\n        \"\"\"\n        Get error messages about object and his ancestor quotas that will be exceeded if quota_delta will be added.\n\n        raise_exception - if True QuotaExceededException will be raised if validation fails\n        quota_deltas - dictionary of quotas deltas, example:\n        {\n            'ram': 1024,\n            'storage': 2048,\n            ...\n        }\n        Example of output:\n            ['ram quota limit: 1024, requires: 2048(instance#1)', ...]\n\n        \"\"\"\n        errors = []\n        for name, delta in six.iteritems(quota_deltas):\n            quota = self.quotas.get(name=name)\n            if quota.is_exceeded(delta):\n                errors.append('%s quota limit: %s, requires %s (%s)\\n' % (\n                    quota.name, quota.limit, quota.usage + delta, quota.scope))\n        if not raise_exception:\n            return errors\n        else:\n            if errors:\n                raise exceptions.QuotaExceededException(_('One or more quotas were exceeded: %s') % ';'.join(errors))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_sum_of_quotas_as_dict(cls, scopes, quota_names=None, fields=['usage', 'limit']):\n        if not scopes:\n            return {}\n\n        if quota_names is None:\n            quota_names = cls.get_quotas_names()\n\n        scope_models = set([scope._meta.model for scope in scopes])\n        if len(scope_models) > 1:\n            raise exceptions.QuotaError(_('All scopes have to be instances of the same model.'))\n\n        filter_kwargs = {\n            'content_type': ct_models.ContentType.objects.get_for_model(scopes[0]),\n            'object_id__in': [scope.id for scope in scopes],\n            'name__in': quota_names\n        }\n\n        result = {}\n        if 'usage' in fields:\n            items = Quota.objects.filter(**filter_kwargs)\\\n                         .values('name').annotate(usage=Sum('usage'))\n            for item in items:\n                result[item['name'] + '_usage'] = item['usage']\n\n        if 'limit' in fields:\n            unlimited_quotas = Quota.objects.filter(limit=-1, **filter_kwargs)\n            unlimited_quotas = list(unlimited_quotas.values_list('name', flat=True))\n            for quota_name in unlimited_quotas:\n                result[quota_name] = -1\n\n            items = Quota.objects\\\n                         .filter(**filter_kwargs)\\\n                         .exclude(name__in=unlimited_quotas)\\\n                         .values('name')\\\n                         .annotate(limit=Sum('limit'))\n            for item in items:\n                result[item['name']] = item['limit']\n\n        return result", "response": "Returns a dictionary with sum of all scopes quotas."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self, request, *args, **kwargs):\n        self.queryset = self.filter_queryset(self.get_queryset())\n\n        page = self.paginate_queryset(self.queryset)\n        if page is not None:\n            return self.get_paginated_response(page)\n        return response.Response(self.queryset)", "response": "Returns a list of events that are connected to the current user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a count of events.", "response": "def count(self, request, *args, **kwargs):\n        \"\"\"\n        To get a count of events - run **GET** against */api/events/count/* as authenticated user.\n        Endpoint support same filters as events list.\n\n        Response example:\n\n        .. code-block:: javascript\n\n            {\"count\": 12321}\n        \"\"\"\n\n        self.queryset = self.filter_queryset(self.get_queryset())\n        return response.Response({'count': self.queryset.count()}, status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts the number of events in a specific time range.", "response": "def count_history(self, request, *args, **kwargs):\n        \"\"\"\n        To get a historical data of events amount - run **GET** against */api/events/count/history/*.\n        Endpoint support same filters as events list.\n        More about historical data - read at section *Historical data*.\n\n        Response example:\n\n        .. code-block:: javascript\n\n            [\n                {\n                    \"point\": 141111111111,\n                    \"object\": {\n                        \"count\": 558\n                    }\n                }\n            ]\n        \"\"\"\n        queryset = self.filter_queryset(self.get_queryset())\n\n        mapped = {\n            'start': request.query_params.get('start'),\n            'end': request.query_params.get('end'),\n            'points_count': request.query_params.get('points_count'),\n            'point_list': request.query_params.getlist('point'),\n        }\n        serializer = core_serializers.HistorySerializer(data={k: v for k, v in mapped.items() if v})\n        serializer.is_valid(raise_exception=True)\n\n        timestamp_ranges = [{'end': point_date} for point_date in serializer.get_filter_data()]\n        aggregated_count = queryset.aggregated_count(timestamp_ranges)\n\n        return response.Response(\n            [{'point': int(ac['end']), 'object': {'count': ac['count']}} for ac in aggregated_count],\n            status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scope_types(self, request, *args, **kwargs):\n        return response.Response(utils.get_scope_types_mapping().keys())", "response": "Returns a list of scope types acceptable by events filter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(self, request, *args, **kwargs):\n        return super(AlertViewSet, self).list(request, *args, **kwargs)", "response": "Get a list of all alerts related to a given resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, request, *args, **kwargs):\n        return super(AlertViewSet, self).create(request, *args, **kwargs)", "response": "Create an alert for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses the current alert.", "response": "def close(self, request, *args, **kwargs):\n        \"\"\"\n        To close alert - run **POST** against */api/alerts/<alert_uuid>/close/*. No data is required.\n        Only users with staff privileges can close alerts.\n        \"\"\"\n        if not request.user.is_staff:\n            raise PermissionDenied()\n        alert = self.get_object()\n        alert.close()\n\n        return response.Response(status=status.HTTP_204_NO_CONTENT)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stats(self, request, *args, **kwargs):\n        queryset = self.filter_queryset(self.get_queryset())\n        alerts_severities_count = queryset.values('severity').annotate(count=Count('severity'))\n\n        severity_names = dict(models.Alert.SeverityChoices.CHOICES)\n        # For consistency with all other endpoint we need to return severity names in lower case.\n        alerts_severities_count = {\n            severity_names[asc['severity']].lower(): asc['count'] for asc in alerts_severities_count}\n        for severity_name in severity_names.values():\n            if severity_name.lower() not in alerts_severities_count:\n                alerts_severities_count[severity_name.lower()] = 0\n\n        return response.Response(alerts_severities_count, status=status.HTTP_200_OK)", "response": "This endpoint returns the count of alerts per severities per alert."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new web hook.", "response": "def create(self, request, *args, **kwargs):\n        \"\"\"\n        To create new web hook issue **POST** against */api/hooks-web/* as an authenticated user.\n        You should specify list of event_types or event_groups.\n\n        Example of a request:\n\n        .. code-block:: http\n\n            POST /api/hooks-web/ HTTP/1.1\n            Content-Type: application/json\n            Accept: application/json\n            Authorization: Token c84d653b9ec92c6cbac41c706593e66f567a7fa4\n            Host: example.com\n\n            {\n                \"event_types\": [\"resource_start_succeeded\"],\n                \"event_groups\": [\"users\"],\n                \"destination_url\": \"http://example.com/\"\n            }\n\n        When hook is activated, **POST** request is issued against destination URL with the following data:\n\n        .. code-block:: javascript\n\n            {\n                \"timestamp\": \"2015-07-14T12:12:56.000000\",\n                \"message\": \"Customer ABC LLC has been updated.\",\n                \"type\": \"customer_update_succeeded\",\n                \"context\": {\n                    \"user_native_name\": \"Walter Lebrowski\",\n                    \"customer_contact_details\": \"\",\n                    \"user_username\": \"Walter\",\n                    \"user_uuid\": \"1c3323fc4ae44120b57ec40dea1be6e6\",\n                    \"customer_uuid\": \"4633bbbb0b3a4b91bffc0e18f853de85\",\n                    \"ip_address\": \"8.8.8.8\",\n                    \"user_full_name\": \"Walter Lebrowski\",\n                    \"customer_abbreviation\": \"ABC LLC\",\n                    \"customer_name\": \"ABC LLC\"\n                },\n                \"levelname\": \"INFO\"\n            }\n\n        Note that context depends on event type.\n        \"\"\"\n        return super(WebHookViewSet, self).create(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new email hook.", "response": "def create(self, request, *args, **kwargs):\n        \"\"\"\n        To create new email hook issue **POST** against */api/hooks-email/* as an authenticated user.\n        You should specify list of event_types or event_groups.\n\n        Example of a request:\n\n        .. code-block:: http\n\n            POST /api/hooks-email/ HTTP/1.1\n            Content-Type: application/json\n            Accept: application/json\n            Authorization: Token c84d653b9ec92c6cbac41c706593e66f567a7fa4\n            Host: example.com\n\n            {\n                \"event_types\": [\"openstack_instance_start_succeeded\"],\n                \"event_groups\": [\"users\"],\n                \"email\": \"test@example.com\"\n            }\n\n        You may temporarily disable hook without deleting it by issuing following **PATCH** request against hook URL:\n\n        .. code-block:: javascript\n\n            {\n                \"is_active\": \"false\"\n            }\n        \"\"\"\n        return super(EmailHookViewSet, self).create(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, request, *args, **kwargs):\n        return super(PushHookViewSet, self).create(request, *args, **kwargs)", "response": "Create a new push hook."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting this instrument s settings from the given file. Will throw ImportException if the file does not exist.", "response": "def import_from_file(self, index, filename):\n        \"\"\"Import this instrument's settings from the given file. Will\n        automatically add the instrument's synth and table to the song's\n        synths and tables if needed.\n\n        Note that this may invalidate existing instrument accessor objects.\n\n        :param index: the index into which to import\n\n        :param filename: the file from which to load\n\n        :raises ImportException: if importing failed, usually because the song\n          doesn't have enough synth or table slots left for the instrument's\n          synth or table\n        \"\"\"\n\n        with open(filename, 'r') as fp:\n            self._import_from_struct(index, json.load(fp))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a Project from a. lsdsng file.", "response": "def load_lsdsng(filename):\n    \"\"\"Load a Project from a ``.lsdsng`` file.\n\n    :param filename: the name of the file from which to load\n    :rtype: :py:class:`pylsdj.Project`\n    \"\"\"\n\n    # Load preamble data so that we know the name and version of the song\n    with open(filename, 'rb') as fp:\n        preamble_data = bread.parse(fp, spec.lsdsng_preamble)\n\n    with open(filename, 'rb') as fp:\n        # Skip the preamble this time around\n        fp.seek(int(len(preamble_data) / 8))\n\n        # Load compressed data into a block map and use BlockReader to\n        # decompress it\n        factory = BlockFactory()\n\n        while True:\n            block_data = bytearray(fp.read(blockutils.BLOCK_SIZE))\n\n            if len(block_data) == 0:\n                break\n\n            block = factory.new_block()\n            block.data = block_data\n\n        remapped_blocks = filepack.renumber_block_keys(factory.blocks)\n\n        reader = BlockReader()\n        compressed_data = reader.read(remapped_blocks)\n\n        # Now, decompress the raw data and use it and the preamble to construct\n        # a Project\n        raw_data = filepack.decompress(compressed_data)\n\n        name = preamble_data.name\n        version = preamble_data.version\n        size_blks = int(math.ceil(\n            float(len(compressed_data)) / blockutils.BLOCK_SIZE))\n\n        return Project(name, version, size_blks, raw_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_srm(filename):\n\n    # .srm files are just decompressed projects without headers\n\n    # In order to determine the file's size in compressed blocks, we have to\n    # compress it first\n    with open(filename, 'rb') as fp:\n        raw_data = fp.read()\n\n    compressed_data = filepack.compress(raw_data)\n\n    factory = BlockFactory()\n    writer = BlockWriter()\n    writer.write(compressed_data, factory)\n\n    size_in_blocks = len(factory.blocks)\n\n    # We'll give the file a dummy name (\"SRMLOAD\") and version, since we know\n    # neither\n    name = \"SRMLOAD\"\n    version = 0\n\n    return Project(name, version, size_in_blocks, raw_data)", "response": "Load a Project from an. srm file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef song(self):\n        if self._song is None:\n            self._song = Song(self._song_data)\n\n        return self._song", "response": "the song associated with the project"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, filename):\n        with open(filename, 'wb') as fp:\n            writer = BlockWriter()\n            factory = BlockFactory()\n\n            preamble_dummy_bytes = bytearray([0] * 9)\n            preamble = bread.parse(\n                preamble_dummy_bytes, spec.lsdsng_preamble)\n            preamble.name = self.name\n            preamble.version = self.version\n\n            preamble_data = bread.write(preamble)\n            raw_data = self.get_raw_data()\n            compressed_data = filepack.compress(raw_data)\n\n            writer.write(compressed_data, factory)\n\n            fp.write(preamble_data)\n\n            for key in sorted(factory.blocks.keys()):\n                fp.write(bytearray(factory.blocks[key].data))", "response": "Save a project in. lsdsng format to the target file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_srm(self, filename):\n        with open(filename, 'wb') as fp:\n            raw_data = bread.write(self._song_data, spec.song)\n            fp.write(raw_data)", "response": "Save a project in. srm format to the target file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef phase_type(self, value):\n        '''compresses the waveform horizontally; one of\n        ``\"normal\"``, ``\"resync\"``, ``\"resync2\"``'''\n        self._params.phase_type = value\n        self._overwrite_lock.disable()", "response": "compresses the waveform horizontally ; one of\n        normal resync resync2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef project_list(self):\n        return [(i, self.projects[i]) for i in sorted(self.projects.keys())]", "response": "The list of project tuples that the the\n. sav file contains"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave this object to a file.", "response": "def save(self, filename, callback=_noop_callback):\n        \"\"\"Save this file.\n\n        :param filename: the file to which to save the .sav file\n        :type filename: str\n        :param callback: a progress callback function\n        :type callback: function\n        \"\"\"\n        with open(filename, 'wb') as fp:\n            self._save(fp, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split(compressed_data, segment_size, block_factory):\n\n    # Split compressed data into blocks\n    segments = []\n\n    current_segment_start = 0\n    index = 0\n    data_size = len(compressed_data)\n\n    while index < data_size:\n        current_byte = compressed_data[index]\n\n        if index < data_size - 1:\n            next_byte = compressed_data[index + 1]\n        else:\n            next_byte = None\n\n        jump_size = 1\n\n        if current_byte == RLE_BYTE:\n            assert next_byte is not None, \"Expected a command to follow \" \\\n                \"RLE byte\"\n            if next_byte == RLE_BYTE:\n                jump_size = 2\n            else:\n                jump_size = 3\n\n        elif current_byte == SPECIAL_BYTE:\n            assert next_byte is not None, \"Expected a command to follow \" \\\n                \"special byte\"\n\n            if next_byte == SPECIAL_BYTE:\n                jump_size = 2\n            elif next_byte == DEFAULT_INSTR_BYTE or \\\n                    next_byte == DEFAULT_WAVE_BYTE:\n                jump_size = 3\n            else:\n                assert False, \"Encountered unexpected EOF or block \" \\\n                    \"switch while segmenting\"\n\n        # Need two bytes for the jump or EOF\n        if index - current_segment_start + jump_size > segment_size - 2:\n            segments.append(compressed_data[\n                current_segment_start:index])\n\n            current_segment_start = index\n        else:\n            index += jump_size\n\n    # Append the last segment, if any\n    if current_segment_start != index:\n        segments.append(compressed_data[\n            current_segment_start:current_segment_start + index])\n\n    # Make sure that no data was lost while segmenting\n    total_segment_length = sum(map(len, segments))\n    assert total_segment_length == len(compressed_data), \"Lost %d bytes of \" \\\n        \"data while segmenting\" % (len(compressed_data) - total_segment_length)\n\n    block_ids = []\n\n    for segment in segments:\n        block = block_factory.new_block()\n        block_ids.append(block.id)\n\n    for (i, segment) in enumerate(segments):\n        block = block_factory.blocks[block_ids[i]]\n\n        assert len(block.data) == 0, \"Encountered a block with \"\n        \"pre-existing data while writing\"\n\n        if i == len(segments) - 1:\n            # Write EOF to the end of the segment\n            add_eof(segment)\n        else:\n            # Write a pointer to the next segment\n            add_block_switch(segment, block_ids[i + 1])\n\n        # Pad segment with zeroes until it's large enough\n        pad(segment, segment_size)\n\n        block.data = segment\n\n    return block_ids", "response": "Splits the compressed data into a list of blocks."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrenumber a block map s indices so that tehy match the blocks.", "response": "def renumber_block_keys(blocks):\n    \"\"\"Renumber a block map's indices so that tehy match the blocks' block\n    switch statements.\n\n    :param blocks a block map to renumber\n    :rtype: a renumbered copy of the block map\n    \"\"\"\n\n    # There is an implicit block switch to the 0th block at the start of the\n    # file\n    byte_switch_keys = [0]\n    block_keys = list(blocks.keys())\n\n    # Scan the blocks, recording every block switch statement\n    for block in list(blocks.values()):\n        i = 0\n        while i < len(block.data) - 1:\n            current_byte = block.data[i]\n            next_byte = block.data[i + 1]\n\n            if current_byte == RLE_BYTE:\n                if next_byte == RLE_BYTE:\n                    i += 2\n                else:\n                    i += 3\n            elif current_byte == SPECIAL_BYTE:\n                if next_byte in SPECIAL_DEFAULTS:\n                    i += 3\n                elif next_byte == SPECIAL_BYTE:\n                    i += 2\n                else:\n                    if next_byte != EOF_BYTE:\n                        byte_switch_keys.append(next_byte)\n\n                    break\n\n            else:\n                i += 1\n\n    byte_switch_keys.sort()\n    block_keys.sort()\n\n    assert len(byte_switch_keys) == len(block_keys), (\n        \"Number of blocks that are target of block switches (%d) \"\n        % (len(byte_switch_keys)) +\n        \"does not equal number of blocks in the song (%d)\"\n        % (len(block_keys)) +\n        \"; possible corruption\")\n\n    if byte_switch_keys == block_keys:\n        # No remapping necessary\n        return blocks\n\n    new_block_map = {}\n\n    for block_key, byte_switch_key in zip(\n            block_keys, byte_switch_keys):\n\n        new_block_map[byte_switch_key] = blocks[block_key]\n\n    return new_block_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(blocks):\n\n    current_block = blocks[sorted(blocks.keys())[0]]\n\n    compressed_data = []\n    eof = False\n\n    while not eof:\n        data_size_to_append = None\n        next_block = None\n\n        i = 0\n        while i < len(current_block.data) - 1:\n            current_byte = current_block.data[i]\n            next_byte = current_block.data[i + 1]\n\n            if current_byte == RLE_BYTE:\n                if next_byte == RLE_BYTE:\n                    i += 2\n                else:\n                    i += 3\n            elif current_byte == SPECIAL_BYTE:\n                if next_byte in SPECIAL_DEFAULTS:\n                    i += 3\n                elif next_byte == SPECIAL_BYTE:\n                    i += 2\n                else:\n                    data_size_to_append = i\n\n                    # hit end of file\n                    if next_byte == EOF_BYTE:\n                        eof = True\n                    else:\n                        next_block = blocks[next_byte]\n\n                    break\n            else:\n                i += 1\n\n        assert data_size_to_append is not None, \"Ran off the end of a \"\\\n            \"block without encountering a block switch or EOF\"\n\n        compressed_data.extend(current_block.data[0:data_size_to_append])\n\n        if not eof:\n            assert next_block is not None, \"Switched blocks, but did \" \\\n                \"not provide the next block to switch to\"\n\n            current_block = next_block\n\n    return compressed_data", "response": "This function takes a list of blocks and returns a list of compressed bytes that can be used to create a new block of compressed data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding zeroes to a segment until it reaches a certain size.", "response": "def pad(segment, size):\n    \"\"\"Add zeroes to a segment until it reaches a certain size.\n\n    :param segment: the segment to pad\n    :param size: the size to which to pad the segment\n    \"\"\"\n    for i in range(size - len(segment)):\n        segment.append(0)\n\n    assert len(segment) == size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecompress data that has been compressed by the filepack algorithm.", "response": "def decompress(compressed_data):\n    \"\"\"Decompress data that has been compressed by the filepack algorithm.\n\n    :param compressed_data: an array of compressed data bytes to decompress\n\n    :rtype: an array of decompressed bytes\"\"\"\n    raw_data = []\n\n    index = 0\n\n    while index < len(compressed_data):\n        current = compressed_data[index]\n        index += 1\n\n        if current == RLE_BYTE:\n            directive = compressed_data[index]\n            index += 1\n\n            if directive == RLE_BYTE:\n                raw_data.append(RLE_BYTE)\n            else:\n                count = compressed_data[index]\n                index += 1\n\n                raw_data.extend([directive] * count)\n        elif current == SPECIAL_BYTE:\n            directive = compressed_data[index]\n            index += 1\n\n            if directive == SPECIAL_BYTE:\n                raw_data.append(SPECIAL_BYTE)\n            elif directive == DEFAULT_WAVE_BYTE:\n                count = compressed_data[index]\n                index += 1\n\n                raw_data.extend(DEFAULT_WAVE * count)\n            elif directive == DEFAULT_INSTR_BYTE:\n                count = compressed_data[index]\n                index += 1\n\n                raw_data.extend(DEFAULT_INSTRUMENT_FILEPACK * count)\n            elif directive == EOF_BYTE:\n                assert False, (\"Unexpected EOF command encountered while \"\n                               \"decompressing\")\n            else:\n                assert False, \"Countered unexpected sequence 0x%02x 0x%02x\" % (\n                    current, directive)\n        else:\n            raw_data.append(current)\n\n    return raw_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compress(raw_data):\n    raw_data = bytearray(raw_data)\n    compressed_data = []\n\n    data_size = len(raw_data)\n\n    index = 0\n    next_bytes = [-1, -1, -1]\n\n    def is_default_instrument(index):\n        if index + len(DEFAULT_INSTRUMENT_FILEPACK) > len(raw_data):\n            return False\n\n        instr_bytes = raw_data[index:index + len(DEFAULT_INSTRUMENT_FILEPACK)]\n\n        if instr_bytes[0] != 0xa8 or instr_bytes[1] != 0:\n            return False\n\n        return instr_bytes == DEFAULT_INSTRUMENT_FILEPACK\n\n    def is_default_wave(index):\n        return (index + len(DEFAULT_WAVE) <= len(raw_data) and\n                raw_data[index:index + len(DEFAULT_WAVE)] == DEFAULT_WAVE)\n\n    while index < data_size:\n        current_byte = raw_data[index]\n\n        for i in range(3):\n            if index < data_size - (i + 1):\n                next_bytes[i] = raw_data[index + (i + 1)]\n            else:\n                next_bytes[i] = -1\n\n        if current_byte == RLE_BYTE:\n            compressed_data.append(RLE_BYTE)\n            compressed_data.append(RLE_BYTE)\n            index += 1\n        elif current_byte == SPECIAL_BYTE:\n            compressed_data.append(SPECIAL_BYTE)\n            compressed_data.append(SPECIAL_BYTE)\n            index += 1\n        elif is_default_instrument(index):\n            counter = 1\n            index += len(DEFAULT_INSTRUMENT_FILEPACK)\n\n            while (is_default_instrument(index) and\n                   counter < 0x100):\n                counter += 1\n                index += len(DEFAULT_INSTRUMENT_FILEPACK)\n\n            compressed_data.append(SPECIAL_BYTE)\n            compressed_data.append(DEFAULT_INSTR_BYTE)\n            compressed_data.append(counter)\n\n        elif is_default_wave(index):\n            counter = 1\n            index += len(DEFAULT_WAVE)\n\n            while is_default_wave(index) and counter < 0xff:\n                counter += 1\n                index += len(DEFAULT_WAVE)\n\n            compressed_data.append(SPECIAL_BYTE)\n            compressed_data.append(DEFAULT_WAVE_BYTE)\n            compressed_data.append(counter)\n\n        elif (current_byte == next_bytes[0] and\n              next_bytes[0] == next_bytes[1] and\n              next_bytes[1] == next_bytes[2]):\n            # Do RLE compression\n\n            compressed_data.append(RLE_BYTE)\n            compressed_data.append(current_byte)\n            counter = 0\n\n            while (index < data_size and\n                   raw_data[index] == current_byte and\n                   counter < 0xff):\n                index += 1\n                counter += 1\n\n            compressed_data.append(counter)\n        else:\n            compressed_data.append(current_byte)\n            index += 1\n\n    return compressed_data", "response": "Compress the raw bytes with the filepack algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a human - readable name without trailing zeroes.", "response": "def name_without_zeroes(name):\n    \"\"\"\n    Return a human-readable name without LSDJ's trailing zeroes.\n\n    :param name: the name from which to strip zeroes\n    :rtype: the name, without trailing zeroes\n    \"\"\"\n    first_zero = name.find(b'\\0')\n\n    if first_zero == -1:\n        return name\n    else:\n        return str(name[:first_zero])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_lsdinst(self, struct_data):\n        self.name = struct_data['name']\n        self.automate = struct_data['data']['automate']\n        self.pan = struct_data['data']['pan']\n\n        if self.table is not None:\n            self.table.import_lsdinst(struct_data)", "response": "import from an lsdinst struct"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting this instrument s settings to a file.", "response": "def export_to_file(self, filename):\n        \"\"\"Export this instrument's settings to a file.\n\n        :param filename: the name of the file\n        \"\"\"\n        instr_json = self.export_struct()\n\n        with open(filename, 'w') as fp:\n            json.dump(instr_json, fp, indent=2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite this sample to a WAV file.", "response": "def write_wav(self, filename):\n        \"\"\"Write this sample to a WAV file.\n\n        :param filename: the file to which to write\n        \"\"\"\n\n        wave_output = None\n        try:\n            wave_output = wave.open(filename, 'w')\n\n            wave_output.setparams(WAVE_PARAMS)\n\n            frames = bytearray([x << 4 for x in self.sample_data])\n\n            wave_output.writeframes(frames)\n        finally:\n            if wave_output is not None:\n                wave_output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading sample data from a WAV file.", "response": "def read_wav(self, filename):\n        \"\"\"Read sample data for this sample from a WAV file.\n\n        :param filename: the file from which to read\n        \"\"\"\n        wave_input = None\n\n        try:\n            wave_input = wave.open(filename, 'r')\n            wave_frames = bytearray(\n                wave_input.readframes(wave_input.getnframes()))\n\n            self.sample_data = [x >> 4 for x in wave_frames]\n\n        finally:\n            if wave_input is not None:\n                wave_input.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the local ip address on the given device", "response": "def get_device_address(device):\n    \"\"\" find the local ip address on the given device \"\"\"\n    if device is None:\n        return None\n    command = ['ip', 'route', 'list', 'dev', device]\n    ip_routes = subprocess.check_output(command).strip()\n    for line in ip_routes.split('\\n'):\n        seen = ''\n        for a in line.split():\n            if seen == 'src':\n                return a\n            seen = a\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_default_net_device():\n    with open('/proc/net/route') as fh:\n        for line in fh:\n            iface, dest, _ = line.split(None, 2)\n            if dest == '00000000':\n                return iface\n    return None", "response": "Find the default network device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_missing_optional_args_with_value_none(args, optional_args):\n    '''\n    Adds key-value pairs to the passed dictionary, so that\n        afterwards, the dictionary can be used without needing\n        to check for KeyErrors.\n\n    If the keys passed as a second argument are not present,\n        they are added with None as a value.\n\n    :args: The dictionary to be completed.\n    :optional_args: The keys that need to be added, if\n        they are not present.\n    :return: The modified dictionary.\n    '''\n\n    for name in optional_args:\n        if not name in args.keys():\n            args[name] = None\n    return args", "response": "Adds key - value pairs to the passed dictionary so that the keys passed as a second argument are not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_presence_of_mandatory_args(args, mandatory_args):\n    '''\n    Checks whether all mandatory arguments are passed.\n\n    This function aims at methods with many arguments\n        which are passed as kwargs so that the order\n        in which the are passed does not matter.\n\n    :args: The dictionary passed as args.\n    :mandatory_args: A list of keys that have to be\n        present in the dictionary.\n    :raise: :exc:`~ValueError`\n    :returns: True, if all mandatory args are passed. If not,\n        an exception is raised.\n\n    '''\n    missing_args = []\n    for name in mandatory_args:\n        if name not in args.keys():\n            missing_args.append(name)\n    if len(missing_args) > 0:\n        raise ValueError('Missing mandatory arguments: '+', '.join(missing_args))\n    else:\n        return True", "response": "Checks whether all mandatory arguments are passed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef size(self, store_hashes=True):\n        if self.modified:\n            self.__cache_content(store_hashes)\n\n        return len(self.cached_content)", "response": "Retrieves the size in bytes of this ZIP content."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmonkeys patch the django. db. migrations. writer. MIGRATION_TEMPLATE so that we can run the fixture at fixture_path.", "response": "def monkey_patch_migration_template(self, app, fixture_path):\n        \"\"\"\n        Monkey patch the django.db.migrations.writer.MIGRATION_TEMPLATE\n\n        Monkey patching django.db.migrations.writer.MIGRATION_TEMPLATE means that we \n        don't have to do any complex regex or reflection.\n\n        It's hacky... but works atm.\n        \"\"\"\n        self._MIGRATION_TEMPLATE = writer.MIGRATION_TEMPLATE\n        module_split = app.module.__name__.split('.')\n\n        if len(module_split) == 1:\n            module_import = \"import %s\\n\" % module_split[0]\n        else:\n            module_import = \"from %s import %s\\n\" % (\n                '.'.join(module_split[:-1]),\n                module_split[-1:][0],\n            )\n\n        writer.MIGRATION_TEMPLATE = writer.MIGRATION_TEMPLATE\\\n            .replace(\n                '%(imports)s',\n                \"%(imports)s\" + \"\\nfrom django_migration_fixture import fixture\\n%s\" % module_import\n            )\\\n            .replace(\n                '%(operations)s', \n                \"        migrations.RunPython(**fixture(%s, ['%s'])),\\n\" % (\n                    app.label,\n                    os.path.basename(fixture_path)\n                ) + \"%(operations)s\\n\" \n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if a migration exists.", "response": "def migration_exists(self, app, fixture_path):\n        \"\"\"\n        Return true if it looks like a migration already exists.\n        \"\"\"\n        base_name = os.path.basename(fixture_path)\n        # Loop through all migrations\n        for migration_path in glob.glob(os.path.join(app.path, 'migrations', '*.py')):\n            if base_name in open(migration_path).read():\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a data migration for app that uses fixture_path.", "response": "def create_migration(self, app, fixture_path):\n        \"\"\"\n        Create a data migration for app that uses fixture_path.\n        \"\"\"\n        self.monkey_patch_migration_template(app, fixture_path)\n\n        out = StringIO()\n        management.call_command('makemigrations', app.label, empty=True, stdout=out)\n\n        self.restore_migration_template()\n\n        self.stdout.write(out.getvalue())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef instantiate_for_read_and_search(handle_server_url, reverselookup_username, reverselookup_password, **config):\n        '''\n        Initialize client with read access and with search function.\n\n        :param handle_server_url: The URL of the Handle Server. May be None\n            (then, the default 'https://hdl.handle.net' is used).\n        :param reverselookup_username: The username to authenticate at the\n            reverse lookup servlet.\n        :param reverselookup_password: The password to authenticate at the\n            reverse lookup servlet.\n        :param \\**config: More key-value pairs may be passed that will be passed\n            on to the constructor as config. Config options from the\n            credentials object are overwritten by this.\n        :return: An instance of the client.\n        '''\n\n        if handle_server_url is None and 'reverselookup_baseuri' not in config.keys():\n            raise TypeError('You must specify either \"handle_server_url\" or \"reverselookup_baseuri\".' + \\\n                ' Searching not possible without the URL of a search servlet.')\n\n        inst = EUDATHandleClient(\n            handle_server_url,\n            reverselookup_username=reverselookup_username,\n            reverselookup_password=reverselookup_password,\n            **config\n        )\n        return inst", "response": "Instantiate an EUDATHandleClient object for reading access and search."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing client against an HSv8 instance with full read/write access. The method will throw an exception upon bad syntax or non-existing Handle. The existence or validity of the password in the handle is not checked at this moment. :param handle_server_url: The URL of the Handle System server. :param username: This must be a handle value reference in the format \"index:prefix/suffix\". :param password: This is the password stored as secret key in the actual Handle value the username points to. :param \\**config: More key-value pairs may be passed that will be passed on to the constructor as config. :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`: If the username handle is not found. :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError` :return: An instance of the client.", "response": "def instantiate_with_username_and_password(handle_server_url, username, password, **config):\n        '''\n        Initialize client against an HSv8 instance with full read/write access.\n\n        The method will throw an exception upon bad syntax or non-existing\n        Handle. The existence or validity of the password in the handle is\n        not checked at this moment.\n\n        :param handle_server_url: The URL of the Handle System server.\n        :param username: This must be a handle value reference in the format\n            \"index:prefix/suffix\".\n        :param password: This is the password stored as secret key in the\n            actual Handle value the username points to.\n        :param \\**config: More key-value pairs may be passed that will be passed\n            on to the constructor as config.\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`: If the username handle is not found.\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :return: An instance of the client.\n        '''\n\n        inst = EUDATHandleClient(handle_server_url, username=username, password=password, **config)\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef instantiate_with_credentials(credentials, **config):\n        '''\n        Initialize the client against an HSv8 instance with full read/write\n        access.\n\n        :param credentials: A credentials object, see separate class\n            PIDClientCredentials.\n        :param \\**config: More key-value pairs may be passed that will be passed\n            on to the constructor as config. Config options from the\n            credentials object are overwritten by this.\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`: If the username handle is not found.\n        :return: An instance of the client.\n        '''\n        key_value_pairs = credentials.get_all_args()\n\n        if config is not None:\n            key_value_pairs.update(**config)  # passed config overrides json file\n\n        inst = EUDATHandleClient(**key_value_pairs)\n        return inst", "response": "Instantiate an EUDATHandleClient object with the specified credentials."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a handle record as a complete nested dict.", "response": "def retrieve_handle_record_json(self, handle):\n        '''\n        Retrieve a handle record from the Handle server as a complete nested\n        dict (including index, ttl, timestamp, ...) for later use.\n\n        Note: For retrieving a simple dict with only the keys and values,\n        please use :meth:`~b2handle.handleclient.EUDATHandleClient.retrieve_handle_record`.\n\n        :param handle: The Handle whose record to retrieve.\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :return: The handle record as a nested dict. If the handle does not\n            exist, returns None.\n        '''\n        LOGGER.debug('retrieve_handle_record_json...')\n\n        utilhandle.check_handle_syntax(handle)\n        response = self.__send_handle_get_request(handle)\n        response_content = decoded_response(response)\n                    \n        if hsresponses.handle_not_found(response):\n            return None\n        elif hsresponses.does_handle_exist(response):\n         \n            handlerecord_json = json.loads(response_content)\n            if not handlerecord_json['handle'] == handle:\n                raise GenericHandleError(\n                    operation='retrieving handle record',\n                    handle=handle,\n                    response=response,\n                    custom_message='The retrieve returned a different handle than was asked for.'\n                )\n            return handlerecord_json\n        elif hsresponses.is_handle_empty(response):\n            handlerecord_json = json.loads(response_content)\n            return handlerecord_json\n        else:\n            raise GenericHandleError(\n                operation='retrieving',\n                handle=handle,\n                response=response\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_handle_record(self, handle, handlerecord_json=None):\n        '''\n        Retrieve a handle record from the Handle server as a dict. If there\n        is several entries of the same type, only the first one is\n        returned. Values of complex types (such as HS_ADMIN) are\n        transformed to strings.\n\n        :param handle: The handle whose record to retrieve.\n        :param handlerecord_json: Optional. If the handlerecord has already\n            been retrieved from the server, it can be reused.\n        :return: A dict where the keys are keys from the Handle record (except\n            for hidden entries) and every value is a string. The result will be\n            None if the Handle does not exist.\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        '''\n        LOGGER.debug('retrieve_handle_record...')\n\n        handlerecord_json = self.__get_handle_record_if_necessary(handle, handlerecord_json)\n        if handlerecord_json is None:\n            return None  # Instead of HandleNotFoundException!\n        list_of_entries = handlerecord_json['values']\n\n        record_as_dict = {}\n        for entry in list_of_entries:\n            key = entry['type']\n            if not key in record_as_dict.keys():\n                record_as_dict[key] = str(entry['data']['value'])\n        return record_as_dict", "response": "Retrieve a handle record from the Handle server as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_value_from_handle(self, handle, key, handlerecord_json=None):\n        '''\n        Retrieve a single value from a single Handle. If several entries with\n        this key exist, the methods returns the first one. If the handle\n        does not exist, the method will raise a HandleNotFoundException.\n\n        :param handle: The handle to take the value from.\n        :param key: The key.\n        :return: A string containing the value or None if the Handle record\n         does not contain the key.\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        '''\n        LOGGER.debug('get_value_from_handle...')\n\n        handlerecord_json = self.__get_handle_record_if_necessary(handle, handlerecord_json)\n        if handlerecord_json is None:\n            raise HandleNotFoundException(handle=handle)\n        list_of_entries = handlerecord_json['values']\n\n        indices = []\n        for i in xrange(len(list_of_entries)):\n            if list_of_entries[i]['type'] == key:\n                indices.append(i)\n\n        if len(indices) == 0:\n            return None\n        else:\n            if len(indices) > 1:\n                LOGGER.debug('get_value_from_handle: The handle ' + handle + \\\n                    ' contains several entries of type \"' + key + \\\n                    '\". Only the first one is returned.')\n            return list_of_entries[indices[0]]['data']['value']", "response": "Retrieves a single value from a single Handle."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_10320LOC_empty(self, handle, handlerecord_json=None):\n        '''\n        Checks if there is a 10320/LOC entry in the handle record.\n        *Note:* In the unlikely case that there is a 10320/LOC entry, but it does\n        not contain any locations, it is treated as if there was none.\n\n        :param handle: The handle.\n        :param handlerecord_json: Optional. The content of the response of a\n            GET request for the handle as a dict. Avoids another GET request.\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :return: True if the record contains NO 10320/LOC entry; False if it\n            does contain one.\n        '''\n        LOGGER.debug('is_10320LOC_empty...')\n\n        handlerecord_json = self.__get_handle_record_if_necessary(handle, handlerecord_json)\n        if handlerecord_json is None:\n            raise HandleNotFoundException(handle=handle)\n        list_of_entries = handlerecord_json['values']\n\n        num_entries = 0\n        num_URL = 0\n        for entry in list_of_entries:\n            if entry['type'] == '10320/LOC':\n                num_entries += 1\n                xmlroot = ET.fromstring(entry['data']['value'])\n                list_of_locations = xmlroot.findall('location')\n                for item in list_of_locations:\n                    if item.get('href') is not None:\n                        num_URL += 1\n        if num_entries == 0:\n            return True\n        else:\n            if num_URL == 0:\n                return True\n            else:\n                return False", "response": "Checks if the 10320 / LOC entry in the handle record contains no 10320 / LOC entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_and_register_handle(self, prefix, location, checksum=None, additional_URLs=None, **extratypes):\n        '''\n        Register a new Handle with a unique random name (random UUID).\n\n        :param prefix: The prefix of the handle to be registered. The method\n            will generate a suffix.\n        :param location: The URL of the data entity to be referenced.\n        :param checksum: Optional. The checksum string.\n        :param extratypes: Optional. Additional key value pairs as dict.\n        :param additional_URLs: Optional. A list of URLs (as strings) to be\n            added to the handle record as 10320/LOC entry.\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        :return: The new handle name.\n        '''\n\n        LOGGER.debug('generate_and_register_handle...')\n\n        handle = self.generate_PID_name(prefix)\n        handle = self.register_handle(\n            handle,\n            location,\n            checksum,\n            additional_URLs,\n            overwrite=True,\n            **extratypes\n        )\n        return handle", "response": "Generate a unique name and register a new handle with a random UUID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmodifying the value of a key - value - pair in a handle record.", "response": "def modify_handle_value(self, handle, ttl=None, add_if_not_exist=True, **kvpairs):\n        '''\n        Modify entries (key-value-pairs) in a handle record. If the key\n        does not exist yet, it is created.\n\n        *Note:* We assume that a key exists only once. In case a key exists\n        several time, an exception will be raised.\n\n        *Note:* To modify 10320/LOC, please use :meth:`~b2handle.handleclient.EUDATHandleClient.add_additional_URL` or\n        :meth:`~b2handle.handleclient.EUDATHandleClient.remove_additional_URL`.\n\n        :param handle: Handle whose record is to be modified\n        :param ttl: Optional. Integer value. If ttl should be set to a\n            non-default value.\n        :param all other args: The user can specify several key-value-pairs.\n            These will be the handle value types and values that will be\n            modified. The keys are the names or the handle value types (e.g.\n            \"URL\"). The values are the new values to store in \"data\". If the\n            key is 'HS_ADMIN', the new value needs to be of the form\n            {'handle':'xyz', 'index':xyz}. The permissions will be set to the\n            default permissions.\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        '''\n        LOGGER.debug('modify_handle_value...')\n\n        # Read handle record:\n        handlerecord_json = self.retrieve_handle_record_json(handle)\n        if handlerecord_json is None:\n            msg = 'Cannot modify unexisting handle'\n            raise HandleNotFoundException(handle=handle, msg=msg)\n        list_of_entries = handlerecord_json['values']\n\n        # HS_ADMIN\n        if 'HS_ADMIN' in kvpairs.keys() and not self.__modify_HS_ADMIN:\n            msg = 'You may not modify HS_ADMIN'\n            raise IllegalOperationException(\n                msg=msg,\n                operation='modifying HS_ADMIN',\n                handle=handle\n            )\n\n        nothingchanged = True\n        new_list_of_entries = []\n        list_of_old_and_new_entries = list_of_entries[:]\n        keys = kvpairs.keys()\n        for key, newval in kvpairs.items():\n            # Change existing entry:\n            changed = False\n            for i in xrange(len(list_of_entries)):\n                if list_of_entries[i]['type'] == key:\n                    if not changed:\n                        list_of_entries[i]['data'] = newval\n                        list_of_entries[i].pop('timestamp')  # will be ignored anyway\n                        if key == 'HS_ADMIN':\n                            newval['permissions'] = self.__HS_ADMIN_permissions\n                            list_of_entries[i].pop('timestamp')  # will be ignored anyway\n                            list_of_entries[i]['data'] = {\n                                'format':'admin',\n                                'value':newval\n                            }\n                            LOGGER.info('Modified' + \\\n                                ' \"HS_ADMIN\" of handle ' + handle)\n                        changed = True\n                        nothingchanged = False\n                        new_list_of_entries.append(list_of_entries[i])\n                        list_of_old_and_new_entries.append(list_of_entries[i])\n                    else:\n                        msg = 'There is several entries of type \"' + key + '\".' + \\\n                            ' This can lead to unexpected behaviour.' + \\\n                            ' Please clean up before modifying the record.'\n                        raise BrokenHandleRecordException(handle=handle, msg=msg)\n\n            # If the entry doesn't exist yet, add it:\n            if not changed:\n                if add_if_not_exist:\n                    LOGGER.debug('modify_handle_value: Adding entry \"' + key + '\"' + \\\n                        ' to handle ' + handle)\n                    index = self.__make_another_index(list_of_old_and_new_entries)\n                    entry_to_add = self.__create_entry(key, newval, index, ttl)\n                    new_list_of_entries.append(entry_to_add)\n                    list_of_old_and_new_entries.append(entry_to_add)\n                    changed = True\n                    nothingchanged = False\n\n        # Add the indices\n        indices = []\n        for i in xrange(len(new_list_of_entries)):\n            indices.append(new_list_of_entries[i]['index'])\n\n        # append to the old record:\n        if nothingchanged:\n            LOGGER.debug('modify_handle_value: There was no entries ' + \\\n                str(kvpairs.keys()) + ' to be modified (handle ' + handle + ').' + \\\n                ' To add them, set add_if_not_exist = True')\n        else:\n            op = 'modifying handle values'\n            resp, put_payload = self.__send_handle_put_request(\n                handle,\n                new_list_of_entries,\n                indices=indices,\n                overwrite=True,\n                op=op)\n            if hsresponses.handle_success(resp):\n                LOGGER.info('Handle modified: ' + handle)\n            else:\n                msg = 'Values: ' + str(kvpairs)\n                raise GenericHandleError(\n                    operation=op,\n                    handle=handle,\n                    response=resp,\n                    msg=msg,\n                    payload=put_payload\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_handle_value(self, handle, key):\n        '''\n        Delete a key-value pair from a handle record. If the key exists more\n        than once, all key-value pairs with this key are deleted.\n\n        :param handle: Handle from whose record the entry should be deleted.\n        :param key: Key to be deleted. Also accepts a list of keys.\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        '''\n        LOGGER.debug('delete_handle_value...')\n\n        # read handle record:\n        handlerecord_json = self.retrieve_handle_record_json(handle)\n        if handlerecord_json is None:\n            msg = 'Cannot modify unexisting handle'\n            raise HandleNotFoundException(handle=handle, msg=msg)\n        list_of_entries = handlerecord_json['values']\n\n\n        # find indices to delete:\n        keys = None\n        indices = []\n        if type(key) != type([]):\n            keys = [key]\n        else:\n            keys = key\n        keys_done = []\n        for key in keys:\n\n            # filter HS_ADMIN\n            if key == 'HS_ADMIN':\n                op = 'deleting \"HS_ADMIN\"'\n                raise IllegalOperationException(operation=op, handle=handle)\n\n            if key not in keys_done:\n                indices_onekey = self.get_handlerecord_indices_for_key(key, list_of_entries)\n                indices = indices + indices_onekey\n                keys_done.append(key)\n\n        # Important: If key not found, do not continue, as deleting without indices would delete the entire handle!!\n        if not len(indices) > 0:\n            LOGGER.debug('delete_handle_value: No values for key(s) ' + str(keys))\n            return None\n        else:\n\n            # delete and process response:\n            op = 'deleting \"' + str(keys) + '\"'\n            resp = self.__send_handle_delete_request(handle, indices=indices, op=op)\n            if hsresponses.handle_success(resp):\n                LOGGER.debug(\"delete_handle_value: Deleted handle values \" + str(keys) + \"of handle \" + handle)\n            elif hsresponses.values_not_found(resp):\n                pass\n            else:\n                raise GenericHandleError(\n                    operation=op,\n                    handle=handle,\n                    response=resp\n                )", "response": "Delete a key - value pair from a handle record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete the handle and its handle record.", "response": "def delete_handle(self, handle, *other):\n        '''Delete the handle and its handle record. If the Handle is not found, an Exception is raised.\n\n        :param handle: Handle to be deleted.\n        :param other: Deprecated. This only exists to catch wrong method usage\n            by users who are used to delete handle VALUES with the method.\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        '''\n\n        LOGGER.debug('delete_handle...')\n\n        utilhandle.check_handle_syntax(handle)\n\n        # Safety check. In old epic client, the method could be used for\n        # deleting handle values (not entire handle) by specifying more\n        # parameters.\n        if len(other) > 0:\n            message = 'You specified more than one argument. If you wanted' + \\\n                ' to delete just some values from a handle, please use the' + \\\n                ' new method \"delete_handle_value()\".'\n            raise TypeError(message)\n\n        op = 'deleting handle'\n        resp = self.__send_handle_delete_request(handle, op=op)\n        if hsresponses.handle_success(resp):\n            LOGGER.info('Handle ' + handle + ' deleted.')\n        elif hsresponses.handle_not_found(resp):\n            msg = ('delete_handle: Handle ' + handle + ' did not exist, '\n                   'so it could not be deleted.')\n            LOGGER.debug(msg)\n            raise HandleNotFoundException(msg=msg, handle=handle, response=resp)\n        else:\n            raise GenericHandleError(op=op, handle=handle, response=resp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exchange_additional_URL(self, handle, old, new):\n        '''\n        Exchange an URL in the 10320/LOC entry against another, keeping the same id\n        and other attributes.\n\n        :param handle: The handle to modify.\n        :param old: The URL to replace.\n        :param new: The URL to set as new URL.\n        '''\n        LOGGER.debug('exchange_additional_URL...')\n\n        handlerecord_json = self.retrieve_handle_record_json(handle)\n        if handlerecord_json is None:\n            msg = 'Cannot exchange URLs in unexisting handle'\n            raise HandleNotFoundException(\n                handle=handle,\n                msg=msg\n            )\n        list_of_entries = handlerecord_json['values']\n\n        if not self.is_URL_contained_in_10320LOC(handle, old, handlerecord_json):\n            LOGGER.debug('exchange_additional_URL: No URLs exchanged, as the url was not in the record.')\n        else:\n            self.__exchange_URL_in_13020loc(old, new, list_of_entries, handle)\n\n            op = 'exchanging URLs'\n            resp, put_payload = self.__send_handle_put_request(\n                handle,\n                list_of_entries,\n                overwrite=True,\n                op=op\n            )\n            # TODO FIXME (one day): Implement overwriting by index (less risky)\n            if hsresponses.handle_success(resp):\n                pass\n            else:\n                msg = 'Could not exchange URL ' + str(old) + ' against ' + str(new)\n                raise GenericHandleError(\n                    operation=op,\n                    handle=handle,\n                    reponse=resp,\n                    msg=msg,\n                    payload=put_payload\n                )", "response": "Exchange an URL in the 10320 / LOC entry against another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a URL entry to the handle record s 10320 / LOC entry.", "response": "def add_additional_URL(self, handle, *urls, **attributes):\n        '''\n        Add a URL entry to the handle record's 10320/LOC entry. If 10320/LOC\n        does not exist yet, it is created. If the 10320/LOC entry already\n        contains the URL, it is not added a second time.\n\n        :param handle: The handle to add the URL to.\n        :param urls: The URL(s) to be added. Several URLs may be specified.\n        :param attributes: Optional. Additional key-value pairs to set as\n            attributes to the <location> elements, e.g. weight, http_role or\n            custom attributes. Note: If the URL already exists but the\n            attributes are different, they are updated!\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        '''\n        LOGGER.debug('add_additional_URL...')\n\n        handlerecord_json = self.retrieve_handle_record_json(handle)\n        if handlerecord_json is None:\n            msg = 'Cannot add URLS to unexisting handle!'\n            raise HandleNotFoundException(handle=handle, msg=msg)\n        list_of_entries = handlerecord_json['values']\n\n        is_new = False\n        for url in urls:\n            if not self.is_URL_contained_in_10320LOC(handle, url, handlerecord_json):\n                is_new = True\n\n        if not is_new:\n            LOGGER.debug(\"add_additional_URL: No new URL to be added (so no URL is added at all).\")\n        else:\n\n            for url in urls:\n                self.__add_URL_to_10320LOC(url, list_of_entries, handle)\n\n            op = 'adding URLs'\n            resp, put_payload = self.__send_handle_put_request(handle, list_of_entries, overwrite=True, op=op)\n            # TODO FIXME (one day) Overwrite by index.\n\n            if hsresponses.handle_success(resp):\n                pass\n            else:\n                msg = 'Could not add URLs ' + str(urls)\n                raise GenericHandleError(\n                    operation=op,\n                    handle=handle,\n                    reponse=resp,\n                    msg=msg,\n                    payload=put_payload\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove URLs from the 10320LOC entry.", "response": "def remove_additional_URL(self, handle, *urls):\n        '''\n        Remove a URL from the handle record's 10320/LOC entry.\n\n        :param handle: The handle to modify.\n        :param urls: The URL(s) to be removed. Several URLs may be specified.\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        '''\n\n        LOGGER.debug('remove_additional_URL...')\n\n        handlerecord_json = self.retrieve_handle_record_json(handle)\n        if handlerecord_json is None:\n            msg = 'Cannot remove URLs from unexisting handle'\n            raise HandleNotFoundException(handle=handle, msg=msg)\n        list_of_entries = handlerecord_json['values']\n\n        for url in urls:\n            self.__remove_URL_from_10320LOC(url, list_of_entries, handle)\n\n        op = 'removing URLs'\n        resp, put_payload = self.__send_handle_put_request(\n            handle,\n            list_of_entries,\n            overwrite=True,\n            op=op\n        )\n        # TODO FIXME (one day): Implement overwriting by index (less risky),\n        # once HS have fixed the issue with the indices.\n        if hsresponses.handle_success(resp):\n            pass\n        else:\n            op = 'removing \"' + str(urls) + '\"'\n            msg = 'Could not remove URLs ' + str(urls)\n            raise GenericHandleError(\n                operation=op,\n                handle=handle,\n                reponse=resp,\n                msg=msg,\n                payload=put_payload\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_handle(self, handle, location, checksum=None, additional_URLs=None, overwrite=False, **extratypes):\n        '''\n        Registers a new Handle with given name. If the handle already exists\n        and overwrite is not set to True, the method will throw an\n        exception.\n\n        :param handle: The full name of the handle to be registered (prefix\n            and suffix)\n        :param location: The URL of the data entity to be referenced\n        :param checksum: Optional. The checksum string.\n        :param extratypes: Optional. Additional key value pairs.\n        :param additional_URLs: Optional. A list of URLs (as strings) to be\n            added to the handle record as 10320/LOC entry.\n        :param overwrite: Optional. If set to True, an existing handle record\n            will be overwritten. Defaults to False.\n        :raises: :exc:`~b2handle.handleexceptions.HandleAlreadyExistsException` Only if overwrite is not set or\n            set to False.\n        :raises: :exc:`~b2handle.handleexceptions.HandleAuthenticationError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :return: The handle name.\n        '''\n        LOGGER.debug('register_handle...')\n\n        # If already exists and can't be overwritten:\n        if overwrite == False:\n            handlerecord_json = self.retrieve_handle_record_json(handle)\n            if handlerecord_json is not None:\n                msg = 'Could not register handle'\n                LOGGER.error(msg + ', as it already exists.')\n                raise HandleAlreadyExistsException(handle=handle, msg=msg)\n\n        # Create admin entry\n        list_of_entries = []\n        adminentry = self.__create_admin_entry(\n            self.__handleowner,\n            self.__HS_ADMIN_permissions,\n            self.__make_another_index(list_of_entries, hs_admin=True),\n            handle\n        )\n        list_of_entries.append(adminentry)\n\n        # Create other entries\n        entry_URL = self.__create_entry(\n            'URL',\n            location,\n            self.__make_another_index(list_of_entries, url=True)\n        )\n        list_of_entries.append(entry_URL)\n        if checksum is not None:\n            entryChecksum = self.__create_entry(\n                'CHECKSUM',\n                checksum,\n                self.__make_another_index(list_of_entries)\n            )\n            list_of_entries.append(entryChecksum)\n        if extratypes is not None:\n            for key, value in extratypes.items():\n                entry = self.__create_entry(\n                    key,\n                    value,\n                    self.__make_another_index(list_of_entries)\n                )\n                list_of_entries.append(entry)\n        if additional_URLs is not None and len(additional_URLs) > 0:\n            for url in additional_URLs:\n                self.__add_URL_to_10320LOC(url, list_of_entries, handle)\n\n        # Create record itself and put to server\n        op = 'registering handle'\n        resp, put_payload = self.__send_handle_put_request(\n            handle,\n            list_of_entries,\n            overwrite=overwrite,\n            op=op\n        )\n        resp_content = decoded_response(resp)\n        if hsresponses.was_handle_created(resp) or hsresponses.handle_success(resp):\n            LOGGER.info(\"Handle registered: \" + handle)\n            return json.loads(resp_content)['handle']\n        elif hsresponses.is_temporary_redirect(resp):\n            oldurl = resp.url\n            newurl = resp.headers['location']\n            raise GenericHandleError(\n                operation=op,\n                handle=handle,\n                response=resp,\n                payload=put_payload,\n                msg='Temporary redirect from ' + oldurl + ' to ' + newurl + '.'\n            )\n        elif hsresponses.handle_not_found(resp):\n            raise GenericHandleError(\n                operation=op,\n                handle=handle,\n                response=resp,\n                payload=put_payload,\n                msg='Could not create handle. Possibly you used HTTP instead of HTTPS?'\n            )\n        else:\n            raise GenericHandleError(\n                operation=op,\n                handle=handle,\n                reponse=resp,\n                payload=put_payload\n            )", "response": "Registers a new handle with given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for all handles containing the specified key with the specified value.", "response": "def search_handle(self, URL=None, prefix=None, **key_value_pairs):\n        '''\n        Search for handles containing the specified key with the specified\n        value. The search terms are passed on to the reverse lookup servlet\n        as-is. The servlet is supposed to be case-insensitive, but if it\n        isn't, the wrong case will cause a :exc:`~b2handle.handleexceptions.ReverseLookupException`.\n\n        *Note:* If allowed search keys are configured, only these are used. If\n        no allowed search keys are specified, all key-value pairs are\n        passed on to the reverse lookup servlet, possibly causing a\n        :exc:`~b2handle.handleexceptions.ReverseLookupException`.\n\n        Example calls:\n\n            .. code:: python\n\n                list_of_handles = search_handle('http://www.foo.com')\n                list_of_handles = search_handle('http://www.foo.com', CHECKSUM=99999)\n                list_of_handles = search_handle(URL='http://www.foo.com', CHECKSUM=99999)\n\n\n        :param URL: Optional. The URL to search for (reverse lookup). [This is\n            NOT the URL of the search servlet!]\n        :param prefix: Optional. The Handle prefix to which the search should\n            be limited to. If unspecified, the method will search across all\n            prefixes present at the server given to the constructor.\n        :param key_value_pairs: Optional. Several search fields and values can\n            be specified as key-value-pairs,\n            e.g. CHECKSUM=123456, URL=www.foo.com\n        :raise: :exc:`~b2handle.handleexceptions.ReverseLookupException`: If a search field is specified that\n            cannot be used, or if something else goes wrong.\n        :return: A list of all Handles (strings) that bear the given key with\n            given value of given prefix or server. The list may be empty and\n            may also contain more than one element.\n        '''\n        LOGGER.debug('search_handle...')\n\n        list_of_handles = self.__searcher.search_handle(URL=URL, prefix=prefix, **key_value_pairs)\n\n        return list_of_handles"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a unique random name for the notwkalot.", "response": "def generate_PID_name(self, prefix=None):\n        '''\n        Generate a unique random Handle name (random UUID). The Handle is not\n        registered. If a prefix is specified, the PID name has the syntax\n        <prefix>/<generatedname>, otherwise it just returns the generated\n        random name (suffix for the Handle).\n\n        :param prefix: Optional. The prefix to be used for the Handle name.\n        :return: The handle name in the form <prefix>/<generatedsuffix> or\n            <generatedsuffix>.\n        '''\n\n        LOGGER.debug('generate_PID_name...')\n\n        randomuuid = uuid.uuid4()\n        if prefix is not None:\n            return prefix + '/' + str(randomuuid)\n        else:\n            return str(randomuuid)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_handlerecord_indices_for_key(self, key, list_of_entries):\n        '''\n        Finds the Handle entry indices of all entries that have a specific\n        type.\n\n        *Important:* It finds the Handle System indices! These are not\n        the python indices of the list, so they can not be used for\n        iteration.\n\n        :param key: The key (Handle Record type)\n        :param list_of_entries: A list of the existing entries in which to find\n            the indices.\n        :return: A list of strings, the indices of the entries of type \"key\" in\n            the given handle record.\n        '''\n\n        LOGGER.debug('get_handlerecord_indices_for_key...')\n\n        indices = []\n        for entry in list_of_entries:\n            if entry['type'] == key:\n                indices.append(entry['index'])\n        return indices", "response": "This function returns the list of strings that are the indices of the entries that have a specific handle record type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __send_handle_delete_request(self, handle, indices=None, op=None):\n        '''\n        Send a HTTP DELETE request to the handle server to delete either an\n            entire handle or to some specified values from a handle record,\n            using the requests module.\n\n        :param handle: The handle.\n        :param indices: Optional. A list of indices to delete. Defaults to\n            None (i.e. the entire handle is deleted.). The list can contain\n            integers or strings.\n        :return: The server's response.\n        '''\n\n        resp = self.__handlesystemconnector.send_handle_delete_request(\n            handle=handle,\n            indices=indices,\n            op=op)\n        return resp", "response": "Sends a HTTP DELETE request to the handle server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a HTTP PUT request to the handle server.", "response": "def __send_handle_put_request(self, handle, list_of_entries, indices=None, overwrite=False, op=None):\n        '''\n        Send a HTTP PUT request to the handle server to write either an entire\n            handle or to some specified values to an handle record, using the\n            requests module.\n\n        :param handle: The handle.\n        :param list_of_entries: A list of handle record entries to be written,\n         in the format [{\"index\":xyz, \"type\":\"xyz\", \"data\":\"xyz\"}] or similar.\n        :param indices: Optional. A list of indices to modify. Defaults\n         to None (i.e. the entire handle is updated.). The list can\n         contain integers or strings.\n        :param overwrite: Optional. Whether the handle should be overwritten\n         if it exists already.\n        :return: The server's response.\n        '''\n\n        resp, payload = self.__handlesystemconnector.send_handle_put_request(\n            handle=handle,\n            list_of_entries=list_of_entries,\n            indices=indices,\n            overwrite=overwrite,\n            op=op\n        )\n        return resp, payload"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a HTTP GET request to the handle server to read either an entire handle or to some specified values from a handle record.", "response": "def __send_handle_get_request(self, handle, indices=None):\n        '''\n        Send a HTTP GET request to the handle server to read either an entire\n            handle or to some specified values from a handle record, using the\n            requests module.\n\n        :param handle: The handle.\n        :param indices: Optional. A list of indices to delete. Defaults to\n            None (i.e. the entire handle is deleted.). The list can contain\n            integers or strings.\n        :return: The server's response.\n        '''\n\n        resp = self.__handlesystemconnector.send_handle_get_request(handle, indices)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the handle record if it is None or the handle record is not the same as the specified handle.", "response": "def __get_handle_record_if_necessary(self, handle, handlerecord_json):\n        '''\n        Returns the handle record if it is None or if its handle is not the\n            same as the specified handle.\n\n        '''\n        if handlerecord_json is None:\n            handlerecord_json = self.retrieve_handle_record_json(handle)\n        else:\n            if handle != handlerecord_json['handle']:\n                handlerecord_json = self.retrieve_handle_record_json(handle)\n        return handlerecord_json"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding an index not yet used in the handle record and not reserved for any (other) special type. :param: list_of_entries: List of all entries to find which indices are used already. :param url: If True, an index for an URL entry is returned (1, unless it is already in use). :param hs_admin: If True, an index for HS_ADMIN is returned (100 or one of the following). :return: An integer.", "response": "def __make_another_index(self, list_of_entries, url=False, hs_admin=False):\n        '''\n        Find an index not yet used in the handle record and not reserved for\n            any (other) special type.\n\n        :param: list_of_entries: List of all entries to find which indices are\n            used already.\n        :param url: If True, an index for an URL entry is returned (1, unless\n            it is already in use).\n        :param hs_admin: If True, an index for HS_ADMIN is returned (100 or one\n            of the following).\n        :return: An integer.\n        '''\n\n        start = 2\n\n        # reserved indices:\n        reserved_for_url = set([1])\n        reserved_for_admin = set(range(100, 200))\n        prohibited_indices = reserved_for_url | reserved_for_admin\n\n        if url:\n            prohibited_indices = prohibited_indices - reserved_for_url\n            start = 1\n        elif hs_admin:\n            prohibited_indices = prohibited_indices - reserved_for_admin\n            start = 100\n\n        # existing indices\n        existing_indices = set()\n        if list_of_entries is not None:\n            for entry in list_of_entries:\n                existing_indices.add(int(entry['index']))\n\n        # find new index:\n        all_prohibited_indices = existing_indices | prohibited_indices\n        searchmax = max(start, max(all_prohibited_indices)) + 2\n        for index in xrange(start, searchmax):\n            if index not in all_prohibited_indices:\n                return index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __create_entry(self, entrytype, data, index, ttl=None):\n        '''\n        Create an entry of any type except HS_ADMIN.\n\n        :param entrytype: THe type of entry to create, e.g. 'URL' or\n            'checksum' or ... Note: For entries of type 'HS_ADMIN', please\n            use __create_admin_entry(). For type '10320/LOC', please use\n            'add_additional_URL()'\n        :param data: The actual value for the entry. Can be a simple string,\n            e.g. \"example\", or a dict {\"format\":\"string\", \"value\":\"example\"}.\n        :param index: The integer to be used as index.\n        :param ttl: Optional. If not set, the library's default is set. If\n            there is no default, it is not set by this library, so Handle\n            System sets it.\n        :return: The entry as a dict.\n        '''\n\n        if entrytype == 'HS_ADMIN':\n            op = 'creating HS_ADMIN entry'\n            msg = 'This method can not create HS_ADMIN entries.'\n            raise IllegalOperationException(operation=op, msg=msg)\n\n        entry = {'index':index, 'type':entrytype, 'data':data}\n\n        if ttl is not None:\n            entry['ttl'] = ttl\n\n        return entry", "response": "Create an entry of any type except HS_ADMIN."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an admin entry.", "response": "def __create_admin_entry(self, handleowner, permissions, index, handle, ttl=None):\n        '''\n        Create an entry of type \"HS_ADMIN\".\n\n        :param username: The username, i.e. a handle with an index\n            (index:prefix/suffix). The value referenced by the index contains\n            authentcation information, e.g. a hidden entry containing a key.\n        :param permissions: The permissions as a string of zeros and ones,\n            e.g. '0111011101011'. If not all twelve bits are set, the remaining\n            ones are set to zero.\n        :param index: The integer to be used as index of this admin entry (not\n            of the username!). Should be 1xx.\n        :param ttl: Optional. If not set, the library's default is set. If\n            there is no default, it is not set by this library, so Handle\n            System sets it.\n        :return: The entry as a dict.\n        '''\n        # If the handle owner is specified, use it. Otherwise, use 200:0.NA/prefix\n        # With the prefix taken from the handle that is being created, not from anywhere else.\n        if handleowner is None:\n            adminindex = '200'\n            prefix = handle.split('/')[0]\n            adminhandle = '0.NA/' + prefix\n        else:\n            adminindex, adminhandle = utilhandle.remove_index_from_handle(handleowner)\n\n        data = {\n            'value':{\n                'index':adminindex,\n                'handle':adminhandle,\n                'permissions':permissions\n            },\n            'format':'admin'\n        }\n\n        entry = {'index':index, 'type':'HS_ADMIN', 'data':data}\n        if ttl is not None:\n            entry['ttl'] = ttl\n\n        return entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_python_indices_for_key(self, key, list_of_entries):\n        '''\n        Finds the indices of all entries that have a specific type. Important:\n            This method finds the python indices of the list of entries! These\n            are not the Handle System index values!\n\n        :param key: The key (Handle Record type)\n        :param list_of_entries: A list of the existing entries in which to find\n            the indices.\n        :return: A list of integers, the indices of the entries of type \"key\"\n            in the given list.\n        '''\n        indices = []\n        for i in xrange(len(list_of_entries)):\n            if list_of_entries[i]['type'] == key:\n                indices.append(i)\n        return indices", "response": "This method returns the python indices of all entries that have a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexchanging every occurrence of oldurl against newurl in a 10320 / LOC entry.", "response": "def __exchange_URL_in_13020loc(self, oldurl, newurl, list_of_entries, handle):\n        '''\n        Exchange every occurrence of oldurl against newurl in a 10320/LOC entry.\n            This does not change the ids or other xml attributes of the\n            <location> element.\n\n        :param oldurl: The URL that will be overwritten.\n        :param newurl: The URL to write into the entry.\n        :param list_of_entries: A list of the existing entries (to find and\n            remove the correct one).\n        :param handle: Only for the exception message.\n        :raise: GenericHandleError: If several 10320/LOC exist (unlikely).\n        '''\n\n        # Find existing 10320/LOC entries\n        python_indices = self.__get_python_indices_for_key(\n            '10320/LOC',\n            list_of_entries\n        )\n\n        num_exchanged = 0\n        if len(python_indices) > 0:\n\n            if len(python_indices) > 1:\n                msg = str(len(python_indices)) + ' entries of type \"10320/LOC\".'\n                raise BrokenHandleRecordException(handle=handle, msg=msg)\n\n            for index in python_indices:\n                entry = list_of_entries.pop(index)\n                xmlroot = ET.fromstring(entry['data']['value'])\n                all_URL_elements = xmlroot.findall('location')\n                for element in all_URL_elements:\n                    if element.get('href') == oldurl:\n                        LOGGER.debug('__exchange_URL_in_13020loc: Exchanging URL ' + oldurl + ' from 10320/LOC.')\n                        num_exchanged += 1\n                        element.set('href', newurl)\n                entry['data']['value'] = ET.tostring(xmlroot, encoding=encoding_value)\n                list_of_entries.append(entry)\n\n        if num_exchanged == 0:\n            LOGGER.debug('__exchange_URL_in_13020loc: No URLs exchanged.')\n        else:\n            message = '__exchange_URL_in_13020loc: The URL \"' + oldurl + '\" was exchanged ' + str(num_exchanged) + \\\n            ' times against the new url \"' + newurl + '\" in 10320/LOC.'\n            message = message.replace('1 times', 'once')\n            LOGGER.debug(message)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __remove_URL_from_10320LOC(self, url, list_of_entries, handle):\n        '''\n        Remove an URL from the handle record's \"10320/LOC\" entry.\n        If it exists several times in the entry, all occurences are removed.\n        If the URL is not present, nothing happens.\n        If after removing, there is no more URLs in the entry, the entry is\n            removed.\n\n        :param url: The URL to be removed.\n        :param list_of_entries: A list of the existing entries (to find and\n            remove the correct one).\n        :param handle: Only for the exception message.\n        :raise: GenericHandleError: If several 10320/LOC exist (unlikely).\n        '''\n\n        # Find existing 10320/LOC entries\n        python_indices = self.__get_python_indices_for_key(\n            '10320/LOC',\n            list_of_entries\n        )\n\n        num_removed = 0\n        if len(python_indices) > 0:\n\n            if len(python_indices) > 1:\n                msg = str(len(python_indices)) + ' entries of type \"10320/LOC\".'\n                raise BrokenHandleRecordException(handle=handle, msg=msg)\n\n            for index in python_indices:\n                entry = list_of_entries.pop(index)\n                xmlroot = ET.fromstring(entry['data']['value'])\n                all_URL_elements = xmlroot.findall('location')\n                for element in all_URL_elements:\n                    if element.get('href') == url:\n                        LOGGER.debug('__remove_URL_from_10320LOC: Removing URL ' + url + '.')\n                        num_removed += 1\n                        xmlroot.remove(element)\n                remaining_URL_elements = xmlroot.findall('location')\n                if len(remaining_URL_elements) == 0:\n                    LOGGER.debug(\"__remove_URL_from_10320LOC: All URLs removed.\")\n                    # TODO FIXME: If we start adapting the Handle Record by\n                    # index (instead of overwriting the entire one), be careful\n                    # to delete the ones that became empty!\n                else:\n                    entry['data']['value'] = ET.tostring(xmlroot, encoding=encoding_value)\n                    LOGGER.debug('__remove_URL_from_10320LOC: ' + str(len(remaining_URL_elements)) + ' URLs' + \\\n                        ' left after removal operation.')\n                    list_of_entries.append(entry)\n        if num_removed == 0:\n            LOGGER.debug('__remove_URL_from_10320LOC: No URLs removed.')\n        else:\n            message = '__remove_URL_from_10320LOC: The URL \"' + url + '\" was removed '\\\n            + str(num_removed) + ' times.'\n            message = message.replace('1 times', 'once')\n            LOGGER.debug(message)", "response": "Remove an URL from the handle record s 10320 / LOC entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a url to the handle record s 10320 / LOC entry.", "response": "def __add_URL_to_10320LOC(self, url, list_of_entries, handle=None, weight=None, http_role=None, **kvpairs):\n        '''\n        Add a url to the handle record's \"10320/LOC\" entry.\n            If no 10320/LOC entry exists, a new one is created (using the\n            default \"chooseby\" attribute, if configured).\n            If the URL is already present, it is not added again, but\n            the attributes (e.g. weight) are updated/added.\n            If the existing 10320/LOC entry is mal-formed, an exception will be\n            thrown (xml.etree.ElementTree.ParseError)\n            Note: In the unlikely case that several \"10320/LOC\" entries exist,\n            an exception is raised.\n\n        :param url: The URL to be added.\n        :param list_of_entries: A list of the existing entries (to find and\n            adapt the correct one).\n        :param weight: Optional. The weight to be set (integer between 0 and\n            1). If None, no weight attribute is set. If the value is outside\n            the accepted range, it is set to 1.\n        :param http_role: Optional. The http_role to be set. This accepts any\n            string. Currently, Handle System can process 'conneg'. In future,\n            it may be able to process 'no_conneg' and 'browser'.\n        :param handle: Optional. Only for the exception message.\n        :param all others: Optional. All other key-value pairs will be set to\n            the element. Any value is accepted and transformed to string.\n        :raise: GenericHandleError: If several 10320/LOC exist (unlikely).\n\n        '''\n\n        # Find existing 10320/LOC entry or create new\n        indices = self.__get_python_indices_for_key('10320/LOC', list_of_entries)\n        makenew = False\n        entry = None\n        if len(indices) == 0:\n            index = self.__make_another_index(list_of_entries)\n            entry = self.__create_entry('10320/LOC', 'add_later', index)\n            makenew = True\n        else:\n            if len(indices) > 1:\n                msg = 'There is ' + str(len(indices)) + ' 10320/LOC entries.'\n                raise BrokenHandleRecordException(handle=handle, msg=msg)\n            ind = indices[0]\n            entry = list_of_entries.pop(ind)\n\n        # Get xml data or make new:\n        xmlroot = None\n        if makenew:\n            xmlroot = ET.Element('locations')\n            if self.__10320LOC_chooseby is not None:\n                xmlroot.set('chooseby', self.__10320LOC_chooseby)\n        else:\n            try:\n                xmlroot = ET.fromstring(entry['data']['value'])\n            except TypeError:\n                xmlroot = ET.fromstring(entry['data'])\n        LOGGER.debug(\"__add_URL_to_10320LOC: xmlroot is (1) \" + ET.tostring(xmlroot, encoding=encoding_value))\n\n        # Check if URL already there...\n        location_element = None\n        existing_location_ids = []\n        if not makenew:\n            list_of_locations = xmlroot.findall('location')\n            for item in list_of_locations:\n                try:\n                    existing_location_ids.append(int(item.get('id')))\n                except TypeError:\n                    pass\n                if item.get('href') == url:\n                    location_element = item\n            existing_location_ids.sort()\n        # ... if not, add it!\n        if location_element is None:\n            location_id = 0\n            for existing_id in existing_location_ids:\n                if location_id == existing_id:\n                    location_id += 1\n            location_element = ET.SubElement(xmlroot, 'location')\n            LOGGER.debug(\"__add_URL_to_10320LOC: location_element is (1) \" + ET.tostring(location_element, encoding=encoding_value) + ', now add id ' + str(location_id))\n            location_element.set('id', str(location_id))\n            LOGGER.debug(\"__add_URL_to_10320LOC: location_element is (2) \" + ET.tostring(location_element, encoding=encoding_value) + ', now add url ' + str(url))\n            location_element.set('href', url)\n            LOGGER.debug(\"__add_URL_to_10320LOC: location_element is (3) \" + ET.tostring(location_element, encoding=encoding_value))\n            self.__set_or_adapt_10320LOC_attributes(location_element, weight, http_role, **kvpairs)\n        # FIXME: If we start adapting the Handle Record by index (instead of\n        # overwriting the entire one), be careful to add and/or overwrite!\n\n        # (Re-)Add entire 10320 to entry, add entry to list of entries:\n        LOGGER.debug(\"__add_URL_to_10320LOC: xmlroot is (2) \" + ET.tostring(xmlroot, encoding=encoding_value))\n        entry['data'] = ET.tostring(xmlroot, encoding=encoding_value)\n        list_of_entries.append(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __set_or_adapt_10320LOC_attributes(self, locelement, weight=None, http_role=None, **kvpairs):\n        '''\n        Adds or updates attributes of a <location> element. Existing attributes\n            are not removed!\n\n        :param locelement: A location element as xml snippet\n            (xml.etree.ElementTree.Element).\n        :param weight: Optional. The weight to be set (integer between 0 and\n            1). If None, no weight attribute is set. If the value is outside\n            the accepted range, it is set to 1.\n        :param http_role: Optional. The http_role to be set. This accepts any\n            string. Currently, Handle System can process 'conneg'. In future,\n            it may be able to process 'no_conneg' and 'browser'.\n        :param all others: Optional. All other key-value pairs will be set to\n            the element. Any value is accepted and transformed to string.\n        '''\n\n        if weight is not None:\n            LOGGER.debug('__set_or_adapt_10320LOC_attributes: weight (' + str(type(weight)) + '): ' + str(weight))\n            weight = float(weight)\n            if weight < 0  or weight > 1:\n                default = 1\n                LOGGER.debug('__set_or_adapt_10320LOC_attributes: Invalid weight (' + str(weight) + \\\n                    '), using default value (' + str(default) + ') instead.')\n                weight = default\n            weight = str(weight)\n            locelement.set('weight', weight)\n\n        if http_role is not None:\n            locelement.set('http_role', http_role)\n\n        for key, value in kvpairs.items():\n            locelement.set(key, str(value))", "response": "Set or update the weight and http_role of a location element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify the fist authorization response url code", "response": "def auth_access(self, auth_code):\n        \"\"\"\n        verify the fist authorization response url code\n\n        response data\n        \u8fd4\u56de\u503c\u5b57\u6bb5      \u5b57\u6bb5\u7c7b\u578b    \u5b57\u6bb5\u8bf4\u660e\n        access_token    string      \u7528\u6237\u6388\u6743\u7684\u552f\u4e00\u7968\u636e\uff0c\u7528\u4e8e\u8c03\u7528\u5fae\u535a\u7684\u5f00\u653e\u63a5\u53e3\uff0c\u540c\u65f6\u4e5f\u662f\u7b2c\u4e09\u65b9\u5e94\u7528\u9a8c\u8bc1\u5fae\u535a\u7528\u6237\u767b\u5f55\u7684\u552f\u4e00\u7968\u636e\uff0c\n                                    \u7b2c\u4e09\u65b9\u5e94\u7528\u5e94\u8be5\u7528\u8be5\u7968\u636e\u548c\u81ea\u5df1\u5e94\u7528\u5185\u7684\u7528\u6237\u5efa\u7acb\u552f\u4e00\u5f71\u5c04\u5173\u7cfb\uff0c\u6765\u8bc6\u522b\u767b\u5f55\u72b6\u6001\uff0c\u4e0d\u80fd\u4f7f\u7528\u672c\u8fd4\u56de\u503c\u91cc\u7684UID\n                                    \u5b57\u6bb5\u6765\u505a\u767b\u5f55\u8bc6\u522b\u3002\n\n        expires_in      string      access_token\u7684\u751f\u547d\u5468\u671f\uff0c\u5355\u4f4d\u662f\u79d2\u6570\u3002\n        remind_in       string      access_token\u7684\u751f\u547d\u5468\u671f\uff08\u8be5\u53c2\u6570\u5373\u5c06\u5e9f\u5f03\uff0c\u5f00\u53d1\u8005\u8bf7\u4f7f\u7528expires_in\uff09\u3002\n        uid             string      \u6388\u6743\u7528\u6237\u7684UID\uff0c\u672c\u5b57\u6bb5\u53ea\u662f\u4e3a\u4e86\u65b9\u4fbf\u5f00\u53d1\u8005\uff0c\u51cf\u5c11\u4e00\u6b21user/show\u63a5\u53e3\u8c03\u7528\u800c\u8fd4\u56de\u7684\uff0c\u7b2c\u4e09\u65b9\u5e94\u7528\u4e0d\u80fd\u7528\u6b64\u5b57\u6bb5\u4f5c\u4e3a\u7528\u6237\n                                    \u767b\u5f55\u72b6\u6001\u7684\u8bc6\u522b\uff0c\u53ea\u6709access_token\u624d\u662f\u7528\u6237\u6388\u6743\u7684\u552f\u4e00\u7968\u636e\u3002\n\n        :param auth_code: authorize_url response code\n        :return:\n\n        normal:\n         {\n               \"access_token\": \"ACCESS_TOKEN\",\n               \"expires_in\": 1234,\n               \"remind_in\":\"798114\",\n               \"uid\":\"12341234\"\n         }\n         mobile:\n         {\n            \"access_token\": \"SlAV32hkKG\",\n            \"remind_in\": 3600,\n            \"expires_in\": 3600\n            \"refresh_token\": \"QXBK19xm62\"\n        }\n\n        \"\"\"\n        data = {\n            'client_id': self.client_id,\n            'client_secret': self.client_secret,\n            'grant_type': 'authorization_code',\n            'code': auth_code,\n            'redirect_uri': self.redirect_url\n        }\n        return self.request(\"post\", \"access_token\", data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a HTTP GET request to the handle server to read a single entry from a record.", "response": "def send_handle_get_request(self, handle, indices=None):\n        '''\n        Send a HTTP GET request to the handle server to read either an entire\n            handle or to some specified values from a handle record, using the\n            requests module.\n\n        :param handle: The handle.\n        :param indices: Optional. A list of indices to delete. Defaults to\n            None (i.e. the entire handle is deleted.). The list can contain\n            integers or strings.\n        :return: The server's response.\n        '''\n\n\n        # Assemble required info:\n        url = self.make_handle_URL(handle, indices)\n        LOGGER.debug('GET Request to '+url)\n        head = self.__get_headers('GET')\n        veri = self.__HTTPS_verify\n\n        # Send the request\n        if self.__cert_needed_for_get_request():\n            # If this is the first request and the connector uses client cert authentication, we need to send the cert along\n            # in the first request that builds the session.\n            resp = self.__session.get(url, headers=head, verify=veri, cert=self.__cert_object)\n        else:\n            # Normal case:\n            resp = self.__session.get(url, headers=head, verify=veri)\n    \n        # Log and return\n        self.__log_request_response_to_file(\n            logger=REQUESTLOGGER,\n            op='GET',\n            handle=handle,\n            url=url,\n            headers=head,\n            verify=veri,\n            resp=resp\n            )\n        self.__first_request = False\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_handle_put_request(self, **args):\n        '''\n        Send a HTTP PUT request to the handle server to write either an entire\n            handle or to some specified values to an handle record, using the\n            requests module.\n\n        :param handle: The handle.\n        :param list_of_entries: A list of handle record entries to be written,\n         in the format [{\"index\":xyz, \"type\":\"xyz\", \"data\":\"xyz\"}] or similar.\n        :param indices: Optional. A list of indices to delete. Defaults\n         to None (i.e. the entire handle is deleted.). The list can\n         contain integers or strings.\n        :param overwrite: Optional. Whether the handle should be overwritten\n         if it exists already.\n        :return: The server's response.\n        '''\n\n        # Check if we have write access at all:\n        if not self.__has_write_access:\n            raise HandleAuthenticationError(msg=self.__no_auth_message)\n\n        # Check args:\n        mandatory_args = ['handle', 'list_of_entries']\n        optional_args = ['indices', 'op', 'overwrite']\n        b2handle.util.add_missing_optional_args_with_value_none(args, optional_args)\n        b2handle.util.check_presence_of_mandatory_args(args, mandatory_args)\n        handle = args['handle']\n        list_of_entries = args['list_of_entries']\n        indices = args['indices']\n        op = args['op']\n        overwrite = args['overwrite'] or False\n\n        # Make necessary values:\n        url = self.make_handle_URL(handle, indices, overwrite=overwrite)\n        LOGGER.debug('PUT Request to '+url)\n        payload = json.dumps({'values':list_of_entries})\n        LOGGER.debug('PUT Request payload: '+payload)\n        head = self.__get_headers('PUT')\n        LOGGER.debug('PUT Request headers: '+str(head))\n        veri = self.__HTTPS_verify\n\n        # Send request to server:\n        resp = self.__send_put_request_to_server(url, payload, head, veri, handle)\n        if b2handle.hsresponses.is_redirect_from_http_to_https(resp):\n            resp = self.__resend_put_request_on_302(payload, head, veri, handle, resp)\n\n        # Check response for authentication issues:\n        if b2handle.hsresponses.not_authenticated(resp):\n            raise HandleAuthenticationError(\n                operation=op,\n                handle=handle,\n                response=resp,\n                username=self.__username\n            )\n        self.__first_request = False\n        return resp, payload", "response": "Send a PUT request to the handle server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a HTTP DELETE request to the handle server.", "response": "def send_handle_delete_request(self, **args):\n        '''\n        Send a HTTP DELETE request to the handle server to delete either an\n            entire handle or to some specified values from a handle record,\n            using the requests module.\n\n        :param handle: The handle.\n        :param indices: Optional. A list of indices to delete. Defaults to\n            None (i.e. the entire handle is deleted.). The list can contain\n            integers or strings.\n        :return: The server's response.\n        '''\n\n        # Check if we have write access at all:\n        if not self.__has_write_access:\n            raise HandleAuthenticationError(msg=self.__no_auth_message)\n\n        # Check args:\n        mandatory_args = ['handle']\n        optional_args = ['indices', 'op']\n        b2handle.util.add_missing_optional_args_with_value_none(args, optional_args)\n        b2handle.util.check_presence_of_mandatory_args(args, mandatory_args)\n        handle = args['handle']\n        indices = args['indices']\n        op = args['op']\n\n        # Make necessary values:\n        url = self.make_handle_URL(handle, indices)\n        if indices is not None and len(indices) > 0:\n            LOGGER.debug('__send_handle_delete_request: Deleting values '+str(indices)+' from handle '+handle+'.')\n        else:\n            LOGGER.debug('__send_handle_delete_request: Deleting handle '+handle+'.')\n        LOGGER.debug('DELETE Request to '+url)\n        head = self.__get_headers('DELETE')\n        veri = self.__HTTPS_verify\n\n        # Make request:\n        resp = None\n        if self.__authentication_method == self.__auth_methods['user_pw']:\n            resp = self.__session.delete(url, headers=head, verify=veri)\n        elif self.__authentication_method == self.__auth_methods['cert']:\n            resp = self.__session.delete(url, headers=head, verify=veri, cert=self.__cert_object)\n        self.__log_request_response_to_file(\n            logger=REQUESTLOGGER,\n            op='DELETE',\n            handle=handle,\n            url=url,\n            headers=head,\n            verify=veri,\n            resp=resp\n        )\n\n        # Check response for authentication issues:\n        if b2handle.hsresponses.not_authenticated(resp):\n            raise HandleAuthenticationError(\n                operation=op,\n                handle=handle,\n                response=resp,\n                username=self.__username\n            )\n        self.__first_request = False\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_if_username_exists(self, username):\n        '''\n        Check if the username handles exists.\n\n        :param username: The username, in the form index:prefix/suffix\n        :raises: :exc:`~b2handle.handleexceptions.HandleNotFoundException`\n        :raises: :exc:`~b2handle.handleexceptions.GenericHandleError`\n        :return: True. If it does not exist, an exception is raised.\n\n        *Note:* Only the existence of the handle is verified. The existence or\n        validity of the index is not checked, because entries containing\n        a key are hidden anyway.\n        '''\n        LOGGER.debug('check_if_username_exists...')\n\n        _, handle = b2handle.utilhandle.remove_index_from_handle(username)\n\n        resp = self.send_handle_get_request(handle)\n        resp_content = decoded_response(resp)\n        if b2handle.hsresponses.does_handle_exist(resp):\n            handlerecord_json = json.loads(resp_content)\n            if not handlerecord_json['handle'] == handle:\n                raise GenericHandleError(\n                    operation='Checking if username exists',\n                    handle=handle,\n                    reponse=resp,\n                    msg='The check returned a different handle than was asked for.'\n                )\n            return True\n        elif b2handle.hsresponses.handle_not_found(resp):\n            msg = 'The username handle does not exist'\n            raise HandleNotFoundException(handle=handle, msg=msg, response=resp)\n        else:\n            op = 'checking if handle exists'\n            msg = 'Checking if username exists went wrong'\n            raise GenericHandleError(operation=op, handle=handle, response=resp, msg=msg)", "response": "Checks if the username handles exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate HTTP headers for different HTTP requests.", "response": "def __get_headers(self, action):\n        '''\n        Create HTTP headers for different HTTP requests. Content-type and\n            Accept are 'application/json', as the library is interacting with\n            a REST API.\n\n        :param action: Action for which to create the header ('GET', 'PUT',\n            'DELETE', 'SEARCH').\n        :return: dict containing key-value pairs, e.g. 'Accept',\n            'Content-Type', etc. (depening on the action).\n        '''\n        header = {}\n        accept = 'application/json'\n        content_type = 'application/json'\n\n        if action is 'GET':\n            header['Accept'] = accept\n\n\n        elif action is 'PUT' or action is 'DELETE':\n\n            if self.__authentication_method == self.__auth_methods['cert']:\n                header['Authorization'] = 'Handle clientCert=\"true\"'\n\n            elif self.__authentication_method == self.__auth_methods['user_pw']:\n                header['Authorization'] = 'Basic ' + self.__basic_authentication_string\n\n            if action is 'PUT':\n                header['Content-Type'] = content_type\n\n\n        else:\n            LOGGER.debug('__getHeader: ACTION is unknown ('+action+')')\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_handle_URL(self, handle, indices=None, overwrite=None, other_url=None):\n        '''\n        Create the URL for a HTTP request (URL + query string) to request\n        a specific handle from the Handle Server.\n\n        :param handle: The handle to access.\n        :param indices: Optional. A list of integers or strings. Indices of\n            the handle record entries to read or write. Defaults to None.\n        :param overwrite: Optional. If set, an overwrite flag will be appended\n            to the URL ({?,&}overwrite=true or {?,&}overwrite=false). If not set, no\n            flag is set, thus the Handle Server's default behaviour will be\n            used. Defaults to None.\n        :param other_url: Optional. If a different Handle Server URL than the\n            one specified in the constructor should be used. Defaults to None.\n            If set, it should be set including the URL extension,\n            e.g. '/api/handles/'.\n        :return: The complete URL, e.g.\n         'http://some.handle.server/api/handles/prefix/suffix?index=2&index=6&overwrite=false\n        '''\n        LOGGER.debug('make_handle_URL...')\n        separator = '?'\n\n        if other_url is not None:\n            url = other_url\n        else:\n            url = self.__handle_server_url.strip('/') +'/'+\\\n                self.__REST_API_url_extension.strip('/')\n        url = url.strip('/')+'/'+ handle\n\n        if indices is None:\n            indices = []\n        if len(indices) > 0:\n            for index in indices:\n                url = url+separator+'index='+str(index)\n                separator = '&'\n\n        if overwrite is not None:\n            if overwrite:\n                url = url+separator+'overwrite=true'\n            else:\n                url = url+separator+'overwrite=false'\n\n        return url", "response": "This method creates a URL for a specific handle from the Handle Server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrecord a single hit on a given metric.", "response": "def publish_metric(self, metric_name, metric_value, epoch_seconds=None):\n        '''Record a single hit on a given metric.\n\n        Args:\n            metric_name: The name of the metric to record with Carbon.\n            metric_value: The value to record with Carbon.\n            epoch_seconds: Optionally specify the time for the metric hit.\n\n        Returns:\n            None\n\n        '''\n        if epoch_seconds is None:\n            epoch_seconds = self._reactor.seconds()\n        self._client_factory.publish_metric(metric_name, metric_value, int(epoch_seconds))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrecord hits to a metric at a specified interval.", "response": "def register_repeating_metric(self, metric_name, frequency, getter):\n        '''Record hits to a metric at a specified interval.\n\n        Args:\n            metric_name: The name of the metric to record with Carbon.\n            frequency: The frequency with which to poll the getter and record the value with Carbon.\n            getter: A function which takes no arguments and returns the value to record with Carbon.\n\n        Returns:\n            RepeatingMetricHandle instance. Call .stop() on it to stop recording the metric.\n\n        '''\n        l = task.LoopingCall(self._publish_repeating_metric, metric_name, getter)\n        repeating_metric_handle = RepeatingMetricHandle(l, frequency)\n        self._repeating_metric_handles.append(repeating_metric_handle)\n        if self.running:\n            repeating_metric_handle.start()\n        return repeating_metric_handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup(console=False, port=None, menu=True):\n\n    if self._has_been_setup:\n        teardown()\n\n    register_plugins()\n    register_host()\n\n    if menu:\n        add_to_filemenu()\n        self._has_menu = True\n\n    self._has_been_setup = True\n    print(\"pyblish: Loaded successfully.\")", "response": "Setup integration with Pyblish"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry showing the most desirable GUI", "response": "def show():\n    \"\"\"Try showing the most desirable GUI\n\n    This function cycles through the currently registered\n    graphical user interfaces, if any, and presents it to\n    the user.\n\n    \"\"\"\n\n    parent = None\n    current = QtWidgets.QApplication.activeWindow()\n    while current:\n        parent = current\n        current = parent.parent()\n\n    window = (_discover_gui() or _show_no_gui)(parent)\n\n    return window"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _nuke_set_zero_margins(widget_object):\n    parentApp = QtWidgets.QApplication.allWidgets()\n    parentWidgetList = []\n    for parent in parentApp:\n        for child in parent.children():\n            if widget_object.__class__.__name__ == child.__class__.__name__:\n                parentWidgetList.append(\n                    parent.parentWidget())\n                parentWidgetList.append(\n                    parent.parentWidget().parentWidget())\n                parentWidgetList.append(\n                    parent.parentWidget().parentWidget().parentWidget())\n\n                for sub in parentWidgetList:\n                        for tinychild in sub.children():\n                            try:\n                                tinychild.setContentsMargins(0, 0, 0, 0)\n                            except Exception:\n                                pass", "response": "Remove Nuke margins when docked UI\n   .. _More info :"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new window that is dockable.", "response": "def dock(window):\n    \"\"\" Expecting a window to parent into a Nuke panel, that is dockable. \"\"\"\n\n    # Deleting existing dock\n    # There is a bug where existing docks are kept in-memory when closed via UI\n    if self._dock:\n        print(\"Deleting existing dock...\")\n        parent = self._dock\n        dialog = None\n        stacked_widget = None\n        main_windows = []\n\n        # Getting dock parents\n        while parent:\n            if isinstance(parent, QtWidgets.QDialog):\n                dialog = parent\n            if isinstance(parent, QtWidgets.QStackedWidget):\n                stacked_widget = parent\n            if isinstance(parent, QtWidgets.QMainWindow):\n                main_windows.append(parent)\n            parent = parent.parent()\n\n        dialog.deleteLater()\n\n        if len(main_windows) > 1:\n            # Then it's a floating window\n            if stacked_widget.count() == 1:\n                # Then it's empty and we can close it,\n                # as is native Nuke UI behaviour\n                main_windows[0].deleteLater()\n\n    # Creating new dock\n    pane = nuke.getPaneFor(\"Properties.1\")\n    widget_path = \"pyblish_nuke.lib.pyblish_nuke_dockwidget\"\n    panel = nukescripts.panels.registerWidgetAsPanel(widget_path,\n                                                     window.windowTitle(),\n                                                     \"pyblish_nuke.dock\",\n                                                     True).addToPane(pane)\n\n    panel_widget = panel.customKnob.getObject().widget\n    panel_widget.layout().addWidget(window)\n    _nuke_set_zero_margins(panel_widget)\n    self._dock = panel_widget\n\n    return self._dock"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the index from the handle string.", "response": "def remove_index_from_handle(handle_with_index):\n    '''\n    Returns index and handle separately, in a tuple.\n\n    :handle_with_index: The handle string with an index (e.g.\n        500:prefix/suffix)\n    :return: index and handle as a tuple.\n    '''\n\n    split = handle_with_index.split(':')\n    if len(split) == 2:\n        split[0] = int(split[0])\n        return split\n    elif len(split) == 1:\n        return (None, handle_with_index)\n    elif len(split) > 2:\n        raise handleexceptions.HandleSyntaxError(\n            msg='Too many colons',\n            handle=handle_with_index,\n            expected_syntax='index:prefix/suffix')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the syntax of a handle without an index.", "response": "def check_handle_syntax(string):\n    '''\n    Checks the syntax of a handle without an index (are prefix\n    and suffix there, are there too many slashes?).\n\n    :string: The handle without index, as string prefix/suffix.\n    :raise: :exc:`~b2handle.handleexceptions.handleexceptions.HandleSyntaxError`\n    :return: True. If it's not ok, exceptions are raised.\n\n    '''\n\n    expected = 'prefix/suffix'\n\n    try:\n        arr = string.split('/')\n    except AttributeError:\n        raise handleexceptions.HandleSyntaxError(msg='The provided handle is None', expected_syntax=expected)\n\n    if len(arr) < 2:\n        msg = 'No slash'\n        raise handleexceptions.HandleSyntaxError(msg=msg, handle=string, expected_syntax=expected)\n\n    if len(arr[0]) == 0:\n        msg = 'Empty prefix'\n        raise handleexceptions.HandleSyntaxError(msg=msg, handle=string, expected_syntax=expected)\n\n    if len(arr[1]) == 0:\n        msg = 'Empty suffix'\n        raise handleexceptions.HandleSyntaxError(msg=msg, handle=string, expected_syntax=expected)\n\n    if ':' in string:\n        check_handle_syntax_with_index(string, base_already_checked=True)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_authentication_string(username, password):\n    '''\n    Creates an authentication string from the username and password.\n\n    :username: Username.\n    :password: Password.\n    :return: The encoded string.\n    '''\n\n    username_utf8 = username.encode('utf-8')\n    userpw_utf8 = password.encode('utf-8')\n    username_perc = quote(username_utf8)\n    userpw_perc = quote(userpw_utf8)\n\n    authinfostring = username_perc + ':' + userpw_perc\n    authinfostring_base64 = base64.b64encode(authinfostring.encode('utf-8')).decode('utf-8')\n    return authinfostring_base64", "response": "Creates an authentication string from the username and password."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a string containing all relevant information about a request made to the Handle System, for logging purposes. :handle: The handle that the request is about. :url: The url the request is sent to. :headers: The headers sent along with the request. :verify: Boolean parameter passed to the requests module (https verification). :resp: The request's response. :op: The library operation during which the request was sent. :payload: Optional. The payload sent with the request. :return: A formatted string.", "response": "def make_request_log_message(**args):\n    '''\n    Creates a string containing all relevant information\n    about a request made to the Handle System, for\n    logging purposes.\n\n    :handle: The handle that the request is about.\n    :url: The url the request is sent to.\n    :headers: The headers sent along with the request.\n    :verify: Boolean parameter passed to the requests\n        module (https verification).\n    :resp: The request's response.\n    :op: The library operation during which the request\n        was sent.\n    :payload: Optional. The payload sent with the request.\n    :return: A formatted string.\n\n    '''\n\n    mandatory_args = ['op', 'handle', 'url', 'headers', 'verify', 'resp']\n    optional_args = ['payload']\n    util.check_presence_of_mandatory_args(args, mandatory_args)\n    util.add_missing_optional_args_with_value_none(args, optional_args)\n\n    space = '\\n   '\n    message = ''\n    message += '\\n'+args['op']+' '+args['handle']\n    message += space+'URL:          '+args['url']\n    message += space+'HEADERS:      '+str(args['headers'])\n    message += space+'VERIFY:       '+str(args['verify'])\n    if 'payload' in args.keys():\n        message += space+'PAYLOAD:'+space+str(args['payload'])\n    message += space+'RESPONSECODE: '+str(args['resp'].status_code)\n    message += space+'RESPONSE:'+space+str(args['resp'].content)\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request_xml(url, auth=None):\n    '''\n    Returns an etree.XMLRoot object loaded from the url\n    :param str url: URL for the resource to load as an XML\n    '''\n    try:\n        r = requests.get(url, auth=auth, verify=False)\n        return r.text.encode('utf-8')\n    except BaseException:\n        logger.error(\"Skipping %s (error parsing the XML)\" % url)\n    return", "response": "Request the XML from the URL and return the result as an etree. XMLRoot object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_catalog_url(self, url):\n        '''\n        Returns the appropriate catalog URL by replacing html with xml in some\n        cases\n        :param str url: URL to the catalog\n        '''\n        u = urlparse.urlsplit(url)\n        name, ext = os.path.splitext(u.path)\n        if ext == \".html\":\n            u = urlparse.urlsplit(url.replace(\".html\", \".xml\"))\n        url = u.geturl()\n        return url", "response": "Returns the appropriate catalog URL by replacing html with xml in some\n        cases"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield a URL corresponding to a leaf dataset for each dataset described by the current catalog .", "response": "def _yield_leaves(self, url, tree):\n        '''\n        Yields a URL corresponding to a leaf dataset for each dataset described by the catalog\n        :param str url: URL for the current catalog\n        :param lxml.etree.Eleemnt tree: Current XML Tree\n        '''\n        for leaf in tree.findall('.//{%s}dataset[@urlPath]' % INV_NS):\n            # Subset by the skips\n            name = leaf.get(\"name\")\n            if any([x.match(name) for x in self.skip]):\n                logger.info(\"Skipping dataset based on 'skips'.  Name: %s\" % name)\n                continue\n\n            # Subset by before and after\n            date_tag = leaf.find('.//{%s}date[@type=\"modified\"]' % INV_NS)\n            if date_tag is not None:\n                try:\n                    dt = parse(date_tag.text)\n                except ValueError:\n                    logger.error(\"Skipping dataset.Wrong date string %s \" % date_tag.text)\n                    continue\n                else:\n                    dt = dt.replace(tzinfo=pytz.utc)\n                if self.after and dt < self.after:\n                    continue\n                if self.before and dt > self.before:\n                    continue\n\n            # Subset by the Selects defined\n            gid = leaf.get('ID')\n            if self.select is not None:\n                if gid is not None and any([x.match(gid) for x in self.select]):\n                    logger.debug(\"Processing %s\" % gid)\n                    yield \"%s?dataset=%s\" % (url, gid)\n                else:\n                    logger.info(\"Ignoring dataset based on 'selects'.  ID: %s\" % gid)\n                    continue\n            else:\n                logger.debug(\"Processing %s\" % gid)\n                yield \"%s?dataset=%s\" % (url, gid)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompile the list of catalog reference URLs for the current catalog.", "response": "def _compile_references(self, url, tree):\n        '''\n        Returns a list of catalog reference URLs for the current catalog\n        :param str url: URL for the current catalog\n        :param lxml.etree.Eleemnt tree: Current XML Tree\n        '''\n        references = []\n        for ref in tree.findall('.//{%s}catalogRef' % INV_NS):\n            # Check skips\n            title = ref.get(\"{%s}title\" % XLINK_NS)\n            if any([x.match(title) for x in self.skip]):\n                logger.info(\"Skipping catalogRef based on 'skips'.  Title: %s\" % title)\n                continue\n            references.append(construct_url(url, ref.get(\"{%s}href\" % XLINK_NS)))\n        return references"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run(self, url, auth):\n        '''\n        Performs a multiprocess depth-first-search of the catalog references\n        and yields a URL for each leaf dataset found\n        :param str url: URL for the current catalog\n        :param requests.auth.AuthBase auth: requets auth object to use\n        '''\n        if url in self.visited:\n            logger.debug(\"Skipping %s (already crawled)\" % url)\n            return\n        self.visited.append(url)\n\n        logger.info(\"Crawling: %s\" % url)\n        url = self._get_catalog_url(url)\n\n        # Get an etree object\n        xml_content = request_xml(url, auth)\n        for ds in self._build_catalog(url, xml_content):\n            yield ds", "response": "Performs a multiprocess depth - first search of the catalog references\n        and yields a URL for each leaf dataset found\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_catalog(self, url, xml_content):\n        '''\n        Recursive function to perform the DFS and yield the leaf datasets\n        :param str url: URL for the current catalog\n        :param str xml_content: XML Body returned from HTTP Request\n        '''\n        try:\n            tree = etree.XML(xml_content)\n        except BaseException:\n            return\n\n        # Get a list of URLs\n        references = self._compile_references(url, tree)\n        # Using multiple processes, make HTTP requests for each child catalog\n        jobs = [self.pool.apply_async(request_xml, args=(ref,)) for ref in references]\n        responses = [j.get() for j in jobs]\n\n        # This is essentially the graph traversal step\n        for i, response in enumerate(responses):\n            for ds in self._build_catalog(references[i], response):\n                yield ds\n\n        # Yield the leaves\n        for ds in self._yield_leaves(url, tree):\n            yield ds", "response": "Recursive function to perform the DFS and yield the leaf datasets"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_module(fdr, fqname, path = None):\n    '''Find a loader for module or package `fqname`.\n\n       This method will be called with the fully qualified name\n       of the module.  If the finder is installed on `sys.meta_path`,\n       it will receive a second argument, which is `None` for\n       a top-level module, or `package.__path__` for submodules\n       or subpackages [5].\n       It should return a loader object if the module was found, or\n       `None` if it wasn't.  If `find_module()` raises an exception,\n       it will be propagated to the caller, aborting the import.\n\n       [5] The path argument to `finder.find_module()` is there\n           because the `pkg.__path__` variable may be needed\n           at this point.  It may either come from the actual\n           parent module or be supplied by `imp.find_module()`\n           or the proposed `imp.get_loader()` function.\n    '''\n    if fqname in fdr.aliases:\n      return Loader(fqname, fdr.aliases[fqname])\n    return None", "response": "Find a loader for a module or package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_module(ldr, fqname):\n    '''Load `fqname` from under `ldr.fspath`.\n\n       The `fqname` argument is the fully qualified module name,\n       eg. \"spam.eggs.ham\".  As explained above, when ::\n\n         finder.find_module(\"spam.eggs.ham\")\n\n       is called, \"spam.eggs\" has already been imported and added\n       to `sys.modules`.  However, the `find_module()` method isn't\n       necessarily always called during an actual import:\n       meta tools that analyze import dependencies (such as freeze,\n       Installer or py2exe) don't actually load modules, so\n       a finder shouldn't depend on the parent package being\n       available in `sys.modules`.\n\n       The `load_module()` method has a few responsibilities that\n       it must fulfill before it runs any code:\n\n       * If there is an existing module object named 'fullname' in\n         `sys.modules`, the loader must use that existing module.\n         (Otherwise, the `reload()` builtin will not work correctly.)\n         If a module named 'fullname' does not exist in\n         `sys.modules`, the loader must create a new module object\n         and add it to `sys.modules`.\n\n         Note that the module object must be in `sys.modules`\n         before the loader executes the module code. This is\n         crucial because the module code may (directly or\n         indirectly) import itself; adding it to `sys.modules`\n         beforehand prevents unbounded recursion in the worst case\n         and multiple loading in the best.\n\n         If the load fails, the loader needs to remove any module it\n         may have inserted into `sys.modules`. If the module was\n         already in `sys.modules` then the loader should leave it\n         alone.\n\n       * The `__file__` attribute must be set. This must be a string,\n         but it may be a dummy value, for example \"<frozen>\".\n         The privilege of not having a `__file__` attribute at all\n         is reserved for built-in modules.\n\n       * The `__name__` attribute must be set. If one uses\n         `imp.new_module()` then the attribute is set automatically.\n\n       * If it's a package, the __path__ variable must be set.\n         This must be a list, but may be empty if `__path__` has no\n         further significance to the importer (more on this later).\n\n       * The `__loader__` attribute must be set to the loader object.\n         This is mostly for introspection and reloading, but can be\n         used for importer-specific extras, for example getting data\n         associated with an importer.\n\n        The `__package__` attribute [8] must be set.\n\n        If the module is a Python module (as opposed to a built-in\n        module or a dynamically loaded extension), it should execute\n        the module's code in the module's global name space\n        (`module.__dict__`).\n\n       [8] PEP 366: Main module explicit relative imports\n           http://www.python.org/dev/peps/pep-0366/\n    '''\n\n    scope = ldr.scope.split('.')\n    modpath = fqname.split('.')\n\n    if scope != modpath[0:len(scope)]:\n      raise AssertionError(\n        \"%s responsible for %s got request for %s\" % (\n          ldr.__class__.__name__,\n          ldr.scope,\n          fqname,\n        )\n      )\n\n    if fqname in sys.modules:\n      mod = sys.modules[fqname]\n    else:\n      mod = sys.modules.setdefault(fqname, types.ModuleType(fqname))\n\n    mod.__loader__ = ldr\n\n    fspath = ldr.path_to(fqname)\n\n    mod.__file__ = str(fspath)\n\n    if fs.is_package(fspath):\n      mod.__path__ = [ldr.fspath]\n      mod.__package__ = str(fqname)\n    else:\n      mod.__package__ = str(fqname.rpartition('.')[0])\n\n    exec(fs.get_code(fspath), mod.__dict__)\n\n    return mod", "response": "Load a module from the given file path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an attached thread and fork it.", "response": "def zthread_fork(ctx, func, *args, **kwargs):\n    \"\"\"\n    Create an attached thread. An attached thread gets a ctx and a PAIR\n    pipe back to its parent. It must monitor its pipe, and exit if the\n    pipe becomes unreadable. Returns pipe, or NULL if there was an error.\n    \"\"\"\n    a = ctx.socket(zmq.PAIR)\n    a.setsockopt(zmq.LINGER, 0)\n    a.setsockopt(zmq.RCVHWM, 100)\n    a.setsockopt(zmq.SNDHWM, 100)\n    a.setsockopt(zmq.SNDTIMEO, 5000)\n    a.setsockopt(zmq.RCVTIMEO, 5000)\n    b = ctx.socket(zmq.PAIR)\n    b.setsockopt(zmq.LINGER, 0)\n    b.setsockopt(zmq.RCVHWM, 100)\n    b.setsockopt(zmq.SNDHWM, 100)\n    b.setsockopt(zmq.SNDTIMEO, 5000)\n    a.setsockopt(zmq.RCVTIMEO, 5000)\n    iface = \"inproc://%s\" % binascii.hexlify(os.urandom(8))\n    a.bind(iface)\n    b.connect(iface)\n\n    thread = threading.Thread(target=func, args=((ctx, b) + args), kwargs=kwargs)\n    thread.daemon = False\n    thread.start()\n\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprevent accidental assignment of existing members of the object.", "response": "def _remap(object, name, value, safe=True):\n    \"\"\"Prevent accidental assignment of existing members\n\n    Arguments:\n        object (object): Parent of new attribute\n        name (str): Name of new attribute\n        value (object): Value of new attribute\n        safe (bool): Whether or not to guarantee that\n            the new attribute was not overwritten.\n            Can be set to False under condition that\n            it is superseded by extensive testing.\n\n    \"\"\"\n\n    if os.getenv(\"QT_TESTING\") is not None and safe:\n        # Cannot alter original binding.\n        if hasattr(object, name):\n            raise AttributeError(\"Cannot override existing name: \"\n                                 \"%s.%s\" % (object.__name__, name))\n\n        # Cannot alter classes of functions\n        if type(object).__name__ != \"module\":\n            raise AttributeError(\"%s != 'module': Cannot alter \"\n                                 \"anything but modules\" % object)\n\n    elif hasattr(object, name):\n        # Keep track of modifications\n        self.__modified__.append(name)\n\n    self.__remapped__.append(name)\n\n    setattr(object, name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog the instantiation of an object to the given logger.", "response": "def log_instantiation(LOGGER, classname, args, forbidden, with_date=False):\n    '''\n    Log the instantiation of an object to the given logger.\n\n    :LOGGER: A logger to log to. Please see module \"logging\".\n    :classname: The name of the class that is being\n        instantiated.\n    :args: A dictionary of arguments passed to the instantiation,\n        which will be logged on debug level.\n    :forbidden: A list of arguments whose values should not be\n        logged, e.g. \"password\".\n    :with_date: Optional. Boolean. Indicated whether the initiation\n        date and time should be logged.\n    '''\n\n    # Info:\n    if with_date:\n            LOGGER.info('Instantiating '+classname+' at '+datetime.datetime.now().strftime('%Y-%m-%d_%H:%M'))\n    else:\n        LOGGER.info('Instantiating '+classname)\n\n    # Debug:\n    for argname in args:\n        if args[argname] is not None:\n            if argname in forbidden:\n                LOGGER.debug('Param '+argname+'*******')\n            else:\n                LOGGER.debug('Param '+argname+'='+str(args[argname]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting dict value if value is bool type False -> false True -> true", "response": "def filter_params(params):\n    \"\"\"\n    convert dict value if value is bool type,\n    False -> \"false\"\n    True -> \"true\"\n    \"\"\"\n    if params is not None:\n        new_params = copy.deepcopy(params)\n        new_params = dict((k, v) for k, v in new_params.items() if v is not None)\n        for key, value in new_params.items():\n            if isinstance(value, bool):\n                new_params[key] = \"true\" if value else \"false\"\n        return new_params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling response from weibo API.", "response": "def _handler_response(self, response, data=None):\n        \"\"\"\n        error code response:\n        {\n            \"request\": \"/statuses/home_timeline.json\",\n            \"error_code\": \"20502\",\n            \"error\": \"Need you follow uid.\"\n        }\n        :param response:\n        :return:\n        \"\"\"\n        if response.status_code == 200:\n            data = response.json()\n            if isinstance(data, dict) and data.get(\"error_code\"):\n\n                raise WeiboAPIError(data.get(\"request\"), data.get(\"error_code\"), data.get(\"error\"))\n            else:\n                return data\n        else:\n            raise WeiboRequestError(\n                \"Weibo API request error: status code: {code} url:{url} ->\"\n                \" method:{method}: data={data}\".format(\n                    code=response.status_code,\n                    url=response.url,\n                    method=response.request.method,\n                    data=data\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting weibo api :param suffix: str, :param params: dict, url query parameters :return:", "response": "def get(self, suffix, params=None):\n        \"\"\"\n        request weibo api\n        :param suffix: str,\n        :param params: dict, url query parameters\n        :return:\n\n        \"\"\"\n\n        url = self.base + suffix\n        params = filter_params(params)\n\n        response = self.session.get(url=url, params=params)\n\n        return self._handler_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self, suffix, params=None, data=None, files=None):\n\n        url = self.base + suffix\n        params = filter_params(params)\n\n        response = self.session.post(url=url, params=params, data=data, files=files)\n\n        return self._handler_response(response, data=data)", "response": "POST a new entry in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_handle(self, **args):\n        '''\n        Search for handles containing the specified key with the specified\n        value. The search terms are passed on to the reverse lookup servlet\n        as-is. The servlet is supposed to be case-insensitive, but if it\n        isn't, the wrong case will cause a :exc:`~b2handle.handleexceptions.ReverseLookupException`.\n\n        *Note:* If allowed search keys are configured, only these are used. If\n        no allowed search keys are specified, all key-value pairs are\n        passed on to the reverse lookup servlet, possibly causing a\n        :exc:`~b2handle.handleexceptions.ReverseLookupException`.\n\n        Example calls:\n          * list_of_handles = search_handle('http://www.foo.com')\n          * list_of_handles = search_handle('http://www.foo.com', CHECKSUM=99999)\n          * list_of_handles = search_handle(URL='http://www.foo.com', CHECKSUM=99999)\n\n        :param URL: Optional. The URL to search for (reverse lookup). [This is\n            NOT the URL of the search servlet!]\n        :param prefix: Optional. The Handle prefix to which the search should\n            be limited to. If unspecified, the method will search across all\n            prefixes present at the server given to the constructor.\n        :param key_value_pairs: Optional. Several search fields and values can\n            be specified as key-value-pairs,\n            e.g. CHECKSUM=123456, URL=www.foo.com\n        :raise: :exc:`~b2handle.handleexceptions.ReverseLookupException`: If a search field is specified that\n            cannot be used, or if something else goes wrong.\n        :return: A list of all Handles (strings) that bear the given key with\n            given value of given prefix or server. The list may be empty and\n            may also contain more than one element.\n        '''\n        LOGGER.debug('search_handle...')\n        if self.__has_search_access:\n            return self.__search_handle(**args)\n        else:\n            LOGGER.error(\n                'Searching not possible. Reason: No access '+\n                'to search system (endpoint: '+\n                str(self.__search_url)+').'\n            )\n            return None", "response": "Search for all handles containing the specified key with the specified value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_revlookup_query(self, *fulltext_searchterms, **keyvalue_searchterms):\n        '''\n        Create the part of the solr request that comes after the question mark,\n        e.g. ?URL=*dkrz*&CHECKSUM=*abc*. If allowed search keys are\n        configured, only these are used. If no'allowed search keys are\n        specified, all key-value pairs are passed on to the reverse lookup\n        servlet.\n\n        :param fulltext_searchterms: Optional. Any term specified will be used\n            as search term. Not implemented yet, so will be ignored.\n        :param keyvalue_searchterms: Optional. Key-value pairs. Any key-value\n            pair will be used to search for the value in the field \"key\".\n            Wildcards accepted (refer to the documentation of the reverse\n            lookup servlet for syntax.)\n        :return: The query string, after the \"?\". If no valid search terms were\n            specified, None is returned.\n        '''\n        LOGGER.debug('create_revlookup_query...')\n\n        allowed_search_keys = self.__allowed_search_keys\n        only_search_for_allowed_keys = False\n        if len(allowed_search_keys) > 0:\n            only_search_for_allowed_keys = True\n\n        fulltext_searchterms_given = True\n        fulltext_searchterms = b2handle.util.remove_value_none_from_list(fulltext_searchterms)\n        if len(fulltext_searchterms) == 0:\n            fulltext_searchterms_given = False\n        \n        if fulltext_searchterms_given:\n            msg = 'Full-text search is not implemented yet.'+\\\n                ' The provided searchterms '+str(fulltext_searchterms)+\\\n                ' can not be used.'\n            raise ReverseLookupException(msg=msg)\n\n        keyvalue_searchterms_given = True\n        keyvalue_searchterms = b2handle.util.remove_value_none_from_dict(keyvalue_searchterms)\n        if len(keyvalue_searchterms) == 0:\n            keyvalue_searchterms_given = False\n\n        if not keyvalue_searchterms_given and not fulltext_searchterms_given:\n            msg = 'No search terms have been specified. Please specify'+\\\n                ' at least one key-value-pair.'\n            raise ReverseLookupException(msg=msg)\n\n        counter = 0\n        query = '?'\n        for key, value in keyvalue_searchterms.items():\n\n            if only_search_for_allowed_keys and key not in allowed_search_keys:\n                msg = 'Cannot search for key \"'+key+'\". Only searches '+\\\n                    'for keys '+str(allowed_search_keys)+' are implemented.'\n                raise ReverseLookupException(msg=msg)\n            else:\n                query = query+'&'+key+'='+value\n                counter += 1\n\n        query = query.replace('?&', '?')\n        LOGGER.debug('create_revlookup_query: query: '+query)\n        if counter == 0: # unreachable?\n            msg = 'No valid search terms have been specified.'\n            raise ReverseLookupException(msg=msg)\n        return query", "response": "Create the part of the solr request that comes after the question mark."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_from_JSON(json_filename):\n        '''\n        Create a new instance of a PIDClientCredentials with information read\n        from a local JSON file.\n\n        :param json_filename: The path to the json credentials file. The json\n            file should have the following format:\n\n                .. code:: json\n\n                    {\n                        \"handle_server_url\": \"https://url.to.your.handle.server\",\n                        \"username\": \"index:prefix/suffix\",\n                        \"password\": \"ZZZZZZZ\",\n                        \"prefix\": \"prefix_to_use_for_writing_handles\",\n                        \"handleowner\": \"username_to_own_handles\"\n                    }\n\n            Any additional key-value-pairs are stored in the instance as\n            config.\n        :raises: :exc:`~b2handle.handleexceptions.CredentialsFormatError`\n        :raises: :exc:`~b2handle.handleexceptions.HandleSyntaxError`\n        :return: An instance.\n        '''\n        try:\n            jsonfilecontent = json.loads(open(json_filename, 'r').read())\n        except ValueError as exc:\n            raise CredentialsFormatError(msg=\"Invalid JSON syntax: \"+str(exc))\n        instance = PIDClientCredentials(credentials_filename=json_filename,**jsonfilecontent)\n        return instance", "response": "Load a new instance of a PIDClientCredentials with information read from a local json file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fixture(app, fixtures, fixtures_dir='fixtures', raise_does_not_exist=False,\n            reversible=True, models=[]):\n    \"\"\"\n    Load fixtures using a data migration.\n\n    The migration will by default provide a rollback, deleting items by primary\n    key. This is not always what you want ; you may set reversible=False to\n    prevent rolling back.\n\n    Usage:\n\n    import myapp\n    import anotherapp\n\n    operations = [\n        migrations.RunPython(**fixture(myapp, 'eggs.yaml')),\n        migrations.RunPython(**fixture(anotherapp, ['sausage.json', 'walks.yaml']))\n        migrations.RunPython(**fixture(yap, ['foo.json'], reversible=False))\n    ]\n    \"\"\"\n    fixture_path = os.path.join(app.__path__[0], fixtures_dir)\n    if isinstance(fixtures, string_types):\n        fixtures = [fixtures]\n\n    def get_format(fixture):\n        return os.path.splitext(fixture)[1][1:]\n\n    def get_objects():\n        for fixture in fixtures:\n            with open(os.path.join(fixture_path, fixture), 'rb') as f:\n                objects = serializers.deserialize(get_format(fixture),\n                                                  f,\n                                                  ignorenonexistent=True)\n                for obj in objects:\n                    yield obj\n\n    def patch_apps(func):\n        \"\"\"\n        Patch the app registry.\n\n        Note that this is necessary so that the Deserializer does not use the\n        current version of the model, which may not necessarily be representative\n        of the model the fixture was created for.\n        \"\"\"\n        @wraps(func)\n        def inner(apps, schema_editor):\n            try:\n                # Firstly patch the serializers registry\n                original_apps = django.core.serializers.python.apps\n                django.core.serializers.python.apps = apps\n                return func(apps, schema_editor)\n\n            finally:\n                # Ensure we always unpatch the serializers registry\n                django.core.serializers.python.apps = original_apps\n\n        return inner\n\n    @patch_apps\n    def load_fixture(apps, schema_editor):\n        for obj in get_objects():\n            obj.save()\n\n    @patch_apps\n    def unload_fixture(apps, schema_editor):\n        for obj in get_objects():\n            model = apps.get_model(app.__name__, obj.object.__class__.__name__)\n            kwargs = dict()\n            if 'id' in obj.object.__dict__:\n                kwargs.update(id=obj.object.__dict__.get('id'))\n            elif 'slug' in obj.object.__dict__:\n                kwargs.update(slug=obj.object.__dict__.get('slug'))\n            else:\n                kwargs.update(**obj.object.__dict__)\n            try:\n                model.objects.get(**kwargs).delete()\n            except model.DoesNotExist:\n                if not raise_does_not_exist:\n                    raise FixtureObjectDoesNotExist((\"Model %s instance with \"\n                                                     \"kwargs %s does not exist.\"\n                                                     % (model, kwargs)))\n\n    kwargs = dict(code=load_fixture)\n\n    if reversible:\n        kwargs['reverse_code'] = unload_fixture\n\n    return kwargs", "response": "Load a set of fixtures into the app registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all non - zero bits in the set", "response": "def nonzero(self):\n        \"\"\"\n        Get all non-zero bits\n        \"\"\"\n        return [i for i in xrange(self.size()) if self.test(i)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tohexstring(self):\n        val = self.tostring()\n        st = \"{0:0x}\".format(int(val, 2))\n        return st.zfill(len(self.bitmap)*2)", "response": "Returns a hexadecimal string representation of the current bitmap entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing BitMap from hex string", "response": "def fromhexstring(cls, hexstring):\n        \"\"\"\n        Construct BitMap from hex string\n        \"\"\"\n        bitstring = format(int(hexstring, 16), \"0\" + str(len(hexstring)/4) + \"b\")\n        return cls.fromstring(bitstring)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromstring(cls, bitstring):\n        nbits = len(bitstring)\n        bm = cls(nbits)\n        for i in xrange(nbits):\n            if bitstring[-i-1] == '1':\n                bm.set(i)\n            elif bitstring[-i-1] != '0':\n                raise Exception(\"Invalid bit string!\")\n        return bm", "response": "Construct a BitMap from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets version information or return default if unable to do so.", "response": "def get_versions():\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split('/'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find root of source tree\"}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    _version_path = os.path.join(os.path.dirname(__file__), '_version')\n    if os.path.exists(_version_path):\n        with open(_version_path) as f:\n            l = f.readline().strip()\n            return {\n                'version': l,\n                'error': None,\n                'dirty': None,\n                'full-revisionid': l\n            }\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to compute version\"}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a value that can be the boolean representation of a string or a boolean itself and returns It as a boolean.", "response": "def get_valid_https_verify(value):\n    '''\n    Get a value that can be the boolean representation of a string\n    or a boolean itself and returns It as a boolean.\n    If this is not the case, It returns a string.\n\n    :value: The HTTPS_verify input value. A string can be passed as a path\n            to a CA_BUNDLE certificate\n    :returns: True, False or a string.\n    '''\n    http_verify_value = value\n    bool_values = {'false': False, 'true': True}\n\n    if isinstance(value, bool):\n        http_verify_value = value\n    elif (isinstance(value, str) or isinstance(value, unicode)) and value.lower() in bool_values.keys():\n        http_verify_value = bool_values[value.lower()]\n\n    return http_verify_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup(self):\n        super(CleanCSSFilter, self).setup()\n        self.root = current_app.config.get('COLLECT_STATIC_ROOT')", "response": "Initialize filter just before it will be used."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rebase_opt(self):\n        if not hasattr(self, '_rebase_opt'):\n            # out = b\"MAJOR.MINOR.REVISION\" // b\"3.4.19\" or b\"4.0.0\"\n            out, err = Popen(\n                ['cleancss', '--version'], stdout=PIPE).communicate()\n            ver = int(out[:out.index(b'.')])\n            self._rebase_opt = ['--root', self.root] if ver == 3 else []\n        return self._rebase_opt", "response": "Determine which option name to use."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap translation in Angular module.", "response": "def output(self, _in, out, **kwargs):\n        \"\"\"Wrap translation in Angular module.\"\"\"\n        out.write(\n            'angular.module(\"{0}\", [\"gettext\"]).run('\n            '[\"gettextCatalog\", function (gettextCatalog) {{'.format(\n                self.catalog_name\n            )\n        )\n        out.write(_in.read())\n        out.write('}]);')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef input(self, _in, out, **kwargs):\n        language_code = _re_language_code.search(_in.read()).group(\n            'language_code'\n        )\n        _in.seek(0)  # move at the begining after matching the language\n        catalog = read_po(_in)\n        out.write('gettextCatalog.setStrings(\"{0}\", '.format(language_code))\n        out.write(json.dumps({\n            key: value.string for key, value in catalog._messages.items()\n            if key and value.string\n        }))\n        out.write(');')", "response": "Process individual translation file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting user and check if password is valid on the database.", "response": "def get_user_and_check_auth(self, username, password):\n        \"\"\"Check the combination username/password that is valid on the\n        database.\n        \"\"\"\n        constraint = sql.or_(\n            models.USERS.c.name == username,\n            models.USERS.c.email == username\n        )\n\n        user = self.identity_from_db(models.USERS, constraint)\n        if user is None:\n            raise dci_exc.DCIException('User %s does not exists.' % username,\n                                       status_code=401)\n\n        return user, auth.check_passwords_equal(password, user.password)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the Github API to retrieve the needed infos.", "response": "def retrieve_info(self):\n        \"\"\"Query the Github API to retrieve the needed infos.\"\"\"\n\n        path = urlparse(self.url).path\n        path = path.split('/')[1:]\n\n        sanity_filter = re.compile('[\\da-z-_]+', re.IGNORECASE)\n        self.product = sanity_filter.match(path[0]).group(0)\n        self.component = sanity_filter.match(path[1]).group(0)\n        self.issue_id = int(path[3])\n\n        github_url = '%s/%s/%s/issues/%s' % (_URL_BASE,\n                                             self.product,\n                                             self.component,\n                                             self.issue_id)\n\n        result = requests.get(github_url)\n        self.status_code = result.status_code\n\n        if result.status_code == 200:\n            result = result.json()\n            self.title = result['title']\n            self.reporter = result['user']['login']\n            if result['assignee'] is not None:\n                self.assignee = result['assignee']['login']\n            self.status = result['state']\n            self.created_at = result['created_at']\n            self.updated_at = result['updated_at']\n            self.closed_at = result['closed_at']\n        elif result.status_code == 404:\n            self.title = 'private issue'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncache the return value in the correct cache directory. Set 'method' to false for static methods.", "response": "def disk_cache(cls, basename, function, *args, method=True, **kwargs):\n        \"\"\"\n        Cache the return value in the correct cache directory. Set 'method' to\n        false for static methods.\n        \"\"\"\n        @utility.disk_cache(basename, cls.directory(), method=method)\n        def wrapper(*args, **kwargs):\n            return function(*args, **kwargs)\n\n        return wrapper(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download(cls, url, filename=None):\n        return utility.download(url, cls.directory(), filename)", "response": "Download a file into the correct cache directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the path that should be used for caching. Different for all subclasses.", "response": "def directory(cls, prefix=None):\n        \"\"\"\n        Path that should be used for caching. Different for all subclasses.\n        \"\"\"\n        prefix = prefix or utility.read_config().directory\n        name = cls.__name__.lower()\n        directory = os.path.expanduser(os.path.join(prefix, name))\n        utility.ensure_directory(directory)\n        return directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the last rconfiguration_id of the last job run by the remoteci.", "response": "def get_last_rconfiguration_id(topic_id, remoteci_id, db_conn=None):\n    \"\"\"Get the rconfiguration_id of the last job run by the remoteci.\n\n    :param topic_id: the topic\n    :param remoteci_id: the remoteci id\n    :return: last rconfiguration_id of the remoteci\n    \"\"\"\n    db_conn = db_conn or flask.g.db_conn\n    __TABLE = models.JOBS\n    query = sql.select([__TABLE.c.rconfiguration_id]). \\\n        order_by(sql.desc(__TABLE.c.created_at)). \\\n        where(sql.and_(__TABLE.c.topic_id == topic_id,\n                       __TABLE.c.remoteci_id == remoteci_id)). \\\n        limit(1)\n    rconfiguration_id = db_conn.execute(query).fetchone()\n    if rconfiguration_id is not None:\n        return str(rconfiguration_id[0])\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a remoteci configuration. This will iterate over each available rconfiguration in a round robin manner depending on the last rconfiguration used by the remoteci.", "response": "def get_remoteci_configuration(topic_id, remoteci_id, db_conn=None):\n    \"\"\"Get a remoteci configuration. This will iterate over each\n    configuration in a round robin manner depending on the last\n    rconfiguration used by the remoteci.\"\"\"\n\n    db_conn = db_conn or flask.g.db_conn\n    last_rconfiguration_id = get_last_rconfiguration_id(\n        topic_id, remoteci_id, db_conn=db_conn)\n    _RCONFIGURATIONS = models.REMOTECIS_RCONFIGURATIONS\n    _J_RCONFIGURATIONS = models.JOIN_REMOTECIS_RCONFIGURATIONS\n    query = sql.select([_RCONFIGURATIONS]). \\\n        select_from(_J_RCONFIGURATIONS.\n                    join(_RCONFIGURATIONS)). \\\n        where(_J_RCONFIGURATIONS.c.remoteci_id == remoteci_id)\n    query = query.where(sql.and_(_RCONFIGURATIONS.c.state != 'archived',\n                                 _RCONFIGURATIONS.c.topic_id == topic_id))\n    query = query.order_by(sql.desc(_RCONFIGURATIONS.c.created_at))\n    query = query.order_by(sql.asc(_RCONFIGURATIONS.c.name))\n    all_rconfigurations = db_conn.execute(query).fetchall()\n\n    if len(all_rconfigurations) > 0:\n        for i in range(len(all_rconfigurations)):\n            if str(all_rconfigurations[i]['id']) == last_rconfiguration_id:\n                # if i==0, then indice -1 is the last element\n                return all_rconfigurations[i - 1]\n        return all_rconfigurations[0]\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self, request: Request) -> None:\n\n        handler_factories = self._registry.lookup(request)\n        if len(handler_factories) != 1:\n            raise ConfigurationException(\"There is no handler registered for this request\")\n        handler = handler_factories[0]()\n        handler.handle(request)", "response": "Dispatches a request. Expects one and one only target handler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndispatching a request. Expects zero or more target handlers", "response": "def publish(self, request: Request) -> None:\n        \"\"\"\n        Dispatches a request. Expects zero or more target handlers\n        :param request: The request to dispatch\n        :return: None.\n        \"\"\"\n        handler_factories = self._registry.lookup(request)\n        for factory in handler_factories:\n            handler = factory()\n            handler.handle(request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndispatch a request over middleware. Returns when the request is sent to the broker.", "response": "def post(self, request: Request) -> None:\n        \"\"\"\n        Dispatches a request over middleware. Returns when message put onto outgoing channel by producer,\n        does not wait for response from a consuming application i.e. is fire-and-forget\n        :param request: The request to dispatch\n        :return: None\n        \"\"\"\n\n        if self._producer is None:\n            raise ConfigurationException(\"Command Processor requires a BrightsideProducer to post to a Broker\")\n        if self._message_mapper_registry is None:\n            raise ConfigurationException(\"Command Processor requires a BrightsideMessage Mapper Registry to post to a Broker\")\n\n        message_mapper = self._message_mapper_registry.lookup(request)\n        message = message_mapper(request)\n        self._message_store.add(message)\n        self._producer.send(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ignore_whitespace_text_nodes(cls, wrapped_node):\n        for child in wrapped_node.children:\n            if child.is_text and child.value.strip() == '':\n                child.delete()\n            else:\n                cls.ignore_whitespace_text_nodes(child)", "response": "Recursively delete any text nodes containing nothing but whitespace in the given node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ns_info_from_node_name(self, name, impl_node):\n        if '}' in name:\n            ns_uri, name = name.split('}')\n            ns_uri = ns_uri[1:]\n            prefix = self.get_ns_prefix_for_uri(impl_node, ns_uri)\n        elif ':' in name:\n            prefix, name = name.split(':')\n            ns_uri = self.get_ns_uri_for_prefix(impl_node, prefix)\n            if ns_uri is None:\n                raise exceptions.UnknownNamespaceException(\n                    \"Prefix '%s' does not have a defined namespace URI\"\n                    % prefix)\n        else:\n            prefix, ns_uri = None, None\n        return prefix, name, ns_uri", "response": "Returns a three - element tuple with the prefix local name and namespace URI for the given element or attribute name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef up(self, count=1, to_name=None):\n        elem = self._element\n        up_count = 0\n        while True:\n            # Don't go up beyond the document root\n            if elem.is_root or elem.parent is None:\n                break\n            elem = elem.parent\n            if to_name is None:\n                up_count += 1\n                if up_count >= count:\n                    break\n            else:\n                if elem.name == to_name:\n                    break\n        return Builder(elem)", "response": "Return a Builder representing an ancestor of the current element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a child element to the node with the given name.", "response": "def element(self, *args, **kwargs):\n        \"\"\"\n        Add a child element to the :class:`xml4h.nodes.Element` node\n        represented by this Builder.\n\n        :return: a new Builder that represents the child element.\n\n        Delegates to :meth:`xml4h.nodes.Element.add_element`.\n        \"\"\"\n        child_element = self._element.add_element(*args, **kwargs)\n        return Builder(child_element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding one or more attributes to the node represented by this Builder.", "response": "def attributes(self, *args, **kwargs):\n        \"\"\"\n        Add one or more attributes to the :class:`xml4h.nodes.Element` node\n        represented by this Builder.\n\n        :return: the current Builder.\n\n        Delegates to :meth:`xml4h.nodes.Element.set_attributes`.\n        \"\"\"\n        self._element.set_attributes(*args, **kwargs)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef processing_instruction(self, target, data):\n        self._element.add_instruction(target, data)\n        return self", "response": "Adds a processing instruction node to the current node represented by this Builder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the namespace prefix of the node represented by this Builder.", "response": "def ns_prefix(self, prefix, ns_uri):\n        \"\"\"\n        Set the namespace prefix of the :class:`xml4h.nodes.Element` node\n        represented by this Builder.\n\n        :return: the current Builder.\n\n        Delegates to :meth:`xml4h.nodes.Element.set_ns_prefix`.\n        \"\"\"\n        self._element.set_ns_prefix(prefix, ns_uri)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createCertRequest(pkey, digest=\"sha256\"):\n    req = crypto.X509Req()\n\n    req.get_subject().C = \"FR\"\n    req.get_subject().ST = \"IDF\"\n    req.get_subject().L = \"Paris\"\n    req.get_subject().O = \"RedHat\"  # noqa\n    req.get_subject().OU = \"DCI\"\n    req.get_subject().CN = \"DCI-remoteCI\"\n\n    req.set_pubkey(pkey)\n    req.sign(pkey, digest)\n    return req", "response": "Create a certificate request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_existence_and_get(id, table, name=None, get_id=False):\n\n    where_clause = table.c.id == id\n    if name:\n        where_clause = table.c.name == name\n\n    if 'state' in table.columns:\n        where_clause = sql.and_(table.c.state != 'archived', where_clause)\n\n    query = sql.select([table]).where(where_clause)\n    result = flask.g.db_conn.execute(query).fetchone()\n\n    if result is None:\n        raise dci_exc.DCIException('Resource \"%s\" not found.' % id,\n                                   status_code=404)\n    if get_id:\n        return result.id\n    return result", "response": "Verify the existence of a resource in the database and then return it if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the list of topics IDs a user has access to.", "response": "def user_topic_ids(user):\n    \"\"\"Retrieve the list of topics IDs a user has access to.\"\"\"\n\n    if user.is_super_admin() or user.is_read_only_user():\n        query = sql.select([models.TOPICS])\n    else:\n        query = (sql.select([models.JOINS_TOPICS_TEAMS.c.topic_id])\n                 .select_from(\n                     models.JOINS_TOPICS_TEAMS.join(\n                         models.TOPICS, sql.and_(models.JOINS_TOPICS_TEAMS.c.topic_id == models.TOPICS.c.id,  # noqa\n                                                 models.TOPICS.c.state == 'active'))  # noqa\n                  ).where(\n                      sql.or_(models.JOINS_TOPICS_TEAMS.c.team_id.in_(user.teams_ids),  # noqa\n                              models.JOINS_TOPICS_TEAMS.c.team_id.in_(user.child_teams_ids))))  # noqa\n\n    rows = flask.g.db_conn.execute(query).fetchall()\n    return [str(row[0]) for row in rows]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_team_in_topic(user, topic_id):\n    if user.is_super_admin() or user.is_read_only_user():\n        return\n    if str(topic_id) not in user_topic_ids(user):\n        raise dci_exc.Unauthorized()", "response": "Verify that the user s team does belong to the given topic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat the level 1 table.", "response": "def _format_level_1(rows, root_table_name):\n    \"\"\"\n    Transform sqlalchemy source:\n    [{'a_id' : 'id1',\n      'a_name' : 'name1,\n      'b_id' : 'id2',\n      'b_name' : 'name2},\n     {'a_id' : 'id3',\n      'a_name' : 'name3,\n      'b_id' : 'id4',\n      'b_name' : 'name4}\n    ]\n    to\n    [{'id' : 'id1',\n      'name': 'name2',\n      'b' : {'id': 'id2', 'name': 'name2'},\n     {'id' : 'id3',\n      'name': 'name3',\n      'b' : {'id': 'id4', 'name': 'name4'}\n    ]\n    \"\"\"\n    result_rows = []\n    for row in rows:\n        row = dict(row)\n        result_row = {}\n        prefixes_to_remove = []\n        for field in row:\n            if field.startswith('next_topic'):\n                prefix = 'next_topic'\n                suffix = field[11:]\n                if suffix == 'id_1':\n                    suffix = 'id'\n            else:\n                prefix, suffix = field.split('_', 1)\n            if suffix == 'id' and row[field] is None:\n                prefixes_to_remove.append(prefix)\n            if prefix not in result_row:\n                result_row[prefix] = {suffix: row[field]}\n            else:\n                result_row[prefix].update({suffix: row[field]})\n        # remove field with id == null\n        for prefix_to_remove in prefixes_to_remove:\n            result_row.pop(prefix_to_remove)\n        root_table_fields = result_row.pop(root_table_name)\n        result_row.update(root_table_fields)\n        result_rows.append(result_row)\n    return result_rows"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _format_level_2(rows, list_embeds, embed_many):\n\n    def _uniqify_list(list_of_dicts):\n        # list() for py34\n        result = []\n        set_ids = set()\n        for v in list_of_dicts:\n            if v['id'] in set_ids:\n                continue\n            set_ids.add(v['id'])\n            result.append(v)\n        return result\n\n    row_ids_to_embed_values = {}\n    for row in rows:\n        # for each row, associate rows's id -> {all embeds values}\n        if row['id'] not in row_ids_to_embed_values:\n            row_ids_to_embed_values[row['id']] = {}\n        # add embeds values to the current row\n        for embd in list_embeds:\n            if embd not in row:\n                continue\n            if embd not in row_ids_to_embed_values[row['id']]:\n                # create a list or a dict depending on embed_many\n                if embed_many[embd]:\n                    row_ids_to_embed_values[row['id']][embd] = [row[embd]]\n                else:\n                    row_ids_to_embed_values[row['id']][embd] = row[embd]\n            else:\n                if embed_many[embd]:\n                    row_ids_to_embed_values[row['id']][embd].append(row[embd])\n        # uniqify each embed list\n        for embd in list_embeds:\n            if embd in row_ids_to_embed_values[row['id']]:\n                embed_values = row_ids_to_embed_values[row['id']][embd]\n                if isinstance(embed_values, list):\n                    row_ids_to_embed_values[row['id']][embd] = _uniqify_list(embed_values)  # noqa\n            else:\n                row_ids_to_embed_values[row['id']][embd] = {}\n                if embed_many[embd]:\n                    row_ids_to_embed_values[row['id']][embd] = []\n\n    # last loop over the initial rows in order to keep the ordering\n    result = []\n    # if row id in seen set then it means the row has been completely processed\n    seen = set()\n    for row in rows:\n        if row['id'] in seen:\n            continue\n        seen.add(row['id'])\n        new_row = {}\n        # adds level 1 fields\n        for field in row:\n            if field not in list_embeds:\n                new_row[field] = row[field]\n        # adds all level 2 fields\n        # list() for py34\n        row_ids_to_embed_values_keys = list(row_ids_to_embed_values[new_row['id']].keys())  # noqa\n        row_ids_to_embed_values_keys.sort()\n        # adds the nested fields if there is somes\n        for embd in list_embeds:\n            if embd in row_ids_to_embed_values_keys:\n                if '.' in embd:\n                    prefix, suffix = embd.split('.', 1)\n                    new_row[prefix][suffix] = row_ids_to_embed_values[new_row['id']][embd]  # noqa\n                else:\n                    new_row[embd] = row_ids_to_embed_values[new_row['id']][embd]  # noqa\n            else:\n                new_row_embd_value = {}\n                if embed_many[embd]:\n                    new_row_embd_value = []\n                if '.' in embd:\n                    prefix, suffix = embd.split('.', 1)\n                    new_row[prefix][suffix] = new_row_embd_value\n                else:\n                    new_row[embd] = new_row_embd_value\n        # row is complete !\n        result.append(new_row)\n    return result", "response": "This function is used to format the level 2 of the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef common_values_dict():\n    now = datetime.datetime.utcnow().isoformat()\n    etag = utils.gen_etag()\n    values = {\n        'id': utils.gen_uuid(),\n        'created_at': now,\n        'updated_at': now,\n        'etag': etag\n    }\n\n    return values", "response": "Build a basic values object used in every create method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the query and return the result.", "response": "def execute(self, fetchall=False, fetchone=False, use_labels=True):\n        \"\"\"\n        :param fetchall: get all rows\n        :param fetchone:  get only one row\n        :param use_labels: prefix row columns names by the table name\n        :return:\n        \"\"\"\n        query = self.get_query(use_labels=use_labels)\n        if fetchall:\n            return flask.g.db_conn.execute(query).fetchall()\n        elif fetchone:\n            return flask.g.db_conn.execute(query).fetchone()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns some information about the currently authenticated identity", "response": "def get_identity(identity):\n    \"\"\"Returns some information about the currently authenticated identity\"\"\"\n    return flask.Response(\n        json.dumps(\n            {\n                'identity': {\n                    'id': identity.id,\n                    'etag': identity.etag,\n                    'name': identity.name,\n                    'fullname': identity.fullname,\n                    'email': identity.email,\n                    'timezone': identity.timezone,\n                    'teams': _encode_dict(identity.teams)\n                }\n            }\n        ), 200,\n        headers={'ETag': identity.etag},\n        content_type='application/json'\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_issues_by_resource(resource_id, table):\n\n    v1_utils.verify_existence_and_get(resource_id, table)\n\n    # When retrieving the issues for a job, we actually retrieve\n    # the issues attach to the job itself + the issues attached to\n    # the components the job has been run with.\n    if table.name == 'jobs':\n        JJI = models.JOIN_JOBS_ISSUES\n        JJC = models.JOIN_JOBS_COMPONENTS\n        JCI = models.JOIN_COMPONENTS_ISSUES\n\n        # Get all the issues attach to all the components attach to a job\n        j1 = sql.join(\n            _TABLE,\n            sql.join(\n                JCI,\n                JJC,\n                sql.and_(\n                    JCI.c.component_id == JJC.c.component_id,\n                    JJC.c.job_id == resource_id,\n                ),\n            ),\n            _TABLE.c.id == JCI.c.issue_id,\n        )\n\n        query = sql.select([_TABLE]).select_from(j1)\n        rows = flask.g.db_conn.execute(query)\n        rows = [dict(row) for row in rows]\n\n        # Get all the issues attach to a job\n        j2 = sql.join(\n            _TABLE,\n            JJI,\n            sql.and_(\n                _TABLE.c.id == JJI.c.issue_id,\n                JJI.c.job_id == resource_id\n            )\n        )\n        query2 = sql.select([_TABLE]).select_from(j2)\n        rows2 = flask.g.db_conn.execute(query2)\n        rows += [dict(row) for row in rows2]\n\n    # When retrieving the issues for a component, we only retrieve the\n    # issues attached to the specified component.\n    else:\n        JCI = models.JOIN_COMPONENTS_ISSUES\n\n        query = (sql.select([_TABLE])\n                 .select_from(JCI.join(_TABLE))\n                 .where(JCI.c.component_id == resource_id))\n\n        rows = flask.g.db_conn.execute(query)\n        rows = [dict(row) for row in rows]\n\n    for row in rows:\n        if row['tracker'] == 'github':\n            l_tracker = github.Github(row['url'])\n        elif row['tracker'] == 'bugzilla':\n            l_tracker = bugzilla.Bugzilla(row['url'])\n        row.update(l_tracker.dump())\n\n    return flask.jsonify({'issues': rows,\n                          '_meta': {'count': len(rows)}})", "response": "Get all the issues attached to a specific job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unattach_issue(resource_id, issue_id, table):\n\n    v1_utils.verify_existence_and_get(issue_id, _TABLE)\n    if table.name == 'jobs':\n        join_table = models.JOIN_JOBS_ISSUES\n        where_clause = sql.and_(join_table.c.job_id == resource_id,\n                                join_table.c.issue_id == issue_id)\n    else:\n        join_table = models.JOIN_COMPONENTS_ISSUES\n        where_clause = sql.and_(join_table.c.component_id == resource_id,\n                                join_table.c.issue_id == issue_id)\n\n    query = join_table.delete().where(where_clause)\n    result = flask.g.db_conn.execute(query)\n\n    if not result.rowcount:\n        raise dci_exc.DCIConflict('%s_issues' % table.name, issue_id)\n\n    return flask.Response(None, 204, content_type='application/json')", "response": "Unattach an issue from a specific job."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattaching an issue to a specific job.", "response": "def attach_issue(resource_id, table, user_id):\n    \"\"\"Attach an issue to a specific job.\"\"\"\n    data = schemas.issue.post(flask.request.json)\n    issue = _get_or_create_issue(data)\n\n    # Second, insert a join record in the JOIN_JOBS_ISSUES or\n    # JOIN_COMPONENTS_ISSUES database.\n    if table.name == 'jobs':\n        join_table = models.JOIN_JOBS_ISSUES\n    else:\n        join_table = models.JOIN_COMPONENTS_ISSUES\n\n    key = '%s_id' % table.name[0:-1]\n    query = join_table.insert().values({\n        'user_id': user_id,\n        'issue_id': issue['id'],\n        key: resource_id\n    })\n\n    try:\n        flask.g.db_conn.execute(query)\n    except sa_exc.IntegrityError:\n        raise dci_exc.DCICreationConflict(join_table.name,\n                                          '%s, issue_id' % key)\n\n    result = json.dumps({'issue': dict(issue)})\n    return flask.Response(result, 201, content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collect_staticroot_removal(app, blueprints):\n    collect_root = app.extensions['collect'].static_root\n    return [bp for bp in blueprints if (\n        bp.has_static_folder and bp.static_folder != collect_root)]", "response": "Remove collect s static root folder from list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_client(access_token):\n    url = 'http://keycloak:8080/auth/admin/realms/dci-test/clients'\n    r = requests.post(url,\n                      data=json.dumps(client_data),\n                      headers=get_auth_headers(access_token))\n    if r.status_code in (201, 409):\n        print('Keycloak client dci created successfully.')\n    else:\n        raise Exception(\n            'Error while creating Keycloak client dci:\\nstatus code %s\\n'\n            'error: %s' % (r.status_code, r.content)\n        )", "response": "Create the dci client in the master realm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_user_dci(access_token):\n    user_data = {'username': 'dci',\n                 'email': 'dci@distributed-ci.io',\n                 'enabled': True,\n                 'emailVerified': True,\n                 'credentials': [{'type': 'password',\n                                  'value': 'dci'}]}\n    r = requests.post('http://keycloak:8080/auth/admin/realms/dci-test/users',\n                      data=json.dumps(user_data),\n                      headers=get_auth_headers(access_token))\n    if r.status_code in (201, 409):\n        print('Keycloak user dci created successfully.')\n    else:\n        raise Exception('Error while creating user dci:\\nstatus code %s\\n'\n                        'error: %s' % (r.status_code, r.content))", "response": "Create a dci user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the object with the given parameters.", "response": "def initialize(self, name=None, dbname=None, base=None, generator=None,\n                   case=None, namespaces=None):\n\n        self.name = none_or(name, str)\n        \"\"\"\n        The name of the site. : str | `None`\n        \"\"\"\n\n        self.dbname = none_or(dbname, str)\n        \"\"\"\n        The dbname of the site. : str | `None`\n        \"\"\"\n\n        self.base = none_or(base, str)\n        \"\"\"\n        TODO: ??? : str | `None`\n        \"\"\"\n\n        self.generator = none_or(generator, str)\n        \"\"\"\n        TODO: ??? : str | `None`\n        \"\"\"\n\n        self.case = none_or(case, str)\n        \"\"\"\n        TODO: ??? : str | `None`\n        \"\"\"\n\n        self.namespaces = none_or(namespaces, list)\n        \"\"\"\n        A list of :class:`mwtypes.Namespace` | `None`\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _serializeBooleans(params):\n        serialized = {}\n        for name, value in params.items():\n            if value is True:\n                value = 'true'\n            elif value is False:\n                value = 'false'\n            serialized[name] = value\n        return serialized\n\n        for k, v in params.items():\n            if isinstance(v, bool):\n                params[k] = str(v).lower()", "response": "Convert all booleans to lowercase strings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps function for requests.", "response": "def request(self, method, url, parameters=dict()):\n        \"\"\"Requests wrapper function\"\"\"\n\n        # The requests library uses urllib, which serializes to \"True\"/\"False\" while Pingdom requires lowercase\n        parameters = self._serializeBooleans(parameters)\n\n        headers = {'App-Key': self.apikey}\n        if self.accountemail:\n            headers.update({'Account-Email': self.accountemail})\n\n        # Method selection handling\n        if method.upper() == 'GET':\n            response = requests.get(self.url + url, params=parameters,\n                                    auth=(self.username, self.password),\n                                    headers=headers)\n        elif method.upper() == 'POST':\n            response = requests.post(self.url + url, data=parameters,\n                                     auth=(self.username, self.password),\n                                     headers=headers)\n        elif method.upper() == 'PUT':\n            response = requests.put(self.url + url, data=parameters,\n                                    auth=(self.username, self.password),\n                                    headers=headers)\n        elif method.upper() == 'DELETE':\n            response = requests.delete(self.url + url, params=parameters,\n                                       auth=(self.username, self.password),\n                                       headers=headers)\n        else:\n            raise Exception(\"Invalid method in pingdom request\")\n\n        # Store pingdom api limits\n        self.shortlimit = response.headers.get(\n            'Req-Limit-Short',\n            self.shortlimit)\n        self.longlimit = response.headers.get(\n            'Req-Limit-Long',\n            self.longlimit)\n\n        # Verify OK response\n        if response.status_code != 200:\n            sys.stderr.write('ERROR from %s: %d' % (response.url,\n                                                    response.status_code))\n            sys.stderr.write('Returned data: %s\\n' % response.json())\n            response.raise_for_status()\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef actions(self, **parameters):\n\n        # Warn user about unhandled parameters\n        for key in parameters:\n            if key not in ['from', 'to', 'limit', 'offset', 'checkids',\n                           'contactids', 'status', 'via']:\n                sys.stderr.write('%s not a valid argument for actions()\\n'\n                                 % key)\n\n        response = self.request('GET', 'actions', parameters)\n\n        return response.json()['actions']", "response": "Returns a list of actions that have been generated for the current date and time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getChecks(self, **parameters):\n\n        # Warn user about unhandled parameters\n        for key in parameters:\n            if key not in ['limit', 'offset', 'tags']:\n                sys.stderr.write('%s not a valid argument for getChecks()\\n'\n                                 % key)\n\n        response = self.request('GET', 'checks', parameters)\n\n        return [PingdomCheck(self, x) for x in response.json()['checks']]", "response": "Pulls all checks from the pingdom daemon."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a detailed description of a specified check.", "response": "def getCheck(self, checkid):\n        \"\"\"Returns a detailed description of a specified check.\"\"\"\n\n        check = PingdomCheck(self, {'id': checkid})\n        check.getDetails()\n        return check"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of Pingdom probe servers that are in use.", "response": "def probes(self, **kwargs):\n        \"\"\"Returns a list of all Pingdom probe servers\n\n        Parameters:\n\n            * limit -- Limits the number of returned probes to the specified\n                quantity\n                    Type: Integer\n\n            * offset -- Offset for listing (requires limit).\n                    Type: Integer\n                    Default: 0\n\n            * onlyactive -- Return only active probes\n                    Type: Boolean\n                    Default: False\n\n            * includedeleted -- Include old probes that are no longer in use\n                    Type: Boolean\n                    Default: False\n\n        Returned structure:\n        [\n            {\n                'id'        : <Integer> Unique probe id\n                'country'   : <String> Country\n                'city'      : <String> City\n                'name'      : <String> Name\n                'active'    : <Boolean> True if probe is active\n                'hostname'  : <String> DNS name\n                'ip'        : <String> IP address\n                'countryiso': <String> Country ISO code\n            },\n            ...\n        ]\n        \"\"\"\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['limit', 'offset', 'onlyactive', 'includedeleted']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument ' +\n                                 'of probes()\\n')\n\n        return self.request(\"GET\", \"probes\", kwargs).json()['probes']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef traceroute(self, host, probeid):\n\n        response = self.request('GET', 'traceroute', {'host': host,\n                                                      'probeid': probeid})\n        return response.json()['traceroute']", "response": "Perform a traceroute to a specified target from a specified Pingdom\n            probe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all contacts.", "response": "def getContacts(self, **kwargs):\n        \"\"\"Returns a list of all contacts.\n\n        Optional Parameters:\n\n            * limit -- Limits the number of returned contacts to the specified\n                quantity.\n                    Type: Integer\n                    Default: 100\n\n            * offset -- Offset for listing (requires limit.)\n                    Type: Integer\n                    Default: 0\n\n        Returned structure:\n        [\n            'id'                 : <Integer> Contact identifier\n            'name'               : <String> Contact name\n            'email'              : <String> Contact email\n            'cellphone'          : <String> Contact telephone\n            'countryiso'         : <String> Cellphone country ISO code\n            'defaultsmsprovider' : <String> Default SMS provider\n            'directtwitter'      : <Boolean> Send Tweets as direct messages\n            'twitteruser'        : <String> Twitter username\n            'paused'             : <Boolean> True if contact is pasued\n            'iphonetokens'       : <String list> iPhone tokens\n            'androidtokens'      : <String list> android tokens\n        ]\n        \"\"\"\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['limit', 'offset']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument ' +\n                                 'of getContacts()\\n')\n\n        return [PingdomContact(self, x) for x in\n                self.request(\"GET\", \"notification_contacts\", kwargs).json()['contacts']]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef newContact(self, name, **kwargs):\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['email', 'cellphone', 'countrycode', 'countryiso',\n                           'defaultsmsprovider', 'directtwitter',\n                           'twitteruser']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument ' +\n                                 'of newContact()\\n')\n\n        kwargs['name'] = name\n        contactinfo = self.request(\"POST\", \"notification_contacts\",\n                                   kwargs).json()['contact']\n\n        return PingdomContact(self, contactinfo)", "response": "Create a new contact."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodify a list of contacts.", "response": "def modifyContacts(self, contactids, paused):\n        \"\"\"Modifies a list of contacts.\n\n        Provide comma separated list of contact ids and desired paused state\n\n        Returns status message\n        \"\"\"\n\n        response = self.request(\"PUT\", \"notification_contacts\", {'contactids': contactids,\n                                                    'paused': paused})\n        return response.json()['message']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of PingdomEmailReport instances.", "response": "def getEmailReports(self):\n        \"\"\"Returns a list of PingdomEmailReport instances.\"\"\"\n\n        reports = [PingdomEmailReport(self, x) for x in\n                   self.request('GET',\n                                'reports.email').json()['subscriptions']]\n\n        return reports"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef newEmailReport(self, name, **kwargs):\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['checkid', 'frequency', 'contactids',\n                           'additionalemails']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument ' +\n                                 'of newEmailReport()\\n')\n\n        parameters = {'name': name}\n        for key, value in kwargs.iteritems():\n            parameters[key] = value\n\n        return self.request('POST', 'reports.email',\n                            parameters).json()['message']", "response": "Creates a new email report for the specified checkid frequency contactids and additionalemails."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of PingdomSharedReport instances", "response": "def getSharedReports(self):\n        \"\"\"Returns a list of PingdomSharedReport instances\"\"\"\n\n        response = self.request('GET',\n                                'reports.shared').json()['shared']['banners']\n\n        reports = [PingdomSharedReport(self, x) for x in response]\n        return reports"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new shared report.", "response": "def newSharedReport(self, checkid, **kwargs):\n        \"\"\"Create a shared report (banner).\n\n        Returns status message for operation\n\n        Optional parameters:\n\n            * auto -- Automatic period (If false, requires: fromyear,\n                frommonth, fromday, toyear, tomonth, today)\n                    Type: Boolean\n\n            * type -- Banner type\n                    Type: String ['uptime', 'response']\n\n            * fromyear -- Period start: year\n                    Type: Integer\n\n            * frommonth -- Period start: month\n                    Type: Integer\n\n            * fromday -- Period start: day\n                    Type: Integer\n\n            * toyear -- Period end: year\n                    Type: Integer\n\n            * tomonth -- Period end: month\n                    Type: Integer\n\n            * today -- Period end: day\n                    Type: Integer\n        \"\"\"\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['auto', 'type', 'fromyear', 'frommonth', 'fromday',\n                           'toyear', 'tomonth', 'today', 'sharedtype']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument ' +\n                                 'of newSharedReport()\\n')\n\n        parameters = {'checkid': checkid, 'sharedtype': 'banner'}\n        for key, value in kwargs.iteritems():\n            parameters[key] = value\n\n        return self.request('POST', 'reports.shared',\n                            parameters).json()['message']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encry_decry_cascade(data, masterkey, bool_encry, assoc_data):\n    engine1 = botan.cipher(algo=\"Serpent/GCM\", encrypt=bool_encry)\n    engine2 = botan.cipher(algo=\"AES-256/GCM\", encrypt=bool_encry)\n    engine3 = botan.cipher(algo=\"Twofish/GCM\", encrypt=bool_encry)\n\n    hash1 = botan.hash_function(algo=\"SHA-256\")\n    hash1.update(masterkey)\n    hashed1 = hash1.final()\n\n    hash2 = botan.hash_function(algo=\"SHA-256\")\n    hash2.update(hashed1)\n    hashed2 = hash2.final()\n\n    engine1.set_key(key=masterkey)\n    engine1.set_assoc_data(assoc_data)\n\n    engine2.set_key(key=hashed1)\n    engine2.set_assoc_data(assoc_data)\n\n    engine3.set_key(key=hashed2)\n    engine3.set_assoc_data(assoc_data)\n\n    if bool_encry is True:\n        nonce1 = generate_nonce_timestamp()\n        nonce2 = generate_nonce_timestamp()\n        nonce3 = generate_nonce_timestamp()\n\n        engine1.start(nonce=nonce1)\n        engine2.start(nonce=nonce2)\n        engine3.start(nonce=nonce3)\n\n        cipher1 = engine1.finish(data)\n        cipher2 = engine2.finish(cipher1)\n        cipher3 = engine3.finish(cipher2)\n        return nonce1 + nonce2 + nonce3 + cipher3\n    else:\n        nonce1 = data[:__nonce_length__]\n        nonce2 = data[__nonce_length__:__nonce_length__ * 2]\n        nonce3 = data[__nonce_length__ * 2:__nonce_length__ * 3]\n\n        encrypteddata = data[__nonce_length__ * 3:]\n\n        engine1.start(nonce=nonce1)\n        engine2.start(nonce=nonce2)\n        engine3.start(nonce=nonce3)\n\n        decrypteddata1 = engine3.finish(encrypteddata)\n        if decrypteddata1 == b\"\":\n            raise Exception(\"Integrity failure: Invalid passphrase or corrupted data\")\n        decrypteddata2 = engine2.finish(decrypteddata1)\n        if decrypteddata2 == b\"\":\n            raise Exception(\"Integrity failure: Invalid passphrase or corrupted data\")\n        decrypteddata3 = engine1.finish(decrypteddata2)\n        if decrypteddata3 == b\"\":\n            raise Exception(\"Integrity failure: Invalid passphrase or corrupted data\")\n        else:\n            return decrypteddata3", "response": "This function encryes the data with the master key and decrypts it with the master key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters the handler for the command or event.", "response": "def register(self, request_class: Request, handler_factory: Callable[[], Handler]) -> None:\n        \"\"\"\n        Register the handler for the command\n        :param request_class: The command or event to dispatch. It must implement getKey()\n        :param handler_factory: A factory method to create the handler to dispatch to\n        :return:\n        \"\"\"\n        key = request_class.__name__\n        is_command = request_class.is_command()\n        is_event = request_class.is_event()\n        is_present = key in self._registry\n        if is_command and is_present:\n            raise ConfigurationException(\"A handler for this request has already been registered\")\n        elif is_event and is_present:\n            self._registry[key].append(handler_factory)\n        elif is_command or is_event:\n            self._registry[key] = [handler_factory]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lookup(self, request: Request) -> List[Callable[[], Handler]]:\n        key = request.__class__.__name__\n        if key not in self._registry:\n            if request.is_command():\n                raise ConfigurationException(\"There is no handler registered for this request\")\n            elif request.is_event():\n                return []  # type: Callable[[] Handler]\n\n        return self._registry[key]", "response": "Look up the handler associated with a request - matches the key on the request to a registered handler\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, request_class: Request, mapper_func: Callable[[Request], BrightsideMessage]) -> None:\n\n        key = request_class.__name__\n        if key not in self._registry:\n            self._registry[key] = mapper_func\n        else:\n            raise ConfigurationException(\"There is already a message mapper defined for this key; there can be only one\")", "response": "Adds a message mapper function to a factory using the requests key\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlooking up the message mapper function associated with this class.", "response": "def lookup(self, request_class: Request) -> Callable[[Request], BrightsideMessage]:\n        \"\"\"\n        Looks up the message mapper function associated with this class. Function should take in a Request derived class\n         and return a BrightsideMessage derived class, for sending on the wire\n        :param request_class:\n        :return:\n        \"\"\"\n        key = request_class.__class__.__name__\n        if key not in self._registry:\n            raise ConfigurationException(\"There is no message mapper associated with this key; we require a mapper\")\n        else:\n            return self._registry[key]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef instance_of(*args):\n    if len(args) == 2:\n        # Standard mode\n        value, ref_type = args\n        if not isinstance(ref_type, set):\n            # ref_type is a single type\n            if isinstance(value, ref_type):\n                return True\n            else:\n                raise HasWrongType(wrong_value=value, ref_type=ref_type)\n\n        else:\n            # ref_type is a set\n            match = False\n            # test against each of the provided types\n            for ref in ref_type:\n                if isinstance(value, ref):\n                    match = True\n                    break\n            if match:\n                return True\n            else:\n                raise HasWrongType(wrong_value=value, ref_type=ref_type,\n                                   help_msg='Value should be an instance of any of {ref_type}')\n\n    elif len(args) == 1:\n        # Function generator mode\n        ref_type = args[0]\n        if not isinstance(ref_type, set):\n            # ref_type is a single type\n            def instance_of_ref(x):\n                if isinstance(x, ref_type):\n                    return True\n                else:\n                    raise HasWrongType(wrong_value=x, ref_type=ref_type)\n        else:\n            # ref_type is a set\n            def instance_of_ref(x):\n                match = False\n                # test against each of the provided types\n                for ref in ref_type:\n                    if isinstance(x, ref):\n                        match = True\n                        break\n                if match:\n                    return True\n                else:\n                    raise HasWrongType(wrong_value=x, ref_type=ref_type,\n                                       help_msg='Value should be an instance of any of {ref_type}')\n\n        instance_of_ref.__name__ = 'instance_of_{}'.format(ref_type)\n        return instance_of_ref\n    else:\n        raise TypeError('instance_of expected 2 (normal) or 1 (function generator) arguments, got ' + str(len(args)))", "response": "This function returns a validation function that checks if a single element of the input array is an instance of the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subclass_of(*args):\n    if len(args) == 2:\n        # Standard mode\n        typ, ref_type = args\n        if not isinstance(ref_type, set):\n            # ref_type is a single type\n            if issubclass(typ, ref_type):\n                return True\n            else:\n                raise IsWrongType(wrong_value=typ, ref_type=ref_type)\n        else:\n            # ref_type is a set\n            match = False\n            # test against each of the provided types\n            for ref in ref_type:\n                if issubclass(typ, ref):\n                    match = True\n                    break\n            if match:\n                return True\n            else:\n                raise IsWrongType(wrong_value=typ, ref_type=ref_type,\n                                  help_msg='Value should be a subclass of any of {ref_type}')\n\n    elif len(args) == 1:\n        # Function generator mode\n        ref_type = args[0]\n        if not isinstance(ref_type, set):\n            def subclass_of_ref(x):\n                if issubclass(x, ref_type):\n                    return True\n                else:\n                    raise IsWrongType(wrong_value=x, ref_type=ref_type)\n        else:\n            # ref_type is a set\n            def subclass_of_ref(x):\n                match = False\n                # test against each of the provided types\n                for ref in ref_type:\n                    if issubclass(x, ref):\n                        match = True\n                        break\n                if match:\n                    return True\n                else:\n                    raise IsWrongType(wrong_value=x, ref_type=ref_type,\n                                      help_msg='Value should be a subclass of any of {ref_type}')\n\n        subclass_of_ref.__name__ = 'subclass_of_{}'.format(ref_type)\n        return subclass_of_ref\n    else:\n        raise TypeError('subclass_of expected 2 (normal) or 1 (function generator) arguments, got ' + str(len(args)))", "response": "This function returns a validation function that checks if a class is a subclass of another class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction decorator for caching pickleable return values on disk. Uses a hash computed from the function arguments for invalidation. If 'method', skip the first argument, usually being self or cls. The cache filepath is 'directory/basename-hash.pickle'.", "response": "def disk_cache(basename, directory, method=False):\n    \"\"\"\n    Function decorator for caching pickleable return values on disk. Uses a\n    hash computed from the function arguments for invalidation. If 'method',\n    skip the first argument, usually being self or cls. The cache filepath is\n    'directory/basename-hash.pickle'.\n    \"\"\"\n    directory = os.path.expanduser(directory)\n    ensure_directory(directory)\n\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = (tuple(args), tuple(kwargs.items()))\n            # Don't use self or cls for the invalidation hash.\n            if method and key:\n                key = key[1:]\n            filename = '{}-{}.pickle'.format(basename, hash(key))\n            filepath = os.path.join(directory, filename)\n            if os.path.isfile(filepath):\n                with open(filepath, 'rb') as handle:\n                    return pickle.load(handle)\n            result = func(*args, **kwargs)\n            with open(filepath, 'wb') as handle:\n                pickle.dump(result, handle)\n            return result\n        return wrapped\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(url, directory, filename=None):\n    if not filename:\n        _, filename = os.path.split(url)\n    directory = os.path.expanduser(directory)\n    ensure_directory(directory)\n    filepath = os.path.join(directory, filename)\n    if os.path.isfile(filepath):\n        return filepath\n    print('Download', filepath)\n    with urlopen(url) as response, open(filepath, 'wb') as file_:\n        shutil.copyfileobj(response, file_)\n    return filepath", "response": "Download a file and return its filename on the local file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensure_directory(directory):\n    directory = os.path.expanduser(directory)\n    try:\n        os.makedirs(directory)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise e", "response": "Create the directories along the provided directory path that do not exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef and_(*validation_func  # type: ValidationFuncs\n         ):\n    # type: (...) -> Callable\n    \"\"\"\n    An 'and' validator: it returns `True` if all of the provided validators return `True`, or raises a\n    `AtLeastOneFailed` failure on the first `False` received or `Exception` caught.\n\n    Note that an implicit `and_` is performed if you provide a list of validators to any of the entry points\n    (`validate`, `validation`/`validator`, `@validate_arg`, `@validate_out`, `@validate_field` ...)\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n    tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :return:\n    \"\"\"\n\n    validation_func = _process_validation_function_s(list(validation_func), auto_and_wrapper=False)\n\n    if len(validation_func) == 1:\n        return validation_func[0]  # simplification for single validator case: no wrapper\n    else:\n        def and_v_(x):\n            for validator in validation_func:\n                try:\n                    res = validator(x)\n                except Exception as e:\n                    # one validator was unhappy > raise\n                    raise AtLeastOneFailed(validation_func, x, cause=e)\n                if not result_is_success(res):\n                    # one validator was unhappy > raise\n                    raise AtLeastOneFailed(validation_func, x)\n\n            return True\n\n        and_v_.__name__ = 'and({})'.format(get_callable_names(validation_func))\n        return and_v_", "response": "A function that returns True if all of the provided validators return True or raises AtLeastOneFailed failure on the first False received or an exception caught."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef not_(validation_func,  # type: ValidationFuncs\n         catch_all=False   # type: bool\n         ):\n    # type: (...) -> Callable\n    \"\"\"\n    Generates the inverse of the provided validation functions: when the validator returns `False` or raises a\n    `Failure`, this function returns `True`. Otherwise it raises a `DidNotFail` failure.\n\n    By default, exceptions of types other than `Failure` are not caught and therefore fail the validation\n    (`catch_all=False`). To change this behaviour you can turn the `catch_all` parameter to `True`, in which case all\n    exceptions will be caught instead of just `Failure`s.\n\n    Note that you may use `not_all(<validation_functions_list>)` as a shortcut for\n    `not_(and_(<validation_functions_list>))`\n\n    :param validation_func: the base validation function. A callable, a tuple(callable, help_msg_str),\n    a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :param catch_all: an optional boolean flag. By default, only Failure are silently caught and turned into\n    a 'ok' result. Turning this flag to True will assume that all exceptions should be caught and turned to a\n    'ok' result\n    :return:\n    \"\"\"\n\n    def not_v_(x):\n        try:\n            res = validation_func(x)\n            if not result_is_success(res):  # inverse the result\n                return True\n\n        except Failure:\n            return True  # caught failure: always return True\n\n        except Exception as e:\n            if not catch_all:\n                raise e\n            else:\n                return True  # caught exception in 'catch_all' mode: return True\n\n        # if we're here that's a failure\n        raise DidNotFail(wrapped_func=validation_func, wrong_value=x, validation_outcome=res)\n\n    not_v_.__name__ = 'not({})'.format(get_callable_name(validation_func))\n    return not_v_", "response": "Generates a validation function that does not pass any value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a function that returns True if at least one of the provided validators returns True.", "response": "def or_(*validation_func  # type: ValidationFuncs\n        ):\n    # type: (...) -> Callable\n    \"\"\"\n    An 'or' validator: returns `True` if at least one of the provided validators returns `True`. All exceptions will be\n    silently caught. In case of failure, a global `AllValidatorsFailed` failure will be raised, together with details\n    about all validation results.\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n    tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :return:\n    \"\"\"\n\n    validation_func = _process_validation_function_s(list(validation_func), auto_and_wrapper=False)\n\n    if len(validation_func) == 1:\n        return validation_func[0]  # simplification for single validator case\n    else:\n        def or_v_(x):\n            for validator in validation_func:\n                # noinspection PyBroadException\n                try:\n                    res = validator(x)\n                    if result_is_success(res):\n                        # we can return : one validator was happy\n                        return True\n                except Exception:\n                    # catch all silently\n                    pass\n\n            # no validator accepted: gather details and raise\n            raise AllValidatorsFailed(validation_func, x)\n\n        or_v_.__name__ = 'or({})'.format(get_callable_names(validation_func))\n        return or_v_"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xor_(*validation_func  # type: ValidationFuncs\n         ):\n    # type: (...) -> Callable\n    \"\"\"\n    A 'xor' validation function: returns `True` if exactly one of the provided validators returns `True`. All exceptions\n    will be silently caught. In case of failure, a global `XorTooManySuccess` or `AllValidatorsFailed` will be raised,\n    together with details about the various validation results.\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n    tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :return:\n    \"\"\"\n\n    validation_func = _process_validation_function_s(list(validation_func), auto_and_wrapper=False)\n\n    if len(validation_func) == 1:\n        return validation_func[0]  # simplification for single validation function case\n    else:\n        def xor_v_(x):\n            ok_validators = []\n            for val_func in validation_func:\n                # noinspection PyBroadException\n                try:\n                    res = val_func(x)\n                    if result_is_success(res):\n                        ok_validators.append(val_func)\n                except Exception:\n                    pass\n\n            # return if were happy or not\n            if len(ok_validators) == 1:\n                # one unique validation function happy: success\n                return True\n\n            elif len(ok_validators) > 1:\n                # several validation_func happy : fail\n                raise XorTooManySuccess(validation_func, x)\n\n            else:\n                # no validation function happy, fail\n                raise AllValidatorsFailed(validation_func, x)\n\n        xor_v_.__name__ = 'xor({})'.format(get_callable_names(validation_func))\n        return xor_v_", "response": "A function to be applied to a base validation function that returns True if exactly one of the provided validators returns True."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef not_all(*validation_func,  # type: ValidationFuncs\n            **kwargs\n            ):\n    # type: (...) -> Callable\n    \"\"\"\n    An alias for not_(and_(validators)).\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n        tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n        are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n        `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n        of callables, they will be transformed to functions automatically.\n    :param catch_all: an optional boolean flag. By default, only Failure are silently caught and turned into\n        a 'ok' result. Turning this flag to True will assume that all exceptions should be caught and turned to a\n        'ok' result\n    :return:\n    \"\"\"\n    catch_all = pop_kwargs(kwargs, [('catch_all', False)])\n\n    # in case this is a list, create a 'and_' around it (otherwise and_ will return the validation function without\n    # wrapping it)\n    main_validator = and_(*validation_func)\n    return not_(main_validator, catch_all=catch_all)", "response": "Returns a new base validation function that does not validate the given base validation function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_secret(length=64):\n    charset = string.ascii_letters + string.digits\n    return ''.join(random.SystemRandom().choice(charset)\n                   for _ in range(length))", "response": "Generates a secret of given length"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encryptfile(filename, passphrase, algo='srp'):\n    try:\n        if algo == \"srp\":\n            header = b\"Cryptoshop srp \" + b_version\n            crypto_algo = \"Serpent/GCM\"\n        if algo == \"aes\":\n            header = b\"Cryptoshop aes \" + b_version\n            crypto_algo = \"AES-256/GCM\"\n        if algo == \"twf\":\n            header = b\"Cryptoshop twf \" + b_version\n            crypto_algo = \"Twofish/GCM\"\n        if algo != \"srp\" and algo != \"aes\" and algo != \"twf\":\n            return \"No valid algo. Use 'srp' 'aes' or 'twf'\"\n        outname = filename + \".cryptoshop\"\n\n        internal_key = botan.rng().get(internal_key_length)\n\n        # Passphrase derivation...\n        salt = botan.rng().get(__salt_size__)\n        masterkey = calc_derivation(passphrase=passphrase, salt=salt)\n\n        # Encrypt internal key...\n        encrypted_key = encry_decry_cascade(data=internal_key, masterkey=masterkey,\n                                            bool_encry=True,\n                                            assoc_data=header)\n        with open(filename, 'rb') as filestream:\n            file_size = os.stat(filename).st_size\n            if file_size == 0:\n                raise Exception(\"Error: You can't encrypt empty file.\")\n            with open(str(outname), 'wb') as filestreamout:\n                filestreamout.write(header)\n                filestreamout.write(salt)\n                filestreamout.write(encrypted_key)\n\n                finished = False\n                # the maximum of the progress bar is the total chunk to process. It's files_size // chunk_size\n                bar = tqdm(range(file_size // __chunk_size__))\n                while not finished:\n                    chunk = filestream.read(__chunk_size__)\n                    if len(chunk) == 0 or len(chunk) % __chunk_size__ != 0:\n                        finished = True\n                    # An encrypted-chunk output is nonce, gcmtag, and cipher-chunk concatenation.\n                    encryptedchunk = encry_decry_chunk(chunk=chunk, key=internal_key, bool_encry=True,\n                                                       algo=crypto_algo, assoc_data=header)\n                    filestreamout.write(encryptedchunk)\n                    bar.update(1)\n\n            return \"successfully encrypted\"\n\n    except IOError:\n        exit(\"Error: file \\\"\" + filename + \"\\\" was not found.\")", "response": "Encrypt a file and write it with. cryptoshop extension."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decryptfile(filename, passphrase):\n    try:\n        outname = os.path.splitext(filename)[0].split(\"_\")[-1]  # create a string file name without extension.\n        with open(filename, 'rb') as filestream:\n            file_size = os.stat(filename).st_size\n            if file_size == 0:\n                raise Exception(\"Error: You can't decrypt empty file.\")\n\n            fileheader = filestream.read(header_length)\n\n            if fileheader == b\"Cryptoshop srp \" + b_version:\n                decrypt_algo = \"Serpent/GCM\"\n            if fileheader == b\"Cryptoshop aes \" + b_version:\n                decrypt_algo = \"AES-256/GCM\"\n            if fileheader == b\"Cryptoshop twf \" + b_version:\n                decrypt_algo = \"Twofish/GCM\"\n            if fileheader != b\"Cryptoshop srp \" + b_version and fileheader != b\"Cryptoshop aes \" + b_version and fileheader != b\"Cryptoshop twf \" + b_version:\n                raise Exception(\"Integrity failure: Bad header\")\n\n            salt = filestream.read(__salt_size__)\n            encrypted_key = filestream.read(encrypted_key_length)\n\n            # Derive the passphrase...\n            masterkey = calc_derivation(passphrase=passphrase, salt=salt)\n\n            # Decrypt internal key...\n            try:\n                internal_key = encry_decry_cascade(data=encrypted_key, masterkey=masterkey,\n                                                   bool_encry=False, assoc_data=fileheader)\n            except Exception as e:\n                return e\n\n            with open(str(outname), 'wb') as filestreamout:\n                files_size = os.stat(filename).st_size\n                # the maximum of the progress bar is the total chunk to process. It's files_size // chunk_size\n                bar = tqdm(range(files_size // __chunk_size__))\n                while True:\n                    # Don't forget... an encrypted chunk is nonce, gcmtag, and cipher-chunk concatenation.\n                    encryptedchunk = filestream.read(__nonce_length__ + __gcmtag_length__ + __chunk_size__)\n                    if len(encryptedchunk) == 0:\n                        break\n\n                    # Chunk decryption.\n                    try:\n                        original = encry_decry_chunk(chunk=encryptedchunk, key=internal_key, algo=decrypt_algo,\n                                                     bool_encry=False, assoc_data=fileheader)\n                    except Exception as e:\n                        return e\n                    else:\n                        filestreamout.write(original)\n                        bar.update(1)\n\n        return \"successfully decrypted\"\n\n    except IOError:\n        exit(\"Error: file \\\"\" + filename + \"\\\" was not found.\")", "response": "Decrypt a file and write corresponding decrypted file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits a sentence while preserving tags.", "response": "def _tokenize(cls, sentence):\n        \"\"\"\n        Split a sentence while preserving tags.\n        \"\"\"\n        while True:\n            match = cls._regex_tag.search(sentence)\n            if not match:\n                yield from cls._split(sentence)\n                return\n            chunk = sentence[:match.start()]\n            yield from cls._split(chunk)\n            tag = match.group(0)\n            yield tag\n            sentence = sentence[(len(chunk) + len(tag)):]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement a distributed stategy for processing XML files. This function constructs a set of py:mod:`multiprocessing` threads (spread over multiple cores) and uses an internal queue to aggregate outputs. To use this function, implement a `process()` function that takes two arguments -- a :class:`mwxml.Dump` and the path the dump was loaded from. Anything that this function ``yield``s will be `yielded` in turn from the :func:`mwxml.map` function. :Parameters: paths : `iterable` ( `str` | `file` ) a list of paths to dump files to process process : `func` A function that takes a :class:`~mwxml.iteration.dump.Dump` and the path the dump was loaded from and yields threads : int the number of individual processing threads to spool up :Example: >>> import mwxml >>> files = [\"examples/dump.xml\", \"examples/dump2.xml\"] >>> >>> def page_info(dump, path): ... for page in dump: ... yield page.id, page.namespace, page.title ... >>> for id, namespace, title in mwxml.map(page_info, files): ... print(id, namespace, title) ...", "response": "def map(process, paths, threads=None):\n    \"\"\"\n    Implements a distributed stategy for processing XML files.  This\n    function constructs a set of py:mod:`multiprocessing` threads (spread over\n    multiple cores) and uses an internal queue to aggregate outputs.  To use\n    this function, implement a `process()` function that takes two arguments\n    -- a :class:`mwxml.Dump` and the path the dump was loaded\n    from. Anything that this function ``yield``s will be `yielded` in turn\n    from the :func:`mwxml.map` function.\n\n    :Parameters:\n        paths : `iterable` ( `str` | `file` )\n            a list of paths to dump files to process\n        process : `func`\n            A function that takes a :class:`~mwxml.iteration.dump.Dump` and the\n            path the dump was loaded from and yields\n        threads : int\n            the number of individual processing threads to spool up\n\n    :Example:\n\n        >>> import mwxml\n        >>> files = [\"examples/dump.xml\", \"examples/dump2.xml\"]\n        >>>\n        >>> def page_info(dump, path):\n        ...     for page in dump:\n        ...         yield page.id, page.namespace, page.title\n        ...\n        >>> for id, namespace, title in mwxml.map(page_info, files):\n        ...     print(id, namespace, title)\n        ...\n    \"\"\"\n    paths = [mwtypes.files.normalize_path(path) for path in paths]\n\n    def process_path(path):\n        dump = Dump.from_file(mwtypes.files.reader(path))\n        yield from process(dump, path)\n\n    yield from para.map(process_path, paths, mappers=threads)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(self):\n\n        return {\n            'title': self.title,\n            'issue_id': self.issue_id,\n            'reporter': self.reporter,\n            'assignee': self.assignee,\n            'status': self.status,\n            'product': self.product,\n            'component': self.component,\n            'created_at': self.created_at,\n            'updated_at': self.updated_at,\n            'closed_at': self.closed_at,\n            'status_code': self.status_code\n        }", "response": "Return the object itself."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_on_each_func_args_sig(func,\n                                cur_args,\n                                cur_kwargs,\n                                sig,  # type: Signature\n                                func_to_apply,\n                                func_to_apply_params_dict):\n    \"\"\"\n    Applies func_to_apply on each argument of func according to what's received in current call (cur_args, cur_kwargs).\n    For each argument of func named 'att' in its signature, the following method is called:\n\n    `func_to_apply(cur_att_value, func_to_apply_paramers_dict[att], func, att_name)`\n\n    :param func:\n    :param cur_args:\n    :param cur_kwargs:\n    :param sig:\n    :param func_to_apply:\n    :param func_to_apply_params_dict:\n    :return:\n    \"\"\"\n\n    # match the received arguments with the signature to know who is who\n    bound_values = sig.bind(*cur_args, **cur_kwargs)\n\n    # add the default values in here to get a full list\n    apply_defaults(bound_values)\n\n    for att_name, att_value in bound_values.arguments.items():\n        if att_name in func_to_apply_params_dict.keys():\n            # value = a normal value, or cur_kwargs as a whole\n            func_to_apply(att_value, func_to_apply_params_dict[att_name], func, att_name)", "response": "Applies func_to_apply on each argument of func according to what s received in current call."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_product_owner(self, team_id):\n\n        if self.is_super_admin():\n            return True\n        team_id = uuid.UUID(str(team_id))\n        return team_id in self.child_teams_ids", "response": "Ensure the user is a PRODUCT_OWNER."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting if user is in team", "response": "def is_in_team(self, team_id):\n        \"\"\"Test if user is in team\"\"\"\n\n        if self.is_super_admin():\n            return True\n        team_id = uuid.UUID(str(team_id))\n        return team_id in self.teams or team_id in self.child_teams_ids"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring ther resource has the role REMOTECI.", "response": "def is_remoteci(self, team_id=None):\n        \"\"\"Ensure ther resource has the role REMOTECI.\"\"\"\n        if team_id is None:\n            return self._is_remoteci\n        team_id = uuid.UUID(str(team_id))\n        if team_id not in self.teams_ids:\n            return False\n        return self.teams[team_id]['role'] == 'REMOTECI'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_feeder(self, team_id=None):\n        if team_id is None:\n            return self._is_feeder\n        team_id = uuid.UUID(str(team_id))\n        if team_id not in self.teams_ids:\n            return False\n        return self.teams[team_id]['role'] == 'FEEDER'", "response": "Ensure ther resource has the role FEEDER."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the node that contains this node or self if this node is the document.", "response": "def document(self):\n        \"\"\"\n        :return: the :class:`Document` node that contains this node,\n            or ``self`` if this node is the document.\n        \"\"\"\n        if self.is_document:\n            return self\n        return self.adapter.wrap_document(self.adapter.impl_document)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef root(self):\n        if self.is_root:\n            return self\n        return self.adapter.wrap_node(\n            self.adapter.impl_root_element, self.adapter.impl_document,\n            self.adapter)", "response": "Returns the root element of the document that contains this node or self if this node is the root element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a list of underlying implementation nodes into a list of NodeList s.", "response": "def _convert_nodelist(self, impl_nodelist):\n        \"\"\"\n        Convert a list of underlying implementation nodes into a list of\n        *xml4h* wrapper nodes.\n        \"\"\"\n        nodelist = [\n            self.adapter.wrap_node(n, self.adapter.impl_document, self.adapter)\n            for n in impl_nodelist]\n        return NodeList(nodelist)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parent(self):\n        parent_impl_node = self.adapter.get_node_parent(self.impl_node)\n        return self.adapter.wrap_node(\n            parent_impl_node, self.adapter.impl_document, self.adapter)", "response": "get the parent of this node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef children(self):\n        impl_nodelist = self.adapter.get_node_children(self.impl_node)\n        return self._convert_nodelist(impl_nodelist)", "response": "Return a list of child nodes of this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef child(self, local_name=None, name=None, ns_uri=None, node_type=None,\n            filter_fn=None):\n        \"\"\"\n        :return: the first child node matching the given constraints, or \\\n                 *None* if there are no matching child nodes.\n\n        Delegates to :meth:`NodeList.filter`.\n        \"\"\"\n        return self.children(name=name, local_name=local_name, ns_uri=ns_uri,\n            node_type=node_type, filter_fn=filter_fn, first_only=True)", "response": "Returns the first child node matching the given constraints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of this node s siblings nodes.", "response": "def siblings(self):\n        \"\"\"\n        :return: a list of this node's sibling nodes.\n        :rtype: NodeList\n        \"\"\"\n        impl_nodelist = self.adapter.get_node_children(self.parent.impl_node)\n        return self._convert_nodelist(\n            [n for n in impl_nodelist if n != self.impl_node])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef siblings_before(self):\n        impl_nodelist = self.adapter.get_node_children(self.parent.impl_node)\n        before_nodelist = []\n        for n in impl_nodelist:\n            if n == self.impl_node:\n                break\n            before_nodelist.append(n)\n        return self._convert_nodelist(before_nodelist)", "response": "returns a list of the siblings that occur before this node in the DOM."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the siblings that occur after this node in the DOM.", "response": "def siblings_after(self):\n        \"\"\"\n        :return: a list of this node's siblings that occur *after* this\n            node in the DOM.\n        \"\"\"\n        impl_nodelist = self.adapter.get_node_children(self.parent.impl_node)\n        after_nodelist = []\n        is_after_myself = False\n        for n in impl_nodelist:\n            if is_after_myself:\n                after_nodelist.append(n)\n            elif n == self.impl_node:\n                is_after_myself = True\n        return self._convert_nodelist(after_nodelist)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, destroy=True):\n        removed_child = self.adapter.remove_node_child(\n            self.adapter.get_node_parent(self.impl_node), self.impl_node,\n            destroy_node=destroy)\n        if removed_child is not None:\n            return self.adapter.wrap_node(removed_child, None, self.adapter)\n        else:\n            return None", "response": "Delete this node from the owning document."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclones a node from another document to become a child of this node.", "response": "def clone_node(self, node):\n        \"\"\"\n        Clone a node from another document to become a child of this node, by\n        copying the node's data into this document but leaving the node\n        untouched in the source document. The node to be cloned can be\n        a :class:`Node` based on the same underlying XML library implementation\n        and adapter, or a \"raw\" node from that implementation.\n\n        :param node: the node in another document to clone.\n        :type node: xml4h or implementation node\n        \"\"\"\n        if isinstance(node, xml4h.nodes.Node):\n            child_impl_node = node.impl_node\n        else:\n            child_impl_node = node  # Assume it's a valid impl node\n        self.adapter.import_node(self.impl_node, child_impl_node, clone=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransplant a node from another document to become a child of this node.", "response": "def transplant_node(self, node):\n        \"\"\"\n        Transplant a node from another document to become a child of this node,\n        removing it from the source document.  The node to be transplanted can\n        be a :class:`Node` based on the same underlying XML library\n        implementation and adapter, or a \"raw\" node from that implementation.\n\n        :param node: the node in another document to transplant.\n        :type node: xml4h or implementation node\n        \"\"\"\n        if isinstance(node, xml4h.nodes.Node):\n            child_impl_node = node.impl_node\n            original_parent_impl_node = node.parent.impl_node\n        else:\n            child_impl_node = node  # Assume it's a valid impl node\n            original_parent_impl_node = self.adapter.get_node_parent(node)\n        self.adapter.import_node(self.impl_node, child_impl_node,\n            original_parent_impl_node, clone=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind all the children of this node with optional name and namespace URI.", "response": "def find(self, name=None, ns_uri=None, first_only=False):\n        \"\"\"\n        Find :class:`Element` node descendants of this node, with optional\n        constraints to limit the results.\n\n        :param name: limit results to elements with this name.\n            If *None* or ``'*'`` all element names are matched.\n        :type name: string or None\n        :param ns_uri: limit results to elements within this namespace URI.\n            If *None* all elements are matched, regardless of namespace.\n        :type ns_uri: string or None\n        :param bool first_only: if *True* only return the first result node\n            or *None* if there is no matching node.\n\n        :returns: a list of :class:`Element` nodes matching any given\n            constraints, or a single node if ``first_only=True``.\n        \"\"\"\n        if name is None:\n            name = '*'  # Match all element names\n        if ns_uri is None:\n            ns_uri = '*'  # Match all namespaces\n        impl_nodelist = self.adapter.find_node_elements(\n            self.impl_node, name=name, ns_uri=ns_uri)\n        if first_only:\n            if impl_nodelist:\n                return self.adapter.wrap_node(\n                    impl_nodelist[0], self.adapter.impl_document, self.adapter)\n            else:\n                return None\n        return self._convert_nodelist(impl_nodelist)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the first node descendant of this node that matches any optional constraints.", "response": "def find_first(self, name=None, ns_uri=None):\n        \"\"\"\n        Find the first :class:`Element` node descendant of this node that\n        matches any optional constraints, or None if there are no matching\n        elements.\n\n        Delegates to :meth:`find` with ``first_only=True``.\n        \"\"\"\n        return self.find(name=name, ns_uri=ns_uri, first_only=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_doc(self, name=None, ns_uri=None, first_only=False):\n        return self.document.find(name=name, ns_uri=ns_uri,\n            first_only=first_only)", "response": "Find the document descendants of this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes this node and its descendants to text and write it to a given writer.", "response": "def write(self, writer=None, encoding='utf-8', indent=0, newline='',\n            omit_declaration=False, node_depth=0, quote_char='\"'):\n        \"\"\"\n        Serialize this node and its descendants to text, writing\n        the output to a given *writer* or to stdout.\n\n        :param writer: an object such as a file or stream to which XML text\n            is sent. If *None* text is sent to :attr:`sys.stdout`.\n        :type writer: a file, stream, etc or None\n        :param string encoding: the character encoding for serialized text.\n        :param indent: indentation prefix to apply to descendent nodes for\n            pretty-printing. The value can take many forms:\n\n            - *int*: the number of spaces to indent. 0 means no indent.\n            - *string*: a literal prefix for indented nodes, such as ``\\\\t``.\n            - *bool*: no indent if *False*, four spaces indent if *True*.\n            - *None*: no indent\n        :type indent: string, int, bool, or None\n        :param newline: the string value used to separate lines of output.\n            The value can take a number of forms:\n\n            - *string*: the literal newline value, such as ``\\\\n`` or ``\\\\r``.\n              An empty string means no newline.\n            - *bool*: no newline if *False*, ``\\\\n`` newline if *True*.\n            - *None*: no newline.\n        :type newline: string, bool, or None\n        :param boolean omit_declaration: if *True* the XML declaration header\n            is omitted, otherwise it is included. Note that the declaration is\n            only output when serializing an :class:`xml4h.nodes.Document` node.\n        :param int node_depth: the indentation level to start at, such as 2 to\n            indent output as if the given *node* has two ancestors.\n            This parameter will only be useful if you need to output XML text\n            fragments that can be assembled into a document.  This parameter\n            has no effect unless indentation is applied.\n        :param string quote_char: the character that delimits quoted content.\n            You should never need to mess with this.\n\n        Delegates to :func:`xml4h.writer.write_node` applied to this node.\n        \"\"\"\n        xml4h.write_node(self,\n            writer=writer, encoding=encoding, indent=indent,\n            newline=newline, omit_declaration=omit_declaration,\n            node_depth=node_depth, quote_char=quote_char)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xml(self, indent=4, **kwargs):\n        writer = StringIO()\n        self.write(writer, indent=indent, **kwargs)\n        return writer.getvalue()", "response": "Returns this node as XML text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xpath(self, xpath, **kwargs):\n        result = self.adapter.xpath_on_node(self.impl_node, xpath, **kwargs)\n        if isinstance(result, (list, tuple)):\n            return [self._maybe_wrap_node(r) for r in result]\n        else:\n            return self._maybe_wrap_node(result)", "response": "Perform an XPath query on the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_attributes(self, attr_obj=None, ns_uri=None, **attr_dict):\n        self._set_element_attributes(self.impl_node,\n            attr_obj=attr_obj, ns_uri=ns_uri, **attr_dict)", "response": "Add or update this element s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attributes(self):\n        attr_impl_nodes = self.adapter.get_node_attributes(self.impl_node)\n        return AttributeDict(attr_impl_nodes, self.impl_node, self.adapter)", "response": "Get or set this element s attributes as name value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attribute_nodes(self):\n        impl_attr_nodes = self.adapter.get_node_attributes(self.impl_node)\n        wrapped_attr_nodes = [\n            self.adapter.wrap_node(a, self.adapter.impl_document, self.adapter)\n            for a in impl_attr_nodes]\n        return sorted(wrapped_attr_nodes, key=lambda x: x.name)", "response": "returns a list of this element s attributes as\n            : class : Attribute nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attribute_node(self, name, ns_uri=None):\n        attr_impl_node = self.adapter.get_node_attribute_node(\n            self.impl_node, name, ns_uri)\n        return self.adapter.wrap_node(\n            attr_impl_node, self.adapter.impl_document, self.adapter)", "response": "returns the node that matches the given attribute name and ns_uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines a namespace prefix that will serve as shorthand for the given namespace URI in element names.", "response": "def set_ns_prefix(self, prefix, ns_uri):\n        \"\"\"\n        Define a namespace prefix that will serve as shorthand for the given\n        namespace URI in element names.\n\n        :param string prefix: prefix that will serve as an alias for a\n            the namespace URI.\n        :param string ns_uri: namespace URI that will be denoted by the\n            prefix.\n        \"\"\"\n        self._add_ns_prefix_attr(self.impl_node, prefix, ns_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new child element to this element with an optional namespace enumeration definition.", "response": "def add_element(self, name, ns_uri=None, attributes=None,\n            text=None, before_this_element=False):\n        \"\"\"\n        Add a new child element to this element, with an optional namespace\n        definition. If no namespace is provided the child will be assigned\n        to the default namespace.\n\n        :param string name: a name for the child node. The name may be used\n            to apply a namespace to the child by including:\n\n            - a prefix component in the name of the form\n              ``ns_prefix:element_name``, where the prefix has already been\n              defined for a namespace URI (such as via :meth:`set_ns_prefix`).\n            - a literal namespace URI value delimited by curly braces, of\n              the form ``{ns_uri}element_name``.\n        :param ns_uri: a URI specifying the new element's namespace. If the\n            ``name`` parameter specifies a namespace this parameter is ignored.\n        :type ns_uri: string or None\n        :param attributes: collection of attributes to assign to the new child.\n        :type attributes: dict, list, tuple, or None\n        :param text: text value to assign to the new child.\n        :type text: string or None\n        :param bool before_this_element: if *True* the new element is\n            added as a sibling preceding this element, instead of as a child.\n            In other words, the new element will be a child of this element's\n            parent node, and will immediately precent this element in the DOM.\n\n        :return: the new child as a an :class:`Element` node.\n        \"\"\"\n        # Determine local name, namespace and prefix info from tag name\n        prefix, local_name, node_ns_uri = \\\n            self.adapter.get_ns_info_from_node_name(name, self.impl_node)\n        if prefix:\n            qname = u'%s:%s' % (prefix, local_name)\n        else:\n            qname = local_name\n        # If no name-derived namespace, apply an alternate namespace\n        if node_ns_uri is None:\n            if ns_uri is None:\n                # Default document namespace\n                node_ns_uri = self.adapter.get_ns_uri_for_prefix(\n                    self.impl_node, None)\n            else:\n                # keyword-parameter namespace\n                node_ns_uri = ns_uri\n        # Create element\n        child_elem = self.adapter.new_impl_element(\n            qname, node_ns_uri, parent=self.impl_node)\n        # If element's default namespace was defined by literal uri prefix,\n        # create corresponding xmlns attribute for element...\n        if not prefix and '}' in name:\n            self._set_element_attributes(child_elem,\n                {'xmlns': node_ns_uri}, ns_uri=self.XMLNS_URI)\n        # ...otherwise define keyword-defined namespace as the default, if any\n        elif ns_uri is not None:\n            self._set_element_attributes(child_elem,\n                {'xmlns': ns_uri}, ns_uri=self.XMLNS_URI)\n        # Create subordinate nodes\n        if attributes is not None:\n            self._set_element_attributes(child_elem, attr_obj=attributes)\n        if text is not None:\n            self._add_text(child_elem, text)\n        # Add new element to its parent before a given node...\n        if before_this_element:\n            self.adapter.add_node_child(\n                self.adapter.get_node_parent(self.impl_node),\n                child_elem, before_sibling=self.impl_node)\n        # ...or in the default position, appended after existing nodes\n        else:\n            self.adapter.add_node_child(self.impl_node, child_elem)\n        return self.adapter.wrap_node(\n            child_elem, self.adapter.impl_document, self.adapter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_text(self, text):\n        if not isinstance(text, basestring):\n            text = unicode(text)\n        self._add_text(self.impl_node, text)", "response": "Add a text node to this element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_instruction(self, target, data):\n        self._add_instruction(self.impl_node, target, data)", "response": "Add an instruction node to this element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of name value attribute pairs sorted by attribute name.", "response": "def items(self):\n        \"\"\"\n        :return: a list of name/value attribute pairs sorted by attribute name.\n        \"\"\"\n        sorted_keys = sorted(self.keys())\n        return [(k, self[k]) for k in sorted_keys]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef namespace_uri(self, name):\n        a_node = self.adapter.get_node_attribute_node(self.impl_element, name)\n        if a_node is None:\n            return None\n        return self.adapter.get_node_namespace_uri(a_node)", "response": "returns the namespace URI associated with the named attribute or None if no such attribute exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the prefix component of the named attribute", "response": "def prefix(self, name):\n        \"\"\"\n        :param string name: the name of an attribute to look up.\n\n        :return: the prefix component of the named attribute's name,\n            or None.\n        \"\"\"\n        a_node = self.adapter.get_node_attribute_node(self.impl_element, name)\n        if a_node is None:\n            return None\n        return a_node.prefix"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef element(self):\n        return self.adapter.wrap_node(\n            self.impl_element, self.adapter.impl_document, self.adapter)", "response": "Returns the Element that contains these attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter(self, local_name=None, name=None, ns_uri=None, node_type=None,\n            filter_fn=None, first_only=False):\n        \"\"\"\n        Apply filters to the set of nodes in this list.\n\n        :param local_name: a local name used to filter the nodes.\n        :type local_name: string or None\n        :param name: a name used to filter the nodes.\n        :type name: string or None\n        :param ns_uri: a namespace URI used to filter the nodes.\n            If *None* all nodes are returned regardless of namespace.\n        :type ns_uri: string or None\n        :param node_type: a node type definition used to filter the nodes.\n        :type node_type: int node type constant, class, or None\n        :param filter_fn: an arbitrary function to filter nodes in this list.\n            This function must accept a single :class:`Node` argument and\n            return a bool indicating whether to include the node in the\n            filtered results.\n\n            .. note:: if ``filter_fn`` is provided all other filter arguments\n                are ignore.\n        :type filter_fn: function or None\n\n        :return: the type of the return value depends on the value of the\n            ``first_only`` parameter and how many nodes match the filter:\n\n            - if ``first_only=False`` return a :class:`NodeList` of filtered\n              nodes, which will be empty if there are no matching nodes.\n            - if ``first_only=True`` and at least one node matches,\n              return the first matching :class:`Node`\n            - if ``first_only=True`` and there are no matching nodes,\n              return *None*\n        \"\"\"\n        # Build our own filter function unless a custom function is provided\n        if filter_fn is None:\n            def filter_fn(n):\n                # Test node type first in case other tests require this type\n                if node_type is not None:\n                    # Node type can be specified as an integer constant (e.g.\n                    # ELEMENT_NODE) or a class.\n                    if isinstance(node_type, int):\n                        if not n.is_type(node_type):\n                            return False\n                    elif n.__class__ != node_type:\n                        return False\n                if name is not None and n.name != name:\n                    return False\n                if local_name is not None and n.local_name != local_name:\n                    return False\n                if ns_uri is not None and n.ns_uri != ns_uri:\n                    return False\n                return True\n        # Filter nodes\n        nodelist = filter(filter_fn, self)\n        # If requested, return just the first node (or None if no nodes)\n        if first_only:\n            return nodelist[0] if nodelist else None\n        else:\n            return NodeList(nodelist)", "response": "This method filters the set of nodes in this list based on the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_analytics(user, job_id):\n\n    args = schemas.args(flask.request.args.to_dict())\n    v1_utils.verify_existence_and_get(job_id, models.JOBS)\n\n    query = v1_utils.QueryBuilder(_TABLE, args, _A_COLUMNS)\n    # If not admin nor rh employee then restrict the view to the team\n    if user.is_not_super_admin() and not user.is_read_only_user():\n        query.add_extra_condition(_TABLE.c.team_id.in_(user.teams_ids))\n\n    query.add_extra_condition(_TABLE.c.job_id == job_id)\n\n    nb_rows = query.get_number_of_rows()\n    rows = query.execute(fetchall=True)\n    rows = v1_utils.format_result(rows, _TABLE.name)\n\n    return flask.jsonify({'analytics': rows, '_meta': {'count': nb_rows}})", "response": "Get all analytics of a job."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_node(node, writer=None, encoding='utf-8', indent=0, newline='',\n        omit_declaration=False, node_depth=0, quote_char='\"'):\n    \"\"\"\n    Serialize an *xml4h* DOM node and its descendants to text, writing\n    the output to a given *writer* or to stdout.\n\n    :param node: the DOM node whose content and descendants will\n        be serialized.\n    :type node: an :class:`xml4h.nodes.Node` or subclass\n    :param writer: an object such as a file or stream to which XML text\n        is sent. If *None* text is sent to :attr:`sys.stdout`.\n    :type writer: a file, stream, etc or None\n    :param string encoding: the character encoding for serialized text.\n    :param indent: indentation prefix to apply to descendent nodes for\n        pretty-printing. The value can take many forms:\n\n        - *int*: the number of spaces to indent. 0 means no indent.\n        - *string*: a literal prefix for indented nodes, such as ``\\\\t``.\n        - *bool*: no indent if *False*, four spaces indent if *True*.\n        - *None*: no indent.\n    :type indent: string, int, bool, or None\n    :param newline: the string value used to separate lines of output.\n        The value can take a number of forms:\n\n        - *string*: the literal newline value, such as ``\\\\n`` or ``\\\\r``.\n          An empty string means no newline.\n        - *bool*: no newline if *False*, ``\\\\n`` newline if *True*.\n        - *None*: no newline.\n    :type newline: string, bool, or None\n    :param boolean omit_declaration: if *True* the XML declaration header\n        is omitted, otherwise it is included. Note that the declaration is\n        only output when serializing an :class:`xml4h.nodes.Document` node.\n    :param int node_depth: the indentation level to start at, such as 2 to\n        indent output as if the given *node* has two ancestors.\n        This parameter will only be useful if you need to output XML text\n        fragments that can be assembled into a document.  This parameter\n        has no effect unless indentation is applied.\n    :param string quote_char: the character that delimits quoted content.\n        You should never need to mess with this.\n    \"\"\"\n    def _sanitize_write_value(value):\n        \"\"\"Return XML-encoded value.\"\"\"\n        if not value:\n            return value\n        return (value\n            .replace(\"&\", \"&amp;\")\n            .replace(\"<\", \"&lt;\")\n            .replace(\"\\\"\", \"&quot;\")\n            .replace(\">\", \"&gt;\")\n            )\n\n    def _write_node_impl(node, node_depth):\n        \"\"\"\n        Internal write implementation that does the real work while keeping\n        track of node depth.\n        \"\"\"\n        # Output document declaration if we're outputting the whole doc\n        if node.is_document:\n            if not omit_declaration:\n                writer.write(\n                    '<?xml version=%s1.0%s' % (quote_char, quote_char))\n                if encoding:\n                    writer.write(' encoding=%s%s%s'\n                        % (quote_char, encoding, quote_char))\n                writer.write('?>%s' % newline)\n            for child in node.children:\n                _write_node_impl(child,\n                    node_depth)  # node_depth not incremented\n            writer.write(newline)\n        elif node.is_document_type:\n            writer.write(\"<!DOCTYPE %s SYSTEM %s%s%s\"\n                % (node.name, quote_char, node.public_id))\n            if node.system_id is not None:\n                writer.write(\n                    \" %s%s%s\" % (quote_char, node.system_id, quote_char))\n            if node.children:\n                writer.write(\"[\")\n                for child in node.children:\n                    _write_node_impl(child, node_depth + 1)\n                writer.write(\"]\")\n            writer.write(\">\")\n        elif node.is_text:\n            writer.write(_sanitize_write_value(node.value))\n        elif node.is_cdata:\n            if ']]>' in node.value:\n                raise ValueError(\"']]>' is not allowed in CDATA node value\")\n            writer.write(\"<![CDATA[%s]]>\" % node.value)\n        #elif node.is_entity_reference:  # TODO\n        elif node.is_entity:\n            writer.write(newline + indent * node_depth)\n            writer.write(\"<!ENTITY \")\n            if node.is_paremeter_entity:\n                writer.write('%% ')\n            writer.write(\"%s %s%s%s>\"\n                % (node.name, quote_char, node.value, quote_char))\n        elif node.is_processing_instruction:\n            writer.write(newline + indent * node_depth)\n            writer.write(\"<?%s %s?>\" % (node.target, node.data))\n        elif node.is_comment:\n            if '--' in node.value:\n                raise ValueError(\"'--' is not allowed in COMMENT node value\")\n            writer.write(\"<!--%s-->\" % node.value)\n        elif node.is_notation:\n            writer.write(newline + indent * node_depth)\n            writer.write(\"<!NOTATION %s\" % node.name)\n            if node.is_system_identifier:\n                writer.write(\" system %s%s%s>\"\n                    % (quote_char, node.external_id, quote_char))\n            elif node.is_system_identifier:\n                writer.write(\" system %s%s%s %s%s%s>\"\n                    % (quote_char, node.external_id, quote_char,\n                    quote_char, node.uri, quote_char))\n        elif node.is_attribute:\n            writer.write(\" %s=%s\" % (node.name, quote_char))\n            writer.write(_sanitize_write_value(node.value))\n            writer.write(quote_char)\n        elif node.is_element:\n            # Only need a preceding newline if we're in a sub-element\n            if node_depth > 0:\n                writer.write(newline)\n            writer.write(indent * node_depth)\n            writer.write(\"<\" + node.name)\n\n            for attr in node.attribute_nodes:\n                _write_node_impl(attr, node_depth)\n            if node.children:\n                found_indented_child = False\n                writer.write(\">\")\n                for child in node.children:\n                    _write_node_impl(child, node_depth + 1)\n                    if not (child.is_text\n                            or child.is_comment\n                            or child.is_cdata):\n                        found_indented_child = True\n                if found_indented_child:\n                    writer.write(newline + indent * node_depth)\n                writer.write('</%s>' % node.name)\n            else:\n                writer.write('/>')\n        else:\n            raise exceptions.Xml4hImplementationBug(\n                'Cannot write node with class: %s' % node.__class__)\n\n    # Sanitize whitespace parameters\n    if indent is True:\n        indent = ' ' * 4\n    elif indent is False:\n        indent = ''\n    elif isinstance(indent, int):\n        indent = ' ' * indent\n    # If indent but no newline set, always apply a newline (it makes sense)\n    if indent and not newline:\n        newline = True\n\n    if newline is None or newline is False:\n        newline = ''\n    elif newline is True:\n        newline = '\\n'\n\n    # We always need a writer, use stdout by default\n    if writer is None:\n        writer = sys.stdout\n\n    # Apply a text encoding if we have one\n    if encoding is None:\n        writer = writer\n    else:\n        writer = codecs.getwriter(encoding)(writer)\n\n    # Do the business...\n    _write_node_impl(node, node_depth)", "response": "Serialize a node to a given writer or to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencrypting a chunk of a GCM file with the given key and decrypts it.", "response": "def encry_decry_chunk(chunk, key, algo, bool_encry, assoc_data):\n    \"\"\"\n    When bool_encry is True, encrypt a chunk of the file with the key and a randomly generated nonce. When it is False,\n    the function extract the nonce from the cipherchunk (first 16 bytes), and decrypt the rest of the chunk.\n    :param chunk: a chunk in bytes to encrypt or decrypt.\n    :param key: a 32 bytes key in bytes.\n    :param algo: a string of algorithm. Can be \"srp\" , \"AES\" or \"twf\"\n    :param bool_encry: if bool_encry is True, chunk is encrypted. Else, it will be decrypted.\n    :param assoc_data: bytes string of additional data for GCM Authentication.\n    :return: if bool_encry is True, corresponding nonce + cipherchunk else, a decrypted chunk.\n    \"\"\"\n    engine = botan.cipher(algo=algo, encrypt=bool_encry)\n    engine.set_key(key=key)\n    engine.set_assoc_data(assoc_data)\n    if bool_encry is True:\n        nonce = generate_nonce_timestamp()\n        engine.start(nonce=nonce)\n        return nonce + engine.finish(chunk)\n    else:\n        nonce = chunk[:__nonce_length__]\n        encryptedchunk = chunk[__nonce_length__:__nonce_length__ + __gcmtag_length__ + __chunk_size__]\n        engine.start(nonce=nonce)\n        decryptedchunk = engine.finish(encryptedchunk)\n        if decryptedchunk == b\"\":\n            raise Exception(\"Integrity failure: Invalid passphrase or corrupted data\")\n        return decryptedchunk"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery Bugzilla API to retrieve the needed infos.", "response": "def retrieve_info(self):\n        \"\"\"Query Bugzilla API to retrieve the needed infos.\"\"\"\n\n        scheme = urlparse(self.url).scheme\n        netloc = urlparse(self.url).netloc\n        query = urlparse(self.url).query\n\n        if scheme not in ('http', 'https'):\n            return\n\n        for item in query.split('&'):\n            if 'id=' in item:\n                ticket_id = item.split('=')[1]\n                break\n        else:\n            return\n\n        bugzilla_url = '%s://%s/%s%s' % (scheme, netloc, _URI_BASE, ticket_id)\n\n        result = requests.get(bugzilla_url)\n        self.status_code = result.status_code\n\n        if result.status_code == 200:\n            tree = ElementTree.fromstring(result.content)\n\n            self.title = tree.findall(\"./bug/short_desc\").pop().text\n            self.issue_id = tree.findall(\"./bug/bug_id\").pop().text\n            self.reporter = tree.findall(\"./bug/reporter\").pop().text\n            self.assignee = tree.findall(\"./bug/assigned_to\").pop().text\n            self.status = tree.findall(\"./bug/bug_status\").pop().text\n            self.product = tree.findall(\"./bug/product\").pop().text\n            self.component = tree.findall(\"./bug/component\").pop().text\n            self.created_at = tree.findall(\"./bug/creation_ts\").pop().text\n            self.updated_at = tree.findall(\"./bug/delta_ts\").pop().text\n            try:\n                self.closed_at = (\n                    tree.findall(\"./bug/cf_last_closed\").pop().text\n                )\n            except IndexError:\n                # cf_last_closed is present only if the issue has been closed\n                # if not present it raises an IndexError, meaning the issue\n                # isn't closed yet, which is a valid use case.\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maxlen(max_length,\n           strict=False  # type: bool\n           ):\n    \"\"\"\n    'Maximum length' validation_function generator.\n    Returns a validation_function to check that len(x) <= max_length (strict=False, default) or len(x) < max_length (strict=True)\n\n    :param max_length: maximum length for x\n    :param strict: Boolean flag to switch between len(x) <= max_length (strict=False) and len(x) < max_length\n    (strict=True)\n    :return:\n    \"\"\"\n    if strict:\n        def maxlen_(x):\n            if len(x) < max_length:\n                return True\n            else:\n                # raise Failure('maxlen: len(x) < ' + str(max_length) + ' does not hold for x=' + str(x))\n                raise TooLong(wrong_value=x, max_length=max_length, strict=True)\n    else:\n        def maxlen_(x):\n            if len(x) <= max_length:\n                return True\n            else:\n                # raise Failure('maxlen: len(x) <= ' + str(max_length) + ' does not hold for x=' + str(x))\n                raise TooLong(wrong_value=x, max_length=max_length, strict=False)\n\n    maxlen_.__name__ = 'length_{}lesser_than_{}'.format('strictly_' if strict else '', max_length)\n    return maxlen_", "response": "Maximum length validation_function generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_length(ref_length):\n    def has_length_(x):\n        if len(x) == ref_length:\n            return True\n        else:\n            raise WrongLength(wrong_value=x, ref_length=ref_length)\n\n    has_length_.__name__ = 'length_equals_{}'.format(ref_length)\n    return has_length_", "response": "length equals validation function generator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbeing length between validation_function generator.", "response": "def length_between(min_len,\n                   max_len,\n                   open_left=False,  # type: bool\n                   open_right=False  # type: bool\n                   ):\n    \"\"\"\n    'Is length between' validation_function generator.\n    Returns a validation_function to check that `min_len <= len(x) <= max_len (default)`. `open_right` and `open_left`\n    flags allow to transform each side into strict mode. For example setting `open_left=True` will enforce\n    `min_len < len(x) <= max_len`.\n\n    :param min_len: minimum length for x\n    :param max_len: maximum length for x\n    :param open_left: Boolean flag to turn the left inequality to strict mode\n    :param open_right: Boolean flag to turn the right inequality to strict mode\n    :return:\n    \"\"\"\n    if open_left and open_right:\n        def length_between_(x):\n            if (min_len < len(x)) and (len(x) < max_len):\n                return True\n            else:\n                # raise Failure('length between: {} < len(x) < {} does not hold for x={}'.format(min_len, max_len,\n                # x))\n                raise LengthNotInRange(wrong_value=x, min_length=min_len, left_strict=True, max_length=max_len,\n                                       right_strict=True)\n    elif open_left:\n        def length_between_(x):\n            if (min_len < len(x)) and (len(x) <= max_len):\n                return True\n            else:\n                # raise Failure('length between: {} < len(x) <= {} does not hold for x={}'.format(min_len, max_len,\n                # x))\n                raise LengthNotInRange(wrong_value=x, min_length=min_len, left_strict=True, max_length=max_len,\n                                       right_strict=False)\n    elif open_right:\n        def length_between_(x):\n            if (min_len <= len(x)) and (len(x) < max_len):\n                return True\n            else:\n                # raise Failure('length between: {} <= len(x) < {} does not hold for x={}'.format(min_len, max_len,\n                #  x))\n                raise LengthNotInRange(wrong_value=x, min_length=min_len, left_strict=False, max_length=max_len,\n                                       right_strict=True)\n    else:\n        def length_between_(x):\n            if (min_len <= len(x)) and (len(x) <= max_len):\n                return True\n            else:\n                # raise Failure('length between: {} <= len(x) <= {} does not hold for x={}'.format(min_len,\n                #  max_len, x))\n                raise LengthNotInRange(wrong_value=x, min_length=min_len, left_strict=False, max_length=max_len,\n                                       right_strict=False)\n\n    length_between_.__name__ = 'length_between_{}_and_{}'.format(min_len, max_len)\n    return length_between_"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalue in validation_function generator.", "response": "def is_in(allowed_values  # type: Set\n          ):\n    \"\"\"\n    'Values in' validation_function generator.\n    Returns a validation_function to check that x is in the provided set of allowed values\n\n    :param allowed_values: a set of allowed values\n    :return:\n    \"\"\"\n    def is_in_allowed_values(x):\n        if x in allowed_values:\n            return True\n        else:\n            # raise Failure('is_in: x in ' + str(allowed_values) + ' does not hold for x=' + str(x))\n            raise NotInAllowedValues(wrong_value=x, allowed_values=allowed_values)\n\n    is_in_allowed_values.__name__ = 'is_in_{}'.format(allowed_values)\n    return is_in_allowed_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_subset(reference_set  # type: Set\n              ):\n    \"\"\"\n    'Is subset' validation_function generator.\n    Returns a validation_function to check that x is a subset of reference_set\n\n    :param reference_set: the reference set\n    :return:\n    \"\"\"\n    def is_subset_of(x):\n        missing = x - reference_set\n        if len(missing) == 0:\n            return True\n        else:\n            # raise Failure('is_subset: len(x - reference_set) == 0 does not hold for x=' + str(x)\n            #                   + ' and reference_set=' + str(reference_set) + '. x contains unsupported '\n            #                      'elements ' + str(missing))\n            raise NotSubset(wrong_value=x, reference_set=reference_set, unsupported=missing)\n\n    is_subset_of.__name__ = 'is_subset_of_{}'.format(reference_set)\n    return is_subset_of", "response": "Is subset validation_function generator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_superset(reference_set  # type: Set\n                ):\n    \"\"\"\n    'Is superset' validation_function generator.\n    Returns a validation_function to check that x is a superset of reference_set\n\n    :param reference_set: the reference set\n    :return:\n    \"\"\"\n    def is_superset_of(x):\n        missing = reference_set - x\n        if len(missing) == 0:\n            return True\n        else:\n            # raise Failure('is_superset: len(reference_set - x) == 0 does not hold for x=' + str(x)\n            #               + ' and reference_set=' + str(reference_set) + '. x does not contain required '\n            #                       'elements ' + str(missing))\n            raise NotSuperset(wrong_value=x, reference_set=reference_set, missing=missing)\n\n    is_superset_of.__name__ = 'is_superset_of_{}'.format(reference_set)\n    return is_superset_of", "response": "Is superset validation_function generator."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a validation_function for collection inputs where each element of the input is validated against the validation_function_func.", "response": "def on_all_(*validation_func):\n    \"\"\"\n    Generates a validation_function for collection inputs where each element of the input will be validated against the\n    validation_functions provided. For convenience, a list of validation_functions can be provided and will be replaced\n    with an 'and_'.\n\n    Note that if you want to apply DIFFERENT validation_functions for each element in the input, you should rather use\n    on_each_.\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n    tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :return:\n    \"\"\"\n    # create the validation functions\n    validation_function_func = _process_validation_function_s(list(validation_func))\n\n    def on_all_val(x):\n        # validate all elements in x in turn\n        for idx, x_elt in enumerate(x):\n            try:\n                res = validation_function_func(x_elt)\n            except Exception as e:\n                raise InvalidItemInSequence(wrong_value=x_elt, wrapped_func=validation_function_func, validation_outcome=e)\n\n            if not result_is_success(res):\n                # one element of x was not valid > raise\n                # raise Failure('on_all_(' + str(validation_func) + '): failed validation for input '\n                #                       'element [' + str(idx) + ']: ' + str(x_elt))\n                raise InvalidItemInSequence(wrong_value=x_elt, wrapped_func=validation_function_func, validation_outcome=res)\n        return True\n\n    on_all_val.__name__ = 'apply_<{}>_on_all_elts'.format(get_callable_name(validation_function_func))\n    return on_all_val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_each_(*validation_functions_collection):\n    # create a tuple of validation functions.\n    validation_function_funcs = tuple(_process_validation_function_s(validation_func)\n                                      for validation_func in validation_functions_collection)\n\n    # generate a validation function based on the tuple of validation_functions lists\n    def on_each_val(x  # type: Tuple\n                    ):\n        if len(validation_function_funcs) != len(x):\n            raise Failure('on_each_: x does not have the same number of elements than validation_functions_collection.')\n        else:\n            # apply each validation_function on the input with the same position in the collection\n            idx = -1\n            for elt, validation_function_func in zip(x, validation_function_funcs):\n                idx += 1\n                try:\n                    res = validation_function_func(elt)\n                except Exception as e:\n                    raise InvalidItemInSequence(wrong_value=elt,\n                                                wrapped_func=validation_function_func,\n                                                validation_outcome=e)\n\n                if not result_is_success(res):\n                    # one validation_function was unhappy > raise\n                    # raise Failure('on_each_(' + str(validation_functions_collection) + '): _validation_function [' + str(idx)\n                    #               + '] (' + str(validation_functions_collection[idx]) + ') failed validation for '\n                    #                       'input ' + str(x[idx]))\n                    raise InvalidItemInSequence(wrong_value=elt,\n                                                wrapped_func=validation_function_func,\n                                                validation_outcome=res)\n            return True\n\n    on_each_val.__name__ = 'map_<{}>_on_elts' \\\n                           ''.format('(' + ', '.join([get_callable_name(f) for f in validation_function_funcs]) + ')')\n    return on_each_val", "response": "Generates a validation function for each element of the input."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all the jobs events from a given sequence number.", "response": "def get_jobs_events_from_sequence(user, sequence):\n    \"\"\"Get all the jobs events from a given sequence number.\"\"\"\n\n    args = schemas.args(flask.request.args.to_dict())\n\n    if user.is_not_super_admin():\n        raise dci_exc.Unauthorized()\n\n    query = sql.select([models.JOBS_EVENTS]). \\\n        select_from(models.JOBS_EVENTS.join(models.JOBS,\n                    models.JOBS.c.id == models.JOBS_EVENTS.c.job_id)). \\\n        where(_TABLE.c.id >= sequence)\n    sort_list = v1_utils.sort_query(args['sort'], _JOBS_EVENTS_COLUMNS,\n                                    default='created_at')\n    query = v1_utils.add_sort_to_query(query, sort_list)\n\n    if args.get('limit', None):\n        query = query.limit(args.get('limit'))\n    if args.get('offset', None):\n        query = query.offset(args.get('offset'))\n\n    rows = flask.g.db_conn.execute(query).fetchall()\n\n    query_nb_rows = sql.select([func.count(models.JOBS_EVENTS.c.id)])\n    nb_rows = flask.g.db_conn.execute(query_nb_rows).scalar()\n\n    return json.jsonify({'jobs_events': rows, '_meta': {'count': nb_rows}})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_file(cls, f):\n        element = ElementIterator.from_file(f)\n        assert element.tag == \"mediawiki\"\n        return cls.from_element(element)", "response": "Constructs a : class ~mwxml. iteration. dump. Dump from a plain text file pointer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_page_xml(cls, page_xml):\n        header = \"\"\"\n        <mediawiki xmlns=\"http://www.mediawiki.org/xml/export-0.5/\"\n                   xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n                   xsi:schemaLocation=\"http://www.mediawiki.org/xml/export-0.5/\n                     http://www.mediawiki.org/xml/export-0.5.xsd\" version=\"0.5\"\n                   xml:lang=\"en\">\n        <siteinfo>\n        </siteinfo>\n        \"\"\"\n\n        footer = \"</mediawiki>\"\n\n        return cls.from_file(mwtypes.files.concat(header, page_xml, footer))", "response": "Constructs a ~mwxml. iteration. dump. Dump from a page XML."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calc_derivation(passphrase, salt):\n    argonhash = argon2.low_level.hash_secret_raw((str.encode(passphrase)), salt=salt, hash_len=32,\n                                                 time_cost=__argon2_timing_cost__, memory_cost=__argon2_memory_cost__,\n                                                 parallelism=__argon2_parallelism__, type=argon2.low_level.Type.I)\n    return argonhash", "response": "Calculates a 32 bytes key derivation with Argon2."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the text value of the node s children.", "response": "def get_node_text(self, node):\n        \"\"\"\n        Return contatenated value of all text node children of this element\n        \"\"\"\n        text_children = [n.nodeValue for n in self.get_node_children(node)\n                         if n.nodeType == xml.dom.Node.TEXT_NODE]\n        if text_children:\n            return u''.join(text_children)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets text value of node.", "response": "def set_node_text(self, node, text):\n        \"\"\"\n        Set text value as sole Text child node of element; any existing\n        Text nodes are removed\n        \"\"\"\n        # Remove any existing Text node children\n        for child in self.get_node_children(node):\n            if child.nodeType == xml.dom.Node.TEXT_NODE:\n                self.remove_node_child(node, child, True)\n        if text is not None:\n            text_node = self.new_impl_text(text)\n            self.add_node_child(node, text_node)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating strings from glob strings.", "response": "def _get_contents(self):\n        \"\"\"Create strings from glob strings.\"\"\"\n        def files():\n            for value in super(GlobBundle, self)._get_contents():\n                for path in glob.glob(value):\n                    yield path\n        return list(files())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_generic_type(tp):\n    if NEW_TYPING:\n        return (isinstance(tp, type) and issubclass(tp, Generic) or\n                isinstance(tp, _GenericAlias) and\n                tp.__origin__ not in (Union, tuple, ClassVar, collections.abc.Callable))\n    # SMA: refering to is_callable_type and is_tuple_type to avoid duplicate code\n    return isinstance(tp, GenericMeta) and not is_callable_type(tp) and not is_tuple_type(tp)", "response": "Test if the given type is a generic type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_union_type(tp):\n    if NEW_TYPING:\n        return (tp is Union or\n                isinstance(tp, _GenericAlias) and tp.__origin__ is Union)\n    try:\n        from typing import _Union\n        return type(tp) is _Union\n    except ImportError:\n        # SMA: support for very old typing module <=3.5.3\n        return type(tp) is Union or type(tp) is type(Union)", "response": "Test if the type is a union type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntests if the type represents a class variable.", "response": "def is_classvar(tp):\n    \"\"\"Test if the type represents a class variable. Examples::\n\n        is_classvar(int) == False\n        is_classvar(ClassVar) == True\n        is_classvar(ClassVar[int]) == True\n        is_classvar(ClassVar[List[T]]) == True\n    \"\"\"\n    if NEW_TYPING:\n        return (tp is ClassVar or\n                isinstance(tp, _GenericAlias) and tp.__origin__ is ClassVar)\n    try:\n        from typing import _ClassVar\n        return type(tp) is _ClassVar\n    except:\n        # SMA: support for very old typing module <=3.5.3\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(to_parse, ignore_whitespace_text_nodes=True, adapter=None):\n    if adapter is None:\n        adapter = best_adapter\n    if isinstance(to_parse, basestring) and '<' in to_parse:\n        return adapter.parse_string(to_parse, ignore_whitespace_text_nodes)\n    else:\n        return adapter.parse_file(to_parse, ignore_whitespace_text_nodes)", "response": "Parses an XML document into an XML structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a new XML tree tree.", "response": "def build(tagname_or_element, ns_uri=None, adapter=None):\n    \"\"\"\n    Return a :class:`~xml4h.builder.Builder` that represents an element in\n    a new or existing XML DOM and provides \"chainable\" methods focussed\n    specifically on adding XML content.\n\n    :param tagname_or_element: a string name for the root node of a\n        new XML document, or an :class:`~xml4h.nodes.Element` node in an\n        existing document.\n    :type tagname_or_element: string or :class:`~xml4h.nodes.Element` node\n    :param ns_uri: a namespace URI to apply to the new root node. This\n        argument has no effect this method is acting on an element.\n    :type ns_uri: string or None\n    :param adapter: the *xml4h* implementation adapter class used to\n        interact with the document DOM nodes.\n        If None, :attr:`best_adapter` will be used.\n    :type adapter: adapter class or None\n\n    :return: a :class:`~xml4h.builder.Builder` instance that represents an\n        :class:`~xml4h.nodes.Element` node in an XML DOM.\n    \"\"\"\n    if adapter is None:\n        adapter = best_adapter\n    if isinstance(tagname_or_element, basestring):\n        doc = adapter.create_document(\n            tagname_or_element, ns_uri=ns_uri)\n        element = doc.root\n    elif isinstance(tagname_or_element, xml4h.nodes.Element):\n        element = tagname_or_element\n    else:\n        raise xml4h.exceptions.IncorrectArgumentTypeException(\n            tagname_or_element, [basestring, xml4h.nodes.Element])\n    return Builder(element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a user - friendly description of a NonePolicy taking into account NoneArgPolicy orrow", "response": "def get_none_policy_text(none_policy,   # type: int\n                         verbose=False  # type: bool\n                         ):\n    \"\"\"\n    Returns a user-friendly description of a NonePolicy taking into account NoneArgPolicy\n\n    :param none_policy:\n    :param verbose:\n    :return:\n    \"\"\"\n    if none_policy is NonePolicy.SKIP:\n        return \"accept None without performing validation\" if verbose else 'SKIP'\n    elif none_policy is NonePolicy.FAIL:\n        return \"fail on None without performing validation\" if verbose else 'FAIL'\n    elif none_policy is NonePolicy.VALIDATE:\n        return \"validate None as any other values\" if verbose else 'VALIDATE'\n    elif none_policy is NoneArgPolicy.SKIP_IF_NONABLE_ELSE_FAIL:\n        return \"accept None without validation if the argument is optional, otherwise fail on None\" if verbose \\\n            else 'SKIP_IF_NONABLE_ELSE_FAIL'\n    elif none_policy is NoneArgPolicy.SKIP_IF_NONABLE_ELSE_VALIDATE:\n        return \"accept None without validation if the argument is optional, otherwise validate None as any other \" \\\n               \"values\" if verbose else 'SKIP_IF_NONABLE_ELSE_VALIDATE'\n    else:\n        raise ValueError('Invalid none_policy ' + str(none_policy))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_none_handler(validation_callable,  # type: Callable\n                      none_policy           # type: int\n                      ):\n    # type: (...) -> Callable\n    \"\"\"\n    Adds a wrapper or nothing around the provided validation_callable, depending on the selected policy\n\n    :param validation_callable:\n    :param none_policy: an int representing the None policy, see NonePolicy\n    :return:\n    \"\"\"\n    if none_policy is NonePolicy.SKIP:\n        return _none_accepter(validation_callable)  # accept all None values\n\n    elif none_policy is NonePolicy.FAIL:\n        return _none_rejecter(validation_callable)  # reject all None values\n\n    elif none_policy is NonePolicy.VALIDATE:\n        return validation_callable                  # do not handle None specifically, do not wrap\n\n    else:\n        raise ValueError('Invalid none_policy : ' + str(none_policy))", "response": "Adds a wrapper or nothing around the provided validation_callable depending on the selected NonePolicy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_base_type_dynamically(error_type, additional_type):\n    # the new type created dynamically, with the same name\n    class new_error_type(with_metaclass(MetaReprForValidator, error_type, additional_type, object)):\n        pass\n\n    new_error_type.__name__ = error_type.__name__ + '[' + additional_type.__name__ + ']'\n    if sys.version_info >= (3, 0):\n        new_error_type.__qualname__ = error_type.__qualname__ + '[' + additional_type.__qualname__+ ']'\n    new_error_type.__module__ = error_type.__module__\n\n    return new_error_type", "response": "Utility method to create a new type dynamically inheriting from both error_type and additional_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_valid(name,              # type: str\n                 value,             # type: Any\n                 *validation_func,  # type: ValidationFuncs\n                 **kwargs):\n    \"\"\"\n    Validates value `value` using validation function(s) `base_validator_s`.\n    As opposed to `is_valid`, this function raises a `ValidationError` if validation fails.\n\n    It is therefore designed to be used for defensive programming, in an independent statement before the code that you\n    intent to protect.\n\n    ```python\n    assert_valid(x, isfinite):\n    ...<your code>\n    ```\n\n    Note: this is a friendly alias for `_validator(base_validator_s)(value)`\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n        tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n        are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n        `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n        of callables, they will be transformed to functions automatically.\n    :param name: the name of the variable to validate. It will be used in error messages\n    :param value: the value to validate\n    :param none_policy: describes how None values should be handled. See `NonePolicy` for the various possibilities.\n        Default is `NonePolicy.VALIDATE`, meaning that None values will be treated exactly like other values and follow\n        the same validation process.\n    :param error_type: a subclass of ValidationError to raise in case of validation failure. By default a\n        ValidationError will be raised with the provided help_msg\n    :param help_msg: an optional help message to be used in the raised error in case of validation failure.\n    :param kw_context_args: optional keyword arguments providing additional context, that will be provided to the error\n        in case of validation failure\n    :return: nothing in case of success. In case of failure, raises a <error_type> if provided, or a ValidationError.\n    \"\"\"\n    error_type, help_msg, none_policy = pop_kwargs(kwargs, [('error_type', None),\n                                                            ('help_msg', None),\n                                                            ('none_policy', None)], allow_others=True)\n    # the rest of keyword arguments is used as context.\n    kw_context_args = kwargs\n\n    return Validator(*validation_func, error_type=error_type, help_msg=help_msg,\n                     none_policy=none_policy).assert_valid(name=name, value=value, **kw_context_args)", "response": "Ensures that a value is valid for a given variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate value using validation function.", "response": "def is_valid(value,\n             *validation_func,  # type: Union[Callable, List[Callable]]\n             **kwargs\n             ):\n    # type: (...) -> bool\n    \"\"\"\n    Validates value `value` using validation function(s) `validator_func`.\n    As opposed to `assert_valid`, this function returns a boolean indicating if validation was a success or a failure.\n    It is therefore designed to be used within if ... else ... statements:\n\n    ```python\n    if is_valid(x, isfinite):\n        ...<code>\n    else\n        ...<code>\n    ```\n\n    Note: this is a friendly alias for `return _validator(validator_func, return_bool=True)(value)`\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n    tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :param value: the value to validate\n    :param none_policy: describes how None values should be handled. See `NonePolicy` for the various possibilities.\n    Default is `NonePolicy.VALIDATE`, meaning that None values will be treated exactly like other values and follow\n    the same validation process. Note that errors raised by NonePolicy.FAIL will be caught and transformed into a\n    returned value of False\n    :return: True if validation was a success, False otherwise\n    \"\"\"\n    none_policy = pop_kwargs(kwargs, [('none_policy', None)])\n\n    return Validator(*validation_func, none_policy=none_policy).is_valid(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an exception or a validator with a specific name.", "response": "def create_manually(cls,\n                        validation_function_name,  # type: str\n                        var_name,                  # type: str\n                        var_value,\n                        validation_outcome=None,   # type: Any\n                        help_msg=None,             # type: str\n                        append_details=True,       # type: bool\n                        **kw_context_args):\n        \"\"\"\n        Creates an instance without using a Validator.\n\n        This method is not the primary way that errors are created - they should rather created by the validation entry\n        points. However it can be handy in rare edge cases.\n\n        :param validation_function_name:\n        :param var_name:\n        :param var_value:\n        :param validation_outcome:\n        :param help_msg:\n        :param append_details:\n        :param kw_context_args:\n        :return:\n        \"\"\"\n        # create a dummy validator\n        def val_fun(x):\n            pass\n        val_fun.__name__ = validation_function_name\n        validator = Validator(val_fun, error_type=cls, help_msg=help_msg, **kw_context_args)\n\n        # create the exception\n        # e = cls(validator, var_value, var_name, validation_outcome=validation_outcome, help_msg=help_msg,\n        #         append_details=append_details, **kw_context_args)\n        e = validator._create_validation_error(var_name, var_value, validation_outcome, error_type=cls,\n                                               help_msg=help_msg, **kw_context_args)\n        return e"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_details(self):\n\n        # create the exception main message according to the type of result\n        if isinstance(self.validation_outcome, Exception):\n\n            prefix = 'Validation function [{val}] raised ' if self.display_prefix_for_exc_outcomes else ''\n\n            # new: we now remove  \"Root validator was [{validator}]\", users can get it through e.validator\n            contents = ('Error validating {what}. ' + prefix + '{exception}: {details}')\\\n                         .format(what=self.get_what_txt(),\n                                 val=self.validator.get_main_function_name(),\n                                 exception=type(self.validation_outcome).__name__,\n                                 details=end_with_dot(str(self.validation_outcome)))\n\n        else:\n            contents = 'Error validating {what}: validation function [{val}] returned [{result}].' \\\n                       ''.format(what=self.get_what_txt(), val=self.validator.get_main_function_name(),\n                                 result=self.validation_outcome)\n\n        # return 'Wrong value: [{}]'.format(self.var_value)\n        return contents", "response": "This function returns the details of the error and the exception main message according to the type of validation outcome."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assert_valid(self,\n                     name,             # type: str\n                     value,            # type: Any\n                     error_type=None,  # type: Type[ValidationError]\n                     help_msg=None,    # type: str\n                     **kw_context_args):\n        \"\"\"\n        Asserts that the provided named value is valid with respect to the inner base validation functions. It returns\n        silently in case of success, and raises a `ValidationError` or a subclass in case of failure. This corresponds\n        to a 'Defensive programming' (sometimes known as 'Offensive programming') mode.\n\n        By default this raises instances of `ValidationError` with a default message, in case of failure. There are\n        two ways that you can customize this behaviour:\n\n         * if you set `help_msg` in this method or in `Validator` constructor, instances of `ValidationError` created\n         will be customized with the provided help message.\n\n         * if you set `error_type` in this method or in `Validator` constructor, instances of your custom class will be\n         created. Note that you may still provide a `help_msg`.\n\n        It is recommended that Users define their own validation error types (case 2 above), so as to provide a unique\n        error type for each kind of applicative error. This eases the process of error handling at app-level.\n\n        :param name: the name of the variable to validate (for error messages)\n        :param value: the value to validate\n        :param error_type: a subclass of `ValidationError` to raise in case of validation failure. By default a\n            `ValidationError` will be raised with the provided `help_msg`\n        :param help_msg: an optional help message to be used in the raised error in case of validation failure.\n        :param kw_context_args: optional contextual information to store in the exception, and that may be also used\n            to format the help message\n        :return: nothing in case of success. Otherwise, raises a ValidationError\n        \"\"\"\n        try:\n            # perform validation\n            res = self.main_function(value)\n\n        except Exception as e:\n            # caught any exception: raise ValidationError or subclass with that exception in the details\n            # --old bad idea: first wrap into a failure ==> NO !!! I tried and it was making it far too messy/verbose\n\n            # note: we do not have to 'raise x from e' of `raise_from`since the ValidationError constructor already\n            # sets the __cause__ so we can safely take the same handling than for non-exception failures.\n            res = e\n\n        # check the result\n        if not result_is_success(res):\n            raise_(self._create_validation_error(name, value, validation_outcome=res, error_type=error_type,\n                                                 help_msg=help_msg, **kw_context_args))", "response": "This method checks that the provided value is valid with respect to the inner base validation functions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a validation error for the current object.", "response": "def _create_validation_error(self,\n                                 name,                     # type: str\n                                 value,                    # type: Any\n                                 validation_outcome=None,  # type: Any\n                                 error_type=None,          # type: Type[ValidationError]\n                                 help_msg=None,            # type: str\n                                 **kw_context_args):\n        \"\"\" The function doing the final error raising.  \"\"\"\n\n        # first merge the info provided in arguments and in self\n        error_type = error_type or self.error_type\n        help_msg = help_msg or self.help_msg\n        ctx = copy(self.kw_context_args)\n        ctx.update(kw_context_args)\n\n        # allow the class to override the name\n        name = self._get_name_for_errors(name)\n\n        if issubclass(error_type, TypeError) or issubclass(error_type, ValueError):\n            # this is most probably a custom error type, it is already annotated with ValueError and/or TypeError\n            # so use it 'as is'\n            new_error_type = error_type\n        else:\n            # Add the appropriate TypeError/ValueError base type dynamically\n            additional_type = None\n            if isinstance(validation_outcome, Exception):\n                if is_error_of_type(validation_outcome, TypeError):\n                    additional_type = TypeError\n                elif is_error_of_type(validation_outcome, ValueError):\n                    additional_type = ValueError\n            if additional_type is None:\n                # not much we can do here, let's assume a ValueError, that is more probable\n                additional_type = ValueError\n\n            new_error_type = add_base_type_dynamically(error_type, additional_type)\n\n        # then raise the appropriate ValidationError or subclass\n        return new_error_type(validator=self, var_value=value, var_name=name, validation_outcome=validation_outcome,\n                              help_msg=help_msg, **ctx)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the provided value and returns a boolean indicating success or failure.", "response": "def is_valid(self,\n                 value  # type: Any\n                 ):\n        # type: (...) -> bool\n        \"\"\"\n        Validates the provided value and returns a boolean indicating success or failure. Any Exception happening in\n        the validation process will be silently caught.\n\n        :param value: the value to validate\n        :return: a boolean flag indicating success or failure\n        \"\"\"\n        # noinspection PyBroadException\n        try:\n            # perform validation\n            res = self.main_function(value)\n\n            # return a boolean indicating if success or failure\n            return result_is_success(res)\n\n        except Exception:\n            # caught exception means failure > return False\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a tag by id.", "response": "def delete_tag_by_id(user, tag_id):\n    \"\"\"Delete a tag.\"\"\"\n    query = _TABLE.delete().where(_TABLE.c.id == tag_id)\n    result = flask.g.db_conn.execute(query)\n\n    if not result.rowcount:\n        raise dci_exc.DCIConflict('Tag deletion conflict', tag_id)\n\n    return flask.Response(None, 204, content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_app(self, app, entry_point_group='invenio_assets.bundles',\n                 **kwargs):\n        \"\"\"Initialize application object.\n\n        :param app: An instance of :class:`~flask.Flask`.\n        :param entry_point_group: A name of entry point group used to load\n            ``webassets`` bundles.\n\n        .. versionchanged:: 1.0.0b2\n           The *entrypoint* has been renamed to *entry_point_group*.\n        \"\"\"\n        self.init_config(app)\n        self.env.init_app(app)\n        self.collect.init_app(app)\n        self.webpack.init_app(app)\n\n        if entry_point_group:\n            self.load_entrypoint(entry_point_group)\n\n        app.extensions['invenio-assets'] = self", "response": "Initialize application object.\n\n        :param app: An instance of :class:`~flask.Flask`.\n        :param entry_point_group: A name of entry point group used to load\n            ``webassets`` bundles.\n\n        .. versionchanged:: 1.0.0b2\n           The *entrypoint* has been renamed to *entry_point_group*."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_config(self, app):\n        app.config.setdefault('REQUIREJS_BASEURL', app.static_folder)\n        app.config.setdefault('COLLECT_STATIC_ROOT', app.static_folder)\n        app.config.setdefault('COLLECT_STORAGE', 'flask_collect.storage.link')\n        app.config.setdefault(\n            'COLLECT_FILTER', partial(collect_staticroot_removal, app))\n        app.config.setdefault(\n            'WEBPACKEXT_PROJECT', 'invenio_assets.webpack:project')", "response": "Initialize configuration.\n\n        :param app: An instance of :class:`~flask.Flask`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_entrypoint(self, entry_point_group):\n        for ep in pkg_resources.iter_entry_points(entry_point_group):\n            self.env.register(ep.name, ep.load())", "response": "Load the entry point."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that value is an instance of one of the allowed types.", "response": "def assert_instance_of(value,\n                       allowed_types  # type: Union[Type, Tuple[Type]]\n                       ):\n    \"\"\"\n    An inlined version of instance_of(var_types)(value) without 'return True': it does not return anything in case of\n    success, and raises a HasWrongType exception in case of failure.\n\n    Used in validate and validation/validator\n\n    :param value: the value to check\n    :param allowed_types: the type(s) to enforce. If a tuple of types is provided it is considered alternate types: one\n        match is enough to succeed. If None, type will not be enforced\n    :return:\n    \"\"\"\n    if not isinstance(value, allowed_types):\n        try:\n            # more than 1 ?\n            allowed_types[1]\n            raise HasWrongType(wrong_value=value, ref_type=allowed_types,\n                               help_msg='Value should be an instance of any of {ref_type}')\n        except IndexError:\n            # 1\n            allowed_types = allowed_types[0]\n        except TypeError:\n            # 1\n            pass\n        raise HasWrongType(wrong_value=value, ref_type=allowed_types)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_subclass_of(typ,\n                       allowed_types  # type: Union[Type, Tuple[Type]]\n                       ):\n    \"\"\"\n    An inlined version of subclass_of(var_types)(value) without 'return True': it does not return anything in case of\n    success, and raises a IsWrongType exception in case of failure.\n\n    Used in validate and validation/validator\n\n    :param typ: the type to check\n    :param allowed_types: the type(s) to enforce. If a tuple of types is provided it is considered alternate types:\n        one match is enough to succeed. If None, type will not be enforced\n    :return:\n    \"\"\"\n    if not issubclass(typ, allowed_types):\n        try:\n            # more than 1 ?\n            allowed_types[1]\n            raise IsWrongType(wrong_value=typ, ref_type=allowed_types,\n                              help_msg='Value should be a subclass of any of {ref_type}')\n        except IndexError:\n            # 1\n            allowed_types = allowed_types[0]\n        except TypeError:\n            # 1\n            pass\n        raise IsWrongType(wrong_value=typ, ref_type=allowed_types)", "response": "Checks that the value is a subclass of the type specified in typ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(name,                   # type: str\n             value,                  # type: Any\n             enforce_not_none=True,  # type: bool\n             equals=None,            # type: Any\n             instance_of=None,       # type: Union[Type, Tuple[Type]]\n             subclass_of=None,       # type: Union[Type, Tuple[Type]]\n             is_in=None,             # type: Container\n             subset_of=None,         # type: Set\n             contains = None,        # type: Union[Any, Iterable]\n             superset_of=None,       # type: Set\n             min_value=None,         # type: Any\n             min_strict=False,       # type: bool\n             max_value=None,         # type: Any\n             max_strict=False,       # type: bool\n             length=None,            # type: int\n             min_len=None,           # type: int\n             min_len_strict=False,   # type: bool\n             max_len=None,           # type: int\n             max_len_strict=False,   # type: bool\n             custom=None,            # type: Callable[[Any], Any]\n             error_type=None,        # type: Type[ValidationError]\n             help_msg=None,          # type: str\n             **kw_context_args):\n    \"\"\"\n    A validation function for quick inline validation of `value`, with minimal capabilities:\n\n    * None handling: reject None (enforce_not_none=True, default), or accept None silently (enforce_not_none=False)\n    * Type validation: `value` should be an instance of any of `var_types` if provided\n    * Value validation:\n       * if `allowed_values` is provided, `value` should be in that set\n       * if `min_value` (resp. `max_value`) is provided, `value` should be greater than it. Comparison is not strict by\n       default and can be set to strict by setting `min_strict`, resp. `max_strict`, to `True`\n       * if `min_len` (resp. `max_len`) is provided, `len(value)` should be greater than it. Comparison is not strict by\n       default and can be set to strict by setting `min_len_strict`, resp. `max_len_strict`, to `True`\n\n    :param name: the applicative name of the checked value, that will be used in error messages\n    :param value: the value to check\n    :param enforce_not_none: boolean, default True. Whether to enforce that `value` is not None.\n    :param equals: an optional value to enforce.\n    :param instance_of: optional type(s) to enforce. If a tuple of types is provided it is considered alternate types: one\n        match is enough to succeed. If None, type will not be enforced\n    :param subclass_of: optional type(s) to enforce. If a tuple of types is provided it is considered alternate types: one\n        match is enough to succeed. If None, type will not be enforced\n    :param is_in: an optional set of allowed values.\n    :param subset_of: an optional superset for the variable\n    :param contains: an optional value that the variable should contain (value in variable == True)\n    :param superset_of: an optional subset for the variable\n    :param min_value: an optional minimum value\n    :param min_strict: if True, only values strictly greater than `min_value` will be accepted\n    :param max_value: an optional maximum value\n    :param max_strict: if True, only values strictly lesser than `max_value` will be accepted\n    :param length: an optional strict length\n    :param min_len: an optional minimum length\n    :param min_len_strict: if True, only values with length strictly greater than `min_len` will be accepted\n    :param max_len: an optional maximum length\n    :param max_len_strict: if True, only values with length strictly lesser than `max_len` will be accepted\n    :param custom: a custom base validation function or list of base validation functions to use. This is the same\n        syntax than for valid8 decorators. A callable, a tuple(callable, help_msg_str), a tuple(callable, failure_type),\n        or a list of several such elements. Nested lists are supported and indicate an implicit `and_`. Tuples indicate\n        an implicit `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be\n        used instead of callables, they will be transformed to functions automatically.\n    :param error_type: a subclass of `ValidationError` to raise in case of validation failure. By default a\n        `ValidationError` will be raised with the provided `help_msg`\n    :param help_msg: an optional help message to be used in the raised error in case of validation failure.\n    :param kw_context_args: optional contextual information to store in the exception, and that may be also used\n        to format the help message\n    :return: nothing in case of success. Otherwise, raises a ValidationError\n    \"\"\"\n\n    # backwards compatibility\n    instance_of = instance_of or (kw_context_args.pop('allowed_types') if 'allowed_types' in kw_context_args else None)\n    is_in = is_in or (kw_context_args.pop('allowed_values') if 'allowed_values' in kw_context_args else None)\n\n    try:\n        # the following corresponds to an inline version of\n        # - _none_rejecter in base.py\n        # - gt/lt in comparables.py\n        # - is_in/contains/subset_of/superset_of/has_length/minlen/maxlen/is_in in collections.py\n        # - instance_of/subclass_of in types.py\n\n        # try (https://github.com/orf/inliner) to perform the inlining below automatically without code duplication ?\n        # > maybe not because quite dangerous (AST mod) and below we skip the \"return True\" everywhere for performance\n        #\n        # Another alternative: easy Cython compiling https://github.com/AlanCristhian/statically\n        # > but this is not py2 compliant\n\n        if value is None:\n            # inlined version of _none_rejecter in base.py\n            if enforce_not_none:\n                raise ValueIsNone(wrong_value=value)\n                # raise MissingMandatoryParameterException('Error, ' + name + '\" is mandatory, it should be non-None')\n\n            # else do nothing and return\n\n        else:\n            if equals is not None:\n                if value != equals:\n                    raise NotEqual(wrong_value=value, ref_value=equals)\n\n            if instance_of is not None:\n                assert_instance_of(value, instance_of)\n\n            if subclass_of is not None:\n                assert_subclass_of(value, subclass_of)\n\n            if is_in is not None:\n                # inlined version of is_in(allowed_values=allowed_values)(value) without 'return True'\n                if value not in is_in:\n                    raise NotInAllowedValues(wrong_value=value, allowed_values=is_in)\n\n            if contains is not None:\n                # inlined version of contains(ref_value=contains)(value) without 'return True'\n                if contains not in value:\n                    raise DoesNotContainValue(wrong_value=value, ref_value=contains)\n\n            if subset_of is not None:\n                # inlined version of is_subset(reference_set=subset_of)(value)\n                missing = value - subset_of\n                if len(missing) != 0:\n                    raise NotSubset(wrong_value=value, reference_set=subset_of, unsupported=missing)\n\n            if superset_of is not None:\n                # inlined version of is_superset(reference_set=superset_of)(value)\n                missing = superset_of - value\n                if len(missing) != 0:\n                    raise NotSuperset(wrong_value=value, reference_set=superset_of, missing=missing)\n\n            if min_value is not None:\n                # inlined version of gt(min_value=min_value, strict=min_strict)(value) without 'return True'\n                if min_strict:\n                    if not value > min_value:\n                        raise TooSmall(wrong_value=value, min_value=min_value, strict=True)\n                else:\n                    if not value >= min_value:\n                        raise TooSmall(wrong_value=value, min_value=min_value, strict=False)\n\n            if max_value is not None:\n                # inlined version of lt(max_value=max_value, strict=max_strict)(value) without 'return True'\n                if max_strict:\n                    if not value < max_value:\n                        raise TooBig(wrong_value=value, max_value=max_value, strict=True)\n                else:\n                    if not value <= max_value:\n                        raise TooBig(wrong_value=value, max_value=max_value, strict=False)\n\n            if length is not None:\n                # inlined version of has_length() without 'return True'\n                if len(value) != length:\n                    raise WrongLength(wrong_value=value, ref_length=length)\n\n            if min_len is not None:\n                # inlined version of minlen(min_length=min_len, strict=min_len_strict)(value) without 'return True'\n                if min_len_strict:\n                    if not len(value) > min_len:\n                        raise TooShort(wrong_value=value, min_length=min_len, strict=True)\n                else:\n                    if not len(value) >= min_len:\n                        raise TooShort(wrong_value=value, min_length=min_len, strict=False)\n\n            if max_len is not None:\n                # inlined version of maxlen(max_length=max_len, strict=max_len_strict)(value) without 'return True'\n                if max_len_strict:\n                    if not len(value) < max_len:\n                        raise TooLong(wrong_value=value, max_length=max_len, strict=True)\n                else:\n                    if not len(value) <= max_len:\n                        raise TooLong(wrong_value=value, max_length=max_len, strict=False)\n\n    except Exception as e:\n        err = _QUICK_VALIDATOR._create_validation_error(name, value, validation_outcome=e, error_type=error_type,\n                                                        help_msg=help_msg, **kw_context_args)\n        raise_(err)\n\n    if custom is not None:\n        # traditional custom validator\n        assert_valid(name, value, custom, error_type=error_type, help_msg=help_msg, **kw_context_args)\n    else:\n        # basic (and not enough) check to verify that there was no typo leading an argument to be put in kw_context_args\n        if error_type is None and help_msg is None and len(kw_context_args) > 0:\n            raise ValueError(\"Keyword context arguments have been provided but help_msg and error_type are not: {}\"\n                             \"\".format(kw_context_args))", "response": "Generic validation function for quick inline validation of a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gt(min_value,    # type: Any\n       strict=False  # type: bool\n       ):\n    \"\"\"\n    'Greater than' validation_function generator.\n    Returns a validation_function to check that x >= min_value (strict=False, default) or x > min_value (strict=True)\n\n    :param min_value: minimum value for x\n    :param strict: Boolean flag to switch between x >= min_value (strict=False) and x > min_value (strict=True)\n    :return:\n    \"\"\"\n    if strict:\n        def gt_(x):\n            if x > min_value:\n                return True\n            else:\n                # raise Failure('x > ' + str(min_value) + ' does not hold for x=' + str(x))\n                # '{val} is not strictly greater than {ref}'\n                raise TooSmall(wrong_value=x, min_value=min_value, strict=True)\n    else:\n        def gt_(x):\n            if x >= min_value:\n                return True\n            else:\n                # raise Failure('x >= ' + str(min_value) + ' does not hold for x=' + str(x))\n                # '{val} is not greater than {ref}'\n                raise TooSmall(wrong_value=x, min_value=min_value, strict=False)\n\n    gt_.__name__ = '{}greater_than_{}'.format('strictly_' if strict else '', min_value)\n    return gt_", "response": "Returns a validation_function generator. It returns a validation_function to check that x > = min_value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lt(max_value,    # type: Any\n       strict=False  # type: bool\n       ):\n    \"\"\"\n    'Lesser than' validation_function generator.\n    Returns a validation_function to check that x <= max_value (strict=False, default) or x < max_value (strict=True)\n\n    :param max_value: maximum value for x\n    :param strict: Boolean flag to switch between x <= max_value (strict=False) and x < max_value (strict=True)\n    :return:\n    \"\"\"\n    if strict:\n        def lt_(x):\n            if x < max_value:\n                return True\n            else:\n                # raise Failure('x < ' + str(max_value) + ' does not hold for x=' + str(x))\n                # '{val} is not strictly lesser than {ref}'\n                raise TooBig(wrong_value=x, max_value=max_value, strict=True)\n    else:\n        def lt_(x):\n            if x <= max_value:\n                return True\n            else:\n                # raise Failure('x <= ' + str(max_value) + ' does not hold for x=' + str(x))\n                # '{val} is not lesser than {ref}'\n                raise TooBig(wrong_value=x, max_value=max_value, strict=False)\n\n    lt_.__name__ = '{}lesser_than_{}'.format('strictly_' if strict else '', max_value)\n    return lt_", "response": "Returns a validation_function generator. It checks that x < max_value and returns True if x < max_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef between(min_val,          # type: Any\n            max_val,          # type: Any\n            open_left=False,  # type: bool\n            open_right=False  # type: bool\n            ):\n    \"\"\"\n    'Is between' validation_function generator.\n    Returns a validation_function to check that min_val <= x <= max_val (default). open_right and open_left flags allow\n    to transform each side into strict mode. For example setting open_left=True will enforce min_val < x <= max_val\n\n    :param min_val: minimum value for x\n    :param max_val: maximum value for x\n    :param open_left: Boolean flag to turn the left inequality to strict mode\n    :param open_right: Boolean flag to turn the right inequality to strict mode\n    :return:\n    \"\"\"\n    if open_left and open_right:\n        def between_(x):\n            if (min_val < x) and (x < max_val):\n                return True\n            else:\n                # raise Failure('{} < x < {} does not hold for x={}'.format(min_val, max_val, x))\n                raise NotInRange(wrong_value=x, min_value=min_val, left_strict=True,\n                                 max_value=max_val, right_strict=True)\n    elif open_left:\n        def between_(x):\n            if (min_val < x) and (x <= max_val):\n                return True\n            else:\n                # raise Failure('between: {} < x <= {} does not hold for x={}'.format(min_val, max_val, x))\n                raise NotInRange(wrong_value=x, min_value=min_val, left_strict=True,\n                                 max_value=max_val, right_strict=False)\n    elif open_right:\n        def between_(x):\n            if (min_val <= x) and (x < max_val):\n                return True\n            else:\n                # raise Failure('between: {} <= x < {} does not hold for x={}'.format(min_val, max_val, x))\n                raise NotInRange(wrong_value=x, min_value=min_val, left_strict=False,\n                                 max_value=max_val, right_strict=True)\n    else:\n        def between_(x):\n            if (min_val <= x) and (x <= max_val):\n                return True\n            else:\n                # raise Failure('between: {} <= x <= {} does not hold for x={}'.format(min_val, max_val, x))\n                raise NotInRange(wrong_value=x, min_value=min_val, left_strict=False,\n                                 max_value=max_val, right_strict=False)\n\n    between_.__name__ = 'between_{}_and_{}'.format(min_val, max_val)\n    return between_", "response": "Is between validation_function generator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sub_process_main(started_event: Event,\n                      channel_name: str,\n                      connection: Connection,\n                      consumer_configuration: BrightsideConsumerConfiguration,\n                      consumer_factory: Callable[[Connection, BrightsideConsumerConfiguration, logging.Logger], BrightsideConsumer],\n                      command_processor_factory: Callable[[str], CommandProcessor],\n                      mapper_func: Callable[[BrightsideMessage], Request]) -> None:\n    \"\"\"\n    This is the main method for the sub=process, everything we need to create the message pump and\n    channel it needs to be passed in as parameters that can be pickled as when we run they will be serialized\n    into this process. The data should be value types, not reference types as we will receive a copy of the original.\n    Inter-process communication is signalled by the event - to indicate startup - and the pipeline to facilitate a\n    sentinel or stop message\n    :param started_event: Used by the sub-process to signal that it is ready\n    :param channel_name: The name we want to give the channel to the broker for identification\n    :param connection: The 'broker' connection\n    :param consumer_configuration: How to configure our consumer of messages from the channel\n    :param consumer_factory: Callback to create the consumer. User code as we don't know what consumer library they\n        want to use. Arame? Something else?\n    :param command_processor_factory: Callback to  register subscribers, policies, and task queues then build command\n        processor. User code that provides us with their requests and handlers\n    :param mapper_func: We need to map between messages on the wire and our handlers\n    :return:\n    \"\"\"\n\n    logger = logging.getLogger(__name__)\n    consumer = consumer_factory(connection, consumer_configuration, logger)\n    channel = Channel(name=channel_name, consumer=consumer, pipeline=consumer_configuration.pipeline)\n\n    # TODO: Fix defaults that need passed in config values\n    command_processor = command_processor_factory(channel_name)\n    message_pump = MessagePump(command_processor=command_processor, channel=channel, mapper_func=mapper_func,\n                               timeout=500, unacceptable_message_limit=None, requeue_count=None)\n\n    logger.debug(\"Starting the message pump for %s\", channel_name)\n    message_pump.run(started_event)", "response": "This is the main method for the sub - process. It is called by the main function of the main function of the sub - process."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns migrations in offline mode.", "response": "def run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    app_conf = dci_config.generate_conf()\n    url = app_conf['SQLALCHEMY_DATABASE_URI']\n    context.configure(\n        url=url, target_metadata=target_metadata, literal_binds=True,\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_migrations_online():\n    app_conf = dci_config.generate_conf()\n    connectable = dci_config.get_engine(app_conf)\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()", "response": "Run migrations in online mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a 401 reject response that enables basic auth.", "response": "def reject():\n    \"\"\"Sends a 401 reject response that enables basic auth.\"\"\"\n\n    auth_message = ('Could not verify your access level for that URL.'\n                    'Please login with proper credentials.')\n    auth_message = json.dumps({'_status': 'Unauthorized',\n                               'message': auth_message})\n\n    headers = {'WWW-Authenticate': 'Basic realm=\"Login required\"'}\n    return flask.Response(auth_message, 401, headers=headers,\n                          content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies a contact. Returns status message Optional Parameters: * name -- Contact name Type: String * email -- Contact email address Type: String * cellphone -- Cellphone number, without the country code part. In some countries you are supposed to exclude leading zeroes. (Requires countrycode and countryiso) Type: String * countrycode -- Cellphone country code (Requires cellphone and countryiso) Type: String * countryiso -- Cellphone country ISO code. For example: US (USA), GB (Britain) or SE (Sweden) (Requires cellphone and countrycode) Type: String * defaultsmsprovider -- Default SMS provider Type: String ['clickatell', 'bulksms', 'esendex', 'cellsynt'] * directtwitter -- Send tweets as direct messages Type: Boolean Default: True * twitteruser -- Twitter user Type: String", "response": "def modify(self, **kwargs):\n        \"\"\"Modify a contact.\n\n        Returns status message\n\n        Optional Parameters:\n\n            * name -- Contact name\n                    Type: String\n\n            * email -- Contact email address\n                    Type: String\n\n            * cellphone -- Cellphone number, without the country code part. In\n                some countries you are supposed to exclude leading zeroes.\n                (Requires countrycode and countryiso)\n                    Type: String\n\n            * countrycode -- Cellphone country code (Requires cellphone and\n                countryiso)\n                    Type: String\n\n            * countryiso -- Cellphone country ISO code. For example: US (USA),\n                GB (Britain) or SE (Sweden) (Requires cellphone and\n                countrycode)\n                    Type: String\n\n            * defaultsmsprovider -- Default SMS provider\n                    Type: String ['clickatell', 'bulksms', 'esendex',\n                                  'cellsynt']\n\n            * directtwitter -- Send tweets as direct messages\n                    Type: Boolean\n                    Default: True\n\n            * twitteruser -- Twitter user\n                    Type: String\n        \"\"\"\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['email', 'cellphone', 'countrycode', 'countryiso',\n                           'defaultsmsprovider', 'directtwitter',\n                           'twitteruser', 'name']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument ' +\n                                 'of <PingdomContact>.modify()\\n')\n\n        response = self.pingdom.request('PUT', 'notification_contacts/%s' % self.id, kwargs)\n\n        return response.json()['message']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nestablishes a connection to the broker.", "response": "def _establish_connection(self, conn: BrokerConnection) -> None:\n        \"\"\"\n        We don't use a pool here. We only have one consumer connection per process, so\n        we get no value from a pool, and we want to use a heartbeat to keep the consumer\n        collection alive, which does not work with a pool\n        :return: the connection to the transport\n        \"\"\"\n        try:\n            self._logger.debug(\"Establishing connection.\")\n            self._conn = conn.ensure_connection(max_retries=3)\n            self._logger.debug('Got connection: %s', conn.as_uri())\n        except kombu_exceptions.OperationalError as oe:\n            self._logger.error(\"Error connecting to RMQ, could not retry %s\", oe)\n            # Try to clean up the mess\n            if self._conn is not None:\n                self._conn.close()\n            else:\n                conn.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_heartbeat_continuously(self) -> threading.Event:\n\n        cancellation_event = threading.Event()\n\n        # Effectively a no-op if we are not actually a long-running thread\n        if not self._is_long_running_handler:\n            return cancellation_event\n\n        self._logger.debug(\"Running long running handler on %s\", self._conn)\n\n        def _send_heartbeat(cnx: BrokerConnection, period: int, logger: logging.Logger) -> None:\n                while not cancellation_event.is_set():\n                    cnx.heartbeat_check()\n                    time.sleep(period)\n                logger.debug(\"Signalled to exit long-running handler heartbeat\")\n\n\n        heartbeat_thread = threading.Thread(target=_send_heartbeat, args=(self._conn, 1, self._logger), daemon=True)\n        self._logger.debug(\"Begin heartbeat thread for  %s\", self._conn)\n        heartbeat_thread.start()\n        self._logger.debug(\"Heartbeat running on thread for  %s\", self._conn)\n        return cancellation_event", "response": "Runs the heartbeat on the broker thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check(user, topic):\n    # if export_control then check the team is associated to the product, ie.:\n    #   - the current user belongs to the product's team\n    #   OR\n    #   - the product's team belongs to the user's parents teams\n    if topic['export_control']:\n        product = v1_utils.verify_existence_and_get(topic['product_id'],\n                                                    models.PRODUCTS)\n        return (user.is_in_team(product['team_id']) or\n                product['team_id'] in user.parent_teams_ids)\n    return False", "response": "Checks if the user is in the team of the product."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_stream_or_content_from_request(request):\n\n    if request.stream.tell():\n        logger.info('Request stream already consumed. '\n                    'Storing file content using in-memory data.')\n        return request.data\n\n    else:\n        logger.info('Storing file content using request stream.')\n        return request.stream", "response": "Checks if the stream is already consumed and if so returns the content from the request stream. If not returns improper value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning result of performing the given XPath query on the given node. All known namespace prefix-to-URI mappings in the document are automatically included in the XPath invocation. If an empty/default namespace (i.e. None) is defined, this is converted to the prefix name '_' so it can be used despite empty namespace prefixes being unsupported by XPath.", "response": "def xpath_on_node(self, node, xpath, **kwargs):\n        \"\"\"\n        Return result of performing the given XPath query on the given node.\n\n        All known namespace prefix-to-URI mappings in the document are\n        automatically included in the XPath invocation.\n\n        If an empty/default namespace (i.e. None) is defined, this is\n        converted to the prefix name '_' so it can be used despite empty\n        namespace prefixes being unsupported by XPath.\n        \"\"\"\n        if isinstance(node, etree._ElementTree):\n            # Document node lxml.etree._ElementTree has no nsmap, lookup root\n            root = self.get_impl_root(node)\n            namespaces_dict = root.nsmap.copy()\n        else:\n            namespaces_dict = node.nsmap.copy()\n        if 'namespaces' in kwargs:\n            namespaces_dict.update(kwargs['namespaces'])\n        # Empty namespace prefix is not supported, convert to '_' prefix\n        if None in namespaces_dict:\n            default_ns_uri = namespaces_dict.pop(None)\n            namespaces_dict['_'] = default_ns_uri\n        # Include XMLNS namespace if it's not already defined\n        if not 'xmlns' in namespaces_dict:\n            namespaces_dict['xmlns'] = nodes.Node.XMLNS_URI\n        return node.xpath(xpath, namespaces=namespaces_dict)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the given namespace name or value is defined in an ancestor of the given node.", "response": "def _is_ns_in_ancestor(self, node, name, value):\n        \"\"\"\n        Return True if the given namespace name/value is defined in an\n        ancestor of the given node, meaning that the given node need not\n        have its own attributes to apply that namespacing.\n        \"\"\"\n        curr_node = self.get_node_parent(node)\n        while curr_node.__class__ == etree._Element:\n            if (hasattr(curr_node, 'nsmap')\n                    and curr_node.nsmap.get(name) == value):\n                return True\n            for n, v in curr_node.attrib.items():\n                if v == value and '{%s}' % nodes.Node.XMLNS_URI in n:\n                    return True\n            curr_node = self.get_node_parent(curr_node)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds blog entries with the most comments: qs = generic_annotate(Entry.objects.public(), Comment.objects.public(), Count('comments__id')) for entry in qs: print entry.title, entry.score Find the highest rated foods: generic_annotate(Food, Rating, Avg('ratings__rating'), alias='avg') for food in qs: print food.name, '- average rating:', food.avg .. note:: In both of the above examples it is assumed that a GenericRelation exists on Entry to Comment (named \"comments\") and also on Food to Rating (named \"ratings\"). If a GenericRelation does *not* exist, the query will still return correct results but the code path will be different as it will use the fallback method. .. warning:: If the underlying column type differs between the qs_model's primary key and the generic_qs_model's foreign key column, it will use the fallback method, which can correctly CASTself. :param qs_model: A model or a queryset of objects you want to perform annotation on, e.g. blog entries :param generic_qs_model: A model or queryset containing a GFK, e.g. comments :param aggregator: an aggregation, from django.db.models, e.g. Count('id') or Avg('rating') :param gfk_field: explicitly specify the field w/the gfk :param alias: attribute name to use for annotation", "response": "def generic_annotate(qs_model, generic_qs_model, aggregator, gfk_field=None, alias='score'):\n    \"\"\"\n    Find blog entries with the most comments:\n    \n        qs = generic_annotate(Entry.objects.public(), Comment.objects.public(), Count('comments__id'))\n        for entry in qs:\n            print entry.title, entry.score\n    \n    Find the highest rated foods:\n    \n        generic_annotate(Food, Rating, Avg('ratings__rating'), alias='avg')\n        for food in qs:\n            print food.name, '- average rating:', food.avg\n    \n    .. note::\n        In both of the above examples it is assumed that a GenericRelation exists\n        on Entry to Comment (named \"comments\") and also on Food to Rating (named \"ratings\").\n        If a GenericRelation does *not* exist, the query will still return correct\n        results but the code path will be different as it will use the fallback method.\n    \n    .. warning::\n        If the underlying column type differs between the qs_model's primary\n        key and the generic_qs_model's foreign key column, it will use the fallback\n        method, which can correctly CASTself.\n    \n    :param qs_model: A model or a queryset of objects you want to perform\n        annotation on, e.g. blog entries\n    :param generic_qs_model: A model or queryset containing a GFK, e.g. comments\n    :param aggregator: an aggregation, from django.db.models, e.g. Count('id') or Avg('rating')\n    :param gfk_field: explicitly specify the field w/the gfk\n    :param alias: attribute name to use for annotation\n    \"\"\"\n    return fallback_generic_annotate(qs_model, generic_qs_model, aggregator, gfk_field, alias)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind total number of comments on blog entries: generic_aggregate(Entry.objects.public(), Comment.objects.public(), Count('comments__id')) Find the average rating for foods starting with 'a': a_foods = Food.objects.filter(name__startswith='a') generic_aggregate(a_foods, Rating, Avg('ratings__rating')) .. note:: In both of the above examples it is assumed that a GenericRelation exists on Entry to Comment (named \"comments\") and also on Food to Rating (named \"ratings\"). If a GenericRelation does *not* exist, the query will still return correct results but the code path will be different as it will use the fallback method. .. warning:: If the underlying column type differs between the qs_model's primary key and the generic_qs_model's foreign key column, it will use the fallback method, which can correctly CASTself. :param qs_model: A model or a queryset of objects you want to perform annotation on, e.g. blog entries :param generic_qs_model: A model or queryset containing a GFK, e.g. comments :param aggregator: an aggregation, from django.db.models, e.g. Count('id') or Avg('rating') :param gfk_field: explicitly specify the field w/the gfk", "response": "def generic_aggregate(qs_model, generic_qs_model, aggregator, gfk_field=None):\n    \"\"\"\n    Find total number of comments on blog entries:\n    \n        generic_aggregate(Entry.objects.public(), Comment.objects.public(), Count('comments__id'))\n    \n    Find the average rating for foods starting with 'a':\n    \n        a_foods = Food.objects.filter(name__startswith='a')\n        generic_aggregate(a_foods, Rating, Avg('ratings__rating'))\n    \n    .. note::\n        In both of the above examples it is assumed that a GenericRelation exists\n        on Entry to Comment (named \"comments\") and also on Food to Rating (named \"ratings\").\n        If a GenericRelation does *not* exist, the query will still return correct\n        results but the code path will be different as it will use the fallback method.\n    \n    .. warning::\n        If the underlying column type differs between the qs_model's primary\n        key and the generic_qs_model's foreign key column, it will use the fallback\n        method, which can correctly CASTself.\n\n    :param qs_model: A model or a queryset of objects you want to perform\n        annotation on, e.g. blog entries\n    :param generic_qs_model: A model or queryset containing a GFK, e.g. comments\n    :param aggregator: an aggregation, from django.db.models, e.g. Count('id') or Avg('rating')\n    :param gfk_field: explicitly specify the field w/the gfk\n    \"\"\"\n    return fallback_generic_aggregate(qs_model, generic_qs_model, aggregator, gfk_field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generic_filter(generic_qs_model, filter_qs_model, gfk_field=None):\n    generic_qs = normalize_qs_model(generic_qs_model)\n    filter_qs = normalize_qs_model(filter_qs_model)\n    \n    if not gfk_field:\n        gfk_field = get_gfk_field(generic_qs.model)\n    \n    pk_field_type = get_field_type(filter_qs.model._meta.pk)\n    gfk_field_type = get_field_type(generic_qs.model._meta.get_field(gfk_field.fk_field))\n    if pk_field_type != gfk_field_type:\n        return fallback_generic_filter(generic_qs, filter_qs, gfk_field)\n    \n    return generic_qs.filter(**{\n        gfk_field.ct_field: ContentType.objects.get_for_model(filter_qs.model),\n        '%s__in' % gfk_field.fk_field: filter_qs.values('pk'),\n    })", "response": "Filter the generic queryset to only show ratings made on entries that start with a"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating random etag based on MD5.", "response": "def gen_etag():\n    \"\"\"Generate random etag based on MD5.\"\"\"\n\n    my_salt = gen_uuid()\n    if six.PY2:\n        my_salt = my_salt.decode('utf-8')\n    elif six.PY3:\n        my_salt = my_salt.encode('utf-8')\n    md5 = hashlib.md5()\n    md5.update(my_salt)\n    return md5.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n\n        response = self.pingdom.request('DELETE',\n                                        'reports.shared/%s' % self.id)\n        return response.json()['message']", "response": "Delete this email report"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_multiple_of(ref):\n    def is_multiple_of_ref(x):\n        if x % ref == 0:\n            return True\n        else:\n            raise IsNotMultipleOf(wrong_value=x, ref=ref)\n            # raise Failure('x % {ref} == 0 does not hold for x={val}'.format(ref=ref, val=x))\n\n    is_multiple_of_ref.__name__ = 'is_multiple_of_{}'.format(ref)\n    return is_multiple_of_ref", "response": "Validates that x is a multiple of the reference."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all components of a topic.", "response": "def get_all_components(user, topic_id):\n    \"\"\"Get all components of a topic.\"\"\"\n\n    args = schemas.args(flask.request.args.to_dict())\n\n    query = v1_utils.QueryBuilder(_TABLE, args, _C_COLUMNS)\n\n    query.add_extra_condition(sql.and_(\n        _TABLE.c.topic_id == topic_id,\n        _TABLE.c.state != 'archived'))\n\n    nb_rows = query.get_number_of_rows()\n    rows = query.execute(fetchall=True)\n    rows = v1_utils.format_result(rows, _TABLE.name, args['embed'],\n                                  _EMBED_MANY)\n\n    # Return only the component which have the export_control flag set to true\n    #\n    if user.is_not_super_admin():\n        rows = [row for row in rows if row['export_control']]\n\n    return flask.jsonify({'components': rows, '_meta': {'count': nb_rows}})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the component types of a topic.", "response": "def get_component_types_from_topic(topic_id, db_conn=None):\n    \"\"\"Returns the component types of a topic.\"\"\"\n    db_conn = db_conn or flask.g.db_conn\n    query = sql.select([models.TOPICS]).\\\n        where(models.TOPICS.c.id == topic_id)\n    topic = db_conn.execute(query).fetchone()\n    topic = dict(topic)\n    return topic['component_types']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning either the topic component types or the rconfigration s component types.", "response": "def get_component_types(topic_id, remoteci_id, db_conn=None):\n    \"\"\"Returns either the topic component types or the rconfigration's\n    component types.\"\"\"\n\n    db_conn = db_conn or flask.g.db_conn\n    rconfiguration = remotecis.get_remoteci_configuration(topic_id,\n                                                          remoteci_id,\n                                                          db_conn=db_conn)\n\n    # if there is no rconfiguration associated to the remoteci or no\n    # component types then use the topic's one.\n    if (rconfiguration is not None and\n            rconfiguration['component_types'] is not None):\n        component_types = rconfiguration['component_types']\n    else:\n        component_types = get_component_types_from_topic(topic_id,\n                                                         db_conn=db_conn)\n\n    return component_types, rconfiguration"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the last set of components of a given type of a topic.", "response": "def get_last_components_by_type(component_types, topic_id, db_conn=None):\n    \"\"\"For each component type of a topic, get the last one.\"\"\"\n    db_conn = db_conn or flask.g.db_conn\n    schedule_components_ids = []\n    for ct in component_types:\n        where_clause = sql.and_(models.COMPONENTS.c.type == ct,\n                                models.COMPONENTS.c.topic_id == topic_id,\n                                models.COMPONENTS.c.export_control == True,\n                                models.COMPONENTS.c.state == 'active')  # noqa\n        query = (sql.select([models.COMPONENTS.c.id])\n                 .where(where_clause)\n                 .order_by(sql.desc(models.COMPONENTS.c.created_at)))\n        cmpt_id = db_conn.execute(query).fetchone()\n\n        if cmpt_id is None:\n            msg = 'Component of type \"%s\" not found or not exported.' % ct\n            raise dci_exc.DCIException(msg, status_code=412)\n\n        cmpt_id = cmpt_id[0]\n        if cmpt_id in schedule_components_ids:\n            msg = ('Component types %s malformed: type %s duplicated.' %\n                   (component_types, ct))\n            raise dci_exc.DCIException(msg, status_code=412)\n        schedule_components_ids.append(cmpt_id)\n    return schedule_components_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_and_get_components_ids(topic_id, components_ids, component_types,\n                                  db_conn=None):\n    \"\"\"Process some verifications of the provided components ids.\"\"\"\n    db_conn = db_conn or flask.g.db_conn\n    if len(components_ids) != len(component_types):\n        msg = 'The number of component ids does not match the number ' \\\n              'of component types %s' % component_types\n        raise dci_exc.DCIException(msg, status_code=412)\n\n    # get the components from their ids\n    schedule_component_types = set()\n    for c_id in components_ids:\n        where_clause = sql.and_(models.COMPONENTS.c.id == c_id,\n                                models.COMPONENTS.c.topic_id == topic_id,\n                                models.COMPONENTS.c.export_control == True,  # noqa\n                                models.COMPONENTS.c.state == 'active')\n        query = (sql.select([models.COMPONENTS])\n                 .where(where_clause))\n        cmpt = db_conn.execute(query).fetchone()\n\n        if cmpt is None:\n            msg = 'Component id %s not found or not exported' % c_id\n            raise dci_exc.DCIException(msg, status_code=412)\n        cmpt = dict(cmpt)\n\n        if cmpt['type'] in schedule_component_types:\n            msg = ('Component types malformed: type %s duplicated.' %\n                   cmpt['type'])\n            raise dci_exc.DCIException(msg, status_code=412)\n        schedule_component_types.add(cmpt['type'])\n    return components_ids", "response": "Verify that the provided components ids are valid and return the list of components ids that are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retrieve_tags_from_component(user, c_id):\n    JCT = models.JOIN_COMPONENTS_TAGS\n    query = (sql.select([models.TAGS])\n             .select_from(JCT.join(models.TAGS))\n             .where(JCT.c.component_id == c_id))\n    rows = flask.g.db_conn.execute(query)\n\n    return flask.jsonify({'tags': rows, '_meta': {'count': rows.rowcount}})", "response": "Retrieve all tags attached to a component."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tag_for_component(user, c_id):\n\n    v1_utils.verify_existence_and_get(c_id, _TABLE)\n\n    values = {\n        'component_id': c_id\n    }\n\n    component_tagged = tags.add_tag_to_resource(values,\n                                                models.JOIN_COMPONENTS_TAGS)\n\n    return flask.Response(json.dumps(component_tagged), 201,\n                          content_type='application/json')", "response": "Add a tag on a specific component."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_tag_for_component(user, c_id, tag_id):\n    # Todo : check c_id and tag_id exist in db\n\n    query = _TABLE_TAGS.delete().where(_TABLE_TAGS.c.tag_id == tag_id and\n                                       _TABLE_TAGS.c.component_id == c_id)\n\n    try:\n        flask.g.db_conn.execute(query)\n    except sa_exc.IntegrityError:\n        raise dci_exc.DCICreationConflict(_TABLE_TAGS.c.tag_id, 'tag_id')\n\n    return flask.Response(None, 204, content_type='application/json')", "response": "Delete a tag on a specific component."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef should_be_hidden_as_cause(exc):\n    # reduced traceback in case of HasWrongType (instance_of checks)\n    from valid8.validation_lib.types import HasWrongType, IsWrongType\n    return isinstance(exc, (HasWrongType, IsWrongType))", "response": "Used everywhere to decide if some exception type should be hidden as cause of an error"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_error_of_type(exc, ref_type):\n    if isinstance(exc, ref_type):\n        return True\n    elif hasattr(exc, '__cause__') and exc.__cause__ is not None:\n        return is_error_of_type(exc.__cause__, ref_type)", "response": "Helper function to determine if some exception is of some type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _failure_raiser(validation_callable,   # type: Callable\n                    failure_type=None,     # type: Type[WrappingFailure]\n                    help_msg=None,         # type: str\n                    **kw_context_args):\n    # type: (...) -> Callable\n    \"\"\"\n    Wraps the provided validation function so that in case of failure it raises the given failure_type or a WrappingFailure\n    with the given help message.\n\n    :param validation_callable:\n    :param failure_type: an optional subclass of `WrappingFailure` that should be raised in case of failure, instead of\n    `WrappingFailure`.\n    :param help_msg: an optional string help message for the raised `WrappingFailure` (if no failure_type is provided)\n    :param kw_context_args: optional context arguments for the custom failure message\n    :return:\n    \"\"\"\n\n    # check failure type\n    if failure_type is not None and help_msg is not None:\n        raise ValueError('Only one of failure_type and help_msg can be set at the same time')\n\n    # convert mini-lambdas to functions if needed\n    validation_callable = as_function(validation_callable)\n\n    # create wrapper\n    # option (a) use the `decorate()` helper method to preserve name and signature of the inner object\n    # ==> NO, we want to support also non-function callable objects\n\n    # option (b) simply create a wrapper manually\n    def raiser(x):\n        \"\"\" Wraps validation_callable to raise a failure_type_or_help_msg in case of failure \"\"\"\n\n        try:\n            # perform validation\n            res = validation_callable(x)\n\n        except Exception as e:\n            # no need to raise from e since the __cause__ is already set in the constructor: we can safely commonalize\n            res = e\n\n        if not result_is_success(res):\n            typ = failure_type or WrappingFailure\n            exc = typ(wrapped_func=validation_callable, wrong_value=x, validation_outcome=res,\n                      help_msg=help_msg, **kw_context_args)\n            raise exc\n\n    # set a name so that the error messages are more user-friendly\n\n    # NO, Do not include the callable type or error message in the name since it is only used in error messages where\n    # they will appear anyway !\n    # ---\n    # if help_msg or failure_type:\n    #     raiser.__name__ = 'failure_raiser({}, {})'.format(get_callable_name(validation_callable),\n    #                                                       help_msg or failure_type.__name__)\n    # else:\n    # ---\n    # raiser.__name__ = 'failure_raiser({})'.format(get_callable_name(validation_callable))\n    raiser.__name__ = get_callable_name(validation_callable)\n    # Note: obviously this can hold as long as we do not check the name of this object in any other context than\n    # raising errors. If we want to support this, then creating a callable object with everything in the fields will be\n    # probably more appropriate so that error messages will be able to display the inner name, while repr() will still\n    # say that this is a failure raiser.\n    # TODO consider transforming failure_raiser into a class (see comment above)\n\n    return raiser", "response": "A function that wraps a validation function so that in case of failure it raises a given failure_type or a WrappingFailure\nWorkItem with the given help message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a validation callable that accepts None values silently.", "response": "def _none_accepter(validation_callable  # type: Callable\n                   ):\n    # type: (...) -> Callable\n    \"\"\"\n    Wraps the given validation callable to accept None values silently. When a None value is received by the wrapper,\n    it is not passed to the validation_callable and instead this function will return True. When any other value is\n    received the validation_callable is called as usual.\n\n    Note: the created wrapper has the same same than the validation callable for more user-friendly error messages\n\n    :param validation_callable:\n    :return:\n    \"\"\"\n    # option (a) use the `decorate()` helper method to preserve name and signature of the inner object\n    # ==> NO, we want to support also non-function callable objects\n\n    # option (b) simply create a wrapper manually\n    def accept_none(x):\n        if x is not None:\n            # proceed with validation as usual\n            return validation_callable(x)\n        else:\n            # value is None: skip validation\n            return True\n\n    # set a name so that the error messages are more user-friendly\n    accept_none.__name__ = 'skip_on_none({})'.format(get_callable_name(validation_callable))\n\n    return accept_none"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a validation callable that rejects None values.", "response": "def _none_rejecter(validation_callable  # type: Callable\n                   ):\n    # type: (...) -> Callable\n    \"\"\"\n    Wraps the given validation callable to reject None values. When a None value is received by the wrapper,\n    it is not passed to the validation_callable and instead this function will raise a WrappingFailure. When any other value is\n    received the validation_callable is called as usual.\n\n    :param validation_callable:\n    :return:\n    \"\"\"\n    # option (a) use the `decorate()` helper method to preserve name and signature of the inner object\n    # ==> NO, we want to support also non-function callable objects\n\n    # option (b) simply create a wrapper manually\n    def reject_none(x):\n        if x is not None:\n            return validation_callable(x)\n        else:\n            raise ValueIsNone(wrong_value=x)\n\n    # set a name so that the error messages are more user-friendly ==> NO ! here we want to see the checker\n    reject_none.__name__ = 'reject_none({})'.format(get_callable_name(validation_callable))\n\n    return reject_none"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_details(self):\n        strval = str(self.wrong_value)\n        if len(strval) > self.__max_str_length_displayed__:\n            return '(Actual value is too big to be printed in this message)'\n        else:\n            return 'Wrong value: [{}]'.format(self.wrong_value)", "response": "Returns the details of the current value of the class attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string describing the function and outcome", "response": "def get_details(self):\n        \"\"\" Overrides the method in Failure so as to add a few details about the wrapped function and outcome \"\"\"\n\n        if isinstance(self.validation_outcome, Exception):\n            if isinstance(self.validation_outcome, Failure):\n                # do not say again what was the value, it is already mentioned inside :)\n                end_str = ''\n            else:\n                end_str = ' for value [{value}]'.format(value=self.wrong_value)\n\n            contents = 'Function [{wrapped}] raised [{exception}: {details}]{end}.' \\\n                       ''.format(wrapped=get_callable_name(self.wrapped_func),\n                                 exception=type(self.validation_outcome).__name__, details=self.validation_outcome,\n                                 end=end_str)\n        else:\n            contents = 'Function [{wrapped}] returned [{result}] for value [{value}].' \\\n                       ''.format(wrapped=get_callable_name(self.wrapped_func), result=self.validation_outcome,\n                                 value=self.wrong_value)\n\n        return contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context_for_help_msgs(self, context_dict):\n        context_dict = copy(context_dict)\n        context_dict['wrapped_func'] = get_callable_name(context_dict['wrapped_func'])\n        return context_dict", "response": "This method is used to get the context dictionary for the help msgs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_arg(f,\n                 arg_name,\n                 *validation_func,  # type: ValidationFuncs\n                 **kwargs\n                 ):\n    # type: (...) -> Callable\n    \"\"\"\n    A decorator to apply function input validation for the given argument name, with the provided base validation\n    function(s). You may use several such decorators on a given function as long as they are stacked on top of each\n    other (no external decorator in the middle)\n\n    :param arg_name:\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n        tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n        are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n        `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n        of callables, they will be transformed to functions automatically.\n    :param error_type: a subclass of ValidationError to raise in case of validation failure. By default a\n        ValidationError will be raised with the provided help_msg\n    :param help_msg: an optional help message to be used in the raised error in case of validation failure.\n    :param none_policy: describes how None values should be handled. See `NoneArgPolicy` for the various\n        possibilities. Default is `NoneArgPolicy.ACCEPT_IF_OPTIONAl_ELSE_VALIDATE`.\n    :param kw_context_args: optional contextual information to store in the exception, and that may be also used\n        to format the help message\n    :return: a function decorator, able to transform a function into a function that will perform input validation\n        before executing the function's code everytime it is executed.\n    \"\"\"\n    return decorate_with_validation(f, arg_name, *validation_func, **kwargs)", "response": "Decorator to apply function input validation for the given argument name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_out(*validation_func,  # type: ValidationFuncs\n                 **kwargs):\n    # type: (...) -> Callable\n    \"\"\"\n    A decorator to apply function output validation to this function's output, with the provided base validation\n    function(s). You may use several such decorators on a given function as long as they are stacked on top of each\n    other (no external decorator in the middle)\n\n    :param validation_func: the base validation function or list of base validation functions to use. A callable, a\n    tuple(callable, help_msg_str), a tuple(callable, failure_type), or a list of several such elements. Nested lists\n    are supported and indicate an implicit `and_` (such as the main list). Tuples indicate an implicit\n    `_failure_raiser`. [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead\n    of callables, they will be transformed to functions automatically.\n    :param none_policy: describes how None values should be handled. See `NoneArgPolicy` for the various\n    possibilities. Default is `NoneArgPolicy.ACCEPT_IF_OPTIONAl_ELSE_VALIDATE`.\n    :return: a function decorator, able to transform a function into a function that will perform input validation\n    before executing the function's code everytime it is executed.\n    \"\"\"\n    def decorate(f):\n        return decorate_with_validation(f, _OUT_KEY, *validation_func, **kwargs)\n    return decorate", "response": "Decorator to apply function output validation to this function s output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decorate_cls_with_validation(cls,\n                                 field_name,        # type: str\n                                 *validation_func,  # type: ValidationFuncs\n                                 **kwargs):\n    # type: (...) -> Type[Any]\n    \"\"\"\n    This method is equivalent to decorating a class with the `@validate_field` decorator but can be used a posteriori.\n\n    :param cls: the class to decorate\n    :param field_name: the name of the argument to validate or _OUT_KEY for output validation\n    :param validation_func: the validation function or\n        list of validation functions to use. A validation function may be a callable, a tuple(callable, help_msg_str),\n        a tuple(callable, failure_type), or a list of several such elements. Nested lists are supported and indicate an\n        implicit `and_` (such as the main list). Tuples indicate an implicit `_failure_raiser`.\n        [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead of callables, they\n        will be transformed to functions automatically.\n    :param error_type: a subclass of ValidationError to raise in case of validation failure. By default a\n        ValidationError will be raised with the provided help_msg\n    :param help_msg: an optional help message to be used in the raised error in case of validation failure.\n    :param none_policy: describes how None values should be handled. See `NoneArgPolicy` for the various possibilities.\n        Default is `NoneArgPolicy.ACCEPT_IF_OPTIONAl_ELSE_REJECT`.\n    :param kw_context_args: optional contextual information to store in the exception, and that may be also used\n        to format the help message\n    :return: the decorated function, that will perform input validation (using `_assert_input_is_valid`) before\n        executing the function's code everytime it is executed.\n    \"\"\"\n    error_type, help_msg, none_policy = pop_kwargs(kwargs, [('error_type', None),\n                                                            ('help_msg', None),\n                                                            ('none_policy', None)], allow_others=True)\n    # the rest of keyword arguments is used as context.\n    kw_context_args = kwargs\n\n    if not isclass(cls):\n        raise TypeError('decorated cls should be a class')\n\n    if hasattr(cls, field_name):\n        # ** A class field with that name exist. Is it a descriptor ?\n\n        var = cls.__dict__[field_name]  # note: we cannot use getattr here\n\n        if hasattr(var, '__set__') and callable(var.__set__):\n\n            if isinstance(var, property):\n                # *** OLD WAY which was losing type hints and default values (see var.__set__ signature) ***\n                # properties are special beasts: their methods are method-wrappers (CPython) and can not have properties\n                # so we have to create a wrapper (sic) before sending it to the main wrapping function\n                # def func(inst, value):\n                #     var.__set__(inst, value)\n\n                # *** NEW WAY : more elegant, use directly the setter provided by the user ***\n                func = var.fset\n                nb_args = 2\n            elif ismethod(var.__set__):\n                # bound method: normal. Let's access to the underlying function\n                func = var.__set__.__func__\n                nb_args = 3\n            else:\n                # strange.. but lets try to continue\n                func = var.__set__\n                nb_args = 3\n\n            # retrieve target function signature, check it and retrieve the 3d param\n            # since signature is \"def __set__(self, obj, val)\"\n            func_sig = signature(func)\n            if len(func_sig.parameters) != nb_args:\n                raise ValueError(\"Class field '{}' is a valid class descriptor for class '{}' but it does not implement\"\n                                 \" __set__ with the correct number of parameters, so it is not possible to add \"\n                                 \"validation to it. See https://docs.python.org/3.6/howto/descriptor.html\".\n                                 format(field_name, cls.__name__))\n            # extract the correct name\n            descriptor_arg_name = list(func_sig.parameters.items())[-1][0]\n\n            # do the same than in decorate_with_validation but with a class field validator\n            # new_setter = decorate_with_validation(func, descriptor_arg_name, *validation_func, help_msg=help_msg,\n            #                                       error_type=error_type, none_policy=none_policy,\n            #                                       _clazz_field_name_=field_name, **kw_context_args)\n\n            # --create the new validator\n            none_policy = none_policy or NoneArgPolicy.SKIP_IF_NONABLE_ELSE_VALIDATE\n            new_validator = _create_function_validator(func, func_sig, descriptor_arg_name, *validation_func,\n                                                       none_policy=none_policy, error_type=error_type,\n                                                       help_msg=help_msg,\n                                                       validated_class=cls, validated_class_field_name=field_name,\n                                                       **kw_context_args)\n\n            # -- create the new setter with validation\n            new_setter = decorate_with_validators(func, func_signature=func_sig, **{descriptor_arg_name: new_validator})\n\n            # replace the old one\n            if isinstance(var, property):\n                # properties are special beasts 2\n                setattr(cls, field_name, var.setter(new_setter))\n            else:\n                # do not use type() for python 2 compat\n                var.__class__.__set__ = new_setter\n\n        elif (hasattr(var, '__get__') and callable(var.__get__)) \\\n            or (hasattr(var, '__delete__') and callable(var.__delete__)):\n            # this is a descriptor but it does not have any setter method: impossible to validate\n            raise ValueError(\"Class field '{}' is a valid class descriptor for class '{}' but it does not implement \"\n                             \"__set__ so it is not possible to add validation to it. See \"\n                             \"https://docs.python.org/3.6/howto/descriptor.html\".format(field_name, cls.__name__))\n\n        else:\n            # this is not a descriptor: unsupported\n            raise ValueError(\"Class field '{}.{}' is not a valid class descriptor, see \"\n                             \"https://docs.python.org/3.6/howto/descriptor.html\".format(cls.__name__, field_name))\n\n    else:\n        # ** No class field with that name exist\n\n        # ? check for attrs ? > no specific need anymore, this is the same than annotating the constructor\n        # if hasattr(cls, '__attrs_attrs__'): this was a proof of attrs-defined class\n\n        # try to annotate the generated constructor\n        try:\n            init_func = cls.__init__\n            if sys.version_info < (3, 0):\n                try:\n                    # python 2 - we have to access the inner `im_func`\n                    init_func = cls.__init__.im_func\n                except AttributeError:\n                    pass\n\n            cls.__init__ = decorate_with_validation(init_func, field_name, *validation_func, help_msg=help_msg,\n                                                    _constructor_of_cls_=cls,\n                                                    error_type=error_type, none_policy=none_policy, **kw_context_args)\n\n        except InvalidNameError:\n            # the field was not found\n\n            # TODO should we also check if a __setattr__ is defined ?\n            # (for __setattr__ see https://stackoverflow.com/questions/15750522/class-properties-and-setattr/15751159)\n\n            # finally raise an error\n            raise ValueError(\"@validate_field definition exception: field '{}' can not be found in class '{}', and it \"\n                             \"is also not an input argument of the __init__ method.\".format(field_name, cls.__name__))\n\n    return cls", "response": "This method is used to decorate a class with the validation function. It is equivalent to the function that will perform input validation on the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decorate_several_with_validation(func,\n                                     _out_=None,         # type: ValidationFuncs\n                                     none_policy=None,   # type: int\n                                     **validation_funcs  # type: ValidationFuncs\n                                     ):\n    # type: (...) -> Callable\n    \"\"\"\n    This method is equivalent to applying `decorate_with_validation` once for each of the provided arguments of\n    the function `func` as well as output `_out_`. validation_funcs keyword arguments are validation functions for each\n    arg name.\n\n    Note that this method is less flexible than decorate_with_validation since\n     * it does not allow to associate a custom error message or error type with each validation.\n     * the none_policy is the same for all inputs and outputs\n\n    :param func:\n    :param _out_:\n    :param validation_funcs:\n    :param none_policy:\n    :return: a function decorated with validation for all of the listed arguments and output if provided.\n    \"\"\"\n\n    # add validation for output if provided\n    if _out_ is not None:\n        func = decorate_with_validation(func, _OUT_KEY, _out_, none_policy=none_policy)\n\n    # add validation for each of the listed arguments\n    for att_name, att_validation_funcs in validation_funcs.items():\n        func = decorate_with_validation(func, att_name, att_validation_funcs, none_policy=none_policy)\n\n    return func", "response": "Decorate a function with validation for all of the provided arguments and output."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decorate_with_validation(func,\n                             arg_name,          # type: str\n                             *validation_func,  # type: ValidationFuncs\n                             **kwargs):\n    # type: (...) -> Callable\n    \"\"\"\n    This method is the inner method used in `@validate_io`, `@validate_arg` and `@validate_out`.\n    It can be used if you with to perform decoration manually without a decorator.\n\n    :param func:\n    :param arg_name: the name of the argument to validate or _OUT_KEY for output validation\n    :param validation_func: the validation function or\n        list of validation functions to use. A validation function may be a callable, a tuple(callable, help_msg_str),\n        a tuple(callable, failure_type), or a list of several such elements. Nested lists are supported and indicate an\n        implicit `and_` (such as the main list). Tuples indicate an implicit `_failure_raiser`.\n        [mini_lambda](https://smarie.github.io/python-mini-lambda/) expressions can be used instead of callables, they\n        will be transformed to functions automatically.\n    :param error_type: a subclass of ValidationError to raise in case of validation failure. By default a\n        ValidationError will be raised with the provided help_msg\n    :param help_msg: an optional help message to be used in the raised error in case of validation failure.\n    :param none_policy: describes how None values should be handled. See `NoneArgPolicy` for the various possibilities.\n        Default is `NoneArgPolicy.ACCEPT_IF_OPTIONAl_ELSE_REJECT`.\n    :param kw_context_args: optional contextual information to store in the exception, and that may be also used\n        to format the help message\n    :return: the decorated function, that will perform input validation (using `_assert_input_is_valid`) before\n        executing the function's code everytime it is executed.\n    \"\"\"\n    error_type, help_msg, none_policy, _constructor_of_cls_ = pop_kwargs(kwargs, [('error_type', None),\n                                                                                  ('help_msg', None),\n                                                                                  ('none_policy', None),\n                                                                                  ('_constructor_of_cls_', None)],\n                                                                         allow_others=True)\n    # the rest of keyword arguments is used as context.\n    kw_context_args = kwargs\n\n    none_policy = none_policy or NoneArgPolicy.SKIP_IF_NONABLE_ELSE_VALIDATE\n\n    # retrieve target function signature\n    func_sig = signature(func)\n\n    # create the new validator\n    if _constructor_of_cls_ is None:\n        # standard method: input validator\n        new_validator = _create_function_validator(func, func_sig, arg_name, *validation_func,\n                                                   none_policy=none_policy, error_type=error_type,\n                                                   help_msg=help_msg, **kw_context_args)\n    else:\n        # class constructor: field validator\n        new_validator = _create_function_validator(func, func_sig, arg_name, *validation_func,\n                                                   none_policy=none_policy, error_type=error_type,\n                                                   help_msg=help_msg, validated_class=_constructor_of_cls_,\n                                                   validated_class_field_name=arg_name,\n                                                   **kw_context_args)\n\n    # decorate or update decorator with this new validator\n    return decorate_with_validators(func, func_signature=func_sig, **{arg_name: new_validator})", "response": "Decorate a function with input validation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the final NonePolicy that is used for validation.", "response": "def _get_final_none_policy_for_validator(is_nonable,   # type: bool\n                                         none_policy   # type: NoneArgPolicy\n                                         ):\n    \"\"\"\n    Depending on none_policy and of the fact that the target parameter is nonable or not, returns a corresponding\n    NonePolicy\n\n    :param is_nonable:\n    :param none_policy:\n    :return:\n    \"\"\"\n    if none_policy in {NonePolicy.VALIDATE, NonePolicy.SKIP, NonePolicy.FAIL}:\n        none_policy_to_use = none_policy\n\n    elif none_policy is NoneArgPolicy.SKIP_IF_NONABLE_ELSE_VALIDATE:\n        none_policy_to_use = NonePolicy.SKIP if is_nonable else NonePolicy.VALIDATE\n\n    elif none_policy is NoneArgPolicy.SKIP_IF_NONABLE_ELSE_FAIL:\n        none_policy_to_use = NonePolicy.SKIP if is_nonable else NonePolicy.FAIL\n\n    else:\n        raise ValueError('Invalid none policy: ' + str(none_policy))\n    return none_policy_to_use"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decorate_with_validators(func,\n                             func_signature=None,  # type: Signature\n                             **validators          # type: Validator\n                             ):\n    \"\"\"\n    Utility method to decorate the provided function with the provided input and output Validator objects. Since this\n    method takes Validator objects as argument, it is for advanced users.\n\n    :param func: the function to decorate. It might already be decorated, this method will check it and wont create\n    another wrapper in this case, simply adding the validators to the existing wrapper\n    :param func_signature: the function's signature if it is already known (internal calls), otherwise it will be found\n    again by inspection\n    :param validators: a dictionary of arg_name (or _out_) => Validator or list of Validator\n    :return:\n    \"\"\"\n    # first turn the dictionary values into lists only\n    for arg_name, validator in validators.items():\n        if not isinstance(validator, list):\n            validators[arg_name] = [validator]\n\n    if hasattr(func, '__wrapped__') and hasattr(func.__wrapped__, '__validators__'):\n        # ---- This function is already wrapped by our validation wrapper ----\n\n        # Update the dictionary of validators with the new validator(s)\n        for arg_name, validator in validators.items():\n            for v in validator:\n                if arg_name in func.__wrapped__.__validators__:\n                    func.__wrapped__.__validators__[arg_name].append(v)\n                else:\n                    func.__wrapped__.__validators__[arg_name] = [v]\n\n        # return the function, no need to wrap it further (it is already wrapped)\n        return func\n\n    else:\n        # ---- This function is not yet wrapped by our validator. ----\n\n        # Store the dictionary of validators as an attribute of the function\n        if hasattr(func, '__validators__'):\n            raise ValueError('Function ' + str(func) + ' already has a defined __validators__ attribute, valid8 '\n                             'decorators can not be applied on it')\n        else:\n            try:\n                func.__validators__ = validators\n            except AttributeError:\n                raise ValueError(\"Error - Could not add validators list to function '%s'\" % func)\n\n        # either reuse or recompute function signature\n        func_signature = func_signature or signature(func)\n\n        # create a wrapper with the same signature\n        @wraps(func)\n        def validating_wrapper(*args, **kwargs):\n            \"\"\" This is the wrapper that will be called everytime the function is called \"\"\"\n\n            # (a) Perform input validation by applying `_assert_input_is_valid` on all received arguments\n            apply_on_each_func_args_sig(func, args, kwargs, func_signature,\n                                        func_to_apply=_assert_input_is_valid,\n                                        func_to_apply_params_dict=func.__validators__)\n\n            # (b) execute the function as usual\n            res = func(*args, **kwargs)\n\n            # (c) validate output if needed\n            if _OUT_KEY in func.__validators__:\n                for validator in func.__validators__[_OUT_KEY]:\n                    validator.assert_valid(res)\n\n            return res\n\n        return validating_wrapper", "response": "This method is used to decorate a function with input and output Validator objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls by the `validating_wrapper` in the first step (a) `apply_on_each_func_args` for each function input before executing the function. It simply delegates to the validator. The signature of this function is hardcoded to correspond to `apply_on_each_func_args`'s behaviour and should therefore not be changed. :param input_value: the value to validate :param validator: the Validator object that will be applied on input_value_to_validate :param validated_func: the function for which this validation is performed. This is not used since the Validator knows it already, but we should not change the signature here. :param input_name: the name of the function input that is being validated :return: Nothing", "response": "def _assert_input_is_valid(input_value,     # type: Any\n                           validators,      # type: List[InputValidator]\n                           validated_func,  # type: Callable\n                           input_name       # type: str\n                           ):\n    \"\"\"\n    Called by the `validating_wrapper` in the first step (a) `apply_on_each_func_args` for each function input before\n    executing the function. It simply delegates to the validator. The signature of this function is hardcoded to\n    correspond to `apply_on_each_func_args`'s behaviour and should therefore not be changed.\n\n    :param input_value: the value to validate\n    :param validator: the Validator object that will be applied on input_value_to_validate\n    :param validated_func: the function for which this validation is performed. This is not used since the Validator\n        knows it already, but we should not change the signature here.\n    :param input_name: the name of the function input that is being validated\n    :return: Nothing\n    \"\"\"\n    for validator in validators:\n        validator.assert_valid(input_name, input_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string that can be used to display the input variable and the function name.", "response": "def get_what_txt(self):\n        \"\"\"\n        Overrides the base behaviour defined in ValidationError in order to add details about the function.\n        :return:\n        \"\"\"\n        return 'input [{var}] for function [{func}]'.format(var=self.get_variable_str(),\n                                                            func=self.validator.get_validated_func_display_name())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string that can be used to display the field name for the class.", "response": "def get_what_txt(self):\n        \"\"\"\n        Overrides the base behaviour defined in ValidationError in order to add details about the class field.\n        :return:\n        \"\"\"\n        return 'field [{field}] for class [{clazz}]'.format(field=self.get_variable_str(),\n                                                            clazz=self.validator.get_validated_class_display_name())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_nonce_timestamp():\n    global count\n    rng = botan.rng().get(30)\n    uuid4 = uuid.uuid4().bytes  # 16 byte\n    tmpnonce = (bytes(str(count).encode('utf-8'))) + uuid4 + rng\n    nonce = tmpnonce[:41]  # 41 byte (328 bit)\n    count += 1\n    return nonce", "response": "Generate unique nonce with counter uuid and rng."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schedule_jobs(user):\n\n    values = schemas.job_schedule.post(flask.request.json)\n\n    values.update({\n        'id': utils.gen_uuid(),\n        'created_at': datetime.datetime.utcnow().isoformat(),\n        'updated_at': datetime.datetime.utcnow().isoformat(),\n        'etag': utils.gen_etag(),\n        'status': 'new',\n        'remoteci_id': user.id,\n        'user_agent': flask.request.environ.get('HTTP_USER_AGENT'),\n        'client_version': flask.request.environ.get(\n            'HTTP_CLIENT_VERSION'\n        ),\n    })\n\n    topic_id = values.pop('topic_id')\n    topic_id_secondary = values.pop('topic_id_secondary')\n    components_ids = values.pop('components_ids')\n\n    # check remoteci\n    remoteci = v1_utils.verify_existence_and_get(user.id, models.REMOTECIS)\n    if remoteci['state'] != 'active':\n        message = 'RemoteCI \"%s\" is disabled.' % remoteci['id']\n        raise dci_exc.DCIException(message, status_code=412)\n\n    # check primary topic\n    topic = v1_utils.verify_existence_and_get(topic_id, models.TOPICS)\n    if topic['state'] != 'active':\n        msg = 'Topic %s:%s not active.' % (topic_id, topic['name'])\n        raise dci_exc.DCIException(msg, status_code=412)\n    v1_utils.verify_team_in_topic(user, topic_id)\n\n    # check secondary topic\n    if topic_id_secondary:\n        topic_secondary = v1_utils.verify_existence_and_get(\n            topic_id_secondary, models.TOPICS)\n        if topic_secondary['state'] != 'active':\n            msg = 'Topic %s:%s not active.' % (topic_id_secondary,\n                                               topic['name'])\n            raise dci_exc.DCIException(msg, status_code=412)\n        v1_utils.verify_team_in_topic(user, topic_id_secondary)\n\n    dry_run = values.pop('dry_run')\n    if dry_run:\n        component_types = components.get_component_types_from_topic(topic_id)\n        components_ids = components.get_last_components_by_type(\n            component_types,\n            topic_id\n        )\n        return flask.Response(\n            json.dumps({'components_ids': components_ids, 'job': None}),\n            201,\n            content_type='application/json'\n        )\n\n    remotecis.kill_existing_jobs(remoteci['id'])\n\n    values = _build_job(topic_id, remoteci, components_ids, values,\n                        topic_id_secondary=topic_id_secondary)\n\n    return flask.Response(json.dumps({'job': values}), 201,\n                          headers={'ETag': values['etag']},\n                          content_type='application/json')", "response": "Dispatch jobs to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_new_update_job_from_an_existing_job(user, job_id):\n\n    values = {\n        'id': utils.gen_uuid(),\n        'created_at': datetime.datetime.utcnow().isoformat(),\n        'updated_at': datetime.datetime.utcnow().isoformat(),\n        'etag': utils.gen_etag(),\n        'status': 'new'\n    }\n\n    original_job_id = job_id\n    original_job = v1_utils.verify_existence_and_get(original_job_id,\n                                                     models.JOBS)\n\n    if not user.is_in_team(original_job['team_id']):\n        raise dci_exc.Unauthorized()\n\n    # get the remoteci\n    remoteci_id = str(original_job['remoteci_id'])\n    remoteci = v1_utils.verify_existence_and_get(remoteci_id,\n                                                 models.REMOTECIS)\n    values.update({'remoteci_id': remoteci_id})\n\n    # get the associated topic\n    topic_id = str(original_job['topic_id'])\n    v1_utils.verify_existence_and_get(topic_id, models.TOPICS)\n\n    values.update({\n        'user_agent': flask.request.environ.get('HTTP_USER_AGENT'),\n        'client_version': flask.request.environ.get(\n            'HTTP_CLIENT_VERSION'\n        ),\n    })\n\n    values = _build_job(topic_id, remoteci, [], values,\n                        update_previous_job_id=original_job_id)\n\n    return flask.Response(json.dumps({'job': values}), 201,\n                          headers={'ETag': values['etag']},\n                          content_type='application/json')", "response": "Create a new job in the same topic as the job_id provided and return the updated job."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new job in the next topic of the topic of the provided job_id.", "response": "def create_new_upgrade_job_from_an_existing_job(user):\n    \"\"\"Create a new job in the 'next topic' of the topic of\n    the provided job_id.\"\"\"\n    values = schemas.job_upgrade.post(flask.request.json)\n\n    values.update({\n        'id': utils.gen_uuid(),\n        'created_at': datetime.datetime.utcnow().isoformat(),\n        'updated_at': datetime.datetime.utcnow().isoformat(),\n        'etag': utils.gen_etag(),\n        'status': 'new'\n    })\n\n    original_job_id = values.pop('job_id')\n    original_job = v1_utils.verify_existence_and_get(original_job_id,\n                                                     models.JOBS)\n    if not user.is_in_team(original_job['team_id']):\n        raise dci_exc.Unauthorized()\n\n    # get the remoteci\n    remoteci_id = str(original_job['remoteci_id'])\n    remoteci = v1_utils.verify_existence_and_get(remoteci_id,\n                                                 models.REMOTECIS)\n    values.update({'remoteci_id': remoteci_id})\n\n    # get the associated topic\n    topic_id = str(original_job['topic_id'])\n    topic = v1_utils.verify_existence_and_get(topic_id, models.TOPICS)\n\n    values.update({\n        'user_agent': flask.request.environ.get('HTTP_USER_AGENT'),\n        'client_version': flask.request.environ.get(\n            'HTTP_CLIENT_VERSION'\n        ),\n    })\n\n    next_topic_id = topic['next_topic_id']\n\n    if not next_topic_id:\n        raise dci_exc.DCIException(\n            \"topic %s does not contains a next topic\" % topic_id)\n\n    # instantiate a new job in the next_topic_id\n    # todo(yassine): make possible the upgrade to choose specific components\n    values = _build_job(next_topic_id, remoteci, [], values,\n                        previous_job_id=original_job_id)\n\n    return flask.Response(json.dumps({'job': values}), 201,\n                          headers={'ETag': values['etag']},\n                          content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all jobs. If topic_id is not None, then return all the jobs with a topic pointed by topic_id.", "response": "def get_all_jobs(user, topic_id=None):\n    \"\"\"Get all jobs.\n\n    If topic_id is not None, then return all the jobs with a topic\n    pointed by topic_id.\n    \"\"\"\n    # get the diverse parameters\n    args = schemas.args(flask.request.args.to_dict())\n\n    # build the query thanks to the QueryBuilder class\n    query = v1_utils.QueryBuilder(_TABLE, args, _JOBS_COLUMNS)\n\n    # add extra conditions for filtering\n\n    # # If not admin nor rh employee then restrict the view to the team\n    if user.is_not_super_admin() and not user.is_read_only_user():\n        query.add_extra_condition(\n            sql.or_(\n                _TABLE.c.team_id.in_(user.teams_ids),\n                _TABLE.c.team_id.in_(user.child_teams_ids)))\n\n    # # If topic_id not None, then filter by topic_id\n    if topic_id is not None:\n        query.add_extra_condition(_TABLE.c.topic_id == topic_id)\n\n    # # Get only the non archived jobs\n    query.add_extra_condition(_TABLE.c.state != 'archived')\n\n    nb_rows = query.get_number_of_rows()\n    rows = query.execute(fetchall=True)\n    rows = v1_utils.format_result(rows, _TABLE.name, args['embed'],\n                                  _EMBED_MANY)\n\n    return flask.jsonify({'jobs': rows, '_meta': {'count': nb_rows}})"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a job by id", "response": "def update_job_by_id(user, job_id):\n    \"\"\"Update a job\n    \"\"\"\n    # get If-Match header\n    if_match_etag = utils.check_and_get_etag(flask.request.headers)\n\n    # get the diverse parameters\n    values = schemas.job.put(flask.request.json)\n\n    job = v1_utils.verify_existence_and_get(job_id, _TABLE)\n    job = dict(job)\n\n    if not user.is_in_team(job['team_id']):\n        raise dci_exc.Unauthorized()\n\n    # Update jobstate if needed\n    status = values.get('status')\n    if status and job.get('status') != status:\n        jobstates.insert_jobstate(user, {\n            'status': status,\n            'job_id': job_id\n        })\n        if status in models.FINAL_STATUSES:\n            jobs_events.create_event(job_id, status, job['topic_id'])\n\n    where_clause = sql.and_(_TABLE.c.etag == if_match_etag,\n                            _TABLE.c.id == job_id)\n\n    values['etag'] = utils.gen_etag()\n    query = _TABLE.update().returning(*_TABLE.columns).\\\n        where(where_clause).values(**values)\n\n    result = flask.g.db_conn.execute(query)\n    if not result.rowcount:\n        raise dci_exc.DCIConflict('Job', job_id)\n\n    return flask.Response(\n        json.dumps({'job': result.fetchone()}), 200,\n        headers={'ETag': values['etag']},\n        content_type='application/json'\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all results from a job.", "response": "def get_all_results_from_jobs(user, j_id):\n    \"\"\"Get all results from job.\n    \"\"\"\n\n    job = v1_utils.verify_existence_and_get(j_id, _TABLE)\n\n    if not user.is_in_team(job['team_id']) and not user.is_read_only_user():\n        raise dci_exc.Unauthorized()\n\n    # get testscases from tests_results\n    query = sql.select([models.TESTS_RESULTS]). \\\n        where(models.TESTS_RESULTS.c.job_id == job['id'])\n    all_tests_results = flask.g.db_conn.execute(query).fetchall()\n\n    results = []\n    for test_result in all_tests_results:\n        test_result = dict(test_result)\n        results.append({'filename': test_result['name'],\n                        'name': test_result['name'],\n                        'total': test_result['total'],\n                        'failures': test_result['failures'],\n                        'errors': test_result['errors'],\n                        'skips': test_result['skips'],\n                        'time': test_result['time'],\n                        'regressions': test_result['regressions'],\n                        'successfixes': test_result['successfixes'],\n                        'success': test_result['success'],\n                        'file_id': test_result['file_id']})\n\n    return flask.jsonify({'results': results,\n                          '_meta': {'count': len(results)}})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_tags_from_job(user, job_id):\n\n    job = v1_utils.verify_existence_and_get(job_id, _TABLE)\n    if not user.is_in_team(job['team_id']) and not user.is_read_only_user():\n        raise dci_exc.Unauthorized()\n\n    JTT = models.JOIN_JOBS_TAGS\n    query = (sql.select([models.TAGS])\n             .select_from(JTT.join(models.TAGS))\n             .where(JTT.c.job_id == job_id))\n    rows = flask.g.db_conn.execute(query)\n\n    return flask.jsonify({'tags': rows, '_meta': {'count': rows.rowcount}})", "response": "Retrieve all tags attached to a job."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tag_to_job(user, job_id):\n\n    job = v1_utils.verify_existence_and_get(job_id, _TABLE)\n    if not user.is_in_team(job['team_id']):\n        raise dci_exc.Unauthorized()\n\n    values = {\n        'job_id': job_id\n    }\n\n    job_tagged = tags.add_tag_to_resource(values, models.JOIN_JOBS_TAGS)\n\n    return flask.Response(json.dumps(job_tagged), 201,\n                          content_type='application/json')", "response": "Add a tag to a job."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a tag from a job.", "response": "def delete_tag_from_job(user, job_id, tag_id):\n    \"\"\"Delete a tag from a job.\"\"\"\n\n    _JJT = models.JOIN_JOBS_TAGS\n    job = v1_utils.verify_existence_and_get(job_id, _TABLE)\n    if not user.is_in_team(job['team_id']):\n        raise dci_exc.Unauthorized()\n    v1_utils.verify_existence_and_get(tag_id, models.TAGS)\n\n    query = _JJT.delete().where(sql.and_(_JJT.c.tag_id == tag_id,\n                                         _JJT.c.job_id == job_id))\n\n    try:\n        flask.g.db_conn.execute(query)\n    except sa_exc.IntegrityError:\n        raise dci_exc.DCICreationConflict('tag', 'tag_id')\n\n    return flask.Response(None, 204, content_type='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_node_an_element(self, node):\n        # Try the simplest approach first, works for plain old ElementTree\n        if isinstance(node, BaseET.Element):\n            return True\n        # For cElementTree we need to be more cunning (or find a better way)\n        if hasattr(node, 'makeelement') and isinstance(node.tag, basestring):\n            return True", "response": "Return True if the given node is an Element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the result of performing the given XPath query on the given node.", "response": "def xpath_on_node(self, node, xpath, **kwargs):\n        \"\"\"\n        Return result of performing the given XPath query on the given node.\n\n        All known namespace prefix-to-URI mappings in the document are\n        automatically included in the XPath invocation.\n\n        If an empty/default namespace (i.e. None) is defined, this is\n        converted to the prefix name '_' so it can be used despite empty\n        namespace prefixes being unsupported by XPath.\n        \"\"\"\n        namespaces_dict = {}\n        if 'namespaces' in kwargs:\n            namespaces_dict.update(kwargs['namespaces'])\n        # Empty namespace prefix is not supported, convert to '_' prefix\n        if None in namespaces_dict:\n            default_ns_uri = namespaces_dict.pop(None)\n            namespaces_dict['_'] = default_ns_uri\n        # If no default namespace URI defined, use root's namespace (if any)\n        if not '_' in namespaces_dict:\n            root = self.get_impl_root(node)\n            qname, ns_uri, prefix, local_name = self._unpack_name(\n                root.tag, root)\n            if ns_uri:\n                namespaces_dict['_'] = ns_uri\n        # Include XMLNS namespace if it's not already defined\n        if not 'xmlns' in namespaces_dict:\n            namespaces_dict['xmlns'] = nodes.Node.XMLNS_URI\n        return node.findall(xpath, namespaces_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the entries to be purged from the database.", "response": "def get_to_purge_archived_resources(user, table):\n    \"\"\"List the entries to be purged from the database. \"\"\"\n\n    if user.is_not_super_admin():\n        raise dci_exc.Unauthorized()\n\n    archived_resources = get_archived_resources(table)\n\n    return flask.jsonify({table.name: archived_resources,\n                          '_meta': {'count': len(archived_resources)}})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef purge_archived_resources(user, table):\n\n    if user.is_not_super_admin():\n        raise dci_exc.Unauthorized()\n\n    where_clause = sql.and_(\n        table.c.state == 'archived'\n    )\n    query = table.delete().where(where_clause)\n    flask.g.db_conn.execute(query)\n\n    return flask.Response(None, 204, content_type='application/json')", "response": "Remove the entries to be purged from the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh_api_secret(user, resource, table):\n\n    resource_name = table.name[0:-1]\n\n    where_clause = sql.and_(\n        table.c.etag == resource['etag'],\n        table.c.id == resource['id'],\n    )\n\n    values = {\n        'api_secret': signature.gen_secret(),\n        'etag': utils.gen_etag()\n    }\n\n    query = table.update().where(where_clause).values(**values)\n    result = flask.g.db_conn.execute(query)\n\n    if not result.rowcount:\n        raise dci_exc.DCIConflict(resource_name, resource['id'])\n\n    res = flask.jsonify(({'id': resource['id'], 'etag': resource['etag'],\n                          'api_secret': values['api_secret']}))\n    res.headers.add_header('ETag', values['etag'])\n    return res", "response": "Refresh the resource API Secret."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a NPM package. json file.", "response": "def npm(package_json, output_file, pinned_file):\n    \"\"\"Generate a package.json file.\"\"\"\n    amd_build_deprecation_warning()\n    try:\n        version = get_distribution(current_app.name).version\n    except DistributionNotFound:\n        version = ''\n\n    output = {\n        'name': current_app.name,\n        'version': make_semver(version) if version else version,\n        'dependencies': {},\n    }\n\n    # Load base file\n    if package_json:\n        output = dict(output, **json.load(package_json))\n\n    # Iterate over bundles\n    deps = extract_deps(current_app.extensions['invenio-assets'].env,\n                        click.echo)\n    output['dependencies'].update(deps)\n\n    # Load pinned dependencies\n    if pinned_file:\n        output['dependencies'].update(\n            json.load(pinned_file).get('dependencies', {}))\n\n    # Write to static folder if output file is not specified\n    if output_file is None:\n        if not os.path.exists(current_app.static_folder):\n            os.makedirs(current_app.static_folder)\n        output_file = open(\n            os.path.join(current_app.static_folder, 'package.json'),\n            'w')\n\n    click.echo('Writing {0}'.format(output_file.name))\n    json.dump(output, output_file, indent=4)\n    output_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAnalyses(self, **kwargs):\n\n        # 'from' is a reserved word, use time_from instead\n        if kwargs.get('time_from'):\n            kwargs['from'] = kwargs.get('time_from')\n            del kwargs['time_from']\n        if kwargs.get('time_to'):\n            kwargs['to'] = kwargs.get('time_to')\n            del kwargs['time_to']\n\n        # Warn user about unhandled kwargs\n        for key in kwargs:\n            if key not in ['limit', 'offset', 'from', 'to']:\n                sys.stderr.write('%s not a valid argument for analysis()\\n'\n                                 % key)\n\n        response = self.pingdom.request('GET', 'analysis/%s' % self.id,\n                                        kwargs)\n\n        return [PingdomAnalysis(self, x) for x in response.json()['analysis']]", "response": "Returns a list of the latest root cause analysis results for the specified check."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getDetails(self):\n\n        response = self.pingdom.request('GET', 'checks/%s' % self.id)\n        self.__addDetails__(response.json()['check'])\n        return response.json()['check']", "response": "Update check details returns dictionary of details"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modify(self, **kwargs):\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['paused', 'resolution', 'contactids', 'sendtoemail',\n                           'sendtosms', 'sendtotwitter', 'sendtoiphone',\n                           'sendnotificationwhendown', 'notifyagainevery',\n                           'notifywhenbackup', 'created', 'type', 'hostname',\n                           'status', 'lasterrortime', 'lasttesttime', 'url',\n                           'encryption', 'port', 'auth', 'shouldcontain',\n                           'shouldnotcontain', 'postdata', 'additionalurls',\n                           'stringtosend', 'stringtoexpect', 'expectedip',\n                           'nameserver', 'use_legacy_notifications', 'host',\n                           'alert_policy', 'autoresolve', 'probe_filters']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument of' +\n                                 '<PingdomCheck>.modify()\\n')\n\n        # If one of the legacy parameters is used, it is required to set the legacy flag.\n        # https://github.com/KennethWilke/PingdomLib/issues/12\n        if any([k for k in kwargs if k in legacy_notification_parameters]):\n            if \"use_legacy_notifications\" in kwargs and kwargs[\"use_legacy_notifications\"] != True:\n                raise Exception(\"Cannot set legacy parameter when use_legacy_notifications is not True\")\n            kwargs[\"use_legacy_notifications\"] = True\n\n        response = self.pingdom.request(\"PUT\", 'checks/%s' % self.id, kwargs)\n\n        return response.json()['message']", "response": "Modify settings for a specific check in the specified base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef averages(self, **kwargs):\n\n        # 'from' is a reserved word, use time_from instead\n        if kwargs.get('time_from'):\n            kwargs['from'] = kwargs.get('time_from')\n            del kwargs['time_from']\n        if kwargs.get('time_to'):\n            kwargs['to'] = kwargs.get('time_to')\n            del kwargs['time_to']\n\n        # Warn user about unhandled parameters\n        for key in kwargs:\n            if key not in ['from', 'to', 'probes', 'includeuptime',\n                           'bycountry', 'byprobe']:\n                sys.stderr.write(\"'%s'\" % key + ' is not a valid argument of' +\n                                 '<PingdomCheck.averages()\\n')\n\n        response = self.pingdom.request('GET', 'summary.average/%s' % self.id,\n                                        kwargs)\n\n        return response.json()['summary']", "response": "Get the average time and uptime value for a specified check and time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of probes that performed tests for a specified check during a specified period.", "response": "def probes(self, fromtime, totime=None):\n        \"\"\"Get a list of probes that performed tests for a specified check\n            during a specified period.\"\"\"\n\n        args = {'from': fromtime}\n        if totime:\n            args['to'] = totime\n\n        response = self.pingdom.request('GET', 'summary.probes/%s' % self.id,\n                                        args)\n\n        return response.json()['probes']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publishPublicReport(self):\n\n        response = self.pingdom.request('PUT', 'reports.public/%s' % self.id)\n        return response.json()['message']", "response": "Activate public report for this check. Returns status message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef removePublicReport(self):\n\n        response = self.pingdom.request('DELETE',\n                                        'reports.public/%s' % self.id)\n        return response.json()['message']", "response": "Deactivate public report for this check. Returns status message"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the dependencies from the bundle and its sub - bundles.", "response": "def extract_deps(bundles, log=None):\n    \"\"\"Extract the dependencies from the bundle and its sub-bundles.\"\"\"\n    def _flatten(bundle):\n        deps = []\n        if hasattr(bundle, 'npm'):\n            deps.append(bundle.npm)\n        for content in bundle.contents:\n            if isinstance(content, BundleBase):\n                deps.extend(_flatten(content))\n        return deps\n\n    flatten_deps = []\n    for bundle in bundles:\n        flatten_deps.extend(_flatten(bundle))\n\n    packages = defaultdict(list)\n    for dep in flatten_deps:\n        for pkg, version in dep.items():\n            packages[pkg].append(version)\n\n    deps = {}\n    for package, versions in packages.items():\n        deps[package] = semver.max_satisfying(versions, '*', True)\n\n        if log and len(versions) > 1:\n            log('Warn: {0} version {1} resolved to: {2}'.format(\n                repr(package), versions, repr(deps[package])\n            ))\n\n    return deps"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a semantic version from a Python PEP440 version string.", "response": "def make_semver(version_str):\n    \"\"\"Make a semantic version from Python PEP440 version.\n\n    Semantic versions does not handle post-releases.\n    \"\"\"\n    v = parse_version(version_str)\n\n    major = v._version.release[0]\n    try:\n        minor = v._version.release[1]\n    except IndexError:\n        minor = 0\n    try:\n        patch = v._version.release[2]\n    except IndexError:\n        patch = 0\n\n    prerelease = []\n    if v._version.pre:\n        prerelease.append(''.join(str(x) for x in v._version.pre))\n    if v._version.dev:\n        prerelease.append(''.join(str(x) for x in v._version.dev))\n    prerelease = '.'.join(prerelease)\n\n    # Create semver\n    version = '{0}.{1}.{2}'.format(major, minor, patch)\n\n    if prerelease:\n        version += '-{0}'.format(prerelease)\n    if v.local:\n        version += '+{0}'.format(v.local)\n\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the maximum size for a question pool.", "response": "def get_max_size(pool, num_option, item_length):\n    \"\"\"\n    Calculate the max number of item that an option can stored in the pool at give time.\n\n    This is to limit the pool size to POOL_SIZE\n\n    Args:\n        option_index (int): the index of the option to calculate the size for\n        pool (dict): answer pool\n        num_option (int): total number of options available for the question\n        item_length (int): the length of the item\n\n    Returns:\n        int: the max number of items that `option_index` can have\n    \"\"\"\n    max_items = POOL_SIZE / item_length\n    # existing items plus the reserved for min size. If there is an option has 1 item, POOL_OPTION_MIN_SIZE - 1 space\n    # is reserved.\n    existing = POOL_OPTION_MIN_SIZE * num_option + sum([max(0, len(pool.get(i, {})) - 5) for i in xrange(num_option)])\n    return int(max_items - existing)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubmit an answer to the answer pool", "response": "def offer_answer(pool, answer, rationale, student_id, algo, options):\n    \"\"\"\n    submit a student answer to the answer pool\n\n    The answer maybe selected to stay in the pool depending on the selection algorithm\n\n    Args:\n        pool (dict): answer pool\n            Answer pool format:\n            {\n                option1_index: {\n                    'student_id': { can store algorithm specific info here },\n                    ...\n                }\n                option2_index: ...\n            }\n        answer (int): the option student selected\n        rationale (str): the rationale text\n        student_id (str): student identifier\n        algo (str): the selection algorithm\n        options (dict): the options available in the question\n\n    Raises:\n        UnknownChooseAnswerAlgorithm: when we don't know the algorithm\n    \"\"\"\n    if algo['name'] == 'simple':\n        offer_simple(pool, answer, rationale, student_id, options)\n    elif algo['name'] == 'random':\n        offer_random(pool, answer, rationale, student_id, options)\n    else:\n        raise UnknownChooseAnswerAlgorithm()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef offer_simple(pool, answer, rationale, student_id, options):\n    existing = pool.setdefault(answer, {})\n    if len(existing) >= get_max_size(pool, len(options), POOL_ITEM_LENGTH_SIMPLE):\n        student_id_to_remove = random.choice(existing.keys())\n        del existing[student_id_to_remove]\n    existing[student_id] = {}\n    pool[answer] = existing", "response": "This algorithm selects an answer from the pool and adds it to the pool if it reaches the limit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate answers based on selection algorithm", "response": "def validate_seeded_answers(answers, options, algo):\n    \"\"\"\n    Validate answers based on selection algorithm\n\n    This is called when instructor setup the tool and providing seeded answers to the question.\n    This function is trying to validate if instructor provided enough seeds for a give algorithm.\n    e.g. we require 1 seed for each option in simple algorithm and at least 1 seed for random\n    algorithm. Because otherwise, the first student won't be able to see the answers on the\n    second step where he/she suppose to compare and review other students answers.\n\n    Args:\n        answers (list): list of dict that contain seeded answers\n        options (dict): all options that should exist in the answers\n        algo (str): selection algorithm\n\n    Returns:\n        None if successful, otherwise error message\n    \"\"\"\n    if algo['name'] == 'simple':\n        return validate_seeded_answers_simple(answers, options, algo)\n    elif algo['name'] == 'random':\n        return validate_seeded_answers_random(answers)\n    else:\n        raise UnknownChooseAnswerAlgorithm()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_other_answers(pool, seeded_answers, get_student_item_dict, algo, options):\n    # \"#\" means the number of responses returned should be the same as the number of options.\n    num_responses = len(options) \\\n        if 'num_responses' not in algo or algo['num_responses'] == \"#\" \\\n        else int(algo['num_responses'])\n\n    if algo['name'] == 'simple':\n        return get_other_answers_simple(pool, seeded_answers, get_student_item_dict, num_responses)\n    elif algo['name'] == 'random':\n        return get_other_answers_random(pool, seeded_answers, get_student_item_dict, num_responses)\n    else:\n        raise UnknownChooseAnswerAlgorithm()", "response": "Select other student s answers from answer pool or seeded answers based on the selection algorithm"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget answers from others with simple algorithm which picks one answer for each option.", "response": "def get_other_answers_simple(pool, seeded_answers, get_student_item_dict, num_responses):\n    \"\"\"\n    Get answers from others with simple algorithm, which picks one answer for each option.\n\n    Args:\n        see `get_other_answers`\n        num_responses (int): the number of responses to be returned. This value may not be\n            respected if there is not enough answers to return\n\n    Returns:\n        dict: answers based on the selection algorithm\n    \"\"\"\n    ret = []\n    # clean up answers so that all keys are int\n    pool = {int(k): v for k, v in pool.items()}\n    total_in_pool = len(seeded_answers)\n    merged_pool = convert_seeded_answers(seeded_answers)\n    student_id = get_student_item_dict()['student_id']\n    # merge the dictionaries in the answer dictionary\n    for key in pool:\n        total_in_pool += len(pool[key])\n        # if student_id has value, we assume the student just submitted an answer. So removing it\n        # from total number in the pool\n        if student_id in pool[key].keys():\n            total_in_pool -= 1\n        if key in merged_pool:\n            merged_pool[key].update(pool[key].items())\n        else:\n            merged_pool[key] = pool[key]\n\n    # remember which option+student_id is selected, so that we don't have duplicates in the result\n    selected = []\n\n    # loop until we have enough answers to return\n    while len(ret) < min(num_responses, total_in_pool):\n        for option, students in merged_pool.items():\n            student = student_id\n            i = 0\n            while (student == student_id or i > 100) and (str(option) + student) not in selected:\n                # retry until we got a different one or after 100 retries\n                # we are suppose to get a different student answer or a seeded one in a few tries\n                # as we have at least one seeded answer for each option in the algo. And it is not\n                # suppose to overflow i order to break the loop\n                student = random.choice(students.keys())\n                i += 1\n            selected.append(str(option)+student)\n            if student.startswith('seeded'):\n                # seeded answer, get the rationale from local\n                rationale = students[student]\n            else:\n                student_item = get_student_item_dict(student)\n                submission = sas_api.get_answers_for_student(student_item)\n                rationale = submission.get_rationale(0)\n            ret.append({'option': option, 'rationale': rationale})\n\n            # check if we have enough answers\n            if len(ret) >= min(num_responses, total_in_pool):\n                break\n\n    return {\"answers\": ret}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget answers from others with random algorithm which randomly select answer from the pool.", "response": "def get_other_answers_random(pool, seeded_answers, get_student_item_dict, num_responses):\n    \"\"\"\n    Get answers from others with random algorithm, which randomly select answer from the pool.\n\n    Student may get three answers for option 1 or one answer for option 1 and two answers for option 2.\n\n    Args:\n        see `get_other_answers`\n        num_responses (int): the number of responses to be returned. This value may not be\n            respected if there is not enough answers to return\n\n    Returns:\n        dict: answers based on the selection algorithm\n    \"\"\"\n    ret = []\n    # clean up answers so that all keys are int\n    pool = {int(k): v for k, v in pool.items()}\n    seeded = {'seeded'+str(index): answer for index, answer in enumerate(seeded_answers)}\n    merged_pool = seeded.keys()\n\n    for key in pool:\n        merged_pool += pool[key].keys()\n\n    # shuffle\n    random.shuffle(merged_pool)\n    # get student identifier\n    student_id = get_student_item_dict()['student_id']\n\n    for student in merged_pool:\n        if len(ret) >= num_responses:\n            # have enough answers\n            break\n        elif student == student_id:\n            # this is the student's answer so don't return\n            continue\n\n        if student.startswith('seeded'):\n            option = seeded[student]['answer']\n            rationale = seeded[student]['rationale']\n        else:\n            student_item = get_student_item_dict(student)\n            submission = sas_api.get_answers_for_student(student_item)\n            rationale = submission.get_rationale(0)\n            option = submission.get_vote(0)\n        ret.append({'option': option, 'rationale': rationale})\n\n    return {\"answers\": ret}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_seeded_answers(answers):\n    converted = {}\n    for index, answer in enumerate(answers):\n        converted.setdefault(answer['answer'], {})\n        converted[answer['answer']]['seeded' + str(index)] = answer['rationale']\n\n    return converted", "response": "Convert seeded answers into the format that can be merged into student answers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupgrading a batch processor from version 1 to version 2.", "response": "def upgradeProcessor1to2(oldProcessor):\n    \"\"\"\n    Batch processors stopped polling at version 2, so they no longer needed the\n    idleInterval attribute.  They also gained a scheduled attribute which\n    tracks their interaction with the scheduler.  Since they stopped polling,\n    we also set them up as a timed event here to make sure that they don't\n    silently disappear, never to be seen again: running them with the scheduler\n    gives them a chance to figure out what's up and set up whatever other state\n    they need to continue to run.\n\n    Since this introduces a new dependency of all batch processors on a powerup\n    for the IScheduler, install a Scheduler or a SubScheduler if one is not\n    already present.\n    \"\"\"\n    newProcessor = oldProcessor.upgradeVersion(\n        oldProcessor.typeName, 1, 2,\n        busyInterval=oldProcessor.busyInterval)\n    newProcessor.scheduled = extime.Time()\n\n    s = newProcessor.store\n    sch = iaxiom.IScheduler(s, None)\n    if sch is None:\n        if s.parent is None:\n            # Only site stores have no parents.\n            sch = Scheduler(store=s)\n        else:\n            # Substores get subschedulers.\n            sch = SubScheduler(store=s)\n        installOn(sch, s)\n\n    # And set it up to run.\n    sch.schedule(newProcessor, newProcessor.scheduled)\n    return newProcessor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef processor(forType):\n    MILLI = 1000\n    try:\n        processor = _processors[forType]\n    except KeyError:\n        def __init__(self, *a, **kw):\n            item.Item.__init__(self, *a, **kw)\n            self.store.powerUp(self, iaxiom.IBatchProcessor)\n\n        attrs = {\n            '__name__': 'Batch_' + forType.__name__,\n\n            '__module__': forType.__module__,\n\n            '__init__': __init__,\n\n            '__repr__': lambda self: '<Batch of %s #%d>' % (reflect.qual(self.workUnitType), self.storeID),\n\n            'schemaVersion': 2,\n\n            'workUnitType': forType,\n\n            'scheduled': attributes.timestamp(doc=\"\"\"\n            The next time at which this processor is scheduled to run.\n            \"\"\", default=None),\n\n            # MAGIC NUMBERS AREN'T THEY WONDERFUL?\n            'busyInterval': attributes.integer(doc=\"\", default=MILLI / 10),\n            }\n        _processors[forType] = processor = item.MetaItem(\n            attrs['__name__'],\n            (item.Item, _BatchProcessorMixin),\n            attrs)\n\n        registerUpgrader(\n            upgradeProcessor1to2,\n            _processors[forType].typeName,\n            1, 2)\n\n    return processor", "response": "Create an Axiom Item type suitable for use as a batch processor for the given type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef storeBatchServiceSpecialCase(st, pups):\n    if st.parent is not None:\n        try:\n            return _SubStoreBatchChannel(st)\n        except TypeError:\n            return None\n    storeService = service.IService(st)\n    try:\n        return storeService.getServiceNamed(\"Batch Processing Controller\")\n    except KeyError:\n        return None", "response": "This function returns a simple wrapper that delegates to the site\n    store s BatchProcessingControllerService."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark the unit of work as failed in the database and update the listener so that it is not skipped.", "response": "def mark(self):\n        \"\"\"\n        Mark the unit of work as failed in the database and update the listener\n        so as to skip it next time.\n        \"\"\"\n        self.reliableListener.lastRun = extime.Time()\n        BatchProcessingError(\n            store=self.reliableListener.store,\n            processor=self.reliableListener.processor,\n            listener=self.reliableListener.listener,\n            item=self.workUnit,\n            error=self.failure.getErrorMessage())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        now = extime.Time()\n        if self.step():\n            self.scheduled = now + datetime.timedelta(milliseconds=self.busyInterval)\n        else:\n            self.scheduled = None\n        return self.scheduled", "response": "Try to run one unit of work through one listener. If there are more work to run then unschedule this item. If there are no more work then run one unit of work through one listener."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addReliableListener(self, listener, style=iaxiom.LOCAL):\n        existing = self.store.findUnique(_ReliableListener,\n                                         attributes.AND(_ReliableListener.processor == self,\n                                                        _ReliableListener.listener == listener),\n                                         default=None)\n        if existing is not None:\n            return existing\n\n        for work in self.store.query(self.workUnitType,\n                                     sort=self.workUnitType.storeID.descending,\n                                     limit=1):\n            forwardMark = work.storeID\n            backwardMark = work.storeID + 1\n            break\n        else:\n            forwardMark = 0\n            backwardMark = 0\n\n        if self.scheduled is None:\n            self.scheduled = extime.Time()\n            iaxiom.IScheduler(self.store).schedule(self, self.scheduled)\n\n        return _ReliableListener(store=self.store,\n                                 processor=self,\n                                 listener=listener,\n                                 forwardMark=forwardMark,\n                                 backwardMark=backwardMark,\n                                 style=style)", "response": "Add the given Item to the set which will be notified of Items\n        available for processing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef removeReliableListener(self, listener):\n        self.store.query(_ReliableListener,\n                         attributes.AND(_ReliableListener.processor == self,\n                                        _ReliableListener.listener == listener)).deleteFromStore()\n        self.store.query(BatchProcessingError,\n                         attributes.AND(BatchProcessingError.processor == self,\n                                        BatchProcessingError.listener == listener)).deleteFromStore()", "response": "Removes a previously added listener."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getReliableListeners(self):\n        for rellist in self.store.query(_ReliableListener, _ReliableListener.processor == self):\n            yield rellist.listener", "response": "Returns an iterable of the listeners which have been added to\n        this batch processor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getFailedItems(self):\n        for failed in self.store.query(BatchProcessingError, BatchProcessingError.processor == self):\n            yield (failed.listener, failed.item)", "response": "Returns an iterable of two - tuples of listeners which raised an an\n        exception from C { processItem } and the item which was passed as\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef itemAdded(self):\n        localCount = self.store.query(\n            _ReliableListener,\n            attributes.AND(_ReliableListener.processor == self,\n                           _ReliableListener.style == iaxiom.LOCAL),\n            limit=1).count()\n\n        remoteCount = self.store.query(\n            _ReliableListener,\n            attributes.AND(_ReliableListener.processor == self,\n                           _ReliableListener.style == iaxiom.REMOTE),\n            limit=1).count()\n\n        if localCount and self.scheduled is None:\n            self.scheduled = extime.Time()\n            iaxiom.IScheduler(self.store).schedule(self, self.scheduled)\n        if remoteCount:\n            batchService = iaxiom.IBatchService(self.store, None)\n            if batchService is not None:\n                batchService.start()", "response": "Called to indicate that a new item of the type monitored by this batch\n            processor is being added to the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(self, itemMethod):\n        item = itemMethod.im_self\n        method = itemMethod.im_func.func_name\n        return self.batchController.getProcess().addCallback(\n            CallItemMethod(storepath=item.store.dbdir,\n                           storeid=item.storeID,\n                           method=method).do)", "response": "Invoke the given bound item method in the batch process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun tasks until stopService is called.", "response": "def processWhileRunning(self):\n        \"\"\"\n        Run tasks until stopService is called.\n        \"\"\"\n        work = self.step()\n        for result, more in work:\n            yield result\n            if not self.running:\n                break\n            if more:\n                delay = 0.1\n            else:\n                delay = 10.0\n            yield task.deferLater(reactor, delay, lambda: None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind every column in every sheet and put it in a new sheet or book.", "response": "def getcols(sheetMatch=None,colMatch=\"Decay\"):\n    \"\"\"find every column in every sheet and put it in a new sheet or book.\"\"\"\n    book=BOOK()\n    if sheetMatch is None:\n        matchingSheets=book.sheetNames\n        print('all %d sheets selected '%(len(matchingSheets)))\n    else:\n        matchingSheets=[x for x in book.sheetNames if sheetMatch in x]\n        print('%d of %d sheets selected matching \"%s\"'%(len(matchingSheets),len(book.sheetNames),sheetMatch))\n    matchingSheetsWithCol=[]\n    for sheetName in matchingSheets:\n        i = book.sheetNames.index(sheetName) # index of that sheet\n        for j,colName in enumerate(book.sheets[i].colDesc):\n            if colMatch in colName:\n                matchingSheetsWithCol.append((sheetName,j))\n                break\n        else:\n            print(\"  no match in [%s]%s\"%(book.bookName,sheetName))\n    print(\"%d of %d of those have your column\"%(len(matchingSheetsWithCol),len(matchingSheets)))\n    for item in matchingSheetsWithCol:\n        print(item,item[0],item[1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upgradeStore(self, store):\n        self.upgradeEverything(store)\n        upgradeExplicitOid(store)\n\n        for substore in store.query(SubStore):\n            print 'Upgrading: {!r}'.format(substore)\n            self.upgradeStore(substore.open())", "response": "Upgrade all the objects in the given store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform(self, store, count):\n        self.count = count\n\n        try:\n            self.upgradeStore(store)\n            print 'Upgrade complete'\n        except errors.ItemUpgradeError as e:\n            print 'Upgrader error:'\n            e.originalFailure.printTraceback(file=sys.stdout)\n            print self.errorMessageFormat % (\n                e.oldType.typeName, e.storeID, e.oldType.schemaVersion,\n                e.newType.schemaVersion)", "response": "Perform the upgrades on the given store and count."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef runcode(self, code):\n        if not self.locals.get('autocommit', None):\n            return self.locals['db'].transact(code.InteractiveConsole.runcode, self, code)\n        return code.InteractiveConsole.runcode(self, code)", "response": "Override the local L{InteractiveConsole. runcode to run the code in a specific transaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary representing the namespace which should be used to access the user s database.", "response": "def namespace(self):\n        \"\"\"\n        Return a dictionary representing the namespace which should be\n        available to the user.\n        \"\"\"\n        self._ns = {\n            'db': self.store,\n            'store': store,\n            'autocommit': False,\n            }\n        return self._ns"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new account to the given store.", "response": "def addAccount(self, siteStore, username, domain, password):\n        \"\"\"\n        Create a new account in the given store.\n\n        @param siteStore: A site Store to which login credentials will be\n        added.\n        @param username: Local part of the username for the credentials to add.\n        @param domain: Domain part of the username for the credentials to add.\n        @param password: Password for the credentials to add.\n        @rtype: L{LoginAccount}\n        @return: The added account.\n        \"\"\"\n        for ls in siteStore.query(userbase.LoginSystem):\n            break\n        else:\n            ls = self.installOn(siteStore)\n        try:\n            acc = ls.addAccount(username, domain, password)\n        except userbase.DuplicateUser:\n            raise usage.UsageError(\"An account by that name already exists.\")\n        return acc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new class with some attributes in its schema.", "response": "def itemTypeWithSomeAttributes(attributeTypes):\n    \"\"\"\n    Create a new L{Item} subclass with L{numAttributes} integers in its\n    schema.\n    \"\"\"\n    class SomeItem(Item):\n        typeName = 'someitem_' + str(typeNameCounter())\n        for i, attributeType in enumerate(attributeTypes):\n            locals()['attr_' + str(i)] = attributeType()\n    return SomeItem"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates some items of a particular type in a store.", "response": "def createSomeItems(store, itemType, values, counter):\n    \"\"\"\n    Create some instances of a particular type in a store.\n    \"\"\"\n    for i in counter:\n        itemType(store=store, **values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, commit=True):\n\n        # walk through the document fields\n        for field_name, field in iter_valid_fields(self._meta):\n            setattr(self.instance, field_name, self.cleaned_data.get(field_name))\n\n        if commit:\n            self.instance.save()\n\n        return self.instance", "response": "save the instance or create a new one"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a callable which will invoke the given function in a transaction using the underlying store attribute of the first parameter passed to it.", "response": "def transacted(func):\n    \"\"\"\n    Return a callable which will invoke C{func} in a transaction using the\n    C{store} attribute of the first parameter passed to it.  Typically this is\n    used to create Item methods which are automatically run in a transaction.\n\n    The attributes of the returned callable will resemble those of C{func} as\n    closely as L{twisted.python.util.mergeFunctionMetadata} can make them.\n    \"\"\"\n    def transactionified(item, *a, **kw):\n        return item.store.transact(func, item, *a, **kw)\n    return mergeFunctionMetadata(func, transactionified)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dependentItems(store, tableClass, comparisonFactory):\n    for cascadingAttr in (_cascadingDeletes.get(tableClass, []) +\n                          _cascadingDeletes.get(None, [])):\n        for cascadedItem in store.query(cascadingAttr.type,\n                                        comparisonFactory(cascadingAttr)):\n            yield cascadedItem", "response": "Returns an iterable of items that should be deleted when an item or items\n    of a particular item type are deleted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef allowDeletion(store, tableClass, comparisonFactory):\n    for cascadingAttr in (_disallows.get(tableClass, []) +\n                          _disallows.get(None, [])):\n        for cascadedItem in store.query(cascadingAttr.type,\n                                        comparisonFactory(cascadingAttr),\n                                        limit=1):\n            return False\n\n    return True", "response": "Returns a C { bool } indicating whether deletion of an item or items of a specific item type should be allowed to proceed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef declareLegacyItem(typeName, schemaVersion, attributes, dummyBases=()):\n    if (typeName, schemaVersion) in _legacyTypes:\n        return _legacyTypes[typeName, schemaVersion]\n    if dummyBases:\n        realBases = [declareLegacyItem(*A) for A in dummyBases]\n    else:\n        realBases = (Item,)\n    attributes = attributes.copy()\n    attributes['__module__'] = 'item_dummy'\n    attributes['__legacy__'] = True\n    attributes['typeName'] = typeName\n    attributes['schemaVersion'] = schemaVersion\n    result = type(str('DummyItem<%s,%d>' % (typeName, schemaVersion)),\n                  realBases,\n                  attributes)\n    assert result is not None, 'wtf, %r' % (type,)\n    _legacyTypes[(typeName, schemaVersion)] = result\n    return result", "response": "Return a dummy subclass of Item that will have the given attributes and baseItem methods."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclass decorator for indicating a powerup s powerup interfaces.", "response": "def empowerment(iface, priority=0):\n    \"\"\"\n    Class decorator for indicating a powerup's powerup interfaces.\n\n    The class will also be declared as implementing the interface.\n\n    @type iface: L{zope.interface.Interface}\n    @param iface: The powerup interface.\n\n    @type priority: int\n    @param priority: The priority the powerup will be installed at.\n    \"\"\"\n    def _deco(cls):\n        cls.powerupInterfaces = (\n            tuple(getattr(cls, 'powerupInterfaces', ())) +\n            ((iface, priority),))\n        implementer(iface)(cls)\n        return cls\n    return _deco"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef powerUp(self, powerup, interface=None, priority=0):\n        if interface is None:\n            for iface, priority in powerup._getPowerupInterfaces():\n                self.powerUp(powerup, iface, priority)\n\n        elif interface is IPowerupIndirector:\n            raise TypeError(\n                \"You cannot install a powerup for IPowerupIndirector: \" +\n                powerup)\n        else:\n            forc = self.store.findOrCreate(_PowerupConnector,\n                                           item=self,\n                                           interface=unicode(qual(interface)),\n                                           powerup=powerup)\n            forc.priority = priority", "response": "Powerup the specified powerup on the item or store."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef powerDown(self, powerup, interface=None):\n        if interface is None:\n            for interface, priority in powerup._getPowerupInterfaces():\n                self.powerDown(powerup, interface)\n        else:\n            for cable in self.store.query(_PowerupConnector,\n                                          AND(_PowerupConnector.item == self,\n                                              _PowerupConnector.interface == unicode(qual(interface)),\n                                              _PowerupConnector.powerup == powerup)):\n                cable.deleteFromStore()\n                return\n            raise ValueError(\"Not powered up for %r with %r\" % (interface,\n                                                                powerup))", "response": "Power down a powerup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef powerupsFor(self, interface):\n        inMemoryPowerup = self._inMemoryPowerups.get(interface, None)\n        if inMemoryPowerup is not None:\n            yield inMemoryPowerup\n        if self.store is None:\n            return\n        name = unicode(qual(interface), 'ascii')\n        for cable in self.store.query(\n            _PowerupConnector,\n            AND(_PowerupConnector.interface == name,\n                _PowerupConnector.item == self),\n            sort=_PowerupConnector.priority.descending):\n            pup = cable.powerup\n            if pup is None:\n                # this powerup was probably deleted during an upgrader.\n                cable.deleteFromStore()\n            else:\n                indirector = IPowerupIndirector(pup, None)\n                if indirector is not None:\n                    yield indirector.indirect(interface)\n                else:\n                    yield pup", "response": "Yields the powerups installed for this item."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator of the interfaces that are installed on this object and which the given powerup is xid installed on this object.", "response": "def interfacesFor(self, powerup):\n        \"\"\"\n        Return an iterator of the interfaces for which the given powerup is\n        installed on this object.\n\n        This is not implemented for in-memory powerups.  It will probably fail\n        in an unpredictable, implementation-dependent way if used on one.\n        \"\"\"\n        pc = _PowerupConnector\n        for iface in self.store.query(pc,\n                                      AND(pc.item == self,\n                                          pc.powerup == powerup)).getColumn('interface'):\n            yield namedAny(iface)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getPowerupInterfaces(self):\n        powerupInterfaces = getattr(self.__class__, \"powerupInterfaces\", ())\n        pifs = []\n        for x in powerupInterfaces:\n            if isinstance(x, type(Interface)):\n                #just an interface\n                pifs.append((x, 0))\n            else:\n                #an interface and a priority\n                pifs.append(x)\n\n        m = getattr(self, \"__getPowerupInterfaces__\", None)\n        if m is not None:\n            pifs = m(pifs)\n            try:\n                pifs = [(i, p) for (i, p) in pifs]\n            except ValueError:\n                raise ValueError(\"return value from %r.__getPowerupInterfaces__\"\n                                 \" not an iterable of 2-tuples\" % (self,))\n        return pifs", "response": "Return a list of all powerup interfaces that this object declares that it can be installed on."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbeing this object currently valid as a reference?", "response": "def _currentlyValidAsReferentFor(self, store):\n        \"\"\"\n        Is this object currently valid as a reference?  Objects which will be\n        deleted in this transaction, or objects which are not in the same store\n        are not valid.  See attributes.reference.__get__.\n        \"\"\"\n        if store is None:\n            # If your store is None, you can refer to whoever you want.  I'm in\n            # a store but it doesn't matter that you're not.\n            return True\n        if self.store is not store:\n            return False\n        if self.__deletingObject:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _schemaPrepareInsert(self, store):\n        for name, atr in self.getSchema():\n            atr.prepareInsert(self, store)", "response": "Prepare each attribute in my schema for insertion into a given store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and return a new instance from a row from the store.", "response": "def existingInStore(cls, store, storeID, attrs):\n        \"\"\"Create and return a new instance from a row from the store.\"\"\"\n        self = cls.__new__(cls)\n\n        self.__justCreated = False\n        self.__subinit__(__store=store,\n                         storeID=storeID,\n                         __everInserted=True)\n\n        schema = self.getSchema()\n        assert len(schema) == len(attrs), \"invalid number of attributes\"\n        for data, (name, attr) in zip(attrs, schema):\n            attr.loaded(self, data)\n        self.activate()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSchema(cls):\n        schema = []\n        for name, atr in cls.__attributes__:\n            atr = atr.__get__(None, cls)\n            if isinstance(atr, SQLAttribute):\n                schema.append((name, atr))\n        cls.getSchema = staticmethod(lambda schema=schema: schema)\n        return schema", "response": "getSchema - Returns a list of all persistent class attributes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef persistentValues(self):\n        return dict((k, getattr(self, k)) for (k, attr) in self.getSchema())", "response": "Return a dictionary of all persistent values of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls after the database is committed with this object.", "response": "def committed(self):\n        \"\"\"\n        Called after the database is brought into a consistent state with this\n        object.\n        \"\"\"\n        if self.__deleting:\n            self.deleted()\n            if not self.__legacy__:\n                self.store.objectCache.uncache(self.storeID, self)\n                self.__store = None\n        self.__justCreated = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the database to reflect in-memory changes made to this item; for example, to make it show up in store.query() calls where it is now valid, but was not the last time it was persisted to the database. This is called automatically when in 'autocommit mode' (i.e. not in a transaction) and at the end of each transaction for every object that has been changed.", "response": "def checkpoint(self):\n        \"\"\"\n        Update the database to reflect in-memory changes made to this item; for\n        example, to make it show up in store.query() calls where it is now\n        valid, but was not the last time it was persisted to the database.\n\n        This is called automatically when in 'autocommit mode' (i.e. not in a\n        transaction) and at the end of each transaction for every object that\n        has been changed.\n        \"\"\"\n\n        if self.store is None:\n            raise NotInStore(\"You can't checkpoint %r: not in a store\" % (self,))\n\n\n        if self.__deleting:\n            if not self.__everInserted:\n                # don't issue duplicate SQL and crap; we were created, then\n                # destroyed immediately.\n                return\n            self.store.executeSQL(self._baseDeleteSQL(self.store), [self.storeID])\n            # re-using OIDs plays havoc with the cache, and with other things\n            # as well.  We need to make sure that we leave a placeholder row at\n            # the end of the table.\n            if self.__deletingObject:\n                # Mark this object as dead.\n                self.store.executeSchemaSQL(_schema.CHANGE_TYPE,\n                                            [-1, self.storeID])\n\n                # Can't do this any more:\n                # self.store.executeSchemaSQL(_schema.DELETE_OBJECT, [self.storeID])\n\n                # TODO: need to measure the performance impact of this, then do\n                # it to make sure things are in fact deleted:\n                # self.store.executeSchemaSQL(_schema.APP_VACUUM)\n\n            else:\n                assert self.__legacy__\n\n            # we're done...\n            if self.store.autocommit:\n                self.committed()\n            return\n\n        if self.__everInserted:\n            # case 1: we've been inserted before, either previously in this\n            # transaction or we were loaded from the db\n            if not self.__dirty__:\n                # we might have been checkpointed twice within the same\n                # transaction; just don't do anything.\n                return\n            self.store.executeSQL(*self._updateSQL())\n        else:\n            # case 2: we are in the middle of creating the object, we've never\n            # been inserted into the db before\n            schemaAttrs = self.getSchema()\n\n            insertArgs = [self.storeID]\n            for (ignoredName, attrObj) in schemaAttrs:\n                attrObjDuplicate, attributeValue = self.__dirty__[attrObj.attrname]\n                # assert attrObjDuplicate is attrObj\n                insertArgs.append(attributeValue)\n\n            # XXX this isn't atomic, gross.\n            self.store.executeSQL(self._baseInsertSQL(self.store), insertArgs)\n            self.__everInserted = True\n        # In case 1, we're dirty but we did an update, synchronizing the\n        # database, in case 2, we haven't been created but we issue an insert.\n        # In either case, the code in attributes.py sets the attribute *as well\n        # as* populating __dirty__, so we clear out dirty and we keep the same\n        # value, knowing it's the same as what's in the db.\n        self.__dirty__.clear()\n        if self.store.autocommit:\n            self.committed()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef registerUpgrader(upgrader, typeName, oldVersion, newVersion):\n    # assert (typeName, oldVersion, newVersion) not in _upgradeRegistry, \"duplicate upgrader\"\n    # ^ this makes the tests blow up so it's just disabled for now; perhaps we\n    # should have a specific test mode\n    # assert newVersion - oldVersion == 1, \"read the doc string\"\n    assert isinstance(typeName, str), \"read the doc string\"\n    _upgradeRegistry[typeName, oldVersion] = upgrader", "response": "Register a function which can perform a schema upgrade between two sequence words."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef registerAttributeCopyingUpgrader(itemType, fromVersion, toVersion, postCopy=None):\n    def upgrader(old):\n        newitem = old.upgradeVersion(itemType.typeName, fromVersion, toVersion,\n                                     **dict((str(name), getattr(old, name))\n                                            for (name, _) in old.getSchema()))\n        if postCopy is not None:\n            postCopy(newitem)\n        return newitem\n    registerUpgrader(upgrader, itemType.typeName, fromVersion, toVersion)", "response": "Register an upgrader for itemType from fromVersion to toVersion which will copy all attributes from the legacy item to the new item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters an upgrader for an item from fromVersion to toVersion which will delete the item from the database.", "response": "def registerDeletionUpgrader(itemType, fromVersion, toVersion):\n    \"\"\"\n    Register an upgrader for C{itemType}, from C{fromVersion} to C{toVersion},\n    which will delete the item from the database.\n\n    @param itemType: L{axiom.item.Item} subclass\n    @return: None\n    \"\"\"\n    # XXX This should actually do something more special so that a new table is\n    # not created and such.\n    def upgrader(old):\n        old.deleteFromStore()\n        return None\n    registerUpgrader(upgrader, itemType.typeName, fromVersion, toVersion)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the given table has an explicit oid column.", "response": "def _hasExplicitOid(store, table):\n    \"\"\"\n    Does the given table have an explicit oid column?\n    \"\"\"\n    return any(info[1] == 'oid' for info\n               in store.querySchemaSQL(\n                   'PRAGMA *DATABASE*.table_info({})'.format(table)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupgrading a table to have an explicit oid.", "response": "def _upgradeTableOid(store, table, createTable, postCreate=lambda: None):\n    \"\"\"\n    Upgrade a table to have an explicit oid.\n\n    Must be called in a transaction to avoid corrupting the database.\n    \"\"\"\n    if _hasExplicitOid(store, table):\n        return\n    store.executeSchemaSQL(\n        'ALTER TABLE *DATABASE*.{0} RENAME TO {0}_temp'.format(table))\n    createTable()\n    store.executeSchemaSQL(\n        'INSERT INTO *DATABASE*.{0} '\n        'SELECT oid, * FROM *DATABASE*.{0}_temp'.format(table))\n    store.executeSchemaSQL('DROP TABLE *DATABASE*.{0}_temp'.format(table))\n    postCreate()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupgrade the system tables to use explicit oid columns.", "response": "def upgradeSystemOid(store):\n    \"\"\"\n    Upgrade the system tables to use explicit oid columns.\n    \"\"\"\n    store.transact(\n        _upgradeTableOid, store, 'axiom_types',\n        lambda: store.executeSchemaSQL(CREATE_TYPES))\n    store.transact(\n        _upgradeTableOid, store, 'axiom_objects',\n        lambda: store.executeSchemaSQL(CREATE_OBJECTS),\n        lambda: store.executeSchemaSQL(CREATE_OBJECTS_IDX))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upgradeExplicitOid(store):\n    upgradeSystemOid(store)\n    for typename, version in store.querySchemaSQL(LATEST_TYPES):\n        cls = _typeNameToMostRecentClass[typename]\n        if cls.schemaVersion != version:\n            remaining = store.querySQL(\n                'SELECT oid FROM {} LIMIT 1'.format(\n                    store._tableNameFor(typename, version)))\n            if len(remaining) == 0:\n                # Nothing to upgrade\n                continue\n            else:\n                raise RuntimeError(\n                    '{}:{} not fully upgraded to {}'.format(\n                        typename, version, cls.schemaVersion))\n        store.transact(\n            _upgradeTableOid,\n            store,\n            store._tableNameOnlyFor(typename, version),\n            lambda: store._justCreateTable(cls),\n            lambda: store._createIndexesFor(cls, []))", "response": "Upgrade a store to use explicit oid columns."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that all of the accumulated Items have a way to get the latest version of the items.", "response": "def checkUpgradePaths(self):\n        \"\"\"\n        Check that all of the accumulated old Item types have a way to get\n        from their current version to the latest version.\n\n        @raise axiom.errors.NoUpgradePathAvailable: for any, and all, Items\n            that do not have a valid upgrade path\n        \"\"\"\n        cantUpgradeErrors = []\n\n        for oldVersion in self._oldTypesRemaining:\n            # We have to be able to get from oldVersion.schemaVersion to\n            # the most recent type.\n\n            currentType = _typeNameToMostRecentClass.get(\n                oldVersion.typeName, None)\n\n            if currentType is None:\n                # There isn't a current version of this type; it's entirely\n                # legacy, will be upgraded by deleting and replacing with\n                # something else.\n                continue\n\n            typeInQuestion = oldVersion.typeName\n            upgver = oldVersion.schemaVersion\n\n            while upgver < currentType.schemaVersion:\n                # Do we have enough of the schema present to upgrade?\n                if ((typeInQuestion, upgver)\n                    not in _upgradeRegistry):\n                    cantUpgradeErrors.append(\n                        \"No upgrader present for %s (%s) from %d to %d\" % (\n                            typeInQuestion, qual(currentType), upgver,\n                            upgver + 1))\n\n                # Is there a type available for each upgrader version?\n                if upgver+1 != currentType.schemaVersion:\n                    if (typeInQuestion, upgver+1) not in _legacyTypes:\n                        cantUpgradeErrors.append(\n                            \"Type schema required for upgrade missing:\"\n                            \" %s version %d\" % (\n                                typeInQuestion, upgver+1))\n                upgver += 1\n\n            if cantUpgradeErrors:\n                raise NoUpgradePathAvailable('\\n    '.join(cantUpgradeErrors))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nqueue a type upgrade for oldtype.", "response": "def queueTypeUpgrade(self, oldtype):\n        \"\"\"\n        Queue a type upgrade for C{oldtype}.\n        \"\"\"\n        if oldtype not in self._oldTypesRemaining:\n            self._oldTypesRemaining.append(oldtype)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupgrade a legacy item.", "response": "def upgradeItem(self, thisItem):\n        \"\"\"\n        Upgrade a legacy item.\n\n        @raise axiom.errors.UpgraderRecursion: If the given item is already in\n            the process of being upgraded.\n        \"\"\"\n        sid = thisItem.storeID\n        if sid in self._currentlyUpgrading:\n            raise UpgraderRecursion()\n        self._currentlyUpgrading[sid] = thisItem\n        try:\n            return upgradeAllTheWay(thisItem)\n        finally:\n            self._currentlyUpgrading.pop(sid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupgrades the entire store in batches yielding after each batch.", "response": "def upgradeBatch(self, n):\n        \"\"\"\n        Upgrade the entire store in batches, yielding after each batch.\n\n        @param n: Number of upgrades to perform per transaction\n        @type n: C{int}\n\n        @raise axiom.errors.ItemUpgradeError: if an item upgrade failed\n\n        @return: A generator that yields after each batch upgrade. This needs\n            to be consumed for upgrading to actually take place.\n        \"\"\"\n        store = self.store\n\n        def _doBatch(itemType):\n            upgradedAnything = False\n\n            for theItem in store.query(itemType, limit=n):\n                upgradedAnything = True\n                try:\n                    self.upgradeItem(theItem)\n                except:\n                    f = Failure()\n                    raise ItemUpgradeError(\n                        f, theItem.storeID, itemType,\n                        _typeNameToMostRecentClass[itemType.typeName])\n\n            return upgradedAnything\n\n        if self.upgradesPending:\n            didAny = False\n\n            while self._oldTypesRemaining:\n                t0 = self._oldTypesRemaining[0]\n\n                upgradedAnything = store.transact(_doBatch, t0)\n                if not upgradedAnything:\n                    self._oldTypesRemaining.pop(0)\n                    if didAny:\n                        msg(\"%s finished upgrading %s\" % (store.dbdir.path, qual(t0)))\n                    continue\n                elif not didAny:\n                    didAny = True\n                    msg(\"%s beginning upgrade...\" % (store.dbdir.path,))\n\n                yield None\n\n            if didAny:\n                msg(\"%s completely upgraded.\" % (store.dbdir.path,))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self):\n        self.vg.open()\n        self.__lvh = lvm_lv_from_uuid(self.vg.handle, self.uuid)\n        if not bool(self.__lvh):\n            raise HandleError(\"Failed to initialize LV Handle.\")", "response": "Opens the lvm vg_t and LV_t and initializes the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(self):\n        self.open()\n        name = lvm_lv_get_name(self.__lvh)\n        self.close()\n        return name", "response": "Returns the logical volume name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the logical volume is active False otherwise.", "response": "def is_active(self):\n        \"\"\"\n        Returns True if the logical volume is active, False otherwise.\n        \"\"\"\n        self.open()\n        active = lvm_lv_is_active(self.__lvh)\n        self.close()\n        return bool(active)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the logical volume is suspended False otherwise.", "response": "def is_suspended(self):\n        \"\"\"\n        Returns True if the logical volume is suspended, False otherwise.\n        \"\"\"\n        self.open()\n        susp = lvm_lv_is_suspended(self.__lvh)\n        self.close()\n        return bool(susp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the logical volume size in the given units.", "response": "def size(self, units=\"MiB\"):\n        \"\"\"\n        Returns the logical volume size in the given units. Default units are  MiB.\n\n        *Args:*\n\n        *       units (str):    Unit label ('MiB', 'GiB', etc...). Default is MiB.\n        \"\"\"\n        self.open()\n        size = lvm_lv_get_size(self.__lvh)\n        self.close()\n        return size_convert(size, units)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate(self):\n        self.open()\n        a = lvm_lv_activate(self.handle)\n        self.close()\n        if a != 0:\n            raise CommitError(\"Failed to activate LV.\")", "response": "Activates the logical volume."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeactivates the logical volume.", "response": "def deactivate(self):\n        \"\"\"\n        Deactivates the logical volume.\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        self.open()\n        d = lvm_lv_deactivate(self.handle)\n        self.close()\n        if d != 0:\n            raise CommitError(\"Failed to deactivate LV.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen the lvm vg_t and pv_t handle.", "response": "def open(self):\n        \"\"\"\n        Obtains the lvm, vg_t and pv_t handle. Usually you would never need to use this\n        method unless you are doing operations using the ctypes function wrappers in\n        conversion.py\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        self.vg.open()\n        self.__pvh = lvm_pv_from_uuid(self.vg.handle, self.uuid)\n        if not bool(self.__pvh):\n            raise HandleError(\"Failed to initialize PV Handle.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the physical volume device path.", "response": "def name(self):\n        \"\"\"\n        Returns the physical volume device path.\n        \"\"\"\n        self.open()\n        name = lvm_pv_get_name(self.handle)\n        self.close()\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mda_count(self):\n        self.open()\n        mda = lvm_pv_get_mda_count(self.handle)\n        self.close()\n        return mda", "response": "Returns the physical volume mda count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the physical volume size in the given units.", "response": "def size(self, units=\"MiB\"):\n        \"\"\"\n        Returns the physical volume size in the given units. Default units are  MiB.\n\n        *Args:*\n\n        *       units (str):    Unit label ('MiB', 'GiB', etc...). Default is MiB.\n        \"\"\"\n        self.open()\n        size = lvm_pv_get_size(self.handle)\n        self.close()\n        return size_convert(size, units)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dev_size(self, units=\"MiB\"):\n        self.open()\n        size = lvm_pv_get_dev_size(self.handle)\n        self.close()\n        return size_convert(size, units)", "response": "Returns the device size in the given units."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef free(self, units=\"MiB\"):\n        self.open()\n        size = lvm_pv_get_free(self.handle)\n        self.close()\n        return size_convert(size, units)", "response": "Returns the free size in the given units."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating through the available valid fields.", "response": "def iter_valid_fields(meta):\n    \"\"\"walk through the available valid fields..\"\"\"\n\n    # fetch field configuration and always add the id_field as exclude\n    meta_fields = getattr(meta, 'fields', ())\n    meta_exclude = getattr(meta, 'exclude', ())\n    meta_exclude += (meta.document._meta.get('id_field'),)\n\n    # walk through meta_fields or through the document fields to keep\n    # meta_fields order in the form\n    if meta_fields:\n        for field_name in meta_fields:\n            field = meta.document._fields.get(field_name)\n            if field:\n                yield (field_name, field)\n    else:\n        for field_name, field in meta.document._fields.iteritems():\n            # skip excluded fields\n            if field_name not in meta_exclude:\n                yield (field_name, field)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves this object from the target.", "response": "def uninstallFrom(self, target):\n    \"\"\"\n    Remove this object from the target, as well as any dependencies\n    that it automatically installed which were not explicitly\n    \"pinned\" by calling \"install\", and raising an exception if\n    anything still depends on this.\n    \"\"\"\n\n    #did this class powerup on any interfaces? powerdown if so.\n    target.powerDown(self)\n\n\n    for dc in self.store.query(_DependencyConnector,\n                               _DependencyConnector.target==target):\n        if dc.installee is self:\n            dc.deleteFromStore()\n\n    for item in installedUniqueRequirements(self, target):\n        uninstallFrom(item, target)\n\n    callback = getattr(self, \"uninstalled\", None)\n    if callback is not None:\n        callback()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the install target if this item is installed on another item. Otherwise returns None.", "response": "def installedOn(self):\n    \"\"\"\n    If this item is installed on another item, return the install\n    target. Otherwise return None.\n    \"\"\"\n    try:\n        return self.store.findUnique(_DependencyConnector,\n                                     _DependencyConnector.installee == self\n                                     ).target\n    except ItemNotFound:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef installedDependents(self, target):\n    for dc in self.store.query(_DependencyConnector,\n                               _DependencyConnector.target == target):\n        depends = dependentsOf(dc.installee.__class__)\n        if self.__class__ in depends:\n            yield dc.installee", "response": "Returns an iterable of things installed on the target that require this item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterable of things installed on the target that this item requires and are not required by any other item.", "response": "def installedUniqueRequirements(self, target):\n    \"\"\"\n    Return an iterable of things installed on the target that this item\n    requires and are not required by anything else.\n    \"\"\"\n\n    myDepends = dependentsOf(self.__class__)\n    #XXX optimize?\n    for dc in self.store.query(_DependencyConnector,\n                               _DependencyConnector.target==target):\n        if dc.installee is self:\n            #we're checking all the others not ourself\n            continue\n        depends = dependentsOf(dc.installee.__class__)\n        if self.__class__ in depends:\n            raise DependencyError(\n                \"%r cannot be uninstalled from %r, \"\n                \"%r still depends on it\" % (self, target, dc.installee))\n\n        for cls in myDepends[:]:\n            #If one of my dependencies is required by somebody\n            #else, leave it alone\n            if cls in depends:\n                myDepends.remove(cls)\n\n    for dc in self.store.query(_DependencyConnector,\n                               _DependencyConnector.target==target):\n        if (dc.installee.__class__ in myDepends\n            and not dc.explicitlyInstalled):\n            yield dc.installee"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef installedRequirements(self, target):\n    myDepends = dependentsOf(self.__class__)\n    for dc in self.store.query(_DependencyConnector,\n                               _DependencyConnector.target == target):\n        if dc.installee.__class__ in myDepends:\n            yield dc.installee", "response": "Returns an iterable of things installed on the target that this item requires."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef storeServiceSpecialCase(st, pups):\n    if st.parent is not None:\n        # If for some bizarre reason we're starting a substore's service, let's\n        # just assume that its parent is running its upgraders, rather than\n        # risk starting the upgrader run twice. (XXX: it *IS* possible to\n        # figure out whether we need to or not, I just doubt this will ever\n        # even happen in practice -- fix here if it does)\n        return serviceSpecialCase(st, pups)\n    if st._axiom_service is not None:\n        # not new, don't add twice.\n        return st._axiom_service\n\n    collection = serviceSpecialCase(st, pups)\n\n    st._upgradeService.setServiceParent(collection)\n\n    if st.dbdir is not None:\n        from axiom import batch\n        batcher = batch.BatchProcessingControllerService(st)\n        batcher.setServiceParent(collection)\n\n    scheduler = iaxiom.IScheduler(st)\n    # If it's an old database, we might get a SubScheduler instance.  It has no\n    # setServiceParent method.\n    setServiceParent = getattr(scheduler, 'setServiceParent', None)\n    if setServiceParent is not None:\n        setServiceParent(collection)\n\n    return collection", "response": "Adapt a store to L { IServiceCollection } and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _schedulerServiceSpecialCase(empowered, pups):\n    from axiom.scheduler import _SiteScheduler, _UserScheduler\n\n    # Give precedence to anything found in the store\n    for pup in pups:\n        return pup\n    # If the empowered is a store, construct a scheduler for it.\n    if isinstance(empowered, Store):\n        if getattr(empowered, '_schedulerService', None) is None:\n            if empowered.parent is None:\n                sched = _SiteScheduler(empowered)\n            else:\n                sched = _UserScheduler(empowered)\n            empowered._schedulerService = sched\n        return empowered._schedulerService\n    return None", "response": "This function creates or returns a previously created L { IScheduler } for the given set of powerups."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat a schema mismatch for human consumption.", "response": "def _diffSchema(diskSchema, memorySchema):\n    \"\"\"\n    Format a schema mismatch for human consumption.\n\n    @param diskSchema: The on-disk schema.\n\n    @param memorySchema: The in-memory schema.\n\n    @rtype: L{bytes}\n    @return: A description of the schema differences.\n    \"\"\"\n    diskSchema = set(diskSchema)\n    memorySchema = set(memorySchema)\n    diskOnly = diskSchema - memorySchema\n    memoryOnly = memorySchema - diskSchema\n    diff = []\n    if diskOnly:\n        diff.append('Only on disk:')\n        diff.extend(map(repr, diskOnly))\n    if memoryOnly:\n        diff.append('Only in memory:')\n        diff.extend(map(repr, memoryOnly))\n    return '\\n'.join(diff)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose this file and commit it to its permanent location.", "response": "def close(self):\n        \"\"\"\n        Close this file and commit it to its permanent location.\n\n        @return: a Deferred which fires when the file has been moved (and\n        backed up to tertiary storage, if necessary).\n        \"\"\"\n        now = time.time()\n        try:\n            file.close(self)\n            _mkdirIfNotExists(self._destpath.dirname())\n            self.finalpath = self._destpath\n            os.rename(self.name, self.finalpath.path)\n            os.utime(self.finalpath.path, (now, now))\n        except:\n            return defer.fail()\n        return defer.succeed(self.finalpath)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _computeFromClause(self, tables):\n        tableAliases = []\n        self.fromClauseParts = []\n        for table in tables:\n            # The indirect calls to store.getTableName() will create the tables\n            # if needed. (XXX That's bad, actually.   They should get created\n            # some other way if necessary.  -exarkun)\n            tableName = table.getTableName(self.store)\n            tableAlias = table.getTableAlias(self.store, tuple(tableAliases))\n            if tableAlias is None:\n                self.fromClauseParts.append(tableName)\n            else:\n                tableAliases.append(tableAlias)\n                self.fromClauseParts.append('%s AS %s' % (tableName,\n                                                          tableAlias))\n\n        self.sortClauseParts = []\n        for attr, direction in self.sort.orderColumns():\n            assert direction in ('ASC', 'DESC'), \"%r not in ASC,DESC\" % (direction,)\n            if attr.type not in tables:\n                raise ValueError(\n                    \"Ordering references type excluded from comparison\")\n            self.sortClauseParts.append(\n                '%s %s' % (attr.getColumnName(self.store), direction))", "response": "Generate the FROM and WHERE clauses for the related tables."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _selectStuff(self, verb='SELECT'):\n        sqlResults = self._runQuery(verb, self._queryTarget)\n        for row in sqlResults:\n            yield self._massageData(row)", "response": "Returns a generator which yields the massaged results of this query with the specified SQL verb."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the next entry in the massaged data set.", "response": "def next(self):\n        \"\"\"\n        This method is deprecated, a holdover from when queries were iterators,\n        rather than iterables.\n\n        @return: one element of massaged data.\n        \"\"\"\n        if self._selfiter is None:\n            warnings.warn(\n                \"Calling 'next' directly on a query is deprecated. \"\n                \"Perhaps you want to use iter(query).next(), or something \"\n                \"more expressive like store.findFirst or store.findOrCreate?\",\n                DeprecationWarning, stacklevel=2)\n            self._selfiter = self.__iter__()\n        return self._selfiter.next()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef paginate(self, pagesize=20):\n\n        sort = self.sort\n        oc = list(sort.orderColumns())\n        if not oc:\n            # You can't have an unsorted pagination.\n            sort = self.tableClass.storeID.ascending\n            oc = list(sort.orderColumns())\n        if len(oc) != 1:\n            raise RuntimeError(\"%d-column sorts not supported yet with paginate\" %(len(oc),))\n        sortColumn = oc[0][0]\n        if oc[0][1] == 'ASC':\n            sortOp = operator.gt\n        else:\n            sortOp = operator.lt\n        if _isColumnUnique(sortColumn):\n            # This is the easy case.  There is never a tie to be broken, so we\n            # can just remember our last value and yield from there.  Right now\n            # this only happens when the column is a storeID, but hopefully in\n            # the future we will have more of this.\n            tiebreaker = None\n        else:\n            tiebreaker = self.tableClass.storeID\n\n        tied = lambda a, b: (sortColumn.__get__(a) ==\n                             sortColumn.__get__(b))\n        def _AND(a, b):\n            if a is None:\n                return b\n            return attributes.AND(a, b)\n\n        results = list(self.store.query(self.tableClass, self.comparison,\n                                        sort=sort, limit=pagesize + 1))\n        while results:\n            if len(results) == 1:\n                # XXX TODO: reject 0 pagesize.  If the length of the result set\n                # is 1, there's no next result to test for a tie with, so we\n                # must be at the end, and we should just yield the result and finish.\n                yield results[0]\n                return\n            for resultidx in range(len(results) - 1):\n                # check for a tie.\n                result = results[resultidx]\n                nextResult = results[resultidx + 1]\n                if tied(result, nextResult):\n                    # Yield any ties first, in the appropriate order.\n                    lastTieBreaker = tiebreaker.__get__(result)\n                    # Note that this query is _NOT_ limited: currently large ties\n                    # will generate arbitrarily large amounts of work.\n                    trq = self.store.query(\n                        self.tableClass,\n                        _AND(self.comparison,\n                             sortColumn == sortColumn.__get__(result)))\n                    tiedResults = list(trq)\n                    tiedResults.sort(key=lambda rslt: (sortColumn.__get__(result),\n                                                       tiebreaker.__get__(result)))\n                    for result in tiedResults:\n                        yield result\n                    # re-start the query here ('result' is set to the\n                    # appropriate value by the inner loop)\n                    break\n                else:\n                    yield result\n\n            lastSortValue = sortColumn.__get__(result) # hooray namespace pollution\n            results = list(self.store.query(\n                    self.tableClass,\n                    _AND(self.comparison,\n                         sortOp(sortColumn,\n                                sortColumn.__get__(result))),\n                    sort=sort,\n                    limit=pagesize + 1))", "response": "This method returns an iterable which yields all the results of this query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a row into an Item instance by loading cached items or creating new ones based on query results.", "response": "def _massageData(self, row):\n        \"\"\"\n        Convert a row into an Item instance by loading cached items or\n        creating new ones based on query results.\n\n        @param row: an n-tuple, where n is the number of columns specified by\n        my item type.\n\n        @return: an instance of the type specified by this query.\n        \"\"\"\n        result = self.store._loadedItem(self.tableClass, row[0], row[1:])\n        assert result.store is not None, \"result %r has funky store\" % (result,)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getColumn(self, attributeName, raw=False):\n        # XXX: 'raw' is undocumented because I think it's completely unused,\n        # and it's definitely untested.  It should probably be removed when\n        # someone has the time. -glyph\n\n        # Quotient POP3 server uses it.  Not that it shouldn't be removed.\n        # ;) -exarkun\n        attr = getattr(self.tableClass, attributeName)\n        return AttributeQuery(self.store,\n                              self.tableClass,\n                              self.comparison,\n                              self.limit,\n                              self.offset,\n                              self.sort,\n                              attr,\n                              raw)", "response": "Returns an attribute query for the specified attribute on the Item class that this query was specified by that attribute."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deleteFromStore(self):\n        if (self.limit is None and\n            not isinstance(self.sort, attributes.UnspecifiedOrdering)):\n            # The ORDER BY is pointless here, and SQLite complains about it.\n            return self.cloneQuery(sort=None).deleteFromStore()\n\n        #We can do this the fast way or the slow way.\n\n        # If there's a 'deleted' callback on the Item type or 'deleteFromStore'\n        # is overridden, we have to do it the slow way.\n        deletedOverridden = (\n            self.tableClass.deleted.im_func is not item.Item.deleted.im_func)\n        deleteFromStoreOverridden = (\n            self.tableClass.deleteFromStore.im_func is not\n            item.Item.deleteFromStore.im_func)\n\n        if deletedOverridden or deleteFromStoreOverridden:\n            for it in self:\n                it.deleteFromStore()\n        else:\n\n            # Find other item types whose instances need to be deleted\n            # when items of the type in this query are deleted, and\n            # remove them from the store.\n            def itemsToDelete(attr):\n                return attr.oneOf(self.getColumn(\"storeID\"))\n\n            if not item.allowDeletion(self.store, self.tableClass, itemsToDelete):\n                raise errors.DeletionDisallowed(\n                    'Cannot delete item; '\n                    'has referents with whenDeleted == reference.DISALLOW')\n\n            for it in item.dependentItems(self.store,\n                                          self.tableClass, itemsToDelete):\n                it.deleteFromStore()\n\n            # actually run the DELETE for the items in this query.\n            self._runQuery('DELETE', \"\")", "response": "Delete all the Items which are found by this query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _involvedTables(self):\n        # SQL and arguments\n        if self.comparison is not None:\n            tables = self.comparison.getInvolvedTables()\n            self.args = self.comparison.getArgs(self.store)\n        else:\n            tables = list(self.tableClass)\n            self.args = []\n\n        for tableClass in self.tableClass:\n            if tableClass not in tables:\n                raise ValueError(\n                    \"Comparison omits required reference to result type %s\"\n                    % tableClass.typeName)\n\n        return tables", "response": "Returns a list of tables involved in this query."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _massageData(self, row):\n\n        \"\"\"\n        Convert a row into a tuple of Item instances, by slicing it\n        according to the number of columns for each instance, and then\n        proceeding as for ItemQuery._massageData.\n\n        @param row: an n-tuple, where n is the total number of columns\n        specified by all the item types in this query.\n\n        @return: a tuple of instances of the types specified by this query.\n        \"\"\"\n        offset = 0\n        resultBits = []\n\n        for i, tableClass in enumerate(self.tableClass):\n            numAttrs = self.schemaLengths[i]\n\n            result = self.store._loadedItem(self.tableClass[i],\n                                            row[offset],\n                                            row[offset+1:offset+numAttrs])\n            assert result.store is not None, \"result %r has funky store\" % (result,)\n            resultBits.append(result)\n\n            offset += numAttrs\n\n        return tuple(resultBits)", "response": "Convert a row into a tuple of Item instances by slicing itby the number of columns for each instance and then slicing itby the number of columns for each instance and then returning a tuple of Item instances."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cloneQuery(self, limit=_noItem, sort=_noItem):\n        newq = self.query.cloneQuery(limit=limit, sort=sort)\n        return self.__class__(newq)", "response": "Clone the original query which this distinct query wraps and return a new\n        wrapper around that clone."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of distinct results of the wrapped query.", "response": "def count(self):\n        \"\"\"\n        Count the number of distinct results of the wrapped query.\n\n        @return: an L{int} representing the number of distinct results.\n        \"\"\"\n        if not self.query.store.autocommit:\n            self.query.store.checkpoint()\n        target = ', '.join([\n            tableClass.storeID.getColumnName(self.query.store)\n            for tableClass in self.query.tableClass ])\n        sql, args = self.query._sqlAndArgs(\n            'SELECT DISTINCT',\n            target)\n        sql = 'SELECT COUNT(*) FROM (' + sql + ')'\n        result = self.query.store.querySQL(sql, args)\n        assert len(result) == 1, 'more than one result: %r' % (result,)\n        return result[0][0] or 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _massageData(self, row):\n        if self.raw:\n            return row[0]\n        return self.attribute.outfilter(row[0], _FakeItemForFilter(self.store))", "response": "Convert a raw database row to the type described by an attribute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sum(self):\n        res = self._runQuery('SELECT', 'SUM(%s)' % (self._queryTarget,)) or [(0,)]\n        assert len(res) == 1, \"more than one result: %r\" % (res,)\n        dbval = res[0][0] or 0\n        return self.attribute.outfilter(dbval, _FakeItemForFilter(self.store))", "response": "Returns the sum of all the values returned by this query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the average value of the entries in the current column.", "response": "def average(self):\n        \"\"\"\n        Return the average value (as defined by the AVG implementation in the\n        database) of the values specified by this query.\n\n        Note: for non-numeric column types the result of this method will be\n        nonsensical.\n\n        @return: a L{float} representing the 'average' value of this column.\n        \"\"\"\n        rslt = self._runQuery('SELECT', 'AVG(%s)' % (self._queryTarget,)) or [(0,)]\n        assert len(rslt) == 1, 'more than one result: %r' % (rslt,)\n        return rslt[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _attachChild(self, child):\n        \"attach a child database, returning an identifier for it\"\n        self._childCounter += 1\n        databaseName = 'child_db_%d' % (self._childCounter,)\n        self._attachedChildren[databaseName] = child\n        # ATTACH DATABASE statements can't use bind paramaters, blech.\n        self.executeSQL(\"ATTACH DATABASE '%s' AS %s\" % (\n                child.dbdir.child('db.sqlite').path,\n                databaseName,))\n        return databaseName", "response": "attach a child database returning an identifier for it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling during the initialization of the base class. This method is called by the base class to check consistency of the database with the items in memory and then checks that all of the items in memory are consistent.", "response": "def _startup(self):\n        \"\"\"\n        Called during __init__.  Check consistency of schema in database with\n        classes in memory.  Load all Python modules for stored items, and load\n        version information for upgrader service to run later.\n        \"\"\"\n        typesToCheck = []\n\n        for oid, module, typename, version in self.querySchemaSQL(_schema.ALL_TYPES):\n            if self.debug:\n                print\n                print 'SCHEMA:', oid, module, typename, version\n            if typename not in _typeNameToMostRecentClass:\n                try:\n                    namedAny(module)\n                except ValueError as err:\n                    raise ImportError('cannot find module ' + module, str(err))\n            self.typenameAndVersionToID[typename, version] = oid\n\n        # Can't call this until typenameAndVersionToID is populated, since this\n        # depends on building a reverse map of that.\n        persistedSchema = self._loadTypeSchema()\n\n        # Now that we have persistedSchema, loop over everything again and\n        # prepare old types.\n        for (typename, version), typeID in self.typenameAndVersionToID.iteritems():\n            cls = _typeNameToMostRecentClass.get(typename)\n\n            if cls is not None:\n                if version != cls.schemaVersion:\n                    typesToCheck.append(\n                        self._prepareOldVersionOf(\n                            typename, version, persistedSchema))\n                else:\n                    typesToCheck.append(cls)\n\n        for cls in typesToCheck:\n            self._checkTypeSchemaConsistency(cls, persistedSchema)\n\n        # Schema is consistent!  Now, if I forgot to create any indexes last\n        # time I saw this table, do it now...\n        extantIndexes = self._loadExistingIndexes()\n        for cls in typesToCheck:\n            self._createIndexesFor(cls, extantIndexes)\n\n        self._upgradeManager.checkUpgradePaths()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind an item in the database and create one if not found.", "response": "def findOrCreate(self, userItemClass, __ifnew=None, **attrs):\n        \"\"\"\n        Usage::\n\n            s.findOrCreate(userItemClass [, function] [, x=1, y=2, ...])\n\n        Example::\n\n            class YourItemType(Item):\n                a = integer()\n                b = text()\n                c = integer()\n\n            def f(x):\n                print x, \\\"-- it's new!\\\"\n            s.findOrCreate(YourItemType, f, a=1, b=u'2')\n\n        Search for an item with columns in the database that match the passed\n        set of keyword arguments, returning the first match if one is found,\n        creating one with the given attributes if not.  Takes an optional\n        positional argument function to call on the new item if it is new.\n        \"\"\"\n        andargs = []\n        for k, v in attrs.iteritems():\n            col = getattr(userItemClass, k)\n            andargs.append(col == v)\n\n        if len(andargs) == 0:\n            cond = []\n        elif len(andargs) == 1:\n            cond = [andargs[0]]\n        else:\n            cond = [attributes.AND(*andargs)]\n\n        for result in self.query(userItemClass, *cond):\n            return result\n        newItem = userItemClass(store=self, **attrs)\n        if __ifnew is not None:\n            __ifnew(newItem)\n        return newItem"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a new file somewhere in this Store s file area.", "response": "def newFile(self, *path):\n        \"\"\"\n        Open a new file somewhere in this Store's file area.\n\n        @param path: a sequence of path segments.\n\n        @return: an L{AtomicFile}.\n        \"\"\"\n        assert len(path) > 0, \"newFile requires a nonzero number of segments\"\n        if self.dbdir is None:\n            if self.filesdir is None:\n                raise RuntimeError(\"This in-memory store has no file directory\")\n            else:\n                tmpbase = self.filesdir\n        else:\n            tmpbase = self.dbdir\n        tmpname = tmpbase.child('temp').child(str(tempCounter.next()) + \".tmp\")\n        return AtomicFile(tmpname.path, self.newFilePath(*path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _loadTypeSchema(self):\n\n        # Oops, need an index going the other way.  This only happens once per\n        # store open, and it's based on data queried from the store, so there\n        # doesn't seem to be any broader way to cache and re-use the result.\n        # However, if we keyed the resulting dict on the database typeID rather\n        # than (typeName, schemaVersion), we wouldn't need the information this\n        # dict gives us.  That would mean changing the callers of this function\n        # to use typeID instead of that tuple, which may be possible.  Probably\n        # only represents a very tiny possible speedup.\n        typeIDToNameAndVersion = {}\n        for key, value in self.typenameAndVersionToID.iteritems():\n            typeIDToNameAndVersion[value] = key\n\n        # Indexing attribute, ordering by it, and getting rid of row_offset\n        # from the schema and the sorted() here doesn't seem to be any faster\n        # than doing this.\n        persistedSchema = sorted(self.querySchemaSQL(\n            \"SELECT attribute, type_id, sqltype, indexed, \"\n            \"pythontype, docstring FROM *DATABASE*.axiom_attributes \"))\n\n        # This is trivially (but measurably!) faster than getattr(attributes,\n        # pythontype).\n        getAttribute = attributes.__dict__.__getitem__\n\n        result = {}\n        for (attribute, typeID, sqltype, indexed, pythontype,\n             docstring) in persistedSchema:\n            key = typeIDToNameAndVersion[typeID]\n            if key not in result:\n                result[key] = []\n            result[key].append((\n                    attribute, sqltype, indexed,\n                    getAttribute(pythontype), docstring))\n        return result", "response": "Load all of the stored schema information for all types known by this store."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _checkTypeSchemaConsistency(self, actualType, onDiskSchema):\n        # make sure that both the runtime and the database both know about this\n        # type; if they don't both know, we can't check that their views are\n        # consistent\n        try:\n            inMemorySchema = _inMemorySchemaCache[actualType]\n        except KeyError:\n            inMemorySchema = _inMemorySchemaCache[actualType] = [\n                (storedAttribute.attrname, storedAttribute.sqltype)\n                for (name, storedAttribute) in actualType.getSchema()]\n\n        key = (actualType.typeName, actualType.schemaVersion)\n        persistedSchema = [(storedAttribute[0], storedAttribute[1])\n                           for storedAttribute in onDiskSchema[key]]\n        if inMemorySchema != persistedSchema:\n            raise RuntimeError(\n                \"Schema mismatch on already-loaded %r <%r> object version %d:\\n%s\" %\n                (actualType, actualType.typeName, actualType.schemaVersion,\n                 _diffSchema(persistedSchema, inMemorySchema)))\n\n        if actualType.__legacy__:\n            return\n\n        if (key[0], key[1] + 1) in onDiskSchema:\n            raise RuntimeError(\n                \"Memory version of %r is %d; database has newer\" % (\n                    actualType.typeName, key[1]))", "response": "Called for all known types at database startup. Checks that the schema of the a\n            table is consistent with the schema of the onDiskSchema."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prepareOldVersionOf(self, typename, version, persistedSchema):\n        appropriateSchema = persistedSchema[typename, version]\n        # create actual attribute objects\n        dummyAttributes = {}\n        for (attribute, sqlType, indexed, pythontype,\n             docstring) in appropriateSchema:\n            atr = pythontype(indexed=indexed, doc=docstring)\n            dummyAttributes[attribute] = atr\n        dummyBases = []\n        oldType = declareLegacyItem(\n            typename, version, dummyAttributes, dummyBases)\n        self._upgradeManager.queueTypeUpgrade(oldType)\n        return oldType", "response": "Prepare a dummy item class for the old version of a particular type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef findUnique(self, tableClass, comparison=None, default=_noItem):\n        results = list(self.query(tableClass, comparison, limit=2))\n        lr = len(results)\n\n        if lr == 0:\n            if default is _noItem:\n                raise errors.ItemNotFound(comparison)\n            else:\n                return default\n        elif lr == 2:\n            raise errors.DuplicateUniqueItem(comparison, results)\n        elif lr == 1:\n            return results[0]\n        else:\n            raise AssertionError(\"limit=2 database query returned 3+ results: \",\n                                 comparison, results)", "response": "Find an item in the database which should be unique."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findFirst(self, tableClass, comparison=None,\n                  offset=None, sort=None, default=None):\n        \"\"\"\n        Usage::\n\n            s.findFirst(tableClass [, query arguments except 'limit'])\n\n        Example::\n\n            class YourItemType(Item):\n                a = integer()\n                b = text()\n                c = integer()\n            ...\n            it = s.findFirst(YourItemType,\n                             AND(YourItemType.a == 1,\n                                 YourItemType.b == u'2'),\n                                 sort=YourItemType.c.descending)\n\n        Search for an item with columns in the database that match the passed\n        comparison, offset and sort, returning the first match if one is found,\n        or the passed default (None if none is passed) if one is not found.\n        \"\"\"\n\n        limit = 1\n        for item in self.query(tableClass, comparison, limit, offset, sort):\n            return item\n        return default", "response": "Returns the first item in the database that matches the passed in criteria."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterable of items or items of a certain class.", "response": "def query(self, tableClass, comparison=None,\n              limit=None, offset=None, sort=None):\n        \"\"\"\n        Return a generator of instances of C{tableClass},\n        or tuples of instances if C{tableClass} is a\n        tuple of classes.\n\n        Examples::\n\n            fastCars = s.query(Vehicle,\n                axiom.attributes.AND(\n                    Vehicle.wheels == 4,\n                    Vehicle.maxKPH > 200),\n                limit=100,\n                sort=Vehicle.maxKPH.descending)\n\n            quotesByClient = s.query( (Client, Quote),\n                axiom.attributes.AND(\n                    Client.active == True,\n                    Quote.client == Client.storeID,\n                    Quote.created >= someDate),\n                limit=10,\n                sort=(Client.name.ascending,\n                      Quote.created.descending))\n\n        @param tableClass: a subclass of Item to look for instances of,\n        or a tuple of subclasses.\n\n        @param comparison: a provider of L{IComparison}, or None, to match\n        all items available in the store. If tableClass is a tuple, then\n        the comparison must refer to all Item subclasses in that tuple,\n        and specify the relationships between them.\n\n        @param limit: an int to limit the total length of the results, or None\n        for all available results.\n\n        @param offset: an int to specify a starting point within the available\n        results, or None to start at 0.\n\n        @param sort: an L{ISort}, something that comes from an SQLAttribute's\n        'ascending' or 'descending' attribute.\n\n        @return: an L{ItemQuery} object, which is an iterable of Items or\n        tuples of Items, according to tableClass.\n        \"\"\"\n        if isinstance(tableClass, tuple):\n            queryClass = MultipleItemQuery\n        else:\n            queryClass = ItemQuery\n\n        return queryClass(self, tableClass, comparison, limit, offset, sort)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef batchInsert(self, itemType, itemAttributes, dataRows):\n        class FakeItem:\n            pass\n        _NEEDS_DEFAULT = object() # token for lookup failure\n        fakeOSelf = FakeItem()\n        fakeOSelf.store = self\n        sql = itemType._baseInsertSQL(self)\n        indices = {}\n        schema = [attr for (name, attr) in itemType.getSchema()]\n        for i, attr in enumerate(itemAttributes):\n            indices[attr] = i\n        for row in dataRows:\n            oid = self.store.executeSchemaSQL(\n                _schema.CREATE_OBJECT, [self.store.getTypeID(itemType)])\n            insertArgs = [oid]\n            for attr in schema:\n                i = indices.get(attr, _NEEDS_DEFAULT)\n                if i is _NEEDS_DEFAULT:\n                    pyval = attr.default\n                else:\n                    pyval = row[i]\n                dbval = attr._convertPyval(fakeOSelf, pyval)\n                insertArgs.append(dbval)\n            self.executeSQL(sql, insertArgs)", "response": "Create multiple items in the store without loading corresponding Python objects into memory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd an item to the current transaction s list of changed items.", "response": "def changed(self, item):\n        \"\"\"\n        An item in this store was changed.  Add it to the current transaction's\n        list of changed items, if a transaction is currently underway, or raise\n        an exception if this L{Store} is currently in a state which does not\n        allow changes.\n        \"\"\"\n        if self._rejectChanges:\n            raise errors.ChangeRejected()\n        if self.transaction is not None:\n            self.transaction.add(item)\n            self.touched.add(item)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transact(self, f, *a, **k):\n        if self.transaction is not None:\n            return f(*a, **k)\n        if self.attachedToParent:\n            return self.parent.transact(f, *a, **k)\n        try:\n            self._begin()\n            try:\n                result = f(*a, **k)\n                self.checkpoint()\n            except:\n                exc = Failure()\n                try:\n                    self.revert()\n                except:\n                    log.err(exc)\n                    raise\n                raise\n            else:\n                self._commit()\n            return result\n        finally:\n            self._cleanupTxnState()", "response": "Execute a function in the context of a nested transaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the unqualified name of the given attribute of the given table.", "response": "def _indexNameOf(self, tableClass, attrname):\n        \"\"\"\n        Return the unqualified (ie, no database name) name of the given\n        attribute of the given table.\n\n        @type tableClass: L{MetaItem}\n        @param tableClass: The Python class associated with a table in the\n            database.\n\n        @param attrname: A sequence of the names of the columns of the\n            indicated table which will be included in the named index.\n\n        @return: A C{str} giving the name of the index which will index the\n            given attributes of the given table.\n        \"\"\"\n        return \"axiomidx_%s_v%d_%s\" % (tableClass.typeName,\n                                       tableClass.schemaVersion,\n                                       '_'.join(attrname))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the fully qualified name of the table holding items of a particular class in this store.", "response": "def getTableName(self, tableClass):\n        \"\"\"\n        Retrieve the fully qualified name of the table holding items\n        of a particular class in this store.  If the table does not\n        exist in the database, it will be created as a side-effect.\n\n        @param tableClass: an Item subclass\n\n        @raises axiom.errors.ItemClassesOnly: if an object other than a\n            subclass of Item is passed.\n\n        @return: a string\n        \"\"\"\n        if not (isinstance(tableClass, type) and issubclass(tableClass, item.Item)):\n            raise errors.ItemClassesOnly(\"Only subclasses of Item have table names.\")\n\n        if tableClass not in self.typeToTableNameCache:\n            self.typeToTableNameCache[tableClass] = self._tableNameFor(tableClass.typeName, tableClass.schemaVersion)\n            # make sure the table exists\n            self.getTypeID(tableClass)\n        return self.typeToTableNameCache[tableClass]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getColumnName(self, attribute):\n        if attribute not in self.attrToColumnNameCache:\n            self.attrToColumnNameCache[attribute] = '.'.join(\n                (self.getTableName(attribute.type),\n                 self.getShortColumnName(attribute)))\n        return self.attrToColumnNameCache[attribute]", "response": "Retreive the fully qualified column name for a particular anatomical item in this store."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the typeID associated with a particular table in this Store.", "response": "def getTypeID(self, tableClass):\n        \"\"\"\n        Retrieve the typeID associated with a particular table in the\n        in-database schema for this Store.  A typeID is an opaque integer\n        representing the Item subclass, and the associated table in this\n        Store's SQLite database.\n\n        @param tableClass: a subclass of Item\n\n        @return: an integer\n        \"\"\"\n        key = (tableClass.typeName,\n               tableClass.schemaVersion)\n        if key in self.typenameAndVersionToID:\n            return self.typenameAndVersionToID[key]\n        return self.transact(self._maybeCreateTable, tableClass, key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _justCreateTable(self, tableClass):\n        sqlstr = []\n        sqlarg = []\n\n        # needs to be calculated including version\n        tableName = self._tableNameFor(tableClass.typeName,\n                                       tableClass.schemaVersion)\n\n        sqlstr.append(\"CREATE TABLE %s (\" % tableName)\n\n        # The column is named \"oid\" instead of \"storeID\" for backwards\n        # compatibility with the implicit oid/rowid column in old Stores.\n        sqlarg.append(\"oid INTEGER PRIMARY KEY\")\n        for nam, atr in tableClass.getSchema():\n            sqlarg.append(\"\\n%s %s\" %\n                          (atr.getShortColumnName(self), atr.sqltype))\n\n        sqlstr.append(', '.join(sqlarg))\n        sqlstr.append(')')\n        self.createSQL(''.join(sqlstr))", "response": "Execute the table creation DDL for an Item subclass."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _maybeCreateTable(self, tableClass, key):\n        try:\n            self._justCreateTable(tableClass)\n        except errors.TableAlreadyExists:\n            # Although we don't have a memory of this table from the last time\n            # we called \"_startup()\", another process has updated the schema\n            # since then.\n            self._startup()\n            return self.typenameAndVersionToID[key]\n\n\n        typeID = self.executeSchemaSQL(_schema.CREATE_TYPE,\n                                       [tableClass.typeName,\n                                        tableClass.__module__,\n                                        tableClass.schemaVersion])\n\n        self.typenameAndVersionToID[key] = typeID\n\n        if self.tablesCreatedThisTransaction is not None:\n            self.tablesCreatedThisTransaction.append(tableClass)\n\n        # If the new type is a legacy type (not the current version), we need\n        # to queue it for upgrade to ensure that if we are in the middle of an\n        # upgrade, legacy items of this version get upgraded.\n        cls = _typeNameToMostRecentClass.get(tableClass.typeName)\n        if cls is not None and tableClass.schemaVersion != cls.schemaVersion:\n            self._upgradeManager.queueTypeUpgrade(tableClass)\n\n        # We can pass () for extantIndexes here because since the table didn't\n        # exist for tableClass, none of its indexes could have either.\n        # Whatever checks _createIndexesFor will make would give the same\n        # result against the actual set of existing indexes as they will\n        # against ().\n        self._createIndexesFor(tableClass, ())\n\n        for n, (name, storedAttribute) in enumerate(tableClass.getSchema()):\n            self.executeSchemaSQL(\n                _schema.ADD_SCHEMA_ATTRIBUTE,\n                [typeID, n, storedAttribute.indexed, storedAttribute.sqltype,\n                 storedAttribute.allowNone, storedAttribute.attrname,\n                 storedAttribute.doc, storedAttribute.__class__.__name__])\n            # XXX probably need something better for pythontype eventually,\n            # when we figure out a good way to do user-defined attributes or we\n            # start parameterizing references.\n\n        return typeID", "response": "Internal method to create a new typeID for an Item subclass."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _createIndexesFor(self, tableClass, extantIndexes):\n        try:\n            indexes = _requiredTableIndexes[tableClass]\n        except KeyError:\n            indexes = set()\n            for nam, atr in tableClass.getSchema():\n                if atr.indexed:\n                    indexes.add(((atr.getShortColumnName(self),), (atr.attrname,)))\n                for compound in atr.compoundIndexes:\n                    indexes.add((tuple(inatr.getShortColumnName(self) for inatr in compound),\n                                 tuple(inatr.attrname for inatr in compound)))\n            _requiredTableIndexes[tableClass] = indexes\n\n        # _ZOMFG_ SQL is such a piece of _shit_: you can't fully qualify the\n        # table name in CREATE INDEX statements because the _INDEX_ is fully\n        # qualified!\n\n        indexColumnPrefix = '.'.join(self.getTableName(tableClass).split(\".\")[1:])\n\n        for (indexColumns, indexAttrs) in indexes:\n            nameOfIndex = self._indexNameOf(tableClass, indexAttrs)\n            if nameOfIndex in extantIndexes:\n                continue\n            csql = 'CREATE INDEX %s.%s ON %s(%s)' % (\n                self.databaseName, nameOfIndex, indexColumnPrefix,\n                ', '.join(indexColumns))\n            self.createSQL(csql)", "response": "Create any indexes which don t exist and are required by the schema\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving an item by its storeID and return it. If no item is found return the given default. If autoUpgrade is set to False the item s class version is not available.", "response": "def getItemByID(self, storeID, default=_noItem, autoUpgrade=True):\n        \"\"\"\n        Retrieve an item by its storeID, and return it.\n\n        Note: most of the failure modes of this method are catastrophic and\n        should not be handled by application code.  The only one that\n        application programmers should be concerned with is KeyError.  They are\n        listed for educational purposes.\n\n        @param storeID: an L{int} which refers to the store.\n\n        @param default: if passed, return this value rather than raising in the\n        case where no Item is found.\n\n        @raise TypeError: if storeID is not an integer.\n\n        @raise UnknownItemType: if the storeID refers to an item row in the\n        database, but the corresponding type information is not available to\n        Python.\n\n        @raise RuntimeError: if the found item's class version is higher than\n        the current application is aware of.  (In other words, if you have\n        upgraded a database to a new schema and then attempt to open it with a\n        previous version of the code.)\n\n        @raise errors.ItemNotFound: if no item existed with the given storeID.\n\n        @return: an Item, or the given default, if it was passed and no row\n        corresponding to the given storeID can be located in the database.\n        \"\"\"\n\n        if not isinstance(storeID, (int, long)):\n            raise TypeError(\"storeID *must* be an int or long, not %r\" % (\n                    type(storeID).__name__,))\n        if storeID == STORE_SELF_ID:\n            return self\n        try:\n            return self.objectCache.get(storeID)\n        except KeyError:\n            pass\n        log.msg(interface=iaxiom.IStatEvent, stat_cache_misses=1, key=storeID)\n        results = self.querySchemaSQL(_schema.TYPEOF_QUERY, [storeID])\n        assert (len(results) in [1, 0]),\\\n            \"Database panic: more than one result for TYPEOF!\"\n        if results:\n            typename, module, version = results[0]\n            useMostRecent = False\n            moreRecentAvailable = False\n\n            # The schema may have changed since the last time I saw the\n            # database.  Let's look to see if this is suspiciously broken...\n\n            if _typeIsTotallyUnknown(typename, version):\n                # Another process may have created it - let's re-up the schema\n                # and see what we get.\n                self._startup()\n\n                # OK, all the modules have been loaded now, everything\n                # verified.\n                if _typeIsTotallyUnknown(typename, version):\n\n                    # If there is STILL no inkling of it anywhere, we are\n                    # almost certainly boned.  Let's tell the user in a\n                    # structured way, at least.\n                    raise errors.UnknownItemType(\n                        \"cannot load unknown schema/version pair: %r %r - id: %r\" %\n                        (typename, version, storeID))\n\n            if typename in _typeNameToMostRecentClass:\n                moreRecentAvailable = True\n                mostRecent = _typeNameToMostRecentClass[typename]\n\n                if mostRecent.schemaVersion < version:\n                    raise RuntimeError(\"%s:%d - was found in the database and most recent %s is %d\" %\n                                       (typename, version, typename, mostRecent.schemaVersion))\n                if mostRecent.schemaVersion == version:\n                    useMostRecent = True\n            if useMostRecent:\n                T = mostRecent\n            else:\n                T = self.getOldVersionOf(typename, version)\n\n            # for the moment we're going to assume no inheritance\n            attrs = self.querySQL(T._baseSelectSQL(self), [storeID])\n            if len(attrs) == 0:\n                if default is _noItem:\n                    raise errors.ItemNotFound(\n                        'No results for known-to-be-good object')\n                return default\n            elif len(attrs) > 1:\n                raise errors.DataIntegrityError(\n                    'Too many results for {:d}'.format(storeID))\n            attrs = attrs[0]\n            x = T.existingInStore(self, storeID, attrs)\n            if moreRecentAvailable and (not useMostRecent) and autoUpgrade:\n                # upgradeVersion will do caching as necessary, we don't have to\n                # cache here.  (It must, so that app code can safely call\n                # upgradeVersion and get a consistent object out of it.)\n                x = self.transact(self._upgradeManager.upgradeItem, x)\n            elif not x.__legacy__:\n                # We loaded the most recent version of an object\n                self.objectCache.cache(storeID, x)\n            return x\n        if default is _noItem:\n            raise errors.ItemNotFound(storeID)\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef querySQL(self, sql, args=()):\n        if self.debug:\n            result = timeinto(self.queryTimes, self._queryandfetch, sql, args)\n        else:\n            result = self._queryandfetch(sql, args)\n        return result", "response": "For use with SELECT or SELECT - like PRAGMA statements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a SQL statement and log the time it took to be created.", "response": "def createSQL(self, sql, args=()):\n        \"\"\"\n        For use with auto-committing statements such as CREATE TABLE or CREATE\n        INDEX.\n        \"\"\"\n        before = time.time()\n        self._execSQL(sql, args)\n        after = time.time()\n        if after - before > 2.0:\n            log.msg('Extremely long CREATE: %s' % (after - before,))\n            log.msg(sql)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a SQL query and returns the ID of the last row.", "response": "def executeSQL(self, sql, args=()):\n        \"\"\"\n        For use with UPDATE or INSERT statements.\n        \"\"\"\n        sql = self._execSQL(sql, args)\n        result = self.cursor.lastRowID()\n        if self.executedThisTransaction is not None:\n            self.executedThisTransaction.append((result, sql, args))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a filename to a file containing a __counter__ variable, open it, read the count, add one, rewrite the file. This: __counter__=123 Becomes: __counter__=124", "response": "def updateVersion(fname):\n    \"\"\"\n    given a filename to a file containing a __counter__ variable,\n    open it, read the count, add one, rewrite the file.\n\n    This:\n        __counter__=123\n    Becomes:\n        __counter__=124\n\n    \"\"\"\n    fname=os.path.abspath(fname)\n    if not os.path.exists(fname):\n        print(\"can not update version! file doesn't exist:\\n\",fname)\n        return\n    with open(fname) as f:\n        raw=f.read().split(\"\\n\")\n    for i,line in enumerate(raw):\n        if line.startswith(\"__counter__=\"):\n            version=int(line.split(\"=\")[1])\n            raw[i]=\"__counter__=%d\"%(version+1)\n    with open(fname,'w') as f:\n        f.write(\"\\n\".join(raw))\n    print(\"upgraded version %d -> %d\"%(version,version+1))\n    sys.path.insert(0,os.path.dirname(fname))\n    import version\n    print(\"New version:\",version.__version__)\n    with open('version.txt','w') as f:\n        f.write(str(version.__version__))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupgrade the given L_SubSchedulerParentHook to version 1 to 2.", "response": "def upgradeParentHook1to2(oldHook):\n    \"\"\"\n    Add the scheduler attribute to the given L{_SubSchedulerParentHook}.\n    \"\"\"\n    newHook = oldHook.upgradeVersion(\n        oldHook.typeName, 1, 2,\n        loginAccount=oldHook.loginAccount,\n        scheduledAt=oldHook.scheduledAt,\n        scheduler=oldHook.store.findFirst(Scheduler))\n    return newHook"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upgradeParentHook3to4(old):\n    new = old.upgradeVersion(\n        old.typeName, 3, 4, subStore=old.loginAccount)\n    uninstallFrom(new, new.store)\n    return new", "response": "Upgrade parent hook 3 to 4."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invokeRunnable(self):\n        runnable = self.runnable\n        if runnable is None:\n            self.deleteFromStore()\n        else:\n            try:\n                self.running = True\n                newTime = runnable.run()\n            finally:\n                self.running = False\n            self._rescheduleFromRun(newTime)", "response": "Invoke the runnable and reschedule it if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handleError(self, now, failureObj):\n        errorHandler = getattr(self.runnable, 'timedEventErrorHandler', None)\n        if errorHandler is not None:\n            self._rescheduleFromRun(errorHandler(self, failureObj))\n        else:\n            self._defaultErrorHandler(now, failureObj)", "response": "Called by the error handler method of the TimedEventThread class to handle the given failure object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unscheduleFirst(self, runnable):\n        for evt in self.store.query(TimedEvent, TimedEvent.runnable == runnable, sort=TimedEvent.time.ascending):\n            evt.deleteFromStore()\n            break", "response": "Remove from given item from the schedule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterable of the times at which the given item is scheduled to be run.", "response": "def scheduledTimes(self, runnable):\n        \"\"\"\n        Return an iterable of the times at which the given item is scheduled to\n        run.\n        \"\"\"\n        events = self.store.query(\n            TimedEvent, TimedEvent.runnable == runnable)\n        return (event.time for event in events if not event.running)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef startService(self):\n        super(_SiteScheduler, self).startService()\n        self._transientSchedule(self.now(), self.now())", "response": "Start calling persistent timed events whose time has come."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stopService(self):\n        super(_SiteScheduler, self).stopService()\n        if self.timer is not None:\n            self.timer.cancel()\n            self.timer = None", "response": "Stop calling persistent timed events."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _transientSchedule(self, when, now):\n        if not self.running:\n            return\n        if self.timer is not None:\n            if self.timer.getTime() < when.asPOSIXTimestamp():\n                return\n            self.timer.cancel()\n        delay = when.asPOSIXTimestamp() - now.asPOSIXTimestamp()\n\n        # reactor.callLater allows only positive delay values.  The scheduler\n        # may want to have scheduled things in the past and that's OK, since we\n        # are dealing with Time() instances it's impossible to predict what\n        # they are relative to the current time from user code anyway.\n        delay = max(_EPSILON, delay)\n        self.timer = self.callLater(delay, self.tick)\n        self.nextEventAt = when", "response": "Schedule a tick to happen later than C { when }."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscheduling this service s store to tick at the given time.", "response": "def _transientSchedule(self, when, now):\n        \"\"\"\n        If this service's store is attached to its parent, ask the parent to\n        schedule this substore to tick at the given time.\n\n        @param when: The time at which to tick.\n        @type when: L{epsilon.extime.Time}\n\n        @param now: Present for signature compatibility with\n            L{_SiteScheduler._transientSchedule}, but ignored otherwise.\n        \"\"\"\n        if self.store.parent is not None:\n            subStore = self.store.parent.getItemByID(self.store.idInParent)\n            hook = self.store.parent.findOrCreate(\n                _SubSchedulerParentHook,\n                subStore=subStore)\n            hook._schedule(when)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the components in the site store for this SubScheduler.", "response": "def migrateDown(self):\n        \"\"\"\n        Remove the components in the site store for this SubScheduler.\n        \"\"\"\n        subStore = self.store.parent.getItemByID(self.store.idInParent)\n        ssph = self.store.parent.findUnique(\n            _SubSchedulerParentHook,\n            _SubSchedulerParentHook.subStore == subStore,\n            default=None)\n        if ssph is not None:\n            te = self.store.parent.findUnique(TimedEvent,\n                                              TimedEvent.runnable == ssph,\n                                              default=None)\n            if te is not None:\n                te.deleteFromStore()\n            ssph.deleteFromStore()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrecreate the hooks in the site store to trigger this SubScheduler.", "response": "def migrateUp(self):\n        \"\"\"\n        Recreate the hooks in the site store to trigger this SubScheduler.\n        \"\"\"\n        te = self.store.findFirst(TimedEvent, sort=TimedEvent.time.descending)\n        if te is not None:\n            self._transientSchedule(te.time, None)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef activate(self):\n        # This is unfortunate.  Perhaps it is the best thing which works (it is\n        # the first I found). -exarkun\n        if '_axiom_memory_dummy' in vars(self):\n            stacklevel = 7\n        else:\n            stacklevel = 5\n        warnings.warn(\n            self.__class__.__name__ + \" is deprecated since Axiom 0.5.32.  \"\n            \"Just adapt stores to IScheduler.\",\n            category=PendingDeprecationWarning,\n            stacklevel=stacklevel)", "response": "Activates the current IScheduler."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nschedules this hook at a specific time.", "response": "def _schedule(self, when):\n        \"\"\"\n        Ensure that this hook is scheduled to run at or before C{when}.\n        \"\"\"\n        sched = IScheduler(self.store)\n        for scheduledAt in sched.scheduledTimes(self):\n            if when < scheduledAt:\n                sched.reschedule(self, scheduledAt, when)\n            break\n        else:\n            sched.schedule(self, when)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_graph(path, term_depth=1000, skim_depth=10,\n                d_weights=False, **kwargs):\n\n    \"\"\"\n    Tokenize a text, index a term matrix, and build out a graph.\n\n    Args:\n        path (str): The file path.\n        term_depth (int): Consider the N most frequent terms.\n        skim_depth (int): Connect each word to the N closest siblings.\n        d_weights (bool): If true, give \"close\" nodes low weights.\n\n    Returns:\n        Skimmer: The indexed graph.\n    \"\"\"\n\n    # Tokenize text.\n    click.echo('\\nTokenizing text...')\n    t = Text.from_file(path)\n    click.echo('Extracted %d tokens' % len(t.tokens))\n\n    m = Matrix()\n\n    # Index the term matrix.\n    click.echo('\\nIndexing terms:')\n    m.index(t, t.most_frequent_terms(term_depth), **kwargs)\n\n    g = Skimmer()\n\n    # Construct the network.\n    click.echo('\\nGenerating graph:')\n    g.build(t, m, skim_depth, d_weights)\n\n    return g", "response": "Builds a graph from a text file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw_spring(self, **kwargs):\n\n        \"\"\"\n        Render a spring layout.\n        \"\"\"\n\n        nx.draw_spring(\n            self.graph,\n            with_labels=True,\n            font_size=10,\n            edge_color='#dddddd',\n            node_size=0,\n            **kwargs\n        )\n\n        plt.show()", "response": "Render a spring layout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build(self, text, matrix, skim_depth=10, d_weights=False):\n\n        \"\"\"\n        1. For each term in the passed matrix, score its KDE similarity with\n        all other indexed terms.\n\n        2. With the ordered stack of similarities in hand, skim off the top X\n        pairs and add them as edges.\n\n        Args:\n            text (Text): The source text instance.\n            matrix (Matrix): An indexed term matrix.\n            skim_depth (int): The number of siblings for each term.\n            d_weights (bool): If true, give \"close\" words low edge weights.\n        \"\"\"\n\n        for anchor in bar(matrix.keys):\n\n            n1 = text.unstem(anchor)\n\n            # Heaviest pair scores:\n            pairs = matrix.anchored_pairs(anchor).items()\n            for term, weight in list(pairs)[:skim_depth]:\n\n                # If edges represent distance, use the complement of the raw\n                # score, so that similar words are connected by \"short\" edges.\n                if d_weights: weight = 1-weight\n\n                n2 = text.unstem(term)\n\n                # NetworkX does not handle numpy types when writing graphml,\n                # so we cast the weight to a regular float.\n                self.graph.add_edge(n1, n2, weight=float(weight))", "response": "Builds the KDE graph from the passed text and matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a configuration dictionary from the configuration source.", "response": "def get_settings(self, section=None, defaults=None):\n        \"\"\"\n        Gets a named section from the configuration source.\n\n        :param section: a :class:`str` representing the section you want to\n            retrieve from the configuration source. If ``None`` this will\n            fallback to the :attr:`plaster.PlasterURL.fragment`.\n        :param defaults: a :class:`dict` that will get passed to\n            :class:`configparser.ConfigParser` and will populate the\n            ``DEFAULT`` section.\n        :return: A :class:`plaster_pastedeploy.ConfigDict` of key/value pairs.\n\n        \"\"\"\n        # This is a partial reimplementation of\n        # ``paste.deploy.loadwsgi.ConfigLoader:get_context`` which supports\n        # \"set\" and \"get\" options and filters out any other globals\n        section = self._maybe_get_default_name(section)\n        if self.filepath is None:\n            return {}\n        parser = self._get_parser(defaults)\n        defaults = parser.defaults()\n\n        try:\n            raw_items = parser.items(section)\n        except NoSectionError:\n            return {}\n\n        local_conf = OrderedDict()\n        get_from_globals = {}\n        for option, value in raw_items:\n            if option.startswith(\"set \"):\n                name = option[4:].strip()\n                defaults[name] = value\n            elif option.startswith(\"get \"):\n                name = option[4:].strip()\n                get_from_globals[name] = value\n                # insert a value into local_conf to preserve the order\n                local_conf[name] = None\n            else:\n                # annoyingly pastedeploy filters out all defaults unless\n                # \"get foo\" is used to pull it in\n                if option in defaults:\n                    continue\n                local_conf[option] = value\n        for option, global_option in get_from_globals.items():\n            local_conf[option] = defaults[global_option]\n        return ConfigDict(local_conf, defaults, self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_wsgi_app(self, name=None, defaults=None):\n        name = self._maybe_get_default_name(name)\n        defaults = self._get_defaults(defaults)\n        return loadapp(\n            self.pastedeploy_spec,\n            name=name,\n            relative_to=self.relative_to,\n            global_conf=defaults,\n        )", "response": "Reads the configuration source and loads a WSGI application defined by the entry with name name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_wsgi_server(self, name=None, defaults=None):\n        name = self._maybe_get_default_name(name)\n        defaults = self._get_defaults(defaults)\n        return loadserver(\n            self.pastedeploy_spec,\n            name=name,\n            relative_to=self.relative_to,\n            global_conf=defaults,\n        )", "response": "Reads the configuration source and returns a WSGI server object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_wsgi_filter(self, name=None, defaults=None):\n        name = self._maybe_get_default_name(name)\n        defaults = self._get_defaults(defaults)\n        return loadfilter(\n            self.pastedeploy_spec,\n            name=name,\n            relative_to=self.relative_to,\n            global_conf=defaults,\n        )", "response": "Reads the configuration soruce and returns a WSGI filter that can be used for the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary representing the application settings for a named WSGI application.", "response": "def get_wsgi_app_settings(self, name=None, defaults=None):\n        \"\"\"\n        Return an :class:`collections.OrderedDict` representing the\n        application config for a WSGI application named ``name`` in the\n        PasteDeploy config file specified by ``self.uri``.\n\n        ``defaults``, if passed, should be a dictionary used as variable\n        assignments like ``{'http_port': 8080}``.  This is useful if e.g.\n        ``%(http_port)s`` is used in the config file.\n\n        If the ``name`` is None, this will attempt to parse the name from\n        the ``config_uri`` string expecting the format ``inifile#name``.\n        If no name is found, the name will default to \"main\".\n\n        :param name: The named WSGI app for which to find the settings.\n            Defaults to ``None`` which becomes ``main``\n            inside :func:`paste.deploy.loadapp`.\n        :param defaults: The ``global_conf`` that will be used during settings\n            generation.\n        :return: A :class:`plaster_pastedeploy.ConfigDict` of key/value pairs.\n\n        \"\"\"\n        name = self._maybe_get_default_name(name)\n        defaults = self._get_defaults(defaults)\n        conf = appconfig(\n            self.pastedeploy_spec,\n            name=name,\n            relative_to=self.relative_to,\n            global_conf=defaults,\n        )\n        return ConfigDict(conf.local_conf, conf.global_conf, self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_logging(self, defaults=None):\n        if \"loggers\" in self.get_sections():\n            defaults = self._get_defaults(defaults)\n            fileConfig(self.uri.path, defaults, disable_existing_loggers=False)\n\n        else:\n            logging.basicConfig()", "response": "Setup logging via logging. config. fileConfig."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _maybe_get_default_name(self, name):\n        if name is None and self.uri.fragment:\n            name = self.uri.fragment\n        return name", "response": "Checks a name and determines whether to use the default name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, hue):\n        x = hue / 360. * self.winfo_width()\n        self.coords('cursor', x, 0, x, self.winfo_height())\n        self._variable.set(hue)", "response": "Set cursor position on the color corresponding to the hue value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an L{IService for the database specified by the given options.", "response": "def makeService(cls, options):\n        \"\"\"\n        Create an L{IService} for the database specified by the given\n        configuration.\n        \"\"\"\n        from axiom.store import Store\n        jm = options['journal-mode']\n        if jm is not None:\n            jm = jm.decode('ascii')\n        store = Store(options['dbdir'], debug=options['debug'], journalMode=jm)\n        service = IService(store)\n        _CheckSystemVersion(store).setServiceParent(service)\n        return service"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the names of all pages in the project.", "response": "def pageNames(matching=False,workbooks=True,graphs=True):\n    \"\"\"\n    Returns the names of everything (books, notes, graphs, etc.) in the project.\n\n    Args:\n        matching (str, optional): if given, only return names with this string in it\n        workbooks (bool): if True, return workbooks\n        graphs (bool): if True, return workbooks\n\n    Returns:\n        A list of the names of what you requested\n    \"\"\"\n    # first collect the pages we want\n    pages=[]\n    if workbooks:\n        pages.extend(PyOrigin.WorksheetPages())\n    if graphs:\n        pages.extend(PyOrigin.GraphPages())\n\n    # then turn them into a list of strings\n    pages = [x.GetName() for x in pages]\n\n    # do our string matching if it's needed\n    if matching:\n        pages=[x for x in pages if matching in x]\n    return pages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the type of the page with that name.", "response": "def getPageType(name,number=False):\n    \"\"\"Returns the type of the page with that name.\n    If that name doesn't exist, None is returned.\n\n    Args:\n        name (str): name of the page to get the folder from\n        number (bool): if True, return numbers (i.e., a graph will be 3)\n            if False, return words where appropriate (i.e, \"graph\")\n\n    Returns:\n        string of the type of object the page is\n    \"\"\"\n    if not name in pageNames():\n        return None\n    pageType=PyOrigin.Pages(name).GetType()\n    if number:\n        return str(pageType)\n    if pageType==1:\n        return \"matrix\"\n    if pageType==2:\n        return \"book\"\n    if pageType==3:\n        return \"graph\"\n    if pageType==4:\n        return \"layout\"\n    if pageType==5:\n        return \"notes\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting every page in the project to the console.", "response": "def listEverything(matching=False):\n    \"\"\"Prints every page in the project to the console.\n\n    Args:\n        matching (str, optional): if given, only return names with this string in it\n\n    \"\"\"\n    pages=pageNames()\n    if matching:\n        pages=[x for x in pages if matching in x]\n    for i,page in enumerate(pages):\n        pages[i]=\"%s%s (%s)\"%(pageFolder(page),page,getPageType(page))\n    print(\"\\n\".join(sorted(pages)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sheetNames(book=None):\n    if book:\n        if not book.lower() in [x.lower() for x in bookNames()]:\n            return False\n    else:\n        book=activeBook()\n    if not book:\n        return False\n    poBook=PyOrigin.WorksheetPages(book)\n    if not len(poBook):\n        return None\n    return [x.GetName() for x in poBook.Layers()]", "response": "Return a list of sheet names of a given book."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getSheet(book=None,sheet=None):\n\n    # figure out what book to use\n    if book and not book.lower() in [x.lower() for x in bookNames()]:\n        print(\"book %s doesn't exist\"%book)\n        return\n    if book is None:\n        book=activeBook().lower()\n    if book is None:\n        print(\"no book given or selected\")\n        return\n\n    # figure out what sheet to use\n    if sheet and not sheet.lower() in [x.lower() for x in sheetNames(book)]:\n        print(\"sheet %s doesn't exist\"%sheet)\n        return\n    if sheet is None:\n        sheet=activeSheet().lower()\n    if sheet is None:\n        return(\"no sheet given or selected\")\n        print\n\n    # by now, we know the book/sheet exists and can be found\n    for poSheet in PyOrigin.WorksheetPages(book).Layers():\n        if poSheet.GetName().lower()==sheet.lower():\n            return poSheet\n    return False", "response": "returns the pyorigin object for a sheet"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a sheet from a book.", "response": "def sheetDelete(book=None,sheet=None):\n    \"\"\"\n    Delete a sheet from a book. If either isn't given, use the active one.\n    \"\"\"\n    if book is None:\n        book=activeBook()\n    if sheet in sheetNames():\n        PyOrigin.WorksheetPages(book).Layers(sheetNames().index(sheet)).Destroy()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete all sheets which contain no data", "response": "def sheetDeleteEmpty(bookName=None):\n    \"\"\"Delete all sheets which contain no data\"\"\"\n    if bookName is None:\n        bookName = activeBook()\n    if not bookName.lower() in [x.lower() for x in bookNames()]:\n        print(\"can't clean up a book that doesn't exist:\",bookName)\n        return\n    poBook=PyOrigin.WorksheetPages(bookName)\n    namesToKill=[]\n    for i,poSheet in enumerate([poSheet for poSheet in poBook.Layers()]):\n        poFirstCol=poSheet.Columns(0)\n        if poFirstCol.GetLongName()==\"\" and poFirstCol.GetData()==[]:\n            namesToKill.append(poSheet.GetName())\n    for sheetName in namesToKill:\n        print(\"deleting empty sheet\",sheetName)\n        sheetDelete(bookName,sheetName)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pickle_load(fname):\n    assert type(fname) is str and os.path.exists(fname)\n    print(\"loaded\",fname)\n    return pickle.load(open(fname,\"rb\"))", "response": "return the contents of a pickle file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pickle_save(thing,fname=None):\n    if fname is None:\n        fname=os.path.expanduser(\"~\")+\"/%d.pkl\"%time.time()\n    assert type(fname) is str and os.path.isdir(os.path.dirname(fname))\n    pickle.dump(thing, open(fname,\"wb\"),pickle.HIGHEST_PROTOCOL)\n    print(\"saved\",fname)", "response": "save something to a pickle file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a PySheets. Sheets object into a temporary HTML file.", "response": "def sheetToHTML(sheet):\n    \"\"\"\n    Put 2d numpy data into a temporary HTML file.\n    This is a hack, copy/pasted from an earlier version of this software.\n    It is very messy, but works great! Good enough for me.\n    \"\"\"\n\n    assert \"SHEET\" in str(type(sheet))\n    #data,names=None,units=None,bookName=None,sheetName=None,xCol=None\n    #sheet=OR.SHEET()\n    data=sheet.data\n    names=sheet.colDesc\n    units=sheet.colUnits\n    bookName=sheet.bookName\n    sheetName=sheet.sheetName\n\n    def htmlListToTR(l,trClass=None,tdClass=None,td1Class=None):\n        \"\"\"\n        turns a list into a <tr><td>something</td></tr>\n        call this when generating HTML tables dynamically.\n        \"\"\"\n        html=\"<tr>\"\n        for item in l:\n            html+=\"<td>%s</td>\"%item\n        html+=\"</tr>\"\n        if trClass:\n            html=html.replace(\"<tr>\",'<tr class=\"%s\">'%trClass)\n        if td1Class:\n            html=html.replace(\"<td>\",'<td class=\"%s\">'%td1Class,1)\n        if tdClass:\n            html=html.replace(\"<td>\",'<td class=\"%s\">'%tdClass)\n        return html\n\n    htmlFname = os.path.expanduser(\"~\")+\"/WKS-%s.%s.html\"%(bookName,sheetName)\n    html=\"\"\"<body>\n    <style>\n    body {\n          background-color: #ababab;\n          padding:20px;\n          }\n    table {\n           font-size:12px;\n           border-spacing: 0;\n           border-collapse: collapse;\n           }\n    .name {background-color:#fafac8;text-align:center;}\n    .units {background-color:#fafac8;text-align:center;}\n    .data0 {background-color:#FFFFFF;font-family: monospace;text-align:center;}\n    .data1 {background-color:#FAFAFA;font-family: monospace;text-align:center;}\n    .labelRow {background-color:#e0dfe4; text-align:right;border:1px solid #000000;}\n    .labelCol {background-color:#e0dfe4; text-align:center;border:1px solid #000000;  padding-left: 20px; padding-right: 20px;}\n    td {\n        border:1px solid #c0c0c0; padding:5px;\n        font-family: Arial, Helvetica, sans-serif;\n        }\n    </style>\n    <html>\"\"\"\n    html+=\"<h1>FauxRigin</h1>\"\n    if bookName or sheetName:\n        html+='<code><b>%s / %s</b></code><br><br>'%(bookName,sheetName)\n    html+=\"<table>\"\n    colNames=['']\n    for i in range(len(units)):\n        shortName=chr(i%26+ord('A'))\n        if i>=26:\n            shortName=chr(int(i/26-1)+ord('A'))+shortName\n        label=\"%s(%s)\"%(shortName,\"X\" if sheet.colTypes[i]==3 else \"Y\")\n        colNames.append(label)\n    html+=htmlListToTR(colNames,'labelCol','labelCol')\n    html+=htmlListToTR(['Long Name']+list(names),'name',td1Class='labelRow')\n    html+=htmlListToTR(['Units']+list(units),'units',td1Class='labelRow')\n    cutOff=False\n    for y in range(len(data)):\n        html+=htmlListToTR([y+1]+list(data[y]),trClass='data%d'%(y%2),td1Class='labelRow')\n        if y>=200:\n            cutOff=True\n            break\n    html+=\"</table>\"\n    html=html.replace(\">nan<\",\">--<\")\n    html=html.replace(\">None<\",\"><\")\n    if cutOff:\n        html+=\"<h3>... showing only %d of %d rows ...</h3>\"%(y,len(data))\n    html+=\"</body></html>\"\n    with open(htmlFname,'w') as f:\n        f.write(html)\n    import webbrowser\n    webbrowser.open(htmlFname)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict with the code for each function", "response": "def getCodeBlocks():\n    \"\"\"return a dict with the code for each function\"\"\"\n    raw=open(\"examples.py\").read()\n    d={}\n    for block in raw.split(\"if __name__\")[0].split(\"\\ndef \"):\n        title=block.split(\"\\n\")[0].split(\"(\")[0]\n        if not title.startswith(\"demo_\"):\n            continue\n        code=[x[4:] for x in block.split(\"\\n\")[1:] if x.startswith(\"    \")]\n        d[title]=\"\\n\".join(code).strip()\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict with the output of each function", "response": "def getOutputBlocks():\n    \"\"\"return a dict with the output of each function\"\"\"\n    raw=open(\"output.txt\").read()\n    d={}\n    for block in raw.split(\"\\n####### \")[1:]:\n        title=block.split(\"\\n\")[0].split(\"(\")[0]\n        block=block.split(\"\\n\",1)[1].strip()\n        d[title]=block.split(\"\\nfinished in \")[0]\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nturns a byte string from the command line into a unicode string.", "response": "def decodeCommandLine(self, cmdline):\n        \"\"\"Turn a byte string from the command line into a unicode string.\n        \"\"\"\n        codec = getattr(sys.stdin, 'encoding', None) or sys.getdefaultencoding()\n        return unicode(cmdline, codec)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tokenize(text):\n\n    \"\"\"\n    Yield tokens.\n\n    Args:\n        text (str): The original text.\n\n    Yields:\n        dict: The next token.\n    \"\"\"\n\n    stem = PorterStemmer().stem\n    tokens = re.finditer('[a-z]+', text.lower())\n\n    for offset, match in enumerate(tokens):\n\n        # Get the raw token.\n        unstemmed = match.group(0)\n\n        yield { # Emit the token.\n            'stemmed':      stem(unstemmed),\n            'unstemmed':    unstemmed,\n            'offset':       offset\n        }", "response": "Yields the next token in the text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort_dict(d, desc=True):\n\n    \"\"\"\n    Sort an ordered dictionary by value, descending.\n\n    Args:\n        d (OrderedDict): An ordered dictionary.\n        desc (bool): If true, sort desc.\n\n    Returns:\n        OrderedDict: The sorted dictionary.\n    \"\"\"\n\n    sort = sorted(d.items(), key=lambda x: x[1], reverse=desc)\n    return OrderedDict(sort)", "response": "Sort an ordered dictionary by value descending."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef window(seq, n=2):\n\n    \"\"\"\n    Yield a sliding window over an iterable.\n\n    Args:\n        seq (iter): The sequence.\n        n (int): The window width.\n\n    Yields:\n        tuple: The next window.\n    \"\"\"\n\n    it = iter(seq)\n    result = tuple(islice(it, n))\n\n    if len(result) == n:\n        yield result\n\n    for token in it:\n        result = result[1:] + (token,)\n        yield result", "response": "Yields a sliding window over an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a new user store into the given site store.", "response": "def insertUserStore(siteStore, userStorePath):\n    \"\"\"\n    Move the SubStore at the indicated location into the given site store's\n    directory and then hook it up to the site store's authentication database.\n\n    @type siteStore: C{Store}\n    @type userStorePath: C{FilePath}\n    \"\"\"\n    # The following may, but does not need to be in a transaction, because it\n    # is merely an attempt to guess a reasonable filesystem name to use for\n    # this avatar.  The user store being operated on is expected to be used\n    # exclusively by this process.\n    ls = siteStore.findUnique(LoginSystem)\n    unattachedSubStore = Store(userStorePath)\n    for lm in unattachedSubStore.query(LoginMethod,\n                                       LoginMethod.account == unattachedSubStore.findUnique(LoginAccount),\n                                       sort=LoginMethod.internal.descending):\n        if ls.accountByAddress(lm.localpart, lm.domain) is None:\n            localpart, domain = lm.localpart, lm.domain\n            break\n    else:\n        raise AllNamesConflict()\n\n    unattachedSubStore.close()\n\n    insertLocation = siteStore.newFilePath('account', domain, localpart + '.axiom')\n    insertParentLoc = insertLocation.parent()\n    if not insertParentLoc.exists():\n        insertParentLoc.makedirs()\n    if insertLocation.exists():\n        raise DatabaseDirectoryConflict()\n    userStorePath.moveTo(insertLocation)\n    ss = SubStore(store=siteStore, storepath=insertLocation)\n    attachedStore = ss.open()\n    # migrateUp() manages its own transactions because it interacts with two\n    # different stores.\n    attachedStore.findUnique(LoginAccount).migrateUp()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extractUserStore(userAccount, extractionDestination, legacySiteAuthoritative=True):\n    if legacySiteAuthoritative:\n        # migrateDown() manages its own transactions, since it is copying items\n        # between two different stores.\n        userAccount.migrateDown()\n    av = userAccount.avatars\n    av.open().close()\n    def _():\n        # We're separately deleting several Items from the site store, then\n        # we're moving some files.  If we cannot move the files, we don't want\n        # to delete the items.\n\n        # There is one unaccounted failure mode here: if the destination of the\n        # move is on a different mount point, the moveTo operation will fall\n        # back to a non-atomic copy; if all of the copying succeeds, but then\n        # part of the deletion of the source files fails, we will be left\n        # without a complete store in this site store's files directory, but\n        # the account Items will remain.  This will cause odd errors on login\n        # and at other unpredictable times.  The database is only one file, so\n        # we will either remove it all or none of it.  Resolving this requires\n        # manual intervention currently: delete the substore's database\n        # directory and the account items (LoginAccount and LoginMethods)\n        # manually.\n\n        # However, this failure is extremely unlikely, as it would almost\n        # certainly indicate a misconfiguration of the permissions on the site\n        # store's files area.  As described above, a failure of the call to\n        # os.rename(), if the platform's rename is atomic (which it generally\n        # is assumed to be) will not move any files and will cause a revert of\n        # the transaction which would have deleted the accompanying items.\n\n        av.deleteFromStore()\n        userAccount.deleteLoginMethods()\n        userAccount.deleteFromStore()\n        av.storepath.moveTo(extractionDestination)\n    userAccount.store.transact(_)", "response": "Move the SubStore for the given user account out of the given site store and place it into the given destination directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves all login methods in the given store optionally constraining them by protocol", "response": "def getLoginMethods(store, protocol=None):\n    \"\"\"\n    Retrieve L{LoginMethod} items from store C{store}, optionally constraining\n    them by protocol\n    \"\"\"\n    if protocol is not None:\n        comp = OR(LoginMethod.protocol == u'*',\n                  LoginMethod.protocol == protocol)\n    else:\n        comp = None\n    return store.query(LoginMethod, comp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAccountNames(store, protocol=None):\n    return ((meth.localpart, meth.domain) for meth\n                in getLoginMethods(store, protocol))", "response": "Retrieve account name information about the given database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a list of all local domain names represented in the given store.", "response": "def getDomainNames(store):\n    \"\"\"\n    Retrieve a list of all local domain names represented in the given store.\n    \"\"\"\n    domains = set()\n    domains.update(store.query(\n            LoginMethod,\n            AND(LoginMethod.internal == True,\n                LoginMethod.domain != None)).getColumn(\"domain\").distinct())\n    return sorted(domains)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef migrateDown(self):\n        ss = self.avatars.open()\n        def _():\n            oldAccounts = ss.query(LoginAccount)\n            oldMethods = ss.query(LoginMethod)\n            for x in list(oldAccounts) + list(oldMethods):\n                x.deleteFromStore()\n            self.cloneInto(ss, ss)\n            IScheduler(ss).migrateDown()\n        ss.transact(_)", "response": "Migrate all the entries from the site store into the site store."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef migrateUp(self):\n        siteStore = self.store.parent\n        def _():\n            # No convenience method for the following because needing to do it is\n            # *rare*.  It *should* be ugly; 99% of the time if you need to do this\n            # you're making a mistake. -glyph\n            siteStoreSubRef = siteStore.getItemByID(self.store.idInParent)\n            self.cloneInto(siteStore, siteStoreSubRef)\n            IScheduler(self.store).migrateUp()\n        siteStore.transact(_)", "response": "Copy this LoginAccount and all associated LoginMethods from my store into the immutable object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cloneInto(self, newStore, avatars):\n        la = LoginAccount(store=newStore,\n                          password=self.password,\n                          avatars=avatars,\n                          disabled=self.disabled)\n        for siteMethod in self.store.query(LoginMethod,\n                                           LoginMethod.account == self):\n            LoginMethod(store=newStore,\n                        localpart=siteMethod.localpart,\n                        domain=siteMethod.domain,\n                        internal=siteMethod.internal,\n                        protocol=siteMethod.protocol,\n                        verified=siteMethod.verified,\n                        account=la)\n        return la", "response": "Create a copy of this LoginAccount and all associated LoginMethods in a different Store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addLoginMethod(self, localpart, domain, protocol=ANY_PROTOCOL, verified=False, internal=False):\n        # Out takes you west or something\n        if self.store.parent is None:\n            # West takes you in\n            otherStore = self.avatars.open()\n            peer = otherStore.findUnique(LoginAccount)\n        else:\n            # In takes you east\n            otherStore = self.store.parent\n            subStoreItem = self.store.parent.getItemByID(self.store.idInParent)\n            peer = otherStore.findUnique(LoginAccount,\n                                         LoginAccount.avatars == subStoreItem)\n\n        # Up and down take you home\n        for store, account in [(otherStore, peer), (self.store, self)]:\n            store.findOrCreate(LoginMethod,\n                               account=account,\n                               localpart=localpart,\n                               domain=domain,\n                               protocol=protocol,\n                               verified=verified,\n                               internal=internal)", "response": "Adds a login method to this account."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replacePassword(self, currentPassword, newPassword):\n        if unicode(currentPassword) != self.password:\n            return fail(BadCredentials())\n        return self.setPassword(newPassword)", "response": "Replace the password of this account with a new one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addAccount(self, username, domain, password, avatars=None,\n                   protocol=u'email', disabled=0, internal=False,\n                   verified=True):\n        \"\"\"\n        Create a user account, add it to this LoginBase, and return it.\n\n        This method must be called within a transaction in my store.\n\n        @param username: the user's name.\n\n        @param domain: the domain part of the user's name [XXX TODO: this\n        really ought to say something about whether it's a Q2Q domain, a SIP\n        domain, an HTTP realm, or an email address domain - right now the\n        assumption is generally that it's an email address domain, but not\n        always]\n\n        @param password: A shared secret.\n\n        @param avatars: (Optional).  A SubStore which, if passed, will be used\n        by cred as the target of all adaptations for this user.  By default, I\n        will create a SubStore, and plugins can be installed on that substore\n        using the powerUp method to provide implementations of cred client\n        interfaces.\n\n        @raise DuplicateUniqueItem: if the 'avatars' argument already contains\n        a LoginAccount.\n\n        @return: an instance of a LoginAccount, with all attributes filled out\n        as they are passed in, stored in my store.\n        \"\"\"\n\n        # unicode(None) == u'None', kids.\n        if username is not None:\n            username = unicode(username)\n        if domain is not None:\n            domain = unicode(domain)\n        if password is not None:\n            password = unicode(password)\n\n        if self.accountByAddress(username, domain) is not None:\n            raise DuplicateUser(username, domain)\n        if avatars is None:\n            avatars = self.makeAvatars(domain, username)\n\n        subStore = avatars.open()\n\n        # create this unconditionally; as the docstring says, we must be run\n        # within a transaction, so if something goes wrong in the substore\n        # transaction this item's creation will be reverted...\n        la = LoginAccount(store=self.store,\n                          password=password,\n                          avatars=avatars,\n                          disabled=disabled)\n\n        def createSubStoreAccountObjects():\n\n            LoginAccount(store=subStore,\n                         password=password,\n                         disabled=disabled,\n                         avatars=subStore)\n\n            la.addLoginMethod(localpart=username,\n                              domain=domain,\n                              protocol=protocol,\n                              internal=internal,\n                              verified=verified)\n\n        subStore.transact(createSubStoreAccountObjects)\n        return la", "response": "Create a user account and return it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nidentify an appropriate SQL error object for the given message for the the field.", "response": "def identifySQLError(self, sql, args, e):\n        \"\"\"\n        Identify an appropriate SQL error object for the given message for the\n        supported versions of sqlite.\n\n        @return: an SQLError\n        \"\"\"\n        message = e.args[0]\n        if message.startswith(\"table\") and message.endswith(\"already exists\"):\n            return errors.TableAlreadyExists(sql, args, e)\n        return errors.SQLError(sql, args, e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createCacheRemoveCallback(cacheRef, key, finalizer):\n    def remove(reference):\n        # Weakref callbacks cannot raise exceptions or DOOM ensues\n        try:\n            finalizer()\n        except:\n            logErrorNoMatterWhat()\n        try:\n            cache = cacheRef()\n            if cache is not None:\n                if key in cache.data:\n                    if cache.data[key] is reference:\n                        del cache.data[key]\n        except:\n            logErrorNoMatterWhat()\n    return remove", "response": "Creates a callback that will be called when a cache entry is removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cache(self, key, value):\n        fin = value.__finalizer__()\n        try:\n            # It's okay if there's already a cache entry for this key as long\n            # as the weakref has already been broken. See the comment in\n            # get() for an explanation of why this might happen.\n            if self.data[key]() is not None:\n                raise CacheInconsistency(\n                    \"Duplicate cache key: %r %r %r\" % (\n                        key, value, self.data[key]))\n        except KeyError:\n            pass\n        callback = createCacheRemoveCallback(self._ref(self), key, fin)\n        self.data[key] = self._ref(value, callback)\n        return value", "response": "Add an entry to the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves an entry from the cache.", "response": "def uncache(self, key, value):\n        \"\"\"\n        Remove a key from the cache.\n\n        As a sanity check, if the specified key is present in the cache, it\n        must have the given value.\n\n        @param key: The key to remove.\n\n        @param value: The expected value for the key.\n        \"\"\"\n        try:\n            assert self.get(key) is value\n            del self.data[key]\n        except KeyError:\n            # If the entry has already been removed from the cache, this will\n            # result in KeyError which we ignore. If the entry is still in the\n            # cache, but the weakref has been broken, this will result in\n            # CacheFault (a KeyError subclass) which we also ignore. See the\n            # comment in get() for an explanation of why this might happen.\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an entry from the cache by key.", "response": "def get(self, key):\n        \"\"\"\n        Get an entry from the cache by key.\n\n        @raise KeyError: if the given key is not present in the cache.\n\n        @raise CacheFault: (a L{KeyError} subclass) if the given key is present\n            in the cache, but the value it points to is gone.\n        \"\"\"\n        o = self.data[key]()\n        if o is None:\n            # On CPython, the weakref callback will always(?) run before any\n            # other code has a chance to observe that the weakref is broken;\n            # and since the callback removes the item from the dict, this\n            # branch of code should never run. However, on PyPy (and possibly\n            # other Python implementations), the weakref callback does not run\n            # immediately, thus we may be able to observe this intermediate\n            # state. Should this occur, we remove the dict item ourselves,\n            # and raise CacheFault (which is a KeyError subclass).\n            del self.data[key]\n            raise CacheFault(\n                \"FinalizingCache has %r but its value is no more.\" % (key,))\n        log.msg(interface=iaxiom.IStatEvent, stat_cache_hits=1, key=key)\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_question_xml(root):\n    question_dict = dict()\n\n    question_prompt_el = root.find('text')\n    if question_prompt_el is not None:\n        question_dict['text'] = _safe_get_text(question_prompt_el)\n    else:\n        raise ValidationError(_('Question must have text element.'))\n\n    # optional image element\n    question_dict.update(parse_image_xml(root))\n\n    return question_dict", "response": "Parses the question XML element in the UBCPI XBlock s content XML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the options XML element in the UBCPI XBlock s content XML.", "response": "def parse_options_xml(root):\n    \"\"\"\n    Parse <options> element in the UBCPI XBlock's content XML.\n\n    Args:\n        root (lxml.etree.Element): The root of the <options> node in the tree.\n\n    Returns:\n        a list of deserialized representation of options. E.g.\n        [{\n            'text': 'Option 1',\n            'image_url': '',\n            'image_position': 'below',\n            'image_show_fields': 0,\n            'image_alt': ''\n        },\n        {....\n        }]\n\n    Raises:\n        ValidationError: The XML definition is invalid.\n    \"\"\"\n    options = []\n    correct_option = None\n    rationale = None\n\n    for option_el in root.findall('option'):\n        option_dict = dict()\n        option_prompt_el = option_el.find('text')\n        if option_prompt_el is not None:\n            option_dict['text'] = _safe_get_text(option_prompt_el)\n        else:\n            raise ValidationError(_('Option must have text element.'))\n\n        # optional image element\n        option_dict.update(parse_image_xml(option_el))\n\n        if 'correct' in option_el.attrib and _parse_boolean(option_el.attrib['correct']):\n            if correct_option is None:\n                correct_option = len(options)\n                rationale_el = option_el.find('rationale')\n                if rationale_el is not None:\n                    rationale = {'text': _safe_get_text(rationale_el)}\n                else:\n                    raise ValidationError(_('Missing rationale for correct answer.'))\n            else:\n                raise ValidationError(_('Only one correct answer can be defined in options.'))\n\n        options.append(option_dict)\n\n    if correct_option is None or rationale is None:\n        raise ValidationError(_('Correct answer and rationale are required and have to be defined in one of the option.'))\n\n    return options, correct_option, rationale"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the UBCPI XBlock s content XML.", "response": "def parse_seeds_xml(root):\n    \"\"\"\n    Parse <seeds> element in the UBCPI XBlock's content XML.\n\n    Args:\n        root (lxml.etree.Element): The root of the <seeds> node in the tree.\n\n    Returns:\n        a list of deserialized representation of seeds. E.g.\n        [{\n            'answer': 1,  # option index starting from one\n            'rationale': 'This is a seeded answer',\n        },\n        {....\n        }]\n\n    Raises:\n        ValidationError: The XML definition is invalid.\n    \"\"\"\n    seeds = []\n\n    for seed_el in root.findall('seed'):\n        seed_dict = dict()\n        seed_dict['rationale'] = _safe_get_text(seed_el)\n\n        if 'option' in seed_el.attrib:\n            seed_dict['answer'] = int(seed_el.attrib['option']) - 1\n        else:\n            raise ValidationError(_('Seed element must have an option attribute.'))\n\n        seeds.append(seed_dict)\n\n    return seeds"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the UBCPI XBlock s content from an XML definition.", "response": "def parse_from_xml(root):\n    \"\"\"\n    Update the UBCPI XBlock's content from an XML definition.\n\n    We need to be strict about the XML we accept, to avoid setting\n    the XBlock to an invalid state (which will then be persisted).\n\n    Args:\n        root (lxml.etree.Element): The XML definition of the XBlock's content.\n\n    Returns:\n        A dictionary of all of the XBlock's content.\n\n    Raises:\n        UpdateFromXmlError: The XML definition is invalid\n    \"\"\"\n\n    # Check that the root has the correct tag\n    if root.tag != 'ubcpi':\n        raise UpdateFromXmlError(_('Every peer instruction tool must contain an \"ubcpi\" element.'))\n\n    display_name_el = root.find('display_name')\n    if display_name_el is None:\n        raise UpdateFromXmlError(_('Every peer instruction tool must contain a \"display_name\" element.'))\n    else:\n        display_name = _safe_get_text(display_name_el)\n\n    rationale_size_min = int(root.attrib['rationale_size_min']) if 'rationale_size_min' in root.attrib else None\n    rationale_size_max = int(root.attrib['rationale_size_max']) if 'rationale_size_max' in root.attrib else None\n\n    question_el = root.find('question')\n    if question_el is None:\n        raise UpdateFromXmlError(_('Every peer instruction must tool contain a \"question\" element.'))\n    else:\n        question = parse_question_xml(question_el)\n\n    options_el = root.find('options')\n    if options_el is None:\n        raise UpdateFromXmlError(_('Every peer instruction must tool contain a \"options\" element.'))\n    else:\n        options, correct_answer, correct_rationale = parse_options_xml(options_el)\n\n    seeds_el = root.find('seeds')\n    if seeds_el is None:\n        raise UpdateFromXmlError(_('Every peer instruction must tool contain a \"seeds\" element.'))\n    else:\n        seeds = parse_seeds_xml(seeds_el)\n\n    algo = unicode(root.attrib['algorithm']) if 'algorithm' in root.attrib else None\n    num_responses = unicode(root.attrib['num_responses']) if 'num_responses' in root.attrib else None\n\n    return {\n        'display_name': display_name,\n        'question_text': question,\n        'options': options,\n        'rationale_size': {'min': rationale_size_min, 'max': rationale_size_max},\n        'correct_answer': correct_answer,\n        'correct_rationale': correct_rationale,\n        'seeds': seeds,\n        'algo': {\"name\": algo, 'num_responses': num_responses}\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_options(options, block):\n    for index, option_dict in enumerate(block.options):\n        option = etree.SubElement(options, 'option')\n        # set correct option and rationale\n        if index == block.correct_answer:\n            option.set('correct', u'True')\n\n            if hasattr(block, 'correct_rationale'):\n                rationale = etree.SubElement(option, 'rationale')\n                rationale.text = block.correct_rationale['text']\n\n        text = etree.SubElement(option, 'text')\n        text.text = option_dict.get('text', '')\n\n        serialize_image(option_dict, option)", "response": "Serialize the options in peer instruction XBlock to xml\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_seeds(seeds, block):\n    for seed_dict in block.seeds:\n        seed = etree.SubElement(seeds, 'seed')\n        # options in xml starts with 1\n        seed.set('option', unicode(seed_dict.get('answer', 0) + 1))\n        seed.text = seed_dict.get('rationale', '')", "response": "Serialize the seeds in peer instruction XBlock to xml\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_to_xml(root, block):\n    root.tag = 'ubcpi'\n\n    if block.rationale_size is not None:\n        if block.rationale_size.get('min'):\n            root.set('rationale_size_min', unicode(block.rationale_size.get('min')))\n        if block.rationale_size.get('max'):\n            root.set('rationale_size_max', unicode(block.rationale_size['max']))\n\n    if block.algo:\n        if block.algo.get('name'):\n            root.set('algorithm', block.algo.get('name'))\n        if block.algo.get('num_responses'):\n            root.set('num_responses', unicode(block.algo.get('num_responses')))\n\n    display_name = etree.SubElement(root, 'display_name')\n    display_name.text = block.display_name\n\n    question = etree.SubElement(root, 'question')\n    question_text = etree.SubElement(question, 'text')\n    question_text.text = block.question_text['text']\n    serialize_image(block.question_text, question)\n\n    options = etree.SubElement(root, 'options')\n    serialize_options(options, block)\n\n    seeds = etree.SubElement(root, 'seeds')\n    serialize_seeds(seeds, block)", "response": "Serialize the Peer Instruction XBlock s content to XML."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen the lvm and vg_t handles.", "response": "def open(self):\n        \"\"\"\n        Obtains the lvm and vg_t handle. Usually you would never need to use this method\n        unless you are doing operations using the ctypes function wrappers in conversion.py\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        if not self.handle:\n            self.lvm.open()\n            self.__vgh = lvm_vg_open(self.lvm.handle, self.name, self.mode)\n            if not bool(self.__vgh):\n                raise HandleError(\"Failed to initialize VG Handle.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses the lvm and vg_t handles.", "response": "def close(self):\n        \"\"\"\n        Closes the lvm and vg_t handle. Usually you would never need to use this method\n        unless you are doing operations using the ctypes function wrappers in conversion.py\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        if self.handle:\n            cl = lvm_vg_close(self.handle)\n            if cl != 0:\n                raise HandleError(\"Failed to close VG handle after init check.\")\n            self.__vgh = None\n            self.lvm.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uuid(self):\n        self.open()\n        uuid = lvm_vg_get_uuid(self.handle)\n        self.close()\n        return uuid", "response": "Returns the uuid of the volume group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the number of volumes in this volume group.", "response": "def extent_count(self):\n        \"\"\"\n        Returns the volume group extent count.\n        \"\"\"\n        self.open()\n        count = lvm_vg_get_extent_count(self.handle)\n        self.close()\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef free_extent_count(self):\n        self.open()\n        count = lvm_vg_get_free_extent_count(self.handle)\n        self.close()\n        return count", "response": "Returns the number of free extent entries in the volume group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pv_count(self):\n        self.open()\n        count = lvm_vg_get_pv_count(self.handle)\n        self.close()\n        return count", "response": "Returns the number of physical volumes in the volume group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef max_pv_count(self):\n        self.open()\n        count = lvm_vg_get_max_pv(self.handle)\n        self.close()\n        return count", "response": "Returns the maximum allowed physical volume count."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef max_lv_count(self):\n        self.open()\n        count = lvm_vg_get_max_lv(self.handle)\n        self.close()\n        return count", "response": "Returns the maximum allowed logical volume count."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_clustered(self):\n        self.open()\n        clust = lvm_vg_is_clustered(self.handle)\n        self.close()\n        return bool(clust)", "response": "Returns True if the VG is clustered False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_exported(self):\n        self.open()\n        exp = lvm_vg_is_exported(self.handle)\n        self.close()\n        return bool(exp)", "response": "Returns True if the VG is exported False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the VG is partial False otherwise.", "response": "def is_partial(self):\n        \"\"\"\n        Returns True if the VG is partial, False otherwise.\n        \"\"\"\n        self.open()\n        part = lvm_vg_is_partial(self.handle)\n        self.close()\n        return bool(part)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sequence(self):\n        self.open()\n        seq = lvm_vg_get_seqno(self.handle)\n        self.close()\n        return seq", "response": "Returns the sequence number of the volume group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef size(self, units=\"MiB\"):\n        self.open()\n        size = lvm_vg_get_size(self.handle)\n        self.close()\n        return size_convert(size, units)", "response": "Returns the size of the volume group in the given units."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the free size in the given units.", "response": "def free_size(self, units=\"MiB\"):\n        \"\"\"\n        Returns the volume group free size in the given units. Default units are  MiB.\n\n        *Args:*\n\n        *       units (str):    Unit label ('MiB', 'GiB', etc...). Default is MiB.\n        \"\"\"\n        self.open()\n        size = lvm_vg_get_free_size(self.handle)\n        self.close()\n        return size_convert(size, units)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the extent size in the given units.", "response": "def extent_size(self, units=\"MiB\"):\n        \"\"\"\n        Returns the volume group extent size in the given units. Default units are  MiB.\n\n        *Args:*\n\n        *       units (str):    Unit label ('MiB', 'GiB', etc...). Default is MiB.\n        \"\"\"\n        self.open()\n        size = lvm_vg_get_extent_size(self.handle)\n        self.close()\n        return size_convert(size, units)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_pv(self, device):\n        if not os.path.exists(device):\n            raise ValueError(\"%s does not exist.\" % device)\n        self.open()\n        ext = lvm_vg_extend(self.handle, device)\n        if ext != 0:\n            self.close()\n            raise CommitError(\"Failed to extend Volume Group.\")\n        self._commit()\n        self.close()\n        return PhysicalVolume(self, name=device)", "response": "Adds a physical volume to the volume group."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the PhysicalVolume object associated with the given device.", "response": "def get_pv(self, device):\n        \"\"\"\n        Returns the physical volume associated with the given device::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\", \"w\")\n            vg.get_pv(\"/dev/sdb1\")\n\n        *Args:*\n\n        *       device (str):   An existing device.\n\n        *Raises:*\n\n        *       ValueError, HandleError\n        \"\"\"\n        if not os.path.exists(device):\n            raise ValueError(\"%s does not exist.\" % device)\n        return PhysicalVolume(self, name=device)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_pv(self, pv):\n        name = pv.name\n        self.open()\n        rm = lvm_vg_reduce(self.handle, name)\n        if rm != 0:\n            self.close()\n            raise CommitError(\"Failed to remove %s.\" % name)\n        self._commit()\n        self.close()", "response": "Removes a physical volume from the volume group."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprobes the volume group for physical volumes and returns a list of PhysicalVolume instances.", "response": "def pvscan(self):\n        \"\"\"\n        Probes the volume group for physical volumes and returns a list of\n        PhysicalVolume instances::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\")\n            pvs = vg.pvscan()\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        self.open()\n        pv_list = []\n        pv_handles = lvm_vg_list_pvs(self.handle)\n        if not bool(pv_handles):\n            return pv_list\n        pvh = dm_list_first(pv_handles)\n        while pvh:\n            c = cast(pvh, POINTER(lvm_pv_list))\n            pv = PhysicalVolume(self, pvh=c.contents.pv)\n            pv_list.append(pv)\n            if dm_list_end(pv_handles, pvh):\n                # end of linked list\n                break\n            pvh = dm_list_next(pv_handles, pvh)\n        self.close()\n        return pv_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lvscan(self):\n        self.open()\n        lv_list = []\n        lv_handles = lvm_vg_list_lvs(self.handle)\n        if not bool(lv_handles):\n            return lv_list\n        lvh = dm_list_first(lv_handles)\n        while lvh:\n            c = cast(lvh, POINTER(lvm_lv_list))\n            lv = LogicalVolume(self, lvh=c.contents.lv)\n            lv_list.append(lv)\n            if dm_list_end(lv_handles, lvh):\n                # end of linked list\n                break\n            lvh = dm_list_next(lv_handles, lvh)\n        self.close()\n        return lv_list", "response": "Probes the volume group for logical volumes and returns a list of LogicalVolume instances."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_lv(self, name, length, units):\n        if units != \"%\":\n            size = size_units[units] * length\n        else:\n            if not (0 < length <= 100) or type(length) is float:\n                raise ValueError(\"Length not supported.\")\n            size = (self.size(\"B\") / 100) * length\n        self.open()\n        lvh = lvm_vg_create_lv_linear(self.handle, name, c_ulonglong(size))\n        if not bool(lvh):\n            self.close()\n            raise CommitError(\"Failed to create LV.\")\n        lv = LogicalVolume(self, lvh=lvh)\n        self.close()\n        return lv", "response": "Creates a new logical volume and returns the LogicalVolume instance associated with the given logical volume."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a logical volume from the volume group.", "response": "def remove_lv(self, lv):\n        \"\"\"\n        Removes a logical volume from the volume group::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\", \"w\")\n            lv = vg.lvscan()[0]\n            vg.remove_lv(lv)\n\n        *Args:*\n\n        *       lv (obj):       A LogicalVolume instance.\n\n        *Raises:*\n\n        *       HandleError,  CommitError, ValueError\n\n        .. note::\n\n            The VolumeGroup instance must be in write mode, otherwise CommitError\n            is raised.\n        \"\"\"\n        lv.open()\n        rm = lvm_vg_remove_lv(lv.handle)\n        lv.close()\n        if rm != 0:\n            raise CommitError(\"Failed to remove LV.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all logical volumes from the volume group.", "response": "def remove_all_lvs(self):\n        \"\"\"\n        Removes all logical volumes from the volume group.\n\n        *Raises:*\n\n        *       HandleError,  CommitError\n        \"\"\"\n        lvs = self.lvscan()\n        for lv in lvs:\n            self.remove_lv(lv)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the volume group extent size in the given units.", "response": "def set_extent_size(self, length, units):\n        \"\"\"\n        Sets the volume group extent size in the given units::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\", \"w\")\n            vg.set_extent_size(2, \"MiB\")\n\n        *Args:*\n\n        *       length (int):   The desired length size.\n        *       units (str):    The desired units (\"MiB\", \"GiB\", etc...).\n\n        *Raises:*\n\n        *       HandleError,  CommitError, KeyError\n\n        .. note::\n\n            The VolumeGroup instance must be in write mode, otherwise CommitError\n            is raised.\n        \"\"\"\n        size = length * size_units[units]\n        self.open()\n        ext = lvm_vg_set_extent_size(self.handle, c_ulong(size))\n        self._commit()\n        self.close()\n        if ext != 0:\n            raise CommitError(\"Failed to set extent size.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value for a pair of terms.", "response": "def set_pair(self, term1, term2, value, **kwargs):\n\n        \"\"\"\n        Set the value for a pair of terms.\n\n        Args:\n            term1 (str)\n            term2 (str)\n            value (mixed)\n        \"\"\"\n\n        key = self.key(term1, term2)\n        self.keys.update([term1, term2])\n        self.pairs[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_pair(self, term1, term2):\n\n        \"\"\"\n        Get the value for a pair of terms.\n\n        Args:\n            term1 (str)\n            term2 (str)\n\n        Returns:\n            The stored value.\n        \"\"\"\n\n        key = self.key(term1, term2)\n        return self.pairs.get(key, None)", "response": "Get the value for a pair of terms."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index(self, text, terms=None, **kwargs):\n\n        \"\"\"\n        Index all term pair distances.\n\n        Args:\n            text (Text): The source text.\n            terms (list): Terms to index.\n        \"\"\"\n\n        self.clear()\n\n        # By default, use all terms.\n        terms = terms or text.terms.keys()\n\n        pairs = combinations(terms, 2)\n        count = comb(len(terms), 2)\n\n        for t1, t2 in bar(pairs, expected_size=count, every=1000):\n\n            # Set the Bray-Curtis distance.\n            score = text.score_braycurtis(t1, t2, **kwargs)\n            self.set_pair(t1, t2, score)", "response": "Index all term pair distances."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef anchored_pairs(self, anchor):\n\n        \"\"\"\n        Get distances between an anchor term and all other terms.\n\n        Args:\n            anchor (str): The anchor term.\n\n        Returns:\n            OrderedDict: The distances, in descending order.\n        \"\"\"\n\n        pairs = OrderedDict()\n\n        for term in self.keys:\n            score = self.get_pair(anchor, term)\n            if score: pairs[term] = score\n\n        return utils.sort_dict(pairs)", "response": "Returns an OrderedDict of anchored term names to their score."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_rgb(r, g=None, b=None):\n    c = r if isinstance(r, list) else [r, g, b]\n    best = {}\n\n    for index, item in enumerate(colors):\n        d = __distance(item, c)\n        if(not best or d <= best['distance']):\n            best = {'distance': d, 'index': index}\n\n    if 'index' in best:\n        return best['index']\n    else:\n        return 1", "response": "Return nearest xterm 256 color code from rgb input."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses command line arguments and run utilities.", "response": "def entry():\n    \"\"\"Parse command line arguments and run utilities.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        'action', help='Action to take',\n        choices=['from_hex', 'to_rgb', 'to_hex'],\n    )\n    parser.add_argument(\n        'value', help='Value for the action',\n    )\n    parsed = parser.parse_args()\n    if parsed.action != \"from_hex\":\n        try:\n            parsed.value = int(parsed.value)\n        except ValueError:\n            raise argparse.ArgumentError(\n                \"Value for this action should be an integer\",\n            )\n    print(globals()[parsed.action](parsed.value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef makeSoftwareVersion(store, version, systemVersion):\n    return store.findOrCreate(SoftwareVersion,\n                              systemVersion=systemVersion,\n                              package=unicode(version.package),\n                              version=unicode(version.short()),\n                              major=version.major,\n                              minor=version.minor,\n                              micro=version.micro)", "response": "Creates a SoftwareVersion object from store corresponding to the specified version object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listVersionHistory(store):\n    q = store.query(SystemVersion, sort=SystemVersion.creation.descending)\n    return [sv.longWindedRepr() for sv in q]", "response": "List the software package version history of store."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the current version is different from the previously recorded version.", "response": "def checkSystemVersion(s, versions=None):\n    \"\"\"\n    Check if the current version is different from the previously recorded\n    version.  If it is, or if there is no previously recorded version,\n    create a version matching the current config.\n    \"\"\"\n\n    if versions is None:\n        versions = getSystemVersions()\n\n    currentVersionMap = dict([(v.package, v) for v in versions])\n    mostRecentSystemVersion = s.findFirst(SystemVersion,\n                                          sort=SystemVersion.creation.descending)\n    mostRecentVersionMap = dict([(v.package, v.asVersion()) for v in\n                                 s.query(SoftwareVersion,\n                                         (SoftwareVersion.systemVersion ==\n                                          mostRecentSystemVersion))])\n\n    if mostRecentVersionMap != currentVersionMap:\n        currentSystemVersion = SystemVersion(store=s, creation=Time())\n        for v in currentVersionMap.itervalues():\n            makeSoftwareVersion(s, v, currentSystemVersion)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the version data in this item to a version object.", "response": "def asVersion(self):\n        \"\"\"\n        Convert the version data in this item to a\n        L{twisted.python.versions.Version}.\n        \"\"\"\n        return versions.Version(self.package, self.major, self.minor, self.micro)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset(self):\n        self.colNames,self.colDesc,self.colUnits,self.colComments,\\\n        self.colTypes,self.colData=[],[],[],[],[],[]", "response": "clears all columns in the current object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef colAdd(self,name=\"\",desc=\"\",unit=\"\",comment=\"\",coltype=0,data=[],pos=None):\n        if pos is None:\n            pos=len(self.colNames)\n        self.colNames.insert(pos,name)\n        self.colDesc.insert(pos,desc)\n        self.colUnits.insert(pos,unit)\n        self.colComments.insert(pos,comment)\n        self.colTypes.insert(pos,coltype)\n        self.colData.insert(pos,data)\n        return", "response": "Add a new column to the log."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a column at a single index. Negative numbers count from the end.", "response": "def colDelete(self,colI=-1):\n        \"\"\"delete a column at a single index. Negative numbers count from the end.\"\"\"\n#        print(\"DELETING COLUMN: [%d] %s\"%(colI,self.colDesc[colI]))\n        self.colNames.pop(colI)\n        self.colDesc.pop(colI)\n        self.colUnits.pop(colI)\n        self.colComments.pop(colI)\n        self.colTypes.pop(colI)\n        self.colData.pop(colI)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef onex(self):\n        xCols=[i for i in range(self.nCols) if self.colTypes[i]==3]\n        if len(xCols)>1:\n            for colI in xCols[1:][::-1]:\n                self.colDelete(colI)", "response": "delete all X columns except the first one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef alignXY(self):\n\n        # figure out what data we have and will align to\n        xVals=[]\n        xCols=[x for x in range(self.nCols) if self.colTypes[x]==3]\n        yCols=[x for x in range(self.nCols) if self.colTypes[x]==0]\n        xCols,yCols=np.array(xCols),np.array(yCols)\n        for xCol in xCols:\n            xVals.extend(self.colData[xCol])\n        #xVals=list(np.round(set(xVals),5))\n        xVals=list(sorted(list(set(xVals))))\n\n        # prepare our new aligned dataset\n        newData=np.empty(len(xVals)*self.nCols)\n        newData[:]=np.nan\n        newData=newData.reshape(len(xVals),self.nCols)\n        oldData=np.round(self.data,5)\n\n        # do the alignment\n        for xCol in xCols:\n            columnsToShift=[xCol]\n            for col in range(xCol+1,self.nCols):\n                if self.colTypes[col]==0:\n                    columnsToShift.append(col)\n                else:\n                    break\n            # determine how to move each row\n            for row in range(len(oldData)):\n                oldXvalue=oldData[row,xCol]\n                if oldXvalue in xVals:\n                    newRow=xVals.index(oldXvalue)\n                    newData[newRow,columnsToShift]=oldData[row,columnsToShift]\n\n        # commit changes\n        newData[:,0]=xVals\n        self.data=newData\n        self.onex()", "response": "aligns XY pairs or XYYY etc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wiggle(self,noiseLevel=.1):\n        noise=(np.random.rand(*self.data.shape))-.5\n        self.data=self.data+noise*noiseLevel", "response": "Slightly changes value of every cell in the worksheet. Used for testing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npull data into this OR. SHEET from a real book or a real sheet", "response": "def pull(self,bookName=None,sheetName=None):\n        \"\"\"pull data into this OR.SHEET from a real book/sheet in Origin\"\"\"\n\n        # tons of validation\n        if bookName is None and self.bookName: bookName=self.bookName\n        if sheetName is None and self.sheetName: sheetName=self.sheetName\n        if bookName is None: bookName=OR.activeBook()\n        if bookName and sheetName is None: sheetName=OR.activeSheet()\n        if not bookName or not sheetName:\n            print(\"can't figure out where to pull from! [%s]%s\"%(bookName,sheetName))\n            return\n\n        # finally doing the thing\n        poSheet=OR.getSheet(bookName,sheetName)\n        self.bookName=bookName\n        self.sheetName=sheetName\n        self.desc=poSheet.GetLongName()\n        self.colNames=[poCol.GetName() for poCol in poSheet.Columns()]\n        self.colDesc=[poCol.GetLongName() for poCol in poSheet.Columns()]\n        self.colUnits=[poCol.GetUnits() for poCol in poSheet.Columns()]\n        self.colComments=[poCol.GetComments() for poCol in poSheet.Columns()]\n        self.colTypes=[poCol.GetType() for poCol in poSheet.Columns()]\n        self.colData=[poCol.GetData() for poCol in poSheet.Columns()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push(self,bookName=None,sheetName=None,overwrite=False):\n        # tons of validation\n        if bookName: self.bookName=bookName\n        if sheetName: self.sheetName=sheetName\n        if not self.sheetName in OR.sheetNames(bookName):\n            print(\"can't find [%s]%s!\"%(bookName,sheetName))\n            return\n\n        # clear out out sheet by deleting EVERY column\n        poSheet=OR.getSheet(bookName,sheetName) # CPyWorksheetPageI\n        if not poSheet:\n            print(\"WARNING: didn't get posheet\",poSheet,bookName,sheetName)\n        for poCol in [x for x in poSheet if x.IsValid()]:\n            poCol.Destroy()\n\n        # create columns and assign properties to each\n        for i in range(len(self.colNames)):\n            poSheet.InsertCol(i,self.colNames[i])\n            poSheet.Columns(i).SetName(self.colNames[i])\n            poSheet.Columns(i).SetLongName(self.colDesc[i])\n            poSheet.Columns(i).SetUnits(self.colUnits[i])\n            poSheet.Columns(i).SetComments(self.colComments[i])\n            poSheet.Columns(i).SetType(self.colTypes[i])\n            poSheet.Columns(i).SetData(self.colData[i])", "response": "pull this OR. SHEET into a real book or sheet"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nRows(self):\n        if self.nCols: return max([len(x) for x in self.colData])\n        else: return 0", "response": "returns maximum number of rows based on the longest colData"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all of colData as a 2D numpy array.", "response": "def data(self):\n        \"\"\"return all of colData as a 2D numpy array.\"\"\"\n        data=np.empty((self.nRows,self.nCols),dtype=np.float)\n        data[:]=np.nan # make everything nan by default\n        for colNum,colData in enumerate(self.colData):\n            validIs=np.where([np.isreal(v) for v in colData])[0]\n            validData=np.ones(len(colData))*np.nan\n            validData[validIs]=np.array(colData)[validIs]\n            data[:len(colData),colNum]=validData # only fill cells that have data\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data(self,data):\n        assert type(data) is np.ndarray\n        assert data.shape[1] == self.nCols\n        for i in range(self.nCols):\n            self.colData[i]=data[:,i].tolist()", "response": "Given a 2D numpy array fill colData with it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange style on focus out events.", "response": "def focusout(self, event):\n        \"\"\"Change style on focus out events.\"\"\"\n        bc = self.style.lookup(\"TEntry\", \"bordercolor\", (\"!focus\",))\n        dc = self.style.lookup(\"TEntry\", \"darkcolor\", (\"!focus\",))\n        lc = self.style.lookup(\"TEntry\", \"lightcolor\", (\"!focus\",))\n        self.style.configure(\"%s.spinbox.TFrame\" % self.frame, bordercolor=bc,\n                             darkcolor=dc, lightcolor=lc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange style on focus in events.", "response": "def focusin(self, event):\n        \"\"\"Change style on focus in events.\"\"\"\n        self.old_value = self.get()\n        bc = self.style.lookup(\"TEntry\", \"bordercolor\", (\"focus\",))\n        dc = self.style.lookup(\"TEntry\", \"darkcolor\", (\"focus\",))\n        lc = self.style.lookup(\"TEntry\", \"lightcolor\", (\"focus\",))\n        self.style.configure(\"%s.spinbox.TFrame\" % self.frame, bordercolor=bc,\n                             darkcolor=dc, lightcolor=lc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open(self):\n        if not self.handle:\n            try:\n                path = self.system_dir\n            except AttributeError:\n                path = ''\n            self.__handle = lvm_init(path)\n            if not bool(self.__handle):\n                raise HandleError(\"Failed to initialize LVM handle.\")", "response": "Opens the lvm handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        if self.handle:\n            q = lvm_quit(self.handle)\n            if q != 0:\n                raise HandleError(\"Failed to close LVM handle.\")\n            self.__handle = None", "response": "Closes the lvm handle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an instance of a specific existing volume group.", "response": "def get_vg(self, name, mode=\"r\"):\n        \"\"\"\n        Returns an instance of VolumeGroup. The name parameter should be an existing\n        volume group. By default, all volume groups are open in \"read\" mode::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\")\n\n        To open a volume group with write permissions set the mode parameter to \"w\"::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\", \"w\")\n\n        *Args:*\n\n        *       name (str):     An existing volume group name.\n        *       mode (str):     \"r\" or \"w\" for read/write respectively. Default is \"r\".\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        vg = VolumeGroup(self, name=name, mode=mode)\n        return vg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_vg(self, name, devices):\n        self.open()\n        vgh = lvm_vg_create(self.handle, name)\n        if not bool(vgh):\n            self.close()\n            raise HandleError(\"Failed to create VG.\")\n        for device in devices:\n            if not os.path.exists(device):\n                self._destroy_vg(vgh)\n                raise ValueError(\"%s does not exist.\" % device)\n            ext = lvm_vg_extend(vgh, device)\n            if ext != 0:\n                self._destroy_vg(vgh)\n                raise CommitError(\"Failed to extend Volume Group.\")\n            try:\n                self._commit_vg(vgh)\n            except CommitError:\n                self._destroy_vg(vgh)\n                raise CommitError(\"Failed to add %s to VolumeGroup.\" % device)\n        self._close_vg(vgh)\n        vg = VolumeGroup(self, name)\n        return vg", "response": "Create a new volume group with the given name and added physycal\n            devices."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a volume group from the disk.", "response": "def remove_vg(self, vg):\n        \"\"\"\n        Removes a volume group::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vg = lvm.get_vg(\"myvg\", \"w\")\n            lvm.remove_vg(vg)\n\n        *Args:*\n\n        *       vg (obj):       A VolumeGroup instance.\n\n        *Raises:*\n\n        *       HandleError,  CommitError\n\n        .. note::\n\n            The VolumeGroup instance must be in write mode, otherwise CommitError\n            is raised.\n        \"\"\"\n        vg.open()\n        rm = lvm_vg_remove(vg.handle)\n        if rm != 0:\n            vg.close()\n            raise CommitError(\"Failed to remove VG.\")\n        com = lvm_vg_write(vg.handle)\n        if com != 0:\n            vg.close()\n            raise CommitError(\"Failed to commit changes to disk.\")\n        vg.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of VolumeGroup objects for all the volumes in the system.", "response": "def vgscan(self):\n        \"\"\"\n        Probes the system for volume groups and returns a list of VolumeGroup\n        instances::\n\n            from lvm2py import *\n\n            lvm = LVM()\n            vgs = lvm.vgscan()\n\n        *Raises:*\n\n        *       HandleError\n        \"\"\"\n        vg_list = []\n        self.open()\n        names = lvm_list_vg_names(self.handle)\n        if not bool(names):\n            return vg_list\n        vgnames = []\n        vg = dm_list_first(names)\n        while vg:\n            c = cast(vg, POINTER(lvm_str_list))\n            vgnames.append(c.contents.str)\n            if dm_list_end(names, vg):\n                # end of linked list\n                break\n            vg = dm_list_next(names, vg)\n        self.close()\n        for name in vgnames:\n            vginst = self.get_vg(name)\n            vg_list.append(vginst)\n        return vg_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a text from a file.", "response": "def from_file(cls, path):\n\n        \"\"\"\n        Create a text from a file.\n\n        Args:\n            path (str): The file path.\n        \"\"\"\n\n        with open(path, 'r', errors='replace') as f:\n            return cls(f.read())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_stopwords(self, path):\n\n        \"\"\"\n        Load a set of stopwords.\n\n        Args:\n            path (str): The stopwords file path.\n        \"\"\"\n\n        if path:\n            with open(path) as f:\n                self.stopwords = set(f.read().splitlines())\n\n        else:\n            self.stopwords = set(\n                pkgutil\n                .get_data('textplot', 'data/stopwords.txt')\n                .decode('utf8')\n                .splitlines()\n            )", "response": "Loads a set of stopwords from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an OrderedDict of term counts.", "response": "def term_counts(self):\n\n        \"\"\"\n        Returns:\n            OrderedDict: An ordered dictionary of term counts.\n        \"\"\"\n\n        counts = OrderedDict()\n        for term in self.terms:\n            counts[term] = len(self.terms[term])\n\n        return utils.sort_dict(counts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary that maps occurrence counts to the terms that have that many times in the text.", "response": "def term_count_buckets(self):\n\n        \"\"\"\n        Returns:\n            dict: A dictionary that maps occurrence counts to the terms that\n            appear that many times in the text.\n        \"\"\"\n\n        buckets = {}\n        for term, count in self.term_counts().items():\n            if count in buckets: buckets[count].append(term)\n            else: buckets[count] = [term]\n\n        return buckets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the X most frequent terms in the text and then probe down to get .", "response": "def most_frequent_terms(self, depth):\n\n        \"\"\"\n        Get the X most frequent terms in the text, and then probe down to get\n        any other terms that have the same count as the last term.\n\n        Args:\n            depth (int): The number of terms.\n\n        Returns:\n            set: The set of frequent terms.\n        \"\"\"\n\n        counts = self.term_counts()\n\n        # Get the top X terms and the instance count of the last word.\n        top_terms = set(list(counts.keys())[:depth])\n        end_count = list(counts.values())[:depth][-1]\n\n        # Merge in all other words with that appear that number of times, so\n        # that we don't truncate the last bucket - eg, half of the words that\n        # appear 5 times, but not the other half.\n\n        bucket = self.term_count_buckets()[end_count]\n        return top_terms.union(set(bucket))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the most common unstemmed variant of a term.", "response": "def unstem(self, term):\n\n        \"\"\"\n        Given a stemmed term, get the most common unstemmed variant.\n\n        Args:\n            term (str): A stemmed term.\n\n        Returns:\n            str: The unstemmed token.\n        \"\"\"\n\n        originals = []\n        for i in self.terms[term]:\n            originals.append(self.tokens[i]['unstemmed'])\n\n        mode = Counter(originals).most_common(1)\n        return mode[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nestimating the kernel density of the instances of term in the text.", "response": "def kde(self, term, bandwidth=2000, samples=1000, kernel='gaussian'):\n\n        \"\"\"\n        Estimate the kernel density of the instances of term in the text.\n\n        Args:\n            term (str): A stemmed term.\n            bandwidth (int): The kernel bandwidth.\n            samples (int): The number of evenly-spaced sample points.\n            kernel (str): The kernel function.\n\n        Returns:\n            np.array: The density estimate.\n        \"\"\"\n\n        # Get the offsets of the term instances.\n        terms = np.array(self.terms[term])[:, np.newaxis]\n\n        # Fit the density estimator on the terms.\n        kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(terms)\n\n        # Score an evely-spaced array of samples.\n        x_axis = np.linspace(0, len(self.tokens), samples)[:, np.newaxis]\n        scores = kde.score_samples(x_axis)\n\n        # Scale the scores to integrate to 1.\n        return np.exp(scores) * (len(self.tokens) / samples)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the geometric area of the overlap between the kernel density of two terms.", "response": "def score_intersect(self, term1, term2, **kwargs):\n\n        \"\"\"\n        Compute the geometric area of the overlap between the kernel density\n        estimates of two terms.\n\n        Args:\n            term1 (str)\n            term2 (str)\n\n        Returns: float\n        \"\"\"\n\n        t1_kde = self.kde(term1, **kwargs)\n        t2_kde = self.kde(term2, **kwargs)\n\n        # Integrate the overlap.\n        overlap = np.minimum(t1_kde, t2_kde)\n        return np.trapz(overlap)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef score_cosine(self, term1, term2, **kwargs):\n\n        \"\"\"\n        Compute a weighting score based on the cosine distance between the\n        kernel density estimates of two terms.\n\n        Args:\n            term1 (str)\n            term2 (str)\n\n        Returns: float\n        \"\"\"\n\n        t1_kde = self.kde(term1, **kwargs)\n        t2_kde = self.kde(term2, **kwargs)\n\n        return 1-distance.cosine(t1_kde, t2_kde)", "response": "Compute a weighting score based on the cosine distance between the kernel density estimates of two terms."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef score_braycurtis(self, term1, term2, **kwargs):\n\n        \"\"\"\n        Compute a weighting score based on the \"City Block\" distance between\n        the kernel density estimates of two terms.\n\n        Args:\n            term1 (str)\n            term2 (str)\n\n        Returns: float\n        \"\"\"\n\n        t1_kde = self.kde(term1, **kwargs)\n        t2_kde = self.kde(term2, **kwargs)\n\n        return 1-distance.braycurtis(t1_kde, t2_kde)", "response": "Compute a weighting score based on the kernel density estimates of two terms."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_term_kdes(self, words, **kwargs):\n\n        \"\"\"\n        Plot kernel density estimates for multiple words.\n\n        Args:\n            words (list): A list of unstemmed terms.\n        \"\"\"\n\n        stem = PorterStemmer().stem\n\n        for word in words:\n            kde = self.kde(stem(word), **kwargs)\n            plt.plot(kde)\n\n        plt.show()", "response": "Plot kernel density estimates for multiple words."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to generate a new formfield from the given field - classname and returns the corresponding object.", "response": "def generate(self, field_name, field):\n        \"\"\"Tries to lookup a matching formfield generator (lowercase\n        field-classname) and raises a NotImplementedError of no generator\n        can be found.\n        \"\"\"\n\n        if hasattr(self, 'generate_%s' % field.__class__.__name__.lower()):\n            generator = getattr(\n                self,\n                'generate_%s' % field.__class__.__name__.lower())\n            return generator(\n                field_name,\n                field,\n                (field.verbose_name or field_name).capitalize())\n        else:\n            raise NotImplementedError('%s is not supported by MongoForm' % \\\n                field.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fixIndex(self, index, truncate=False):\n        assert not isinstance(index, slice), 'slices are not supported (yet)'\n        if index < 0:\n            index += self.length\n        if index < 0:\n            if not truncate:\n                raise IndexError('stored List index out of range')\n            else:\n                index = 0\n        return index", "response": "Fixes the index of the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef overlapping(startAttribute, # X\n                endAttribute,   # Y\n                startValue,     # A\n                endValue,       # B\n                ):\n    \"\"\"\n    Return an L{axiom.iaxiom.IComparison} (an object that can be passed as the\n    'comparison' argument to Store.query/.sum/.count) which will constrain a\n    query against 2 attributes for ranges which overlap with the given\n    arguments.\n\n    For a database with Items of class O which represent values in this\n    configuration::\n\n              X                   Y\n             (a)                 (b)\n              |-------------------|\n        (c)      (d)\n         |--------|          (e)      (f)\n                              |--------|\n\n     (g) (h)\n      |---|                            (i)    (j)\n                                        |------|\n\n     (k)                                   (l)\n      |-------------------------------------|\n\n             (a)                           (l)\n              |-----------------------------|\n        (c)                      (b)\n         |------------------------|\n\n        (c)  (a)\n         |----|\n                                 (b)       (l)\n                                  |---------|\n\n    The query::\n\n        myStore.query(\n            O,\n            findOverlapping(O.X, O.Y,\n                            a, b))\n\n    Will return a generator of Items of class O which represent segments a-b,\n    c-d, e-f, k-l, a-l, c-b, c-a and b-l, but NOT segments g-h or i-j.\n\n    (NOTE: If you want to pass attributes of different classes for\n    startAttribute and endAttribute, read the implementation of this method to\n    discover the additional join clauses required.  This may be eliminated some\n    day so for now, consider this method undefined over multiple classes.)\n\n    In the database where this query is run, for an item N, all values of\n    N.startAttribute must be less than N.endAttribute.\n\n    startValue must be less than endValue.\n    \"\"\"\n    assert startValue <= endValue\n\n    return OR(\n        AND(startAttribute >= startValue,\n            startAttribute <= endValue),\n        AND(endAttribute >= startValue,\n            endAttribute <= endValue),\n        AND(startAttribute <= startValue,\n            endAttribute >= endValue)\n        )", "response": "Returns an iterator of items that overlap with the given start and end attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare two in - database tuples. Useful when sorting by a compound keysequence.", "response": "def _tupleCompare(tuple1, ineq, tuple2,\n                 eq=lambda a,b: (a==b),\n                 ander=AND,\n                 orer=OR):\n    \"\"\"\n    Compare two 'in-database tuples'.  Useful when sorting by a compound key\n    and slicing into the middle of that query.\n    \"\"\"\n\n    orholder = []\n    for limit in range(len(tuple1)):\n        eqconstraint = [\n            eq(elem1, elem2) for elem1, elem2 in zip(tuple1, tuple2)[:limit]]\n        ineqconstraint = ineq(tuple1[limit], tuple2[limit])\n        orholder.append(ander(*(eqconstraint + [ineqconstraint])))\n    return orer(*orholder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef truncate_rationale(rationale, max_length=MAX_RATIONALE_SIZE_IN_EVENT):\n    if isinstance(rationale, basestring) and max_length is not None and len(rationale) > max_length:\n        return rationale[0:max_length], True\n    else:\n        return rationale, False", "response": "Truncates the rationale for analytics event emission if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_options(options):\n    errors = []\n\n    if int(options['rationale_size']['min']) < 1:\n        errors.append(_('Minimum Characters'))\n    if int(options['rationale_size']['max']) < 0 or int(options['rationale_size']['max']) > MAX_RATIONALE_SIZE:\n        errors.append(_('Maximum Characters'))\n    if not any(error in [_('Minimum Characters'), _('Maximum Characters')] for error in errors) \\\n            and int(options['rationale_size']['max']) <= int(options['rationale_size']['min']):\n        errors += [_('Minimum Characters'), _('Maximum Characters')]\n    try:\n        if options['algo']['num_responses'] != '#' and int(options['algo']['num_responses']) < 0:\n            errors.append(_('Number of Responses'))\n    except ValueError:\n        errors.append(_('Not an Integer'))\n\n    if not errors:\n        return None\n    else:\n        return {'options_error': _('Invalid Option(s): ') + ', '.join(errors)}", "response": "Validate the options that course author set up and return errors in a dict if there is any error"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a student item_dict from our surrounding context.", "response": "def get_student_item_dict(self, anonymous_user_id=None):\n        \"\"\"Create a student_item_dict from our surrounding context.\n\n        See also: submissions.api for details.\n\n        Args:\n            anonymous_user_id(str): A unique anonymous_user_id for (user, course) pair.\n        Returns:\n            (dict): The student item associated with this XBlock instance. This\n                includes the student id, item id, and course id.\n        \"\"\"\n\n        item_id = self._serialize_opaque_key(self.scope_ids.usage_id)\n\n        # This is not the real way course_ids should work, but this is a\n        # temporary expediency for LMS integration\n        if hasattr(self, \"xmodule_runtime\"):\n            course_id = self.get_course_id()  # pylint:disable=E1101\n\n            if anonymous_user_id:\n                student_id = anonymous_user_id\n            else:\n                student_id = self.xmodule_runtime.anonymous_student_id  # pylint:disable=E1101\n        else:\n            course_id = \"edX/Enchantment_101/April_1\"\n            if self.scope_ids.user_id is None:\n                student_id = ''\n            else:\n                student_id = unicode(self.scope_ids.user_id)\n\n        student_item_dict = dict(\n            student_id=student_id,\n            item_id=item_id,\n            course_id=course_id,\n            item_type='ubcpi'\n        )\n        return student_item_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the answers for a student and question.", "response": "def get_answers_for_student(student_item):\n    \"\"\"\n    Retrieve answers from backend for a student and question\n\n    Args:\n        student_item (dict): The location of the problem this submission is\n            associated with, as defined by a course, student, and item.\n\n    Returns:\n        Answers: answers for the student\n    \"\"\"\n    submissions = sub_api.get_submissions(student_item)\n    if not submissions:\n        return Answers()\n\n    latest_submission = submissions[0]\n    latest_answer_item = latest_submission.get('answer', {})\n    return Answers(latest_answer_item.get(ANSWER_LIST_KEY, []))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_answer_for_student(student_item, vote, rationale):\n    answers = get_answers_for_student(student_item)\n    answers.add_answer(vote, rationale)\n\n    sub_api.create_submission(student_item, {\n        ANSWER_LIST_KEY: answers.get_answers_as_list()\n    })", "response": "Adds an answer for a student to the backend\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _safe_get(self, revision, key):\n        if self.has_revision(revision):\n            return self.raw_answers[revision].get(key)\n        else:\n            return None", "response": "Get an answer data by revision"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_answer(self, vote, rationale):\n        self.raw_answers.append({\n            VOTE_KEY: vote,\n            RATIONALE_KEY: rationale,\n        })", "response": "Add an answer to the list of answers for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exceptionToString(e,silent=False):\n    exc_type, exc_obj, exc_tb = sys.exc_info()\n    s=(\"\\n\"+\"=\"*50+\"\\n\")\n    s+=\"EXCEPTION THROWN UNEXPECTEDLY\\n\"\n    s+=\"  FILE: %s\\n\"%os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n    s+=\"  LINE: %s\\n\"%exc_tb.tb_lineno\n    s+=\"  TYPE: %s\\n\"%exc_type\n    s+='-'*50+'\\n'\n    s+=traceback.format_exc()\n    s=s.strip()+'\\n'+\"=\"*50+\"\\n\"\n    if not silent:\n        print(s)\n    return s", "response": "when you except Exception as e give me the e and I ll give you a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef createNew(cls, store, pathSegments):\n        if isinstance(pathSegments, basestring):\n            raise ValueError(\n                'Received %r instead of a sequence' % (pathSegments,))\n        if store.dbdir is None:\n            self = cls(store=store, storepath=None)\n        else:\n            storepath = store.newDirectory(*pathSegments)\n            self = cls(store=store, storepath=storepath)\n        self.open()\n        self.close()\n        return self", "response": "Create a new SubStore allocating a new file space for it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createStore(self, debug, journalMode=None):\n        if self.storepath is None:\n            self.store._memorySubstores.append(self) # don't fall out of cache\n            if self.store.filesdir is None:\n                filesdir = None\n            else:\n                filesdir = (self.store.filesdir.child(\"_substore_files\")\n                                               .child(str(self.storeID))\n                                               .path)\n            return Store(parent=self.store,\n                         filesdir=filesdir,\n                         idInParent=self.storeID,\n                         debug=debug,\n                         journalMode=journalMode)\n        else:\n            return Store(self.storepath.path,\n                         parent=self.store,\n                         idInParent=self.storeID,\n                         debug=debug,\n                         journalMode=journalMode)", "response": "Create the actual Store this Substore represents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupgrading the catalog 1 to 2.", "response": "def upgradeCatalog1to2(oldCatalog):\n    \"\"\"\n    Create _TagName instances which version 2 of Catalog automatically creates\n    for use in determining the tagNames result, but which version 1 of Catalog\n    did not create.\n    \"\"\"\n    newCatalog = oldCatalog.upgradeVersion('tag_catalog', 1, 2,\n                                           tagCount=oldCatalog.tagCount)\n    tags = newCatalog.store.query(Tag, Tag.catalog == newCatalog)\n    tagNames = tags.getColumn(\"name\").distinct()\n    for t in tagNames:\n        _TagName(store=newCatalog.store, catalog=newCatalog, name=t)\n    return newCatalog"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator of unicode strings - the unique tag names which have been applied objects in this catalog.", "response": "def tagNames(self):\n        \"\"\"\n        Return an iterator of unicode strings - the unique tag names which have\n        been applied objects in this catalog.\n        \"\"\"\n        return self.store.query(_TagName, _TagName.catalog == self).getColumn(\"name\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator of unicode strings - the tag names which apply to the given object.", "response": "def tagsOf(self, obj):\n        \"\"\"\n        Return an iterator of unicode strings - the tag names which apply to\n        the given object.\n        \"\"\"\n        return self.store.query(\n            Tag,\n            AND(Tag.catalog == self,\n                Tag.object == obj)).getColumn(\"name\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loaded(self, oself, dbval):\n        setattr(oself, self.dbunderlying, dbval)\n        delattr(oself, self.underlying)", "response": "This method is invoked when the item is loaded from the database and the item s database value is retrieved."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convertPyval(self, oself, pyval):\n        # convert to dbval later, I guess?\n        if pyval is None and not self.allowNone:\n            raise TypeError(\"attribute [%s.%s = %s()] must not be None\" % (\n                    self.classname, self.attrname, self.__class__.__name__))\n\n        return self.infilter(pyval, oself, oself.store)", "response": "Convert a Python value to a value suitable for inserting into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _queryContainer(self, store):\n        if self._subselectSQL is None:\n            sql, args = self.container._sqlAndArgs('SELECT',\n                                                   self.container._queryTarget)\n            self._subselectSQL, self._subselectArgs = sql, args\n        return self._subselectSQL", "response": "Generate and cache the subselect SQL and its arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a sequence of the items in the container.", "response": "def _sequenceContainer(self, store):\n        \"\"\"\n        Smash whatever we got into a list and save the result in case we are\n        executed multiple times.  This keeps us from tripping up over\n        generators and the like.\n        \"\"\"\n        if self._sequence is None:\n            self._sequence = list(self.container)\n            self._clause = ', '.join(['?'] * len(self._sequence))\n        return self._clause"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of arguments to filter the data using the attribute type being tested for containment and hand back the resulting list.", "response": "def _sequenceArgs(self, store):\n        \"\"\"\n        Filter each element of the data using the attribute type being\n        tested for containment and hand back the resulting list.\n        \"\"\"\n        self._sequenceContainer(store) # Force _sequence to be valid\n        return [self.attribute.infilter(pyval, None, store) for pyval in self._sequence]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepareInsert(self, oself, store):\n        if self.relative:\n            fspath = self.__get__(oself)\n            oself.__dirty__[self.attrname] = self, self.infilter(fspath, oself, store)", "response": "Prepare for insertion into the database by making the dbunderlying\n        attribute of the item a relative pathname with respect to the store\n        attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef full_restore(self, using=None):\n        using = using or router.db_for_write(self.__class__, instance=self)\n        restore_counter = Counter()\n        if self.deleted:\n            time = self.deleted_at\n        else:\n            return restore_counter\n        self.collector = models.deletion.Collector(using=using)\n        self.collector.collect([self])\n        \n\n        for model, instances in self.collector.data.items():\n            instances_to_delete = sorted(instances, key=attrgetter(\"pk\"))\n\n        self.sort()\n\n        for qs in self.collector.fast_deletes:\n            # TODO make sure the queryset delete has been made a soft delete\n            for qs_instance in qs:\n                restore_counter.update([qs_instance._meta.model_name])\n                qs_instance.restore(time=time)\n\n        for model, instances in self.collector.data.items():\n            for instance in instances:\n                restore_counter.update([instance._meta.model_name])\n                instance.restore(time=time)\n\n        return sum(restore_counter.values()), dict(restore_counter)\n\n        \"\"\"\n        Restores itself, as well as objects that might have been deleted along with it if cascade is the deletion strategy\n        \"\"\"\n        self.collector = models.deletion.Collector(using=using) \n        self.collector.collect([self], keep_parents=keep_parents)", "response": "Restores all objects in this object and all of its children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting to AWS EC2", "response": "def connect_to_ec2(region='us-east-1', access_key=None, secret_key=None):\n    \"\"\" Connect to AWS ec2\n\n    :type region: str\n    :param region: AWS region to connect to\n    :type access_key: str\n    :param access_key: AWS access key id\n    :type secret_key: str\n    :param secret_key: AWS secret access key\n    :returns: boto.ec2.connection.EC2Connection -- EC2 connection\n    \"\"\"\n\n    if access_key:\n        # Connect using supplied credentials\n        logger.info('Connecting to AWS EC2 in {}'.format(region))\n        connection = ec2.connect_to_region(\n            region,\n            aws_access_key_id=access_key,\n            aws_secret_access_key=secret_key)\n    else:\n        # Fetch instance metadata\n        metadata = get_instance_metadata(timeout=1, num_retries=1)\n        if metadata:\n            try:\n                region = metadata['placement']['availability-zone'][:-1]\n            except KeyError:\n                pass\n\n        # Connect using env vars or boto credentials\n        logger.info('Connecting to AWS EC2 in {}'.format(region))\n        connection = ec2.connect_to_region(region)\n\n    if not connection:\n        logger.error('An error occurred when connecting to EC2')\n        sys.exit(1)\n\n    return connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self, output):\n        output = self._get_lines_with_stems(output)\n        words = self._make_unique(output)\n        return self._parse_for_simple_stems(words)", "response": "Parse a given text into a list of simple stems."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validlocations(configuration=None):\n        # type: () -> List[Dict]\n        \"\"\"\n        Read valid locations from HDX\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            List[Dict]: A list of valid locations\n        \"\"\"\n        if Locations._validlocations is None:\n            if configuration is None:\n                configuration = Configuration.read()\n            Locations._validlocations = configuration.call_remoteckan('group_list', {'all_fields': True})\n        return Locations._validlocations", "response": "Reads valid locations from HDX and returns a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_location_from_HDX_code(code, locations=None, configuration=None):\n        # type: (str, Optional[List[Dict]], Optional[Configuration]) -> Optional[str]\n        \"\"\"Get location from HDX location code\n\n        Args:\n            code (str): code for which to get location name\n            locations (Optional[List[Dict]]): Valid locations list. Defaults to list downloaded from HDX.\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[str]: location name\n        \"\"\"\n        if locations is None:\n            locations = Locations.validlocations(configuration)\n        for locdict in locations:\n            if code.upper() == locdict['name'].upper():\n                return locdict['title']\n        return None", "response": "Get location name from HDX location code"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_HDX_code_from_location(location, locations=None, configuration=None):\n        # type: (str, Optional[List[Dict]], Optional[Configuration]) -> Optional[str]\n        \"\"\"Get HDX code for location\n\n        Args:\n            location (str): Location for which to get HDX code\n            locations (Optional[List[Dict]]): Valid locations list. Defaults to list downloaded from HDX.\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[str]: HDX code or None\n        \"\"\"\n        if locations is None:\n            locations = Locations.validlocations(configuration)\n        locationupper = location.upper()\n        for locdict in locations:\n            locationcode = locdict['name'].upper()\n            if locationupper == locationcode:\n                return locationcode\n\n        for locdict in locations:\n            if locationupper == locdict['title'].upper():\n                return locdict['name'].upper()\n        return None", "response": "Get HDX code for a location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn HDX code for location and whether it matches the given locations.", "response": "def get_HDX_code_from_location_partial(location, locations=None, configuration=None):\n        # type: (str, Optional[List[Dict]], Optional[Configuration]) -> Tuple[Optional[str], bool]\n        \"\"\"Get HDX code for location\n\n        Args:\n            location (str): Location for which to get HDX code\n            locations (Optional[List[Dict]]): Valid locations list. Defaults to list downloaded from HDX.\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Tuple[Optional[str], bool]: HDX code and if the match is exact or (None, False) for no match\n        \"\"\"\n        hdx_code = Locations.get_HDX_code_from_location(location, locations, configuration)\n\n        if hdx_code is not None:\n            return hdx_code, True\n\n        if locations is None:\n            locations = Locations.validlocations(configuration)\n        locationupper = location.upper()\n        for locdict in locations:\n            locationname = locdict['title'].upper()\n            if locationupper in locationname or locationname in locationupper:\n                return locdict['name'].upper(), False\n\n        return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Main():\n  argument_parser = argparse.ArgumentParser(\n      description='Validates dtFabric format definitions.')\n\n  argument_parser.add_argument(\n      'source', nargs='?', action='store', metavar='PATH', default=None,\n      help=(\n          'path of the file or directory containing the dtFabric format '\n          'definitions.'))\n\n  options = argument_parser.parse_args()\n\n  if not options.source:\n    print('Source value is missing.')\n    print('')\n    argument_parser.print_help()\n    print('')\n    return False\n\n  if not os.path.exists(options.source):\n    print('No such file: {0:s}'.format(options.source))\n    print('')\n    return False\n\n  logging.basicConfig(\n      level=logging.INFO, format='[%(levelname)s] %(message)s')\n\n\n  source_is_directory = os.path.isdir(options.source)\n\n  validator = DefinitionsValidator()\n\n  if source_is_directory:\n    source_description = os.path.join(options.source, '*.yaml')\n  else:\n    source_description = options.source\n\n  print('Validating dtFabric definitions in: {0:s}'.format(source_description))\n  if source_is_directory:\n    result = validator.CheckDirectory(options.source)\n  else:\n    result = validator.CheckFile(options.source)\n\n  if not result:\n    print('FAILURE')\n  else:\n    print('SUCCESS')\n\n  return result", "response": "The main function of the main program."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CheckDirectory(self, path, extension='yaml'):\n    result = True\n\n    if extension:\n      glob_spec = os.path.join(path, '*.{0:s}'.format(extension))\n    else:\n      glob_spec = os.path.join(path, '*')\n\n    for definition_file in sorted(glob.glob(glob_spec)):\n      if not self.CheckFile(definition_file):\n        result = False\n\n    return result", "response": "Checks that the directory contains valid definition files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CheckFile(self, path):\n    print('Checking: {0:s}'.format(path))\n\n    definitions_registry = registry.DataTypeDefinitionsRegistry()\n    definitions_reader = reader.YAMLDataTypeDefinitionsFileReader()\n    result = False\n\n    try:\n      definitions_reader.ReadFile(definitions_registry, path)\n      result = True\n\n    except KeyError as exception:\n      logging.warning((\n          'Unable to register data type definition in file: {0:s} with '\n          'error: {1:s}').format(path, exception))\n\n    except errors.FormatError as exception:\n      logging.warning(\n          'Unable to validate file: {0:s} with error: {1:s}'.format(\n              path, exception))\n\n    return result", "response": "Checks the file for valid data type definitions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef styleattribute(self, element):\n        css_text = element.get('style')\n        if css_text:\n            return cssutils.css.CSSStyleDeclaration(cssText=css_text)\n        else:\n            return None", "response": "returns css. CSSStyleDeclaration of inline styles for html"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the configuration file and return it as a dict", "response": "def get_configuration(filename):\n    \"\"\" Read configuration file\n\n    :type filename: str\n    :param filename: Path to the configuration file\n    \"\"\"\n    logger.debug('Reading configuration from {}'.format(filename))\n    conf = SafeConfigParser()\n    conf.read(filename)\n\n    if not conf:\n        logger.error('Configuration file {} not found'.format(filename))\n        sys.exit(1)\n\n    if not conf.has_section('general'):\n        logger.error('Missing [general] section in the configuration file')\n        sys.exit(1)\n\n    try:\n        config = {\n            'access-key-id': conf.get('general', 'access-key-id'),\n            'secret-access-key': conf.get('general', 'secret-access-key'),\n            'region': conf.get('general', 'region'),\n        }\n    except NoOptionError as err:\n        logger.error('Error in config file: {}'.format(err))\n        sys.exit(1)\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inline_css(html_message, encoding='unicode'):\n\n    document = etree.HTML(html_message)\n    converter = Conversion()\n    converter.perform(document, html_message, '', encoding=encoding)\n    return converter.convertedHTML", "response": "Inlines all CSS in an HTML string into the applicable elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the byte stream is large enough for the data type.", "response": "def _CheckByteStreamSize(self, byte_stream, byte_offset, data_type_size):\n    \"\"\"Checks if the byte stream is large enough for the data type.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (int): offset into the byte stream where to start.\n      data_type_size (int): data type size.\n\n    Raises:\n      ByteStreamTooSmallError: if the byte stream is too small.\n      MappingError: if the size of the byte stream cannot be determined.\n    \"\"\"\n    try:\n      byte_stream_size = len(byte_stream)\n\n    except Exception as exception:\n      raise errors.MappingError(exception)\n\n    if byte_stream_size - byte_offset < data_type_size:\n      raise errors.ByteStreamTooSmallError(\n          'Byte stream too small requested: {0:d} available: {1:d}'.format(\n              data_type_size, byte_stream_size))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the byte stream operation.", "response": "def _GetByteStreamOperation(self):\n    \"\"\"Retrieves the byte stream operation.\n\n    Returns:\n      ByteStreamOperation: byte stream operation or None if unable to determine.\n    \"\"\"\n    byte_order_string = self.GetStructByteOrderString()\n    format_string = self.GetStructFormatString()  # pylint: disable=assignment-from-none\n    if not format_string:\n      return None\n\n    format_string = ''.join([byte_order_string, format_string])\n    return byte_operations.StructOperation(format_string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetStructByteOrderString(self):\n    if not self._data_type_definition:\n      return None\n\n    return self._BYTE_ORDER_STRINGS.get(\n        self._data_type_definition.byte_order, None)", "response": "Retrieves the Python struct format string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfolds the data type into a byte stream.", "response": "def FoldByteStream(self, mapped_value, **unused_kwargs):\n    \"\"\"Folds the data type into a byte stream.\n\n    Args:\n      mapped_value (object): mapped value.\n\n    Returns:\n      bytes: byte stream.\n\n    Raises:\n      FoldingError: if the data type definition cannot be folded into\n          the byte stream.\n    \"\"\"\n    try:\n      value = self.FoldValue(mapped_value)\n      return self._operation.WriteTo(tuple([value]))\n\n    except Exception as exception:\n      error_string = (\n          'Unable to write: {0:s} to byte stream with error: {1!s}').format(\n              self._data_type_definition.name, exception)\n      raise errors.FoldingError(error_string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef MapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps the data type on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      object: mapped value.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    data_type_size = self._data_type_definition.GetByteSize()\n    self._CheckByteStreamSize(byte_stream, byte_offset, data_type_size)\n\n    try:\n      struct_tuple = self._operation.ReadFrom(byte_stream[byte_offset:])\n      mapped_value = self.MapValue(*struct_tuple)\n\n    except Exception as exception:\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: {2!s}').format(\n              self._data_type_definition.name, byte_offset, exception)\n      raise errors.MappingError(error_string)\n\n    if context:\n      context.byte_size = data_type_size\n\n    return mapped_value", "response": "Maps the data type on a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FoldValue(self, value):\n    if value is False and self._data_type_definition.false_value is not None:\n      return self._data_type_definition.false_value\n\n    if value is True and self._data_type_definition.true_value is not None:\n      return self._data_type_definition.true_value\n\n    raise ValueError('No matching True and False values')", "response": "Folds the data type into a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetStructFormatString(self):\n    if self._data_type_definition.format == definitions.FORMAT_UNSIGNED:\n      return self._FORMAT_STRINGS_UNSIGNED.get(\n          self._data_type_definition.size, None)\n\n    return self._FORMAT_STRINGS_SIGNED.get(\n        self._data_type_definition.size, None)", "response": "Retrieves the format string as used by Python struct."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FoldByteStream(self, mapped_value, **unused_kwargs):\n    value = None\n\n    try:\n      if self._byte_order == definitions.BYTE_ORDER_BIG_ENDIAN:\n        value = mapped_value.bytes\n      elif self._byte_order == definitions.BYTE_ORDER_LITTLE_ENDIAN:\n        value = mapped_value.bytes_le\n\n    except Exception as exception:\n      error_string = (\n          'Unable to write: {0:s} to byte stream with error: {1!s}').format(\n              self._data_type_definition.name, exception)\n      raise errors.FoldingError(error_string)\n\n    return value", "response": "Folds the data type into a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef MapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps the data type on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      uuid.UUID: mapped value.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    data_type_size = self._data_type_definition.GetByteSize()\n    self._CheckByteStreamSize(byte_stream, byte_offset, data_type_size)\n\n    try:\n      if self._byte_order == definitions.BYTE_ORDER_BIG_ENDIAN:\n        mapped_value = uuid.UUID(\n            bytes=byte_stream[byte_offset:byte_offset + 16])\n      elif self._byte_order == definitions.BYTE_ORDER_LITTLE_ENDIAN:\n        mapped_value = uuid.UUID(\n            bytes_le=byte_stream[byte_offset:byte_offset + 16])\n\n    except Exception as exception:\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: {2!s}').format(\n              self._data_type_definition.name, byte_offset, exception)\n      raise errors.MappingError(error_string)\n\n    if context:\n      context.byte_size = data_type_size\n\n    return mapped_value", "response": "Maps the data type on a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _CalculateElementsDataSize(self, context):\n    elements_data_size = None\n\n    if self._HasElementsDataSize():\n      elements_data_size = self._EvaluateElementsDataSize(context)\n\n    elif self._HasNumberOfElements():\n      element_byte_size = self._element_data_type_definition.GetByteSize()\n      if element_byte_size is not None:\n        number_of_elements = self._EvaluateNumberOfElements(context)\n        elements_data_size = number_of_elements * element_byte_size\n\n    return elements_data_size", "response": "Calculates the elements data size for the elements of the specified data type map context."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the elements data size of the elements element type map.", "response": "def _EvaluateElementsDataSize(self, context):\n    \"\"\"Evaluates elements data size.\n\n    Args:\n      context (DataTypeMapContext): data type map context.\n\n    Returns:\n      int: elements data size.\n\n    Raises:\n      MappingError: if the elements data size cannot be determined.\n    \"\"\"\n    elements_data_size = None\n    if self._data_type_definition.elements_data_size:\n      elements_data_size = self._data_type_definition.elements_data_size\n\n    elif self._data_type_definition.elements_data_size_expression:\n      expression = self._data_type_definition.elements_data_size_expression\n      namespace = {}\n      if context and context.values:\n        namespace.update(context.values)\n      # Make sure __builtins__ contains an empty dictionary.\n      namespace['__builtins__'] = {}\n\n      try:\n        elements_data_size = eval(expression, namespace)  # pylint: disable=eval-used\n      except Exception as exception:\n        raise errors.MappingError(\n            'Unable to determine elements data size with error: {0!s}'.format(\n                exception))\n\n    if elements_data_size is None or elements_data_size < 0:\n      raise errors.MappingError(\n          'Invalid elements data size: {0!s}'.format(elements_data_size))\n\n    return elements_data_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _EvaluateNumberOfElements(self, context):\n    number_of_elements = None\n    if self._data_type_definition.number_of_elements:\n      number_of_elements = self._data_type_definition.number_of_elements\n\n    elif self._data_type_definition.number_of_elements_expression:\n      expression = self._data_type_definition.number_of_elements_expression\n      namespace = {}\n      if context and context.values:\n        namespace.update(context.values)\n      # Make sure __builtins__ contains an empty dictionary.\n      namespace['__builtins__'] = {}\n\n      try:\n        number_of_elements = eval(expression, namespace)  # pylint: disable=eval-used\n      except Exception as exception:\n        raise errors.MappingError(\n            'Unable to determine number of elements with error: {0!s}'.format(\n                exception))\n\n    if number_of_elements is None or number_of_elements < 0:\n      raise errors.MappingError(\n          'Invalid number of elements: {0!s}'.format(number_of_elements))\n\n    return number_of_elements", "response": "Evaluates the number of elements in the data type map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the element data type definition.", "response": "def _GetElementDataTypeDefinition(self, data_type_definition):\n    \"\"\"Retrieves the element data type definition.\n\n    Args:\n      data_type_definition (DataTypeDefinition): data type definition.\n\n    Returns:\n      DataTypeDefinition: element data type definition.\n\n    Raises:\n      FormatError: if the element data type cannot be determined from the data\n          type definition.\n    \"\"\"\n    if not data_type_definition:\n      raise errors.FormatError('Missing data type definition')\n\n    element_data_type_definition = getattr(\n        data_type_definition, 'element_data_type_definition', None)\n    if not element_data_type_definition:\n      raise errors.FormatError(\n          'Invalid data type definition missing element')\n\n    return element_data_type_definition"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetSizeHint(self, context=None, **unused_kwargs):\n    context_state = getattr(context, 'state', {})\n\n    elements_data_size = self.GetByteSize()\n    if elements_data_size:\n      return elements_data_size\n\n    try:\n      elements_data_size = self._CalculateElementsDataSize(context)\n    except errors.MappingError:\n      pass\n\n    if elements_data_size is None and self._HasElementsTerminator():\n      size_hints = context_state.get('size_hints', {})\n      size_hint = size_hints.get(self._data_type_definition.name, None)\n\n      elements_data_size = 0\n\n      if size_hint:\n        elements_data_size = size_hint.byte_size\n\n      if not size_hint or not size_hint.is_complete:\n        elements_data_size += self._element_data_type_definition.GetByteSize()\n\n    return elements_data_size", "response": "Retrieves a hint about the size of the elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmap a composite data type on a byte stream.", "response": "def _CompositeMapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps a sequence of composite data types on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      tuple[object, ...]: mapped values.\n\n    Raises:\n      ByteStreamTooSmallError: if the byte stream is too small.\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    elements_data_size = None\n    elements_terminator = None\n    number_of_elements = None\n\n    if self._HasElementsDataSize():\n      elements_data_size = self._EvaluateElementsDataSize(context)\n\n      element_byte_size = self._element_data_type_definition.GetByteSize()\n      if element_byte_size is not None:\n        number_of_elements, _ = divmod(elements_data_size, element_byte_size)\n      else:\n        elements_terminator = (\n            self._element_data_type_definition.elements_terminator)\n\n    elif self._HasElementsTerminator():\n      elements_terminator = self._data_type_definition.elements_terminator\n\n    elif self._HasNumberOfElements():\n      number_of_elements = self._EvaluateNumberOfElements(context)\n\n    if elements_terminator is None and number_of_elements is None:\n      raise errors.MappingError(\n          'Unable to determine element terminator or number of elements')\n\n    context_state = getattr(context, 'state', {})\n\n    elements_data_offset = context_state.get('elements_data_offset', 0)\n    element_index = context_state.get('element_index', 0)\n    element_value = None\n    mapped_values = context_state.get('mapped_values', [])\n    size_hints = context_state.get('size_hints', {})\n    subcontext = context_state.get('context', None)\n\n    if not subcontext:\n      subcontext = DataTypeMapContext()\n\n    try:\n      while byte_stream[byte_offset:]:\n        if (number_of_elements is not None and\n            element_index == number_of_elements):\n          break\n\n        if (elements_data_size is not None and\n            elements_data_offset >= elements_data_size):\n          break\n\n        element_value = self._element_data_type_map.MapByteStream(\n            byte_stream, byte_offset=byte_offset, context=subcontext)\n\n        byte_offset += subcontext.byte_size\n        elements_data_offset += subcontext.byte_size\n        element_index += 1\n        mapped_values.append(element_value)\n\n        if (elements_terminator is not None and\n            element_value == elements_terminator):\n          break\n\n    except errors.ByteStreamTooSmallError as exception:\n      context_state['context'] = subcontext\n      context_state['elements_data_offset'] = elements_data_offset\n      context_state['element_index'] = element_index\n      context_state['mapped_values'] = mapped_values\n      raise errors.ByteStreamTooSmallError(exception)\n\n    except Exception as exception:\n      raise errors.MappingError(exception)\n\n    if number_of_elements is not None and element_index != number_of_elements:\n      context_state['context'] = subcontext\n      context_state['elements_data_offset'] = elements_data_offset\n      context_state['element_index'] = element_index\n      context_state['mapped_values'] = mapped_values\n\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: missing element: {2:d}').format(\n              self._data_type_definition.name, byte_offset, element_index - 1)\n      raise errors.ByteStreamTooSmallError(error_string)\n\n    if (elements_terminator is not None and\n        element_value != elements_terminator and (\n            elements_data_size is None or\n            elements_data_offset < elements_data_size)):\n      byte_stream_size = len(byte_stream)\n\n      size_hints[self._data_type_definition.name] = DataTypeMapSizeHint(\n          byte_stream_size - byte_offset)\n\n      context_state['context'] = subcontext\n      context_state['elements_data_offset'] = elements_data_offset\n      context_state['element_index'] = element_index\n      context_state['mapped_values'] = mapped_values\n      context_state['size_hints'] = size_hints\n\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: unable to find elements terminator').format(\n              self._data_type_definition.name, byte_offset)\n      raise errors.ByteStreamTooSmallError(error_string)\n\n    if context:\n      context.byte_size = elements_data_offset\n      context.state = {}\n\n    return tuple(mapped_values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _LinearFoldByteStream(self, mapped_value, **unused_kwargs):\n    try:\n      return self._operation.WriteTo(mapped_value)\n\n    except Exception as exception:\n      error_string = (\n          'Unable to write: {0:s} to byte stream with error: {1!s}').format(\n              self._data_type_definition.name, exception)\n      raise errors.FoldingError(error_string)", "response": "Folds the data type into a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _LinearMapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps a data type sequence on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      tuple[object, ...]: mapped values.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    elements_data_size = self._data_type_definition.GetByteSize()\n    self._CheckByteStreamSize(byte_stream, byte_offset, elements_data_size)\n\n    try:\n      struct_tuple = self._operation.ReadFrom(byte_stream[byte_offset:])\n      mapped_values = map(self._element_data_type_map.MapValue, struct_tuple)\n\n    except Exception as exception:\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: {2!s}').format(\n              self._data_type_definition.name, byte_offset, exception)\n      raise errors.MappingError(error_string)\n\n    if context:\n      context.byte_size = elements_data_size\n\n    return tuple(mapped_values)", "response": "Maps a data type sequence on a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the Python struct format string.", "response": "def GetStructFormatString(self):\n    \"\"\"Retrieves the Python struct format string.\n\n    Returns:\n      str: format string as used by Python struct or None if format string\n          cannot be determined.\n    \"\"\"\n    if not self._element_data_type_map:\n      return None\n\n    number_of_elements = None\n    if self._data_type_definition.elements_data_size:\n      element_byte_size = self._element_data_type_definition.GetByteSize()\n      if element_byte_size is None:\n        return None\n\n      number_of_elements, _ = divmod(\n          self._data_type_definition.elements_data_size, element_byte_size)\n\n    elif self._data_type_definition.number_of_elements:\n      number_of_elements = self._data_type_definition.number_of_elements\n\n    format_string = self._element_data_type_map.GetStructFormatString()\n    if not number_of_elements or not format_string:\n      return None\n\n    return '{0:d}{1:s}'.format(number_of_elements, format_string)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FoldByteStream(self, mapped_value, context=None, **unused_kwargs):\n    elements_data_size = self._CalculateElementsDataSize(context)\n    if elements_data_size is not None:\n      if elements_data_size != len(mapped_value):\n        raise errors.FoldingError(\n            'Mismatch between elements data size and mapped value size')\n\n    elif not self._HasElementsTerminator():\n      raise errors.FoldingError('Unable to determine elements data size')\n\n    else:\n      elements_terminator = self._data_type_definition.elements_terminator\n      elements_terminator_size = len(elements_terminator)\n      if mapped_value[-elements_terminator_size:] != elements_terminator:\n        mapped_value = b''.join([mapped_value, elements_terminator])\n\n    return mapped_value", "response": "Folds the data type into a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef MapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps the data type on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      tuple[object, ...]: mapped values.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    context_state = getattr(context, 'state', {})\n\n    size_hints = context_state.get('size_hints', {})\n\n    elements_data_size = self._CalculateElementsDataSize(context)\n    if elements_data_size is not None:\n      self._CheckByteStreamSize(byte_stream, byte_offset, elements_data_size)\n\n    elif not self._HasElementsTerminator():\n      raise errors.MappingError(\n          'Unable to determine elements data size and missing elements '\n          'terminator')\n\n    else:\n      byte_stream_size = len(byte_stream)\n\n      element_byte_size = self._element_data_type_definition.GetByteSize()\n      elements_data_offset = byte_offset\n      next_elements_data_offset = elements_data_offset + element_byte_size\n\n      elements_terminator = self._data_type_definition.elements_terminator\n      element_value = byte_stream[\n          elements_data_offset:next_elements_data_offset]\n\n      while byte_stream[elements_data_offset:]:\n        elements_data_offset = next_elements_data_offset\n        if element_value == elements_terminator:\n          elements_data_size = elements_data_offset - byte_offset\n          break\n\n        next_elements_data_offset += element_byte_size\n        element_value = byte_stream[\n            elements_data_offset:next_elements_data_offset]\n\n      if element_value != elements_terminator:\n        size_hints[self._data_type_definition.name] = DataTypeMapSizeHint(\n            byte_stream_size - byte_offset)\n\n        context_state['size_hints'] = size_hints\n\n        error_string = (\n            'Unable to read: {0:s} from byte stream at offset: {1:d} '\n            'with error: unable to find elements terminator').format(\n                self._data_type_definition.name, byte_offset)\n        raise errors.ByteStreamTooSmallError(error_string)\n\n    if context:\n      context.byte_size = elements_data_size\n\n      size_hints[self._data_type_definition.name] = DataTypeMapSizeHint(\n          elements_data_size, is_complete=True)\n\n      context_state['size_hints'] = size_hints\n\n    return byte_stream[byte_offset:byte_offset + elements_data_size]", "response": "Maps the data type on a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps the data type on a byte stream.", "response": "def MapByteStream(self, byte_stream, byte_offset=0, **unused_kwargs):\n    \"\"\"Maps the data type on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n\n    Returns:\n      object: mapped value.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    return byte_stream[byte_offset:byte_offset + self.byte_size]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfolding the data type into a byte stream.", "response": "def FoldByteStream(self, mapped_value, **kwargs):\n    \"\"\"Folds the data type into a byte stream.\n\n    Args:\n      mapped_value (object): mapped value.\n\n    Returns:\n      bytes: byte stream.\n\n    Raises:\n      FoldingError: if the data type definition cannot be folded into\n          the byte stream.\n    \"\"\"\n    try:\n      byte_stream = mapped_value.encode(self._data_type_definition.encoding)\n\n    except Exception as exception:\n      error_string = (\n          'Unable to write: {0:s} to byte stream with error: {1!s}').format(\n              self._data_type_definition.name, exception)\n      raise errors.MappingError(error_string)\n\n    return super(StringMap, self).FoldByteStream(byte_stream, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmaps the data type on a byte stream.", "response": "def MapByteStream(self, byte_stream, byte_offset=0, **kwargs):\n    \"\"\"Maps the data type on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n\n    Returns:\n      str: mapped values.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    byte_stream = super(StringMap, self).MapByteStream(\n        byte_stream, byte_offset=byte_offset, **kwargs)\n\n    if self._HasElementsTerminator():\n      # Remove the elements terminator and any trailing data from\n      # the byte stream.\n      elements_terminator = self._data_type_definition.elements_terminator\n      elements_terminator_size = len(elements_terminator)\n\n      byte_offset = 0\n      byte_stream_size = len(byte_stream)\n\n      while byte_offset < byte_stream_size:\n        end_offset = byte_offset + elements_terminator_size\n        if byte_stream[byte_offset:end_offset] == elements_terminator:\n          break\n\n        byte_offset += elements_terminator_size\n\n      byte_stream = byte_stream[:byte_offset]\n\n    try:\n      return byte_stream.decode(self._data_type_definition.encoding)\n\n    except Exception as exception:\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: {2!s}').format(\n              self._data_type_definition.name, byte_offset, exception)\n      raise errors.MappingError(error_string)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a data type definition needs a composite map.", "response": "def _CheckCompositeMap(self, data_type_definition):\n    \"\"\"Determines if the data type definition needs a composite map.\n\n    Args:\n      data_type_definition (DataTypeDefinition): structure data type definition.\n\n    Returns:\n      bool: True if a composite map is needed, False otherwise.\n\n    Raises:\n      FormatError: if a composite map is needed cannot be determined from the\n          data type definition.\n    \"\"\"\n    if not data_type_definition:\n      raise errors.FormatError('Missing data type definition')\n\n    members = getattr(data_type_definition, 'members', None)\n    if not members:\n      raise errors.FormatError('Invalid data type definition missing members')\n\n    is_composite_map = False\n    last_member_byte_order = data_type_definition.byte_order\n\n    for member_definition in members:\n      if member_definition.IsComposite():\n        is_composite_map = True\n        break\n\n      # TODO: check for padding type\n      # TODO: determine if padding type can be defined as linear\n      if (last_member_byte_order != definitions.BYTE_ORDER_NATIVE and\n          member_definition.byte_order != definitions.BYTE_ORDER_NATIVE and\n          last_member_byte_order != member_definition.byte_order):\n        is_composite_map = True\n        break\n\n      last_member_byte_order = member_definition.byte_order\n\n    return is_composite_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _CompositeFoldByteStream(\n      self, mapped_value, context=None, **unused_kwargs):\n    \"\"\"Folds the data type into a byte stream.\n\n    Args:\n      mapped_value (object): mapped value.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      bytes: byte stream.\n\n    Raises:\n      FoldingError: if the data type definition cannot be folded into\n          the byte stream.\n    \"\"\"\n    context_state = getattr(context, 'state', {})\n\n    attribute_index = context_state.get('attribute_index', 0)\n    subcontext = context_state.get('context', None)\n\n    if not subcontext:\n      subcontext = DataTypeMapContext(values={\n          type(mapped_value).__name__: mapped_value})\n\n    data_attributes = []\n\n    for attribute_index in range(attribute_index, self._number_of_attributes):\n      attribute_name = self._attribute_names[attribute_index]\n      data_type_map = self._data_type_maps[attribute_index]\n\n      member_value = getattr(mapped_value, attribute_name, None)\n      if data_type_map is None or member_value is None:\n        continue\n\n      member_data = data_type_map.FoldByteStream(\n          member_value, context=subcontext)\n      if member_data is None:\n        return None\n\n      data_attributes.append(member_data)\n\n    if context:\n      context.state = {}\n\n    return b''.join(data_attributes)", "response": "Folds the data type into a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _CompositeMapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps a sequence of composite data types on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      object: mapped value.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    context_state = getattr(context, 'state', {})\n\n    attribute_index = context_state.get('attribute_index', 0)\n    mapped_values = context_state.get('mapped_values', None)\n    subcontext = context_state.get('context', None)\n\n    if not mapped_values:\n      mapped_values = self._structure_values_class()\n    if not subcontext:\n      subcontext = DataTypeMapContext(values={\n          type(mapped_values).__name__: mapped_values})\n\n    members_data_size = 0\n\n    for attribute_index in range(attribute_index, self._number_of_attributes):\n      attribute_name = self._attribute_names[attribute_index]\n      data_type_map = self._data_type_maps[attribute_index]\n      member_definition = self._data_type_definition.members[attribute_index]\n\n      condition = getattr(member_definition, 'condition', None)\n      if condition:\n        namespace = dict(subcontext.values)\n        # Make sure __builtins__ contains an empty dictionary.\n        namespace['__builtins__'] = {}\n\n        try:\n          condition_result = eval(condition, namespace)  # pylint: disable=eval-used\n        except Exception as exception:\n          raise errors.MappingError(\n              'Unable to evaluate condition with error: {0!s}'.format(\n                  exception))\n\n        if not isinstance(condition_result, bool):\n          raise errors.MappingError(\n              'Condition does not result in a boolean value')\n\n        if not condition_result:\n          continue\n\n      if isinstance(member_definition, data_types.PaddingDefinition):\n        _, byte_size = divmod(\n            members_data_size, member_definition.alignment_size)\n        if byte_size > 0:\n          byte_size = member_definition.alignment_size - byte_size\n\n        data_type_map.byte_size = byte_size\n\n      try:\n        value = data_type_map.MapByteStream(\n            byte_stream, byte_offset=byte_offset, context=subcontext)\n        setattr(mapped_values, attribute_name, value)\n\n      except errors.ByteStreamTooSmallError as exception:\n        context_state['attribute_index'] = attribute_index\n        context_state['context'] = subcontext\n        context_state['mapped_values'] = mapped_values\n        raise errors.ByteStreamTooSmallError(exception)\n\n      except Exception as exception:\n        raise errors.MappingError(exception)\n\n      supported_values = getattr(member_definition, 'values', None)\n      if supported_values and value not in supported_values:\n        raise errors.MappingError(\n            'Value: {0!s} not in supported values: {1:s}'.format(\n                value, ', '.join([\n                    '{0!s}'.format(value) for value in supported_values])))\n\n      byte_offset += subcontext.byte_size\n      members_data_size += subcontext.byte_size\n\n    if attribute_index != (self._number_of_attributes - 1):\n      context_state['attribute_index'] = attribute_index\n      context_state['context'] = subcontext\n      context_state['mapped_values'] = mapped_values\n\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: missing attribute: {2:d}').format(\n              self._data_type_definition.name, byte_offset, attribute_index)\n      raise errors.ByteStreamTooSmallError(error_string)\n\n    if context:\n      context.byte_size = members_data_size\n      context.state = {}\n\n    return mapped_values", "response": "Maps a composite data type on a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the attribute names of the members of the data type definition.", "response": "def _GetAttributeNames(self, data_type_definition):\n    \"\"\"Determines the attribute (or field) names of the members.\n\n    Args:\n      data_type_definition (DataTypeDefinition): data type definition.\n\n    Returns:\n      list[str]: attribute names.\n\n    Raises:\n      FormatError: if the attribute names cannot be determined from the data\n          type definition.\n    \"\"\"\n    if not data_type_definition:\n      raise errors.FormatError('Missing data type definition')\n\n    attribute_names = []\n    for member_definition in data_type_definition.members:\n      attribute_names.append(member_definition.name)\n\n    return attribute_names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetMemberDataTypeMaps(self, data_type_definition, data_type_map_cache):\n    if not data_type_definition:\n      raise errors.FormatError('Missing data type definition')\n\n    members = getattr(data_type_definition, 'members', None)\n    if not members:\n      raise errors.FormatError('Invalid data type definition missing members')\n\n    data_type_maps = []\n\n    members_data_size = 0\n    for member_definition in members:\n      if isinstance(member_definition, data_types.MemberDataTypeDefinition):\n        member_definition = member_definition.member_data_type_definition\n\n      if (data_type_definition.byte_order != definitions.BYTE_ORDER_NATIVE and\n          member_definition.byte_order == definitions.BYTE_ORDER_NATIVE):\n        # Make a copy of the data type definition where byte-order can be\n        # safely changed.\n        member_definition = copy.copy(member_definition)\n        member_definition.name = '_{0:s}_{1:s}'.format(\n            data_type_definition.name, member_definition.name)\n        member_definition.byte_order = data_type_definition.byte_order\n\n      if member_definition.name not in data_type_map_cache:\n        data_type_map = DataTypeMapFactory.CreateDataTypeMapByType(\n            member_definition)\n        data_type_map_cache[member_definition.name] = data_type_map\n\n      data_type_map = data_type_map_cache[member_definition.name]\n      if members_data_size is not None:\n        if not isinstance(member_definition, data_types.PaddingDefinition):\n          byte_size = member_definition.GetByteSize()\n        else:\n          _, byte_size = divmod(\n              members_data_size, member_definition.alignment_size)\n          if byte_size > 0:\n            byte_size = member_definition.alignment_size - byte_size\n\n          data_type_map.byte_size = byte_size\n\n        if byte_size is None:\n          members_data_size = None\n        else:\n          members_data_size += byte_size\n\n      data_type_maps.append(data_type_map)\n\n    return data_type_maps", "response": "Retrieves the member data type maps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfold the data type into a byte stream.", "response": "def _LinearFoldByteStream(self, mapped_value, **unused_kwargs):\n    \"\"\"Folds the data type into a byte stream.\n\n    Args:\n      mapped_value (object): mapped value.\n\n    Returns:\n      bytes: byte stream.\n\n    Raises:\n      FoldingError: if the data type definition cannot be folded into\n          the byte stream.\n    \"\"\"\n    try:\n      attribute_values = [\n          getattr(mapped_value, attribute_name, None)\n          for attribute_name in self._attribute_names]\n      attribute_values = [\n          value for value in attribute_values if value is not None]\n      return self._operation.WriteTo(tuple(attribute_values))\n\n    except Exception as exception:\n      error_string = (\n          'Unable to write: {0:s} to byte stream with error: {1!s}').format(\n              self._data_type_definition.name, exception)\n      raise errors.FoldingError(error_string)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _LinearMapByteStream(\n      self, byte_stream, byte_offset=0, context=None, **unused_kwargs):\n    \"\"\"Maps a data type sequence on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      byte_offset (Optional[int]): offset into the byte stream where to start.\n      context (Optional[DataTypeMapContext]): data type map context.\n\n    Returns:\n      object: mapped value.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    members_data_size = self._data_type_definition.GetByteSize()\n    self._CheckByteStreamSize(byte_stream, byte_offset, members_data_size)\n\n    try:\n      struct_tuple = self._operation.ReadFrom(byte_stream[byte_offset:])\n      struct_values = []\n      for attribute_index, value in enumerate(struct_tuple):\n        data_type_map = self._data_type_maps[attribute_index]\n        member_definition = self._data_type_definition.members[attribute_index]\n\n        value = data_type_map.MapValue(value)\n\n        supported_values = getattr(member_definition, 'values', None)\n        if supported_values and value not in supported_values:\n          raise errors.MappingError(\n              'Value: {0!s} not in supported values: {1:s}'.format(\n                  value, ', '.join([\n                      '{0!s}'.format(value) for value in supported_values])))\n\n        struct_values.append(value)\n\n      mapped_value = self._structure_values_class(*struct_values)\n\n    except Exception as exception:\n      error_string = (\n          'Unable to read: {0:s} from byte stream at offset: {1:d} '\n          'with error: {2!s}').format(\n              self._data_type_definition.name, byte_offset, exception)\n      raise errors.MappingError(error_string)\n\n    if context:\n      context.byte_size = members_data_size\n\n    return mapped_value", "response": "Maps a data type sequence on a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a hint about the size of the data type.", "response": "def GetSizeHint(self, context=None, **unused_kwargs):\n    \"\"\"Retrieves a hint about the size.\n\n    Args:\n      context (Optional[DataTypeMapContext]): data type map context, used to\n          determine the size hint.\n\n    Returns:\n      int: hint of the number of bytes needed from the byte stream or None.\n    \"\"\"\n    context_state = getattr(context, 'state', {})\n\n    subcontext = context_state.get('context', None)\n    if not subcontext:\n      mapped_values = context_state.get('mapped_values', None)\n      subcontext = DataTypeMapContext(values={\n          type(mapped_values).__name__: mapped_values})\n\n    size_hint = 0\n    for data_type_map in self._data_type_maps:\n      data_type_size = data_type_map.GetSizeHint(context=subcontext)\n      if data_type_size is None:\n        break\n\n      size_hint += data_type_size\n\n    return size_hint"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the Python struct format string.", "response": "def GetStructFormatString(self):\n    \"\"\"Retrieves the Python struct format string.\n\n    Returns:\n      str: format string as used by Python struct or None if format string\n          cannot be determined.\n    \"\"\"\n    if self._format_string is None and self._data_type_maps:\n      format_strings = []\n      for member_data_type_map in self._data_type_maps:\n        if member_data_type_map is None:\n          return None\n\n        member_format_string = member_data_type_map.GetStructFormatString()\n        if member_format_string is None:\n          return None\n\n        format_strings.append(member_format_string)\n\n      self._format_string = ''.join(format_strings)\n\n    return self._format_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfold the data type into a byte stream.", "response": "def FoldByteStream(self, mapped_value, **unused_kwargs):  # pylint: disable=redundant-returns-doc\n    \"\"\"Folds the data type into a byte stream.\n\n    Args:\n      mapped_value (object): mapped value.\n\n    Returns:\n      bytes: byte stream.\n\n    Raises:\n      FoldingError: if the data type definition cannot be folded into\n          the byte stream.\n    \"\"\"\n    raise errors.FoldingError(\n        'Unable to fold {0:s} data type into byte stream'.format(\n            self._data_type_definition.TYPE_INDICATOR))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps the data type on a byte stream.", "response": "def MapByteStream(self, byte_stream, **unused_kwargs):  # pylint: disable=redundant-returns-doc\n    \"\"\"Maps the data type on a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n\n    Returns:\n      object: mapped value.\n\n    Raises:\n      MappingError: if the data type definition cannot be mapped on\n          the byte stream.\n    \"\"\"\n    raise errors.MappingError(\n        'Unable to map {0:s} data type to byte stream'.format(\n            self._data_type_definition.TYPE_INDICATOR))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetName(self, number):\n    value = self._data_type_definition.values_per_number.get(number, None)\n    if not value:\n      return None\n\n    return value.name", "response": "Retrieves the name of an enumeration value by number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CreateDataTypeMap(self, definition_name):\n    data_type_definition = self._definitions_registry.GetDefinitionByName(\n        definition_name)\n    if not data_type_definition:\n      return None\n\n    return DataTypeMapFactory.CreateDataTypeMapByType(data_type_definition)", "response": "Creates a specific data type map by name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef CreateDataTypeMapByType(cls, data_type_definition):\n    data_type_map_class = cls._MAP_PER_DEFINITION.get(\n        data_type_definition.TYPE_INDICATOR, None)\n    if not data_type_map_class:\n      return None\n\n    return data_type_map_class(data_type_definition)", "response": "Creates a specific data type map by type indicator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the byte size of the data type definition.", "response": "def GetByteSize(self):\n    \"\"\"Retrieves the byte size of the data type definition.\n\n    Returns:\n      int: data type size in bytes or None if size cannot be determined.\n    \"\"\"\n    if self.size == definitions.SIZE_NATIVE or self.units != 'bytes':\n      return None\n\n    return self.size"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the byte size of the data type definition.", "response": "def GetByteSize(self):\n    \"\"\"Retrieves the byte size of the data type definition.\n\n    Returns:\n      int: data type size in bytes or None if size cannot be determined.\n    \"\"\"\n    if not self.element_data_type_definition:\n      return None\n\n    if self.elements_data_size:\n      return self.elements_data_size\n\n    if not self.number_of_elements:\n      return None\n\n    element_byte_size = self.element_data_type_definition.GetByteSize()\n    if not element_byte_size:\n      return None\n\n    return element_byte_size * self.number_of_elements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a member definition to the internal list of members.", "response": "def AddMemberDefinition(self, member_definition):\n    \"\"\"Adds a member definition.\n\n    Args:\n      member_definition (DataTypeDefinition): member data type definition.\n    \"\"\"\n    self._byte_size = None\n    self.members.append(member_definition)\n\n    if self.sections:\n      section_definition = self.sections[-1]\n      section_definition.members.append(member_definition)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if the data type is composite.", "response": "def IsComposite(self):\n    \"\"\"Determines if the data type is composite.\n\n    A composite data type consists of other data types.\n\n    Returns:\n      bool: True if the data type is composite, False otherwise.\n    \"\"\"\n    return bool(self.condition) or (\n        self.member_data_type_definition and\n        self.member_data_type_definition.IsComposite())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetByteSize(self):\n    if self._byte_size is None and self.members:\n      self._byte_size = 0\n      for member_definition in self.members:\n        if isinstance(member_definition, PaddingDefinition):\n          _, byte_size = divmod(\n              self._byte_size, member_definition.alignment_size)\n          if byte_size > 0:\n            byte_size = member_definition.alignment_size - byte_size\n\n        else:\n          byte_size = member_definition.GetByteSize()\n          if byte_size is None:\n            self._byte_size = None\n            break\n\n        self._byte_size += byte_size\n\n    return self._byte_size", "response": "Retrieves the byte size of the data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetByteSize(self):\n    if self._byte_size is None and self.members:\n      self._byte_size = 0\n      for member_definition in self.members:\n        byte_size = member_definition.GetByteSize()\n        if byte_size is None:\n          self._byte_size = None\n          break\n\n        self._byte_size = max(self._byte_size, byte_size)\n\n    return self._byte_size", "response": "Retrieves the byte size of the data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an enumeration value.", "response": "def AddValue(self, name, number, aliases=None, description=None):\n    \"\"\"Adds an enumeration value.\n\n    Args:\n      name (str): name.\n      number (int): number.\n      aliases (Optional[list[str]]): aliases.\n      description (Optional[str]): description.\n\n    Raises:\n      KeyError: if the enumeration value already exists.\n    \"\"\"\n    if name in self.values_per_name:\n      raise KeyError('Value with name: {0:s} already exists.'.format(name))\n\n    if number in self.values_per_number:\n      raise KeyError('Value with number: {0!s} already exists.'.format(number))\n\n    for alias in aliases or []:\n      if alias in self.values_per_alias:\n        raise KeyError('Value with alias: {0:s} already exists.'.format(alias))\n\n    enumeration_value = EnumerationValue(\n        name, number, aliases=aliases, description=description)\n\n    self.values.append(enumeration_value)\n    self.values_per_name[name] = enumeration_value\n    self.values_per_number[number] = enumeration_value\n\n    for alias in aliases or []:\n      self.values_per_alias[alias] = enumeration_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a member definition to the internal list of members.", "response": "def AddMemberDefinition(self, member_definition):\n    \"\"\"Adds a member definition.\n\n    Args:\n      member_definition (DataTypeDefinition): member data type definition.\n    \"\"\"\n    self.members.append(member_definition)\n    member_definition.family_definition = self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_series(s):\n    if isinstance(s, Element):\n        s = s._format_element()\n    if not s or s == '*':\n        # Happens when there's nothing, which the CSS parser thinks of as *\n        return (0, 0)\n    if isinstance(s, int):\n        # Happens when you just get a number\n        return (0, s)\n    if s == 'odd':\n        return (2, 1)\n    elif s == 'even':\n        return (2, 0)\n    elif s == 'n':\n        return (1, 0)\n    if 'n' not in s:\n        # Just a b\n        return (0, int(s))\n    a, b = s.split('n', 1)\n    if not a:\n        a = 1\n    elif a == '-' or a == '+':\n        a = int(a+'1')\n    else:\n        a = int(a)\n    if not b:\n        b = 0\n    elif b == '-' or b == '+':\n        b = int(b+'1')\n    else:\n        b = int(b)\n    return (a, b)", "response": "Parses a series of numbers into a tuple of two sets of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_star_prefix(self):\n        if self.path:\n            self.path += '*/'\n        else:\n            self.path = '*/'\n        self.star_prefix = True", "response": "Adds a /* prefix if there is no prefix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ReadBooleanDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a boolean data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      BooleanDataTypeDefinition: boolean data type definition.\n    \"\"\"\n    return self._ReadFixedSizeDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.BooleanDefinition, definition_name,\n        self._SUPPORTED_ATTRIBUTES_BOOLEAN, is_member=is_member,\n        supported_size_values=(1, 2, 4))", "response": "Reads a boolean data type definition."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a character data type definition.", "response": "def _ReadCharacterDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a character data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      CharacterDataTypeDefinition: character data type definition.\n    \"\"\"\n    return self._ReadFixedSizeDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.CharacterDefinition, definition_name,\n        self._SUPPORTED_ATTRIBUTES_FIXED_SIZE_DATA_TYPE,\n        is_member=is_member, supported_size_values=(1, 2, 4))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ReadConstantDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a constant data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      ConstantDataTypeDefinition: constant data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      error_message = 'data type not supported as member'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    value = definition_values.get('value', None)\n    if value is None:\n      error_message = 'missing value'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object = self._ReadSemanticDataTypeDefinition(\n        definitions_registry, definition_values, data_types.ConstantDefinition,\n        definition_name, self._SUPPORTED_DEFINITION_VALUES_CONSTANT)\n    definition_object.value = value\n\n    return definition_object", "response": "Reads a constant data type definition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadDataTypeDefinition(\n      self, definitions_registry, definition_values, data_type_definition_class,\n      definition_name, supported_definition_values):\n    \"\"\"Reads a data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supported_definition_values (set[str]): names of the supported definition\n          values.\n\n    Returns:\n      DataTypeDefinition: data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    aliases = definition_values.get('aliases', None)\n    description = definition_values.get('description', None)\n    urls = definition_values.get('urls', None)\n\n    unsupported_definition_values = set(definition_values.keys()).difference(\n        supported_definition_values)\n    if unsupported_definition_values:\n      error_message = 'unsupported definition values: {0:s}'.format(\n          ', '.join(unsupported_definition_values))\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    return data_type_definition_class(\n        definition_name, aliases=aliases, description=description, urls=urls)", "response": "Reads a data type definition from the data type definitions registry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a data type definition with members.", "response": "def _ReadDataTypeDefinitionWithMembers(\n      self, definitions_registry, definition_values,\n      data_type_definition_class, definition_name, supports_conditions=False):\n    \"\"\"Reads a data type definition with members.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supports_conditions (Optional[bool]): True if conditions are supported\n          by the data type definition.\n\n    Returns:\n      StringDefinition: string data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    members = definition_values.get('members', None)\n    if not members:\n      error_message = 'missing members'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    supported_definition_values = (\n        self._SUPPORTED_DEFINITION_VALUES_STORAGE_DATA_TYPE_WITH_MEMBERS)\n    definition_object = self._ReadDataTypeDefinition(\n        definitions_registry, definition_values, data_type_definition_class,\n        definition_name, supported_definition_values)\n\n    attributes = definition_values.get('attributes', None)\n    if attributes:\n      unsupported_attributes = set(attributes.keys()).difference(\n          self._SUPPORTED_ATTRIBUTES_STORAGE_DATA_TYPE)\n      if unsupported_attributes:\n        error_message = 'unsupported attributes: {0:s}'.format(\n            ', '.join(unsupported_attributes))\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      byte_order = attributes.get('byte_order', definitions.BYTE_ORDER_NATIVE)\n      if byte_order not in definitions.BYTE_ORDERS:\n        error_message = 'unsupported byte-order attribute: {0!s}'.format(\n            byte_order)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      definition_object.byte_order = byte_order\n\n    for member in members:\n      section = member.get('section', None)\n      if section:\n        member_section_definition = data_types.MemberSectionDefinition(section)\n        definition_object.AddSectionDefinition(member_section_definition)\n      else:\n        member_data_type_definition = self._ReadMemberDataTypeDefinitionMember(\n            definitions_registry, member, definition_object.name,\n            supports_conditions=supports_conditions)\n        definition_object.AddMemberDefinition(member_data_type_definition)\n\n    return definition_object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ReadEnumerationDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads an enumeration data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      EnumerationDataTypeDefinition: enumeration data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      error_message = 'data type not supported as member'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    values = definition_values.get('values')\n    if not values:\n      error_message = 'missing values'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object = self._ReadSemanticDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.EnumerationDefinition, definition_name,\n        self._SUPPORTED_DEFINITION_VALUES_ENUMERATION)\n\n    last_name = None\n    for enumeration_value in values:\n      aliases = enumeration_value.get('aliases', None)\n      description = enumeration_value.get('description', None)\n      name = enumeration_value.get('name', None)\n      number = enumeration_value.get('number', None)\n\n      if not name or number is None:\n        if last_name:\n          error_location = 'after: {0:s}'.format(last_name)\n        else:\n          error_location = 'at start'\n\n        error_message = '{0:s} missing name or number'.format(error_location)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      else:\n        try:\n          definition_object.AddValue(\n              name, number, aliases=aliases, description=description)\n        except KeyError as exception:\n          error_message = '{0!s}'.format(exception)\n          raise errors.DefinitionReaderError(definition_name, error_message)\n\n      last_name = name\n\n    return definition_object", "response": "Reads an enumeration data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading an element sequence data type definition.", "response": "def _ReadElementSequenceDataTypeDefinition(\n      self, definitions_registry, definition_values,\n      data_type_definition_class, definition_name, supported_definition_values):\n    \"\"\"Reads an element sequence data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supported_definition_values (set[str]): names of the supported definition\n          values.\n\n    Returns:\n      SequenceDefinition: sequence data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    unsupported_definition_values = set(definition_values.keys()).difference(\n        supported_definition_values)\n    if unsupported_definition_values:\n      error_message = 'unsupported definition values: {0:s}'.format(\n          ', '.join(unsupported_definition_values))\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    element_data_type = definition_values.get('element_data_type', None)\n    if not element_data_type:\n      error_message = 'missing element data type'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    elements_data_size = definition_values.get('elements_data_size', None)\n    elements_terminator = definition_values.get('elements_terminator', None)\n    number_of_elements = definition_values.get('number_of_elements', None)\n\n    size_values = (elements_data_size, elements_terminator, number_of_elements)\n    size_values = [value for value in size_values if value is not None]\n\n    if not size_values:\n      error_message = (\n          'missing element data size, elements terminator and number of '\n          'elements')\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    if len(size_values) > 1:\n      error_message = (\n          'element data size, elements terminator and number of elements '\n          'not allowed to be set at the same time')\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    element_data_type_definition = definitions_registry.GetDefinitionByName(\n        element_data_type)\n    if not element_data_type_definition:\n      error_message = 'undefined element data type: {0:s}.'.format(\n          element_data_type)\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    element_byte_size = element_data_type_definition.GetByteSize()\n    element_type_indicator = element_data_type_definition.TYPE_INDICATOR\n    if not element_byte_size and element_type_indicator != (\n        definitions.TYPE_INDICATOR_STRING):\n      error_message = (\n          'unsupported variable size element data type: {0:s}'.format(\n              element_data_type))\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    aliases = definition_values.get('aliases', None)\n    description = definition_values.get('description', None)\n    urls = definition_values.get('urls', None)\n\n    definition_object = data_type_definition_class(\n        definition_name, element_data_type_definition, aliases=aliases,\n        data_type=element_data_type, description=description, urls=urls)\n\n    if elements_data_size is not None:\n      try:\n        definition_object.elements_data_size = int(elements_data_size)\n      except ValueError:\n        definition_object.elements_data_size_expression = elements_data_size\n\n    elif elements_terminator is not None:\n      if isinstance(elements_terminator, py2to3.UNICODE_TYPE):\n        elements_terminator = elements_terminator.encode('ascii')\n\n      definition_object.elements_terminator = elements_terminator\n\n    elif number_of_elements is not None:\n      try:\n        definition_object.number_of_elements = int(number_of_elements)\n      except ValueError:\n        definition_object.number_of_elements_expression = number_of_elements\n\n    return definition_object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadFixedSizeDataTypeDefinition(\n      self, definitions_registry, definition_values, data_type_definition_class,\n      definition_name, supported_attributes,\n      default_size=definitions.SIZE_NATIVE, default_units='bytes',\n      is_member=False, supported_size_values=None):\n    \"\"\"Reads a fixed-size data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supported_attributes (set[str]): names of the supported attributes.\n      default_size (Optional[int]): default size.\n      default_units (Optional[str]): default units.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n      supported_size_values (Optional[tuple[int]]): supported size values,\n          or None if not set.\n\n    Returns:\n      FixedSizeDataTypeDefinition: fixed-size data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    definition_object = self._ReadStorageDataTypeDefinition(\n        definitions_registry, definition_values, data_type_definition_class,\n        definition_name, supported_attributes, is_member=is_member)\n\n    attributes = definition_values.get('attributes', None)\n    if attributes:\n      size = attributes.get('size', default_size)\n      if size != definitions.SIZE_NATIVE:\n        try:\n          int(size)\n        except ValueError:\n          error_message = 'unuspported size attribute: {0!s}'.format(size)\n          raise errors.DefinitionReaderError(definition_name, error_message)\n\n        if supported_size_values and size not in supported_size_values:\n          error_message = 'unuspported size value: {0!s}'.format(size)\n          raise errors.DefinitionReaderError(definition_name, error_message)\n\n      definition_object.size = size\n      definition_object.units = attributes.get('units', default_units)\n\n    return definition_object", "response": "Reads a fixed - size data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a floating - point data type definition.", "response": "def _ReadFloatingPointDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a floating-point data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      FloatingPointDefinition: floating-point data type definition.\n    \"\"\"\n    return self._ReadFixedSizeDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.FloatingPointDefinition, definition_name,\n        self._SUPPORTED_ATTRIBUTES_FIXED_SIZE_DATA_TYPE,\n        is_member=is_member, supported_size_values=(4, 8))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ReadFormatDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a format data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      FormatDefinition: format definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      error_message = 'data type not supported as member'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object = self._ReadLayoutDataTypeDefinition(\n        definitions_registry, definition_values, data_types.FormatDefinition,\n        definition_name, self._SUPPORTED_DEFINITION_VALUES_FORMAT)\n\n    # TODO: disabled for now\n    # layout = definition_values.get('layout', None)\n    # if layout is None:\n    #   error_message = 'missing layout'\n    #   raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object.metadata = definition_values.get('metadata', {})\n\n    attributes = definition_values.get('attributes', None)\n    if attributes:\n      unsupported_attributes = set(attributes.keys()).difference(\n          self._SUPPORTED_ATTRIBUTES_FORMAT)\n      if unsupported_attributes:\n        error_message = 'unsupported attributes: {0:s}'.format(\n            ', '.join(unsupported_attributes))\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      byte_order = attributes.get('byte_order', definitions.BYTE_ORDER_NATIVE)\n      if byte_order not in definitions.BYTE_ORDERS:\n        error_message = 'unsupported byte-order attribute: {0!s}'.format(\n            byte_order)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      definition_object.byte_order = byte_order\n\n    return definition_object", "response": "Reads a format data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ReadIntegerDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads an integer data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      IntegerDataTypeDefinition: integer data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    definition_object = self._ReadFixedSizeDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.IntegerDefinition, definition_name,\n        self._SUPPORTED_ATTRIBUTES_INTEGER, is_member=is_member,\n        supported_size_values=(1, 2, 4, 8))\n\n    attributes = definition_values.get('attributes', None)\n    if attributes:\n      format_attribute = attributes.get('format', definitions.FORMAT_SIGNED)\n      if format_attribute not in self._INTEGER_FORMAT_ATTRIBUTES:\n        error_message = 'unsupported format attribute: {0!s}'.format(\n            format_attribute)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      definition_object.format = format_attribute\n\n    return definition_object", "response": "Reads an integer data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ReadLayoutDataTypeDefinition(\n      self, definitions_registry, definition_values, data_type_definition_class,\n      definition_name, supported_definition_values):\n    \"\"\"Reads a layout data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supported_definition_values (set[str]): names of the supported definition\n          values.\n\n    Returns:\n      LayoutDataTypeDefinition: layout data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    return self._ReadDataTypeDefinition(\n        definitions_registry, definition_values, data_type_definition_class,\n        definition_name, supported_definition_values)", "response": "Reads a layout data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ReadMemberDataTypeDefinitionMember(\n      self, definitions_registry, definition_values, definition_name,\n      supports_conditions=False):\n    \"\"\"Reads a member data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      supports_conditions (Optional[bool]): True if conditions are supported\n          by the data type definition.\n\n    Returns:\n      DataTypeDefinition: structure member data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if not definition_values:\n      error_message = 'invalid structure member missing definition values'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    name = definition_values.get('name', None)\n    type_indicator = definition_values.get('type', None)\n\n    if not name and type_indicator != definitions.TYPE_INDICATOR_UNION:\n      error_message = 'invalid structure member missing name'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    # TODO: detect duplicate names.\n\n    data_type = definition_values.get('data_type', None)\n\n    type_values = (data_type, type_indicator)\n    type_values = [value for value in type_values if value is not None]\n\n    if not type_values:\n      error_message = (\n          'invalid structure member: {0:s} both data type and type are '\n          'missing').format(name or '<NAMELESS>')\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    if len(type_values) > 1:\n      error_message = (\n          'invalid structure member: {0:s} data type and type not allowed to '\n          'be set at the same time').format(name or '<NAMELESS>')\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    condition = definition_values.get('condition', None)\n    if not supports_conditions and condition:\n      error_message = (\n          'invalid structure member: {0:s} unsupported condition').format(\n              name or '<NAMELESS>')\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    value = definition_values.get('value', None)\n    values = definition_values.get('values', None)\n\n    if None not in (value, values):\n      error_message = (\n          'invalid structure member: {0:s} value and values not allowed to '\n          'be set at the same time').format(name or '<NAMELESS>')\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    if value:\n      values = [value]\n\n    supported_values = None\n    if values:\n      supported_values = []\n      for value in values:\n        if isinstance(value, py2to3.UNICODE_TYPE):\n          value = value.encode('ascii')\n\n        supported_values.append(value)\n\n    if type_indicator is not None:\n      data_type_callback = self._DATA_TYPE_CALLBACKS.get(type_indicator, None)\n      if data_type_callback:\n        data_type_callback = getattr(self, data_type_callback, None)\n      if not data_type_callback:\n        error_message = 'unuspported data type definition: {0:s}.'.format(\n            type_indicator)\n        raise errors.DefinitionReaderError(name, error_message)\n\n      try:\n        data_type_definition = data_type_callback(\n            definitions_registry, definition_values, name, is_member=True)\n      except errors.DefinitionReaderError as exception:\n        error_message = 'in: {0:s} {1:s}'.format(\n            exception.name or '<NAMELESS>', exception.message)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      if condition or supported_values:\n        definition_object = data_types.MemberDataTypeDefinition(\n            name, data_type_definition, condition=condition,\n            values=supported_values)\n      else:\n        definition_object = data_type_definition\n\n    elif data_type is not None:\n      data_type_definition = definitions_registry.GetDefinitionByName(\n          data_type)\n      if not data_type_definition:\n        error_message = (\n            'invalid structure member: {0:s} undefined data type: '\n            '{1:s}').format(name or '<NAMELESS>', data_type)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      unsupported_definition_values = set(definition_values.keys()).difference(\n          self._SUPPORTED_DEFINITION_VALUES_MEMBER_DATA_TYPE)\n      if unsupported_definition_values:\n        error_message = 'unsupported definition values: {0:s}'.format(\n            ', '.join(unsupported_definition_values))\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      aliases = definition_values.get('aliases', None)\n      description = definition_values.get('description', None)\n\n      definition_object = data_types.MemberDataTypeDefinition(\n          name, data_type_definition, aliases=aliases, condition=condition,\n          data_type=data_type, description=description, values=supported_values)\n\n    return definition_object", "response": "Reads a member data type definition member."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a padding data type definition.", "response": "def _ReadPaddingDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a padding data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      PaddingtDefinition: padding definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if not is_member:\n      error_message = 'data type only supported as member'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object = self._ReadDataTypeDefinition(\n        definitions_registry, definition_values, data_types.PaddingDefinition,\n        definition_name, self._SUPPORTED_DEFINITION_VALUES_PADDING)\n\n    alignment_size = definition_values.get('alignment_size', None)\n    if not alignment_size:\n      error_message = 'missing alignment_size'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    try:\n      int(alignment_size)\n    except ValueError:\n      error_message = 'unuspported alignment size attribute: {0!s}'.format(\n          alignment_size)\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    if alignment_size not in (2, 4, 8, 16):\n      error_message = 'unuspported alignment size value: {0!s}'.format(\n          alignment_size)\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object.alignment_size = alignment_size\n\n    return definition_object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a semantic data type definition.", "response": "def _ReadSemanticDataTypeDefinition(\n      self, definitions_registry, definition_values, data_type_definition_class,\n      definition_name, supported_definition_values):\n    \"\"\"Reads a semantic data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supported_definition_values (set[str]): names of the supported definition\n          values.\n\n    Returns:\n      SemanticDataTypeDefinition: semantic data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    return self._ReadDataTypeDefinition(\n        definitions_registry, definition_values, data_type_definition_class,\n        definition_name, supported_definition_values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadSequenceDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a sequence data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      SequenceDefinition: sequence data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_ELEMENTS_MEMBER_DATA_TYPE)\n    else:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_ELEMENTS_DATA_TYPE)\n\n    return self._ReadElementSequenceDataTypeDefinition(\n        definitions_registry, definition_values, data_types.SequenceDefinition,\n        definition_name, supported_definition_values)", "response": "Reads a sequence data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ReadStorageDataTypeDefinition(\n      self, definitions_registry, definition_values, data_type_definition_class,\n      definition_name, supported_attributes, is_member=False):\n    \"\"\"Reads a storage data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      data_type_definition_class (str): data type definition class.\n      definition_name (str): name of the definition.\n      supported_attributes (set[str]): names of the supported attributes.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      StorageDataTypeDefinition: storage data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_MEMBER_DATA_TYPE)\n    else:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_STORAGE_DATA_TYPE)\n\n    definition_object = self._ReadDataTypeDefinition(\n        definitions_registry, definition_values, data_type_definition_class,\n        definition_name, supported_definition_values)\n\n    attributes = definition_values.get('attributes', None)\n    if attributes:\n      unsupported_attributes = set(attributes.keys()).difference(\n          supported_attributes)\n      if unsupported_attributes:\n        error_message = 'unsupported attributes: {0:s}'.format(\n            ', '.join(unsupported_attributes))\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      byte_order = attributes.get('byte_order', definitions.BYTE_ORDER_NATIVE)\n      if byte_order not in definitions.BYTE_ORDERS:\n        error_message = 'unsupported byte-order attribute: {0!s}'.format(\n            byte_order)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      definition_object.byte_order = byte_order\n\n    return definition_object", "response": "Reads a storage data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ReadStreamDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a stream data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      StreamDefinition: stream data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_ELEMENTS_MEMBER_DATA_TYPE)\n    else:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_ELEMENTS_DATA_TYPE)\n\n    return self._ReadElementSequenceDataTypeDefinition(\n        definitions_registry, definition_values, data_types.StreamDefinition,\n        definition_name, supported_definition_values)", "response": "Reads a data type definition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadStringDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a string data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      StringDefinition: string data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      supported_definition_values = (\n          self._SUPPORTED_DEFINITION_VALUES_STRING_MEMBER)\n    else:\n      supported_definition_values = self._SUPPORTED_DEFINITION_VALUES_STRING\n\n    definition_object = self._ReadElementSequenceDataTypeDefinition(\n        definitions_registry, definition_values, data_types.StringDefinition,\n        definition_name, supported_definition_values)\n\n    encoding = definition_values.get('encoding', None)\n    if not encoding:\n      error_message = 'missing encoding'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object.encoding = encoding\n\n    return definition_object", "response": "Reads a string data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a structure data type definition.", "response": "def _ReadStructureDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a structure data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      StructureDefinition: structure data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      error_message = 'data type not supported as member'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    return self._ReadDataTypeDefinitionWithMembers(\n        definitions_registry, definition_values, data_types.StructureDefinition,\n        definition_name, supports_conditions=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadStructureFamilyDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads a structure family data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      StructureDefinition: structure data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if is_member:\n      error_message = 'data type not supported as member'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object = self._ReadLayoutDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.StructureFamilyDefinition, definition_name,\n        self._SUPPORTED_DEFINITION_VALUES_STRUCTURE_FAMILY)\n\n    runtime = definition_values.get('runtime', None)\n    if not runtime:\n      error_message = 'missing runtime'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    runtime_data_type_definition = definitions_registry.GetDefinitionByName(\n        runtime)\n    if not runtime_data_type_definition:\n      error_message = 'undefined runtime: {0:s}.'.format(runtime)\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    if runtime_data_type_definition.family_definition:\n      error_message = 'runtime: {0:s} already part of a family.'.format(runtime)\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    definition_object.AddRuntimeDefinition(runtime_data_type_definition)\n\n    members = definition_values.get('members', None)\n    if not members:\n      error_message = 'missing members'\n      raise errors.DefinitionReaderError(definition_name, error_message)\n\n    for member in members:\n      member_data_type_definition = definitions_registry.GetDefinitionByName(\n          member)\n      if not member_data_type_definition:\n        error_message = 'undefined member: {0:s}.'.format(member)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      if member_data_type_definition.family_definition:\n        error_message = 'member: {0:s} already part of a family.'.format(member)\n        raise errors.DefinitionReaderError(definition_name, error_message)\n\n      definition_object.AddMemberDefinition(member_data_type_definition)\n\n    return definition_object", "response": "Reads a structure family data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ReadUnionDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads an union data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      UnionDefinition: union data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    return self._ReadDataTypeDefinitionWithMembers(\n        definitions_registry, definition_values, data_types.UnionDefinition,\n        definition_name, supports_conditions=False)", "response": "Reads a union data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads an UUID data type definition.", "response": "def _ReadUUIDDataTypeDefinition(\n      self, definitions_registry, definition_values, definition_name,\n      is_member=False):\n    \"\"\"Reads an UUID data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n      definition_name (str): name of the definition.\n      is_member (Optional[bool]): True if the data type definition is a member\n          data type definition.\n\n    Returns:\n      UUIDDataTypeDefinition: UUID data type definition.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    return self._ReadFixedSizeDataTypeDefinition(\n        definitions_registry, definition_values,\n        data_types.UUIDDefinition, definition_name,\n        self._SUPPORTED_ATTRIBUTES_FIXED_SIZE_DATA_TYPE, default_size=16,\n        is_member=is_member, supported_size_values=(16, ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a data type definition from the given definitions registry and returns it.", "response": "def _ReadDefinition(self, definitions_registry, definition_values):\n    \"\"\"Reads a data type definition.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      definition_values (dict[str, object]): definition values.\n\n    Returns:\n      DataTypeDefinition: data type definition or None.\n\n    Raises:\n      DefinitionReaderError: if the definitions values are missing or if\n          the format is incorrect.\n    \"\"\"\n    if not definition_values:\n      error_message = 'missing definition values'\n      raise errors.DefinitionReaderError(None, error_message)\n\n    name = definition_values.get('name', None)\n    if not name:\n      error_message = 'missing name'\n      raise errors.DefinitionReaderError(None, error_message)\n\n    type_indicator = definition_values.get('type', None)\n    if not type_indicator:\n      error_message = 'invalid definition missing type'\n      raise errors.DefinitionReaderError(name, error_message)\n\n    data_type_callback = self._DATA_TYPE_CALLBACKS.get(type_indicator, None)\n    if data_type_callback:\n      data_type_callback = getattr(self, data_type_callback, None)\n    if not data_type_callback:\n      error_message = 'unuspported data type definition: {0:s}.'.format(\n          type_indicator)\n      raise errors.DefinitionReaderError(name, error_message)\n\n    return data_type_callback(definitions_registry, definition_values, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReadFile(self, definitions_registry, path):\n    with open(path, 'r') as file_object:\n      self.ReadFileObject(definitions_registry, file_object)", "response": "Reads data type definitions from a file into the registry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a format error location.", "response": "def _GetFormatErrorLocation(\n      self, yaml_definition, last_definition_object):\n    \"\"\"Retrieves a format error location.\n\n    Args:\n      yaml_definition (dict[str, object]): current YAML definition.\n      last_definition_object (DataTypeDefinition): previous data type\n          definition.\n\n    Returns:\n      str: format error location.\n    \"\"\"\n    name = yaml_definition.get('name', None)\n    if name:\n      error_location = 'in: {0:s}'.format(name or '<NAMELESS>')\n    elif last_definition_object:\n      error_location = 'after: {0:s}'.format(last_definition_object.name)\n    else:\n      error_location = 'at start'\n\n    return error_location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading data type definitions from a file - like object into the data type definitions registry.", "response": "def ReadFileObject(self, definitions_registry, file_object):\n    \"\"\"Reads data type definitions from a file-like object into the registry.\n\n    Args:\n      definitions_registry (DataTypeDefinitionsRegistry): data type definitions\n          registry.\n      file_object (file): file-like object to read from.\n\n    Raises:\n      FormatError: if the definitions values are missing or if the format is\n          incorrect.\n    \"\"\"\n    last_definition_object = None\n    error_location = None\n    error_message = None\n\n    try:\n      yaml_generator = yaml.safe_load_all(file_object)\n\n      for yaml_definition in yaml_generator:\n        definition_object = self._ReadDefinition(\n            definitions_registry, yaml_definition)\n        if not definition_object:\n          error_location = self._GetFormatErrorLocation(\n              yaml_definition, last_definition_object)\n          error_message = '{0:s} Missing definition object.'.format(\n              error_location)\n          raise errors.FormatError(error_message)\n\n        definitions_registry.RegisterDefinition(definition_object)\n        last_definition_object = definition_object\n\n    except errors.DefinitionReaderError as exception:\n      error_message = 'in: {0:s} {1:s}'.format(\n          exception.name or '<NAMELESS>', exception.message)\n      raise errors.FormatError(error_message)\n\n    except (yaml.reader.ReaderError, yaml.scanner.ScannerError) as exception:\n      error_location = self._GetFormatErrorLocation({}, last_definition_object)\n      error_message = '{0:s} {1!s}'.format(error_location, exception)\n      raise errors.FormatError(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds files with an optional extension in a given path.", "response": "def find_files(path, filter=\"*.md\"):\n        \"\"\" Finds files with an (optional) given extension in a given path. \"\"\"\n        if os.path.isfile(path):\n            return [path]\n\n        if os.path.isdir(path):\n            matches = []\n            for root, dirnames, filenames in os.walk(path):\n                for filename in fnmatch.filter(filenames, filter):\n                    matches.append(os.path.join(root, filename))\n            return matches"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the organization given by identifier from HDX and returns the Organization object if successful.", "response": "def read_from_hdx(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> Optional['Organization']\n        \"\"\"Reads the organization given by identifier from HDX and returns Organization object\n\n        Args:\n            identifier (str): Identifier of organization\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[Organization]: Organization object if successful read, None if not\n        \"\"\"\n\n        organization = Organization(configuration=configuration)\n        result = organization._load_from_hdx('organization', identifier)\n        if result:\n            return organization\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_users(self, capacity=None):\n        # type: (Optional[str]) -> List[User]\n        \"\"\"Returns the organization's users.\n\n        Args:\n            capacity (Optional[str]): Filter by capacity eg. member, admin. Defaults to None.\n        Returns:\n            List[User]: Organization's users.\n        \"\"\"\n        users = list()\n        usersdicts = self.data.get('users')\n        if usersdicts is not None:\n            for userdata in usersdicts:\n                if capacity is not None and userdata['capacity'] != capacity:\n                    continue\n                id = userdata.get('id')\n                if id is None:\n                    id = userdata['name']\n                user = hdx.data.user.User.read_from_hdx(id, configuration=self.configuration)\n                user['capacity'] = userdata['capacity']\n                users.append(user)\n        return users", "response": "Returns the organization s users."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds or update a user in organization with new metadata.", "response": "def add_update_user(self, user, capacity=None):\n        # type: (Union[hdx.data.user.User,Dict,str],Optional[str]) -> None\n        \"\"\"Add new or update existing user in organization with new metadata. Capacity eg. member, admin\n        must be supplied either within the User object or dictionary or using the capacity argument (which takes\n        precedence).\n\n        Args:\n            user (Union[User,Dict,str]): Either a user id or user metadata either from a User object or a dictionary\n            capacity (Optional[str]): Capacity of user eg. member, admin. Defaults to None.\n\n        Returns:\n            None\n\n        \"\"\"\n        if isinstance(user, str):\n            user = hdx.data.user.User.read_from_hdx(user, configuration=self.configuration)\n        elif isinstance(user, dict):\n            user = hdx.data.user.User(user, configuration=self.configuration)\n        if isinstance(user, hdx.data.user.User):\n            users = self.data.get('users')\n            if users is None:\n                users = list()\n                self.data['users'] = users\n            if capacity is not None:\n                user['capacity'] = capacity\n            self._addupdate_hdxobject(users, 'name', user)\n            return\n        raise HDXError('Type %s cannot be added as a user!' % type(user).__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_update_users(self, users, capacity=None):\n        # type: (List[Union[hdx.data.user.User,Dict,str]],Optional[str]) -> None\n        \"\"\"Add new or update existing users in organization with new metadata. Capacity eg. member, admin\n        must be supplied either within the User object or dictionary or using the capacity argument (which takes\n        precedence).\n\n        Args:\n            users (List[Union[User,Dict,str]]): A list of either user ids or users metadata from User objects or dictionaries\n            capacity (Optional[str]): Capacity of users eg. member, admin. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        if not isinstance(users, list):\n            raise HDXError('Users should be a list!')\n        for user in users:\n            self.add_update_user(user, capacity)", "response": "Adds or updates existing users in organization with new metadata."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_datasets(self, query='*:*', **kwargs):\n        # type: (str, Any) -> List[hdx.data.dataset.Dataset]\n        \"\"\"Get list of datasets in organization\n\n        Args:\n            query (str): Restrict datasets returned to this query (in Solr format). Defaults to '*:*'.\n            **kwargs: See below\n            sort (string): Sorting of the search results. Defaults to 'relevance asc, metadata_modified desc'.\n            rows (int): Number of matching rows to return. Defaults to all datasets (sys.maxsize).\n            start (int): Offset in the complete result for where the set of returned datasets should begin\n            facet (string): Whether to enable faceted results. Default to True.\n            facet.mincount (int): Minimum counts for facet fields should be included in the results\n            facet.limit (int): Maximum number of values the facet fields return (- = unlimited). Defaults to 50.\n            facet.field (List[str]): Fields to facet upon. Default is empty.\n            use_default_schema (bool): Use default package schema instead of custom schema. Defaults to False.\n\n        Returns:\n            List[Dataset]: List of datasets in organization\n        \"\"\"\n        return hdx.data.dataset.Dataset.search_in_hdx(query=query,\n                                                      configuration=self.configuration,\n                                                      fq='organization:%s' % self.data['name'], **kwargs)", "response": "Get list of datasets in organization"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_organization_names(configuration=None, **kwargs):\n        # type: (Optional[Configuration], Any) -> List[str]\n        \"\"\"Get all organization names in HDX\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            **kwargs: See below\n            sort (str): Sort the search results according to field name and sort-order. Allowed fields are \u2018name\u2019, \u2018package_count\u2019 and \u2018title\u2019. Defaults to 'name asc'.\n            organizations (List[str]): List of names of the groups to return.\n            all_fields (bool): Return group dictionaries instead of just names. Only core fields are returned - get some more using the include_* options. Defaults to False.\n            include_extras (bool): If all_fields, include the group extra fields. Defaults to False.\n            include_tags (bool): If all_fields, include the group tags. Defaults to False.\n            include_groups: If all_fields, include the groups the groups are in. Defaults to False.\n\n        Returns:\n            List[str]: List of all organization names in HDX\n        \"\"\"\n        organization = Organization(configuration=configuration)\n        organization['id'] = 'all organizations'  # only for error message if produced\n        return organization._write_to_hdx('list', kwargs, 'id')", "response": "Get all organization names in HDX"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a read call to HDX passing in given parameter.", "response": "def _read_from_hdx(self, object_type, value, fieldname='id',\n                       action=None, **kwargs):\n        # type: (str, str, str, Optional[str], Any) -> Tuple[bool, Union[Dict, str]]\n        \"\"\"Makes a read call to HDX passing in given parameter.\n\n        Args:\n            object_type (str): Description of HDX object type (for messages)\n            value (str): Value of HDX field\n            fieldname (str): HDX field name. Defaults to id.\n            action (Optional[str]): Replacement CKAN action url to use. Defaults to None.\n            **kwargs: Other fields to pass to CKAN.\n\n        Returns:\n            Tuple[bool, Union[Dict, str]]: (True/False, HDX object metadata/Error)\n        \"\"\"\n        if not fieldname:\n            raise HDXError('Empty %s field name!' % object_type)\n        if action is None:\n            action = self.actions()['show']\n        data = {fieldname: value}\n        data.update(kwargs)\n        try:\n            result = self.configuration.call_remoteckan(action, data)\n            return True, result\n        except NotFound:\n            return False, '%s=%s: not found!' % (fieldname, value)\n        except Exception as e:\n            raisefrom(HDXError, 'Failed when trying to read: %s=%s! (POST)' % (fieldname, value), e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if HDX object exists and if so load it.", "response": "def _check_load_existing_object(self, object_type, id_field_name, operation='update'):\n        # type: (str, str, str) -> None\n        \"\"\"Check metadata exists and contains HDX object identifier, and if so load HDX object\n\n        Args:\n            object_type (str): Description of HDX object type (for messages)\n            id_field_name (str): Name of field containing HDX object identifier\n            operation (str): Operation to report if error. Defaults to update.\n\n        Returns:\n            None\n        \"\"\"\n        self._check_existing_object(object_type, id_field_name)\n        if not self._load_from_hdx(object_type, self.data[id_field_name]):\n            raise HDXError('No existing %s to %s!' % (object_type, operation))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate or updates an HDX object in HDX and return HDX object metadata dict Args: action (str): Action to perform eg. 'create', 'update' data (Dict): Data to write to HDX id_field_name (str): Name of field containing HDX object identifier or None file_to_upload (Optional[str]): File to upload to HDX Returns: Dict: HDX object metadata", "response": "def _write_to_hdx(self, action, data, id_field_name, file_to_upload=None):\n        # type: (str, Dict, str, Optional[str]) -> Dict\n        \"\"\"Creates or updates an HDX object in HDX and return HDX object metadata dict\n\n        Args:\n            action (str): Action to perform eg. 'create', 'update'\n            data (Dict): Data to write to HDX\n            id_field_name (str): Name of field containing HDX object identifier or None\n            file_to_upload (Optional[str]): File to upload to HDX\n\n        Returns:\n            Dict: HDX object metadata\n        \"\"\"\n        file = None\n        try:\n            if file_to_upload:\n                file = open(file_to_upload, 'rb')\n                files = [('upload', file)]\n            else:\n                files = None\n            return self.configuration.call_remoteckan(self.actions()[action], data, files=files)\n        except Exception as e:\n            raisefrom(HDXError, 'Failed when trying to %s %s! (POST)' % (action, data[id_field_name]), e)\n        finally:\n            if file_to_upload and file:\n                file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving or updates an HDX object in HDX and returns None", "response": "def _save_to_hdx(self, action, id_field_name, file_to_upload=None):\n        # type: (str, str, Optional[str]) -> None\n        \"\"\"Creates or updates an HDX object in HDX, saving current data and replacing with returned HDX object data\n        from HDX\n\n        Args:\n            action (str): Action to perform: 'create' or 'update'\n            id_field_name (str): Name of field containing HDX object identifier\n            file_to_upload (Optional[str]): File to upload to HDX\n\n        Returns:\n            None\n        \"\"\"\n        result = self._write_to_hdx(action, self.data, id_field_name, file_to_upload)\n        self.old_data = self.data\n        self.data = result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _delete_from_hdx(self, object_type, id_field_name):\n        # type: (str, str) -> None\n        \"\"\"Helper method to deletes a resource from HDX\n\n        Args:\n            object_type (str): Description of HDX object type (for messages)\n            id_field_name (str): Name of field containing HDX object identifier\n\n        Returns:\n            None\n        \"\"\"\n        if id_field_name not in self.data:\n            raise HDXError('No %s field (mandatory) in %s!' % (id_field_name, object_type))\n        self._save_to_hdx('delete', id_field_name)", "response": "Internal method to delete a resource from HDX"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_hdxobject(self, objlist, obj, matchon='id', delete=False):\n        # type: (List[Union[HDXObjectUpperBound,Dict]], Union[HDXObjectUpperBound,Dict,str], str, bool) -> bool\n        \"\"\"Remove an HDX object from a list within the parent HDX object\n\n        Args:\n            objlist (List[Union[T <= HDXObject,Dict]]): list of HDX objects\n            obj (Union[T <= HDXObject,Dict,str]): Either an id or hdx object metadata either from an HDX object or a dictionary\n            matchon (str): Field to match on. Defaults to id.\n            delete (bool): Whether to delete HDX object. Defaults to False.\n\n        Returns:\n            bool: True if object removed, False if not\n        \"\"\"\n        if objlist is None:\n            return False\n        if isinstance(obj, six.string_types):\n            obj_id = obj\n        elif isinstance(obj, dict) or isinstance(obj, HDXObject):\n            obj_id = obj.get(matchon)\n        else:\n            raise HDXError('Type of object not a string, dict or T<=HDXObject')\n        if not obj_id:\n            return False\n        for i, objdata in enumerate(objlist):\n            objid = objdata.get(matchon)\n            if objid and objid == obj_id:\n                if delete:\n                    objlist[i].delete_from_hdx()\n                del objlist[i]\n                return True\n        return False", "response": "Remove an HDX object from a list within the parent HDX object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_hdxobjects(self, hdxobjects):\n        # type: (List[HDXObjectUpperBound]) -> List[HDXObjectUpperBound]\n        \"\"\"Helper function to convert supplied list of HDX objects to a list of dict\n\n        Args:\n            hdxobjects (List[T <= HDXObject]): List of HDX objects to convert\n\n        Returns:\n            List[Dict]: List of HDX objects converted to simple dictionaries\n        \"\"\"\n        newhdxobjects = list()\n        for hdxobject in hdxobjects:\n            newhdxobjects.append(hdxobject.data)\n        return newhdxobjects", "response": "Helper function to convert a list of HDX objects to a list of dict containing HDX objects"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _copy_hdxobjects(self, hdxobjects, hdxobjectclass, attribute_to_copy=None):\n        # type: (List[HDXObjectUpperBound], type, Optional[str]) -> List[HDXObjectUpperBound]\n        \"\"\"Helper function to make a deep copy of a supplied list of HDX objects\n\n        Args:\n            hdxobjects (List[T <= HDXObject]): list of HDX objects to copy\n            hdxobjectclass (type): Type of the HDX Objects to be copied\n            attribute_to_copy (Optional[str]): An attribute to copy over from the HDX object. Defaults to None.\n\n        Returns:\n            List[T <= HDXObject]: Deep copy of list of HDX objects\n        \"\"\"\n        newhdxobjects = list()\n        for hdxobject in hdxobjects:\n            newhdxobjectdata = copy.deepcopy(hdxobject.data)\n            newhdxobject = hdxobjectclass(newhdxobjectdata, configuration=self.configuration)\n            if attribute_to_copy:\n                value = getattr(hdxobject, attribute_to_copy)\n                setattr(newhdxobject, attribute_to_copy, value)\n            newhdxobjects.append(newhdxobject)\n        return newhdxobjects", "response": "Helper function to make a deep copy of a list of HDX objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _separate_hdxobjects(self, hdxobjects, hdxobjects_name, id_field, hdxobjectclass):\n        # type: (List[HDXObjectUpperBound], str, str, type) -> None\n        \"\"\"Helper function to take a list of HDX objects contained in the internal dictionary and add them to a\n        supplied list of HDX objects or update existing metadata if any objects already exist in the list. The list in\n        the internal dictionary is then deleted.\n\n        Args:\n            hdxobjects (List[T <= HDXObject]): list of HDX objects to which to add new objects or update existing ones\n            hdxobjects_name (str): Name of key in internal dictionary from which to obtain list of HDX objects\n            id_field (str): Field on which to match to determine if object already exists in list\n            hdxobjectclass (type): Type of the HDX Object to be added/updated\n\n        Returns:\n            None\n        \"\"\"\n        new_hdxobjects = self.data.get(hdxobjects_name, list())\n        \"\"\":type : List[HDXObjectUpperBound]\"\"\"\n        if new_hdxobjects:\n            hdxobject_names = set()\n            for hdxobject in hdxobjects:\n                hdxobject_name = hdxobject[id_field]\n                hdxobject_names.add(hdxobject_name)\n                for new_hdxobject in new_hdxobjects:\n                    if hdxobject_name == new_hdxobject[id_field]:\n                        merge_two_dictionaries(hdxobject, new_hdxobject)\n                        break\n            for new_hdxobject in new_hdxobjects:\n                if not new_hdxobject[id_field] in hdxobject_names:\n                    hdxobjects.append(hdxobjectclass(new_hdxobject, configuration=self.configuration))\n            del self.data[hdxobjects_name]", "response": "This function is used to separate a list of HDX objects from the internal dictionary and add them to the internal dictionary if any objects already exist in the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_tags(self):\n        # type: () -> List[str]\n        \"\"\"Return the dataset's list of tags\n\n        Returns:\n            List[str]: list of tags or [] if there are none\n        \"\"\"\n        tags = self.data.get('tags', None)\n        if not tags:\n            return list()\n        return [x['name'] for x in tags]", "response": "Return the dataset s list of tags"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_tag(self, tag):\n        # type: (str) -> bool\n        \"\"\"Add a tag\n\n        Args:\n            tag (str): Tag to add\n\n        Returns:\n            bool: True if tag added or False if tag already present\n        \"\"\"\n        tags = self.data.get('tags', None)\n        if tags:\n            if tag in [x['name'] for x in tags]:\n                return False\n        else:\n            tags = list()\n        tags.append({'name': tag})\n        self.data['tags'] = tags\n        return True", "response": "Add a tag to the internal data structure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_tags(self, tags):\n        # type: (List[str]) -> bool\n        \"\"\"Add a list of tag\n\n        Args:\n            tags (List[str]): list of tags to add\n\n        Returns:\n            bool: True if all tags added or False if any already present.\n        \"\"\"\n        alltagsadded = True\n        for tag in tags:\n            if not self._add_tag(tag):\n                alltagsadded = False\n        return alltagsadded", "response": "Add a list of tags to the internal cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_stringlist_from_commastring(self, field):\n        # type: (str) -> List[str]\n        \"\"\"Return list of strings from comma separated list\n\n        Args:\n            field (str): Field containing comma separated list\n\n        Returns:\n            List[str]: List of strings\n        \"\"\"\n        strings = self.data.get(field)\n        if strings:\n            return strings.split(',')\n        else:\n            return list()", "response": "Returns list of strings from comma separated list\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a string to a comma separated list of strings", "response": "def _add_string_to_commastring(self, field, string):\n        # type: (str, str) -> bool\n        \"\"\"Add a string to a comma separated list of strings\n\n        Args:\n            field (str): Field containing comma separated list\n            string (str): String to add\n\n        Returns:\n            bool: True if string added or False if string already present\n        \"\"\"\n        if string in self._get_stringlist_from_commastring(field):\n            return False\n        strings = '%s,%s' % (self.data.get(field, ''), string)\n        if strings[0] == ',':\n            strings = strings[1:]\n        self.data[field] = strings\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a list of strings to a comma separated list of strings", "response": "def _add_strings_to_commastring(self, field, strings):\n        # type: (str, List[str]) -> bool\n        \"\"\"Add a list of strings to a comma separated list of strings\n\n        Args:\n            field (str): Field containing comma separated list\n            strings (List[str]): list of strings to add\n\n        Returns:\n            bool: True if all strings added or False if any already present.\n        \"\"\"\n        allstringsadded = True\n        for string in strings:\n            if not self._add_string_to_commastring(field, string):\n                allstringsadded = False\n        return allstringsadded"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a string from a comma separated list of strings", "response": "def _remove_string_from_commastring(self, field, string):\n        # type: (str, str) -> bool\n        \"\"\"Remove a string from a comma separated list of strings\n\n        Args:\n            field (str): Field containing comma separated list\n            string (str): String to remove\n\n        Returns:\n            bool: True if string removed or False if not\n        \"\"\"\n        commastring = self.data.get(field, '')\n        if string in commastring:\n            self.data[field] = commastring.replace(string, '')\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the resource given by identifier from HDX and returns Resource object if successful.", "response": "def read_from_hdx(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> Optional['Resource']\n        \"\"\"Reads the resource given by identifier from HDX and returns Resource object\n\n        Args:\n            identifier (str): Identifier of resource\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[Resource]: Resource object if successful read, None if not\n        \"\"\"\n\n        if is_valid_uuid(identifier) is False:\n            raise HDXError('%s is not a valid resource id!' % identifier)\n        resource = Resource(configuration=configuration)\n        result = resource._load_from_hdx('resource', identifier)\n        if result:\n            return resource\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_file_to_upload(self, file_to_upload):\n        # type: (str) -> None\n        \"\"\"Delete any existing url and set the file uploaded to the local path provided\n\n        Args:\n            file_to_upload (str): Local path to file to upload\n\n        Returns:\n            None\n        \"\"\"\n        if 'url' in self.data:\n            del self.data['url']\n        self.file_to_upload = file_to_upload", "response": "Delete any existing url and set the file uploaded to the local path provided\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_url_filetoupload(self):\n        # type: () -> None\n        \"\"\"Check if url or file to upload provided for resource and add resource_type and url_type if not supplied\n\n        Returns:\n            None\n        \"\"\"\n        if self.file_to_upload is None:\n            if 'url' in self.data:\n                if 'resource_type' not in self.data:\n                    self.data['resource_type'] = 'api'\n                if 'url_type' not in self.data:\n                    self.data['url_type'] = 'api'\n            else:\n                raise HDXError('Either a url or a file to upload must be supplied!')\n        else:\n            if 'url' in self.data:\n                if self.data['url'] != hdx.data.dataset.Dataset.temporary_url:\n                    raise HDXError('Either a url or a file to upload must be supplied not both!')\n            if 'resource_type' not in self.data:\n                self.data['resource_type'] = 'file.upload'\n            if 'url_type' not in self.data:\n                self.data['url_type'] = 'upload'\n            if 'tracking_summary' in self.data:\n                del self.data['tracking_summary']", "response": "Check if url or file to upload is supplied for resource and add resource_type and url_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the resource in HDX if it exists in HDX and if so update it.", "response": "def update_in_hdx(self, **kwargs):\n        # type: (Any) -> None\n        \"\"\"Check if resource exists in HDX and if so, update it\n\n        Args:\n            **kwargs: See below\n            operation (string): Operation to perform eg. patch. Defaults to update.\n\n        Returns:\n            None\n        \"\"\"\n        self._check_load_existing_object('resource', 'id')\n        if self.file_to_upload and 'url' in self.data:\n            del self.data['url']\n        self._merge_hdx_update('resource', 'id', self.file_to_upload, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_in_hdx(self):\n        # type: () -> None\n        \"\"\"Check if resource exists in HDX and if so, update it, otherwise create it\n\n        Returns:\n            None\n        \"\"\"\n        self.check_required_fields()\n        id = self.data.get('id')\n        if id and self._load_from_hdx('resource', id):\n            logger.warning('%s exists. Updating %s' % ('resource', id))\n            if self.file_to_upload and 'url' in self.data:\n                del self.data['url']\n            self._merge_hdx_update('resource', 'id', self.file_to_upload)\n        else:\n            self._save_to_hdx('create', 'name', self.file_to_upload)", "response": "Check if resource exists in HDX and if so update it otherwise create it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dataset(self):\n        # type: () -> hdx.data.dataset.Dataset\n        \"\"\"Return dataset containing this resource\n\n        Returns:\n            hdx.data.dataset.Dataset: Dataset containing this resource\n        \"\"\"\n        package_id = self.data.get('package_id')\n        if package_id is None:\n            raise HDXError('Resource has no package id!')\n        return hdx.data.dataset.Dataset.read_from_hdx(package_id)", "response": "Returns the dataset containing this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_in_hdx(query, configuration=None, **kwargs):\n        # type: (str, Optional[Configuration], Any) -> List['Resource']\n        \"\"\"Searches for resources in HDX. NOTE: Does not search dataset metadata!\n\n        Args:\n            query (str): Query\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            **kwargs: See below\n            order_by (str): A field on the Resource model that orders the results\n            offset (int): Apply an offset to the query\n            limit (int): Apply a limit to the query\n        Returns:\n            List[Resource]: List of resources resulting from query\n        \"\"\"\n\n        resources = []\n        resource = Resource(configuration=configuration)\n        success, result = resource._read_from_hdx('resource', query, 'query', Resource.actions()['search'])\n        if result:\n            count = result.get('count', None)\n            if count:\n                for resourcedict in result['results']:\n                    resource = Resource(resourcedict, configuration=configuration)\n                    resources.append(resource)\n        else:\n            logger.debug(result)\n        return resources", "response": "Searches for resources in HDX."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload the resource store to provided folder or temporary folder if no folder supplied", "response": "def download(self, folder=None):\n        # type: (Optional[str]) -> Tuple[str, str]\n        \"\"\"Download resource store to provided folder or temporary folder if no folder supplied\n\n        Args:\n            folder (Optional[str]): Folder to download resource to. Defaults to None.\n\n        Returns:\n            Tuple[str, str]: (URL downloaded, Path to downloaded file)\n\n        \"\"\"\n        # Download the resource\n        url = self.data.get('url', None)\n        if not url:\n            raise HDXError('No URL to download!')\n        logger.debug('Downloading %s' % url)\n        filename = self.data['name']\n        format = '.%s' % self.data['format']\n        if format not in filename:\n            filename = '%s%s' % (filename, format)\n        with Download(full_agent=self.configuration.get_user_agent()) as downloader:\n            path = downloader.download_file(url, folder, filename)\n            return url, path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget list of resources that have a datastore returning their ids.", "response": "def get_all_resource_ids_in_datastore(configuration=None):\n        # type: (Optional[Configuration]) -> List[str]\n        \"\"\"Get list of resources that have a datastore returning their ids.\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            List[str]: List of resource ids that are in the datastore\n        \"\"\"\n        resource = Resource(configuration=configuration)\n        success, result = resource._read_from_hdx('datastore', '_table_metadata', 'resource_id',\n                                                  Resource.actions()['datastore_search'], limit=10000)\n        resource_ids = list()\n        if not success:\n            logger.debug(result)\n        else:\n            for record in result['records']:\n                resource_ids.append(record['name'])\n        return resource_ids"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the resource has a datastore.", "response": "def has_datastore(self):\n        # type: () -> bool\n        \"\"\"Check if the resource has a datastore.\n\n        Returns:\n            bool: Whether the resource has a datastore or not\n        \"\"\"\n        success, result = self._read_from_hdx('datastore', self.data['id'], 'resource_id',\n                                              self.actions()['datastore_search'])\n        if not success:\n            logger.debug(result)\n        else:\n            if result:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_datastore(self):\n        # type: () -> None\n        \"\"\"Delete a resource from the HDX datastore\n\n        Returns:\n            None\n        \"\"\"\n        success, result = self._read_from_hdx('datastore', self.data['id'], 'resource_id',\n                                              self.actions()['datastore_delete'],\n                                              force=True)\n        if not success:\n            logger.debug(result)", "response": "Delete a resource from the HDX datastore"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_datastore(self, schema=None, primary_key=None,\n                         delete_first=0, path=None):\n        # type: (Optional[List[Dict]], Optional[str], int, Optional[str]) -> None\n        \"\"\"For tabular data, create a resource in the HDX datastore which enables data preview in HDX. If no schema is provided\n        all fields are assumed to be text. If path is not supplied, the file is first downloaded from HDX.\n\n        Args:\n            schema (List[Dict]): List of fields and types of form {'id': 'FIELD', 'type': 'TYPE'}. Defaults to None.\n            primary_key (Optional[str]): Primary key of schema. Defaults to None.\n            delete_first (int): Delete datastore before creation. 0 = No, 1 = Yes, 2 = If no primary key. Defaults to 0.\n            path (Optional[str]): Local path to file that was uploaded. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        if delete_first == 0:\n            pass\n        elif delete_first == 1:\n            self.delete_datastore()\n        elif delete_first == 2:\n            if primary_key is None:\n                self.delete_datastore()\n        else:\n            raise HDXError('delete_first must be 0, 1 or 2! (0 = No, 1 = Yes, 2 = Delete if no primary key)')\n        if path is None:\n            # Download the resource\n            url, path = self.download()\n            delete_after_download = True\n        else:\n            url = path\n            delete_after_download = False\n\n        def convert_to_text(extended_rows):\n            for number, headers, row in extended_rows:\n                for i, val in enumerate(row):\n                    row[i] = str(val)\n                yield (number, headers, row)\n\n        with Download(full_agent=self.configuration.get_user_agent()) as downloader:\n            try:\n                stream = downloader.get_tabular_stream(path, headers=1, post_parse=[convert_to_text],\n                                                       bytes_sample_size=1000000)\n                nonefieldname = False\n                if schema is None:\n                    schema = list()\n                    for fieldname in stream.headers:\n                        if fieldname is not None:\n                            schema.append({'id': fieldname, 'type': 'text'})\n                        else:\n                            nonefieldname = True\n                data = {'resource_id': self.data['id'], 'force': True, 'fields': schema, 'primary_key': primary_key}\n                self._write_to_hdx('datastore_create', data, 'resource_id')\n                if primary_key is None:\n                    method = 'insert'\n                else:\n                    method = 'upsert'\n                logger.debug('Uploading data from %s to datastore' % url)\n                offset = 0\n                chunksize = 100\n                rowset = stream.read(keyed=True, limit=chunksize)\n                while len(rowset) != 0:\n                    if nonefieldname:\n                        for row in rowset:\n                            del row[None]\n                    data = {'resource_id': self.data['id'], 'force': True, 'method': method, 'records': rowset}\n                    self._write_to_hdx('datastore_upsert', data, 'resource_id')\n                    rowset = stream.read(keyed=True, limit=chunksize)\n                    logger.debug('Uploading: %s' % offset)\n                    offset += chunksize\n            except Exception as e:\n                raisefrom(HDXError, 'Upload to datastore of %s failed!' % url, e)\n            finally:\n                if delete_after_download:\n                    remove(path)", "response": "Create a resource in the HDX datastore which enables data preview in HDX."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_datastore_from_dict_schema(self, data, delete_first=0, path=None):\n        # type: (dict, int, Optional[str]) -> None\n        \"\"\"For tabular data, create a resource in the HDX datastore which enables data preview in HDX from a dictionary\n        containing a list of fields and types of form {'id': 'FIELD', 'type': 'TYPE'} and optionally a primary key.\n        If path is not supplied, the file is first downloaded from HDX.\n\n        Args:\n            data (dict): Dictionary containing list of fields and types of form {'id': 'FIELD', 'type': 'TYPE'}\n            delete_first (int): Delete datastore before creation. 0 = No, 1 = Yes, 2 = If no primary key. Defaults to 0.\n            path (Optional[str]): Local path to file that was uploaded. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        schema = data['schema']\n        primary_key = data.get('primary_key')\n        self.create_datastore(schema, primary_key, delete_first, path=path)", "response": "Create a resource in the HDX datastore from a dictionary containing a list of fields and types of form TYPE and optionally a primary key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a resource in the HDX datastore from a YAML file containing a list of fields and types of form TYPE and optionally a primary key.", "response": "def create_datastore_from_yaml_schema(self, yaml_path, delete_first=0,\n                                          path=None):\n        # type: (str, Optional[int], Optional[str]) -> None\n        \"\"\"For tabular data, create a resource in the HDX datastore which enables data preview in HDX from a YAML file\n        containing a list of fields and types of form {'id': 'FIELD', 'type': 'TYPE'} and optionally a primary key.\n        If path is not supplied, the file is first downloaded from HDX.\n\n        Args:\n            yaml_path (str): Path to YAML file containing list of fields and types of form {'id': 'FIELD', 'type': 'TYPE'}\n            delete_first (int): Delete datastore before creation. 0 = No, 1 = Yes, 2 = If no primary key. Defaults to 0.\n            path (Optional[str]): Local path to file that was uploaded. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        data = load_yaml(yaml_path)\n        self.create_datastore_from_dict_schema(data, delete_first, path=path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_datastore_from_json_schema(self, json_path, delete_first=0, path=None):\n        # type: (str, int, Optional[str]) -> None\n        \"\"\"For tabular data, create a resource in the HDX datastore which enables data preview in HDX from a JSON file\n        containing a list of fields and types of form {'id': 'FIELD', 'type': 'TYPE'} and optionally a primary key.\n        If path is not supplied, the file is first downloaded from HDX.\n\n        Args:\n            json_path (str): Path to JSON file containing list of fields and types of form {'id': 'FIELD', 'type': 'TYPE'}\n            delete_first (int): Delete datastore before creation. 0 = No, 1 = Yes, 2 = If no primary key. Defaults to 0.\n            path (Optional[str]): Local path to file that was uploaded. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        data = load_json(json_path)\n        self.create_datastore_from_dict_schema(data, delete_first, path=path)", "response": "For tabular data create a resource in the HDX datastore which enables data preview in HDX from a JSON file containing a list of fields and types of form TYPE and optionally a primary key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_datastore_for_topline(self, delete_first=0, path=None):\n        # type: (int, Optional[str]) -> None\n        \"\"\"For tabular data, create a resource in the HDX datastore which enables data preview in HDX using the built in\n        YAML definition for a topline. If path is not supplied, the file is first downloaded from HDX.\n\n        Args:\n            delete_first (int): Delete datastore before creation. 0 = No, 1 = Yes, 2 = If no primary key. Defaults to 0.\n            path (Optional[str]): Local path to file that was uploaded. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        data = load_yaml(script_dir_plus_file(join('..', 'hdx_datasource_topline.yml'), Resource))\n        self.create_datastore_from_dict_schema(data, delete_first, path=path)", "response": "Create a resource in the HDX datastore which enables data preview in HDX using the built in\n        YAML definition for a topline."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_resource_view(self, resource_view):\n        # type: (Union[ResourceView,Dict]) -> ResourceView\n        \"\"\"Get resource view id\n\n        Args:\n            resource_view (Union[ResourceView,Dict]): ResourceView metadata from a ResourceView object or dictionary\n\n        Returns:\n            ResourceView: ResourceView object\n        \"\"\"\n        if isinstance(resource_view, dict):\n            resource_view = ResourceView(resource_view, configuration=self.configuration)\n        if isinstance(resource_view, ResourceView):\n            return resource_view\n        raise HDXError('Type %s is not a valid resource view!' % type(resource_view).__name__)", "response": "Get resource view id from a resource view object or dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_update_resource_views(self, resource_views):\n        # type: (List[Union[ResourceView,Dict]]) -> None\n        \"\"\"Add new or update existing resource views in resource with new metadata.\n\n        Args:\n            resource_views (List[Union[ResourceView,Dict]]): A list of resource views metadata from ResourceView objects or dictionaries\n\n        Returns:\n            None\n        \"\"\"\n        if not isinstance(resource_views, list):\n            raise HDXError('ResourceViews should be a list!')\n        for resource_view in resource_views:\n            self.add_update_resource_view(resource_view)", "response": "Add new or update existing resource views in resource with new metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreordering resource views in resource.", "response": "def reorder_resource_views(self, resource_views):\n        # type: (List[Union[ResourceView,Dict,str]]) -> None\n        \"\"\"Order resource views in resource.\n\n        Args:\n            resource_views (List[Union[ResourceView,Dict,str]]): A list of either resource view ids or resource views metadata from ResourceView objects or dictionaries\n\n        Returns:\n            None\n        \"\"\"\n        if not isinstance(resource_views, list):\n            raise HDXError('ResourceViews should be a list!')\n        ids = list()\n        for resource_view in resource_views:\n            if isinstance(resource_view, str):\n                resource_view_id = resource_view\n            else:\n                resource_view_id = resource_view['id']\n            if is_valid_uuid(resource_view_id) is False:\n                raise HDXError('%s is not a valid resource view id!' % resource_view)\n            ids.append(resource_view_id)\n        _, result = self._read_from_hdx('resource view', self.data['id'], 'id',\n                                        ResourceView.actions()['reorder'], order=ids)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a resource view from the resource and HDX", "response": "def delete_resource_view(self, resource_view):\n        # type: (Union[ResourceView,Dict,str]) -> None\n        \"\"\"Delete a resource view from the resource and HDX\n\n        Args:\n            resource_view (Union[ResourceView,Dict,str]): Either a resource view id or resource view metadata either from a ResourceView object or a dictionary\n\n        Returns:\n            None\n        \"\"\"\n        if isinstance(resource_view, str):\n            if is_valid_uuid(resource_view) is False:\n                raise HDXError('%s is not a valid resource view id!' % resource_view)\n            resource_view = ResourceView({'id': resource_view}, configuration=self.configuration)\n        else:\n            resource_view = self._get_resource_view(resource_view)\n            if 'id' not in resource_view:\n                found = False\n                title = resource_view.get('title')\n                for rv in self.get_resource_views():\n                    if resource_view['title'] == rv['title']:\n                        resource_view = rv\n                        found = True\n                        break\n                if not found:\n                    raise HDXError('No resource views have title %s in this resource!' % title)\n        resource_view.delete_from_hdx()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_for_simple_stems(output, skip_empty=False, skip_same_stems=True):\n    lines_with_stems = _get_lines_with_stems(output)\n    stems = list()\n\n    last_word = None\n    for line in lines_with_stems:\n        word, stem, _ = line.split(\"\\t\")\n        stem = stem if stem != '-' else None\n\n        if skip_empty and (stem is None):\n            continue\n\n        if last_word != word:\n            stems.append((word, []))\n\n        ## append new stem only if not on list already\n        stem = None if skip_same_stems and stem in stems[-1][1] else stem\n        if stem is not None:\n            stems[-1][1].append(stem)\n\n        last_word = word\n\n    return stems", "response": "Parses the output stem lines to produce a list with possible stems for each word in the output."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _CreateClassTemplate(cls, data_type_definition):\n    type_name = data_type_definition.name\n\n    type_description = data_type_definition.description or type_name\n    while type_description.endswith('.'):\n      type_description = type_description[:-1]\n\n    class_attributes_description = []\n    init_arguments = []\n    instance_attributes = []\n\n    for member_definition in data_type_definition.members:\n      attribute_name = member_definition.name\n\n      description = member_definition.description or attribute_name\n      while description.endswith('.'):\n        description = description[:-1]\n\n      member_data_type = getattr(member_definition, 'member_data_type', '')\n      if isinstance(member_definition, data_types.MemberDataTypeDefinition):\n        member_definition = member_definition.member_data_type_definition\n\n      member_type_indicator = member_definition.TYPE_INDICATOR\n      if member_type_indicator == definitions.TYPE_INDICATOR_SEQUENCE:\n        element_type_indicator = member_definition.element_data_type\n        member_type_indicator = 'tuple[{0:s}]'.format(element_type_indicator)\n      else:\n        member_type_indicator = cls._PYTHON_NATIVE_TYPES.get(\n            member_type_indicator, member_data_type)\n\n      argument = '{0:s}=None'.format(attribute_name)\n\n      definition = '    self.{0:s} = {0:s}'.format(attribute_name)\n\n      description = '    {0:s} ({1:s}): {2:s}.'.format(\n          attribute_name, member_type_indicator, description)\n\n      class_attributes_description.append(description)\n      init_arguments.append(argument)\n      instance_attributes.append(definition)\n\n    class_attributes_description = '\\n'.join(\n        sorted(class_attributes_description))\n    init_arguments = ', '.join(init_arguments)\n    instance_attributes = '\\n'.join(sorted(instance_attributes))\n\n    template_values = {\n        'class_attributes_description': class_attributes_description,\n        'init_arguments': init_arguments,\n        'instance_attributes': instance_attributes,\n        'type_description': type_description,\n        'type_name': type_name}\n\n    return cls._CLASS_TEMPLATE.format(**template_values)", "response": "Creates the class template."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _IsIdentifier(cls, string):\n    return (\n        string and not string[0].isdigit() and\n        all(character.isalnum() or character == '_' for character in string))", "response": "Checks if a string contains an identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the data type definition.", "response": "def _ValidateDataTypeDefinition(cls, data_type_definition):\n    \"\"\"Validates the data type definition.\n\n    Args:\n      data_type_definition (DataTypeDefinition): data type definition.\n\n    Raises:\n      ValueError: if the data type definition is not considered valid.\n    \"\"\"\n    if not cls._IsIdentifier(data_type_definition.name):\n      raise ValueError(\n          'Data type definition name: {0!s} not a valid identifier'.format(\n              data_type_definition.name))\n\n    if keyword.iskeyword(data_type_definition.name):\n      raise ValueError(\n          'Data type definition name: {0!s} matches keyword'.format(\n              data_type_definition.name))\n\n    members = getattr(data_type_definition, 'members', None)\n    if not members:\n      raise ValueError(\n          'Data type definition name: {0!s} missing members'.format(\n              data_type_definition.name))\n\n    defined_attribute_names = set()\n\n    for member_definition in members:\n      attribute_name = member_definition.name\n\n      if not cls._IsIdentifier(attribute_name):\n        raise ValueError('Attribute name: {0!s} not a valid identifier'.format(\n            attribute_name))\n\n      if attribute_name.startswith('_'):\n        raise ValueError('Attribute name: {0!s} starts with underscore'.format(\n            attribute_name))\n\n      if keyword.iskeyword(attribute_name):\n        raise ValueError('Attribute name: {0!s} matches keyword'.format(\n            attribute_name))\n\n      if attribute_name in defined_attribute_names:\n        raise ValueError('Attribute name: {0!s} already defined'.format(\n            attribute_name))\n\n      defined_attribute_names.add(attribute_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CreateClass(cls, data_type_definition):\n    cls._ValidateDataTypeDefinition(data_type_definition)\n\n    class_definition = cls._CreateClassTemplate(data_type_definition)\n\n    namespace = {\n        '__builtins__' : {\n            'object': builtins.object,\n            'super': builtins.super},\n        '__name__': '{0:s}'.format(data_type_definition.name)}\n\n    if sys.version_info[0] >= 3:\n      # pylint: disable=no-member\n      namespace['__builtins__']['__build_class__'] = builtins.__build_class__\n\n    exec(class_definition, namespace)  # pylint: disable=exec-used\n\n    return namespace[data_type_definition.name]", "response": "Creates a new structure values class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetDefinitionByName(self, name):\n    lookup_name = name.lower()\n    if lookup_name not in self._definitions:\n      lookup_name = self._aliases.get(name, None)\n\n    return self._definitions.get(lookup_name, None)", "response": "Retrieves a specific data type definition by name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef RegisterDefinition(self, data_type_definition):\n    name_lower = data_type_definition.name.lower()\n    if name_lower in self._definitions:\n      raise KeyError('Definition already set for name: {0:s}.'.format(\n          data_type_definition.name))\n\n    if data_type_definition.name in self._aliases:\n      raise KeyError('Alias already set for name: {0:s}.'.format(\n          data_type_definition.name))\n\n    for alias in data_type_definition.aliases:\n      if alias in self._aliases:\n        raise KeyError('Alias already set for name: {0:s}.'.format(alias))\n\n    self._definitions[name_lower] = data_type_definition\n\n    for alias in data_type_definition.aliases:\n      self._aliases[alias] = name_lower\n\n    if data_type_definition.TYPE_INDICATOR == definitions.TYPE_INDICATOR_FORMAT:\n      self._format_definitions.append(name_lower)", "response": "Registers a data type definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_on_csv_string(rules_str, func):\n        splitted = rules_str.split(\",\")\n        for str in splitted:\n            func(str.strip())", "response": "Splits a given string by comma trims whitespace on the resulting strings and applies a given function to each item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the HTML for the Favicon - URL for the Model.", "response": "def placeFavicon(context):\n    \"\"\"\n    Gets Favicon-URL for the Model.\n\n    Template Syntax:\n\n        {% placeFavicon %}\n\n    \"\"\"\n    fav = Favicon.objects.filter(isFavicon=True).first()\n    if not fav:\n        return mark_safe('<!-- no favicon -->')\n    html = ''\n    for rel in config:\n        for size in sorted(config[rel], reverse=True):\n            n = fav.get_favicon(size=size, rel=rel)\n            html += '<link rel=\"%s\" sizes=\"%sx%s\" href=\"%s\"/>' % (\n                n.rel, n.size, n.size, n.faviconImage.url)\n\n    default_fav = fav.get_favicon(size=32, rel='shortcut icon')\n    html += '<link rel=\"%s\" sizes=\"%sx%s\" href=\"%s\"/>' % (\n        default_fav.rel, default_fav.size, default_fav.size, default_fav.faviconImage.url)\n\n    return mark_safe(html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets default theme name based in config file.", "response": "def set_default_theme(theme):\n    \"\"\"\n    Set default theme name based in config file.\n    \"\"\"\n    pref_init()  # make sure config files exist\n    parser = cp.ConfigParser()\n    parser.read(PREFS_FILE)\n    # Do we need to create a section?\n    if not parser.has_section(\"theme\"):\n        parser.add_section(\"theme\")\n    parser.set(\"theme\", \"default\", theme)\n    # best way to make sure no file truncation?\n    with open(\"%s.2\" % PREFS_FILE, \"w\") as fp:\n        parser.write(fp)\n    copy(\"%s.2\" % PREFS_FILE, PREFS_FILE)\n    unlink(\"%s.2\" % PREFS_FILE,)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget theme name based on manual input prefs file or default to plain.", "response": "def pick_theme(manual):\n    \"\"\"\n    Return theme name based on manual input, prefs file, or default to \"plain\".\n    \"\"\"\n    if manual:\n        return manual\n    pref_init()\n    parser = cp.ConfigParser()\n    parser.read(PREFS_FILE)\n    try:\n        theme = parser.get(\"theme\", \"default\")\n    except (cp.NoSectionError, cp.NoOptionError):\n        theme = \"plain\"\n    return theme"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates ~. cdk dir if it doesn t exist. Copy the default prefs file if it doesn t exist.", "response": "def pref_init():\n    \"\"\"Can be called without penalty. Create ~/.cdk dir if it doesn't\n    exist. Copy the default pref file if it doesn't exist.\"\"\"\n\n    # make sure we have a ~/.cdk dir\n    if not isdir(PREFS_DIR):\n        mkdir(PREFS_DIR)\n    # make sure we have a default prefs file\n    if not isfile(PREFS_FILE):\n        copy(join(LOCATION, \"custom\", \"prefs\"), PREFS_DIR)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall a theme file to the themes directory.", "response": "def install_theme(path_to_theme):\n    \"\"\"\n    Pass a path to a theme file which will be extracted to the themes directory.\n    \"\"\"\n    pref_init()\n    # cp the file\n    filename = basename(path_to_theme)\n    dest = join(THEMES_DIR, filename)\n    copy(path_to_theme, dest)\n    # unzip\n    zf = zipfile.ZipFile(dest)\n    # should make sure zipfile contains only themename folder which doesn't conflict\n    # with existing themename. Or some kind of sanity check\n    zf.extractall(THEMES_DIR)  # plus this is a potential security flaw pre 2.7.4\n    # remove the copied zipfile\n    unlink(dest)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    # Try parsing command line args and flags with docopt\n    args = docopt(__doc__, version=\"cdk\")\n    # Am I going to need validation? No Schema for the moment...\n    if args['FILE']:\n        out = output_file(args['FILE'])\n        # Great! Run asciidoc with appropriate flags\n        theme = pick_theme(args['--theme'])\n        if theme not in listdir(THEMES_DIR):\n            exit('Selected theme \"%s\" not found. Check ~/.cdk/prefs' % theme)\n        cmd = create_command(theme, args['--bare'], args['--toc'], args['--notransition'],\n                             args['--logo'])\n        run_command(cmd, args)\n        if args['--toc']:\n            add_css(out, '.deck-container .deck-toc li a span{color: #888;display:inline;}')\n        if args['--custom-css']:\n            add_css_file(out, args['--custom-css'])\n        if args['--open']:\n            webbrowser.open(\"file://\" + abspath(out))\n\n    # other commands\n    elif args['--generate']:\n        if isfile(args['--generate']):\n            exit(\"%s already exists!\" % args['--generate'])\n        with open(args['--generate'], \"w\") as fp:\n            sample = join(LOCATION,  \"custom\", \"sample.asc\")\n            fp.write(open(sample).read())\n            print(\"Created sample slide deck in %s...\" % args['--generate'])\n        exit()\n\n    elif args['--install-theme']:\n        path = args['--install-theme']\n        if not isfile(path):\n            exit(\"Theme file not found.\")\n        if not path.endswith(\".zip\"):\n            exit(\"Theme installation currently only supports theme install from \"\n                 \".zip files.\")\n        install_theme(path)\n    elif args['--default-theme']:\n        set_default_theme(args['--default-theme'])", "response": "Entry point for asciidocapi\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves contents of resources key in internal dictionary into self. resources", "response": "def separate_resources(self):\n        # type: () -> None\n        \"\"\"Move contents of resources key in internal dictionary into self.resources\n\n        Returns:\n            None\n        \"\"\"\n        self._separate_hdxobjects(self.resources, 'resources', 'name', hdx.data.resource.Resource)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a resource object from a resource object or a dictionary.", "response": "def _get_resource_from_obj(self, resource):\n        # type: (Union[hdx.data.resource.Resource,Dict,str]) -> hdx.data.resource.Resource\n        \"\"\"Add new or update existing resource in dataset with new metadata\n\n        Args:\n            resource (Union[hdx.data.resource.Resource,Dict,str]): Either resource id or resource metadata from a Resource object or a dictionary\n\n        Returns:\n            hdx.data.resource.Resource: Resource object\n        \"\"\"\n        if isinstance(resource, str):\n            if is_valid_uuid(resource) is False:\n                raise HDXError('%s is not a valid resource id!' % resource)\n            resource = hdx.data.resource.Resource.read_from_hdx(resource, configuration=self.configuration)\n        elif isinstance(resource, dict):\n            resource = hdx.data.resource.Resource(resource, configuration=self.configuration)\n        if not isinstance(resource, hdx.data.resource.Resource):\n            raise HDXError('Type %s cannot be added as a resource!' % type(resource).__name__)\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_update_resource(self, resource, ignore_datasetid=False):\n        # type: (Union[hdx.data.resource.Resource,Dict,str], bool) -> None\n        \"\"\"Add new or update existing resource in dataset with new metadata\n\n        Args:\n            resource (Union[hdx.data.resource.Resource,Dict,str]): Either resource id or resource metadata from a Resource object or a dictionary\n            ignore_datasetid (bool): Whether to ignore dataset id in the resource\n\n        Returns:\n            None\n        \"\"\"\n        resource = self._get_resource_from_obj(resource)\n        if 'package_id' in resource:\n            if not ignore_datasetid:\n                raise HDXError('Resource %s being added already has a dataset id!' % (resource['name']))\n        resource.check_url_filetoupload()\n        resource_updated = self._addupdate_hdxobject(self.resources, 'name', resource)\n        if resource.get_file_to_upload():\n            resource_updated.set_file_to_upload(resource.get_file_to_upload())", "response": "Add or update a resource in dataset with new metadata"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds new or update existing resources with new metadata to the dataset", "response": "def add_update_resources(self, resources, ignore_datasetid=False):\n        # type: (List[Union[hdx.data.resource.Resource,Dict,str]], bool) -> None\n        \"\"\"Add new or update existing resources with new metadata to the dataset\n\n        Args:\n            resources (List[Union[hdx.data.resource.Resource,Dict,str]]): A list of either resource ids or resources metadata from either Resource objects or dictionaries\n            ignore_datasetid (bool): Whether to ignore dataset id in the resource. Defaults to False.\n\n        Returns:\n            None\n        \"\"\"\n        if not isinstance(resources, list):\n            raise HDXError('Resources should be a list!')\n        for resource in resources:\n            self.add_update_resource(resource, ignore_datasetid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a resource from the dataset and also from HDX by default", "response": "def delete_resource(self, resource, delete=True):\n        # type: (Union[hdx.data.resource.Resource,Dict,str], bool) -> bool\n        \"\"\"Delete a resource from the dataset and also from HDX by default\n\n        Args:\n            resource (Union[hdx.data.resource.Resource,Dict,str]): Either resource id or resource metadata from a Resource object or a dictionary\n            delete (bool): Whetehr to delete the resource from HDX (not just the dataset). Defaults to True.\n\n        Returns:\n            bool: True if resource removed or False if not\n        \"\"\"\n        if isinstance(resource, str):\n            if is_valid_uuid(resource) is False:\n                raise HDXError('%s is not a valid resource id!' % resource)\n        return self._remove_hdxobject(self.resources, resource, delete=delete)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reorder_resources(self, resource_ids, hxl_update=True):\n        # type: (List[str], bool) -> None\n        \"\"\"Reorder resources in dataset according to provided list.\n        If only some resource ids are supplied then these are\n        assumed to be first and the other resources will stay in\n        their original order.\n\n        Args:\n            resource_ids (List[str]): List of resource ids\n            hxl_update (bool): Whether to call package_hxl_update. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        dataset_id = self.data.get('id')\n        if not dataset_id:\n            raise HDXError('Dataset has no id! It must be read, created or updated first.')\n        data = {'id': dataset_id,\n                'order': resource_ids}\n        self._write_to_hdx('reorder', data, 'package_id')\n        if hxl_update:\n            self.hxl_update()", "response": "Reorder resources in the dataset according to provided list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_from_yaml(self, path=join('config', 'hdx_dataset_static.yml')):\n        # type: (str) -> None\n        \"\"\"Update dataset metadata with static metadata from YAML file\n\n        Args:\n            path (str): Path to YAML dataset metadata. Defaults to config/hdx_dataset_static.yml.\n\n        Returns:\n            None\n        \"\"\"\n        super(Dataset, self).update_from_yaml(path)\n        self.separate_resources()", "response": "Update dataset metadata with static metadata from YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating dataset metadata with static metadata from JSON file at path.", "response": "def update_from_json(self, path=join('config', 'hdx_dataset_static.json')):\n        # type: (str) -> None\n        \"\"\"Update dataset metadata with static metadata from JSON file\n\n        Args:\n            path (str): Path to JSON dataset metadata. Defaults to config/hdx_dataset_static.json.\n\n        Returns:\n            None\n        \"\"\"\n        super(Dataset, self).update_from_json(path)\n        self.separate_resources()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_from_hdx(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> Optional['Dataset']\n        \"\"\"Reads the dataset given by identifier from HDX and returns Dataset object\n\n        Args:\n            identifier (str): Identifier of dataset\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[Dataset]: Dataset object if successful read, None if not\n        \"\"\"\n\n        dataset = Dataset(configuration=configuration)\n        result = dataset._dataset_load_from_hdx(identifier)\n        if result:\n            return dataset\n        return None", "response": "Reads the dataset given by identifier from HDX and returns Dataset object if successful."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dataset_create_resources(self):\n        # type: () -> None\n        \"\"\"Creates resource objects in dataset\n        \"\"\"\n\n        if 'resources' in self.data:\n            self.old_data['resources'] = self._copy_hdxobjects(self.resources, hdx.data.resource.Resource, 'file_to_upload')\n            self.init_resources()\n            self.separate_resources()", "response": "Creates resource objects in dataset\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the dataset given by either id or name from HDX and creates the resources if needed.", "response": "def _dataset_load_from_hdx(self, id_or_name):\n        # type: (str) -> bool\n        \"\"\"Loads the dataset given by either id or name from HDX\n\n        Args:\n            id_or_name (str): Either id or name of dataset\n\n        Returns:\n            bool: True if loaded, False if not\n        \"\"\"\n\n        if not self._load_from_hdx('dataset', id_or_name):\n            return False\n        self._dataset_create_resources()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that metadata for dataset and resources is complete.", "response": "def check_required_fields(self, ignore_fields=list(), allow_no_resources=False):\n        # type: (List[str], bool) -> None\n        \"\"\"Check that metadata for dataset and its resources is complete. The parameter ignore_fields\n        should be set if required to any fields that should be ignored for the particular operation.\n\n        Args:\n            ignore_fields (List[str]): Fields to ignore. Default is [].\n            allow_no_resources (bool): Whether to allow no resources. Defaults to False.\n\n        Returns:\n            None\n        \"\"\"\n        if self.is_requestable():\n            self._check_required_fields('dataset-requestable', ignore_fields)\n        else:\n            self._check_required_fields('dataset', ignore_fields)\n            if len(self.resources) == 0 and not allow_no_resources:\n                raise HDXError('There are no resources! Please add at least one resource!')\n            for resource in self.resources:\n                ignore_fields = ['package_id']\n                resource.check_required_fields(ignore_fields=ignore_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dataset_merge_filestore_resource(self, resource, updated_resource, filestore_resources, ignore_fields):\n        # type: (hdx.data.Resource, hdx.data.Resource, List[hdx.data.Resource], List[str]) -> None\n        \"\"\"Helper method to merge updated resource from dataset into HDX resource read from HDX including filestore.\n\n        Args:\n            resource (hdx.data.Resource): Resource read from HDX\n            updated_resource (hdx.data.Resource): Updated resource from dataset\n            filestore_resources (List[hdx.data.Resource]): List of resources that use filestore (to be appended to)\n            ignore_fields (List[str]): List of fields to ignore when checking resource\n\n        Returns:\n            None\n        \"\"\"\n        if updated_resource.get_file_to_upload():\n            resource.set_file_to_upload(updated_resource.get_file_to_upload())\n            filestore_resources.append(resource)\n        merge_two_dictionaries(resource, updated_resource)\n        resource.check_required_fields(ignore_fields=ignore_fields)\n        if resource.get_file_to_upload():\n            resource['url'] = Dataset.temporary_url", "response": "Helper method to merge updated resource into resource from dataset into filestore."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dataset_merge_filestore_newresource(self, new_resource, ignore_fields, filestore_resources):\n        # type: (hdx.data.Resource, List[str], List[hdx.data.Resource]) -> None\n        \"\"\"Helper method to add new resource from dataset including filestore.\n\n        Args:\n            new_resource (hdx.data.Resource): New resource from dataset\n            ignore_fields (List[str]): List of fields to ignore when checking resource\n            filestore_resources (List[hdx.data.Resource]): List of resources that use filestore (to be appended to)\n\n        Returns:\n            None\n        \"\"\"\n        new_resource.check_required_fields(ignore_fields=ignore_fields)\n        self.resources.append(new_resource)\n        if new_resource.get_file_to_upload():\n            filestore_resources.append(new_resource)\n            new_resource['url'] = Dataset.temporary_url", "response": "Helper method to add new resource from dataset including filestore."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_filestore_resources(self, filestore_resources, create_default_views, hxl_update):\n        # type: (List[hdx.data.Resource], bool, bool) -> None\n        \"\"\"Helper method to create files in filestore by updating resources.\n\n        Args:\n            filestore_resources (List[hdx.data.Resource]): List of resources that use filestore (to be appended to)\n            create_default_views (bool): Whether to call package_create_default_resource_views.\n            hxl_update (bool): Whether to call package_hxl_update.\n\n        Returns:\n            None\n        \"\"\"\n        for resource in filestore_resources:\n            for created_resource in self.data['resources']:\n                if resource['name'] == created_resource['name']:\n                    merge_two_dictionaries(resource.data, created_resource)\n                    del resource['url']\n                    resource.update_in_hdx()\n                    merge_two_dictionaries(created_resource, resource.data)\n                    break\n        self.init_resources()\n        self.separate_resources()\n        if create_default_views:\n            self.create_default_views()\n        if hxl_update:\n            self.hxl_update()", "response": "Private method to add filestore resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_in_hdx(self, update_resources=True, update_resources_by_name=True,\n                      remove_additional_resources=False, create_default_views=True, hxl_update=True):\n        # type: (bool, bool, bool, bool, bool) -> None\n        \"\"\"Check if dataset exists in HDX and if so, update it\n\n        Args:\n            update_resources (bool): Whether to update resources. Defaults to True.\n            update_resources_by_name (bool): Compare resource names rather than position in list. Defaults to True.\n            remove_additional_resources (bool): Remove additional resources found in dataset. Defaults to False.\n            create_default_views (bool): Whether to call package_create_default_resource_views. Defaults to True.\n            hxl_update (bool): Whether to call package_hxl_update. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        loaded = False\n        if 'id' in self.data:\n            self._check_existing_object('dataset', 'id')\n            if self._dataset_load_from_hdx(self.data['id']):\n                loaded = True\n            else:\n                logger.warning('Failed to load dataset with id %s' % self.data['id'])\n        if not loaded:\n            self._check_existing_object('dataset', 'name')\n            if not self._dataset_load_from_hdx(self.data['name']):\n                raise HDXError('No existing dataset to update!')\n        self._dataset_merge_hdx_update(update_resources=update_resources,\n                                       update_resources_by_name=update_resources_by_name,\n                                       remove_additional_resources=remove_additional_resources,\n                                       create_default_views=create_default_views,\n                                       hxl_update=hxl_update)", "response": "Update the resource in HDX if it exists in HDX and if so create the resource if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_in_hdx(self, allow_no_resources=False, update_resources=True, update_resources_by_name=True,\n                      remove_additional_resources=False, create_default_views=True, hxl_update=True):\n        # type: (bool, bool, bool, bool, bool, bool) -> None\n        \"\"\"Check if dataset exists in HDX and if so, update it, otherwise create it\n\n        Args:\n            allow_no_resources (bool): Whether to allow no resources. Defaults to False.\n            update_resources (bool): Whether to update resources (if updating). Defaults to True.\n            update_resources_by_name (bool): Compare resource names rather than position in list. Defaults to True.\n            remove_additional_resources (bool): Remove additional resources found in dataset (if updating). Defaults to False.\n            create_default_views (bool): Whether to call package_create_default_resource_views (if updating). Defaults to True.\n            hxl_update (bool): Whether to call package_hxl_update. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        self.check_required_fields(allow_no_resources=allow_no_resources)\n        loadedid = None\n        if 'id' in self.data:\n            if self._dataset_load_from_hdx(self.data['id']):\n                loadedid = self.data['id']\n            else:\n                logger.warning('Failed to load dataset with id %s' % self.data['id'])\n        if not loadedid:\n            if self._dataset_load_from_hdx(self.data['name']):\n                loadedid = self.data['name']\n        if loadedid:\n            logger.warning('Dataset exists. Updating %s' % loadedid)\n            self._dataset_merge_hdx_update(update_resources=update_resources,\n                                           update_resources_by_name=update_resources_by_name,\n                                           remove_additional_resources=remove_additional_resources,\n                                           create_default_views=create_default_views,\n                                           hxl_update=hxl_update)\n            return\n\n        filestore_resources = list()\n        if self.resources:\n            ignore_fields = ['package_id']\n            for resource in self.resources:\n                resource.check_required_fields(ignore_fields=ignore_fields)\n                if resource.get_file_to_upload():\n                    filestore_resources.append(resource)\n                    resource['url'] = Dataset.temporary_url\n            self.data['resources'] = self._convert_hdxobjects(self.resources)\n        self._save_to_hdx('create', 'name')\n        self._add_filestore_resources(filestore_resources, False, hxl_update)", "response": "Checks if dataset exists in HDX and if so updates it otherwise creates it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches for datasets in HDX and returns them as a list of Dataset objects.", "response": "def search_in_hdx(cls, query='*:*', configuration=None, page_size=1000, **kwargs):\n        # type: (Optional[str], Optional[Configuration], int, Any) -> List['Dataset']\n        \"\"\"Searches for datasets in HDX\n\n        Args:\n            query (Optional[str]): Query (in Solr format). Defaults to '*:*'.\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            page_size (int): Size of page to return. Defaults to 1000.\n            **kwargs: See below\n            fq (string): Any filter queries to apply\n            sort (string): Sorting of the search results. Defaults to 'relevance asc, metadata_modified desc'.\n            rows (int): Number of matching rows to return. Defaults to all datasets (sys.maxsize).\n            start (int): Offset in the complete result for where the set of returned datasets should begin\n            facet (string): Whether to enable faceted results. Default to True.\n            facet.mincount (int): Minimum counts for facet fields should be included in the results\n            facet.limit (int): Maximum number of values the facet fields return (- = unlimited). Defaults to 50.\n            facet.field (List[str]): Fields to facet upon. Default is empty.\n            use_default_schema (bool): Use default package schema instead of custom schema. Defaults to False.\n\n        Returns:\n            List[Dataset]: list of datasets resulting from query\n        \"\"\"\n\n        dataset = Dataset(configuration=configuration)\n        total_rows = kwargs.get('rows', cls.max_int)\n        start = kwargs.get('start', 0)\n        all_datasets = None\n        attempts = 0\n        while attempts < cls.max_attempts and all_datasets is None:  # if the count values vary for multiple calls, then must redo query\n            all_datasets = list()\n            counts = set()\n            for page in range(total_rows // page_size + 1):\n                pagetimespagesize = page * page_size\n                kwargs['start'] = start + pagetimespagesize\n                rows_left = total_rows - pagetimespagesize\n                rows = min(rows_left, page_size)\n                kwargs['rows'] = rows\n                _, result = dataset._read_from_hdx('dataset', query, 'q', Dataset.actions()['search'], **kwargs)\n                datasets = list()\n                if result:\n                    count = result.get('count', None)\n                    if count:\n                        counts.add(count)\n                        no_results = len(result['results'])\n                        for datasetdict in result['results']:\n                            dataset = Dataset(configuration=configuration)\n                            dataset.old_data = dict()\n                            dataset.data = datasetdict\n                            dataset._dataset_create_resources()\n                            datasets.append(dataset)\n                        all_datasets += datasets\n                        if no_results < rows:\n                            break\n                    else:\n                        break\n                else:\n                    logger.debug(result)\n            if all_datasets and len(counts) != 1:  # Make sure counts are all same for multiple calls to HDX\n                all_datasets = None\n                attempts += 1\n            else:\n                ids = [dataset['id'] for dataset in all_datasets]  # check for duplicates (shouldn't happen)\n                if len(ids) != len(set(ids)):\n                    all_datasets = None\n                    attempts += 1\n        if attempts == cls.max_attempts and all_datasets is None:\n            raise HDXError('Maximum attempts reached for searching for datasets!')\n        return all_datasets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_dataset_names(configuration=None, **kwargs):\n        # type: (Optional[Configuration], Any) -> List[str]\n        \"\"\"Get all dataset names in HDX\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            **kwargs: See below\n            limit (int): Number of rows to return. Defaults to all dataset names.\n            offset (int): Offset in the complete result for where the set of returned dataset names should begin\n\n        Returns:\n            List[str]: list of all dataset names in HDX\n        \"\"\"\n        dataset = Dataset(configuration=configuration)\n        dataset['id'] = 'all dataset names'  # only for error message if produced\n        return dataset._write_to_hdx('list', kwargs, 'id')", "response": "Get all dataset names in HDX"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_datasets(cls, configuration=None, page_size=1000, check_duplicates=True, **kwargs):\n        # type: (Optional[Configuration], int, bool, Any) -> List['Dataset']\n        \"\"\"Get all datasets in HDX\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            page_size (int): Size of page to return. Defaults to 1000.\n            check_duplicates (bool): Whether to check for duplicate datasets. Defaults to True.\n            **kwargs: See below\n            limit (int): Number of rows to return. Defaults to all datasets (sys.maxsize)\n            offset (int): Offset in the complete result for where the set of returned datasets should begin\n\n        Returns:\n            List[Dataset]: list of all datasets in HDX\n        \"\"\"\n\n        dataset = Dataset(configuration=configuration)\n        dataset['id'] = 'all datasets'  # only for error message if produced\n        total_rows = kwargs.get('limit', cls.max_int)\n        start = kwargs.get('offset', 0)\n        all_datasets = None\n        attempts = 0\n        while attempts < cls.max_attempts and all_datasets is None:  # if the dataset names vary for multiple calls, then must redo query\n            all_datasets = list()\n            for page in range(total_rows // page_size + 1):\n                pagetimespagesize = page * page_size\n                kwargs['offset'] = start + pagetimespagesize\n                rows_left = total_rows - pagetimespagesize\n                rows = min(rows_left, page_size)\n                kwargs['limit'] = rows\n                result = dataset._write_to_hdx('all', kwargs, 'id')\n                datasets = list()\n                if isinstance(result, list):\n                    no_results = len(result)\n                    if no_results == 0 and page == 0:\n                        all_datasets = None\n                        break\n                    for datasetdict in result:\n                        dataset = Dataset(configuration=configuration)\n                        dataset.old_data = dict()\n                        dataset.data = datasetdict\n                        dataset._dataset_create_resources()\n                        datasets.append(dataset)\n                    all_datasets += datasets\n                    if no_results < rows:\n                        break\n                else:\n                    logger.debug(result)\n            if all_datasets is None:\n                attempts += 1\n            elif check_duplicates:\n                names_list = [dataset['name'] for dataset in all_datasets]\n                names = set(names_list)\n                if len(names_list) != len(names):  # check for duplicates (shouldn't happen)\n                    all_datasets = None\n                    attempts += 1\n                # This check is no longer valid because of showcases being returned by package_list!\n                # elif total_rows == max_int:\n                #     all_names = set(Dataset.get_all_dataset_names())  # check dataset names match package_list\n                #     if names != all_names:\n                #         all_datasets = None\n                #         attempts += 1\n        if attempts == cls.max_attempts and all_datasets is None:\n            raise HDXError('Maximum attempts reached for getting all datasets!')\n        return all_datasets", "response": "Get all datasets in HDX."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all resources from a list of datasets", "response": "def get_all_resources(datasets):\n        # type: (List['Dataset']) -> List[hdx.data.resource.Resource]\n        \"\"\"Get all resources from a list of datasets (such as returned by search)\n\n        Args:\n            datasets (List[Dataset]): list of datasets\n\n        Returns:\n            List[hdx.data.resource.Resource]: list of resources within those datasets\n        \"\"\"\n        resources = []\n        for dataset in datasets:\n            for resource in dataset.get_resources():\n                resources.append(resource)\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets dataset date as datetime. datetime object. For range returns start date.", "response": "def get_dataset_date_as_datetime(self):\n        # type: () -> Optional[datetime]\n        \"\"\"Get dataset date as datetime.datetime object. For range returns start date.\n\n        Returns:\n            Optional[datetime.datetime]: Dataset date in datetime object or None if no date is set\n        \"\"\"\n        dataset_date = self.data.get('dataset_date', None)\n        if dataset_date:\n            if '-' in dataset_date:\n                dataset_date = dataset_date.split('-')[0]\n            return datetime.strptime(dataset_date, '%m/%d/%Y')\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting dataset end date as datetime. datetime object.", "response": "def get_dataset_end_date_as_datetime(self):\n        # type: () -> Optional[datetime]\n        \"\"\"Get dataset end date as datetime.datetime object.\n\n        Returns:\n            Optional[datetime.datetime]: Dataset date in datetime object or None if no date is set\n        \"\"\"\n        dataset_date = self.data.get('dataset_date', None)\n        if dataset_date:\n            if '-' in dataset_date:\n                dataset_date = dataset_date.split('-')[1]\n                return datetime.strptime(dataset_date, '%m/%d/%Y')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_formatted_date(dataset_date, date_format=None):\n        # type: (Optional[datetime], Optional[str]) -> Optional[str]\n        \"\"\"Get supplied dataset date as string in specified format. \n        If no format is supplied, an ISO 8601 string is returned.\n\n        Args:\n            dataset_date (Optional[datetime.datetime]): dataset date in datetime.datetime format \n            date_format (Optional[str]): Date format. None is taken to be ISO 8601. Defaults to None.\n\n        Returns:\n            Optional[str]: Dataset date string or None if no date is set\n        \"\"\"\n        if dataset_date:\n            if date_format:\n                return dataset_date.strftime(date_format)\n            else:\n                return dataset_date.date().isoformat()\n        else:\n            return None", "response": "Returns the supplied dataset date as string in specified format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dataset_date(self, date_format=None):\n        # type: (Optional[str]) -> Optional[str]\n        \"\"\"Get dataset date as string in specified format. For range returns start date.\n        If no format is supplied, an ISO 8601 string is returned.\n\n        Args:\n            date_format (Optional[str]): Date format. None is taken to be ISO 8601. Defaults to None.\n\n        Returns:\n            Optional[str]: Dataset date string or None if no date is set\n        \"\"\"\n        dataset_date = self.get_dataset_date_as_datetime()\n        return self._get_formatted_date(dataset_date, date_format)", "response": "Returns the dataset date as string in specified format. For range returns start date."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dataset_end_date(self, date_format=None):\n        # type: (Optional[str]) -> Optional[str]\n        \"\"\"Get dataset date as string in specified format. For range returns start date.\n        If no format is supplied, an ISO 8601 string is returned.\n\n        Args:\n            date_format (Optional[str]): Date format. None is taken to be ISO 8601. Defaults to None.\n\n        Returns:\n            Optional[str]: Dataset date string or None if no date is set\n        \"\"\"\n        dataset_date = self.get_dataset_end_date_as_datetime()\n        return self._get_formatted_date(dataset_date, date_format)", "response": "Returns the dataset end date as string in specified format. For range returns start date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_dataset_date_from_datetime(self, dataset_date, dataset_end_date=None):\n        # type: (datetime, Optional[datetime]) -> None\n        \"\"\"Set dataset date from datetime.datetime object\n\n        Args:\n            dataset_date (datetime.datetime): Dataset date\n            dataset_end_date (Optional[datetime.datetime]): Dataset end date\n\n        Returns:\n            None\n        \"\"\"\n        start_date = dataset_date.strftime('%m/%d/%Y')\n        if dataset_end_date is None:\n            self.data['dataset_date'] = start_date\n        else:\n            end_date = dataset_end_date.strftime('%m/%d/%Y')\n            self.data['dataset_date'] = '%s-%s' % (start_date, end_date)", "response": "Set dataset date from datetime. datetime object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_date(dataset_date, date_format):\n        # type: (str, Optional[str]) -> datetime\n        \"\"\"Parse dataset date from string using specified format. If no format is supplied, the function will guess.\n        For unambiguous formats, this should be fine.\n\n        Args:\n            dataset_date (str): Dataset date string\n            date_format (Optional[str]): Date format. If None is given, will attempt to guess. Defaults to None.\n\n        Returns:\n            datetime.datetime\n        \"\"\"\n        if date_format is None:\n            try:\n                return parser.parse(dataset_date)\n            except (ValueError, OverflowError) as e:\n                raisefrom(HDXError, 'Invalid dataset date!', e)\n        else:\n            try:\n                return datetime.strptime(dataset_date, date_format)\n            except ValueError as e:\n                raisefrom(HDXError, 'Invalid dataset date!', e)", "response": "Parse dataset date from string using specified format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the dataset date from string using specified format.", "response": "def set_dataset_date(self, dataset_date, dataset_end_date=None, date_format=None):\n        # type: (str, Optional[str], Optional[str]) -> None\n        \"\"\"Set dataset date from string using specified format. If no format is supplied, the function will guess.\n        For unambiguous formats, this should be fine.\n\n        Args:\n            dataset_date (str): Dataset date string\n            dataset_end_date (Optional[str]): Dataset end date string\n            date_format (Optional[str]): Date format. If None is given, will attempt to guess. Defaults to None.\n\n        Returns:\n            None\n        \"\"\"\n        parsed_date = self._parse_date(dataset_date, date_format)\n        if dataset_end_date is None:\n            self.set_dataset_date_from_datetime(parsed_date)\n        else:\n            parsed_end_date = self._parse_date(dataset_end_date, date_format)\n            self.set_dataset_date_from_datetime(parsed_date, parsed_end_date)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_dataset_year_range(self, dataset_year, dataset_end_year=None):\n        # type: (Union[str, int], Optional[Union[str, int]]) -> None\n        \"\"\"Set dataset date as a range from year or start and end year.\n\n        Args:\n            dataset_year (Union[str, int]): Dataset year given as string or int\n            dataset_end_year (Optional[Union[str, int]]): Dataset end year given as string or int\n\n        Returns:\n            None\n        \"\"\"\n        if isinstance(dataset_year, int):\n            dataset_date = '01/01/%d' % dataset_year\n        elif isinstance(dataset_year, str):\n            dataset_date = '01/01/%s' % dataset_year\n        else:\n            raise hdx.data.hdxobject.HDXError('dataset_year has type %s which is not supported!' % type(dataset_year).__name__)\n        if dataset_end_year is None:\n            dataset_end_year = dataset_year\n        if isinstance(dataset_end_year, int):\n            dataset_end_date = '31/12/%d' % dataset_end_year\n        elif isinstance(dataset_end_year, str):\n            dataset_end_date = '31/12/%s' % dataset_end_year\n        else:\n            raise hdx.data.hdxobject.HDXError('dataset_end_year has type %s which is not supported!' % type(dataset_end_year).__name__)\n        self.set_dataset_date(dataset_date, dataset_end_date)", "response": "Set the dataset date as a range from year or start and end year."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the expected update frequency in textual rather than numeric form.", "response": "def get_expected_update_frequency(self):\n        # type: () -> Optional[str]\n        \"\"\"Get expected update frequency (in textual rather than numeric form)\n\n        Returns:\n            Optional[str]: Update frequency in textual form or None if the update frequency doesn't exist or is blank.\n        \"\"\"\n        days = self.data.get('data_update_frequency', None)\n        if days:\n            return Dataset.transform_update_frequency(days)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_expected_update_frequency(self, update_frequency):\n        # type: (str) -> None\n        \"\"\"Set expected update frequency\n\n        Args:\n            update_frequency (str): Update frequency\n\n        Returns:\n            None\n        \"\"\"\n        try:\n            int(update_frequency)\n        except ValueError:\n            update_frequency = Dataset.transform_update_frequency(update_frequency)\n        if not update_frequency:\n            raise HDXError('Invalid update frequency supplied!')\n        self.data['data_update_frequency'] = update_frequency", "response": "Set expected update frequency for the entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_tag(self, tag):\n        # type: (str) -> bool\n        \"\"\"Remove a tag\n\n        Args:\n            tag (str): Tag to remove\n\n        Returns:\n            bool: True if tag removed or False if not\n        \"\"\"\n        return self._remove_hdxobject(self.data.get('tags'), tag, matchon='name')", "response": "Removes a tag from the taglist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_location(self, locations=None):\n        # type: (Optional[List[str]]) -> List[str]\n        \"\"\"Return the dataset's location\n\n        Args:\n            locations (Optional[List[str]]): Valid locations list. Defaults to list downloaded from HDX.\n\n        Returns:\n            List[str]: list of locations or [] if there are none\n        \"\"\"\n        countries = self.data.get('groups', None)\n        if not countries:\n            return list()\n        return [Locations.get_location_from_HDX_code(x['name'], locations=locations,\n                                                     configuration=self.configuration) for x in countries]", "response": "Returns the dataset s location from HDX."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_country_location(self, country, exact=True, locations=None, use_live=True):\n        # type: (str, bool, Optional[List[str]], bool) -> bool\n        \"\"\"Add a country. If an iso 3 code is not provided, value is parsed and if it is a valid country name,\n        converted to an iso 3 code. If the country is already added, it is ignored.\n\n        Args:\n            country (str): Country to add\n            exact (bool): True for exact matching or False to allow fuzzy matching. Defaults to True.\n            locations (Optional[List[str]]): Valid locations list. Defaults to list downloaded from HDX.\n            use_live (bool): Try to get use latest country data from web rather than file in package. Defaults to True.\n\n        Returns:\n            bool: True if country added or False if country already present\n        \"\"\"\n        iso3, match = Country.get_iso3_country_code_fuzzy(country, use_live=use_live)\n        if iso3 is None:\n            raise HDXError('Country: %s - cannot find iso3 code!' % country)\n        return self.add_other_location(iso3, exact=exact,\n                                       alterror='Country: %s with iso3: %s could not be found in HDX list!' %\n                                                (country, iso3),\n                                       locations=locations)", "response": "Add a country location to the HDX list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a list of countries to the HDX database.", "response": "def add_country_locations(self, countries, locations=None, use_live=True):\n        # type: (List[str], Optional[List[str]], bool) -> bool\n        \"\"\"Add a list of countries. If iso 3 codes are not provided, values are parsed and where they are valid country\n        names, converted to iso 3 codes. If any country is already added, it is ignored.\n\n        Args:\n            countries (List[str]): list of countries to add\n            locations (Optional[List[str]]): Valid locations list. Defaults to list downloaded from HDX.\n            use_live (bool): Try to get use latest country data from web rather than file in package. Defaults to True.\n\n        Returns:\n            bool: True if all countries added or False if any already present.\n        \"\"\"\n        allcountriesadded = True\n        for country in countries:\n            if not self.add_country_location(country, locations=locations, use_live=use_live):\n                allcountriesadded = False\n        return allcountriesadded"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd all countries in a region.", "response": "def add_region_location(self, region, locations=None, use_live=True):\n        # type: (str, Optional[List[str]], bool) -> bool\n        \"\"\"Add all countries in a region. If a 3 digit UNStats M49 region code is not provided, value is parsed as a\n        region name. If any country is already added, it is ignored.\n\n        Args:\n            region (str): M49 region, intermediate region or subregion to add\n            locations (Optional[List[str]]): Valid locations list. Defaults to list downloaded from HDX.\n            use_live (bool): Try to get use latest country data from web rather than file in package. Defaults to True.\n\n        Returns:\n            bool: True if all countries in region added or False if any already present.\n        \"\"\"\n        return self.add_country_locations(Country.get_countries_in_region(region, exception=HDXError,\n                                                                          use_live=use_live), locations=locations)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a location which is not a country or region. Value is parsed and compared to existing locations in HDX.", "response": "def add_other_location(self, location, exact=True, alterror=None, locations=None):\n        # type: (str, bool, Optional[str], Optional[List[str]]) -> bool\n        \"\"\"Add a location which is not a country or region. Value is parsed and compared to existing locations in\n        HDX. If the location is already added, it is ignored.\n\n        Args:\n            location (str): Location to add\n            exact (bool): True for exact matching or False to allow fuzzy matching. Defaults to True.\n            alterror (Optional[str]): Alternative error message to builtin if location not found. Defaults to None.\n            locations (Optional[List[str]]): Valid locations list. Defaults to list downloaded from HDX.\n\n        Returns:\n            bool: True if location added or False if location already present\n        \"\"\"\n        hdx_code, match = Locations.get_HDX_code_from_location_partial(location, locations=locations,\n                                                                       configuration=self.configuration)\n        if hdx_code is None or (exact is True and match is False):\n            if alterror is None:\n                raise HDXError('Location: %s - cannot find in HDX!' % location)\n            else:\n                raise HDXError(alterror)\n        groups = self.data.get('groups', None)\n        hdx_code = hdx_code.lower()\n        if groups:\n            if hdx_code in [x['name'] for x in groups]:\n                return False\n        else:\n            groups = list()\n        groups.append({'name': hdx_code})\n        self.data['groups'] = groups\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_location(self, location):\n        # type: (str) -> bool\n        \"\"\"Remove a location. If the location is already added, it is ignored.\n\n        Args:\n            location (str): Location to remove\n\n        Returns:\n            bool: True if location removed or False if not\n        \"\"\"\n        res = self._remove_hdxobject(self.data.get('groups'), location, matchon='name')\n        if not res:\n            res = self._remove_hdxobject(self.data.get('groups'), location.upper(), matchon='name')\n        if not res:\n            res = self._remove_hdxobject(self.data.get('groups'), location.lower(), matchon='name')\n        return res", "response": "Removes a location from the resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the dataset s maintainer.", "response": "def get_maintainer(self):\n        # type: () -> hdx.data.user.User\n        \"\"\"Get the dataset's maintainer.\n\n         Returns:\n             User: Dataset's maintainer\n        \"\"\"\n        return hdx.data.user.User.read_from_hdx(self.data['maintainer'], configuration=self.configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the dataset s maintainer.", "response": "def set_maintainer(self, maintainer):\n        # type: (Union[hdx.data.user.User,Dict,str]) -> None\n        \"\"\"Set the dataset's maintainer.\n\n         Args:\n             maintainer (Union[User,Dict,str]): Either a user id or User metadata from a User object or dictionary.\n         Returns:\n             None\n        \"\"\"\n        if isinstance(maintainer, hdx.data.user.User) or isinstance(maintainer, dict):\n            if 'id' not in maintainer:\n                maintainer = hdx.data.user.User.read_from_hdx(maintainer['name'], configuration=self.configuration)\n            maintainer = maintainer['id']\n        elif not isinstance(maintainer, str):\n            raise HDXError('Type %s cannot be added as a maintainer!' % type(maintainer).__name__)\n        if is_valid_uuid(maintainer) is False:\n            raise HDXError('%s is not a valid user id for a maintainer!' % maintainer)\n        self.data['maintainer'] = maintainer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_organization(self):\n        # type: () -> hdx.data.organization.Organization\n        \"\"\"Get the dataset's organization.\n\n         Returns:\n             Organization: Dataset's organization\n        \"\"\"\n        return hdx.data.organization.Organization.read_from_hdx(self.data['owner_org'], configuration=self.configuration)", "response": "Get the dataset s organization."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_organization(self, organization):\n        # type: (Union[hdx.data.organization.Organization,Dict,str]) -> None\n        \"\"\"Set the dataset's organization.\n\n         Args:\n             organization (Union[Organization,Dict,str]): Either an Organization id or Organization metadata from an Organization object or dictionary.\n         Returns:\n             None\n        \"\"\"\n        if isinstance(organization, hdx.data.organization.Organization) or isinstance(organization, dict):\n            if 'id' not in organization:\n                organization = hdx.data.organization.Organization.read_from_hdx(organization['name'], configuration=self.configuration)\n            organization = organization['id']\n        elif not isinstance(organization, str):\n            raise HDXError('Type %s cannot be added as a organization!' % type(organization).__name__)\n        if is_valid_uuid(organization) is False and organization != 'hdx':\n            raise HDXError('%s is not a valid organization id!' % organization)\n        self.data['owner_org'] = organization", "response": "Set the dataset s organization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget any showcases the dataset is in", "response": "def get_showcases(self):\n        # type: () -> List[hdx.data.showcase.Showcase]\n        \"\"\"Get any showcases the dataset is in\n\n        Returns:\n            List[Showcase]: list of showcases\n        \"\"\"\n        assoc_result, showcases_dicts = self._read_from_hdx('showcase', self.data['id'], fieldname='package_id',\n                                                            action=hdx.data.showcase.Showcase.actions()['list_showcases'])\n        showcases = list()\n        if assoc_result:\n            for showcase_dict in showcases_dicts:\n                showcase = hdx.data.showcase.Showcase(showcase_dict, configuration=self.configuration)\n                showcases.append(showcase)\n        return showcases"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_dataset_showcase_dict(self, showcase):\n        # type: (Union[hdx.data.showcase.Showcase, Dict,str]) -> Dict\n        \"\"\"Get dataset showcase dict\n\n        Args:\n            showcase (Union[Showcase,Dict,str]): Either a showcase id or Showcase metadata from a Showcase object or dictionary\n\n        Returns:\n            dict: dataset showcase dict\n        \"\"\"\n        if isinstance(showcase, hdx.data.showcase.Showcase) or isinstance(showcase, dict):\n            if 'id' not in showcase:\n                showcase = hdx.data.showcase.Showcase.read_from_hdx(showcase['name'])\n            showcase = showcase['id']\n        elif not isinstance(showcase, str):\n            raise HDXError('Type %s cannot be added as a showcase!' % type(showcase).__name__)\n        if is_valid_uuid(showcase) is False:\n            raise HDXError('%s is not a valid showcase id!' % showcase)\n        return {'package_id': self.data['id'], 'showcase_id': showcase}", "response": "Get dataset showcase dict from a showcase object or a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_showcase(self, showcase, showcases_to_check=None):\n        # type: (Union[hdx.data.showcase.Showcase,Dict,str], List[hdx.data.showcase.Showcase]) -> bool\n        \"\"\"Add dataset to showcase\n\n        Args:\n            showcase (Union[Showcase,Dict,str]): Either a showcase id or showcase metadata from a Showcase object or dictionary\n            showcases_to_check (List[Showcase]): list of showcases against which to check existence of showcase. Defaults to showcases containing dataset.\n\n        Returns:\n            bool: True if the showcase was added, False if already present\n        \"\"\"\n        dataset_showcase = self._get_dataset_showcase_dict(showcase)\n        if showcases_to_check is None:\n            showcases_to_check = self.get_showcases()\n        for showcase in showcases_to_check:\n            if dataset_showcase['showcase_id'] == showcase['id']:\n                return False\n        showcase = hdx.data.showcase.Showcase({'id': dataset_showcase['showcase_id']}, configuration=self.configuration)\n        showcase._write_to_hdx('associate', dataset_showcase, 'package_id')\n        return True", "response": "Adds a dataset to a showcase."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_showcases(self, showcases, showcases_to_check=None):\n        # type: (List[Union[hdx.data.showcase.Showcase,Dict,str]], List[hdx.data.showcase.Showcase]) -> bool\n        \"\"\"Add dataset to multiple showcases\n\n        Args:\n            showcases (List[Union[Showcase,Dict,str]]): A list of either showcase ids or showcase metadata from Showcase objects or dictionaries\n            showcases_to_check (List[Showcase]): list of showcases against which to check existence of showcase. Defaults to showcases containing dataset.\n\n        Returns:\n            bool: True if all showcases added or False if any already present\n        \"\"\"\n        if showcases_to_check is None:\n            showcases_to_check = self.get_showcases()\n        allshowcasesadded = True\n        for showcase in showcases:\n            if not self.add_showcase(showcase, showcases_to_check=showcases_to_check):\n                allshowcasesadded = False\n        return allshowcasesadded", "response": "Add dataset to multiple showcases"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_showcase(self, showcase):\n        # type: (Union[hdx.data.showcase.Showcase,Dict,str]) -> None\n        \"\"\"Remove dataset from showcase\n\n        Args:\n            showcase (Union[Showcase,Dict,str]): Either a showcase id string or showcase metadata from a Showcase object or dictionary\n\n        Returns:\n            None\n        \"\"\"\n        dataset_showcase = self._get_dataset_showcase_dict(showcase)\n        showcase = hdx.data.showcase.Showcase({'id': dataset_showcase['showcase_id']}, configuration=self.configuration)\n        showcase._write_to_hdx('disassociate', dataset_showcase, 'package_id')", "response": "Removes dataset from showcase"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the dataset to be of type requestable or notater.", "response": "def set_requestable(self, requestable=True):\n        # type: (bool) -> None\n        \"\"\"Set the dataset to be of type requestable or not\n\n        Args:\n            requestable (bool): Set whether dataset is requestable. Defaults to True.\n\n        Returns:\n            None\n        \"\"\"\n        self.data['is_requestdata_type'] = requestable\n        if requestable:\n            self.data['private'] = False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_filetypes(self):\n        # type: () -> List[str]\n        \"\"\"Return list of filetypes in your data\n\n        Returns:\n            List[str]: List of filetypes\n        \"\"\"\n        if not self.is_requestable():\n            return [resource.get_file_type() for resource in self.get_resources()]\n        return self._get_stringlist_from_commastring('file_types')", "response": "Return list of filetypes in your data\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncleans dataset tags according to tags cleanup spreadsheet and return if any changes occurred", "response": "def clean_dataset_tags(self):\n        # type: () -> Tuple[bool, bool]\n        \"\"\"Clean dataset tags according to tags cleanup spreadsheet and return if any changes occurred\n\n        Returns:\n            Tuple[bool, bool]: Returns (True if tags changed or False if not, True if error or False if not)\n        \"\"\"\n        tags_dict, wildcard_tags = Tags.tagscleanupdicts()\n\n        def delete_tag(tag):\n            logger.info('%s - Deleting tag %s!' % (self.data['name'], tag))\n            return self.remove_tag(tag), False\n\n        def update_tag(tag, final_tags, wording, remove_existing=True):\n            text = '%s - %s: %s -> ' % (self.data['name'], wording, tag)\n            if not final_tags:\n                logger.error('%snothing!' % text)\n                return False, True\n            tags_lower_five = final_tags[:5].lower()\n            if tags_lower_five == 'merge' or tags_lower_five == 'split' or (\n                    ';' not in final_tags and len(final_tags) > 50):\n                logger.error('%s%s - Invalid final tag!' % (text, final_tags))\n                return False, True\n            if remove_existing:\n                self.remove_tag(tag)\n            tags = ', '.join(self.get_tags())\n            if self.add_tags(final_tags.split(';')):\n                logger.info('%s%s! Dataset tags: %s' % (text, final_tags, tags))\n            else:\n                logger.warning(\n                    '%s%s - At least one of the tags already exists! Dataset tags: %s' % (text, final_tags, tags))\n            return True, False\n\n        def do_action(tag, tags_dict_key):\n            whattodo = tags_dict[tags_dict_key]\n            action = whattodo[u'action']\n            final_tags = whattodo[u'final tags (semicolon separated)']\n            if action == u'Delete':\n                changed, error = delete_tag(tag)\n            elif action == u'Merge':\n                changed, error = update_tag(tag, final_tags, 'Merging')\n            elif action == u'Fix spelling':\n                changed, error = update_tag(tag, final_tags, 'Fixing spelling')\n            elif action == u'Non English':\n                changed, error = update_tag(tag, final_tags, 'Anglicising', remove_existing=False)\n            else:\n                changed = False\n                error = False\n            return changed, error\n\n        def process_tag(tag):\n            changed = False\n            error = False\n            if tag in tags_dict.keys():\n                changed, error = do_action(tag, tag)\n            else:\n                for wildcard_tag in wildcard_tags:\n                    if fnmatch.fnmatch(tag, wildcard_tag):\n                        changed, error = do_action(tag, wildcard_tag)\n                        break\n            return changed, error\n\n        anychange = False\n        anyerror = False\n        for tag in self.get_tags():\n            changed, error = process_tag(tag)\n            if changed:\n                anychange = True\n            if error:\n                anyerror = True\n\n        return anychange, anyerror"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the resource that will be used for displaying QuickCharts in dataset preview", "response": "def set_quickchart_resource(self, resource):\n        # type: (Union[hdx.data.resource.Resource,Dict,str,int]) -> bool\n        \"\"\"Set the resource that will be used for displaying QuickCharts in dataset preview\n\n        Args:\n            resource (Union[hdx.data.resource.Resource,Dict,str,int]): Either resource id or name, resource metadata from a Resource object or a dictionary or position\n\n        Returns:\n            bool: Returns True if resource for QuickCharts in dataset preview set or False if not\n        \"\"\"\n        if isinstance(resource, int) and not isinstance(resource, bool):\n            resource = self.get_resources()[resource]\n        if isinstance(resource, hdx.data.resource.Resource) or isinstance(resource, dict):\n            res = resource.get('id')\n            if res is None:\n                resource = resource['name']\n            else:\n                resource = res\n        elif not isinstance(resource, str):\n            raise hdx.data.hdxobject.HDXError('Resource id cannot be found in type %s!' % type(resource).__name__)\n        if is_valid_uuid(resource) is True:\n            search = 'id'\n        else:\n            search = 'name'\n        changed = False\n        for dataset_resource in self.resources:\n            if dataset_resource[search] == resource:\n                dataset_resource.enable_dataset_preview()\n                self.preview_resource()\n                changed = True\n            else:\n                dataset_resource.disable_dataset_preview()\n        return changed"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating default resource views for all resources in dataset", "response": "def create_default_views(self, create_datastore_views=False):\n        # type: (bool) -> None\n        \"\"\"Create default resource views for all resources in dataset\n\n        Args:\n            create_datastore_views (bool): Whether to try to create resource views that point to the datastore\n\n        Returns:\n            None\n        \"\"\"\n        package = deepcopy(self.data)\n        if self.resources:\n            package['resources'] = self._convert_hdxobjects(self.resources)\n\n        data = {'package': package, 'create_datastore_views': create_datastore_views}\n        self._write_to_hdx('create_default_views', data, 'package')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_credentials(self):\n        # type: () -> Optional[Tuple[str, str]]\n        \"\"\"\n        Return HDX site username and password\n\n        Returns:\n            Optional[Tuple[str, str]]: HDX site username and password or None\n\n        \"\"\"\n        site = self.data[self.hdx_site]\n        username = site.get('username')\n        if username:\n            return b64decode(username).decode('utf-8'), b64decode(site['password']).decode('utf-8')\n        else:\n            return None", "response": "Returns username and password of the HDX site if username and password are not provided otherwise None."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the remote CKAN method in the CKAN instance.", "response": "def call_remoteckan(self, *args, **kwargs):\n        # type: (Any, Any) -> Dict\n        \"\"\"\n        Calls the remote CKAN\n\n        Args:\n            *args: Arguments to pass to remote CKAN call_action method\n            **kwargs: Keyword arguments to pass to remote CKAN call_action method\n\n        Returns:\n            Dict: The response from the remote CKAN call_action method\n\n        \"\"\"\n        requests_kwargs = kwargs.get('requests_kwargs', dict())\n        credentials = self._get_credentials()\n        if credentials:\n            requests_kwargs['auth'] = credentials\n        kwargs['requests_kwargs'] = requests_kwargs\n        apikey = kwargs.get('apikey', self.get_api_key())\n        kwargs['apikey'] = apikey\n        return self.remoteckan().call_action(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _environment_variables(**kwargs):\n        # type: (Any) -> Any\n        \"\"\"\n        Overwrite keyword arguments with environment variables\n\n        Args:\n            **kwargs: See below\n            hdx_url (str): HDX url to use. Overrides hdx_site.\n            hdx_site (str): HDX site to use eg. prod, test. Defaults to test.\n            hdx_key (str): Your HDX key. Ignored if hdx_read_only = True.\n\n        Returns:\n            kwargs: Changed keyword arguments\n\n        \"\"\"\n\n        hdx_key = os.getenv('HDX_KEY')\n        if hdx_key is not None:\n            kwargs['hdx_key'] = hdx_key\n        hdx_url = os.getenv('HDX_URL')\n        if hdx_url is not None:\n            kwargs['hdx_url'] = hdx_url\n        else:\n            hdx_site = os.getenv('HDX_SITE')\n            if hdx_site is not None:\n                kwargs['hdx_site'] = hdx_site\n        return kwargs", "response": "Returns a dictionary of keyword arguments with environment variables set in the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_remoteckan(cls, site_url, user_agent=None, user_agent_config_yaml=None, user_agent_lookup=None,\n                          session=None, **kwargs):\n        # type: (str, Optional[str], Optional[str], Optional[str], requests.Session, Any) -> ckanapi.RemoteCKAN\n        \"\"\"\n        Create remote CKAN instance from configuration\n\n        Args:\n            site_url (str): Site url.\n            user_agent (Optional[str]): User agent string. HDXPythonLibrary/X.X.X- is prefixed.\n            user_agent_config_yaml (Optional[str]): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (Optional[str]): Lookup key for YAML. Ignored if user_agent supplied.\n            session (requests.Session): requests Session object to use. Defaults to calling hdx.utilities.session.get_session()\n\n        Returns:\n            ckanapi.RemoteCKAN: Remote CKAN instance\n\n        \"\"\"\n        if not session:\n            session = get_session(user_agent, user_agent_config_yaml, user_agent_lookup, prefix=Configuration.prefix,\n                                  method_whitelist=frozenset(['HEAD', 'TRACE', 'GET', 'POST', 'PUT',\n                                                              'OPTIONS', 'DELETE']), **kwargs)\n            ua = session.headers['User-Agent']\n        else:\n            ua = kwargs.get('full_agent')\n            if not ua:\n                ua = UserAgent.get(user_agent, user_agent_config_yaml, user_agent_lookup, prefix=Configuration.prefix,\n                                   **kwargs)\n        return ckanapi.RemoteCKAN(site_url, user_agent=ua, session=session)", "response": "Create CKAN instance from configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets up remote CKAN from provided CKAN or by creating from configuration Args: remoteckan (Optional[ckanapi.RemoteCKAN]): CKAN instance. Defaults to setting one up from configuration. Returns: None", "response": "def setup_remoteckan(self, remoteckan=None, **kwargs):\n        # type: (Optional[ckanapi.RemoteCKAN], Any) -> None\n        \"\"\"\n        Set up remote CKAN from provided CKAN or by creating from configuration\n\n        Args:\n            remoteckan (Optional[ckanapi.RemoteCKAN]): CKAN instance. Defaults to setting one up from configuration.\n\n        Returns:\n            None\n\n        \"\"\"\n        if remoteckan is None:\n            self._remoteckan = self.create_remoteckan(self.get_hdx_site_url(), full_agent=self.get_user_agent(),\n                                                      **kwargs)\n        else:\n            self._remoteckan = remoteckan"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets up the HDX configuration object.", "response": "def setup(cls, configuration=None, **kwargs):\n        # type: (Optional['Configuration'], Any) -> None\n        \"\"\"\n        Set up the HDX configuration\n\n        Args:\n            configuration (Optional[Configuration]): Configuration instance. Defaults to setting one up from passed arguments.\n            **kwargs: See below\n            user_agent (str): User agent string. HDXPythonLibrary/X.X.X- is prefixed. Must be supplied if remoteckan is not.\n            user_agent_config_yaml (str): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (str): Lookup key for YAML. Ignored if user_agent supplied.\n            hdx_url (str): HDX url to use. Overrides hdx_site.\n            hdx_site (str): HDX site to use eg. prod, test.\n            hdx_read_only (bool): Whether to access HDX in read only mode. Defaults to False.\n            hdx_key (str): Your HDX key. Ignored if hdx_read_only = True.\n            hdx_config_dict (dict): HDX configuration dictionary to use instead of above 3 parameters OR\n            hdx_config_json (str): Path to JSON HDX configuration OR\n            hdx_config_yaml (str): Path to YAML HDX configuration\n            project_config_dict (dict): Project configuration dictionary OR\n            project_config_json (str): Path to JSON Project configuration OR\n            project_config_yaml (str): Path to YAML Project configuration\n            hdx_base_config_dict (dict): HDX base configuration dictionary OR\n            hdx_base_config_json (str): Path to JSON HDX base configuration OR\n            hdx_base_config_yaml (str): Path to YAML HDX base configuration. Defaults to library's internal hdx_base_configuration.yml.\n\n        Returns:\n            None\n\n        \"\"\"\n        if configuration is None:\n            cls._configuration = Configuration(**kwargs)\n        else:\n            cls._configuration = configuration"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating HDX configuration object.", "response": "def _create(cls, configuration=None, remoteckan=None, **kwargs):\n        # type: (Optional['Configuration'], Optional[ckanapi.RemoteCKAN], Any) -> str\n        \"\"\"\n        Create HDX configuration\n\n        Args:\n            configuration (Optional[Configuration]): Configuration instance. Defaults to setting one up from passed arguments.\n            remoteckan (Optional[ckanapi.RemoteCKAN]): CKAN instance. Defaults to setting one up from configuration.\n            **kwargs: See below\n            user_agent (str): User agent string. HDXPythonLibrary/X.X.X- is prefixed. Must be supplied if remoteckan is not.\n            user_agent_config_yaml (str): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (str): Lookup key for YAML. Ignored if user_agent supplied.\n            hdx_url (str): HDX url to use. Overrides hdx_site.\n            hdx_site (str): HDX site to use eg. prod, test.\n            hdx_read_only (bool): Whether to access HDX in read only mode. Defaults to False.\n            hdx_key (str): Your HDX key. Ignored if hdx_read_only = True.\n            hdx_config_dict (dict): HDX configuration dictionary to use instead of above 3 parameters OR\n            hdx_config_json (str): Path to JSON HDX configuration OR\n            hdx_config_yaml (str): Path to YAML HDX configuration\n            project_config_dict (dict): Project configuration dictionary OR\n            project_config_json (str): Path to JSON Project configuration OR\n            project_config_yaml (str): Path to YAML Project configuration\n            hdx_base_config_dict (dict): HDX base configuration dictionary OR\n            hdx_base_config_json (str): Path to JSON HDX base configuration OR\n            hdx_base_config_yaml (str): Path to YAML HDX base configuration. Defaults to library's internal hdx_base_configuration.yml.\n\n        Returns:\n            str: HDX site url\n\n        \"\"\"\n        kwargs = cls._environment_variables(**kwargs)\n        cls.setup(configuration, **kwargs)\n        cls._configuration.setup_remoteckan(remoteckan, **kwargs)\n        return cls._configuration.get_hdx_site_url()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, configuration=None, remoteckan=None, **kwargs):\n        # type: (Optional['Configuration'], Optional[ckanapi.RemoteCKAN], Any) -> str\n        \"\"\"\n        Create HDX configuration. Can only be called once (will raise an error if called more than once).\n\n        Args:\n            configuration (Optional[Configuration]): Configuration instance. Defaults to setting one up from passed arguments.\n            remoteckan (Optional[ckanapi.RemoteCKAN]): CKAN instance. Defaults to setting one up from configuration.\n            **kwargs: See below\n            user_agent (str): User agent string. HDXPythonLibrary/X.X.X- is prefixed. Must be supplied if remoteckan is not.\n            user_agent_config_yaml (str): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (str): Lookup key for YAML. Ignored if user_agent supplied.\n            hdx_url (str): HDX url to use. Overrides hdx_site.\n            hdx_site (str): HDX site to use eg. prod, test.\n            hdx_read_only (bool): Whether to access HDX in read only mode. Defaults to False.\n            hdx_key (str): Your HDX key. Ignored if hdx_read_only = True.\n            hdx_config_dict (dict): HDX configuration dictionary to use instead of above 3 parameters OR\n            hdx_config_json (str): Path to JSON HDX configuration OR\n            hdx_config_yaml (str): Path to YAML HDX configuration\n            project_config_dict (dict): Project configuration dictionary OR\n            project_config_json (str): Path to JSON Project configuration OR\n            project_config_yaml (str): Path to YAML Project configuration\n            hdx_base_config_dict (dict): HDX base configuration dictionary OR\n            hdx_base_config_json (str): Path to JSON HDX base configuration OR\n            hdx_base_config_yaml (str): Path to YAML HDX base configuration. Defaults to library's internal hdx_base_configuration.yml.\n\n        Returns:\n            str: HDX site url\n\n        \"\"\"\n        if cls._configuration is not None:\n            raise ConfigurationError('Configuration already created!')\n        return cls._create(configuration=configuration, remoteckan=remoteckan, **kwargs)", "response": "Create HDX configuration object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a dictionary into a string with assignments", "response": "def kwargs_to_variable_assignment(kwargs: dict, value_representation=repr,\n                                  assignment_operator: str = ' = ',\n                                  statement_separator: str = '\\n',\n                                  statement_per_line: bool = False) -> str:\n    \"\"\"\n    Convert a dictionary into a string with assignments\n\n    Each assignment is constructed based on:\n    key assignment_operator value_representation(value) statement_separator,\n    where key and value are the key and value of the dictionary.\n    Moreover one can seprate the assignment statements by new lines.\n\n    Parameters\n    ----------\n    kwargs : dict\n\n    assignment_operator: str, optional:\n        Assignment operator (\" = \" in python)\n    value_representation: str, optinal\n        How to represent the value in the assignments (repr function in python)\n    statement_separator : str, optional:\n        Statement separator (new line in python)\n    statement_per_line: bool, optional\n        Insert each statement on a different line\n\n    Returns\n    -------\n    str\n        All the assignemnts.\n\n    >>> kwargs_to_variable_assignment({'a': 2, 'b': \"abc\"})\n    \"a = 2\\\\nb = 'abc'\\\\n\"\n    >>> kwargs_to_variable_assignment({'a':2 ,'b': \"abc\"}, statement_per_line=True)\n    \"a = 2\\\\n\\\\nb = 'abc'\\\\n\"\n    >>> kwargs_to_variable_assignment({'a': 2})\n    'a = 2\\\\n'\n    >>> kwargs_to_variable_assignment({'a': 2}, statement_per_line=True)\n    'a = 2\\\\n'\n    \"\"\"\n    code = []\n    join_str = '\\n' if statement_per_line else ''\n    for key, value in kwargs.items():\n        code.append(key + assignment_operator +\n                    value_representation(value)+statement_separator)\n    return join_str.join(code)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode_json(json_input: Union[str, None] = None):\n    if json_input is None:\n        return {}\n    else:\n        if isinstance(json_input, str) is False:\n            raise TypeError()\n        elif json_input[-5:] == \".json\":\n            with open(json_input) as f:\n                decoded_json = json.load(f)\n        else:\n            decoded_json = json.loads(json_input)\n    return decoded_json", "response": "Simple wrapper of json. load and json. loads."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if an object is json serialisable.", "response": "def is_jsonable(obj) -> bool:\n    \"\"\"\n    Check if an object is jsonable.\n\n    An object is jsonable if it is json serialisable and by loading its json representation the same object is recovered.\n    Parameters\n    ----------\n    obj : \n        Python object\n\n    Returns\n    -------\n    bool\n\n    >>> is_jsonable([1,2,3])\n    True\n    >>> is_jsonable((1,2,3))\n    False\n    >>> is_jsonable({'a':True,'b':1,'c':None})\n    True\n    \"\"\"\n    try:\n        return obj==json.loads(json.dumps(obj))\n    except TypeError:\n        return False\n    except:\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if an expresion can be literal_eval.", "response": "def is_literal_eval(node_or_string) -> tuple:\n    \"\"\"\n    Check if an expresion can be literal_eval.\n\n    ----------\n    node_or_string : \n        Input\n\n    Returns\n    -------\n    tuple\n        (bool,python object)\n\n        \n        If it can be literal_eval the python object is returned. Otherwise None it is returned.\n        \n    >>> is_literal_eval('[1,2,3]')\n    (True, [1, 2, 3])\n    >>> is_literal_eval('a')\n    (False, None)\n    \"\"\"\n    try:\n        obj=ast.literal_eval(node_or_string)\n        return (True, obj)\n    except:\n        return (False, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the duplicates in a list.", "response": "def find_duplicates(l: list) -> set:\n    \"\"\"\n    Return the duplicates in a list.\n\n    The function relies on\n    https://stackoverflow.com/questions/9835762/find-and-list-duplicates-in-a-list .\n    Parameters\n    ----------\n    l : list\n        Name\n\n    Returns\n    -------\n    set\n        Duplicated values\n\n    >>> find_duplicates([1,2,3])\n    set()\n    >>> find_duplicates([1,2,1])\n    {1}\n    \"\"\"\n    return set([x for x in l if l.count(x) > 1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sort_dict(d: dict, by: str = 'key',\n              allow_duplicates: bool = True) -> collections.OrderedDict:\n    \"\"\"\n    Sort a dictionary by key or value.\n\n    The function relies on\n    https://docs.python.org/3/library/collections.html#collections.OrderedDict .\n    The dulicated are determined based on\n    https://stackoverflow.com/questions/9835762/find-and-list-duplicates-in-a-list .\n    Parameters\n    ----------\n    d : dict\n        Input dictionary\n    by : ['key','value'], optional\n        By what to sort the input dictionary\n    allow_duplicates : bool, optional\n        Flag to indicate if the duplicates are allowed.\n    Returns\n    -------\n    collections.OrderedDict\n        Sorted dictionary.\n\n    >>> sort_dict({2: 3, 1: 2, 3: 1})\n    OrderedDict([(1, 2), (2, 3), (3, 1)])\n    >>> sort_dict({2: 3, 1: 2, 3: 1}, by='value')\n    OrderedDict([(3, 1), (1, 2), (2, 3)])\n    >>> sort_dict({'2': 3, '1': 2}, by='value')\n    OrderedDict([('1', 2), ('2', 3)])\n    >>> sort_dict({2: 1, 1: 2, 3: 1}, by='value', allow_duplicates=False)\n    Traceback (most recent call last):\n        ...\n    ValueError: There are duplicates in the values: {1}\n    >>> sort_dict({1:1,2:3},by=True)\n    Traceback (most recent call last):\n        ...\n    ValueError: by can be 'key' or 'value'.\n    \"\"\"\n    if by == 'key':\n        i = 0\n    elif by == 'value':\n        values = list(d.values())\n        if len(values) != len(set(values)) and not allow_duplicates:\n            duplicates = find_duplicates(values)\n            raise ValueError(\"There are duplicates in the values: {}\".format(duplicates))\n        i = 1\n    else:\n        raise ValueError(\"by can be 'key' or 'value'.\")\n\n    return collections.OrderedDict(sorted(d.items(), key=lambda t: t[i]))", "response": "Sort a dictionary by key or value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngrouping a dictionary by values.", "response": "def group_dict_by_value(d: dict) -> dict:\n    \"\"\"\n    Group a dictionary by values.\n\n\n    Parameters\n    ----------\n    d : dict\n        Input dictionary\n\n    Returns\n    -------\n    dict\n        Output dictionary. The keys are the values of the initial dictionary\n        and the values ae given by a list of keys corresponding to the value.\n\n    >>> group_dict_by_value({2: 3, 1: 2, 3: 1})\n    {3: [2], 2: [1], 1: [3]}\n    >>> group_dict_by_value({2: 3, 1: 2, 3: 1, 10:1, 12: 3})\n    {3: [2, 12], 2: [1], 1: [3, 10]}\n    \"\"\"\n    d_out = {}\n    for k, v in d.items():\n        if v in d_out:\n            d_out[v].append(k)\n        else:\n            d_out[v] = [k]\n    return d_out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef variable_status(code: str,\n                    exclude_variable: Union[set, None] = None,\n                    jsonable_parameter: bool = True) -> tuple:\n    \"\"\"\n    Find the possible parameters and \"global\" variables from a python code.\n\n    This is achieved by parsing the abstract syntax tree.\n\n    Parameters\n    ----------\n    code : str\n        Input code as string.\n    exclude_variable : set, None, optional\n        Variable to exclude.\n    jsonable_parameter: bool, True, optional\n        Consider only jsonable parameter\n\n    Returns\n    -------\n    tuple\n        (a set of possible parameter, a set of parameter to exclude, a dictionary of possible parameter )\n\n        A variable is a possible parameter if 1) it is not in the input exclude_variable,\n        2) the code contains only assignments, and 3) it is used only to bound objects.\n\n        The set of parameter to exclude is the union of the input exclude_variable and all names that looks like a global variable.\n        The dictionary of possible parameter {parameter name, parameter value} is available only if jsonable_parameter is True. \n\n\n\n\n    >>> variable_status(\"a=3\")\n    ({'a'}, {'a'}, {'a': 3})\n    >>> variable_status(\"a=3\",jsonable_parameter=False)\n    ({'a'}, {'a'}, {})\n    >>> variable_status(\"a += 1\")\n    (set(), {'a'}, {})\n    >>> variable_status(\"def f(x,y=3):\\\\n\\\\t pass\")\n    (set(), {'f'}, {})\n    >>> variable_status(\"class C(A):\\\\n\\\\t pass\")\n    (set(), {'C'}, {})\n    >>> variable_status(\"import f\")\n    (set(), {'f'}, {})\n    >>> variable_status(\"import f as g\")\n    (set(), {'g'}, {})\n    >>> variable_status(\"from X import f\")\n    (set(), {'f'}, {})\n    >>> variable_status(\"from X import f as g\")\n    (set(), {'g'}, {})\n    \"\"\"\n    if exclude_variable is None:\n        exclude_variable = set()\n    else:\n        exclude_variable = copy.deepcopy(exclude_variable)\n    root = ast.parse(code)\n    store_variable_name = set()\n    assign_only = True\n    dict_parameter={}\n\n    for node in ast.iter_child_nodes(root):\n        if isinstance(node, ast.Assign):\n            for assign_node in ast.walk(node):\n                if isinstance(assign_node, ast.Name):\n\n                    if isinstance(assign_node.ctx, ast.Store):\n                        if jsonable_parameter is False:\n                            store_variable_name |= {assign_node.id}\n                    else:\n                        exclude_variable |= {assign_node.id}\n\n            _is_literal_eval,_value=is_literal_eval(node.value)\n\n            if jsonable_parameter is True:\n                for assign_node in ast.iter_child_nodes(node):\n                    if isinstance(assign_node, ast.Tuple):\n                        i=0\n                        for assign_tuple_node in ast.iter_child_nodes(assign_node):\n                            if isinstance(assign_tuple_node, ast.Name):\n\n                                if isinstance(_value,(collections.Iterable)) and is_jsonable(_value[i]) and _is_literal_eval:\n                                    dict_parameter[assign_tuple_node.id]=_value[i]                                \n                                    store_variable_name |= {assign_tuple_node.id} \n                                else:\n                                    exclude_variable |= {assign_tuple_node.id}\n                                i += 1\n                    else:\n                        if isinstance(assign_node, ast.Name):\n                            if is_jsonable(_value) and _is_literal_eval:\n                                dict_parameter[assign_node.id]=_value\n                                store_variable_name |= {assign_node.id} \n                            else:\n                                exclude_variable |= {assign_node.id}\n\n        elif isinstance(node, ast.AugAssign):\n            for assign_node in ast.walk(node):\n                if isinstance(assign_node, ast.Name):\n                    exclude_variable |= {assign_node.id}\n        # class and function\n        elif isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n            assign_only = False\n            exclude_variable |= {node.name}\n        # import\n        elif isinstance(node, ast.Import):\n            assign_only = False\n            for node1 in ast.iter_child_nodes(node):\n                if node1.asname is not None:\n                    exclude_variable |= {node1.asname}\n                else:\n                    exclude_variable |= {node1.name}\n        # import from\n        elif isinstance(node, ast.ImportFrom):\n            assign_only = False\n            for node1 in ast.iter_child_nodes(node):\n                if node1.asname is not None:\n                    exclude_variable |= {node1.asname}\n                else:\n                    exclude_variable |= {node1.name}\n        else:\n            assign_only = False\n    if assign_only is True:\n        possible_parameter = store_variable_name-exclude_variable\n        if jsonable_parameter is True:\n            dict_parameter = {k:dict_parameter[k] for k in possible_parameter}\n        return (possible_parameter, store_variable_name | exclude_variable, dict_parameter)\n    return set(), store_variable_name | exclude_variable, {}", "response": "Return the list of possible parameters and global variables from a python code."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nincrements the name where the incremental part is given by parameters.", "response": "def increment_name(name: str, start_marker: str = \" (\",\n                   end_marker: str = \")\") -> str:\n    \"\"\"\n    Increment the name where the incremental part is given by parameters.\n\n    Parameters\n    ----------\n    name : str, nbformat.notebooknode.NotebookNode\n        Name\n    start_marker : str\n        The marker used before the incremental\n    end_marker : str\n        The marker after the incrementa\n\n    Returns\n    -------\n    str\n        Incremented name.\n\n    >>> increment_name('abc')\n    'abc (1)'\n    >>> increment_name('abc(1)')\n    'abc(1) (1)'\n    >>> increment_name('abc (123)')\n    'abc (124)'\n    >>> increment_name('abc-1',start_marker='-',end_marker='')\n    'abc-2'\n    >>> increment_name('abc[2]',start_marker='[',end_marker=']')\n    'abc[3]'\n    >>> increment_name('abc1',start_marker='',end_marker='')\n    Traceback (most recent call last):\n        ...\n    ValueError: start_marker can not be the empty string.\n    \"\"\"\n    if start_marker == '':\n        raise ValueError(\"start_marker can not be the empty string.\")\n    a = name\n    start = len(a)-a[::-1].find(start_marker[::-1])\n\n    if (a[len(a)-len(end_marker):len(a)] == end_marker\n            and start < (len(a)-len(end_marker))\n            and a[start-len(start_marker):start] == start_marker\n            and a[start:len(a)-len(end_marker)].isdigit()):\n\n        old_int = int(a[start:len(a)-len(end_marker)])\n        new_int = old_int+1\n        new_name = a[:start]+str(new_int)+end_marker\n    else:\n        new_name = a+start_marker+'1'+end_marker\n    return new_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_from_hdx(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> Optional['ResourceView']\n        \"\"\"Reads the resource view given by identifier from HDX and returns ResourceView object\n\n        Args:\n            identifier (str): Identifier of resource view\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[ResourceView]: ResourceView object if successful read, None if not\n        \"\"\"\n\n        resourceview = ResourceView(configuration=configuration)\n        result = resourceview._load_from_hdx('resource view', identifier)\n        if result:\n            return resourceview\n        return None", "response": "Reads the resource view given by identifier from HDX and returns ResourceView object if successful."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_for_resource(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> List['ResourceView']\n        \"\"\"Read all resource views for a resource given by identifier from HDX and returns list of ResourceView objects\n\n        Args:\n            identifier (str): Identifier of resource\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            List[ResourceView]: List of ResourceView objects\n        \"\"\"\n\n        resourceview = ResourceView(configuration=configuration)\n        success, result = resourceview._read_from_hdx('resource view', identifier, 'id', ResourceView.actions()['list'])\n        resourceviews = list()\n        if success:\n            for resourceviewdict in result:\n                resourceview = ResourceView(resourceviewdict, configuration=configuration)\n                resourceviews.append(resourceview)\n        return resourceviews", "response": "Read all resource views for a resource given by identifier from HDX and return list of ResourceView objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if resource view exists in HDX and if so update resource view", "response": "def _update_resource_view(self, log=False):\n        # type: () -> bool\n        \"\"\"Check if resource view exists in HDX and if so, update resource view\n\n        Returns:\n            bool: True if updated and False if not\n        \"\"\"\n        update = False\n        if 'id' in self.data and self._load_from_hdx('resource view', self.data['id']):\n            update = True\n        else:\n            if 'resource_id' in self.data:\n                resource_views = self.get_all_for_resource(self.data['resource_id'])\n                for resource_view in resource_views:\n                    if self.data['title'] == resource_view['title']:\n                        self.old_data = self.data\n                        self.data = resource_view.data\n                        update = True\n                        break\n        if update:\n            if log:\n                logger.warning('resource view exists. Updating %s' % self.data['id'])\n            self._merge_hdx_update('resource view', 'id')\n        return update"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_in_hdx(self):\n        # type: () -> None\n        \"\"\"Check if resource view exists in HDX and if so, update it, otherwise create resource view\n\n        Returns:\n            None\n        \"\"\"\n        self.check_required_fields()\n        if not self._update_resource_view(log=True):\n            self._save_to_hdx('create', 'title')", "response": "Check if resource view exists in HDX and if so create it otherwise create resource view\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies all fields except id resource_id and package_id from another resource view.", "response": "def copy(self, resource_view):\n        # type: (Union[ResourceView,Dict,str]) -> None\n        \"\"\"Copies all fields except id, resource_id and package_id from another resource view.\n\n        Args:\n            resource_view (Union[ResourceView,Dict,str]): Either a resource view id or resource view metadata either from a ResourceView object or a dictionary\n\n        Returns:\n            None\n        \"\"\"\n        if isinstance(resource_view, str):\n            if is_valid_uuid(resource_view) is False:\n                raise HDXError('%s is not a valid resource view id!' % resource_view)\n            resource_view = ResourceView.read_from_hdx(resource_view)\n        if not isinstance(resource_view, dict) and not isinstance(resource_view, ResourceView):\n            raise HDXError('%s is not a valid resource view!' % resource_view)\n        for key in resource_view:\n            if key not in ('id', 'resource_id', 'package_id'):\n                self.data[key] = resource_view[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tagscleanupdicts(configuration=None, url=None, keycolumn=5, failchained=True):\n        # type: (Optional[Configuration], Optional[str], int, bool) -> Tuple[Dict,List]\n        \"\"\"\n        Get tags cleanup dictionaries\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            url (Optional[str]): Url of tags cleanup spreadsheet. Defaults to None (internal configuration parameter).\n            keycolumn (int): Column number of tag column in spreadsheet. Defaults to 5.\n            failchained (bool): Fail if chained rules found. Defaults to True.\n\n        Returns:\n            Tuple[Dict,List]: Returns (Tags dictionary, Wildcard tags list)\n        \"\"\"\n        if not Tags._tags_dict:\n            if configuration is None:\n                configuration = Configuration.read()\n            with Download(full_agent=configuration.get_user_agent()) as downloader:\n                if url is None:\n                    url = configuration['tags_cleanup_url']\n                Tags._tags_dict = downloader.download_tabular_rows_as_dicts(url, keycolumn=keycolumn)\n                keys = Tags._tags_dict.keys()\n                chainerror = False\n                for i, tag in enumerate(keys):\n                    whattodo = Tags._tags_dict[tag]\n                    action = whattodo[u'action']\n                    final_tags = whattodo[u'final tags (semicolon separated)']\n                    for final_tag in final_tags.split(';'):\n                        if final_tag in keys:\n                            index = list(keys).index(final_tag)\n                            if index != i:\n                                whattodo2 = Tags._tags_dict[final_tag]\n                                action2 = whattodo2[u'action']\n                                if action2 != 'OK' and action2 != 'Other':\n                                    final_tags2 = whattodo2[u'final tags (semicolon separated)']\n                                    if final_tag not in final_tags2.split(';'):\n                                        chainerror = True\n                                        if failchained:\n                                            logger.error('Chained rules: %s (%s -> %s) | %s (%s -> %s)' %\n                                                         (action, tag, final_tags, action2, final_tag, final_tags2))\n\n                if failchained and chainerror:\n                    raise ChainRuleError('Chained rules for tags detected!')\n                Tags._wildcard_tags = list()\n                for tag in Tags._tags_dict:\n                    if '*' in tag:\n                        Tags._wildcard_tags.append(tag)\n        return Tags._tags_dict, Tags._wildcard_tags", "response": "Get tags cleanup dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_from_hdx(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> Optional['User']\n        \"\"\"Reads the user given by identifier from HDX and returns User object\n\n        Args:\n            identifier (str): Identifier of user\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[User]: User object if successful read, None if not\n        \"\"\"\n\n        user = User(configuration=configuration)\n        result = user._load_from_hdx('user', identifier)\n        if result:\n            return user\n        return None", "response": "Reads the user given by identifier from HDX and returns User object if successful."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_in_hdx(self):\n        # type: () -> None\n        \"\"\"Check if user exists in HDX and if so, update user\n\n        Returns:\n            None\n        \"\"\"\n        capacity = self.data.get('capacity')\n        if capacity is not None:\n            del self.data['capacity']  # remove capacity (which comes from users from Organization)\n        self._update_in_hdx('user', 'id')\n        if capacity is not None:\n            self.data['capacity'] = capacity", "response": "Check if user exists in HDX and if so update user\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if user exists in HDX and if so create it otherwise create user", "response": "def create_in_hdx(self):\n        # type: () -> None\n        \"\"\"Check if user exists in HDX and if so, update it, otherwise create user\n\n        Returns:\n            None\n        \"\"\"\n        capacity = self.data.get('capacity')\n        if capacity is not None:\n            del self.data['capacity']\n        self._create_in_hdx('user', 'id', 'name')\n        if capacity is not None:\n            self.data['capacity'] = capacity"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef email(self, subject, text_body, html_body=None, sender=None, **kwargs):\n        # type: (str, str, Optional[str], Optional[str], Any) -> None\n        \"\"\"Emails a user.\n\n        Args:\n            subject (str): Email subject\n            text_body (str): Plain text email body\n            html_body (str): HTML email body\n            sender (Optional[str]): Email sender. Defaults to SMTP username.\n            **kwargs: See below\n            mail_options (List): Mail options (see smtplib documentation)\n            rcpt_options (List): Recipient options (see smtplib documentation)\n\n        Returns:\n            None\n        \"\"\"\n        self.configuration.emailer().send([self.data['email']], subject, text_body, html_body=html_body, sender=sender,\n                                          **kwargs)", "response": "Emails a user.\n\n        Args:\n            subject (str): Email subject\n            text_body (str): Plain text email body\n            html_body (str): HTML email body\n            sender (Optional[str]): Email sender. Defaults to SMTP username.\n            **kwargs: See below\n            mail_options (List): Mail options (see smtplib documentation)\n            rcpt_options (List): Recipient options (see smtplib documentation)\n\n        Returns:\n            None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all users in HDX", "response": "def get_all_users(configuration=None, **kwargs):\n        # type: (Optional[Configuration], Any) -> List['User']\n        \"\"\"Get all users in HDX\n\n        Args:\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n            **kwargs: See below\n            q (str): Restrict to names containing a string. Defaults to all users.\n            order_by (str): Field by which to sort - any user field or edits (number_of_edits). Defaults to 'name'.\n\n        Returns:\n            List[User]: List of all users in HDX\n        \"\"\"\n        user = User(configuration=configuration)\n        user['id'] = 'all users'  # only for error message if produced\n        result = user._write_to_hdx('list', kwargs, 'id')\n        users = list()\n        if result:\n            for userdict in result:\n                user = User(userdict, configuration=configuration)\n                users.append(user)\n        else:\n            logger.debug(result)\n        return users"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef email_users(users, subject, text_body, html_body=None, sender=None, configuration=None, **kwargs):\n        # type: (List['User'], str, str, Optional[str], Optional[str], Optional[Configuration], Any) -> None\n        \"\"\"Email a list of users\n\n        Args:\n            users (List[User]): List of users\n            subject (str): Email subject\n            text_body (str): Plain text email body\n            html_body (str): HTML email body\n            sender (Optional[str]): Email sender. Defaults to SMTP username.\n            configuration (Optional[Configuration]): HDX configuration. Defaults to configuration of first user in list.\n            **kwargs: See below\n            mail_options (List): Mail options (see smtplib documentation)\n            rcpt_options (List): Recipient options (see smtplib documentation)\n\n        Returns:\n            None\n        \"\"\"\n        if not users:\n            raise ValueError('No users supplied')\n        recipients = list()\n        for user in users:\n            recipients.append(user.data['email'])\n        if configuration is None:\n            configuration = users[0].configuration\n        configuration.emailer().send(recipients, subject, text_body, html_body=html_body, sender=sender, **kwargs)", "response": "Email a list of users to the HDX server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_organizations(self, permission='read'):\n        # type: (str) -> List['Organization']\n        \"\"\"Get organizations in HDX that this user is a member of.\n\n        Args:\n            permission (str): Permission to check for. Defaults to 'read'.\n\n        Returns:\n            List[Organization]: List of organizations in HDX that this user is a member of\n        \"\"\"\n        success, result = self._read_from_hdx('user', self.data['name'], 'id', self.actions()['listorgs'],\n                                              permission=permission)\n        organizations = list()\n        if success:\n            for organizationdict in result:\n                organization = hdx.data.organization.Organization.read_from_hdx(organizationdict['id'])\n                organizations.append(organization)\n        return organizations", "response": "Get organizations in HDX that this user is a member of."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying loading the config from the given path. If no path is specified the default config is returned.", "response": "def get_lint_config(config_path=None):\n    \"\"\" Tries loading the config from the given path. If no path is specified, the default config path\n    is tried, and if that is not specified, we the default config is returned. \"\"\"\n    # config path specified\n    if config_path:\n        config = LintConfig.load_from_file(config_path)\n        click.echo(\"Using config from {0}\".format(config_path))\n    # default config path\n    elif os.path.exists(DEFAULT_CONFIG_FILE):\n        config = LintConfig.load_from_file(DEFAULT_CONFIG_FILE)\n        click.echo(\"Using config from {0}\".format(DEFAULT_CONFIG_FILE))\n    # no config file\n    else:\n        config = LintConfig()\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    # Read configuration from the config file if present, else fall back to\n    # command line options\n    if args.config:\n        config = config_file_parser.get_configuration(args.config)\n        access_key_id = config['access-key-id']\n        secret_access_key = config['secret-access-key']\n        region = config['region']\n    else:\n        access_key_id = args.access_key_id\n        secret_access_key = args.secret_access_key\n        region = args.region\n\n    if args.daemon:\n        pid_file = '/tmp/automatic-ebs-snapshots.pid'\n        daemon = AutoEBSDaemon(pid_file)\n\n        if args.daemon == 'start':\n            daemon.start()\n\n        elif args.daemon == 'stop':\n            daemon.stop()\n            sys.exit(0)\n\n        elif args.daemon == 'restart':\n            daemon.restart()\n\n        elif args.daemon in ['foreground', 'fg']:\n            daemon.run()\n\n        else:\n            print 'Valid options for --daemon are start, stop and restart'\n            sys.exit(1)\n\n    # Connect to AWS\n    connection = connection_manager.connect_to_ec2(\n        region, access_key_id, secret_access_key)\n\n    if args.watch:\n        volume_manager.watch(\n            connection,\n            args.watch,\n            args.interval,\n            args.retention)\n\n    if args.unwatch:\n        volume_manager.unwatch(connection, args.unwatch)\n\n    if args.watch_file:\n        volume_manager.watch_from_file(connection, args.watch_file)\n\n    if args.unwatch_file:\n        volume_manager.unwatch_from_file(connection, args.unwatch_file)\n\n    if args.snapshots:\n        volume_manager.list_snapshots(connection, args.snapshots)\n\n    if args.list:\n        volume_manager.list(connection)\n\n    if args.run:\n        snapshot_manager.run(connection)", "response": "Main function for the main function of the main function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, check_interval=300):\n        while True:\n            # Read configuration from the config file if present, else fall\n            # back to command line options\n            if args.config:\n                config = config_file_parser.get_configuration(args.config)\n                access_key_id = config['access-key-id']\n                secret_access_key = config['secret-access-key']\n                region = config['region']\n            else:\n                access_key_id = args.access_key_id\n                secret_access_key = args.secret_access_key\n                region = args.region\n\n            # Connect to AWS\n            connection = connection_manager.connect_to_ec2(\n                region, access_key_id, secret_access_key)\n\n            snapshot_manager.run(connection)\n\n            logger.info('Sleeping {} seconds until next check'.format(\n                check_interval))\n            time.sleep(check_interval)", "response": "Run the daemon daemon"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the lines in a given markdown string and applies all the enabled line rules to each line.", "response": "def _apply_line_rules(self, markdown_string):\n        \"\"\" Iterates over the lines in a given markdown string and applies all the enabled line rules to each line \"\"\"\n        all_violations = []\n        lines = markdown_string.split(\"\\n\")\n        line_rules = self.line_rules\n        line_nr = 1\n        ignoring = False\n        for line in lines:\n            if ignoring:\n                if line.strip() == '<!-- markdownlint:enable -->':\n                    ignoring = False\n            else:\n                if line.strip() == '<!-- markdownlint:disable -->':\n                    ignoring = True\n                    continue\n\n                for rule in line_rules:\n                    violation = rule.validate(line)\n                    if violation:\n                        violation.line_nr = line_nr\n                        all_violations.append(violation)\n            line_nr += 1\n        return all_violations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlint a list of files.", "response": "def lint_files(self, files):\n        \"\"\" Lints a list of files.\n        :param files: list of files to lint\n        :return: a list of violations found in the files\n        \"\"\"\n        all_violations = []\n        for filename in files:\n            with open(filename, 'r') as f:\n                content = f.read()\n                violations = self.lint(content)\n                all_violations.extend(violations)\n                for e in violations:\n                    print(\"{0}:{1}: {2} {3}\".format(filename, e.line_nr, e.rule_id, e.message))\n        return len(all_violations)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the values from a byte stream.", "response": "def ReadFrom(self, byte_stream):\n    \"\"\"Read values from a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n\n    Returns:\n      tuple[object, ...]: values copies from the byte stream.\n\n    Raises:\n      IOError: if byte stream cannot be read.\n      OSError: if byte stream cannot be read.\n    \"\"\"\n    try:\n      return self._struct.unpack_from(byte_stream)\n    except (TypeError, struct.error) as exception:\n      raise IOError('Unable to read byte stream with error: {0!s}'.format(\n          exception))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WriteTo(self, values):\n    try:\n      return self._struct.pack(*values)\n    except (TypeError, struct.error) as exception:\n      raise IOError('Unable to write stream with error: {0!s}'.format(\n          exception))", "response": "Writes values to a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure that we have snapshots for a given volume.", "response": "def run(connection):\n    \"\"\" Ensure that we have snapshots for a given volume\n\n    :type connection: boto.ec2.connection.EC2Connection\n    :param connection: EC2 connection object\n    :returns: None\n    \"\"\"\n    volumes = volume_manager.get_watched_volumes(connection)\n\n    for volume in volumes:\n        _ensure_snapshot(connection, volume)\n        _remove_old_snapshots(connection, volume)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new snapshot for the given volume", "response": "def _create_snapshot(volume):\n    \"\"\" Create a new snapshot\n\n    :type volume: boto.ec2.volume.Volume\n    :param volume: Volume to snapshot\n    :returns: boto.ec2.snapshot.Snapshot -- The new snapshot\n    \"\"\"\n    logger.info('Creating new snapshot for {}'.format(volume.id))\n    snapshot = volume.create_snapshot(\n        description=\"Automatic snapshot by Automated EBS Snapshots\")\n    logger.info('Created snapshot {} for volume {}'.format(\n        snapshot.id, volume.id))\n\n    return snapshot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ensure_snapshot(connection, volume):\n    if 'AutomatedEBSSnapshots' not in volume.tags:\n        logger.warning(\n            'Missing tag AutomatedEBSSnapshots for volume {}'.format(\n                volume.id))\n        return\n\n    interval = volume.tags['AutomatedEBSSnapshots']\n    if volume.tags['AutomatedEBSSnapshots'] not in VALID_INTERVALS:\n        logger.warning(\n            '\"{}\" is not a valid snapshotting interval for volume {}'.format(\n                interval, volume.id))\n        return\n\n    snapshots = connection.get_all_snapshots(filters={'volume-id': volume.id})\n\n    # Create a snapshot if we don't have any\n    if not snapshots:\n        _create_snapshot(volume)\n        return\n\n    min_delta = 3600*24*365*10  # 10 years :)\n    for snapshot in snapshots:\n        timestamp = datetime.datetime.strptime(\n            snapshot.start_time,\n            '%Y-%m-%dT%H:%M:%S.000Z')\n        delta_seconds = int(\n            (datetime.datetime.utcnow() - timestamp).total_seconds())\n\n        if delta_seconds < min_delta:\n            min_delta = delta_seconds\n\n    logger.info('The newest snapshot for {} is {} seconds old'.format(\n        volume.id, min_delta))\n    if interval == 'hourly' and min_delta > 3600:\n        _create_snapshot(volume)\n    elif interval == 'daily' and min_delta > 3600*24:\n        _create_snapshot(volume)\n    elif interval == 'weekly' and min_delta > 3600*24*7:\n        _create_snapshot(volume)\n    elif interval == 'monthly' and min_delta > 3600*24*30:\n        _create_snapshot(volume)\n    elif interval == 'yearly' and min_delta > 3600*24*365:\n        _create_snapshot(volume)\n    else:\n        logger.info('No need for a new snapshot of {}'.format(volume.id))", "response": "Ensures that a given volume has an appropriate snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving old snapshots from the list of old snapshots.", "response": "def _remove_old_snapshots(connection, volume):\n    \"\"\" Remove old snapshots\n\n    :type connection: boto.ec2.connection.EC2Connection\n    :param connection: EC2 connection object\n    :type volume: boto.ec2.volume.Volume\n    :param volume: Volume to check\n    :returns: None\n    \"\"\"\n    if 'AutomatedEBSSnapshotsRetention' not in volume.tags:\n        logger.warning(\n            'Missing tag AutomatedEBSSnapshotsRetention for volume {}'.format(\n                volume.id))\n        return\n    retention = int(volume.tags['AutomatedEBSSnapshotsRetention'])\n\n    snapshots = connection.get_all_snapshots(filters={'volume-id': volume.id})\n\n    # Sort the list based on the start time\n    snapshots.sort(key=lambda x: x.start_time)\n\n    # Remove snapshots we want to keep\n    snapshots = snapshots[:-int(retention)]\n\n    if not snapshots:\n        logger.info('No old snapshots to remove')\n        return\n\n    for snapshot in snapshots:\n        logger.info('Deleting snapshot {}'.format(snapshot.id))\n        try:\n            snapshot.delete()\n        except EC2ResponseError as error:\n            logger.warning('Could not remove snapshot: {}'.format(\n                error.message))\n\n    logger.info('Done deleting snapshots')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist watched EBS volumes and return a new object.", "response": "def list(connection):\n    \"\"\" List watched EBS volumes\n\n    :type connection: boto.ec2.connection.EC2Connection\n    :param connection: EC2 connection object\n    :returns: None\n    \"\"\"\n    volumes = get_watched_volumes(connection)\n\n    if not volumes:\n        logger.info('No watched volumes found')\n        return\n\n    logger.info(\n        '+-----------------------'\n        '+----------------------'\n        '+--------------'\n        '+------------+')\n    logger.info(\n        '| {volume:<21} '\n        '| {volume_name:<20.20} '\n        '| {interval:<12} '\n        '| {retention:<10} |'.format(\n            volume='Volume ID',\n            volume_name='Volume name',\n            interval='Interval',\n            retention='Retention'))\n    logger.info(\n        '+-----------------------'\n        '+----------------------'\n        '+--------------'\n        '+------------+')\n\n    for volume in volumes:\n        if 'AutomatedEBSSnapshots' not in volume.tags:\n            interval = 'Interval tag not found'\n        elif volume.tags['AutomatedEBSSnapshots'] not in VALID_INTERVALS:\n            interval = 'Invalid interval'\n        else:\n            interval = volume.tags['AutomatedEBSSnapshots']\n\n        if 'AutomatedEBSSnapshotsRetention' not in volume.tags:\n            retention = 0\n        else:\n            retention = volume.tags['AutomatedEBSSnapshotsRetention']\n\n        # Get the volume name\n        try:\n            volume_name = volume.tags['Name']\n        except KeyError:\n            volume_name = ''\n\n        logger.info(\n            '|\u00a0{volume_id:<14} '\n            '| {volume_name:<20.20} '\n            '| {interval:<12} '\n            '| {retention:<10} |'.format(\n                volume_id=volume.id,\n                volume_name=volume_name,\n                interval=interval,\n                retention=retention))\n\n    logger.info(\n        '+-----------------------'\n        '+----------------------'\n        '+--------------'\n        '+------------+')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unwatch(connection, volume_id):\n    try:\n        volume = connection.get_all_volumes(volume_ids=[volume_id])[0]\n        volume.remove_tag('AutomatedEBSSnapshots')\n    except EC2ResponseError:\n        pass\n\n    logger.info('Removed {} from the watchlist'.format(volume_id))\n\n    return True", "response": "Remove watching of a volume"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef watch(connection, volume_id, interval='daily', retention=0):\n    try:\n        volume = connection.get_all_volumes(volume_ids=[volume_id])[0]\n    except EC2ResponseError:\n        logger.warning('Volume {} not found'.format(volume_id))\n        return False\n\n    if interval not in VALID_INTERVALS:\n        logger.warning(\n            '{} is not a valid interval. Valid intervals are {}'.format(\n                interval, ', '.join(VALID_INTERVALS)))\n\n    # Remove the tag first\n    volume.remove_tag('AutomatedEBSSnapshots')\n\n    # Re-add the tag\n    volume.add_tag('AutomatedEBSSnapshots', value=interval)\n\n    # Remove the tag first\n    volume.remove_tag('AutomatedEBSSnapshotsRetention')\n\n    # Re-add the tag\n    volume.add_tag('AutomatedEBSSnapshotsRetention', value=int(retention))\n\n    logger.info('Updated the rotation interval to {} for {}'.format(\n        interval, volume_id))\n\n    return True", "response": "Start watching a new volume and add it to the watchlist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_volume_id(connection, volume):\n    # Regular expression to check whether input is a volume id\n    volume_id_pattern = re.compile('vol-\\w{8}')\n\n    if volume_id_pattern.match(volume):\n        # input is volume id\n        try:\n            # Check whether it exists\n            connection.get_all_volumes(volume_ids=[volume])\n            volume_id = volume\n        except EC2ResponseError:\n            logger.warning('Volume {} not found'.format(volume))\n            return None\n    else:\n        # input is volume name\n        name_filter = {'tag-key': 'Name', 'tag-value': volume}\n        volumes = connection.get_all_volumes(filters=name_filter)\n        if not volumes:\n            logger.warning('Volume {} not found'.format(volume))\n            return None\n        if len(volumes) > 1:\n            logger.warning('Volume {} not unique'.format(volume))\n        volume_id = volumes[0].id\n\n    return volume_id", "response": "Get Volume ID from the given volume. Input can be volume id\n    or volume Name\n   . Returns None if the given volume does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef watch_from_file(connection, file_name):\n    with open(file_name, 'r') as filehandle:\n        for line in filehandle.xreadlines():\n            volume, interval, retention = line.rstrip().split(',')\n            watch(\n                connection,\n                get_volume_id(connection, volume),\n                interval, retention)", "response": "Start watching a new block device from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts watching a new volume :type connection: boto.ec2.connection.EC2Connection :param connection: EC2 connection object :type file_name: str :param file_name: path to config file :returns: None", "response": "def unwatch_from_file(connection, file_name):\n    \"\"\" Start watching a new volume\n\n    :type connection: boto.ec2.connection.EC2Connection\n    :param connection: EC2 connection object\n    :type file_name: str\n    :param file_name: path to config file\n    :returns: None\n    \"\"\"\n    with open(file_name, 'r') as filehandle:\n        for line in filehandle.xreadlines():\n            volume, interval, retention = line.rstrip().split(',')\n            unwatch(connection, get_volume_id(connection, volume))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all snapshots for the specified volume", "response": "def list_snapshots(connection, volume):\n    \"\"\" List all snapshots for the volume\n\n    :type connection: boto.ec2.connection.EC2Connection\n    :param connection: EC2 connection object\n    :type volume: str\n    :param volume: Volume ID or Volume Name\n    :returns: None\n    \"\"\"\n\n    logger.info(\n        '+----------------'\n        '+----------------------'\n        '+---------------------------+')\n    logger.info(\n        '| {snapshot:<14} '\n        '| {snapshot_name:<20.20} '\n        '| {created:<25} |'.format(\n            snapshot='Snapshot ID',\n            snapshot_name='Snapshot name',\n            created='Created'))\n    logger.info(\n        '+----------------'\n        '+----------------------'\n        '+---------------------------+')\n\n    vid = get_volume_id(connection, volume)\n    if vid:\n        vol = connection.get_all_volumes(volume_ids=[vid])[0]\n        for snap in vol.snapshots():\n            logger.info(\n                '| {snapshot:<14} '\n                '| {snapshot_name:<20.20} '\n                '| {created:<25} |'.format(\n                    snapshot=snap.id,\n                    snapshot_name=snap.tags.get('Name', ''),\n                    created=snap.start_time))\n\n    logger.info(\n        '+----------------'\n        '+----------------------'\n        '+---------------------------+')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting stems for the words using a given parser", "response": "def stem(self, words, parser, **kwargs):\n        \"\"\"\n        Get stems for the words using a given parser\n\n        Example:\n            from .parsing import ListParser\n\n            parser = ListParser()\n            stemmer = Morfologik()\n            stemmer.stem(['ja ta\u0144cz\u0119 a ona \u015bpi], parser)\n\n            [\n                 ('ja': ['ja']),\n                 ('ta\u0144cz\u0119': ['ta\u0144czy\u0107']),\n                 ('a': ['a']),\n                 ('ona': ['on']),\n                 ('\u015bpi': ['spa\u0107'])\n            ]\n        \"\"\"\n        output = self._run_morfologik(words)\n        return parser.parse(output, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning morfologik java jar and returns the result as unicode.", "response": "def _run_morfologik(self, words):\n        \"\"\"\n        Runs morfologik java jar and assumes that input and output is\n        UTF-8 encoded.\n        \"\"\"\n        p = subprocess.Popen(\n            ['java', '-jar', self.jar_path, 'plstem',\n             '-ie', 'UTF-8',\n             '-oe', 'UTF-8'],\n            bufsize=-1,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT)\n        out, _ = p.communicate(input=bytes(\"\\n\".join(words), \"utf-8\"))\n        return decode(out, 'utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_from_hdx(identifier, configuration=None):\n        # type: (str, Optional[Configuration]) -> Optional['Showcase']\n        \"\"\"Reads the showcase given by identifier from HDX and returns Showcase object\n\n        Args:\n            identifier (str): Identifier of showcase\n            configuration (Optional[Configuration]): HDX configuration. Defaults to global configuration.\n\n        Returns:\n            Optional[Showcase]: Showcase object if successful read, None if not\n        \"\"\"\n\n        showcase = Showcase(configuration=configuration)\n        result = showcase._load_from_hdx('showcase', identifier)\n        if result:\n            return showcase\n        return None", "response": "Reads the showcase given by identifier from HDX and returns the object if successful."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_datasets(self):\n        # type: () -> List[hdx.data.dataset.Dataset]\n        \"\"\"Get any datasets in the showcase\n\n        Returns:\n            List[Dataset]: List of datasets\n        \"\"\"\n        assoc_result, datasets_dicts = self._read_from_hdx('showcase', self.data['id'], fieldname='showcase_id',\n                                                           action=self.actions()['list_datasets'])\n        datasets = list()\n        if assoc_result:\n            for dataset_dict in datasets_dicts:\n                dataset = hdx.data.dataset.Dataset(dataset_dict, configuration=self.configuration)\n                datasets.append(dataset)\n        return datasets", "response": "Get any datasets in the showcase\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting showcase dataset dict from a showcase object or dict", "response": "def _get_showcase_dataset_dict(self, dataset):\n        # type: (Union[hdx.data.dataset.Dataset,Dict,str]) -> Dict\n        \"\"\"Get showcase dataset dict\n\n        Args:\n            showcase (Union[Showcase,Dict,str]): Either a showcase id or Showcase metadata from a Showcase object or dictionary\n\n        Returns:\n            Dict: showcase dataset dict\n        \"\"\"\n        if isinstance(dataset, hdx.data.dataset.Dataset) or isinstance(dataset, dict):\n            if 'id' not in dataset:\n                dataset = hdx.data.dataset.Dataset.read_from_hdx(dataset['name'])\n            dataset = dataset['id']\n        elif not isinstance(dataset, str):\n            raise hdx.data.hdxobject.HDXError('Type %s cannot be added as a dataset!' % type(dataset).__name__)\n        if is_valid_uuid(dataset) is False:\n            raise hdx.data.hdxobject.HDXError('%s is not a valid dataset id!' % dataset)\n        return {'showcase_id': self.data['id'], 'package_id': dataset}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_dataset(self, dataset, datasets_to_check=None):\n        # type: (Union[hdx.data.dataset.Dataset,Dict,str], List[hdx.data.dataset.Dataset]) -> bool\n        \"\"\"Add a dataset\n\n        Args:\n            dataset (Union[Dataset,Dict,str]): Either a dataset id or dataset metadata either from a Dataset object or a dictionary\n            datasets_to_check (List[Dataset]): List of datasets against which to check existence of dataset. Defaults to datasets in showcase.\n\n        Returns:\n            bool: True if the dataset was added, False if already present\n        \"\"\"\n        showcase_dataset = self._get_showcase_dataset_dict(dataset)\n        if datasets_to_check is None:\n            datasets_to_check = self.get_datasets()\n        for dataset in datasets_to_check:\n            if showcase_dataset['package_id'] == dataset['id']:\n                return False\n        self._write_to_hdx('associate', showcase_dataset, 'package_id')\n        return True", "response": "Adds a dataset to the showcase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd multiple datasets to the showcase.", "response": "def add_datasets(self, datasets, datasets_to_check=None):\n        # type: (List[Union[hdx.data.dataset.Dataset,Dict,str]], List[hdx.data.dataset.Dataset]) -> bool\n        \"\"\"Add multiple datasets\n\n        Args:\n            datasets (List[Union[Dataset,Dict,str]]): A list of either dataset ids or dataset metadata from Dataset objects or dictionaries\n            datasets_to_check (List[Dataset]): List of datasets against which to check existence of dataset. Defaults to datasets in showcase.\n\n        Returns:\n            bool: True if all datasets added or False if any already present\n        \"\"\"\n        if datasets_to_check is None:\n            datasets_to_check = self.get_datasets()\n        alldatasetsadded = True\n        for dataset in datasets:\n            if not self.add_dataset(dataset, datasets_to_check=datasets_to_check):\n                alldatasetsadded = False\n        return alldatasetsadded"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef possible_parameter(nb, jsonable_parameter=True, end_cell_index=None):\n    jh = _JupyterNotebookHelper(nb, jsonable_parameter, end_cell_index)\n\n    if jsonable_parameter is True:\n        PossibleParameter=collections.namedtuple('PossibleParameter',['name','value','cell_index'])\n    else:\n        PossibleParameter=collections.namedtuple('PossibleParameter',['name', 'cell_index'])\n\n    res=[]\n    for name, cell_index in jh.param_cell_index.items():\n        if jsonable_parameter is True:\n            res.append(PossibleParameter(name=name,value=jh.param_value[name],cell_index=cell_index))\n        else:\n            res.append(PossibleParameter(name=name,cell_index=cell_index))\n\n    return sorted(res, key = lambda x: (x.name))", "response": "Find the possible parameters from a jupyter notebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns an input jupyter notebook file and optionally (python3 only) parametrise it. One can pass arguments as keyword arguments or in a json format (file or string). For safety reasons, in order to avoid any code injection, only json serialisable keywords arguments are available. The keyword arguments are firstly encoded in json format using the standard json encoder. The json content is decoded into python objects using the standard json decoder and it is mapped to a variable assignment by unpacking it. The assignments are appended at the end of the cell where they are initially defined. Parameters ---------- input_path : str Path of the input jupyter notebook. output_path : str, optional Path of the output jupyter notebook. One can use the input_path location as relative path by starting with \"///\" . * can be used once in the beggining or end (excluding the \".ipynb\" extension) as a wildcard of the input_path filename. \"///_run_jnb/*-output\" is the default value and states that the output is in the run_jnb folder with respect to the input_path directory and \"-output\" is appended to the input name. execution_path : str, optional The path of the folder where to execute the notebook. r'///input' or r'///output' can be used to denote the input / output folder. return_mode : ['parametrised_only','except',True, False], optional Flag to write the generated notebook to the output_path: \"parametrised_only\" writes the generated notebook without executing it, \"except\" writes in case of an exception, True writes always, False writes never. overwrite : bool, optional Flag to overwrite or not the output_path. If the parameter is False the used output_path will be incremented until a valid one is found. timeout : int, optional ExecutePreprocessor.timeout kernel_name : str, optional ExecutePreprocessor.kernel_name ep_kwargs : dict, optional Other kwargs accepted by nbconvert.preprocessors.ExecutePreprocessor jsonable_parameter: bool, optional Parametrise only jsonable parameters end_cell_index : int, optional End cell index used to slice the notebook in finding the possible parameters. arg : str Path of a json file (it should end in \".json\") or json formatted string used to parametrise the jupyter notebook. It should containt json objects. It is decoded into python objects following https://docs.python.org/3.6/library/json.html#json-to-py-table . kwargs: json serialsable keyword arguments used to parametrise the jupyter notebook. Returns ------- collections.namedtuple The fields are ('output_nb_path', 'error_prompt_number','error_type','error_value','error_traceback'). If the generated file is written the output path is returned otherwise None. If an error is catched the details are return otherwise None.", "response": "def run_jnb(input_path, output_path=r\"///_run_jnb/*-output\",\n            execution_path=r'///input',\n            return_mode='except',\n            overwrite=False,\n            timeout=ExecutePreprocessor.timeout.default_value,\n            kernel_name=ExecutePreprocessor.kernel_name.default_value,\n            ep_kwargs=None, jsonable_parameter=True, end_cell_index=None, arg=None, **kwargs):\n    \"\"\"\n    Run an input jupyter notebook file and optionally (python3 only)\n    parametrise it.\n\n    One can pass arguments as keyword arguments or in a json format (file or string).\n    For safety reasons, in order to avoid any code injection,\n    only json serialisable keywords arguments are available. The keyword\n    arguments are firstly encoded in json format using the standard json encoder.\n    The json content is decoded into python objects using the standard json decoder\n    and it is mapped to a variable assignment by unpacking it.\n    The assignments are appended at the end of the cell where they are initially defined.\n\n\n    Parameters\n    ----------\n    input_path : str\n        Path of the input jupyter notebook.\n    output_path : str, optional\n        Path of the output jupyter notebook.\n        One can use the input_path location as relative path by starting with \"///\" .\n        * can be used once in the beggining or end (excluding the \".ipynb\" extension) as a wildcard of the input_path filename.\n        \"///_run_jnb/*-output\" is the default value and states that the output\n        is in the run_jnb folder with respect to the input_path directory and \"-output\" is appended to the input name.\n    execution_path : str, optional\n        The path of the folder where to execute the notebook.\n        r'///input' or r'///output' can be used to denote the input / output folder.\n\n    return_mode : ['parametrised_only','except',True, False], optional\n        Flag to write the generated notebook to the output_path: \"parametrised_only\" writes the generated notebook without executing it, \"except\" writes in case of an exception, True writes always, False writes never.\n    overwrite : bool, optional\n        Flag to overwrite or not the output_path. If the parameter is False\n        the used output_path will be incremented until a valid one is found.\n    timeout : int, optional\n        ExecutePreprocessor.timeout\n    kernel_name : str, optional\n        ExecutePreprocessor.kernel_name\n    ep_kwargs : dict, optional\n        Other kwargs accepted by nbconvert.preprocessors.ExecutePreprocessor\n    jsonable_parameter: bool, optional\n        Parametrise only jsonable parameters\n    end_cell_index : int, optional\n        End cell index used to slice the notebook in finding the possible parameters.\n    arg : str\n        Path of a json file (it should end in \".json\") or json formatted string used to parametrise the jupyter notebook.\n        It should containt json objects. It is decoded into python objects following https://docs.python.org/3.6/library/json.html#json-to-py-table .\n    kwargs:\n        json serialsable keyword arguments used to parametrise the jupyter notebook.\n\n    Returns\n    -------\n    collections.namedtuple\n        The fields are ('output_nb_path', 'error_prompt_number','error_type','error_value','error_traceback').\n        If the generated file is written the output path is returned otherwise None.\n        If an error is catched the details are return otherwise None.\n        \"\"\"\n\n    if os.path.splitext(input_path)[1] != '.ipynb':\n        raise ValueError(\"The extension of input_path = '{}' is not '.ipynb'\".format(input_path))\n    if os.path.basename(input_path) == '*':\n        raise ValueError(\"The filename ={} can not start with *\".format(input_path))\n\n\n    input_path_dir, input_path_base = os.path.split(input_path)\n    if output_path.startswith(r'///'):\n        input_rel = True\n        output_path = output_path[3:]\n    else:\n        input_rel = False\n    output_path_dir, output_path_base = os.path.split(output_path)\n\n    if input_rel:\n        output_path_dir = os.path.join(input_path_dir, output_path_dir)\n        output_path_dir = os.path.normpath(output_path_dir)\n\n    if os.path.exists(output_path_dir) is False:\n        os.makedirs(output_path_dir)\n\n    if output_path_base.endswith('.ipynb'):\n        pass\n    elif output_path_base.startswith(\"*\"):\n        output_path_base = input_path_base[:-6]+output_path_base[1:]+'.ipynb'\n    elif output_path_base.endswith(\"*\"):\n        output_path_base = output_path_base[:-1]+input_path_base[:-6]+'.ipynb'\n    else:\n        raise ValueError(\"Invalid output_path\")\n\n    output_path = os.path.abspath(os.path.join(output_path_dir,\n                                               output_path_base))\n\n    if output_path is not None and os.path.splitext(output_path)[1] != '.ipynb':\n        raise ValueError(\"The extension of output_path = '{}' is not '.ipynb'\".format(output_path))\n\n    if execution_path.startswith(r'///input'):\n        execution_path = os.path.join(input_path_dir, execution_path[8:])\n    elif execution_path.startswith(r'///output'):\n        execution_path = os.path.join(input_path_dir, execution_path[8:])\n    execution_path = os.path.normpath(execution_path)\n\n    if os.path.exists(execution_path) is False:\n        os.makedirs(execution_path)\n\n    if ep_kwargs is None:\n        ep_kwargs = {}\n\n    if return_mode not in ['parametrised_only', 'except', True, False]:\n        raise TypeError(\"return mode is not valid!\")\n\n    kwarg_to_json = json.dumps(kwargs)\n    kwarg_as_kwarg = decode_json(kwarg_to_json)\n    arg_as_kwarg = decode_json(arg)\n\n    multiple_kwarg = set(arg_as_kwarg.keys()) & set(kwarg_as_kwarg.keys())\n    if multiple_kwarg != set():\n        raise ValueError('Multiple values for keyword argument {}'.format(multiple_kwarg))\n    jupyter_kwargs = {**arg_as_kwarg, **kwarg_as_kwarg}\n    nb = _read_nb(input_path)\n\n    # clean notebook\n    for i, cell in enumerate(nb['cells']):\n        if cell['cell_type'] == 'code':\n            nb['cells'][i]['outputs'] = []\n            nb['cells'][i]['execution_count'] = None\n\n    if jupyter_kwargs != {}:\n        params_of_interest = {}\n        jnh = _JupyterNotebookHelper(nb, jsonable_parameter ,end_cell_index)\n        for el in jupyter_kwargs.keys():\n            if el not in jnh.param_cell_index.keys():\n                raise ValueError(repr(el)+' is not a possible parameter {}.'.format(list(jnh.param_cell_index.keys())))\n            else:\n                params_of_interest[el] = jnh.param_cell_index[el]\n        params_of_interest = sort_dict(params_of_interest, by='value')\n        cell_index_param = group_dict_by_value(params_of_interest)\n        for key, value in cell_index_param.items():\n            cell_param = {k: jupyter_kwargs[k] for k in value}\n            cell_code = kwargs_to_variable_assignment(cell_param)\n            marked_code = _mark_auto_generated_code(cell_code)\n            nb['cells'][key]['source'] += marked_code\n\n    if return_mode != 'parametrised_only':\n        ep = ExecutePreprocessor(timeout=timeout, kernel_name=kernel_name,\n                                 **ep_kwargs)\n\n    catch_except = False\n\n    error = (None, None, None, None)\n    try:\n        if return_mode != 'parametrised_only':\n            ep.preprocess(nb, {'metadata': {'path': execution_path}})\n    except CellExecutionError:\n        catch_except = True\n\n        for cell in nb['cells'][::-1]:\n            if cell['cell_type'] == 'code' and cell.get('outputs') != []:\n                for output in cell['outputs']:\n                    if output.get('output_type') == 'error':\n                        error = (cell['execution_count'],\n                                 output.get('ename'), output.get('evalue'),\n                                 output.get('traceback'))\n                        break\n                if error[0] is not None:\n                    break\n                else:\n                    raise ValueError('Cell expected to have an error.')\n    except:\n        raise\n\n    if return_mode == 'except':\n        if catch_except is True:\n            nb_return = True\n        else:\n            nb_return = None\n    elif return_mode is True or return_mode == 'parametrised_only':\n        nb_return = True\n    elif return_mode is False:\n        nb_return = None\n\n    if nb_return is not None:\n        if overwrite is False:\n            while os.path.exists(output_path):\n                dirname, basename = os.path.split(output_path)\n                root, ext = os.path.splitext(basename)\n                new_root = increment_name(root)\n                output_path = os.path.join(dirname, new_root+ext)\n        nb_return = output_path  # update the output_path\n        _write_nb(nb, output_path)\n    Output=collections.namedtuple('Output',['output_nb_path', 'error_prompt_number','error_type','error_value','error_traceback'])\n    res = Output(output_nb_path=nb_return,error_prompt_number=error[0],\n                error_type=error[1],error_value=error[2],error_traceback=error[3])\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef join(self, joiner, formatter=lambda s, t: t.format(s),\n             template=\"{}\"):\n        \"\"\"Join values and convert to string\n\n        Example:\n\n            >>> from ww import l\n            >>> lst = l('012')\n            >>> lst.join(',')\n            u'0,1,2'\n            >>> lst.join(',', template=\"{}#\")\n            u'0#,1#,2#'\n            >>> string = lst.join(',',\\\n                                  formatter = lambda x, y: str(int(x) ** 2))\n            >>> string\n            u'0,1,4'\n        \"\"\"\n\n        return ww.s(joiner).join(self, formatter, template)", "response": "Join values and convert to string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append(self, *values):\n\n        for value in values:\n            list.append(self, value)\n        return self", "response": "Append values at the end of the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extend(self, *iterables):\n\n        for value in iterables:\n            list.extend(self, value)\n        return self", "response": "Add all values of all iterables at the end of the list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing the value for writing into a cell.", "response": "def normalize_cell_value(value):\n    \"\"\"Process value for writing into a cell.\n\n    Args:\n        value: any type of variable\n\n    Returns:\n        json serialized value if value is list or dict, else value\n    \"\"\"\n    if isinstance(value, dict) or isinstance(value, list):\n        return json.dumps(value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_addresses_from_input_file(input_file_name):\n    mode = 'r'\n    if sys.version_info[0] < 3:\n        mode = 'rb'\n    with io.open(input_file_name, mode) as input_file:\n        reader = csv.reader(input_file, delimiter=',', quotechar='\"')\n\n        addresses = list(map(tuple, reader))\n\n        if len(addresses) == 0:\n            raise Exception('No addresses found in input file')\n\n        header_columns = list(column.lower() for column in addresses.pop(0))\n\n        try:\n            address_index = header_columns.index('address')\n            zipcode_index = header_columns.index('zipcode')\n        except ValueError:\n            raise Exception(\"\"\"The first row of the input CSV must be a header that contains \\\na column labeled 'address' and a column labeled 'zipcode'.\"\"\")\n\n        return list((row[address_index], row[zipcode_index]) for row in addresses)", "response": "Read addresses from input file into list of tuples. This only supports address and zipcode headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_identifiers_from_input_file(input_file_name):\n    valid_identifiers = ['address', 'zipcode', 'unit', 'city', 'state', 'slug', 'block_id', 'msa',\n                         'num_bins', 'property_type', 'client_value', 'client_value_sqft', 'meta']\n    mode = 'r'\n    if sys.version_info[0] < 3:\n        mode = 'rb'\n    with io.open(input_file_name, mode) as input_file:\n        result = [{identifier: val for identifier, val in list(row.items())\n                   if identifier in valid_identifiers}\n                  for row in csv.DictReader(input_file, skipinitialspace=True)]\n        return result", "response": "Read identifiers from input file into list of dicts with the header row values\nATTRIBS as keys and the rest of the rows as values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_real_time_locate(ipAddress, auth, url):\n    real_time_locate_url = \"/imcrs/res/access/realtimeLocate?type=2&value=\" + str(ipAddress) + \"&total=false\"\n    f_url = url + real_time_locate_url\n    r = requests.get(f_url, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            response =  json.loads(r.text)\n            if 'realtimeLocation' in response:\n                real_time_locate = json.loads(r.text)['realtimeLocation']\n                if type(real_time_locate) is dict:\n                    real_time_locate = [real_time_locate]\n                    return real_time_locate\n                else:\n                    return json.loads(r.text)['realtimeLocation']\n            else:\n                return json.loads(r.text)\n\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_real_time_locate: An Error has occured\"", "response": "This function returns the real time locate of the specified host."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction takes devId of specific device and issues a RESTFUL call to get the IP MAC ARP list of the target device.", "response": "def get_ip_mac_arp_list(devId, auth,url):\n    \"\"\"\n    function takes devid of specific device and issues a RESTFUL call to get the IP/MAC/ARP list from the target device.\n\n    :param devId: int or str value of the target device.\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: list of dictionaries containing the IP/MAC/ARP list of the target device.\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.termaccess import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> ip_mac_list = get_ip_mac_arp_list('10', auth.creds, auth.url)\n\n    >>> assert type(ip_mac_list) is list\n\n    >>> assert 'deviceId' in ip_mac_list[0]\n\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    ip_mac_arp_list_url = \"/imcrs/res/access/ipMacArp/\" + str(devId)\n    f_url = url + ip_mac_arp_list_url\n    r = requests.get(f_url, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            macarplist = (json.loads(r.text))\n            if len(macarplist) > 1:\n                return macarplist['ipMacArp']\n            else:\n                return ['this function is unsupported']\n\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_ip_mac_arp_list: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ip_scope_detail(scopeId, auth, url ):\n    get_ip_scope_url = \"/imcrs/res/access/assignedIpScope/\"+str(scopeId)\n\n    f_url = url + get_ip_scope_url\n    r = requests.get(f_url, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            ipscopelist = (json.loads(r.text))\n            return ipscopelist\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_ip_scope: An Error has occured\"", "response": "function takes input of scopeId and auth object and url and returns the list of IP address scopes currently configured on the HPE IMC server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to delete an entire IP segment from the IMC IP Address management under terminal access", "response": "def delete_ip_scope(network_address, auth, url):\n    '''Function to delete an entire IP segment from the IMC IP Address management under terminal access\n    :param network_address\n    :param auth\n    :param url\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.termaccess import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> new_scope = add_ip_scope('10.50.0.1', '10.50.0.254', 'cyoung', 'test group', auth.creds, auth.url)\n\n    >>> delete_scope = delete_ip_scope('10.50.0.0/24', auth.creds, auth.url)\n\n\n    '''\n    scope_id = get_scope_id(network_address, auth,url)\n    delete_ip_address_url = '''/imcrs/res/access/assignedIpScope/'''+str(scope_id)\n    f_url = url + delete_ip_address_url\n    r = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        return r\n        if r.status_code == 204:\n            #print(\"IP Segment Successfully Deleted\")\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" delete_ip_scope: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to add new host IP address allocation to existing scope ID", "response": "def add_scope_ip(ipaddress, name, description, scopeid, auth, url):\n    \"\"\"\n    Function to add new host IP address allocation to existing scope ID\n\n    :param ipaddress:\n\n    :param name: name of the owner of this host\n\n    :param description: Description of the host\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return:\n\n    :rtype:\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.termaccess import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> add_scope_ip('10.50.0.5', 'cyoung', 'New Test Host','175', auth.creds, auth.url)\n\n    \"\"\"\n    new_ip = { \"ip\": ipaddress,\n      \"name\": name,\n      \"description\": description}\n    add_scope_ip_url = '/imcrs/res/access/assignedIpScope/ip?ipScopeId='+str(scopeid)\n    f_url = url + add_scope_ip_url\n    payload = json.dumps(new_ip)\n    r = requests.post(f_url, auth=auth, headers=HEADERS,\n                      data=payload)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            #print(\"IP Scope Successfully Created\")\n            return r.status_code\n        elif r.status_code == 409:\n            #print(\"IP Scope Already Exists\")\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" add_ip_scope: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_scope_ip(hostid, auth, url):\n    add_scope_ip_url = '/imcrs/res/access/assignedIpScope/ip/'+str(hostid)\n    f_url = url + add_scope_ip_url\n\n    r = requests.delete(f_url, auth=auth, headers=HEADERS,\n                      )\n    try:\n        if r.status_code == 204:\n            #print(\"Host Successfully Deleted\")\n            return r.status_code\n        elif r.status_code == 409:\n            #print(\"IP Scope Already Exists\")\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" add_ip_scope: An Error has occured\"", "response": "Function to add remove IP address allocation to the base url of the host"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ip_scope_hosts( scopeId, auth, url):\n    get_ip_scope_url = \"/imcrs/res/access/assignedIpScope/ip?size=10000&ipScopeId=\"+str(scopeId)\n    f_url = url + get_ip_scope_url\n    r = requests.get(f_url, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            ipscopelist = (json.loads(r.text))\n            if ipscopelist == {}:\n                return ipscopelist\n            else: ipscopelist = ipscopelist['assignedIpInfo']\n            if type(ipscopelist) is dict:\n                ipscope = []\n                ipscope.append(ipscopelist)\n                return ipscope\n            return ipscopelist\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_ip_scope: An Error has occured\"", "response": "Function returns list of allocated IP address for the specified scope"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_host_to_segment(ipaddress, name, description, network_address, auth, url):\n    ''' Function to abstract existing add_scope_ip_function. Allows for use of network address rather than forcing human\n    to learn the scope_id\n    :param ipaddress:\n\n    :param name: name of the owner of this host\n\n    :param description: Description of the host\n\n    :param: network_address: network address of the target scope in format x.x.x.x/yy  where x.x.x.x representents the\n    network address and yy represents the length of the subnet mask.  Example:  10.50.0.0 255.255.255.0 would be written\n    as 10.50.0.0/24\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return:\n\n    :rtype:\n\n\n\n    '''\n    scope_id = get_scope_id(network_address, auth, url)\n    add_scope_ip(ipaddress, name, description, scope_id, auth,url)", "response": "Function to abstract existing add_scope_ip_function. Allows for use of network address rather than forcing human\n    to learn the scope_id\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_host_from_segment(ipaddress, networkaddress, auth, url):\n    '''Function to abstract\n\n    '''\n    host_id = get_host_id(ipaddress, networkaddress, auth, url)\n    remove_scope_ip(host_id, auth.creds, auth.url)", "response": "Function to abstract\n    remove host from segment"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_signature(method, version, endpoint,\n                       date, rel_url, content_type, content,\n                       access_key, secret_key, hash_type):\n    '''\n    Generates the API request signature from the given parameters.\n    '''\n    hash_type = hash_type\n    hostname = endpoint._val.netloc  # FIXME: migrate to public API\n    if version >= 'v4.20181215':\n        content = b''\n    else:\n        if content_type.startswith('multipart/'):\n            content = b''\n    body_hash = hashlib.new(hash_type, content).hexdigest()\n\n    sign_str = '{}\\n{}\\n{}\\nhost:{}\\ncontent-type:{}\\nx-backendai-version:{}\\n{}'.format(  # noqa\n        method.upper(),\n        rel_url,\n        date.isoformat(),\n        hostname,\n        content_type.lower(),\n        version,\n        body_hash\n    )\n    sign_bytes = sign_str.encode()\n\n    sign_key = hmac.new(secret_key.encode(),\n                        date.strftime('%Y%m%d').encode(), hash_type).digest()\n    sign_key = hmac.new(sign_key, hostname.encode(), hash_type).digest()\n\n    signature = hmac.new(sign_key, sign_bytes, hash_type).hexdigest()\n    headers = {\n        'Authorization': 'BackendAI signMethod=HMAC-{}, credential={}:{}'.format(\n            hash_type.upper(),\n            access_key,\n            signature\n        ),\n    }\n    return headers, signature", "response": "Generates the API request signature from the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the list of agents with the given status with limit and offset for pagination.", "response": "async def list_with_limit(cls,\n                              limit,\n                              offset,\n                              status: str = 'ALIVE',\n                              fields: Iterable[str] = None) -> Sequence[dict]:\n        '''\n        Fetches the list of agents with the given status with limit and offset for\n        pagination.\n\n        :param limit: number of agents to get\n        :param offset: offset index of agents to get\n        :param status: An upper-cased string constant representing agent\n            status (one of ``'ALIVE'``, ``'TERMINATED'``, ``'LOST'``,\n            etc.)\n        :param fields: Additional per-agent query fields to fetch.\n        '''\n        if fields is None:\n            fields = (\n                'id',\n                'addr',\n                'status',\n                'first_contact',\n                'mem_slots',\n                'cpu_slots',\n                'gpu_slots',\n            )\n        q = 'query($limit: Int!, $offset: Int!, $status: String) {' \\\n            '  agent_list(limit: $limit, offset: $offset, status: $status) {' \\\n            '   items { $fields }' \\\n            '   total_count' \\\n            '  }' \\\n            '}'\n        q = q.replace('$fields', ' '.join(fields))\n        variables = {\n            'limit': limit,\n            'offset': offset,\n            'status': status,\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['agent_list']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_content(self, value: RequestContent, *,\n                    content_type: str = None):\n        '''\n        Sets the content of the request.\n        '''\n        assert self._attached_files is None, \\\n               'cannot set content because you already attached files.'\n        guessed_content_type = 'application/octet-stream'\n        if value is None:\n            guessed_content_type = 'text/plain'\n            self._content = b''\n        elif isinstance(value, str):\n            guessed_content_type = 'text/plain'\n            self._content = value.encode('utf-8')\n        else:\n            guessed_content_type = 'application/octet-stream'\n            self._content = value\n        self.content_type = (content_type if content_type is not None\n                             else guessed_content_type)", "response": "Sets the content of the request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nattach a list of files represented as AttachedFile.", "response": "def attach_files(self, files: Sequence[AttachedFile]):\n        '''\n        Attach a list of files represented as AttachedFile.\n        '''\n        assert not self._content, 'content must be empty to attach files.'\n        self.content_type = 'multipart/form-data'\n        self._attached_files = files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the signature of the request and adds it to the headers.", "response": "def _sign(self, rel_url, access_key=None, secret_key=None, hash_type=None):\n        '''\n        Calculates the signature of the given request and adds the\n        Authorization HTTP header.\n        It should be called at the very end of request preparation and before\n        sending the request to the server.\n        '''\n        if access_key is None:\n            access_key = self.config.access_key\n        if secret_key is None:\n            secret_key = self.config.secret_key\n        if hash_type is None:\n            hash_type = self.config.hash_type\n        hdrs, _ = generate_signature(\n            self.method, self.config.version, self.config.endpoint,\n            self.date, str(rel_url), self.content_type, self._content,\n            access_key, secret_key, hash_type)\n        self.headers.update(hdrs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a request to the server and reads the response.", "response": "def fetch(self, **kwargs) -> 'FetchContextManager':\n        '''\n        Sends the request to the server and reads the response.\n\n        You may use this method either with plain synchronous Session or\n        AsyncSession.  Both the followings patterns are valid:\n\n        .. code-block:: python3\n\n          from ai.backend.client.request import Request\n          from ai.backend.client.session import Session\n\n          with Session() as sess:\n            rqst = Request(sess, 'GET', ...)\n            with rqst.fetch() as resp:\n              print(resp.text())\n\n        .. code-block:: python3\n\n          from ai.backend.client.request import Request\n          from ai.backend.client.session import AsyncSession\n\n          async with AsyncSession() as sess:\n            rqst = Request(sess, 'GET', ...)\n            async with rqst.fetch() as resp:\n              print(await resp.text())\n        '''\n        assert self.method in self._allowed_methods, \\\n               'Disallowed HTTP method: {}'.format(self.method)\n        self.date = datetime.now(tzutc())\n        self.headers['Date'] = self.date.isoformat()\n        if self.content_type is not None:\n            self.headers['Content-Type'] = self.content_type\n        full_url = self._build_url()\n        self._sign(full_url.relative())\n        rqst_ctx = self.session.aiohttp_session.request(\n            self.method,\n            str(full_url),\n            data=self._pack_content(),\n            timeout=_default_request_timeout,\n            headers=self.headers)\n        return FetchContextManager(self.session, rqst_ctx, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_websocket(self, **kwargs) -> 'WebSocketContextManager':\n        '''\n        Creates a WebSocket connection.\n\n        .. warning::\n\n          This method only works with\n          :class:`~ai.backend.client.session.AsyncSession`.\n        '''\n        assert isinstance(self.session, AsyncSession), \\\n               'Cannot use websockets with sessions in the synchronous mode'\n        assert self.method == 'GET', 'Invalid websocket method'\n        self.date = datetime.now(tzutc())\n        self.headers['Date'] = self.date.isoformat()\n        # websocket is always a \"binary\" stream.\n        self.content_type = 'application/octet-stream'\n        full_url = self._build_url()\n        self._sign(full_url.relative())\n        ws_ctx = self.session.aiohttp_session.ws_connect(\n            str(full_url),\n            autoping=True, heartbeat=30.0,\n            headers=self.headers)\n        return WebSocketContextManager(self.session, ws_ctx, **kwargs)", "response": "Creates a WebSocket connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_perf_task(task, auth, url):\n    add_perf_task_url = \"/imcrs/perf/task\"\n    f_url = url + add_perf_task_url\n    payload = json.dumps(task)\n    response = requests.post(f_url, data=payload, auth=auth, headers=HEADERS)\n    try:\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' add_perf_task: An Error has occured'", "response": "function adds a performance task to the device"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction takes a str object containing the name of an existing performance task and issues a RESTFUL call to the IMC REST service to get the performance task information.", "response": "def get_perf_task(task_name, auth, url):\n    \"\"\"\n        function takes the a str object containing the name of an existing performance tasks and\n        issues a RESTFUL call to the IMC REST service. It will return a list\n\n        :param task_name: str containing the name of the performance task\n\n        :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n        :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n        :return: 204\n\n        :rtype: dict\n\n        >>> from pyhpeimc.auth import *\n\n        >>> from pyhpeimc.plat.perf import *\n\n        >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n        >>> selected_task = get_perf_task('Cisco_Temperature', auth.creds, auth.url)\n\n        >>> assert type(selected_task) is dict\n\n        >>> assert 'taskName' in selected_task\n        \"\"\"\n    get_perf_task_url = \"/imcrs/perf/task?name=\" + task_name + \"&orderBy=taskId&desc=false\"\n    f_url = url + get_perf_task_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            perf_task_info = (json.loads(response.text))\n            if 'task' in perf_task_info:\n                perf_task_info = (json.loads(response.text))['task']\n            else:\n                perf_task_info = \"Task Doesn't Exist\"\n            return perf_task_info\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_perf_task: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to delete a Perf Task from the IMC RS.", "response": "def delete_perf_task(task_name, auth, url):\n    \"\"\"\n    Function takes a str of the target task_name to be deleted and retrieves task_id using\n    the get_perf_task function. Once the task_id has been successfully retrieved it is\n    populated into the task_id variable and an DELETE call is made against the HPE IMC REST\n    interface to delete the target task.\n    :param task_name: str of task name\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: int of 204 if successful, str of \"Perf Task doesn't exist\" i\n\n    :rtype: int\n\n    \"\"\"\n    task_id = get_perf_task(task_name, auth, url)\n    if isinstance(task_id, str):\n        print(\"Perf task doesn't exist\")\n        return 403\n    task_id = task_id['taskId']\n    get_perf_task_url = \"/imcrs/perf/task/delete/\" + str(task_id)\n    f_url = url + get_perf_task_url\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            print(\"Perf Task successfully delete\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' delete_perf_task: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a response from the API.", "response": "def process_json_response(self, response):\n        \"\"\"For a json response, check if there was any error and throw exception.\n        Otherwise, create a housecanary.response.Response.\"\"\"\n\n        response_json = response.json()\n\n        # handle errors\n        code_key = \"code\"\n        if code_key in response_json and response_json[code_key] != constants.HTTP_CODE_OK:\n            code = response_json[code_key]\n\n            message = response_json\n            if \"message\" in response_json:\n                message = response_json[\"message\"]\n            elif \"code_description\" in response_json:\n                message = response_json[\"code_description\"]\n\n            if code == constants.HTTP_FORBIDDEN:\n                raise housecanary.exceptions.UnauthorizedException(code, message)\n            if code == constants.HTTP_TOO_MANY_REQUESTS:\n                raise housecanary.exceptions.RateLimitException(code, message, response)\n            else:\n                raise housecanary.exceptions.RequestException(code, message)\n\n        request_url = response.request.url\n\n        endpoint_name = self._parse_endpoint_name_from_url(request_url)\n\n        return Response.create(endpoint_name, response_json, response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_watcher_thread(self):\n        # Create watcher thread\n        watcher_thread = threading.Thread(target=self.run_watcher)\n\n        # If the reload mode is `spawn_wait`\n        if self._reload_mode == self.RELOAD_MODE_V_SPAWN_WAIT:\n            # Use non-daemon thread\n            daemon = False\n\n        # If the reload mode is not `spawn_wait`\n        else:\n            # Use daemon thread\n            daemon = True\n\n        # Set whether the thread is daemon\n        watcher_thread.setDaemon(daemon)\n\n        # Start watcher thread\n        watcher_thread.start()\n\n        # Return watcher thread\n        return watcher_thread", "response": "Start the watcher thread."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_watch_paths(self):\n        # Add directory paths in `sys.path` to watch paths\n        watch_path_s = set(os.path.abspath(x) for x in sys.path)\n\n        # For each extra path\n        for extra_path in self._extra_paths or ():\n            # Get the extra path's directory path\n            extra_dir_path = os.path.dirname(os.path.abspath(extra_path))\n\n            # Add to watch paths\n            watch_path_s.add(extra_dir_path)\n\n        # For each module in `sys.modules`\n        for module in list(sys.modules.values()):\n            # Get module file path\n            module_path = getattr(module, '__file__', None)\n\n            # If have module file path\n            if module_path is not None:\n                # Get module directory path\n                module_dir_path = os.path.dirname(os.path.abspath(module_path))\n\n                # Add to watch paths\n                watch_path_s.add(module_dir_path)\n\n        # Find short paths of these watch paths.\n        # E.g. if both `/home` and `/home/aoik` exist, only keep `/home`.\n        watch_path_s = self._find_short_paths(watch_path_s)\n\n        # Return the watch paths\n        return watch_path_s", "response": "Find paths to watch."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_short_paths(self, paths):\n        # Split each path to parts.\n        # E.g. '/home/aoik' to ['', 'home', 'aoik']\n        path_parts_s = [path.split(os.path.sep) for path in paths]\n\n        # Root node\n        root_node = {}\n\n        # Sort these path parts by length, with the longest being the first.\n        #\n        # Longer paths appear first so that their extra parts are discarded\n        # when a shorter path is found at 5TQ8L.\n        #\n        # Then for each path's parts.\n        for parts in sorted(path_parts_s, key=len, reverse=True):\n            # Start from the root node\n            node = root_node\n\n            # For each part of the path\n            for part in parts:\n                # Create node of the path\n                node = node.setdefault(part, {})\n\n            # 5TQ8L\n            # Clear the last path part's node's child nodes.\n            #\n            # This aims to keep only the shortest path that needs be watched.\n            #\n            node.clear()\n\n        # Short paths\n        short_path_s = set()\n\n        # Collect leaf paths\n        self._collect_leaf_paths(\n            node=root_node,\n            path_parts=(),\n            leaf_paths=short_path_s,\n        )\n\n        # Return short paths\n        return short_path_s", "response": "Find short paths of given paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncollects paths of leaf nodes. :param node: Starting node. Type is dict. Key is child node's path part. Value is child node. :param path_parts: The starting node's path parts. Type is tuple. :param leaf_paths: Leaf path list. :return: None.", "response": "def _collect_leaf_paths(self, node, path_parts, leaf_paths):\n        \"\"\"\n        Collect paths of leaf nodes.\n\n        :param node:\n            Starting node. Type is dict.\n\n            Key is child node's path part. Value is child node.\n\n        :param path_parts:\n            The starting node's path parts. Type is tuple.\n\n        :param leaf_paths:\n            Leaf path list.\n\n        :return:\n            None.\n        \"\"\"\n        # If the node is leaf node\n        if not node:\n            # Get node path\n            node_path = '/'.join(path_parts)\n\n            # Add to list\n            leaf_paths.add(node_path)\n\n        # If the node is not leaf node\n        else:\n            # For each child node\n            for child_path_part, child_node in node.items():\n                # Get the child node's path parts\n                child_path_part_s = path_parts + (child_path_part,)\n\n                # Visit the child node\n                self._collect_leaf_paths(\n                    node=child_node,\n                    path_parts=child_path_part_s,\n                    leaf_paths=leaf_paths,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dispatch(self, event):\n        # Get file path\n        file_path = event.src_path\n\n        # If the file path is in extra paths\n        if file_path in self._extra_paths:\n            # Call `reload`\n            self.reload()\n\n        # If the file path ends with `.pyc` or `.pyo`\n        if file_path.endswith(('.pyc', '.pyo')):\n            # Get `.py` file path\n            file_path = file_path[:-1]\n\n        # If the file path ends with `.py`\n        if file_path.endswith('.py'):\n            # Get the file's directory path\n            file_dir = os.path.dirname(file_path)\n\n            # If the file's directory path starts with any of the watch paths\n            if file_dir.startswith(tuple(self._watch_paths)):\n                # Call `reload`\n                self.reload()", "response": "Dispatches the event object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reload(self):\n        # Get reload mode\n        reload_mode = self._reload_mode\n\n        # If reload mode is `exec`\n        if self._reload_mode == self.RELOAD_MODE_V_EXEC:\n            # Call `reload_using_exec`\n            self.reload_using_exec()\n\n        # If reload mode is `spawn_exit`\n        elif self._reload_mode == self.RELOAD_MODE_V_SPAWN_EXIT:\n            # Call `reload_using_spawn_exit`\n            self.reload_using_spawn_exit()\n\n        # If reload mode is `spawn_wait`\n        elif self._reload_mode == self.RELOAD_MODE_V_SPAWN_WAIT:\n            # Call `reload_using_spawn_wait`\n            self.reload_using_spawn_wait()\n\n        # If reload mode is none of above\n        else:\n            # Get error message\n            error_msg = 'Invalid reload mode: {}.'.format(repr(reload_mode))\n\n            # Raise error\n            raise ValueError(error_msg)", "response": "Reload the program.\n\n        :return:\n            None."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreloading the program process using the executable.", "response": "def reload_using_exec(self):\n        \"\"\"\n        Reload the program process.\n\n        :return:\n            None.\n        \"\"\"\n        # Create command parts\n        cmd_parts = [sys.executable] + sys.argv\n\n        # Get env dict copy\n        env_copy = os.environ.copy()\n\n        # Reload the program process\n        os.execvpe(\n            # Program file path\n            sys.executable,\n            # Command parts\n            cmd_parts,\n            # Env dict\n            env_copy,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns a subprocess and exit the current process.", "response": "def reload_using_spawn_exit(self):\n        \"\"\"\n        Spawn a subprocess and exit the current process.\n\n        :return:\n            None.\n        \"\"\"\n        # Create command parts\n        cmd_parts = [sys.executable] + sys.argv\n\n        # Get env dict copy\n        env_copy = os.environ.copy()\n\n        # Spawn subprocess\n        subprocess.Popen(cmd_parts, env=env_copy, close_fds=True)\n\n        # If need force exit\n        if self._force_exit:\n            # Force exit\n            os._exit(0)  # pylint: disable=protected-access\n\n        # If not need force exit\n        else:\n            # Send interrupt to main thread\n            interrupt_main()\n\n        # Set the flag\n        self._watcher_to_stop = True\n\n        # Exit the watcher thread\n        sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns a subprocess and wait until it finishes.", "response": "def reload_using_spawn_wait(self):\n        \"\"\"\n        Spawn a subprocess and wait until it finishes.\n\n        :return:\n            None.\n        \"\"\"\n        # Create command parts\n        cmd_parts = [sys.executable] + sys.argv\n\n        # Get env dict copy\n        env_copy = os.environ.copy()\n\n        # Send interrupt to main thread\n        interrupt_main()\n\n        # Spawn subprocess and wait until it finishes\n        subprocess.call(cmd_parts, env=env_copy, close_fds=True)\n\n        # Exit the watcher thread\n        sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef agent(agent_id):\n    '''\n    Show the information about the given agent.\n    '''\n    fields = [\n        ('ID', 'id'),\n        ('Status', 'status'),\n        ('Region', 'region'),\n        ('First Contact', 'first_contact'),\n        ('CPU Usage (%)', 'cpu_cur_pct'),\n        ('Used Memory (MiB)', 'mem_cur_bytes'),\n        ('Total slots', 'available_slots'),\n        ('Occupied slots', 'occupied_slots'),\n    ]\n    if is_legacy_server():\n        del fields[9]\n        del fields[6]\n    q = 'query($agent_id:String!) {' \\\n        '  agent(agent_id:$agent_id) { $fields }' \\\n        '}'\n    q = q.replace('$fields', ' '.join(item[1] for item in fields))\n    v = {'agent_id': agent_id}\n    with Session() as session:\n        try:\n            resp = session.Admin.query(q, v)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        info = resp['agent']\n        rows = []\n        for name, key in fields:\n            if key == 'mem_cur_bytes' and info[key] is not None:\n                info[key] = round(info[key] / 2 ** 20, 1)\n            if key in info:\n                rows.append((name, info[key]))\n        print(tabulate(rows, headers=('Field', 'Value')))", "response": "Show the information about the given agent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef agents(status, all):\n    '''\n    List and manage agents.\n    (admin privilege required)\n    '''\n    fields = [\n        ('ID', 'id'),\n        ('Status', 'status'),\n        ('Region', 'region'),\n        ('First Contact', 'first_contact'),\n        ('CPU Usage (%)', 'cpu_cur_pct'),\n        ('Used Memory (MiB)', 'mem_cur_bytes'),\n        ('Total slots', 'available_slots'),\n        ('Occupied slots', 'occupied_slots'),\n    ]\n    if is_legacy_server():\n        del fields[9]\n        del fields[6]\n\n    def execute_paginated_query(limit, offset):\n        try:\n            resp_agents = session.Agent.list_with_limit(\n                limit, offset, status, fields=(item[1] for item in fields))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        return resp_agents\n\n    def round_mem(results):\n        for item in results:\n            if 'mem_cur_bytes' in item and item['mem_cur_bytes'] is not None:\n                item['mem_cur_bytes'] = round(item['mem_cur_bytes'] / 2 ** 20, 1)\n        return results\n\n    def _generate_paginated_results(interval):\n        offset = 0\n        is_first = True\n        total_count = -1\n        while True:\n            limit = (interval if is_first else\n                    min(interval, total_count - offset))\n            try:\n                result = execute_paginated_query(limit, offset)\n            except Exception as e:\n                print_error(e)\n                sys.exit(1)\n            offset += interval\n            total_count = result['total_count']\n            items = result['items']\n            items = round_mem(items)\n            table = tabulate((item.values() for item in items),\n                                headers=(item[0] for item in fields))\n            if is_first:\n                is_first = False\n            else:\n                table_rows = table.split('\\n')\n                table = '\\n'.join(table_rows[2:])\n            yield table + '\\n'\n\n            if not offset < total_count:\n                break\n\n    with Session() as session:\n        paginating_interval = 10\n        if all:\n            click.echo_via_pager(_generate_paginated_results(paginating_interval))\n        else:\n            result = execute_paginated_query(paginating_interval, offset=0)\n            total_count = result['total_count']\n            if total_count == 0:\n                print('There are no matching agents.')\n                return\n            items = result['items']\n            items = round_mem(items)\n            fields = [field for field in fields if field[1] in items[0]]\n            print(tabulate((item.values() for item in items),\n                            headers=(item[0] for item in fields)))\n            if total_count > paginating_interval:\n                print(\"More agents can be displayed by using --all option.\")", "response": "Return a list of agents with the given status and all if all is True."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow details about a keypair resource policy.", "response": "def resource_policy(name):\n    \"\"\"\n    Show details about a keypair resource policy. When `name` option is omitted, the\n    resource policy for the current access_key will be returned.\n    \"\"\"\n    fields = [\n        ('Name', 'name'),\n        ('Created At', 'created_at'),\n        ('Default for Unspecified', 'default_for_unspecified'),\n        ('Total Resource Slot', 'total_resource_slots'),\n        ('Max Concurrent Sessions', 'max_concurrent_sessions'),\n        ('Max Containers per Session', 'max_containers_per_session'),\n        ('Max vFolder Count', 'max_vfolder_count'),\n        ('Max vFolder Size', 'max_vfolder_size'),\n        ('Idle Timeeout', 'idle_timeout'),\n        ('Allowed vFolder Hosts', 'allowed_vfolder_hosts'),\n    ]\n    with Session() as session:\n        try:\n            rp = session.ResourcePolicy(session.config.access_key)\n            info = rp.info(name, fields=(item[1] for item in fields))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        rows = []\n        if info is None:\n            print('No such resource policy.')\n            sys.exit(1)\n        for name, key in fields:\n            rows.append((name, info[key]))\n        print(tabulate(rows, headers=('Field', 'Value')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resource_policies(ctx):\n    '''\n    List and manage resource policies.\n    (admin privilege required)\n    '''\n    if ctx.invoked_subcommand is not None:\n        return\n    fields = [\n        ('Name', 'name'),\n        ('Created At', 'created_at'),\n        ('Default for Unspecified', 'default_for_unspecified'),\n        ('Total Resource Slot', 'total_resource_slots'),\n        ('Max Concurrent Sessions', 'max_concurrent_sessions'),\n        ('Max Containers per Session', 'max_containers_per_session'),\n        ('Max vFolder Count', 'max_vfolder_count'),\n        ('Max vFolder Size', 'max_vfolder_size'),\n        ('Idle Timeeout', 'idle_timeout'),\n        ('Allowed vFolder Hosts', 'allowed_vfolder_hosts'),\n    ]\n    with Session() as session:\n        try:\n            items = session.ResourcePolicy.list(fields=(item[1] for item in fields))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if len(items) == 0:\n            print('There are no keypair resource policies.')\n            return\n        print(tabulate((item.values() for item in items),\n                       headers=(item[0] for item in fields)))", "response": "List and manage resource policies."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new keypair resource policy.", "response": "def add(name, default_for_unspecified, total_resource_slots, max_concurrent_sessions,\n        max_containers_per_session, max_vfolder_count, max_vfolder_size,\n        idle_timeout, allowed_vfolder_hosts):\n    '''\n    Add a new keypair resource policy.\n\n    NAME: NAME of a new keypair resource policy.\n    '''\n    with Session() as session:\n        try:\n            data = session.ResourcePolicy.create(\n                name,\n                default_for_unspecified=default_for_unspecified,\n                total_resource_slots=total_resource_slots,\n                max_concurrent_sessions=max_concurrent_sessions,\n                max_containers_per_session=max_containers_per_session,\n                max_vfolder_count=max_vfolder_count,\n                max_vfolder_size=max_vfolder_size,\n                idle_timeout=idle_timeout,\n                allowed_vfolder_hosts=allowed_vfolder_hosts,\n            )\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if not data['ok']:\n            print_fail('KeyPair Resource Policy creation has failed: {0}'\n                       .format(data['msg']))\n            sys.exit(1)\n        item = data['resource_policy']\n        print('Keypair resource policy ' + item['name'] + ' is created.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a keypair resource policy.", "response": "def delete(name):\n    \"\"\"\n    Delete a keypair resource policy.\n\n    NAME: NAME of a keypair resource policy to delete.\n    \"\"\"\n    with Session() as session:\n        if input('Are you sure? (y/n): ').lower().strip()[:1] != 'y':\n            print('Canceled.')\n            sys.exit(1)\n        try:\n            data = session.ResourcePolicy.delete(name)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if not data['ok']:\n            print_fail('KeyPair Resource Policy deletion has failed: {0}'\n                       .format(data['msg']))\n            sys.exit(1)\n        print('Resource policy ' + name + ' is deleted.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a local proxy to a service provided by Backend.AI compute sessions. The type of proxy depends on the app definition: plain TCP or HTTP. \\b SESSID: The compute session ID. APP: The name of service provided by the given session.", "response": "def app(session_id, app, bind, port):\n    \"\"\"\n    Run a local proxy to a service provided by Backend.AI compute sessions.\n\n    The type of proxy depends on the app definition: plain TCP or HTTP.\n\n    \\b\n    SESSID: The compute session ID.\n    APP: The name of service provided by the given session.\n    \"\"\"\n    api_session = None\n    runner = None\n\n    async def app_setup():\n        nonlocal api_session, runner\n        loop = current_loop()\n        api_session = AsyncSession()\n        # TODO: generalize protocol using service ports metadata\n        protocol = 'http'\n        runner = ProxyRunner(api_session, session_id, app,\n                             protocol, bind, port,\n                             loop=loop)\n        await runner.ready()\n        print_info(\n            \"A local proxy to the application \\\"{0}\\\" \".format(app) +\n            \"provided by the session \\\"{0}\\\" \".format(session_id) +\n            \"is available at: {0}://{1}:{2}\"\n            .format(protocol, bind, port)\n        )\n\n    async def app_shutdown():\n        nonlocal api_session, runner\n        print_info(\"Shutting down....\")\n        await runner.close()\n        await api_session.close()\n        print_info(\"The local proxy to \\\"{}\\\" has terminated.\"\n                   .format(app))\n\n    asyncio_run_forever(app_setup(), app_shutdown(),\n                        stop_signals={signal.SIGINT, signal.SIGTERM})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a configuration value from the environment variables.", "response": "def get_env(key: str,\n            default: Any = None,\n            clean: Callable[[str], Any] = lambda v: v):\n    '''\n    Retrieves a configuration value from the environment variables.\n    The given *key* is uppercased and prefixed by ``\"BACKEND_\"`` and then\n    ``\"SORNA_\"`` if the former does not exist.\n\n    :param key: The key name.\n    :param default: The default value returned when there is no corresponding\n        environment variable.\n    :param clean: A single-argument function that is applied to the result of lookup\n        (in both successes and the default value for failures).\n        The default is returning the value as-is.\n\n    :returns: The value processed by the *clean* function.\n    '''\n    key = key.upper()\n    v = os.environ.get('BACKEND_' + key)\n    if v is None:\n        v = os.environ.get('SORNA_' + key)\n    if v is None:\n        if default is None:\n            raise KeyError(key)\n        v = default\n    return clean(v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing the output logs of a running container.", "response": "def logs(sess_id_or_alias):\n    '''\n    Shows the output logs of a running container.\n\n    \\b\n    SESSID: Session ID or its alias given when creating the session.\n    '''\n    with Session() as session:\n        try:\n            print_wait('Retrieving container logs...')\n            kernel = session.Kernel(sess_id_or_alias)\n            result = kernel.get_logs().get('result')\n            logs = result.get('logs') if 'logs' in result else ''\n            print(logs)\n            print_done('End of logs.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap the key from the function input.", "response": "def _wrap_key(function, args, kws):\n\t'''\n\tget the key from the function input.\n\t'''\n\treturn hashlib.md5(pickle.dumps((_from_file(function) + function.__name__, args, kws))).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(key, adapter = MemoryAdapter):\n\t'''\n\tget the cache value\n\t'''\n\ttry:\n\t\treturn pickle.loads(adapter().get(key))\n\texcept CacheExpiredException:\n\t\treturn None", "response": "get the cache value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(key, value, timeout = -1, adapter = MemoryAdapter):\n\t'''\n\tset cache by code, must set timeout length\n\t'''\n\tif adapter(timeout = timeout).set(key, pickle.dumps(value)):\n\t\treturn value\n\telse:\n\t\treturn None", "response": "set a value in the cache by code"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrapcache(timeout = -1, adapter = MemoryAdapter):\n\t'''\n\tthe Decorator to cache Function.\n\t'''\n\tdef _wrapcache(function):\n\t\t@wraps(function)\n\t\tdef __wrapcache(*args, **kws):\n\t\t\thash_key = _wrap_key(function, args, kws)\n\t\t\ttry:\n\t\t\t\tadapter_instance = adapter()\n\t\t\t\treturn pickle.loads(adapter_instance.get(hash_key))\n\t\t\texcept CacheExpiredException:\n\t\t\t\t#timeout\n\t\t\t\tvalue = function(*args, **kws)\n\t\t\t\tset(hash_key, value, timeout, adapter)\n\t\t\t\treturn value\n\t\treturn __wrapcache\n\treturn _wrapcache", "response": "Decorator to cache a function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an Excel file containing data returned by the Analytics API and saves it to a file.", "response": "def export_analytics_data_to_excel(data, output_file_name, result_info_key, identifier_keys):\n    \"\"\"Creates an Excel file containing data returned by the Analytics API\n\n    Args:\n        data: Analytics API data as a list of dicts\n        output_file_name: File name for output Excel file (use .xlsx extension).\n\n    \"\"\"\n    workbook = create_excel_workbook(data, result_info_key, identifier_keys)\n    workbook.save(output_file_name)\n    print('Saved Excel file to {}'.format(output_file_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export_analytics_data_to_csv(data, output_folder, result_info_key, identifier_keys):\n    workbook = create_excel_workbook(data, result_info_key, identifier_keys)\n\n    suffix = '.csv'\n\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    for worksheet in workbook.worksheets:\n        file_name = utilities.convert_title_to_snake_case(worksheet.title)\n\n        file_path = os.path.join(output_folder, file_name + suffix)\n\n        mode = 'w'\n        if sys.version_info[0] < 3:\n            mode = 'wb'\n        with io.open(file_path, mode) as output_file:\n            csv_writer = csv.writer(output_file)\n            for row in worksheet.rows:\n                csv_writer.writerow([cell.value for cell in row])\n\n    print('Saved CSV files to {}'.format(output_folder))", "response": "Creates a CSV file containing data returned by the Analytics API and saves it into the specified output_folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an Excel file made up of combining the Value Report or Rental Report Excel output for the provided addresses. Args: addresses: A list of (address, zipcode) tuples output_file_name: A file name for the Excel output endpoint: One of 'value_report' or 'rental_report' report_type: One of 'full' or 'summary' retry: optional boolean to retry if rate limit is reached api_key: optional API Key api_secret: optional API Secret files_path: Path to save individual files. If None, don't save files", "response": "def concat_excel_reports(addresses, output_file_name, endpoint, report_type,\n                         retry, api_key, api_secret, files_path):\n    \"\"\"Creates an Excel file made up of combining the Value Report or Rental Report Excel\n       output for the provided addresses.\n\n    Args:\n        addresses: A list of (address, zipcode) tuples\n        output_file_name: A file name for the Excel output\n        endpoint: One of 'value_report' or 'rental_report'\n        report_type: One of 'full' or 'summary'\n        retry: optional boolean to retry if rate limit is reached\n        api_key: optional API Key\n        api_secret: optional API Secret\n        files_path: Path to save individual files. If None, don't save files\n    \"\"\"\n    # create the master workbook to output\n    master_workbook = openpyxl.Workbook()\n\n    if api_key is not None and api_secret is not None:\n        client = ApiClient(api_key, api_secret)\n    else:\n        client = ApiClient()\n\n    errors = []\n\n    # for each address, call the API and load the xlsx content in a workbook.\n    for index, addr in enumerate(addresses):\n        print('Processing {}'.format(addr[0]))\n        result = _get_excel_report(\n            client, endpoint, addr[0], addr[1], report_type, retry)\n\n        if not result['success']:\n            print('Error retrieving report for {}'.format(addr[0]))\n            print(result['content'])\n            errors.append({'address': addr[0], 'message': result['content']})\n            continue\n\n        orig_wb = openpyxl.load_workbook(filename=io.BytesIO(result['content']))\n\n        _save_individual_file(orig_wb, files_path, addr[0])\n\n        # for each worksheet for this address\n        for sheet_name in orig_wb.get_sheet_names():\n            # if worksheet doesn't exist in master workbook, create it\n            if sheet_name in master_workbook.get_sheet_names():\n                master_ws = master_workbook.get_sheet_by_name(sheet_name)\n            else:\n                master_ws = master_workbook.create_sheet(sheet_name)\n\n            # get all the rows in the address worksheet\n            orig_rows = orig_wb.get_sheet_by_name(sheet_name).rows\n\n            if sheet_name == 'Summary' or sheet_name == 'Chart Data':\n                _process_non_standard_sheet(master_ws, orig_rows, addr, index)\n                continue\n\n            _process_standard_sheet(master_ws, orig_rows, addr, index)\n\n    # remove the first sheet which will be empty\n    master_workbook.remove(master_workbook.worksheets[0])\n\n    # if any errors occurred, write them to an \"Errors\" worksheet\n    if len(errors) > 0:\n        errors_sheet = master_workbook.create_sheet('Errors')\n        for error_idx, error in enumerate(errors):\n            errors_sheet.cell(row=error_idx+1, column=1, value=error['address'])\n            errors_sheet.cell(row=error_idx+1, column=2, value=error['message'])\n\n    # save the master workbook to output_file_name\n    adjust_column_width_workbook(master_workbook)\n    output_file_path = os.path.join(files_path, output_file_name)\n    master_workbook.save(output_file_path)\n    print('Saved output to {}'.format(output_file_path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_excel_workbook(data, result_info_key, identifier_keys):\n    workbook = analytics_data_excel.get_excel_workbook(data, result_info_key, identifier_keys)\n    adjust_column_width_workbook(workbook)\n    return workbook", "response": "Creates the Excel Workbook"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadjusts column width in the specified worksheet.", "response": "def adjust_column_width(worksheet):\n    \"\"\"Adjust column width in worksheet.\n\n    Args:\n        worksheet: worksheet to be adjusted\n    \"\"\"\n    dims = {}\n    padding = 1\n    for row in worksheet.rows:\n        for cell in row:\n            if not cell.value:\n                continue\n            dims[cell.column] = max(\n                dims.get(cell.column, 0),\n                len(str(cell.value))\n            )\n    for col, value in list(dims.items()):\n        worksheet.column_dimensions[col].width = value + padding"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ap_info(ipaddress, auth, url):\n    get_ap_info_url = \"/imcrs/wlan/apInfo/queryApBasicInfoByCondition?ipAddress=\" + str(ipaddress)\n    f_url = url + get_ap_info_url\n    payload = None\n    r = requests.get(f_url, auth=auth,\n                     headers=HEADERS)  # creates the URL using the payload variable as the contents\n    # print(r.status_code)\n    try:\n        if r.status_code == 200:\n            if len(r.text) > 0:\n                return json.loads(r.text)['apBasicInfo']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_ap_info_all: An Error has occured\"", "response": "This function returns the details of the target access point at time of query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of compute sessions.", "response": "def sessions(status, access_key, id_only, all):\n    '''\n    List and manage compute sessions.\n    '''\n    fields = [\n        ('Session ID', 'sess_id'),\n    ]\n    with Session() as session:\n        if is_admin(session):\n            fields.append(('Owner', 'access_key'))\n    if not id_only:\n        fields.extend([\n            ('Image', 'image'),\n            ('Tag', 'tag'),\n            ('Created At', 'created_at',),\n            ('Terminated At', 'terminated_at'),\n            ('Status', 'status'),\n            ('Occupied Resource', 'occupied_slots'),\n            ('Used Memory (MiB)', 'mem_cur_bytes'),\n            ('Max Used Memory (MiB)', 'mem_max_bytes'),\n            ('CPU Using (%)', 'cpu_using'),\n        ])\n        if is_legacy_server():\n            del fields[2]\n\n    def execute_paginated_query(limit, offset):\n        q = '''\n        query($limit:Int!, $offset:Int!, $ak:String, $status:String) {\n          compute_session_list(\n              limit:$limit, offset:$offset, access_key:$ak, status:$status) {\n            items { $fields }\n            total_count\n          }\n        }'''\n        q = textwrap.dedent(q).strip()\n        q = q.replace('$fields', ' '.join(item[1] for item in fields))\n        v = {\n            'limit': limit,\n            'offset': offset,\n            'status': status if status != 'ALL' else None,\n            'ak': access_key,\n        }\n        try:\n            resp = session.Admin.query(q, v)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        return resp['compute_session_list']\n\n    def round_mem(items):\n        for item in items:\n            if 'mem_cur_bytes' in item:\n                item['mem_cur_bytes'] = round(item['mem_cur_bytes'] / 2 ** 20, 1)\n            if 'mem_max_bytes' in item:\n                item['mem_max_bytes'] = round(item['mem_max_bytes'] / 2 ** 20, 1)\n        return items\n\n    def _generate_paginated_results(interval):\n        offset = 0\n        is_first = True\n        total_count = -1\n        while True:\n            limit = (interval if is_first else\n                    min(interval, total_count - offset))\n            try:\n                result = execute_paginated_query(limit, offset)\n            except Exception as e:\n                print_error(e)\n                sys.exit(1)\n            offset += interval\n            total_count = result['total_count']\n            items = result['items']\n            items = round_mem(items)\n\n            if id_only:\n                yield '\\n'.join([item['sess_id'] for item in items]) + '\\n'\n            else:\n                table = tabulate([item.values() for item in items],\n                                    headers=(item[0] for item in fields))\n                if not is_first:\n                    table_rows = table.split('\\n')\n                    table = '\\n'.join(table_rows[2:])\n                yield table + '\\n'\n\n            if is_first:\n                is_first = False\n            if not offset < total_count:\n                break\n\n    with Session() as session:\n        paginating_interval = 10\n        if all:\n            click.echo_via_pager(_generate_paginated_results(paginating_interval))\n        else:\n            result = execute_paginated_query(paginating_interval, offset=0)\n            total_count = result['total_count']\n            if total_count == 0:\n                print('There are no compute sessions currently {0}.'\n                      .format(status.lower()))\n                return\n            items = result['items']\n            items = round_mem(items)\n            if id_only:\n                for item in items:\n                    print(item['sess_id'])\n            else:\n                print(tabulate([item.values() for item in items],\n                                headers=(item[0] for item in fields)))\n            if total_count > paginating_interval:\n                print(\"More sessions can be displayed by using --all option.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow detailed information for a running compute session.", "response": "def session(sess_id_or_alias):\n    '''\n    Show detailed information for a running compute session.\n\n    SESSID: Session id or its alias.\n    '''\n    fields = [\n        ('Session ID', 'sess_id'),\n        ('Role', 'role'),\n        ('Image', 'image'),\n        ('Tag', 'tag'),\n        ('Created At', 'created_at'),\n        ('Terminated At', 'terminated_at'),\n        ('Agent', 'agent'),\n        ('Status', 'status'),\n        ('Status Info', 'status_info'),\n        ('Occupied Resources', 'occupied_slots'),\n        ('CPU Used (ms)', 'cpu_used'),\n        ('Used Memory (MiB)', 'mem_cur_bytes'),\n        ('Max Used Memory (MiB)', 'mem_max_bytes'),\n        ('Number of Queries', 'num_queries'),\n        ('Network RX Bytes', 'net_rx_bytes'),\n        ('Network TX Bytes', 'net_tx_bytes'),\n        ('IO Read Bytes', 'io_read_bytes'),\n        ('IO Write Bytes', 'io_write_bytes'),\n        ('IO Max Scratch Size', 'io_max_scratch_size'),\n        ('IO Current Scratch Size', 'io_cur_scratch_size'),\n        ('CPU Using (%)', 'cpu_using'),\n    ]\n    if is_legacy_server():\n        del fields[3]\n    q = 'query($sess_id:String) {' \\\n        '  compute_session(sess_id:$sess_id) { $fields }' \\\n        '}'\n    q = q.replace('$fields', ' '.join(item[1] for item in fields))\n    v = {'sess_id': sess_id_or_alias}\n    with Session() as session:\n        try:\n            resp = session.Admin.query(q, v)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if resp['compute_session']['sess_id'] is None:\n            print('There is no such running compute session.')\n            return\n        print('Session detail:\\n---------------')\n        for i, value in enumerate(resp['compute_session'].values()):\n            if fields[i][1] in ['mem_cur_bytes', 'mem_max_bytes']:\n                value = round(value / 2 ** 20, 1)\n            print(fields[i][0] + ': ' + str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new instance of the correct type of Response based on the data.", "response": "def create(cls, endpoint_name, json_body, original_response):\n        \"\"\"Factory for creating the correct type of Response based on the data.\n        Args:\n            endpoint_name (str) - The endpoint of the request, such as \"property/value\"\n            json_body - The response body in json format.\n            original_response (response object) - server response returned from an http request.\n        \"\"\"\n\n        if endpoint_name == \"property/value_report\":\n            return ValueReportResponse(endpoint_name, json_body, original_response)\n\n        if endpoint_name == \"property/rental_report\":\n            return RentalReportResponse(endpoint_name, json_body, original_response)\n\n        prefix = endpoint_name.split(\"/\")[0]\n\n        if prefix == \"block\":\n            return BlockResponse(endpoint_name, json_body, original_response)\n\n        if prefix == \"zip\":\n            return ZipCodeResponse(endpoint_name, json_body, original_response)\n\n        if prefix == \"msa\":\n            return MsaResponse(endpoint_name, json_body, original_response)\n\n        return PropertyResponse(endpoint_name, json_body, original_response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of business error messages strings for each of the requested objects that had a business error. Returns an empty list if there was no error.", "response": "def get_object_errors(self):\n        \"\"\"Gets a list of business error message strings\n        for each of the requested objects that had a business error.\n        If there was no error, returns an empty list\n\n        Returns:\n            List of strings\n        \"\"\"\n        if self._object_errors is None:\n            self._object_errors = [{str(o): o.get_errors()}\n                                   for o in self.objects()\n                                   if o.has_error()]\n\n        return self._object_errors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true if any requested object had a business logic error code.", "response": "def has_object_error(self):\n        \"\"\"Returns true if any requested object had a business logic error,\n        otherwise returns false\n\n        Returns:\n            boolean\n        \"\"\"\n        if self._has_object_error is None:\n            # scan the objects for any business error codes\n            self._has_object_error = next(\n                (True for o in self.objects()\n                 if o.has_error()),\n                False)\n        return self._has_object_error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of rate limit details.", "response": "def rate_limits(self):\n        \"\"\"Returns a list of rate limit details.\"\"\"\n        if not self._rate_limits:\n            self._rate_limits = utilities.get_rate_limits(self.response)\n\n        return self._rate_limits"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_imc_creds(auth, url):\n    test_url = '/imcrs'\n    f_url = url + test_url\n    try:\n        response = requests.get(f_url, auth=auth, headers=HEADERS, verify=False)\n        return bool(response.status_code == 200)\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" test_imc_creds: An Error has occured\"", "response": "Function takes input of auth class object auth object and URL and returns a BOOL of TRUE\n     if the authentication was successful."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_to_file(object_name):\n    with open('pyoutput.txt', 'w') as filehandler:\n        output = None\n        if isinstance(object_name, list):\n            output = json.dumps(object, indent=4)\n        if isinstance(object_name, dict):\n            output = json.dumps(object, indent=4)\n        if isinstance(object_name, str):\n            output = object_name\n        filehandler.write(output)", "response": "Function prints out to file handler and saves to current working directory as pyoutput. txt\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_auth(self):\n        url = self.h_url + self.server + \":\" + self.port\n        auth = requests.auth.HTTPDigestAuth(self.username, self.password)\n        f_url = url + \"/imcrs\"\n        try:\n            response = requests.get(f_url, auth=auth, headers=HEADERS, verify=False)\n            if response.status_code != 200:  # checks for valid IMC credentials\n                print(\"Error:\\n\" + \"Error: \\n You're credentials are invalid. Please try again\\n\\n\")\n                set_imc_creds()\n            return response.status_code\n        except requests.exceptions.RequestException as error:\n            return \"Error:\\n\" + str(error) + 'The IMC server address is invalid. Please try again'", "response": "This method requests an authentication object from the HPE IMC NMS and returns an HTTPDigest Auth Object containing the ID of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_title(title, is_end=False):\n    # If is end title\n    if is_end:\n        # Use `=`\n        sep = '====='\n\n    # If is not end title\n    else:\n        # Use `-`\n        sep = '-----'\n\n    # If is not end title\n    if not is_end:\n        # Print an empty line for visual comfort\n        print_text()\n\n    # Print the title, e.g. `----- {title} -----`\n    print_text('# {sep} {title} {sep}'.format(title=title, sep=sep))", "response": "Print a title in a sequence of words."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_full_python_version():\n    # Get version part, e.g. `3.5.1.final.0`\n    version_part = '.'.join(str(x) for x in sys.version_info)\n\n    # Get integer width, e.g. 32 or 64\n    int_width = struct.calcsize('P') * 8\n\n    # Get integer width part, e.g. `64bit` or `32bit`\n    int_width_part = str(int_width) + 'bit'\n\n    # Return full Python version\n    return version_part + '.' + int_width_part", "response": "Get full Python version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting given virtual environment s python program path.", "response": "def get_python_path(venv_path):\n    \"\"\"\n    Get given virtual environment's `python` program path.\n\n    :param venv_path: Virtual environment directory path.\n\n    :return: `python` program path.\n    \"\"\"\n    # Get `bin` directory path\n    bin_path = get_bin_path(venv_path)\n\n    # Get `python` program path\n    program_path = os.path.join(bin_path, 'python')\n\n    # If the platform is Windows\n    if sys.platform.startswith('win'):\n        # Add `.exe` suffix to the `python` program path\n        program_path = program_path + '.exe'\n\n    # Return the `python` program path\n    return program_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_options(ctx):\n    # Add option\n    ctx.add_option(\n        '--always',\n        action='store_true',\n        default=False,\n        dest='always',\n        help='whether always run tasks.',\n    )\n\n    # Add option\n    ctx.add_option(\n        '--check-import',\n        action='store_true',\n        default=False,\n        dest='check_import',\n        help='whether import module for dirty checking.',\n    )\n\n    # Add option\n    ctx.add_option(\n        '--venv',\n        dest='venv',\n        help=(\n            'virtual environment directory relative path relative to top'\n            ' directory.'\n        ),\n    )\n\n    # Add option\n    ctx.add_option(\n        '--venv-add-version',\n        default='1',\n        dest='venv_add_version',\n        # Convert to int so that the value can be used as boolean\n        type=int,\n        metavar='0|1',\n        help=(\n            'whether add full Python version to virtual environment directory'\n            ' name. E.g. `.py3.5.1.final.0.64bit`. Default is add.'\n        ),\n    )\n\n    # Add option\n    ctx.add_option(\n        '--req',\n        default=None,\n        dest='req_path',\n        help='requirements file relative path relative to top directory.',\n    )", "response": "Add command line options."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds given path to PYTHONPATH environment variable.", "response": "def add_pythonpath(path):\n    \"\"\"\n    Prepend given path to environment variable PYTHONPATH.\n\n    :param path: Path to add to PYTHONPATH.\n\n    :return: New PYTHONPATH value.\n    \"\"\"\n    # Get PYTHONPATH value. Default is empty string.\n    pythonpath = os.environ.setdefault('PYTHONPATH', '')\n\n    # If given path is not in PYTHONPATH\n    if path not in pythonpath.split(os.pathsep):\n        # Prepend given path to PYTHONPATH\n        pythonpath = os.environ['PYTHONPATH'] = \\\n            (path + os.pathsep + pythonpath) if pythonpath else path\n\n    # Return new PYTHONPATH value\n    return pythonpath"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mark_path(path):\n    # If given path is not string,\n    # or given path is absolute path.\n    if not isinstance(path, str) or os.path.isabs(path):\n        # Get error message\n        msg = 'Error (2D9ZA): Given path is not relative path: {0}.'.format(\n            path\n        )\n\n        # Raise error\n        raise ValueError(msg)\n\n    # If given path is string,\n    # and given path is not absolute path.\n\n    # Wrap given path\n    return _ItemWrapper(type='path', item=path)", "response": "Wrap given path as relative path relative to top directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap given item as input or output target that should be added to task.", "response": "def _mark_target(type, item):\n    \"\"\"\n    Wrap given item as input or output target that should be added to task.\n\n    Wrapper object will be handled specially in \\\n    :paramref:`create_cmd_task.parts`.\n\n    :param type: Target type.\n\n        Allowed values:\n            - 'input'\n            - 'output'\n\n    :param item: Item to mark as input or output target.\n\n        Allowed values:\n            - Relative path relative to top directory.\n            - Node object.\n            - List of these.\n\n    :return: Wrapper object.\n    \"\"\"\n    # If given type is not valid\n    if type not in ('input', 'output'):\n        # Get error message\n        msg = 'Error (7D74X): Type is not valid: {0}'.format(type)\n\n        # Raise error\n        raise ValueError(msg)\n\n    # If given type is valid.\n\n    # Store given item\n    orig_item = item\n\n    # If given path is list\n    if isinstance(item, list):\n        # Use it as items list\n        item_s = item\n\n    # If given path is not list\n    else:\n        # Create items list containing given path\n        item_s = [item]\n\n    # For the items list's each item\n    for item in item_s:\n        # If the item is string,\n        # and the item is absolute path.\n        if isinstance(item, str) and os.path.isabs(item):\n            # Get error message\n            msg = (\n                'Error (5VWOZ): Given path is not relative path: {0}.'\n            ).format(item)\n\n            # Raise error\n            raise ValueError(msg)\n\n    # Wrap given item\n    return _ItemWrapper(type=type, item=orig_item)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_node(ctx, path):\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # Get top directory's relative path relative to `wscript` directory\n    top_dir_relpath = os.path.relpath(\n        # Top directory's absolute path\n        ctx.top_dir,\n        # `wscript` directory's absolute path\n        ctx.run_dir,\n    )\n\n    # Convert given relative path to be relative to `wscript` directory\n    node_path = os.path.join(top_dir_relpath, path)\n\n    # Create node using the relative path relative to `wscript` directory\n    node = ctx.path.make_node(node_path)\n\n    # Return the created node\n    return node", "response": "Create a node for given relative path relative to the top directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _normalize_items(\n    ctx,\n    items,\n    str_to_node=False,\n    node_to_str=False,\n    allow_task=False,\n):\n    \"\"\"\n    Normalize given items.\n\n    Do several things:\n        - Ignore None.\n        - Flatten list.\n        - Unwrap wrapped item in `_ItemWrapper`.\n\n    :param ctx: BuildContext object.\n\n    :param items: Items list to normalize.\n\n    :param str_to_node: Convert string to node.\n\n    :param node_to_str: Convert node to absolute path.\n\n    :param allow_task: Whether allow task item.\n\n    :return: Normalized tuples list.\n\n        Tuple format is:\n        ::\n\n            (\n                normalized_item,        # Normalized item.\n                wrapper_type,           # Original `_ItemWrapper` type.\n            )\n    \"\"\"\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # Normalized tuples list\n    norm_tuple_s = []\n\n    # If given items list is empty\n    if not items:\n        # Return empty list\n        return norm_tuple_s\n\n    # If given items list is not empty.\n\n    # For given items list's each item\n    for item in items:\n        # If the item is item wrapper\n        if isinstance(item, _ItemWrapper):\n            # Get wrapper type\n            wrapper_type = item.type()\n\n            # Get real item\n            item = item.item()\n\n        # If the item is not item wrapper\n        else:\n            # Set wrapper type be None\n            wrapper_type = None\n\n            # Use the item as real item\n            item = item\n\n        # If the real item is list\n        if isinstance(item, list):\n            # Use the real item as real items list\n            real_item_s = item\n\n        # If the real item is not list\n        else:\n            # Create real items list containing the real item\n            real_item_s = [item]\n\n        # For each real item\n        for real_item in real_item_s:\n            # If the real item is None\n            if real_item is None:\n                # Ignore None\n                continue\n\n            # If the real item is not None.\n\n            # If the real item is string\n            elif isinstance(real_item, str):\n                # If need convert string to node\n                if (wrapper_type is not None) or str_to_node:\n                    # If the path string is absolute path\n                    if os.path.isabs(real_item):\n                        # Get error message\n                        msg = (\n                            'Error (7MWU9): Given path is not relative path:'\n                            ' {0}.'\n                        ).format(real_item)\n\n                        # Raise error\n                        raise ValueError(msg)\n\n                    # If the path string is not absolute path.\n\n                    # Create node as normalized item\n                    norm_item = create_node(ctx, real_item)\n\n                    # If need convert node to absolute path\n                    if node_to_str:\n                        # Convert the node to absolute path\n                        norm_item = norm_item.abspath()\n\n                # If not need convert string to node\n                else:\n                    # Use the string as normalized item\n                    norm_item = real_item\n\n                # Create normalized tuple\n                norm_tuple = (norm_item, wrapper_type)\n\n            # If the real item is not string.\n\n            # If the real item is node\n            elif isinstance(real_item, Node):\n                # If need convert node to absolute path\n                if node_to_str:\n                    # Convert the node to absolute path\n                    real_item = real_item.abspath()\n\n                # Create normalized tuple\n                norm_tuple = (real_item, wrapper_type)\n\n            # If the real item is not node.\n\n            # If the real item is task\n            elif isinstance(real_item, Task):\n                # If allow task item\n                if allow_task:\n                    # Create normalized tuple\n                    norm_tuple = (real_item, wrapper_type)\n\n                # If not allow task item\n                else:\n                    # Get error message\n                    msg = 'Error (6PVMG): Item type is not valid: {0}.'.format(\n                        real_item\n                    )\n\n                    # Raise error\n                    raise ValueError(msg)\n\n            # If the real item is not task.\n\n            # If the real item is not None, string, node, or task\n            else:\n                # Get error message\n                msg = 'Error (63KUG): Item type is not valid: {0}.'.format(\n                    real_item\n                )\n\n                # Raise error\n                raise ValueError(msg)\n\n            # Add the normalized tuple to list\n            norm_tuple_s.append(norm_tuple)\n\n    # Return the normalized tuples list\n    return norm_tuple_s", "response": "Normalizes given items list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the touch file at given path.", "response": "def update_touch_file(\n    ctx,\n    path,\n    check_import=False,\n    check_import_module=None,\n    check_import_python=None,\n    always=False,\n):\n    \"\"\"\n    Update touch file at given path.\n\n    Do two things:\n        - Create touch file if it not exists.\n        - Update touch file if import checking fails.\n\n    The returned touch file node is used as task's output target for dirty\n    checking. Task will run if the touch file changes.\n\n    :param ctx: BuildContext instance.\n\n    :param path: Touch file relative path relative to top directory.\n\n    :param check_import: Whether import module for dirty checking.\n\n    :param check_import_module: Module name to import for dirty checking.\n\n    :param check_import_python: Python program to use for dirty checking.\n\n    :param always: Whether always run.\n\n    :return: A two-item tuple.\n\n        Tuple format is:\n        ::\n\n            (\n                touch_file_node,        # Touch file node.\n                task_needs_run,         # Whether task needs run.\n            )\n    \"\"\"\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # Print title\n    print_title('Update touch file: {}'.format(path))\n\n    # Create touch node\n    touch_node = create_node(ctx, path)\n\n    # Whether task needs run\n    need_run = False\n\n    # If the touch file not exists,\n    # or `always` flag is on.\n    if not touch_node.exists() or always:\n        # Set `need_run` flag on\n        need_run = True\n\n    # If the touch file exists,\n    # and `always` flag is off.\n    else:\n        # If need import module for dirty checking,\n        # and module name to import is given.\n        if check_import and check_import_module:\n            # Get import statement.\n            # Notice `from` import ensures the imported module is not imported\n            # as `__main__` module. And `__name__` exists in any module.\n            import_stmt = 'from {} import __name__'.format(check_import_module)\n\n            # Print info\n            print_text('Check import: {}'.format(import_stmt))\n\n            # If Python program to check import is not given\n            if check_import_python is None:\n                # Get error message\n                msg = (\n                    'Error (3BKFW): Python program to check import is not'\n                    ' given.'\n                )\n\n                # Raise error\n                raise ValueError(msg)\n\n            # If Python program to check import is given.\n\n            # Normalize given Python program path\n            check_import_python, _ = _normalize_items(\n                ctx=ctx,\n                items=[check_import_python],\n                # Convert node to absolute path\n                node_to_str=True,\n            )[0]\n\n            # If the Python program path is not string\n            if not isinstance(check_import_python, str):\n                # Get error message\n                msg = (\n                    'Error (39FQE): Given Python program to check import is'\n                    ' not string or node: {0}.'\n                ).format(check_import_python)\n\n                # Raise error\n                raise ValueError(msg)\n\n            # If the Python program path is string.\n\n            # If the Python program path is not absolute path\n            if not os.path.isabs(check_import_python):\n                # Convert the Python program path to absolute path\n                check_import_python = \\\n                    create_node(ctx, check_import_python).abspath()\n\n            # The Python program path is absolute path now.\n\n            # Get command parts\n            cmd_part_s = [\n                # Python program absolute path\n                check_import_python,\n\n                # Run code\n                '-c',\n\n                # Code to run\n                import_stmt\n            ]\n\n            # Print the command in multi-line format\n            print_text(_format_multi_line_command(cmd_part_s))\n\n            #\n            try:\n                # Run the command\n                subprocess.check_output(cmd_part_s)\n\n                # If not have error,\n                # it means the module can be imported.\n                #     Set `need_run` flag off.\n                need_run = False\n\n            # If have error,\n            # it means the module can not be imported.\n            #\n            # Notice the program may not exist. So catch general exception.\n            except Exception:  # pylint: disable=W0703\n                # Set `need_run` flag on\n                need_run = True\n\n    # If task needs run\n    if need_run:\n        # If the touch file's parent directory not exists\n        if not touch_node.parent.exists():\n            # Create the touch file's parent directory\n            touch_node.parent.mkdir()\n\n        # Write current time to the touch file to force content change.\n        # This will fail dirty-checking and cause task to run.\n        touch_node.write('{0}\\n'.format(datetime.utcnow()))\n\n        # Print info\n        print_text('Updated.')\n\n    # If task not needs run\n    else:\n        # Print info\n        print_text('Skipped.')\n\n    # Print end title\n    print_title('Update touch file: {}'.format(path), is_end=True)\n\n    # Return a two-item tuple\n    return touch_node, need_run"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chain_tasks(tasks):\n    # If given tasks list is not empty\n    if tasks:\n        # Previous task\n        previous_task = None\n\n        # For given tasks list's each task\n        for task in tasks:\n            # If the task is not None.\n            # Task can be None to allow code like ``task if _PY2 else None``.\n            if task is not None:\n                # If previous task is not None\n                if previous_task is not None:\n                    # Set the task to run after the previous task\n                    task.set_run_after(previous_task)\n\n                # Set the task as previous task for the next task\n                previous_task = task\n\n    # Return given tasks list.\n    return tasks", "response": "Chain given tasks. Set each task to run after its previous task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_cmd_task(\n    ctx,\n    parts,\n    inputs=None,\n    outputs=None,\n    env=None,\n    cwd=None,\n    task_name=None,\n    cache_key=None,\n    always=False,\n    add_to_group=True,\n):\n    \"\"\"\n    Create task that runs given command.\n\n    :param ctx: BuildContext object.\n\n    :param parts: Command parts list.\n\n        Each part can be:\n            - **None**: Will be ignored.\n            - **String**: Will be used as-is.\n            - **Node object**: Will be converted to absolute path.\n            - **List of these**: Will be flattened.\n            - **Item wrapper of these**: Will be unwrapped. Item marked as\n              input or output target will be added to created task.\n\n    :param inputs: Input items list to add to created task.\n\n        Each item can be:\n            - **None**: Will be ignored.\n            - **Path**: Relative path relative to top directory. Will be\n              converted to node.\n            - **Node object**: Will be used as-is.\n            - **Task object**: Will set created task to run after the task.\n            - **List of these**: Will be flattened.\n            - **Item wrapper of these**: Will be unwrapped.\n\n    :param outputs: Outputs items list to add to created task.\n\n        Each item can be:\n            - **None**: Will be ignored.\n            - **Path**: Relative path relative to top directory. Will be\n              converted to node.\n            - **Node object**: Will be used as-is.\n            - **Task object**: Will set the task to run after created task.\n            - **List of these**: Will be flattened.\n            - **Item wrapper of these**: Will be unwrapped.\n\n    :param env: Environment dict.\n\n        Default is use given context object's environment dict.\n\n    :param cwd: Working directory in which to run given command.\n\n        Default is top directory.\n\n    :param task_name: Task name for display purpose.\n\n        Default is use the caller function's name.\n\n    :param cache_key: Task cache key.\n\n    :param always: Whether mark created task as always run.\n\n    :param add_to_group: Whether add created task to given context.\n\n    :return: Created task.\n\n    :notes:\n        It is recommended to refer to files inside project using relative\n        paths. This is even required if the files are used as task's input or\n        output targets.\n\n        It is not ideal to make relative paths relative to current working\n        directory, or relative to `wscript` file, because neither of the two\n        choices guarantee a fixed start directory.\n\n        It is not ideal to let `Waf` resolve relative paths neither, because\n        the start directory used for resolving relative paths varies with\n        different types of command context (i.e. OptionsContext,\n        ConfigurationContext, BuildContext, and Context).\n\n        It is best to make relative paths relative to project's top directory.\n        To do so, first use `Waf`'s pre-defined path variable `top` to locate\n        project's top directory (Notice path variable `top`'s value is relative\n        to `wscript` file.). Then `aoikwafutil`'s functions like\n        `create_cmd_task` will use path variable `top`'s value to resolve other\n        relative paths.\n\n        `create_cmd_task` handles relative paths using rules below:\n\n            - Relative paths marked by `mark_path`, `mark_input`, or\n              `mark_output` are relative to top directory.\n\n            - Relative paths passed to argument `parts` are used as-is. They\n              are relative to the working directory in which to run the\n              command. However, they can be marked to be relative to top\n              directory instead.\n\n            - Relative paths passed to argument `inputs` or `outputs` are\n              relative to top directory. They need not be marked.\n    \"\"\"\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # If task name is not given\n    if not task_name:\n        # Get the caller function's name\n        task_name = inspect.stack()[1][3]\n\n    # Print title\n    print_title('Create task: {}'.format(task_name))\n\n    # If cache key is given\n    if cache_key:\n        # Find cached task\n        cached_task = _TASKS_CACHE.get(cache_key, None)\n\n        # If have found cached task\n        if cached_task is not None:\n            # Print info\n            print_text('Use cached task `{}`.'.format(cache_key))\n\n            # Print end title\n            print_title('Create task: {}'.format(task_name), is_end=True)\n\n            # Return the cached task\n            return cached_task\n\n        # If have not found cached task.\n        #     Continue to create task.\n\n    # If cache key is not given.\n    #     Continue to create task.\n\n    # Normalized command parts list\n    norm_part_s = []\n\n    # Input nodes list\n    input_node_s = []\n\n    # Output nodes list\n    output_node_s = []\n\n    # Get the first command part that is program path\n    first_part = parts[0]\n\n    # If the first command part is list.\n    # Notice the first command part can be list if the value is from `ctx.env`,\n    # e.g `ctx.env.PYTHON`.\n    if isinstance(first_part, list):\n        # Use the first item in the list as the first command part\n        parts[0] = first_part[0]\n\n    # For given command parts list's each command part\n    for part, wrapper_type in _normalize_items(ctx=ctx, items=parts):\n        # If the command part is string\n        if isinstance(part, str):\n            # Add the string to the normalized list\n            norm_part_s.append(part)\n\n        # If the command part is node\n        elif isinstance(part, Node):\n            # Add the node's absolute path to the normalized list\n            norm_part_s.append(part.abspath())\n\n            # If the wrapper type is `input`\n            if wrapper_type == 'input':\n                # Add the node to the input nodes list\n                input_node_s.append(part)\n\n            # If the wrapper type is `output`\n            elif wrapper_type == 'output':\n                # Add the node to the output nodes list\n                output_node_s.append(part)\n\n            # If the wrapper type is not `input` or `output`\n            else:\n                # Do nothing\n                pass\n\n        # If the command part is not string or node\n        else:\n            # Get error message\n            msg = 'Error (2W9YD): Command part is not valid: {0}.'.format(part)\n\n            # Raise error\n            raise ValueError(msg)\n\n    # If environment dict is not given\n    if env is None:\n        # Use given context object's environment dict\n        env = ctx.env\n\n    # If working directory path is not given\n    if cwd is None:\n        # Set working directory path be top directory absolute path\n        cwd = ctx.top_dir\n\n    # If the working directory path is not absolute path.\n    if not os.path.isabs(cwd):\n        # Convert the working directory path to absolute path\n        cwd = create_node(ctx, cwd).abspath()\n\n    # Create task that runs command\n    task = CmdTask(\n        # Context object\n        ctx=ctx,\n\n        # Command parts list\n        parts=norm_part_s,\n\n        # Environment dict\n        env=env,\n\n        # Working directory\n        cwd=cwd,\n\n        # Task name\n        task_name=task_name,\n    )\n\n    # For each input or output item.\n    # Notice the code structure for handling input and output items are the\n    # same so use the same code with different variables to avoid duplicate\n    # code.\n    for wrapper_type, item_s, node_s, nodes_set_func in [\n        ('input', inputs, input_node_s, task.set_inputs),\n        ('output', outputs, output_node_s, task.set_outputs),\n    ]:\n        # For each normalized item\n        for item, _ in _normalize_items(\n            # Context\n            ctx=ctx,\n\n            # Items to normalize\n            items=item_s,\n\n            # Convert string to node\n            str_to_node=True,\n\n            # Allow task item\n            allow_task=True,\n        ):\n            # If the item is node\n            if isinstance(item, Node):\n                # Add the node to the nodes list\n                node_s.append(item)\n\n            # If the item is task\n            elif isinstance(item, Task):\n                # If the wrapper type is `input`\n                if wrapper_type == 'input':\n                    # Set the created task to run after the task\n                    task.set_run_after(item)\n\n                # If the wrapper type is `output`\n                elif wrapper_type == 'output':\n                    # Set the task to run after the created task\n                    item.set_run_after(task)\n\n                # If the wrapper type is not `input` or `output`\n                else:\n                    # Get error message\n                    msg = (\n                        'Error (3ZLGJ): Wrapper type is not valid: {0}.'\n                    ).format(wrapper_type)\n\n                    # Raise error\n                    raise ValueError(msg)\n\n            # If the item is not node or task\n            else:\n                # Get error message\n                msg = 'Error (5H4GC): Item type is not valid: {0}.'.format(\n                    item\n                )\n\n                # Raise error\n                raise ValueError(msg)\n\n        # Add these nodes to the created task as input or output targets\n        nodes_set_func(node_s)\n\n    # If need mark the created task as always run\n    if always:\n        # Mark the created task as always run\n        task.always_run = True  # pylint: disable=W0201\n\n    # If need add the created task to given context\n    if add_to_group:\n        # Add the created task to given context\n        ctx.add_to_group(task)\n\n    # If cache key is given\n    if cache_key:\n        # Add the created task to the cache\n        _TASKS_CACHE[cache_key] = task\n\n    # Print end title\n    print_title('Create task: {}'.format(task_name), is_end=True)\n\n    # Return the task\n    return task", "response": "Create a task that runs given command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint given context s info.", "response": "def print_ctx(ctx):\n    \"\"\"\n    Print given context's info.\n\n    :param ctx: Context object.\n\n    :return: None.\n    \"\"\"\n    # Print title\n    print_title('ctx attributes')\n\n    # Print context object's attributes\n    print_text(dir(ctx))\n\n    # Print end title\n    print_title('ctx attributes', is_end=True)\n\n    # Print title\n    print_title('ctx.options')\n\n    # Print context options dict\n    print_text(pformat(vars(ctx.options), indent=4, width=1))\n\n    # Print end title\n    print_title('ctx.options', is_end=True)\n\n    # If the context object has `env` attribute.\n    # Notice plain context object not has `env` attribute.\n    if hasattr(ctx, 'env'):\n        # Print title\n        print_title('ctx.env')\n\n        # Print context environment variables dict\n        print_text(pformat(dict(ctx.env), indent=4, width=1))\n\n        # Print end title\n        print_title('ctx.env', is_end=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate task that sets up virtualenv.", "response": "def virtualenv_setup(\n    ctx,\n    python,\n    inputs=None,\n    outputs=None,\n    touch=None,\n    check_import=False,\n    pip_setup_file=None,\n    pip_setup_touch=None,\n    cache_key=None,\n    always=False,\n):\n    \"\"\"\n    Create task that sets up `virtualenv` package.\n\n    :param ctx: BuildContext object.\n\n    :param python: Python program path.\n\n    :param inputs: Input items list to add to created task.\n\n        See :paramref:`create_cmd_task.inputs` for allowed item types.\n\n    :param outputs: Output items list to add to created task.\n\n        See :paramref:`create_cmd_task.outputs` for allowed item types.\n\n    :param touch: Touch file path for dirty checking.\n\n    :param check_import: Whether import module for dirty checking.\n\n    :param pip_setup_file: `get-pip.py` file path for `pip_setup` task.\n\n    :param pip_setup_touch: Touch file path for `pip_setup` task.\n\n    :param cache_key: Task cache key.\n\n    :param always: Whether always run.\n\n    :return: Created task.\n    \"\"\"\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # If `get-pip.py` file path is not given\n    if pip_setup_file is None:\n        # Not create task that sets up `pip`\n        pip_setup_task = None\n\n    # If `get-pip.py` file path is given\n    else:\n        # Create task that sets up `pip`\n        pip_setup_task = pip_setup(\n            # Context\n            ctx=ctx,\n\n            # Python program path\n            python=python,\n\n            # `get-pip.py` file path\n            setup_file=pip_setup_file,\n\n            # Touch file path\n            touch=pip_setup_touch,\n\n            # Whether import module for dirty checking\n            check_import=check_import,\n\n            # Whether always run\n            always=always,\n        )\n\n    # If touch file path is not given\n    if touch is None:\n        # Not update touch file\n        touch_node = None\n    else:\n        # Update touch file\n        touch_node, always = update_touch_file(\n            # Context\n            ctx=ctx,\n\n            # Touch file path\n            path=touch,\n\n            # Whether import module for dirty checking\n            check_import=check_import,\n\n            # Module name to import for dirty checking\n            check_import_module='virtualenv',\n\n            # Python program path for dirty checking\n            check_import_python=python,\n\n            # Whether always run\n            always=always,\n        )\n\n    # Create task that sets up `virtualenv` package\n    task = create_cmd_task(\n        # Context\n        ctx=ctx,\n\n        # Command parts\n        parts=[\n            # Python program path\n            python,\n\n            # Run module\n            '-m',\n\n            # Module name\n            'pip',\n\n            # Install package\n            'install',\n\n            # Package name\n            'virtualenv',\n        ],\n\n        # Input items list\n        inputs=[\n            # Run after the task that sets up `pip`\n            pip_setup_task,\n\n            # Given input items list\n            inputs,\n        ],\n\n        # Output items list\n        outputs=[\n            # Use the touch node as output target for dirty checking\n            touch_node,\n\n            # Given output items list\n            outputs,\n        ],\n\n        # Whether always run\n        always=always,\n\n        # Task cache key\n        cache_key=cache_key or (python, 'virtualenv'),\n    )\n\n    # Return the created task\n    return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a virtual environment.", "response": "def create_venv(\n    ctx,\n    python,\n    venv_path,\n    inputs=None,\n    outputs=None,\n    pip_setup_file=None,\n    pip_setup_touch=None,\n    virtualenv_setup_touch=None,\n    task_name=None,\n    cache_key=None,\n    always=False,\n):\n    \"\"\"\n    Create task that sets up virtual environment.\n\n    :param ctx: BuildContext object.\n\n    :param python: Python program path.\n\n    :param venv_path: Virtual environment directory relative path relative to\n        top directory.\n\n    :param inputs: Input items list to add to created task.\n\n        See :paramref:`create_cmd_task.inputs` for allowed item types.\n\n    :param outputs: Output items list to add to created task.\n\n        See :paramref:`create_cmd_task.outputs` for allowed item types.\n\n    :param pip_setup_file: `get-pip.py` file path for `pip_setup` task.\n\n    :param pip_setup_touch: Touch file path for `pip_setup` task.\n\n    :param virtualenv_setup_touch: Touch file path for `virtualenv_setup` task.\n\n    :param task_name: Task name for display purpose.\n\n    :param cache_key: Task cache key.\n\n    :param always: Whether always run.\n\n    :return: Created task.\n    \"\"\"\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # Create task that sets up `virtualenv` package\n    virtualenv_setup_task = virtualenv_setup(\n        # Context\n        ctx=ctx,\n\n        # Python program path\n        python=python,\n\n        # Touch file path\n        touch=virtualenv_setup_touch,\n\n        # `get-pip.py` file path for `pip_setup` task.\n        pip_setup_file=pip_setup_file,\n\n        # Touch file path for `pip_setup` task.\n        pip_setup_touch=pip_setup_touch,\n    )\n\n    # Get virtual environment directory path node\n    venv_path_node, _ = _normalize_items(\n        ctx=ctx,\n        items=[venv_path],\n        # Convert path string to node\n        str_to_node=True\n    )[0]\n\n    # Create task that sets up virtual environment.\n    task = create_cmd_task(\n        # Context\n        ctx=ctx,\n\n        # Command parts\n        parts=[\n            # Python program path\n            python,\n\n            # Run module\n            '-m',\n\n            # Module name\n            'virtualenv',\n\n            # Virtual environment directory absolute path\n            venv_path_node.abspath(),\n        ],\n\n        # Input items list\n        inputs=[\n            # Run after the task that sets up `virtualenv` package\n            virtualenv_setup_task,\n\n            # Given input items list\n            inputs,\n        ],\n\n        # Output items list\n        outputs=[\n            # Add the virtual environment's `python` program path as output\n            # target for dirty checking\n            get_python_path(venv_path),\n\n            # Add the virtual environment's `pip` program path as output target\n            # for dirty checking\n            get_pip_path(venv_path),\n\n            # Given output items list\n            outputs,\n        ],\n\n        # Whether always run\n        always=always,\n\n        # Task name\n        task_name=task_name,\n\n        # Task cache key\n        cache_key=cache_key or (python, venv_path),\n    )\n\n    # Return the created task\n    return task"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a pip - ins - req task.", "response": "def pip_ins_req(\n    ctx,\n    python,\n    req_path,\n    venv_path=None,\n    inputs=None,\n    outputs=None,\n    touch=None,\n    check_import=False,\n    check_import_module=None,\n    pip_setup_file=None,\n    pip_setup_touch=None,\n    virtualenv_setup_touch=None,\n    always=False,\n):\n    \"\"\"\n    Create task that uses given virtual environment's `pip` to sets up \\\n    packages listed in given requirements file.\n\n    :param ctx: BuildContext object.\n\n    :param python: Python program path used to set up `pip` and `virtualenv`.\n\n    :param req_path: Requirements file relative path relative to top directory.\n\n    :param venv_path: Virtual environment directory relative path relative to\n        top directory.\n\n        If given, will create the virtual environment and set up packages\n        listed in given requirements file in the virtual environment.\n\n        If not given, will set up packages listed in given requirements file in\n        given Python program's environment.\n\n    :param inputs: Input items list to add to created task.\n\n        See :paramref:`create_cmd_task.inputs` for allowed item types.\n\n    :param outputs: Output items list to add to created task.\n\n        See :paramref:`create_cmd_task.outputs` for allowed item types.\n\n    :param touch: Touch file path for dirty checking.\n\n    :param check_import: Whether import module for dirty checking.\n\n    :param check_import_module: Module name to import for dirty checking.\n\n    :param pip_setup_file: `get-pip.py` file path for `pip_setup` task.\n\n    :param pip_setup_touch: Touch file path for `pip_setup` task.\n\n    :param virtualenv_setup_touch: Touch file path for `virtualenv_setup` task.\n\n    :param always: Whether always run.\n\n    :return: Created task.\n    \"\"\"\n    # Ensure given context object is BuildContext object\n    _ensure_build_context(ctx)\n\n    # If virtual environment directory path is not given\n    if venv_path is None:\n        # Use given Python program path\n        venv_python = python\n\n    # If virtual environment directory path is given\n    else:\n        # Get Python program path in the virtual environment\n        venv_python = get_python_path(venv_path)\n\n        # Mark the path as input target\n        venv_python = mark_input(venv_python)\n\n    # If virtual environment directory path is not given,\n    # it means not create virtual environment.\n    if venv_path is None:\n        # Create task that sets up `pip`\n        pip_setup_task = pip_setup(\n            # Context\n            ctx=ctx,\n\n            # Python program path\n            python=python,\n\n            # `get-pip.py` file path\n            setup_file=pip_setup_file,\n\n            # Touch file path\n            touch=pip_setup_touch,\n\n            # Whether import module for dirty checking\n            always=always,\n        )\n\n        # Not create virtual environment\n        venv_task = None\n\n    # If virtual environment directory path is given\n    else:\n        # Not create task that sets up `pip` here because `create_venv`\n        # function below will do\n        pip_setup_task = None\n\n        # Create task that sets up virtual environment\n        venv_task = create_venv(\n            # Context\n            ctx=ctx,\n\n            # Python program path\n            python=python,\n\n            # Virtual environment directory path\n            venv_path=venv_path,\n\n            # Output items list\n            outputs=[\n                # Add the virtual environment's `python` program path as output\n                # target for dirty checking\n                get_python_path(venv_path),\n\n                # Add the virtual environment's `pip` program path as output\n                # target for dirty checking\n                get_pip_path(venv_path),\n            ],\n\n            # Whether always run\n            always=always,\n\n            # Task name\n            task_name='Create venv `{}`'.format(venv_path),\n\n            # `get-pip.py` file path for `pip_setup` task\n            pip_setup_file=pip_setup_file,\n\n            # Touch file path for `pip_setup` task\n            pip_setup_touch=pip_setup_touch,\n\n            # Touch file path for `virtualenv_setup` task\n            virtualenv_setup_touch=virtualenv_setup_touch,\n        )\n\n    # If touch file path is not given\n    if not touch:\n        # Not update touch file\n        touch_node = None\n\n    # If touch file path is given\n    else:\n        # Update touch file\n        touch_node, always = update_touch_file(\n            # Context\n            ctx=ctx,\n\n            # Touch file path\n            path=touch,\n\n            # Whether import module for dirty checking\n            check_import=check_import,\n\n            # Module name to import for dirty checking\n            check_import_module=check_import_module,\n\n            # Python program path for dirty checking\n            check_import_python=venv_python,\n\n            # Whether always run\n            always=always,\n        )\n\n    # Create task that sets up packages\n    task = create_cmd_task(\n        # Context\n        ctx=ctx,\n\n        # Command parts\n        parts=[\n            # Python program path\n            venv_python,\n\n            # Run module\n            '-m',\n\n            # Module name\n            'pip',\n\n            # Install package\n            'install',\n\n            # Read package names from requirements file\n            '-r',\n\n            # Requirements file path. Mark as input target.\n            mark_input(req_path),\n        ],\n\n        # Input items list\n        inputs=inputs,\n\n        # Output items list\n        outputs=[\n            # Use the touch node as output target for dirty checking\n            touch_node,\n\n            # Given output items list\n            outputs,\n        ],\n\n        # Whether always run\n        always=always,\n    )\n\n    # Chain these tasks to run one after another\n    chain_tasks([\n        pip_setup_task,\n        venv_task,\n        task,\n    ])\n\n    # Return the created task\n    return task"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef git_clean(ctx):\n    # Get command parts\n    cmd_part_s = [\n        # Program path\n        'git',\n\n        # Clean untracked files\n        'clean',\n\n        # Remove all untracked files\n        '-x',\n\n        # Remove untracked directories too\n        '-d',\n\n        # Force to remove\n        '-f',\n\n        # Give two `-f` flags to remove sub-repositories too\n        '-f',\n    ]\n\n    # Print title\n    print_title('git_clean')\n\n    # Print the command in multi-line format\n    print_text(_format_multi_line_command(cmd_part_s))\n\n    # Create subprocess to run the command in top directory\n    proc = subprocess.Popen(cmd_part_s, cwd=ctx.top_dir)\n\n    # Wait the subprocess to finish\n    proc.wait()\n\n    # Print end title\n    print_title('git_clean', is_end=True)", "response": "Delete all untracked files and directories in the current git repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        # Print task title\n        print_title(self._task_name_title)\n\n        # Get context object\n        ctx = self._ctx\n\n        # Get command parts\n        cmd_part_s = self._parts\n\n        # Print title\n        print_title('Find program')\n\n        # Get program path from command parts\n        program_path = cmd_part_s[0]\n\n        # If the program path ends with one of the file extensions below\n        if program_path.endswith(('.exe', '.com', '.bat', '.cmd')):\n            # Remove the file extension.\n            # This is because `Waf`'s `find_binary` function adds each of the\n            # file extensions when finding the program.\n            program_path = program_path[:-4]\n\n        # Print info\n        print_text('Find program: {0}'.format(program_path))\n\n        #\n        try:\n            # Find program\n            found_program_path_s = ctx.find_program(program_path, quiet=True)\n\n        # If program paths are not found\n        except ConfigurationError:\n            # Get error message\n            msg = 'Error (2D7VS): Program is not found: {0}'.format(\n                program_path\n            )\n\n            # Raise error\n            raise ValueError(msg)\n\n        # If program paths are found.\n\n        # If program paths are found.\n        #     Use the first program path found.\n        # If program paths are not found. (Should not happen.)\n        #     Use given program path.\n        found_program_path = found_program_path_s[0] \\\n            if found_program_path_s else program_path\n\n        # Use the program path found as the first command part\n        cmd_part_s[0] = found_program_path\n\n        # Print info\n        print_text('Use program: {0}'.format(found_program_path))\n\n        # Print end title\n        print_title('Find program', is_end=True)\n\n        # Print title\n        print_title('PATH')\n\n        # Print environment variable PATH's value, one part per line\n        print_text('\\n'.join(os.environ.get('PATH', '').split(os.pathsep)))\n\n        # Print end title\n        print_title('PATH', is_end=True)\n\n        # Print title\n        print_title('PYTHONPATH')\n\n        # Print environment variable PYTHONPATH's value, one part per line\n        print_text(\n            '\\n'.join(os.environ.get('PYTHONPATH', '').split(os.pathsep))\n        )\n\n        # Print end title\n        print_title('PYTHONPATH', is_end=True)\n\n        # Print title\n        print_title('DIR')\n\n        # Print working directory\n        print_text(self._cwd)\n\n        # Print end title\n        print_title('DIR', is_end=True)\n\n        # Print title\n        print_title('CMD')\n\n        # Print the command in multi-line format\n        print_text(_format_multi_line_command(cmd_part_s))\n\n        # Print end title\n        print_title('CMD', is_end=True)\n\n        # Print title\n        print_title('RUN')\n\n        # Run the command in the working directory\n        exit_code = self.exec_command(cmd_part_s, cwd=self._cwd)\n\n        # Print the command's exit code\n        print_text('Exit code: {0}'.format(exit_code))\n\n        # Print end title\n        print_title('RUN', is_end=True)\n\n        # Print task end title\n        print_title(self._task_name_title, True)\n\n        # Return the exit code\n        return exit_code", "response": "Run command.\n\n        :return: Command exit code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ac_info_all(auth, url):\n    get_ac_info_all_url = \"/imcrs/wlan/acInfo/queryAcBasicInfo\"\n    f_url = url + get_ac_info_all_url\n    payload = None\n    r = requests.get(f_url, auth=auth,\n                     headers=HEADERS)  # creates the URL using the payload variable as the contents\n    # print(r.status_code)\n    try:\n        if r.status_code == 200:\n            if len(r.text) > 0:\n                return json.loads(r.text)['acBasicInfo']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_ac_info_all: An Error has occured\"", "response": "This function returns a list of dictionaries where each element of the list represents a single wireless controller which has been discovered in the HPE IMC WSM module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addvlan(self, vlanid, vlan_name):\n        create_dev_vlan( vlanid, vlan_name, self.auth, self.url, devid = self.devid)", "response": "This function creates a new VLAN on the device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning operates on the IMCDev object. Takes input of vlanid (1-4094), auth and url to execute the delete_dev_vlans method on the IMCDev object. Device must be supported in the HPE IMC Platform VLAN Manager module. :param vlanid: str of VLANId ( valid 1-4094 ) :return:", "response": "def delvlan(self, vlanid):\n        \"\"\"\n        Function operates on the IMCDev object. Takes input of vlanid (1-4094),\n        auth and url to execute the delete_dev_vlans method on the IMCDev object. Device must be\n        supported in the HPE IMC Platform VLAN Manager module.\n        :param vlanid: str of VLANId ( valid 1-4094 )\n        :return:\n        \"\"\"\n        delete_dev_vlans( vlanid, self.auth, self.url, devid = self.devid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction operates on the IMCDev object and updates the ipmacarp attribute :return:", "response": "def getipmacarp(self):\n        \"\"\"\n        Function operates on the IMCDev object and updates the ipmacarp attribute\n        :return:\n        \"\"\"\n        self.ipmacarp = get_ip_mac_arp_list(self.auth, self.url, devid = self.devid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning operates on the IMCInterface object and configures the interface into an administratively down state and refreshes contents of self.adminstatus :return:", "response": "def down(self):\n        \"\"\"\n        Function operates on the IMCInterface object and configures the interface into an\n        administratively down state and refreshes contents of self.adminstatus\n        :return:\n        \"\"\"\n        set_interface_down(self.ifIndex, self.auth, self.url, devip=self.ip)\n        self.adminstatus = get_interface_details(self.ifIndex, self.auth, self.url, devip=self.ip)[\n            'adminStatusDesc']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction operates on the IMCInterface object and configures the interface into an an administratively up state and refreshes contents of self. adminstatus", "response": "def up(self):\n        \"\"\"\n                Function operates on the IMCInterface object and configures the interface into an\n                administratively up state and refreshes contents of self.adminstatus\n                :return:\n                \"\"\"\n        set_interface_up(self.ifIndex, self.auth, self.url, devip=self.ip)\n        self.adminstatus = get_interface_details(self.ifIndex, self.auth, self.url, devip=self.ip)[\n            'adminStatusDesc']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nobjecting method takes in input of hostipaddress, name and description and adds them to the parent ip scope. :param hostipaddress: str of ipv4 address of the target host ip record :param name: str of the name of the owner of the target host ip record :param description: str of a description of the target host ip record :return:", "response": "def allocate_ip(self, hostipaddress, name, description):\n        \"\"\"\n        Object method takes in input of hostipaddress, name and description and adds them to the\n        parent ip scope.\n        :param hostipaddress: str of ipv4 address of the target host ip record\n        :param name: str of the name of the owner of the target host ip record\n        :param description: str of a description of the target host ip record\n        :return:\n        \"\"\"\n        add_scope_ip(hostipaddress, name, description, self.auth, self.url, scopeid=self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nobjecting method takes in input of hostip address,removes them from the parent ip scope. :param hostid: str of the hostid of the target host ip record :return:", "response": "def deallocate_ip(self, hostipaddress):\n        \"\"\"\n        Object method takes in input of hostip address,removes them from the parent ip scope.\n        :param hostid: str of the hostid of  the target host ip record\n\n        :return:\n        \"\"\"\n        delete_host_from_segment(hostipaddress, self.netaddr, self.auth, self.url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning takes no input or returns list of dicts where each dictionary represents one or more dictionaries where each dictionary represents one or more telnet template", "response": "def get_telnet_template(auth, url, template_name=None):\n    \"\"\"\n    Takes no input, or template_name as input to issue RESTUL call to HP IMC\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param template_name: str value of template name\n\n    :return list object containing one or more dictionaries where each dictionary represents one\n    telnet template\n\n    :rtype list\n\n    \"\"\"\n    f_url = url + \"/imcrs/plat/res/telnet?start=0&size=10000&desc=false&total=false\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            telnet_templates = (json.loads(response.text))\n            template = None\n            if type(telnet_templates['telnetParamTemplate']) is dict:\n                my_templates = [telnet_templates['telnetParamTemplate']]\n                telnet_templates['telnetParamTemplate'] = my_templates\n            if template_name is None:\n                return telnet_templates['telnetParamTemplate']\n            elif template_name is not None:\n                for telnet_template in telnet_templates['telnetParamTemplate']:\n\n                    if telnet_template['name'] == template_name:\n                        template = [telnet_template]\n                print (type(template))\n                if template == None:\n                    return 404\n                else:\n                    return template\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_telnet_templates: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modify_telnet_template(auth, url, telnet_template, template_name= None, template_id = None):\n    if template_name is None:\n        template_name = telnet_template['name']\n    if template_id is None:\n        telnet_templates = get_telnet_template(auth, url)\n        template_id = None\n        for template in telnet_templates:\n            if template['name'] == template_name:\n                template_id = template['id']\n    f_url = url + \"/imcrs/plat/res/telnet/\"+str(template_id)+\"/update\"\n    response = requests.put(f_url, data = json.dumps(telnet_template), auth=auth, headers=HEADERS)\n    try:\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" modify_telnet_template: An Error has occured\"", "response": "Function takes input of a dictionary containing the required key - value pair for the modification of a specific telnet template."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes template_name as input to issue RESTUL call to HP IMC which will delete the specific telnet template from the IMC system :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param template_name: str value of template name :param template_id: str value template template_id value :return: int HTTP response code :rtype int", "response": "def delete_telnet_template(auth, url, template_name= None, template_id= None):\n    \"\"\"\n    Takes template_name as input to issue RESTUL call to HP IMC which will delete the specific\n    telnet template from the IMC system\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param template_name: str value of template name\n\n    :param template_id: str value template template_id value\n\n    :return: int HTTP response code\n\n    :rtype  int\n    \"\"\"\n    try:\n        if template_id is None:\n            telnet_templates = get_telnet_template(auth, url)\n            if template_name is None:\n                template_name = telnet_template['name']\n            template_id = None\n            for template in telnet_templates:\n                if template['name'] == template_name:\n                    template_id = template['id']\n        f_url = url + \"/imcrs/plat/res/telnet/%s/delete\" % template_id\n        response = requests.delete(f_url, auth=auth, headers=HEADERS)\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" delete_telnet_template: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_ssh_template(auth, url, ssh_template ):\n    f_url = url + \"/imcrs/plat/res/ssh/add\"\n    response = requests.post(f_url, data = json.dumps(ssh_template), auth=auth, headers=HEADERS)\n    try:\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" create_ssh_template: An Error has occured\"", "response": "Function creates an SSH template"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake no input, or template_name as input to issue RESTUL call to HP IMC :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param template_name: str value of template name :return list object containing one or more dictionaries where each dictionary represents one ssh template :rtype list", "response": "def get_ssh_template(auth, url, template_name=None):\n    \"\"\"\n    Takes no input, or template_name as input to issue RESTUL call to HP IMC\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param template_name: str value of template name\n\n    :return list object containing one or more dictionaries where each dictionary represents one\n    ssh template\n\n    :rtype list\n\n    \"\"\"\n    f_url = url + \"/imcrs/plat/res/ssh?start=0&size=10000&desc=false&total=false\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            ssh_templates = (json.loads(response.text))\n            template = None\n            if type(ssh_templates['sshParamTemplate']) is dict:\n                my_templates = [ssh_templates['sshParamTemplate']]\n                ssh_templates['sshParamTemplate'] = my_templates\n            if template_name is None:\n                return ssh_templates['sshParamTemplate']\n            elif template_name is not None:\n                for ssh_template in ssh_templates['sshParamTemplate']:\n                    if ssh_template['name'] == template_name:\n                        template = [ssh_template]\n                print (type(template))\n                if template == None:\n                    return 404\n                else:\n                    return template\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_ssh_templates: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions takes input of a dictionary containing the required key - value pair for the modification of an internal SSH template.", "response": "def modify_ssh_template(auth, url, ssh_template, template_name= None, template_id = None):\n    \"\"\"\n    Function takes input of a dictionry containing the required key/value pair for the modification\n    of a ssh template.\n\n    :param auth:\n    :param url:\n    :param ssh_template: Human readable label which is the name of the specific ssh template\n    :param template_id Internal IMC number which designates the specific ssh template\n    :return: int value of HTTP response code 201 for proper creation or 404 for failed creation\n    :rtype int\n\n    Sample of proper KV pairs. Please see documentation for valid values for different fields.\n\n    ssh_template = {\n    \"type\": \"0\",\n    \"name\": \"ssh_admin_template\",\n    \"authType\": \"3\",\n    \"authTypeStr\": \"Password + Super Password\",\n    \"userName\": \"newadmin\",\n    \"password\": \"password\",\n    \"superPassword\": \"password\",\n    \"port\": \"22\",\n    \"timeout\": \"10\",\n    \"retries\": \"3\",\n    \"keyFileName\": \"\",\n    \"keyPhrase\": \"\"\n    }\n    \"\"\"\n    if template_name is None:\n        template_name = ssh_template['name']\n    if template_id is None:\n        ssh_templates = get_ssh_template(auth, url)\n        template_id = None\n        for template in ssh_templates:\n            if template['name'] == template_name:\n                template_id = template['id']\n    f_url = url + \"/imcrs/plat/res/ssh/\"+str(template_id)+\"/update\"\n    response = requests.put(f_url, data = json.dumps(ssh_template), auth=auth, headers=HEADERS)\n    try:\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" modify_ssh_template: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_ssh_template(auth, url, template_name= None, template_id= None):\n    try:\n        if template_id is None:\n            ssh_templates = get_ssh_template(auth, url)\n            if template_name is None:\n                template_name = ssh_template['name']\n            template_id = None\n            for template in ssh_templates:\n                if template['name'] == template_name:\n                    template_id = template['id']\n        f_url = url + \"/imcrs/plat/res/ssh/%s/delete\" % template_id\n        response = requests.delete(f_url, auth=auth, headers=HEADERS)\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" delete_ssh_template: An Error has occured\"", "response": "This function will issue RESTUL call to HP IMC which will delete the specific\n    ssh template from the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking no input, or template_name as input to issue RESTUL call to HP IMC :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param template_name: str value of template name :return list object containing one or more dictionaries where each dictionary represents one snmp template :rtype list", "response": "def get_snmp_templates(auth, url, template_name=None):\n    \"\"\"\n    Takes no input, or template_name as input to issue RESTUL call to HP IMC\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param template_name: str value of template name\n\n    :return list object containing one or more dictionaries where each dictionary represents one\n    snmp template\n\n    :rtype list\n\n    \"\"\"\n    f_url = url + \"/imcrs/plat/res/snmp?start=0&size=10000&desc=false&total=false\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            snmp_templates = (json.loads(response.text))\n            template = None\n            if type(snmp_templates['snmpParamTemplate']) is dict:\n                my_templates = [snmp_templates['snmpParamTemplate']]\n                snmp_templates['snmpParamTemplate'] = my_templates\n            if template_name is None:\n                return snmp_templates['snmpParamTemplate']\n            elif template_name is not None:\n                for snmp_template in snmp_templates['snmpParamTemplate']:\n                    if snmp_template['name'] == template_name:\n                        template = [snmp_template]\n                if template == None:\n                    return 404\n                else:\n                    return template\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_snmp_templates: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modify_snmp_template(auth, url, snmp_template, template_name= None, template_id = None):\n    if template_name is None:\n        template_name = snmp_template['name']\n    if template_id is None:\n        snmp_templates = get_snmp_templates(auth, url)\n        template_id = None\n        for template in snmp_templates:\n            if template['name'] == template_name:\n                template_id = template['id']\n    f_url = url + \"/imcrs/plat/res/snmp/\"+str(template_id)+\"/update\"\n    response = requests.put(f_url, data = json.dumps(snmp_template), auth=auth, headers=HEADERS)\n    try:\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" modify_snmp_template: An Error has occured\"", "response": "Function to modify an existing SNMP template."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_snmp_template(auth, url, template_name= None, template_id= None):\n    try:\n        if template_id is None:\n            snmp_templates = get_snmp_templates(auth, url)\n            if template_name is None:\n                template_name = snmp_template['name']\n            template_id = None\n            for template in snmp_templates:\n                if template['name'] == template_name:\n                    template_id = template['id']\n        f_url = url + \"/imcrs/plat/res/snmp/%s/delete\" % template_id\n        response = requests.delete(f_url, auth=auth, headers=HEADERS)\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" delete_snmp_template: An Error has occured\"", "response": "This function will issue RESTUL call to HP IMC which will delete the specific\n    from the IMC system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking in ipaddress as input to fetch device assett details from HP IMC RESTFUL API", "response": "def get_dev_asset_details(ipaddress, auth, url):\n    \"\"\"Takes in ipaddress as input to fetch device assett details from HP IMC RESTFUL API\n\n    :param ipaddress: IP address of the device you wish to gather the asset details\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: object of type list containing the device asset details, with each asset contained\n    in a dictionary\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.netassets import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> single_asset = get_dev_asset_details('10.101.0.1', auth.creds, auth.url)\n\n    >>> assert type(single_asset) is list\n\n    >>> assert 'name' in single_asset[0]\n\n    \"\"\"\n    ipaddress = get_dev_details(ipaddress, auth, url)\n    if isinstance(ipaddress, dict):\n        ipaddress = ipaddress['ip']\n    else:\n        print(\"Asset Doesn't Exist\")\n        return 403\n    f_url = url + \"/imcrs/netasset/asset?assetDevice.ip=\" + str(ipaddress)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_asset_info = (json.loads(response.text))\n            if len(dev_asset_info) > 0:\n                dev_asset_info = dev_asset_info['netAsset']\n            if isinstance(dev_asset_info, dict):\n                dev_asset_info = [dev_asset_info]\n            if isinstance(dev_asset_info, list):\n                dev_asset_info[:] = [dev for dev in dev_asset_info if dev.get('deviceIp') ==\n                                     ipaddress]\n            return dev_asset_info\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_dev_asset_details: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes no input to fetch device assett details from HP IMC RESTFUL API", "response": "def get_dev_asset_details_all(auth, url):\n    \"\"\"Takes no input to fetch device assett details from HP IMC RESTFUL API\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: list of dictionatires containing the device asset details\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.netassets import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> all_assets = get_dev_asset_details_all( auth.creds, auth.url)\n\n    >>> assert type(all_assets) is list\n\n    >>> assert 'asset' in all_assets[0]\n\n    \"\"\"\n    f_url = url + \"/imcrs/netasset/asset?start=0&size=15000\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_asset_info = (json.loads(response.text))['netAsset']\n            return dev_asset_info\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_dev_asset_details: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns a non - encrypted non - authorized API proxy server.", "response": "def proxy(ctx, bind, port):\n    \"\"\"\n    Run a non-encrypted non-authorized API proxy server.\n    Use this only for development and testing!\n    \"\"\"\n    app = web.Application()\n    app.on_startup.append(startup_proxy)\n    app.on_cleanup.append(cleanup_proxy)\n\n    app.router.add_route(\"GET\", r'/stream/{path:.*$}', websocket_handler)\n    app.router.add_route(\"GET\", r'/wsproxy/{path:.*$}', websocket_handler)\n    app.router.add_route('*', r'/{path:.*$}', web_handler)\n    if getattr(ctx.args, 'testing', False):\n        return app\n    web.run_app(app, host=bind, port=port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes string input of IP address to issue RESTUL call to HP IMC\\n :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param network_address: str IPv4 Network Address :param category: str or int corresponding to device category (0=router, 1=switches, see API docs for other examples) :return: dictionary of device details :rtype: dict >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.device import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> dev_list = get_all_devs( auth.creds, auth.url, network_address= '10.11.') >>> assert type(dev_list) is list >>> assert 'sysName' in dev_list[0]", "response": "def get_all_devs(auth, url, network_address=None, category=None, label=None):\n    \"\"\"Takes string input of IP address to issue RESTUL call to HP IMC\\n\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n    :param network_address: str IPv4 Network Address\n    :param category: str or int corresponding to device category (0=router, 1=switches, see API docs for other examples)\n    :return: dictionary of device details\n    :rtype: dict\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> dev_list = get_all_devs( auth.creds, auth.url, network_address= '10.11.')\n\n    >>> assert type(dev_list) is list\n\n    >>> assert 'sysName' in dev_list[0]\n\n    \"\"\"\n    base_url = \"/imcrs/plat/res/device?resPrivilegeFilter=false\"\n    end_url = \"&start=0&size=1000&orderBy=id&desc=false&total=false\"\n    if network_address:\n        network_address = \"&ip=\" + str(network_address)\n    else:\n        network_address = ''\n    if label:\n        label = \"&label=\" + str(label)\n    else:\n        label = ''\n    if category:\n        category = \"&category\" + category\n    else:\n        category = ''\n    f_url = url + base_url + str(network_address) + str(label) + str(category) + end_url\n    print(f_url)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_details = (json.loads(response.text))\n            if len(dev_details) == 0:\n                print(\"Device not found\")\n                return \"Device not found\"\n            elif type(dev_details['device']) is dict:\n                return [dev_details['device']]\n            else:\n                return dev_details['device']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_dev_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dev_details(ip_address, auth, url):\n    get_dev_details_url = \"/imcrs/plat/res/device?resPrivilegeFilter=false&ip=\" + \\\n                          str(ip_address) + \"&start=0&size=1000&orderBy=id&desc=false&total=false\"\n    f_url = url + get_dev_details_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_details = (json.loads(response.text))\n            if len(dev_details) == 0:\n                print(\"Device not found\")\n                return \"Device not found\"\n            elif isinstance(dev_details['device'], list):\n                for i in dev_details['device']:\n                    if i['ip'] == ip_address:\n                        dev_details = i\n                        return dev_details\n            elif isinstance(dev_details['device'], dict):\n                return dev_details['device']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_dev_details: An Error has occured\"", "response": "This function issues RESTUL call to HP IMC API to get details of a device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dev_interface(auth, url, devid=None, devip=None):\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    get_dev_interface_url = \"/imcrs/plat/res/device/\" + str(devid) + \\\n                            \"/interface?start=0&size=1000&desc=false&total=false\"\n    f_url = url + get_dev_interface_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            int_list = json.loads(response.text)\n            if 'interface' in int_list:\n                return int_list['interface']\n            else:\n                return []\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_dev_interface: An Error has occured\"", "response": "Function returns list of device objects which contains a dictionary per interface"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dev_mac_learn(auth, url, devid=None, devip=None):\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    f_url = url + '/imcrs/res/access/ipMacLearn/' + str(devid)\n    try:\n        response = requests.get(f_url, auth=auth, headers=HEADERS)\n        if response.status_code == 200:\n            if len(json.loads(response.text)) < 1:\n                mac_learn_query = []\n                return mac_learn_query\n            else:\n                mac_learn_query = (json.loads(response.text))['ipMacLearnResult']\n                if isinstance(mac_learn_query, dict):\n                    mac_learn_query = [mac_learn_query]\n                return mac_learn_query\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_dev_mac_learn: An Error has occured\"", "response": "function takes devid of specific device and issues a RESTFUL call to gather the current IP - MAC learning entries on the target device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning runs the command list on the target device and returns the output of the commands.", "response": "def run_dev_cmd(cmd_list, auth, url, devid=None, devip=None):\n    \"\"\"\n    Function takes devid of target device and a sequential list of strings which define the\n    specific commands to be run on the target device and returns a str object containing the\n    output of the commands.\n\n    :param devid: int devid of the target device\n\n    :param cmd_list: list of strings\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: str containing the response of the commands\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> cmd_list = ['display version']\n\n    >>> cmd_output = run_dev_cmd( cmd_list, auth.creds, auth.url, devid ='10')\n\n    >>> cmd_output = run_dev_cmd( cmd_list, auth.creds, auth.url, devip='10.101.0.221')\n\n    >>> assert type(cmd_output) is dict\n\n    >>> assert 'cmdlist' in cmd_output\n\n    >>> assert 'success' in cmd_output\n\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    run_dev_cmd_url = '/imcrs/icc/confFile/executeCmd'\n    f_url = url + run_dev_cmd_url\n    cmd_list = _make_cmd_list(cmd_list)\n    payload = '''{ \"deviceId\" : \"''' + str(devid) + '''\",\n                   \"cmdlist\" : { \"cmd\" :\n                   [''' + cmd_list + ''']\n                   }\n                   }'''\n    try:\n        response = requests.post(f_url, data=payload, auth=auth, headers=HEADERS)\n        if response.status_code == 200:\n            if len(response.text) < 1:\n                return ''\n            else:\n                return json.loads(response.text)\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" run_dev_cmd: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_interface_details(auth, url, devid=None, devip=None):\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    get_all_interface_details_url = \"/imcrs/plat/res/device/\" + str(\n        devid) + \"/interface/?start=0&size=1000&desc=false&total=false\"\n    f_url = url + get_all_interface_details_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_details = (json.loads(response.text))\n            return dev_details['interface']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_all_interface_details: An Error has occured\"", "response": "function to get all interfaces on a specific device"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction takest devid and ifindex of specific device and interface and issues a RESTFUL call to \" shut\" the specified interface on the target device. :param devid: int or str value of the target device :param devip: ipv4 address of the target devices :param ifindex: int or str value of the target interface :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: HTTP status code 204 with no values. :rtype:int >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.device import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> int_up_response = set_inteface_up('9', auth.creds, auth.url, devip = '10.101.0.221') >>> int_down_response = set_interface_down( '9', auth.creds, auth.url, devid = '10') 204 >>> int_up_response = set_inteface_up('9', auth.creds, auth.url, devip = '10.101.0.221') >>> int_down_response = set_interface_down( '9', auth.creds, auth.url, devip = '10.101.0.221') 204 >>> assert type(int_down_response) is int >>> assert int_down_response is 204 >>> int_up_response = set_inteface_up('9', auth.creds, auth.url, devip = '10.101.0.221')", "response": "def set_interface_down(ifindex, auth, url, devid=None, devip=None):\n    \"\"\"\n    function takest devid and ifindex of specific device and interface and issues a RESTFUL call\n    to \" shut\" the specified interface on the target device.\n    :param devid: int or str value of the target device\n\n    :param devip: ipv4 address of the target devices\n\n    :param ifindex: int or str value of the target interface\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: HTTP status code 204 with no values.\n\n    :rtype:int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> int_up_response = set_inteface_up('9', auth.creds, auth.url, devip = '10.101.0.221')\n\n    >>> int_down_response = set_interface_down( '9', auth.creds, auth.url, devid = '10')\n    204\n\n    >>> int_up_response = set_inteface_up('9', auth.creds, auth.url, devip = '10.101.0.221')\n\n    >>> int_down_response = set_interface_down( '9', auth.creds, auth.url, devip = '10.101.0.221')\n    204\n\n    >>> assert type(int_down_response) is int\n\n    >>> assert int_down_response is 204\n\n    >>> int_up_response = set_inteface_up('9', auth.creds, auth.url, devip = '10.101.0.221')\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    set_int_down_url = \"/imcrs/plat/res/device/\" + str(devid) + \"/interface/\" + str(ifindex) + \\\n                       \"/down\"\n    f_url = url + set_int_down_url\n    try:\n        response = requests.put(f_url, auth=auth, headers=HEADERS)\n        print(response.status_code)\n        if response.status_code == 204:\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" set_inteface_down: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_inteface_up(ifindex, auth, url, devid=None, devip=None):\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    set_int_up_url = \"/imcrs/plat/res/device/\" + str(devid) + \"/interface/\" + str(ifindex) + \"/up\"\n    f_url = url + set_int_up_url\n    try:\n        response = requests.put(f_url, auth=auth, headers=HEADERS)\n        if response.status_code == 204:\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" set_inteface_up: An Error has occured\"", "response": "This function sets the interface up on the specified device and returns a RESTFUL call to undo shut the specified interface on the target device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_cmd_list(cmd_list):\n    cmd = ''\n    for i in cmd_list:\n        cmd = cmd + '\"' + i + '\",'\n    cmd = cmd[:-1]\n    return cmd", "response": "Helper function to easily create a proper json formated string from a list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new keypair with the given options.", "response": "async def create(cls, user_id: Union[int, str],\n                     is_active: bool = True,\n                     is_admin: bool = False,\n                     resource_policy: str = None,\n                     rate_limit: int = None,\n                     fields: Iterable[str] = None) -> dict:\n        '''\n        Creates a new keypair with the given options.\n        You need an admin privilege for this operation.\n        '''\n        if fields is None:\n            fields = ('access_key', 'secret_key')\n        uid_type = 'Int!' if isinstance(user_id, int) else 'String!'\n        q = 'mutation($user_id: {0}, $input: KeyPairInput!) {{'.format(uid_type) + \\\n            '  create_keypair(user_id: $user_id, props: $input) {' \\\n            '    ok msg keypair { $fields }' \\\n            '  }' \\\n            '}'\n        q = q.replace('$fields', ' '.join(fields))\n        variables = {\n            'user_id': user_id,\n            'input': {\n                'is_active': is_active,\n                'is_admin': is_admin,\n                'resource_policy': resource_policy,\n                'rate_limit': rate_limit,\n            },\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['create_keypair']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the current keypair with the given options.", "response": "async def update(cls, access_key: str,\n                     is_active: bool = None,\n                     is_admin: bool = None,\n                     resource_policy: str = None,\n                     rate_limit: int = None) -> dict:\n        \"\"\"\n        Creates a new keypair with the given options.\n        You need an admin privilege for this operation.\n        \"\"\"\n        q = 'mutation($access_key: String!, $input: ModifyKeyPairInput!) {' + \\\n            '  modify_keypair(access_key: $access_key, props: $input) {' \\\n            '    ok msg' \\\n            '  }' \\\n            '}'\n        variables = {\n            'access_key': access_key,\n            'input': {\n                'is_active': is_active,\n                'is_admin': is_admin,\n                'resource_policy': resource_policy,\n                'rate_limit': rate_limit,\n            },\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['modify_keypair']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def delete(cls, access_key: str):\n        q = 'mutation($access_key: String!) {' \\\n            '  delete_keypair(access_key: $access_key) {' \\\n            '    ok msg' \\\n            '  }' \\\n            '}'\n        variables = {\n            'access_key': access_key,\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['delete_keypair']", "response": "Deletes an existing keypair with given ACCESSKEY."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def list(cls, user_id: Union[int, str] = None,\n                   is_active: bool = None,\n                   fields: Iterable[str] = None) -> Sequence[dict]:\n        '''\n        Lists the keypairs.\n        You need an admin privilege for this operation.\n        '''\n        if fields is None:\n            fields = (\n                'access_key', 'secret_key',\n                'is_active', 'is_admin',\n            )\n        if user_id is None:\n            q = 'query($is_active: Boolean) {' \\\n                '  keypairs(is_active: $is_active) {' \\\n                '    $fields' \\\n                '  }' \\\n                '}'\n        else:\n            uid_type = 'Int!' if isinstance(user_id, int) else 'String!'\n            q = 'query($user_id: {0}, $is_active: Boolean) {{'.format(uid_type) + \\\n                '  keypairs(user_id: $user_id, is_active: $is_active) {' \\\n                '    $fields' \\\n                '  }' \\\n                '}'\n        q = q.replace('$fields', ' '.join(fields))\n        variables = {\n            'is_active': is_active,\n        }\n        if user_id is not None:\n            variables['user_id'] = user_id\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['keypairs']", "response": "Lists the keypairs.\n        You need an admin privilege for this operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def info(self, fields: Iterable[str] = None) -> dict:\n        '''\n        Returns the keypair's information such as resource limits.\n\n        :param fields: Additional per-agent query fields to fetch.\n\n        .. versionadded:: 18.12\n        '''\n        if fields is None:\n            fields = (\n                'access_key', 'secret_key',\n                'is_active', 'is_admin',\n            )\n        q = 'query {' \\\n            '  keypair {' \\\n            '    $fields' \\\n            '  }' \\\n            '}'\n        q = q.replace('$fields', ' '.join(fields))\n        rqst = Request(self.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['keypair']", "response": "Returns the keypair s information such as resource limits and resource limits."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def activate(cls, access_key: str) -> dict:\n        '''\n        Activates this keypair.\n        You need an admin privilege for this operation.\n        '''\n        q = 'mutation($access_key: String!, $input: ModifyKeyPairInput!) {' + \\\n            '  modify_keypair(access_key: $access_key, props: $input) {' \\\n            '    ok msg' \\\n            '  }' \\\n            '}'\n        variables = {\n            'access_key': access_key,\n            'input': {\n                'is_active': True,\n                'is_admin': None,\n                'resource_policy': None,\n                'rate_limit': None,\n            },\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['modify_keypair']", "response": "Activates this keypair.\n        You need an admin privilege for this operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeactivates this keypair. Deactivated keypairs cannot make any API requests unless activated again by an administrator. You need an admin privilege for this operation.", "response": "async def deactivate(cls, access_key: str) -> dict:\n        '''\n        Deactivates this keypair.\n        Deactivated keypairs cannot make any API requests\n        unless activated again by an administrator.\n        You need an admin privilege for this operation.\n        '''\n        q = 'mutation($access_key: String!, $input: ModifyKeyPairInput!) {' + \\\n            '  modify_keypair(access_key: $access_key, props: $input) {' \\\n            '    ok msg' \\\n            '  }' \\\n            '}'\n        variables = {\n            'access_key': access_key,\n            'input': {\n                'is_active': False,\n                'is_admin': None,\n                'resource_policy': None,\n                'rate_limit': None,\n            },\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['modify_keypair']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction adds a new Ip Scope to the HPE IMC base access object.", "response": "def add_ip_scope(auth, url,startIp, endIp, name, description):\n    \"\"\"\n    Function takes input of four strings Start Ip, endIp, name, and description to add new Ip Scope to terminal access\n    in the HPE IMC base platform\n    :param startIp: str Start of IP address scope ex. '10.101.0.1'\n    :param endIp: str End of IP address scope ex. '10.101.0.254'\n    :param name: str Name of the owner of this IP scope  ex. 'admin'\n    :param description: str description of the Ip scope\n    :return:\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n\n    add_ip_scope_url = \"/imcrs/res/access/assignedIpScope\"\n    f_url = url + add_ip_scope_url\n    payload = ('''{  \"startIp\": \"%s\", \"endIp\": \"%s\",\"name\": \"%s\",\"description\": \"%s\" }'''\n               %(str(startIp), str(endIp), str(name), str(description)))\n    r = requests.post(f_url, auth=auth, headers=HEADERS, data=payload) # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            print(\"IP Scope Successfully Created\")\n            return r.status_code\n        elif r.status_code == 409:\n            print (\"IP Scope Already Exists\")\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" add_ip_scope: An Error has occured\"\n\n\n    #Add host to IP scope\n    #http://10.101.0.203:8080/imcrs/res/access/assignedIpScope/ip?ipScopeId=1\n    '''{\n      \"ip\": \"10.101.0.1\",\n      \"name\": \"Cisco2811.lab.local\",\n      \"description\": \"Cisco 2811\",\n      \"parentId\": \"1\"\n    }'''"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def check_presets(cls):\n        '''\n        Lists all resource presets in the current scaling group with additiona\n        information.\n        '''\n        rqst = Request(cls.session, 'POST', '/resource/check-presets')\n        async with rqst.fetch() as resp:\n           return await resp.json()", "response": "Lists all resource presets in the current scaling group with additiona\n        information."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_perf_task(task, auth, url):\n    add_perf_task_url = \"/imcrs/perf/task\"\n    f_url = url + add_perf_task_url\n    payload = json.dumps(task)\n    # creates the URL using the payload variable as the contents\n    r = requests.post(f_url, data = payload, auth=auth, headers=headers)\n    try:\n        return r.status_code\n\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + ' get_dev_alarms: An Error has occured'", "response": "function takes a python dict containing all required fields for a performance task and issues a RESTFUL call to create the performance task."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions takes a str object containing the name of an existing performance task and issues a RESTFUL call to the IMC REST service and returns a list of the performance task s attributes.", "response": "def get_perf_task(task_name, auth, url):\n    \"\"\"\n        function takes the a str object containing the name of an existing performance tasks and issues a RESTFUL call\n        to the IMC REST service. It will return a list\n\n        :param task_name: str containing the name of the performance task\n\n        :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n        :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n        :return: 204\n\n        :rtype: dict\n\n        >>> from pyhpeimc.auth import *\n\n        >>> from pyhpeimc.plat.perf import *\n\n        >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n        >>> selected_task = get_perf_task('Cisco_Temperature', auth.creds, auth.url)\n\n        >>> assert type(selected_task) is dict\n\n        >>> assert 'taskName' in selected_task\n        \"\"\"\n    get_perf_task_url = \"/imcrs/perf/task?name=\"+task_name+\"&orderBy=taskId&desc=false\"\n    f_url = url + get_perf_task_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    try:\n        if r.status_code == 200:\n            perf_task_info = (json.loads(r.text))['task']\n            return perf_task_info\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + ' get_dev_alarms: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_vm_host_info(hostip, auth, url):\n    hostId = get_dev_details(hostip, auth, url)['id']\n    get_vm_host_info_url = \"/imcrs/vrm/host?hostId=\" + str(hostId)\n    f_url = url + get_vm_host_info_url\n    payload = None\n    r = requests.get(f_url, auth=auth,\n                     headers=HEADERS)  # creates the URL using the payload variable as the contents\n    # print(r.status_code)\n    try:\n        if r.status_code == 200:\n            if len(r.text) > 0:\n                return json.loads(r.text)\n        elif r.status_code == 204:\n            print(\"Device is not a supported Hypervisor\")\n            return \"Device is not a supported Hypervisor\"\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_vm_host_info: An Error has occured\"", "response": "function to get information for the target VM"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ac_info_all(auth, url):\n    f_url = url + \"/imcrs/wlan/acInfo/queryAcBasicInfo\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            if len(response.text) > 0:\n                acs = json.loads(response.text)['acBasicInfo']\n                if type(acs) is dict:\n                    acs = [acs]\n                return acs\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_ac_info_all: An Error has occured\"", "response": "function takes no input to RESTFUL call to HP IMC API to get list of ACs that have been discovered in the HPE IMC WSM module"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_imc_creds(h_url=None, imc_server=None, imc_port=None, imc_user=None,imc_pw=None):\n    global auth, url\n    if h_url is None:\n        imc_protocol = input(\n        \"What protocol would you like to use to connect to the IMC server: \\n Press 1 for HTTP: \\n Press 2 for HTTPS:\")\n        if imc_protocol == \"1\":\n            h_url = 'http://'\n        else:\n            h_url = 'https://'\n        imc_server = input(\"What is the ip address of the IMC server?\")\n        imc_port = input(\"What is the port number of the IMC server?\")\n        imc_user = input(\"What is the username of the IMC eAPI user?\")\n        imc_pw = input('''What is the password of the IMC eAPI user?''')\n    url = h_url + imc_server + \":\" + imc_port\n    auth = requests.auth.HTTPDigestAuth(imc_user, imc_pw)\n    test_url = '/imcrs'\n    f_url = url + test_url\n    try:\n        r = requests.get(f_url, auth=auth, headers=headers, verify=False)\n        print (r.status_code)\n        return auth\n    # checks for reqeusts exceptions\n    except requests.exceptions.RequestException as e:\n        print(\"Error:\\n\" + str(e))\n        print(\"\\n\\nThe IMC server address is invalid. Please try again\\n\\n\")\n        set_imc_creds()\n    if r.status_code != 200:  # checks for valid IMC credentials\n        print(\"Error: \\n You're credentials are invalid. Please try again\\n\\n\")\n        set_imc_creds()\n    else:\n        print(\"You've successfully access the IMC eAPI\")", "response": "This function prompts user for IMC server information and credentuials and stores the values in url and auth global variables"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction prints out the object to file handler and saves it to current working directory as pyoutput. txt", "response": "def print_to_file(object):\n    \"\"\"\n    Function takes in object of type str, list, or dict and prints out to current working directory as pyoutput.txt\n    :param:  Object: object of type str, list, or dict\n    :return: No return. Just prints out to file handler and save to current working directory as pyoutput.txt\n    \"\"\"\n    with open ('pyoutput.txt', 'w') as fh:\n        x = None\n        if type(object) is list:\n            x = json.dumps(object, indent = 4)\n        if type(object) is dict:\n            x = json.dumps(object, indent = 4)\n        if type (object) is str:\n            x = object\n        fh.write(x)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_auth(self):\n        url = self.h_url + self.server + \":\" + self.port\n        auth = requests.auth.HTTPDigestAuth(self.username,self.password)\n        auth_url = \"/imcrs\"\n        f_url = url + auth_url\n        try:\n            r = requests.get(f_url, auth=auth, headers=headers, verify=False)\n            return r.status_code\n    # checks for reqeusts exceptions\n        except requests.exceptions.RequestException as e:\n            return (\"Error:\\n\" + str(e) + '\\n\\nThe IMC server address is invalid. Please try again')\n            set_imc_creds()\n        if r.status_code != 200:  # checks for valid IMC credentials\n            return (\"Error:\\n\" + str(e) +\"Error: \\n You're credentials are invalid. Please try again\\n\\n\")\n            set_imc_creds()", "response": "This method requests an authentication object from the HPE IMC NMS and returns an HTTPDigest Auth Object containing the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version(root):\n    version_json = os.path.join(root, 'version.json')\n    if os.path.exists(version_json):\n        with open(version_json, 'r') as version_json_file:\n            return json.load(version_json_file)\n    return None", "response": "Load and return the contents of version. json."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall this instance s request_client s post method with the specified component endpoint_name and identifier_input.", "response": "def fetch(self, endpoint_name, identifier_input, query_params=None):\n        \"\"\"Calls this instance's request_client's post method with the\n        specified component endpoint\n\n        Args:\n            - endpoint_name (str) - The endpoint to call like \"property/value\".\n            - identifier_input - One or more identifiers to request data for. An identifier can\n                be in one of these forms:\n\n                - A list of property identifier dicts:\n                    - A property identifier dict can contain the following keys:\n                      (address, zipcode, unit, city, state, slug, meta).\n                      One of 'address' or 'slug' is required.\n\n                      Ex: [{\"address\": \"82 County Line Rd\",\n                           \"zipcode\": \"72173\",\n                           \"meta\": \"some ID\"}]\n\n                      A slug is a URL-safe string that identifies a property.\n                      These are obtained from HouseCanary.\n\n                      Ex: [{\"slug\": \"123-Example-St-San-Francisco-CA-94105\"}]\n\n                - A list of dicts representing a block:\n                  - A block identifier dict can contain the following keys:\n                      (block_id, num_bins, property_type, meta).\n                      'block_id' is required.\n\n                  Ex: [{\"block_id\": \"060750615003005\", \"meta\": \"some ID\"}]\n\n                - A list of dicts representing a zipcode:\n\n                  Ex: [{\"zipcode\": \"90274\", \"meta\": \"some ID\"}]\n\n                - A list of dicts representing an MSA:\n\n                  Ex: [{\"msa\": \"41860\", \"meta\": \"some ID\"}]\n\n                The \"meta\" field is always optional.\n\n        Returns:\n            A Response object, or the output of a custom OutputGenerator\n            if one was specified in the constructor.\n        \"\"\"\n\n        endpoint_url = constants.URL_PREFIX + \"/\" + self._version + \"/\" + endpoint_name\n\n        if query_params is None:\n            query_params = {}\n\n        if len(identifier_input) == 1:\n            # If only one identifier specified, use a GET request\n            query_params.update(identifier_input[0])\n            return self._request_client.get(endpoint_url, query_params)\n\n        # when more than one address, use a POST request\n        return self._request_client.post(endpoint_url, identifier_input, query_params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls this instance s request_client s get method with the the specified component endpoint", "response": "def fetch_synchronous(self, endpoint_name, query_params=None):\n        \"\"\"Calls this instance's request_client's get method with the\n        specified component endpoint\"\"\"\n\n        endpoint_url = constants.URL_PREFIX + \"/\" + self._version + \"/\" + endpoint_name\n\n        if query_params is None:\n            query_params = {}\n\n        return self._request_client.get(endpoint_url, query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_identifier_input(self, identifier_data):\n\n        identifier_input = []\n\n        if isinstance(identifier_data, list) and len(identifier_data) > 0:\n            # if list, convert each item in the list to json\n            for address in identifier_data:\n                identifier_input.append(self._convert_to_identifier_json(address))\n        else:\n            identifier_input.append(self._convert_to_identifier_json(identifier_data))\n\n        return identifier_input", "response": "Convert the various formats of input identifier_data into\n            the proper json format expected by the ApiClient fetch method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_identifier_component(self, endpoint_name, identifier_data, query_params=None):\n\n        if query_params is None:\n            query_params = {}\n\n        identifier_input = self.get_identifier_input(identifier_data)\n\n        return self._api_client.fetch(endpoint_name, identifier_input, query_params)", "response": "Fetch the identifier component of the given endpoint"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts input address data into json format", "response": "def _convert_to_identifier_json(self, address_data):\n        \"\"\"Convert input address data into json format\"\"\"\n\n        if isinstance(address_data, str):\n            # allow just passing a slug string.\n            return {\"slug\": address_data}\n\n        if isinstance(address_data, tuple) and len(address_data) > 0:\n            address_json = {\"address\": address_data[0]}\n            if len(address_data) > 1:\n                address_json[\"zipcode\"] = address_data[1]\n            if len(address_data) > 2:\n                address_json[\"meta\"] = address_data[2]\n            return address_json\n\n        if isinstance(address_data, dict):\n            allowed_keys = [\"address\", \"zipcode\", \"unit\", \"city\", \"state\", \"slug\", \"meta\",\n                            \"client_value\", \"client_value_sqft\"]\n\n            # ensure the dict does not contain any unallowed keys\n            for key in address_data:\n                if key not in allowed_keys:\n                    msg = \"Key in address input not allowed: \" + key\n                    raise housecanary.exceptions.InvalidInputException(msg)\n\n            # ensure it contains an \"address\" key\n            if \"address\" in address_data or \"slug\" in address_data:\n                return address_data\n\n        # if we made it here, the input was not valid.\n        msg = (\"Input is invalid. Must be a list of (address, zipcode) tuples, or a dict or list\"\n               \" of dicts with each item containing at least an 'address' or 'slug' key.\")\n        raise housecanary.exceptions.InvalidInputException((msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef value_report(self, address, zipcode, report_type=\"full\", format_type=\"json\"):\n        query_params = {\n            \"report_type\": report_type,\n            \"format\": format_type,\n            \"address\": address,\n            \"zipcode\": zipcode\n        }\n\n        return self._api_client.fetch_synchronous(\"property/value_report\", query_params)", "response": "Call the value_report component on the value store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the rental_report component on the specified address and zipcode.", "response": "def rental_report(self, address, zipcode, format_type=\"json\"):\n        \"\"\"Call the rental_report component\n\n        Rental Report only supports a single address.\n\n        Args:\n            - address\n            - zipcode\n\n        Kwargs:\n            - format_type - \"json\", \"xlsx\" or \"all\". Default is \"json\".\n        \"\"\"\n\n        # only json is supported by rental report.\n        query_params = {\n            \"format\": format_type,\n            \"address\": address,\n            \"zipcode\": zipcode\n        }\n\n        return self._api_client.fetch_synchronous(\"property/rental_report\", query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the zip component_mget endpoint.", "response": "def component_mget(self, zip_data, components):\n        \"\"\"Call the zip component_mget endpoint\n\n        Args:\n            - zip_data - As described in the class docstring.\n            - components - A list of strings for each component to include in the request.\n                Example: [\"zip/details\", \"zip/volatility\"]\n        \"\"\"\n        if not isinstance(components, list):\n            print(\"Components param must be a list\")\n            return\n\n        query_params = {\"components\": \",\".join(components)}\n\n        return self.fetch_identifier_component(\n            \"zip/component_mget\", zip_data, query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version(request):\n    version_json = import_string(version_callback)(settings.BASE_DIR)\n    if version_json is None:\n        return HttpResponseNotFound('version.json not found')\n    else:\n        return JsonResponse(version_json)", "response": "Returns the contents of version. json or a 404."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning all the Django checks and returns a JsonResponse with either a status code of 200 or 500 depending on the results of the checks.", "response": "def heartbeat(request):\n    \"\"\"\n    Runs all the Django checks and returns a JsonResponse with either\n    a status code of 200 or 500 depending on the results of the checks.\n\n    Any check that returns a warning or worse (error, critical) will\n    return a 500 response.\n    \"\"\"\n    all_checks = checks.registry.registry.get_checks(\n        include_deployment_checks=not settings.DEBUG,\n    )\n\n    details = {}\n    statuses = {}\n    level = 0\n\n    for check in all_checks:\n        detail = heartbeat_check_detail(check)\n        statuses[check.__name__] = detail['status']\n        level = max(level, detail['level'])\n        if detail['level'] > 0:\n            details[check.__name__] = detail\n\n    if level < checks.messages.WARNING:\n        status_code = 200\n        heartbeat_passed.send(sender=heartbeat, level=level)\n    else:\n        status_code = 500\n        heartbeat_failed.send(sender=heartbeat, level=level)\n\n    payload = {\n        'status': level_to_text(level),\n        'checks': statuses,\n        'details': details,\n    }\n    return JsonResponse(payload, status=status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a list of ComponentResult objects from the json_data.", "response": "def _create_component_results(json_data, result_key):\n    \"\"\" Returns a list of ComponentResult from the json_data\"\"\"\n    component_results = []\n    for key, value in list(json_data.items()):\n        if key not in [result_key, \"meta\"]:\n            component_result = ComponentResult(\n                key,\n                value[\"result\"],\n                value[\"api_code\"],\n                value[\"api_code_description\"]\n            )\n\n            component_results.append(component_result)\n\n    return component_results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether there was a business logic error when fetching data for any components for this property.", "response": "def has_error(self):\n        \"\"\"Returns whether there was a business logic error when fetching data\n        for any components for this property.\n\n        Returns:\n            boolean\n        \"\"\"\n        return next(\n            (True for cr in self.component_results\n             if cr.has_error()),\n            False\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the error messages for this property.", "response": "def get_errors(self):\n        \"\"\"If there were any business errors fetching data for this property,\n        returns the error messages.\n\n        Returns:\n            string - the error message, or None if there was no error.\n\n        \"\"\"\n        return [{cr.component_name: cr.get_error()}\n                for cr in self.component_results if cr.has_error()]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_from_json(cls, json_data):\n        prop = Property()\n        address_info = json_data[\"address_info\"]\n        prop.address = address_info[\"address\"]\n        prop.block_id = address_info[\"block_id\"]\n        prop.zipcode = address_info[\"zipcode\"]\n        prop.zipcode_plus4 = address_info[\"zipcode_plus4\"]\n        prop.address_full = address_info[\"address_full\"]\n        prop.city = address_info[\"city\"]\n        prop.county_fips = address_info[\"county_fips\"]\n        prop.geo_precision = address_info[\"geo_precision\"]\n        prop.lat = address_info[\"lat\"]\n        prop.lng = address_info[\"lng\"]\n        prop.slug = address_info[\"slug\"]\n        prop.state = address_info[\"state\"]\n        prop.unit = address_info[\"unit\"]\n\n        prop.meta = None\n        if \"meta\" in json_data:\n            prop.meta = json_data[\"meta\"]\n\n        prop.component_results = _create_component_results(json_data, \"address_info\")\n\n        return prop", "response": "Deserialize property json data into a Property object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef starts_when(iterable, condition):\n    # type: (Iterable, Union[Callable, Any]) -> Iterable\n    \"\"\"Start yielding items when a condition arise.\n\n    Args:\n        iterable: the iterable to filter.\n        condition: if the callable returns True once, start yielding\n                   items. If it's not a callable, it will be converted\n                   to one as `lambda condition: condition == item`.\n\n    Example:\n\n        >>> list(starts_when(range(10), lambda x: x > 5))\n        [6, 7, 8, 9]\n        >>> list(starts_when(range(10), 7))\n        [7, 8, 9]\n    \"\"\"\n    if not callable(condition):\n        cond_value = condition\n\n        def condition(x):\n            return x == cond_value\n    return itertools.dropwhile(lambda x: not condition(x), iterable)", "response": "Start yielding items when a condition arise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping yielding items when a condition arise.", "response": "def stops_when(iterable, condition):\n    # type: (Iterable, Union[Callable, Any]) -> Iterable\n    \"\"\"Stop yielding items when a condition arise.\n\n    Args:\n        iterable: the iterable to filter.\n        condition: if the callable returns True once, stop yielding\n                   items. If it's not a callable, it will be converted\n                   to one as `lambda condition: condition == item`.\n\n    Example:\n\n        >>> list(stops_when(range(10), lambda x: x > 5))\n        [0, 1, 2, 3, 4, 5]\n        >>> list(stops_when(range(10), 7))\n        [0, 1, 2, 3, 4, 5, 6]\n    \"\"\"\n    if not callable(condition):\n        cond_value = condition\n\n        def condition(x):\n            return x == cond_value\n    return itertools.takewhile(lambda x: not condition(x), iterable)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef skip_duplicates(iterable, key=None, fingerprints=()):\n    # type: (Iterable, Callable, Any) -> Iterable\n    \"\"\"\n        Returns a generator that will yield all objects from iterable, skipping\n        duplicates.\n\n        Duplicates are identified using the `key` function to calculate a\n        unique fingerprint. This does not use natural equality, but the\n        result use a set() to remove duplicates, so defining __eq__\n        on your objects would have no effect.\n\n        By default the fingerprint is the object itself,\n        which ensure the functions works as-is with an iterable of primitives\n        such as int, str or tuple.\n\n        :Example:\n\n            >>> list(skip_duplicates([1, 2, 3, 4, 4, 2, 1, 3 , 4]))\n            [1, 2, 3, 4]\n\n        The return value of `key` MUST be hashable, which means for\n        non hashable objects such as dict, set or list, you need to specify\n        a a function that returns a hashable fingerprint.\n\n        :Example:\n\n            >>> list(skip_duplicates(([], [], (), [1, 2], (1, 2)),\n            ...                      lambda x: tuple(x)))\n            [[], [1, 2]]\n            >>> list(skip_duplicates(([], [], (), [1, 2], (1, 2)),\n            ...                      lambda x: (type(x), tuple(x))))\n            [[], (), [1, 2], (1, 2)]\n\n        For more complex types, such as custom classes, the default behavior\n        is to remove nothing. You MUST provide a `key` function is you wish\n        to filter those.\n\n        :Example:\n\n            >>> class Test(object):\n            ...    def __init__(self, foo='bar'):\n            ...        self.foo = foo\n            ...    def __repr__(self):\n            ...        return \"Test('%s')\" % self.foo\n            ...\n            >>> list(skip_duplicates([Test(), Test(), Test('other')]))\n            [Test('bar'), Test('bar'), Test('other')]\n            >>> list(skip_duplicates([Test(), Test(), Test('other')],\\\n                                     lambda x: x.foo))\n            [Test('bar'), Test('other')]\n\n    \"\"\"\n\n    fingerprints = fingerprints or set()\n    fingerprint = None  # needed on type errors unrelated to hashing\n\n    try:\n        # duplicate some code to gain perf in the most common case\n        if key is None:\n            for x in iterable:\n                if x not in fingerprints:\n                    yield x\n                    fingerprints.add(x)\n        else:\n            for x in iterable:\n                fingerprint = key(x)\n                if fingerprint not in fingerprints:\n                    yield x\n                    fingerprints.add(fingerprint)\n    except TypeError:\n        try:\n            hash(fingerprint)\n        except TypeError:\n            raise TypeError(\n                \"The 'key' function returned a non hashable object of type \"\n                \"'%s' when receiving '%s'. Make sure this function always \"\n                \"returns a hashable object. Hint: immutable primitives like\"\n                \"int, str or tuple, are hashable while dict, set and list are \"\n                \"not.\" % (type(fingerprint), x))\n        else:\n            raise", "response": "Returns a generator that yields all objects from iterable skipping duplicate entries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield items from an iterable in chunks.", "response": "def chunks(iterable, chunksize, cast=tuple):\n    # type: (Iterable, int, Callable) -> Iterable\n    \"\"\"\n        Yields items from an iterator in iterable chunks.\n    \"\"\"\n    it = iter(iterable)\n    while True:\n        yield cast(itertools.chain([next(it)],\n                   itertools.islice(it, chunksize - 1)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef window(iterable, size=2, cast=tuple):\n    # type: (Iterable, int, Callable) -> Iterable\n    \"\"\"\n        Yields iterms by bunch of a given size, but rolling only one item\n        in and out at a time when iterating.\n\n        >>> list(window([1, 2, 3]))\n        [(1, 2), (2, 3)]\n\n        By default, this will cast the window to a tuple before yielding it;\n        however, any function that will accept an iterable as its argument\n        is a valid target.\n\n        If you pass None as a cast value, the deque will be returned as-is,\n        which is more performant. However, since only one deque is used\n        for the entire iteration, you'll get the same reference everytime,\n        only the deque will contains different items. The result might not\n        be what you want :\n\n        >>> list(window([1, 2, 3], cast=None))\n        [deque([2, 3], maxlen=2), deque([2, 3], maxlen=2)]\n\n    \"\"\"\n    iterable = iter(iterable)\n    d = deque(itertools.islice(iterable, size), size)\n    if cast:\n        yield cast(d)\n        for x in iterable:\n            d.append(x)\n            yield cast(d)\n    else:\n        yield d\n        for x in iterable:\n            d.append(x)\n            yield d", "response": "Yields the items in the given iterable in a given size but rolling only one item\n        in and out at a time when iterating."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef at_index(iterable, index):\n    # type: (Iterable[T], int) -> T\n    \"\"\"\" Return the item at the index of this iterable or raises IndexError.\n\n        WARNING: this will consume generators.\n\n        Negative indices are allowed but be aware they will cause n items to\n        be held in memory, where n = abs(index)\n    \"\"\"\n    try:\n        if index < 0:\n            return deque(iterable, maxlen=abs(index)).popleft()\n\n        return next(itertools.islice(iterable, index, index + 1))\n    except (StopIteration, IndexError) as e:\n        raise_from(IndexError('Index \"%d\" out of range' % index), e)", "response": "Return the item at the index of this iterable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef first_true(iterable, func):\n    # type: (Iterable[T], Callable) -> T\n    \"\"\"\" Return the first item of the iterable for which func(item) == True.\n\n        Or raises IndexError.\n\n        WARNING: this will consume generators.\n    \"\"\"\n    try:\n        return next((x for x in iterable if func(x)))\n    except StopIteration as e:\n        # TODO: Find a better error message\n        raise_from(IndexError('No match for %s' % func), e)", "response": "Return the first item of the iterable for which func returns True."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iterslice(iterable, start=0, stop=None, step=1):\n    # type: (Iterable[T], int, int, int) -> Iterable[T]\n    \"\"\" Like itertools.islice, but accept int and callables.\n\n        If `start` is a callable, start the slice after the first time\n        start(item) == True.\n\n        If `stop` is a callable, stop the slice after the first time\n        stop(item) == True.\n    \"\"\"\n\n    if step < 0:\n        raise ValueError(\"The step can not be negative: '%s' given\" % step)\n\n    if not isinstance(start, int):\n\n        # [Callable:Callable]\n        if not isinstance(stop, int) and stop:\n            return stops_when(starts_when(iterable, start), stop)\n\n        # [Callable:int]\n        return starts_when(itertools.islice(iterable, None, stop, step), start)\n\n    # [int:Callable]\n    if not isinstance(stop, int) and stop:\n        return stops_when(itertools.islice(iterable, start, None, step), stop)\n\n    # [int:int]\n    return itertools.islice(iterable, start, stop, step)", "response": "Like itertools. islice but accept int and callables."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef firsts(iterable, items=1, default=None):\n    # type: (Iterable[T], int, T) -> Iterable[T]\n    \"\"\" Lazily return the first x items from this iterable or default. \"\"\"\n\n    try:\n        items = int(items)\n    except (ValueError, TypeError):\n        raise ValueError(\"items should be usable as an int but is currently \"\n                         \"'{}' of type '{}'\".format(items, type(items)))\n\n    # TODO: replace this so that it returns lasts()\n    if items < 0:\n        raise ValueError(ww.f(\"items is {items} but should \"\n                              \"be greater than 0. If you wish to get the last \"\n                              \"items, use the lasts() function.\"))\n\n    i = 0\n    for i, item in zip(range(items), iterable):\n        yield item\n\n    for x in range(items - (i + 1)):\n        yield default", "response": "Lazily return the first x items from this iterable or default."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lasts(iterable, items=1, default=None):\n    # type: (Iterable[T], int, T) -> Iterable[T]\n    \"\"\" Lazily return the last x items from this iterable or default. \"\"\"\n\n    last_items = deque(iterable, maxlen=items)\n\n    for _ in range(items - len(last_items)):\n        yield default\n\n    for y in last_items:\n        yield y", "response": "Lazily return the last x items from this iterable or default."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine execution mode. Legacy mode : <= v4. 20171215", "response": "def is_legacy_server():\n    '''Determine execution mode.\n\n    Legacy mode: <= v4.20181215\n    '''\n    with Session() as session:\n        ret = session.Kernel.hello()\n    bai_version = ret['version']\n    legacy = True if bai_version <= 'v4.20181215' else False\n    return legacy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        '''\n        Terminates the session.  It schedules the ``close()`` coroutine\n        of the underlying aiohttp session and then enqueues a sentinel\n        object to indicate termination.  Then it waits until the worker\n        thread to self-terminate by joining.\n        '''\n        if self._closed:\n            return\n        self._closed = True\n        self._worker_thread.work_queue.put(self.aiohttp_session.close())\n        self._worker_thread.work_queue.put(self.worker_thread.sentinel)\n        self._worker_thread.join()", "response": "Closes the session and waits until the worker thread is self - terminated."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asyncio_run_forever(setup_coro, shutdown_coro, *,\n                        stop_signals={signal.SIGINT}, debug=False):\n    '''\n    A proposed-but-not-implemented asyncio.run_forever() API based on\n    @vxgmichel's idea.\n    See discussions on https://github.com/python/asyncio/pull/465\n    '''\n    async def wait_for_stop():\n        loop = current_loop()\n        future = loop.create_future()\n        for stop_sig in stop_signals:\n            loop.add_signal_handler(stop_sig, future.set_result, stop_sig)\n        try:\n            recv_sig = await future\n        finally:\n            loop.remove_signal_handler(recv_sig)\n\n    loop = asyncio.new_event_loop()\n    try:\n        asyncio.set_event_loop(loop)\n        loop.set_debug(debug)\n        loop.run_until_complete(setup_coro)\n        loop.run_until_complete(wait_for_stop())\n    finally:\n        try:\n            loop.run_until_complete(shutdown_coro)\n            _cancel_all_tasks(loop)\n            if hasattr(loop, 'shutdown_asyncgens'):  # Python 3.6+\n                loop.run_until_complete(loop.shutdown_asyncgens())\n        finally:\n            asyncio.set_event_loop(None)\n            loop.close()", "response": "A proposed - but - not - implemented asyncio. run_forever API based on asyncio. run_forever."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\n\t\t'''\n\t\tclaar all the cache, and release memory\n\t\t'''\n\t\tfor node in self.dli():\n\t\t\tnode.empty = True\n\t\t\tnode.key = None\n\t\t\tnode.value = None\n\t\t\n\t\tself.head = _dlnode()\n\t\tself.head.next = self.head\n\t\tself.head.prev = self.head\n\t\tself.listSize = 1\n\t\t\n\t\tself.table.clear()\n\t\t\n\t\t# status var\n\t\tself.hit_cnt = 0 \n\t\tself.miss_cnt = 0\n\t\tself.remove_cnt = 0", "response": "clear all the cache and release memory"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete the item with the given key. If the key is not present in the dictionary default is returned.", "response": "def pop(self, key, default = None):\n\t\t\"\"\"Delete the item\"\"\"\n\t\tnode = self.get(key, None)\n\t\t\n\t\tif node == None:\n\t\t\tvalue = default\n\t\telse:\n\t\t\tvalue = node\n\t\ttry:\n\t\t\tdel self[key]\n\t\texcept:\n\t\t\treturn value\n\t\treturn value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    try:\n        # Get the `src` directory's absolute path\n        src_path = os.path.dirname(\n            # `aoiklivereload` directory's absolute path\n            os.path.dirname(\n                # `demo` directory's absolute path\n                os.path.dirname(\n                    # This file's absolute path\n                    os.path.abspath(__file__)\n                )\n            )\n        )\n\n        # If the `src` directory path is not in `sys.path`\n        if src_path not in sys.path:\n            # Add to `sys.path`.\n            #\n            # This aims to save user setting PYTHONPATH when running this demo.\n            #\n            sys.path.append(src_path)\n\n        # Import reloader class\n        from aoiklivereload import LiveReloader\n\n        # Create reloader\n        reloader = LiveReloader()\n\n        # Start watcher thread\n        reloader.start_watcher_thread()\n\n        # Server host\n        server_host = '0.0.0.0'\n\n        # Server port\n        server_port = 8000\n\n        # Get message\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(\n            server_host, server_port\n        )\n\n        # Print message\n        print(msg)\n\n        # Create request handler\n        @bottle.get('/')\n        def hello_handler():  # pylint: disable=unused-variable\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            # Return response body\n            return 'hello'\n\n        # Run server\n        bottle.run(host=server_host, port=server_port)\n\n    # If have `KeyboardInterrupt`\n    except KeyboardInterrupt:\n        # Not treat as error\n        pass", "response": "Main function.\n\n    :return:\n        None."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets or create a compute session.", "response": "async def get_or_create(cls, lang: str, *,\n                            client_token: str = None,\n                            mounts: Iterable[str] = None,\n                            envs: Mapping[str, str] = None,\n                            resources: Mapping[str, int] = None,\n                            cluster_size: int = 1,\n                            tag: str = None,\n                            owner_access_key: str = None) -> 'Kernel':\n        '''\n        Get-or-creates a compute session.\n        If *client_token* is ``None``, it creates a new compute session as long as\n        the server has enough resources and your API key has remaining quota.\n        If *client_token* is a valid string and there is an existing compute session\n        with the same token and the same *lang*, then it returns the :class:`Kernel`\n        instance representing the existing session.\n\n        :param lang: The image name and tag for the compute session.\n            Example: ``python:3.6-ubuntu``.\n            Check out the full list of available images in your server using (TODO:\n            new API).\n        :param client_token: A client-side identifier to seamlessly reuse the compute\n            session already created.\n        :param mounts: The list of vfolder names that belongs to the currrent API\n            access key.\n        :param envs: The environment variables which always bypasses the jail policy.\n        :param resources: The resource specification. (TODO: details)\n        :param cluster_size: The number of containers in this compute session.\n            Must be at least 1.\n        :param tag: An optional string to annotate extra information.\n        :param owner: An optional access key that owns the created session. (Only\n            available to administrators)\n\n        :returns: The :class:`Kernel` instance.\n        '''\n        if client_token:\n            assert 4 <= len(client_token) <= 64, \\\n                   'Client session token should be 4 to 64 characters long.'\n        else:\n            client_token = uuid.uuid4().hex\n        if mounts is None:\n            mounts = []\n        if resources is None:\n            resources = {}\n        mounts.extend(cls.session.config.vfolder_mounts)\n        rqst = Request(cls.session, 'POST', '/kernel/create')\n        rqst.set_json({\n            'lang': lang,\n            'tag': tag,\n            'clientSessionToken': client_token,\n            'config': {\n                'mounts': mounts,\n                'environ': envs,\n                'clusterSize': cluster_size,\n                'resources': resources,\n            },\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            o = cls(data['kernelId'], owner_access_key)  # type: ignore\n            o.created = data.get('created', True)     # True is for legacy\n            o.service_ports = data.get('servicePorts', [])\n            return o"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def destroy(self):\n        '''\n        Destroys the compute session.\n        Since the server literally kills the container(s), all ongoing executions are\n        forcibly interrupted.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        rqst = Request(self.session,\n                       'DELETE', '/kernel/{}'.format(self.kernel_id),\n                       params=params)\n        async with rqst.fetch() as resp:\n            if resp.status == 200:\n                return await resp.json()", "response": "Destroys the compute session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def restart(self):\n        '''\n        Restarts the compute session.\n        The server force-destroys the current running container(s), but keeps their\n        temporary scratch directories intact.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        rqst = Request(self.session,\n                       'PATCH', '/kernel/{}'.format(self.kernel_id),\n                       params=params)\n        async with rqst.fetch():\n            pass", "response": "Restarts the compute session."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the auto - completion candidates from the given code string.", "response": "async def complete(self, code: str, opts: dict = None) -> Iterable[str]:\n        '''\n        Gets the auto-completion candidates from the given code string,\n        as if a user has pressed the tab key just after the code in\n        IDEs.\n\n        Depending on the language of the compute session, this feature\n        may not be supported.  Unsupported sessions returns an empty list.\n\n        :param code: An (incomplete) code text.\n        :param opts: Additional information about the current cursor position,\n            such as row, col, line and the remainder text.\n\n        :returns: An ordered list of strings.\n        '''\n        opts = {} if opts is None else opts\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        rqst = Request(self.session,\n            'POST', '/kernel/{}/complete'.format(self.kernel_id),\n            params=params)\n        rqst.set_json({\n            'code': code,\n            'options': {\n                'row': int(opts.get('row', 0)),\n                'col': int(opts.get('col', 0)),\n                'line': opts.get('line', ''),\n                'post': opts.get('post', ''),\n            },\n        })\n        async with rqst.fetch() as resp:\n            return await resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a brief information about the compute session.", "response": "async def get_info(self):\n        '''\n        Retrieves a brief information about the compute session.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        rqst = Request(self.session,\n                       'GET', '/kernel/{}'.format(self.kernel_id),\n                       params=params)\n        async with rqst.fetch() as resp:\n            return await resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def execute(self, run_id: str = None,\n                      code: str = None,\n                      mode: str = 'query',\n                      opts: dict = None):\n        '''\n        Executes a code snippet directly in the compute session or sends a set of\n        build/clean/execute commands to the compute session.\n\n        For more details about using this API, please refer :doc:`the official API\n        documentation <user-api/intro>`.\n\n        :param run_id: A unique identifier for a particular run loop.  In the\n            first call, it may be ``None`` so that the server auto-assigns one.\n            Subsequent calls must use the returned ``runId`` value to request\n            continuation or to send user inputs.\n        :param code: A code snippet as string.  In the continuation requests, it\n            must be an empty string.  When sending user inputs, this is where the\n            user input string is stored.\n        :param mode: A constant string which is one of ``\"query\"``, ``\"batch\"``,\n            ``\"continue\"``, and ``\"user-input\"``.\n        :param opts: A dict for specifying additional options. Mainly used in the\n            batch mode to specify build/clean/execution commands.\n            See :ref:`the API object reference <batch-execution-query-object>`\n            for details.\n\n        :returns: :ref:`An execution result object <execution-result-object>`\n        '''\n        opts = opts if opts is not None else {}\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        if mode in {'query', 'continue', 'input'}:\n            assert code is not None, \\\n                   'The code argument must be a valid string even when empty.'\n            rqst = Request(self.session,\n                'POST', '/kernel/{}'.format(self.kernel_id),\n                params=params)\n            rqst.set_json({\n                'mode': mode,\n                'code': code,\n                'runId': run_id,\n            })\n        elif mode == 'batch':\n            rqst = Request(self.session,\n                'POST', '/kernel/{}'.format(self.kernel_id),\n                params=params)\n            rqst.set_json({\n                'mode': mode,\n                'code': code,\n                'runId': run_id,\n                'options': {\n                    'clean': opts.get('clean', None),\n                    'build': opts.get('build', None),\n                    'buildLog': bool(opts.get('buildLog', False)),\n                    'exec': opts.get('exec', None),\n                },\n            })\n        elif mode == 'complete':\n            rqst = Request(self.session,\n                'POST', '/kernel/{}/complete'.format(self.kernel_id),\n                params=params)\n            rqst.set_json({\n                'code': code,\n                'options': {\n                    'row': int(opts.get('row', 0)),\n                    'col': int(opts.get('col', 0)),\n                    'line': opts.get('line', ''),\n                    'post': opts.get('post', ''),\n                },\n            })\n        else:\n            raise BackendClientError('Invalid execution mode: {0}'.format(mode))\n        async with rqst.fetch() as resp:\n            return (await resp.json())['result']", "response": "Executes a code snippet directly in the compute session or sends a set of build - clean - execute commands to the compute session."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def upload(self, files: Sequence[Union[str, Path]],\n                     basedir: Union[str, Path] = None,\n                     show_progress: bool = False):\n        '''\n        Uploads the given list of files to the compute session.\n        You may refer them in the batch-mode execution or from the code\n        executed in the server afterwards.\n\n        :param files: The list of file paths in the client-side.\n            If the paths include directories, the location of them in the compute\n            session is calculated from the relative path to *basedir* and all\n            intermediate parent directories are automatically created if not exists.\n\n            For example, if a file path is ``/home/user/test/data.txt`` (or\n            ``test/data.txt``) where *basedir* is ``/home/user`` (or the current\n            working directory is ``/home/user``), the uploaded file is located at\n            ``/home/work/test/data.txt`` in the compute session container.\n        :param basedir: The directory prefix where the files reside.\n            The default value is the current working directory.\n        :param show_progress: Displays a progress bar during uploads.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        base_path = (Path.cwd() if basedir is None\n                     else Path(basedir).resolve())\n        files = [Path(file).resolve() for file in files]\n        total_size = 0\n        for file_path in files:\n            total_size += file_path.stat().st_size\n        tqdm_obj = tqdm(desc='Uploading files',\n                        unit='bytes', unit_scale=True,\n                        total=total_size,\n                        disable=not show_progress)\n        with tqdm_obj:\n            attachments = []\n            for file_path in files:\n                try:\n                    attachments.append(AttachedFile(\n                        str(file_path.relative_to(base_path)),\n                        ProgressReportingReader(str(file_path),\n                                                tqdm_instance=tqdm_obj),\n                        'application/octet-stream',\n                    ))\n                except ValueError:\n                    msg = 'File \"{0}\" is outside of the base directory \"{1}\".' \\\n                          .format(file_path, base_path)\n                    raise ValueError(msg) from None\n\n            rqst = Request(self.session,\n                           'POST', '/kernel/{}/upload'.format(self.kernel_id),\n                           params=params)\n            rqst.attach_files(attachments)\n            async with rqst.fetch() as resp:\n                return resp", "response": "Uploads the given list of files to the compute session container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def download(self, files: Sequence[Union[str, Path]],\n                       dest: Union[str, Path] = '.',\n                       show_progress: bool = False):\n        '''\n        Downloads the given list of files from the compute session.\n\n        :param files: The list of file paths in the compute session.\n            If they are relative paths, the path is calculated from\n            ``/home/work`` in the compute session container.\n        :param dest: The destination directory in the client-side.\n        :param show_progress: Displays a progress bar during downloads.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        rqst = Request(self.session,\n                       'GET', '/kernel/{}/download'.format(self.kernel_id),\n                       params=params)\n        rqst.set_json({\n            'files': [*map(str, files)],\n        })\n        async with rqst.fetch() as resp:\n            chunk_size = 1 * 1024\n            file_names = None\n            tqdm_obj = tqdm(desc='Downloading files',\n                            unit='bytes', unit_scale=True,\n                            total=resp.content.total_bytes,\n                            disable=not show_progress)\n            with tqdm_obj as pbar:\n                fp = None\n                while True:\n                    chunk = await resp.aread(chunk_size)\n                    if not chunk:\n                        break\n                    pbar.update(len(chunk))\n                    # TODO: more elegant parsing of multipart response?\n                    for part in chunk.split(b'\\r\\n'):\n                        if part.startswith(b'--'):\n                            if fp:\n                                fp.close()\n                                with tarfile.open(fp.name) as tarf:\n                                    tarf.extractall(path=dest)\n                                    file_names = tarf.getnames()\n                                os.unlink(fp.name)\n                            fp = tempfile.NamedTemporaryFile(suffix='.tar',\n                                                             delete=False)\n                        elif part.startswith(b'Content-') or part == b'':\n                            continue\n                        else:\n                            fp.write(part)\n                if fp:\n                    fp.close()\n                    os.unlink(fp.name)\n            result = {'file_names': file_names}\n            return result", "response": "Downloads the given list of files from the compute session container."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def list_files(self, path: Union[str, Path] = '.'):\n        '''\n        Gets the list of files in the given path inside the compute session\n        container.\n\n        :param path: The directory path in the compute session.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        rqst = Request(self.session,\n                       'GET', '/kernel/{}/files'.format(self.kernel_id),\n                       params=params)\n        rqst.set_json({\n            'path': path,\n        })\n        async with rqst.fetch() as resp:\n            return await resp.json()", "response": "Gets the list of files in the given path inside the compute session\n        container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a pseudo - terminal of the kernel.", "response": "def stream_pty(self) -> 'StreamPty':\n        '''\n        Opens a pseudo-terminal of the kernel (if supported) streamed via\n        websockets.\n\n        :returns: a :class:`StreamPty` object.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        request = Request(self.session,\n                          'GET', '/stream/kernel/{}/pty'.format(self.kernel_id),\n                          params=params)\n        return request.connect_websocket(response_cls=StreamPty)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a code snippet in the streaming mode.", "response": "def stream_execute(self, code: str = '', *,\n                       mode: str = 'query',\n                       opts: dict = None) -> WebSocketResponse:\n        '''\n        Executes a code snippet in the streaming mode.\n        Since the returned websocket represents a run loop, there is no need to\n        specify *run_id* explicitly.\n        '''\n        params = {}\n        if self.owner_access_key:\n            params['owner_access_key'] = self.owner_access_key\n        opts = {} if opts is None else opts\n        if mode == 'query':\n            opts = {}\n        elif mode == 'batch':\n            opts = {\n                'clean': opts.get('clean', None),\n                'build': opts.get('build', None),\n                'buildLog': bool(opts.get('buildLog', False)),\n                'exec': opts.get('exec', None),\n            }\n        else:\n            msg = 'Invalid stream-execution mode: {0}'.format(mode)\n            raise BackendClientError(msg)\n        request = Request(self.session,\n                          'GET', '/stream/kernel/{}/execute'.format(self.kernel_id),\n                          params=params)\n\n        async def send_code(ws):\n            await ws.send_json({\n                'code': code,\n                'mode': mode,\n                'options': opts,\n            })\n\n        return request.connect_websocket(on_enter=send_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _connect(self, mqttc, userdata, flags, rc):\n        if rc == 0:\n            self.connected = True\n            results = []\n            LOGGER.info(\"MQTT Connected with result code \" + str(rc) + \" (Success)\")\n            # result, mid = self._mqttc.subscribe(self.topicInput)\n            results.append((self.topicInput, tuple(self._mqttc.subscribe(self.topicInput))))\n            results.append((self.topicPolyglotConnection, tuple(self._mqttc.subscribe(self.topicPolyglotConnection))))\n            for (topic, (result, mid)) in results:\n                if result == 0:\n                    LOGGER.info(\"MQTT Subscribing to topic: \" + topic + \" - \" + \" MID: \" + str(mid) + \" Result: \" + str(result))\n                else:\n                    LOGGER.info(\"MQTT Subscription to \" + topic + \" failed. This is unusual. MID: \" + str(mid) + \" Result: \" + str(result))\n                    # If subscription fails, try to reconnect.\n                    self._mqttc.reconnect()\n            self._mqttc.publish(self.topicSelfConnection, json.dumps(\n                {\n                    'connected': True,\n                    'node': self.profileNum\n                }), retain=True)\n            LOGGER.info('Sent Connected message to Polyglot')\n        else:\n            LOGGER.error(\"MQTT Failed to connect. Result code: \" + str(rc))", "response": "Callback for when the client receives a CONNACK response from the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _message(self, mqttc, userdata, msg):\n        try:\n            inputCmds = ['query', 'command', 'result', 'status', 'shortPoll', 'longPoll', 'delete']\n            parsed_msg = json.loads(msg.payload.decode('utf-8'))\n            if 'node' in parsed_msg:\n                if parsed_msg['node'] != 'polyglot':\n                    return\n                del parsed_msg['node']\n                for key in parsed_msg:\n                    # LOGGER.debug('MQTT Received Message: {}: {}'.format(msg.topic, parsed_msg))\n                    if key == 'config':\n                        self.inConfig(parsed_msg[key])\n                    elif key == 'connected':\n                        self.polyglotConnected = parsed_msg[key]\n                    elif key == 'stop':\n                        LOGGER.debug('Received stop from Polyglot... Shutting Down.')\n                        self.stop()\n                    elif key in inputCmds:\n                        self.input(parsed_msg)\n                    else:\n                        LOGGER.error('Invalid command received in message from Polyglot: {}'.format(key))\n\n        except (ValueError) as err:\n            LOGGER.error('MQTT Received Payload Error: {}'.format(err), exc_info=True)", "response": "This callback is called when a PUBLISH message is received from the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _disconnect(self, mqttc, userdata, rc):\n        self.connected = False\n        if rc != 0:\n            LOGGER.info(\"MQTT Unexpected disconnection. Trying reconnect.\")\n            try:\n                self._mqttc.reconnect()\n            except Exception as ex:\n                template = \"An exception of type {0} occured. Arguments:\\n{1!r}\"\n                message = template.format(type(ex).__name__, ex.args)\n                LOGGER.error(\"MQTT Connection error: \" + message)\n        else:\n            LOGGER.info(\"MQTT Graceful disconnection.\")", "response": "Callback for when a DISCONNECT occurs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _startMqtt(self):\n        LOGGER.info('Connecting to MQTT... {}:{}'.format(self._server, self._port))\n        try:\n            # self._mqttc.connect_async(str(self._server), int(self._port), 10)\n            self._mqttc.connect_async('{}'.format(self._server), int(self._port), 10)\n            self._mqttc.loop_forever()\n        except Exception as ex:\n            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n            message = template.format(type(ex).__name__, ex.args)\n            LOGGER.error(\"MQTT Connection error: {}\".format(message), exc_info=True)", "response": "Starts the MQTT client thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self):\n        # self.loop.call_soon_threadsafe(self.loop.stop)\n        # self.loop.stop()\n        # self._longPoll.cancel()\n        # self._shortPoll.cancel()\n        if self.connected:\n            LOGGER.info('Disconnecting from MQTT... {}:{}'.format(self._server, self._port))\n            self._mqttc.publish(self.topicSelfConnection, json.dumps({'node': self.profileNum, 'connected': False}), retain=True)\n            self._mqttc.loop_stop()\n            self._mqttc.disconnect()\n        try:\n            for watcher in self.__stopObservers:\n                watcher()\n        except KeyError as e:\n            LOGGER.exception('KeyError in gotConfig: {}'.format(e), exc_info=True)", "response": "Stop the client and disconnect the broker if clean shutdown."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to Polyglot.", "response": "def send(self, message):\n        \"\"\"\n        Formatted Message to send to Polyglot. Connection messages are sent automatically from this module\n        so this method is used to send commands to/from Polyglot and formats it for consumption\n        \"\"\"\n        if not isinstance(message, dict) and self.connected:\n            warnings.warn('payload not a dictionary')\n            return False\n        try:\n            message['node'] = self.profileNum\n            self._mqttc.publish(self.topicInput, json.dumps(message), retain=False)\n        except TypeError as err:\n            LOGGER.error('MQTT Send Error: {}'.format(err), exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addNode(self, node):\n        LOGGER.info('Adding node {}({})'.format(node.name, node.address))\n        message = {\n            'addnode': {\n                'nodes': [{\n                    'address': node.address,\n                    'name': node.name,\n                    'node_def_id': node.id,\n                    'primary': node.primary,\n                    'drivers': node.drivers,\n                    'hint': node.hint\n                }]\n            }\n        }\n        self.send(message)", "response": "Adds a node to the NodeServer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend custom dictionary to Polyglot to save and retrieve on startup.", "response": "def saveCustomData(self, data):\n        \"\"\"\n        Send custom dictionary to Polyglot to save and be retrieved on startup.\n\n        :param data: Dictionary of key value pairs to store in Polyglot database.\n        \"\"\"\n        LOGGER.info('Sending customData to Polyglot.')\n        message = { 'customdata': data }\n        self.send(message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend custom dictionary to Polyglot to save and retrieve on startup.", "response": "def saveCustomParams(self, data):\n        \"\"\"\n        Send custom dictionary to Polyglot to save and be retrieved on startup.\n\n        :param data: Dictionary of key value pairs to store in Polyglot database.\n        \"\"\"\n        LOGGER.info('Sending customParams to Polyglot.')\n        message = { 'customparams': data }\n        self.send(message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding custom notice to Polyglot", "response": "def addNotice(self, data):\n        \"\"\"\n        Add custom notice to front-end for this NodeServers\n\n        :param data: String of characters to add as a notification in the front-end.\n        \"\"\"\n        LOGGER.info('Sending addnotice to Polyglot: {}'.format(data))\n        message = { 'addnotice': data }\n        self.send(message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef removeNotice(self, data):\n        LOGGER.info('Sending removenotice to Polyglot for index {}'.format(data))\n        message = { 'removenotice': data }\n        self.send(message)", "response": "Add custom notice to front - end for this node"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delNode(self, address):\n        LOGGER.info('Removing node {}'.format(address))\n        message = {\n            'removenode': {\n                'address': address\n            }\n        }\n        self.send(message)", "response": "Delete a node from the NodeServer"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getNode(self, address):\n        try:\n            for node in self.config['nodes']:\n                if node['address'] == address:\n                    return node\n            return False\n        except KeyError:\n            LOGGER.error('Usually means we have not received the config yet.', exc_info=True)\n            return False", "response": "Get Node by Address of existing nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inConfig(self, config):\n        self.config = config\n        self.isyVersion = config['isyVersion']\n        try:\n            for watcher in self.__configObservers:\n                watcher(config)\n\n            self.send_custom_config_docs()\n\n        except KeyError as e:\n            LOGGER.error('KeyError in gotConfig: {}'.format(e), exc_info=True)", "response": "Called by Polyglot when a new config is received from Polyglot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_typed_params(self, data):\n        LOGGER.info('Sending typed parameters to Polyglot.')\n        if type(data) is not list:\n            data = [ data ]\n        message = { 'typedparams': data }\n        self.send(message)", "response": "Send typed parameters to Polyglot"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delNode(self, address):\n        if address in self.nodes:\n            del self.nodes[address]\n        self.poly.delNode(address)", "response": "Delete a node from the node list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the database for the specified key - value dictionary.", "response": "async def query(cls, query: str,\n                    variables: Optional[Mapping[str, Any]] = None,\n                    ) -> Any:\n        '''\n        Sends the GraphQL query and returns the response.\n\n        :param query: The GraphQL query string.\n        :param variables: An optional key-value dictionary\n            to fill the interpolated template variables\n            in the query.\n\n        :returns: The object parsed from the response JSON string.\n        '''\n        gql_query = {\n            'query': query,\n            'variables': variables if variables else {},\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json(gql_query)\n        async with rqst.fetch() as resp:\n            return await resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning human readable string from number of seconds", "response": "def get_readable_time_string(seconds):\n    \"\"\"Returns human readable string from number of seconds\"\"\"\n    seconds = int(seconds)\n    minutes = seconds // 60\n    seconds = seconds % 60\n    hours = minutes // 60\n    minutes = minutes % 60\n    days = hours // 24\n    hours = hours % 24\n\n    result = \"\"\n    if days > 0:\n        result += \"%d %s \" % (days, \"Day\" if (days == 1) else \"Days\")\n    if hours > 0:\n        result += \"%d %s \" % (hours, \"Hour\" if (hours == 1) else \"Hours\")\n    if minutes > 0:\n        result += \"%d %s \" % (minutes, \"Minute\" if (minutes == 1) else \"Minutes\")\n    if seconds > 0:\n        result += \"%d %s \" % (seconds, \"Second\" if (seconds == 1) else \"Seconds\")\n\n    return result.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of rate limit information from a given response s headers.", "response": "def get_rate_limits(response):\n    \"\"\"Returns a list of rate limit information from a given response's headers.\"\"\"\n    periods = response.headers['X-RateLimit-Period']\n    if not periods:\n        return []\n\n    rate_limits = []\n\n    periods = periods.split(',')\n    limits = response.headers['X-RateLimit-Limit'].split(',')\n    remaining = response.headers['X-RateLimit-Remaining'].split(',')\n    reset = response.headers['X-RateLimit-Reset'].split(',')\n\n    for idx, period in enumerate(periods):\n        rate_limit = {}\n        limit_period = get_readable_time_string(period)\n        rate_limit[\"period\"] = limit_period\n        rate_limit[\"period_seconds\"] = period\n        rate_limit[\"request_limit\"] = limits[idx]\n        rate_limit[\"requests_remaining\"] = remaining[idx]\n\n        reset_datetime = get_datetime_from_timestamp(reset[idx])\n        rate_limit[\"reset\"] = reset_datetime\n\n        right_now = datetime.now()\n        if (reset_datetime is not None) and (right_now < reset_datetime):\n            # add 1 second because of rounding\n            seconds_remaining = (reset_datetime - right_now).seconds + 1\n        else:\n            seconds_remaining = 0\n\n        rate_limit[\"reset_in_seconds\"] = seconds_remaining\n\n        rate_limit[\"time_to_reset\"] = get_readable_time_string(seconds_remaining)\n        rate_limits.append(rate_limit)\n\n    return rate_limits"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isubset(self, *keys):\n        # type: (*Hashable) -> ww.g\n        \"\"\"Return key, self[key] as generator for key in keys.\n\n        Raise KeyError if a key does not exist\n\n        Args:\n            keys: Iterable containing keys\n\n        Example:\n\n            >>> from ww import d\n            >>> list(d({1: 1, 2: 2, 3: 3}).isubset(1, 3))\n            [(1, 1), (3, 3)]\n        \"\"\"\n        return ww.g((key, self[key]) for key in keys)", "response": "Return key as generator for key in keys Raise KeyError if a key does not exist\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef swap(self):\n        # type: () -> DictWrapper\n        \"\"\"Swap key and value\n\n        /!\\ Be carreful, if there are duplicate values, only one will\n        survive /!\\\n\n        Example:\n\n            >>> from ww import d\n            >>> d({1: 2, 2: 2, 3: 3}).swap()\n            {2: 2, 3: 3}\n        \"\"\"\n        return self.__class__((v, k) for k, v in self.items())", "response": "Swap key and value of a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fromkeys(cls, iterable, value=None):\n        # TODO : type: (Iterable, Union[Any, Callable]) -> DictWrapper\n        # https://github.com/python/mypy/issues/2254\n        \"\"\"Create a new d from\n\n        Args:\n            iterable: Iterable containing keys\n            value: value to associate with each key.\n            If callable, will be value[key]\n\n        Returns: new DictWrapper\n\n        Example:\n\n            >>> from ww import d\n            >>> sorted(d.fromkeys('123', value=4).items())\n            [('1', 4), ('2', 4), ('3', 4)]\n            >>> sorted(d.fromkeys(range(3), value=lambda e:e**2).items())\n            [(0, 0), (1, 1), (2, 4)]\n        \"\"\"\n        if not callable(value):\n            return cls(dict.fromkeys(iterable, value))\n\n        return cls((key, value(key)) for key in iterable)", "response": "Create a new DictWrapper from a list of keys and a value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    try:\n        # Get the `src` directory's absolute path\n        src_path = os.path.dirname(\n            # `aoiklivereload` directory's absolute path\n            os.path.dirname(\n                # `demo` directory's absolute path\n                os.path.dirname(\n                    # This file's absolute path\n                    os.path.abspath(__file__)\n                )\n            )\n        )\n\n        # If the `src` directory path is not in `sys.path`\n        if src_path not in sys.path:\n            # Add to `sys.path`.\n            #\n            # This aims to save user setting PYTHONPATH when running this demo.\n            #\n            sys.path.append(src_path)\n\n        # Import reloader class\n        from aoiklivereload import LiveReloader\n\n        # Create reloader\n        reloader = LiveReloader()\n\n        # Start watcher thread\n        reloader.start_watcher_thread()\n\n        # Server host\n        server_host = '0.0.0.0'\n\n        # Server port\n        server_port = 8000\n\n        # Get message\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(\n            server_host, server_port\n        )\n\n        # Print message\n        print(msg)\n\n        # Create Flask app\n        flask_app = flask.Flask(__name__)\n\n        # Create request handler\n        @flask_app.route('/')\n        def hello_handler():  # pylint: disable=unused-variable\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            # Return response body\n            return 'hello'\n\n        # Run server\n        flask_app.run(\n            host=server_host,\n            port=server_port,\n            # Disable Flask's reloader\n            debug=False,\n        )\n\n    # If have `KeyboardInterrupt`\n    except KeyboardInterrupt:\n        # Not treat as error\n        pass", "response": "Main function.\n\n    :return:\n        None."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating an Excel workbook object given api_data", "response": "def get_excel_workbook(api_data, result_info_key, identifier_keys):\n    \"\"\"Generates an Excel workbook object given api_data returned by the Analytics API\n\n    Args:\n        api_data: Analytics API data as a list of dicts (one per identifier)\n        result_info_key: the key in api_data dicts that contains the data results\n        identifier_keys: the list of keys used as requested identifiers\n                         (address, zipcode, block_id, etc)\n\n    Returns:\n        raw excel file data\n    \"\"\"\n\n    cleaned_data = []\n\n    for item_data in api_data:\n        result_info = item_data.pop(result_info_key, {})\n\n        cleaned_item_data = {}\n\n        if 'meta' in item_data:\n            meta = item_data.pop('meta')\n            cleaned_item_data['meta'] = meta\n\n        for key in item_data:\n            cleaned_item_data[key] = item_data[key]['result']\n\n        cleaned_item_data[result_info_key] = result_info\n\n        cleaned_data.append(cleaned_item_data)\n\n    data_list = copy.deepcopy(cleaned_data)\n\n    workbook = openpyxl.Workbook()\n\n    write_worksheets(workbook, data_list, result_info_key, identifier_keys)\n\n    return workbook"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite rest of the worksheets into the current workbook.", "response": "def write_worksheets(workbook, data_list, result_info_key, identifier_keys):\n    \"\"\"Writes rest of the worksheets to workbook.\n\n    Args:\n        workbook: workbook to write into\n        data_list: Analytics API data as a list of dicts\n        result_info_key: the key in api_data dicts that contains the data results\n        identifier_keys: the list of keys used as requested identifiers\n                         (address, zipcode, block_id, etc)\n    \"\"\"\n\n    # we can use the first item to figure out the worksheet keys\n    worksheet_keys = get_worksheet_keys(data_list[0], result_info_key)\n\n    for key in worksheet_keys:\n\n        title = key.split('/')[1]\n\n        title = utilities.convert_snake_to_title_case(title)\n\n        title = KEY_TO_WORKSHEET_MAP.get(title, title)\n\n        if key == 'property/nod':\n            # the property/nod endpoint needs to be split into two worksheets\n            create_property_nod_worksheets(workbook, data_list, result_info_key, identifier_keys)\n        else:\n            # all other endpoints are written to a single worksheet\n\n            # Maximum 31 characters allowed in sheet title\n            worksheet = workbook.create_sheet(title=title[:31])\n\n            processed_data = process_data(key, data_list, result_info_key, identifier_keys)\n\n            write_data(worksheet, processed_data)\n\n    # remove the first, unused empty sheet\n    workbook.remove_sheet(workbook.active)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_property_nod_worksheets(workbook, data_list, result_info_key, identifier_keys):\n    nod_details_list = []\n    nod_default_history_list = []\n\n    for prop_data in data_list:\n        nod_data = prop_data['property/nod']\n\n        if nod_data is None:\n            nod_data = {}\n\n        default_history_data = nod_data.pop('default_history', [])\n\n        _set_identifier_fields(nod_data, prop_data, result_info_key, identifier_keys)\n\n        nod_details_list.append(nod_data)\n\n        for item in default_history_data:\n            _set_identifier_fields(item, prop_data, result_info_key, identifier_keys)\n            nod_default_history_list.append(item)\n\n    worksheet = workbook.create_sheet(title='NOD Details')\n    write_data(worksheet, nod_details_list)\n\n    worksheet = workbook.create_sheet(title='NOD Default History')\n    write_data(worksheet, nod_default_history_list)", "response": "Creates two worksheets out of the property and nod data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting sorted keys from the dict ignoring result_info_key and meta keys", "response": "def get_worksheet_keys(data_dict, result_info_key):\n    \"\"\"Gets sorted keys from the dict, ignoring result_info_key and 'meta' key\n    Args:\n        data_dict: dict to pull keys from\n\n    Returns:\n        list of keys in the dict other than the result_info_key\n    \"\"\"\n    keys = set(data_dict.keys())\n    keys.remove(result_info_key)\n    if 'meta' in keys:\n        keys.remove('meta')\n    return sorted(keys)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all possible keys from a list of dicts sorting by leading_columns first", "response": "def get_keys(data_list, leading_columns=LEADING_COLUMNS):\n    \"\"\"Gets all possible keys from a list of dicts, sorting by leading_columns first\n\n    Args:\n        data_list: list of dicts to pull keys from\n        leading_columns: list of keys to put first in the result\n\n    Returns:\n        list of keys to be included as columns in excel worksheet\n    \"\"\"\n    all_keys = set().union(*(list(d.keys()) for d in data_list))\n\n    leading_keys = []\n\n    for key in leading_columns:\n        if key not in all_keys:\n            continue\n        leading_keys.append(key)\n        all_keys.remove(key)\n\n    return leading_keys + sorted(all_keys)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a key in api_data dicts pulls the data for that endpoint out of the data_list for each address and processes the data into a more specific format and returns the data.", "response": "def process_data(key, data_list, result_info_key, identifier_keys):\n    \"\"\" Given a key as the endpoint name, pulls the data for that endpoint out\n        of the data_list for each address, processes the data into a more\n        excel-friendly format and returns that data.\n\n        Args:\n            key: the endpoint name of the data to process\n            data_list: the main data list to take the data from\n            result_info_key: the key in api_data dicts that contains the data results\n            identifier_keys: the list of keys used as requested identifiers\n                             (address, zipcode, block_id, etc)\n\n        Returns:\n            A list of dicts (rows) to be written to a worksheet\n    \"\"\"\n    master_data = []\n\n    for item_data in data_list:\n        data = item_data[key]\n\n        if data is None:\n            current_item_data = {}\n        else:\n            if key == 'property/value':\n                current_item_data = data['value']\n\n            elif key == 'property/details':\n                top_level_keys = ['property', 'assessment']\n                current_item_data = flatten_top_level_keys(data, top_level_keys)\n\n            elif key == 'property/school':\n                current_item_data = data['school']\n\n                school_list = []\n                for school_type_key in current_item_data:\n                    schools = current_item_data[school_type_key]\n                    for school in schools:\n                        school['school_type'] = school_type_key\n                        school['school_address'] = school['address']\n                        school['school_zipcode'] = school['zipcode']\n                        school_list.append(school)\n\n                current_item_data = school_list\n\n            elif key == 'property/value_forecast':\n                current_item_data = {}\n                for month_key in data:\n                    current_item_data[month_key] = data[month_key]['value']\n\n            elif key in ['property/value_within_block', 'property/rental_value_within_block']:\n                current_item_data = flatten_top_level_keys(data, [\n                    'housecanary_value_percentile_range',\n                    'housecanary_value_sqft_percentile_range',\n                    'client_value_percentile_range',\n                    'client_value_sqft_percentile_range'\n                ])\n\n            elif key in ['property/zip_details', 'zip/details']:\n                top_level_keys = ['multi_family', 'single_family']\n                current_item_data = flatten_top_level_keys(data, top_level_keys)\n\n            else:\n                current_item_data = data\n\n        if isinstance(current_item_data, dict):\n            _set_identifier_fields(current_item_data, item_data, result_info_key, identifier_keys)\n\n            master_data.append(current_item_data)\n        else:\n            # it's a list\n            for item in current_item_data:\n                _set_identifier_fields(item, item_data, result_info_key, identifier_keys)\n\n            master_data.extend(current_item_data)\n\n    return master_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_database_connected(app_configs, **kwargs):\n    errors = []\n\n    try:\n        connection.ensure_connection()\n    except OperationalError as e:\n        msg = 'Could not connect to database: {!s}'.format(e)\n        errors.append(checks.Error(msg,\n                                   id=health.ERROR_CANNOT_CONNECT_DATABASE))\n    except ImproperlyConfigured as e:\n        msg = 'Datbase misconfigured: \"{!s}\"'.format(e)\n        errors.append(checks.Error(msg,\n                                   id=health.ERROR_MISCONFIGURED_DATABASE))\n    else:\n        if not connection.is_usable():\n            errors.append(checks.Error('Database connection is not usable',\n                                       id=health.ERROR_UNUSABLE_DATABASE))\n\n    return errors", "response": "A Django check to see if connecting to the configured default\n    database backend succeeds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_migrations_applied(app_configs, **kwargs):\n    from django.db.migrations.loader import MigrationLoader\n    errors = []\n\n    # Load migrations from disk/DB\n    try:\n        loader = MigrationLoader(connection, ignore_no_migrations=True)\n    except (ImproperlyConfigured, ProgrammingError, OperationalError):\n        msg = \"Can't connect to database to check migrations\"\n        return [checks.Info(msg, id=health.INFO_CANT_CHECK_MIGRATIONS)]\n\n    if app_configs:\n        app_labels = [app.label for app in app_configs]\n    else:\n        app_labels = loader.migrated_apps\n\n    for node, migration in loader.graph.nodes.items():\n        if migration.app_label not in app_labels:\n            continue\n        if node not in loader.applied_migrations:\n            msg = 'Unapplied migration {}'.format(migration)\n            # NB: This *must* be a Warning, not an Error, because Errors\n            # prevent migrations from being run.\n            errors.append(checks.Warning(msg,\n                                         id=health.WARNING_UNAPPLIED_MIGRATION))\n\n    return errors", "response": "A Django check to see if all migrations have been applied correctly."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks Redis connection and see if Redis ping is successful.", "response": "def check_redis_connected(app_configs, **kwargs):\n    \"\"\"\n    A Django check to connect to the default redis connection\n    using ``django_redis.get_redis_connection`` and see if Redis\n    responds to a ``PING`` command.\n    \"\"\"\n    import redis\n    from django_redis import get_redis_connection\n    errors = []\n\n    try:\n        connection = get_redis_connection('default')\n    except redis.ConnectionError as e:\n        msg = 'Could not connect to redis: {!s}'.format(e)\n        errors.append(checks.Error(msg, id=health.ERROR_CANNOT_CONNECT_REDIS))\n    except NotImplementedError as e:\n        msg = 'Redis client not available: {!s}'.format(e)\n        errors.append(checks.Error(msg, id=health.ERROR_MISSING_REDIS_CLIENT))\n    except ImproperlyConfigured as e:\n        msg = 'Redis misconfigured: \"{!s}\"'.format(e)\n        errors.append(checks.Error(msg, id=health.ERROR_MISCONFIGURED_REDIS))\n    else:\n        result = connection.ping()\n        if not result:\n            msg = 'Redis ping failed'\n            errors.append(checks.Error(msg, id=health.ERROR_REDIS_PING_FAILED))\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions takes in no param as input to fetch Real - Time Alarms from HPE IMC RESTFUL API", "response": "def get_realtime_alarm(username, auth, url):\n    \"\"\"Takes in no param as input to fetch RealTime Alarms from HP IMC RESTFUL API\n\n    :param username OpeatorName, String type. Required. Default Value \"admin\". Checks the operator\n     has the privileges to view the Real-Time Alarms.\n\n    :param devId: int or str value of the target device\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return:list of dictionaries where each element of the list represents a single alarm as pulled from the the current\n     list of realtime alarms in the HPE IMC Platform\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.alarms import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> real_time_alarm = get_realtime_alarm('admin', auth.creds, auth.url)\n\n    >>> type(real_time_alarm)\n    <class 'list'>\n    >>> assert 'faultDesc' in real_time_alarm[0]\n\n    \"\"\"\n    get_realtime_alarm_url = \"/imcrs/fault/faultRealTime?operatorName=\" + username\n    f_url = url + get_realtime_alarm_url\n    r = requests.get(f_url, auth=auth, headers=headers)\n    try:\n        realtime_alarm_list = (json.loads(r.text))\n        return realtime_alarm_list['faultRealTime']['faultRealTimeList']\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + ' get_realtime_alarm: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of dicts where each element of the list represents a single alarm.", "response": "def get_alarms(username, auth, url):\n    \"\"\"Takes in no param as input to fetch RealTime Alarms from HP IMC RESTFUL API\n\n    :param username OpeatorName, String type. Required. Default Value \"admin\". Checks the operator\n     has the privileges to view the Real-Time Alarms.\n\n    :param devId: int or str value of the target device\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return:list of dictionaries where each element of the list represents a single alarm as pulled from the the current\n     list of browse alarms in the HPE IMC Platform\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.alarms import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> all_alarms = get_alarms('admin', auth.creds, auth.url)\n\n    >>> type(all_alarms)\n    <class 'list'>\n    >>> assert 'ackStatus' in all_alarms[0]\n\n\n    [{'OID': '1.3.6.1.4.1.11.2.14.11.15.2.75.5.3.1.6.7',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '1001',\n  'alarmCategoryDesc': 'Wireless Device Alarm',\n  'alarmDesc': 'The device(MAC Address:   F4 B7 E2 95 A0 CD) is detected to be flooding the network. Attack Frame Type: Probe Request.',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187616',\n  'alarmLevel': '3',\n  'alarmLevelDesc': 'Minor',\n  'deviceId': '31',\n  'deviceIp': '10.10.10.5',\n  'deviceName': 'HP830_WSC',\n  'faultTime': '1469471298',\n  'faultTimeDesc': '2016-07-25 14:28:18',\n  'holdInfo': '',\n  'id': '187616',\n  'originalType': '1',\n  'originalTypeDesc': 'Trap',\n  'paras': '*Attack MAC=  F4 B7 E2 95 A0 CD;Attack Frame Type=Probe Request',\n  'parentId': '0',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'},\n {'OID': '1.3.6.1.4.1.25506.4.2.2.2.6.1',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '15',\n  'alarmCategoryDesc': 'Other Alarms from NMS',\n  'alarmDesc': 'iMC alarm system has received 100 alarms about the event (hh3cPeriodicalTrap) of device ADP_Initial_Config(10.20.10.10) from 2016-07-25 12:56:01 to 2016-07-25 14:36:01.',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187625',\n  'alarmLevel': '4',\n  'alarmLevelDesc': 'Warning',\n  'deviceId': '0',\n  'deviceIp': '127.0.0.1',\n  'deviceName': 'NMS',\n  'faultTime': '1469471761',\n  'faultTimeDesc': '2016-07-25 14:36:01',\n  'id': '187625',\n  'originalType': '3',\n  'originalTypeDesc': 'iMC',\n  'paras': 'Start Time=2016-07-25 12:56:01;Stop Time=2016-07-25 14:36:01;Times=100;*Repeat Event Name=hh3cPeriodicalTrap;*Device IP=10.20.10.10;Device Name=ADP_Initial_Config',\n  'parentId': '173953',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'},\n {'OID': '1.3.6.1.4.1.25506.4.2.2.2.6.1',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '15',\n  'alarmCategoryDesc': 'Other Alarms from NMS',\n  'alarmDesc': 'iMC alarm system has received 100 alarms about the event (Some ambient device interferes) of device HP830_WSC(10.10.10.5) from 2016-07-25 14:07:06 to 2016-07-25 14:40:21.',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187626',\n  'alarmLevel': '4',\n  'alarmLevelDesc': 'Warning',\n  'deviceId': '0',\n  'deviceIp': '127.0.0.1',\n  'deviceName': 'NMS',\n  'faultTime': '1469472021',\n  'faultTimeDesc': '2016-07-25 14:40:21',\n  'id': '187626',\n  'originalType': '3',\n  'originalTypeDesc': 'iMC',\n  'paras': 'Start Time=2016-07-25 14:07:06;Stop Time=2016-07-25 14:40:21;Times=100;*Repeat Event Name=Some ambient device interferes;*Device IP=10.10.10.5;Device Name=HP830_WSC',\n  'parentId': '173953',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'},\n {'OID': '1.3.6.1.4.1.25506.4.2.3.2.6.11',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '9',\n  'alarmCategoryDesc': 'Traffic Analysis and Audit Alarm',\n  'alarmDesc': 'The in direction of interface GigabitEthernet1/0/23 on device 192.168.1.221 at 2016-07-25 14:32:00 is greater than the baseline(2.87 Mbps).',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187631',\n  'alarmLevel': '2',\n  'alarmLevelDesc': 'Major',\n  'deviceId': '67',\n  'deviceIp': '10.101.0.203',\n  'deviceName': 'HPEIMC72WIN2K12R2',\n  'faultTime': '1469472140',\n  'faultTimeDesc': '2016-07-25 14:42:20',\n  'holdInfo': '',\n  'id': '187631',\n  'originalType': '3',\n  'originalTypeDesc': 'iMC',\n  'paras': '*UNBA Server Name=NMS;*UNBA Server IP=127.0.0.1;*Alarm Object Name=The in direction of interface GigabitEthernet1/0/23 on device 192.168.1.221;Alarm Occur Time=2016-07-25 14:32:00;Current Flow Speed=48.38 Mbps;Alarm Severity=2;Threshold Speed=2.87 Mbps;Device IP=192.168.1.221;Interface Index=23;Interface Name=GigabitEthernet1/0/23;Flow Direction=1',\n  'parentId': '0',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'},\n {'OID': '1.3.6.1.4.1.25506.4.2.3.2.6.11',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '9',\n  'alarmCategoryDesc': 'Traffic Analysis and Audit Alarm',\n  'alarmDesc': 'The out direction of interface GigabitEthernet1/0/2 on device 192.168.1.221 at 2016-07-25 14:32:00 is greater than the baseline(1.78 Mbps).',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187632',\n  'alarmLevel': '2',\n  'alarmLevelDesc': 'Major',\n  'deviceId': '67',\n  'deviceIp': '10.101.0.203',\n  'deviceName': 'HPEIMC72WIN2K12R2',\n  'faultTime': '1469472140',\n  'faultTimeDesc': '2016-07-25 14:42:20',\n  'holdInfo': '',\n  'id': '187632',\n  'originalType': '3',\n  'originalTypeDesc': 'iMC',\n  'paras': '*UNBA Server Name=NMS;*UNBA Server IP=127.0.0.1;*Alarm Object Name=The out direction of interface GigabitEthernet1/0/2 on device 192.168.1.221;Alarm Occur Time=2016-07-25 14:32:00;Current Flow Speed=48.79 Mbps;Alarm Severity=2;Threshold Speed=1.78 Mbps;Device IP=192.168.1.221;Interface Index=2;Interface Name=GigabitEthernet1/0/2;Flow Direction=0',\n  'parentId': '0',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'},\n {'OID': '1.3.6.1.4.1.25506.4.2.2.2.6.1',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '15',\n  'alarmCategoryDesc': 'Other Alarms from NMS',\n  'alarmDesc': 'iMC alarm system has received 100 alarms about the event (Some ambient AP interferes) of device HP830_WSC(10.10.10.5) from 2016-07-25 14:14:00 to 2016-07-25 14:47:55.',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187637',\n  'alarmLevel': '4',\n  'alarmLevelDesc': 'Warning',\n  'deviceId': '0',\n  'deviceIp': '127.0.0.1',\n  'deviceName': 'NMS',\n  'faultTime': '1469472475',\n  'faultTimeDesc': '2016-07-25 14:47:55',\n  'id': '187637',\n  'originalType': '3',\n  'originalTypeDesc': 'iMC',\n  'paras': 'Start Time=2016-07-25 14:14:00;Stop Time=2016-07-25 14:47:55;Times=100;*Repeat Event Name=Some ambient AP interferes;*Device IP=10.10.10.5;Device Name=HP830_WSC',\n  'parentId': '173953',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'},\n {'OID': '1.3.6.1.4.1.25506.4.2.2.2.6.1',\n  'ackStatus': '0',\n  'ackStatusDesc': 'Unacknowledged',\n  'ackTime': '0',\n  'ackTimeDesc': '',\n  'ackUserName': '',\n  'alarmCategory': '15',\n  'alarmCategoryDesc': 'Other Alarms from NMS',\n  'alarmDesc': 'iMC alarm system has received 100 alarms about the event (Some ambient device interferes) of device HP830_WSC(10.10.10.5) from 2016-07-25 14:40:21 to 2016-07-25 15:15:50.',\n  'alarmDetail': 'http://10.101.0.203:8080/imcrs/fault/alarm/187654',\n  'alarmLevel': '4',\n  'alarmLevelDesc': 'Warning',\n  'deviceId': '0',\n  'deviceIp': '127.0.0.1',\n  'deviceName': 'NMS',\n  'faultTime': '1469474150',\n  'faultTimeDesc': '2016-07-25 15:15:50',\n  'id': '187654',\n  'originalType': '3',\n  'originalTypeDesc': 'iMC',\n  'paras': 'Start Time=2016-07-25 14:40:21;Stop Time=2016-07-25 15:15:50;Times=100;*Repeat Event Name=Some ambient device interferes;*Device IP=10.10.10.5;Device Name=HP830_WSC',\n  'parentId': '173953',\n  'recStatus': '0',\n  'recStatusDesc': 'Unrecovered',\n  'recTime': '0',\n  'recTimeDesc': '',\n  'recUserName': '',\n  'remark': '',\n  'somState': '0'}]\n    \"\"\"\n    get_alarms_url = \"/imcrs/fault/alarm?operatorName=\" + username + \"&recStatus=0&ackStatus=0&timeRange=0&size=50&desc=true\"\n    f_url = url + get_alarms_url\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            alarm_list = (json.loads(r.text))\n            return alarm_list['alarm']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_alarms: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dev_alarms(auth, url, devid=None, devip=None):\n    # checks to see if the imc credentials are already available\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    f_url = url + \"/imcrs/fault/alarm?operatorName=admin&deviceId=\" + \\\n                        str(devid) + \"&desc=false\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_alarm = (json.loads(response.text))\n            if 'alarm' in dev_alarm:\n                return dev_alarm['alarm']\n            else:\n                return \"Device has no alarms\"\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_dev_alarms: An Error has occured'", "response": "function takes the devId of a specific device and issues a RESTFUL call to get the current alarms for that device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_realtime_alarm(username, auth, url):\n    f_url = url + \"/imcrs/fault/faultRealTime?operatorName=\" + username\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        realtime_alarm_list = (json.loads(response.text))\n        return realtime_alarm_list['faultRealTime']['faultRealTimeList']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_realtime_alarm: An Error has occured'", "response": "Function takes in no param as input to fetch Real - Time Alarms from HP IMC RESTFUL API"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_alarms(username, auth, url):\n    f_url = url + \"/imcrs/fault/alarm?operatorName=\" + username + \\\n                     \"&recStatus=0&ackStatus=0&timeRange=0&size=50&desc=true\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            alarm_list = (json.loads(response.text))\n            return alarm_list['alarm']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_alarms: An Error has occured'", "response": "Function takes in no param as input to fetch Real - Time Alarms from HP IMC RESTFUL API"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to take str input of alarm_id issues a REST call to the IMC REST interface and returns the details of a specific alarm", "response": "def get_alarm_details(alarm_id, auth, url):\n    \"\"\"\n    function to take str input of alarm_id, issues a REST call to the IMC REST interface and\n    returns a dictionary object which contains the  details of a specific alarm.\n    :param alarm_id: str number which represents the internal ID of a specific alarm\n    :param auth:\n    :param url:\n    :return:\n    \"\"\"\n    f_url = url + \"/imcrs/fault/alarm/\" + str(alarm_id)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        alarm_details = json.loads(response.text)\n        return alarm_details\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_alarm_details: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction sends to REST API to acknowledge the specified alarm in the IMC alarm database.", "response": "def acknowledge_alarm(alarm_id, auth, url):\n    \"\"\"\n    Function tasks input of str of alarm ID and sends to REST API. Function will acknowledge\n    designated alarm in the IMC alarm database.\n    :param alarm_id: str of alarm ID\n    param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n    :return: integer HTTP response code\n\n    :rtype int\n    \"\"\"\n    f_url = url + \"/imcrs/fault/alarm/acknowledge/\"+str(alarm_id)\n    response = requests.put(f_url, auth=auth, headers=HEADERS)\n    try:\n        return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_alarms: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_operator(operator, auth, url,headers=HEADERS):\n    create_operator_url = '/imcrs/plat/operator'\n    f_url = url + create_operator_url\n    payload = json.dumps(operator, indent=4)\n    # creates the URL using the payload variable as the contents\n    r = requests.post(f_url, data=payload, auth=auth, headers=headers)\n    try:\n        if r.status_code == 409:\n            #print(\"Operator Already Exists\")\n            return r.status_code\n        elif r.status_code == 201:\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' create_operator: An Error has occured'", "response": "Function creates a new operator in HPE IMC Restful API"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists virtual folders that belongs to the current user.", "response": "def list():\n    '''List virtual folders that belongs to the current user.'''\n    fields = [\n        ('Name', 'name'),\n        ('ID', 'id'),\n        ('Owner', 'is_owner'),\n        ('Permission', 'permission'),\n    ]\n    with Session() as session:\n        try:\n            resp = session.VFolder.list()\n            if not resp:\n                print('There is no virtual folders created yet.')\n                return\n            rows = (tuple(vf[key] for _, key in fields) for vf in resp)\n            hdrs = (display_name for display_name, _ in fields)\n            print(tabulate(rows, hdrs))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_hosts():\n    '''List the hosts of virtual folders that is accessible to the current user.'''\n    with Session() as session:\n        try:\n            resp = session.VFolder.list_hosts()\n            print(f\"Default vfolder host: {resp['default']}\")\n            print(f\"Usable hosts: {', '.join(resp['allowed'])}\")\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)", "response": "List the hosts of virtual folders that is accessible to the current user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(name, host):\n    '''Create a new virtual folder.\n\n    \\b\n    NAME: Name of a virtual folder.\n    HOST: Name of a virtual folder host in which the virtual folder will be created.\n    '''\n    with Session() as session:\n        try:\n            result = session.VFolder.create(name, host)\n            print('Virtual folder \"{0}\" is created.'.format(result['name']))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)", "response": "Create a new virtual folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the given virtual folder. This operation is irreversible!", "response": "def delete(name):\n    '''Delete the given virtual folder. This operation is irreversible!\n\n    NAME: Name of a virtual folder.\n    '''\n    with Session() as session:\n        try:\n            session.VFolder(name).delete()\n            print_done('Deleted.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenames the given virtual folder.", "response": "def rename(old_name, new_name):\n    '''Rename the given virtual folder. This operation is irreversible!\n    You cannot change the vfolders that are shared by other users,\n    and the new name must be unique among all your accessible vfolders\n    including the shared ones.\n\n    OLD_NAME: The current name of a virtual folder.\n    NEW_NAME: The new name of a virtual folder.\n    '''\n    with Session() as session:\n        try:\n            session.VFolder(old_name).rename(new_name)\n            print_done('Renamed.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef info(name):\n    '''Show the information of the given virtual folder.\n\n    NAME: Name of a virtual folder.\n    '''\n    with Session() as session:\n        try:\n            result = session.VFolder(name).info()\n            print('Virtual folder \"{0}\" (ID: {1})'\n                  .format(result['name'], result['id']))\n            print('- Owner:', result['is_owner'])\n            print('- Permission:', result['permission'])\n            print('- Number of files: {0}'.format(result['numFiles']))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)", "response": "Show the information of the given virtual folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(name, filenames):\n    '''\n    Download a file from the virtual folder to the current working directory.\n    The files with the same names will be overwirtten.\n\n    \\b\n    NAME: Name of a virtual folder.\n    FILENAMES: Paths of the files to be uploaded.\n    '''\n    with Session() as session:\n        try:\n            session.VFolder(name).download(filenames, show_progress=True)\n            print_done('Done.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)", "response": "Downloads a file from the virtual folder to the current working directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an empty directory in the virtual folder.", "response": "def mkdir(name, path):\n    '''Create an empty directory in the virtual folder.\n\n    \\b\n    NAME: Name of a virtual folder.\n    PATH: The name or path of directory. Parent directories are created automatically\n          if they do not exist.\n    '''\n    with Session() as session:\n        try:\n            session.VFolder(name).mkdir(path)\n            print_done('Done.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes files in a virtual folder.", "response": "def rm(name, filenames, recursive):\n    '''\n    Delete files in a virtual folder.\n    If one of the given paths is a directory and the recursive option is enabled,\n    all its content and the directory itself are recursively deleted.\n\n    This operation is irreversible!\n\n    \\b\n    NAME: Name of a virtual folder.\n    FILENAMES: Paths of the files to delete.\n    '''\n    with Session() as session:\n        try:\n            if input(\"> Are you sure? (y/n): \").lower().strip()[:1] == 'y':\n                session.VFolder(name).delete_files(\n                    filenames,\n                    recursive=recursive)\n                print_done('Done.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist files in a virtual folder.", "response": "def ls(name, path):\n    \"\"\"\n    List files in a path of a virtual folder.\n\n    \\b\n    NAME: Name of a virtual folder.\n    PATH: Path inside vfolder.\n    \"\"\"\n    with Session() as session:\n        try:\n            print_wait('Retrieving list of files in \"{}\"...'.format(path))\n            result = session.VFolder(name).list_files(path)\n            if 'error_msg' in result and result['error_msg']:\n                print_fail(result['error_msg'])\n                return\n            files = json.loads(result['files'])\n            table = []\n            headers = ['file name', 'size', 'modified', 'mode']\n            for file in files:\n                mdt = datetime.fromtimestamp(file['mtime'])\n                mtime = mdt.strftime('%b %d %Y %H:%M:%S')\n                row = [file['filename'], file['size'], mtime, file['mode']]\n                table.append(row)\n            print_done('Retrived.')\n            print(tabulate(table, headers=headers))\n        except Exception as e:\n            print_error(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef invite(name, emails, perm):\n    with Session() as session:\n        try:\n            assert perm in ['rw', 'ro'], \\\n                   'Invalid permission: {}'.format(perm)\n            result = session.VFolder(name).invite(perm, emails)\n            invited_ids = result.get('invited_ids', [])\n            if len(invited_ids) > 0:\n                print('Invitation sent to:')\n                for invitee in invited_ids:\n                    print('\\t- ' + invitee)\n            else:\n                print('No users found. Invitation was not sent.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)", "response": "Invite other users to access the virtual folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists and manage received invitations.", "response": "def invitations():\n    \"\"\"List and manage received invitations.\n    \"\"\"\n    with Session() as session:\n        try:\n            result = session.VFolder.invitations()\n            invitations = result.get('invitations', [])\n            if len(invitations) < 1:\n                print('No invitations.')\n                return\n            print('List of invitations (inviter, vfolder id, permission):')\n            for cnt, inv in enumerate(invitations):\n                if inv['perm'] == 'rw':\n                    perm = 'read-write'\n                elif inv['perm'] == 'ro':\n                    perm = 'read-only'\n                else:\n                    perm = inv['perm']\n                print('[{}] {}, {}, {}'.format(cnt + 1, inv['inviter'],\n                                               inv['vfolder_id'], perm))\n\n            selection = input('Choose invitation number to manage: ')\n            if selection.isdigit():\n                selection = int(selection) - 1\n            else:\n                return\n            if 0 <= selection < len(invitations):\n                while True:\n                    action = input('Choose action. (a)ccept, (r)eject, (c)ancel: ')\n                    if action.lower() == 'a':\n                        # TODO: Let user can select access_key among many.\n                        #       Currently, the config objects holds only one key.\n                        config = get_config()\n                        result = session.VFolder.accept_invitation(\n                            invitations[selection]['id'], config.access_key)\n                        print(result['msg'])\n                        break\n                    elif action.lower() == 'r':\n                        result = session.VFolder.delete_invitation(\n                            invitations[selection]['id'])\n                        print(result['msg'])\n                        break\n                    elif action.lower() == 'c':\n                        break\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a given check callback with the provided object to the list of checks. Useful for built - ins advanced custom checks.", "response": "def init_check(self, check, obj):\n        \"\"\"\n        Adds a given check callback with the provided object to the list\n        of checks. Useful for built-ins but also advanced custom checks.\n        \"\"\"\n        self.logger.info('Adding extension check %s' % check.__name__)\n        check = functools.wraps(check)(functools.partial(check, obj))\n        self.check(func=check)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the extension with the given app.", "response": "def init_app(self, app):\n        \"\"\"\n        Initializes the extension with the given app, registers the\n        built-in views with an own blueprint and hooks up our signal\n        callbacks.\n        \"\"\"\n        # If no version path was provided in the init of the Dockerflow\n        # class we'll use the parent directory of the app root path.\n        if self.version_path is None:\n            self.version_path = os.path.dirname(app.root_path)\n\n        for view in (\n            ('/__version__', 'version', self._version_view),\n            ('/__heartbeat__', 'heartbeat', self._heartbeat_view),\n            ('/__lbheartbeat__', 'lbheartbeat', self._lbheartbeat_view),\n        ):\n            self._blueprint.add_url_rule(*view)\n        self._blueprint.before_app_request(self._before_request)\n        self._blueprint.after_app_request(self._after_request)\n        self._blueprint.app_errorhandler(HeartbeatFailure)(self._heartbeat_exception_handler)\n        app.register_blueprint(self._blueprint)\n        got_request_exception.connect(self._got_request_exception, sender=app)\n\n        if not hasattr(app, 'extensions'):  # pragma: nocover\n            app.extensions = {}\n        app.extensions['dockerflow'] = self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _after_request(self, response):\n        if not getattr(g, '_has_exception', False):\n            extra = self.summary_extra()\n            self.summary_logger.info('', extra=extra)\n        return response", "response": "Called by the HTTP server when the request has finished."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when a request exception occurs.", "response": "def _got_request_exception(self, sender, exception, **extra):\n        \"\"\"\n        The signal handler for the got_request_exception signal.\n        \"\"\"\n        extra = self.summary_extra()\n        extra['errno'] = 500\n        self.summary_logger.error(str(exception), extra=extra)\n        g._has_exception = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef user_id(self):\n        # This needs flask-login to be installed\n        if not has_flask_login:\n            return\n\n        # and the actual login manager installed\n        if not hasattr(current_app, 'login_manager'):\n            return\n\n        # fail if no current_user was attached to the request context\n        try:\n            is_authenticated = current_user.is_authenticated\n        except AttributeError:\n            return\n\n        # because is_authenticated could be a callable, call it\n        if callable(is_authenticated):\n            is_authenticated = is_authenticated()\n\n        # and fail if the user isn't authenticated\n        if not is_authenticated:\n            return\n\n        # finally return the user id\n        return current_user.get_id()", "response": "Return the ID of the current user"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef summary_extra(self):\n        out = {\n            'errno': 0,\n            'agent': request.headers.get('User-Agent', ''),\n            'lang': request.headers.get('Accept-Language', ''),\n            'method': request.method,\n            'path': request.path,\n        }\n\n        # set the uid value to the current user ID\n        user_id = self.user_id()\n        if user_id is None:\n            user_id = ''\n        out['uid'] = user_id\n\n        # the rid value to the current request ID\n        request_id = g.get('_request_id', None)\n        if request_id is not None:\n            out['rid'] = request_id\n\n        # and the t value to the time it took to render\n        start_timestamp = g.get('_start_timestamp', None)\n        if start_timestamp is not None:\n            # Duration of request, in milliseconds.\n            out['t'] = int(1000 * (time.time() - start_timestamp))\n\n        return out", "response": "Build the extra data for the summary logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nview that returns the contents of version. json or a 404.", "response": "def _version_view(self):\n        \"\"\"\n        View that returns the contents of version.json or a 404.\n        \"\"\"\n        version_json = self._version_callback(self.version_path)\n        if version_json is None:\n            return 'version.json not found', 404\n        else:\n            return jsonify(version_json)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _heartbeat_view(self):\n        details = {}\n        statuses = {}\n        level = 0\n\n        for name, check in self.checks.items():\n            detail = self._heartbeat_check_detail(check)\n            statuses[name] = detail['status']\n            level = max(level, detail['level'])\n            if detail['level'] > 0:\n                details[name] = detail\n\n        payload = {\n            'status': checks.level_to_text(level),\n            'checks': statuses,\n            'details': details,\n        }\n\n        def render(status_code):\n            return make_response(jsonify(payload), status_code)\n\n        if level < checks.WARNING:\n            status_code = 200\n            heartbeat_passed.send(self, level=level)\n            return render(status_code)\n        else:\n            status_code = 500\n            heartbeat_failed.send(self, level=level)\n            raise HeartbeatFailure(response=render(status_code))", "response": "Runs all the registered checks and returns a JSON response with either a status code of 200 or 500 depending on the results of the checks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef drange(start: Decimal, stop: Decimal, num: int):\n    '''\n    A simplified version of numpy.linspace with default options\n    '''\n    delta = stop - start\n    step = delta / (num - 1)\n    yield from (start + step * Decimal(tick) for tick in range(0, num))", "response": "A simplified version of numpy. linspace with default options\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef range_expr(arg):\n    '''\n    Accepts a range expression which generates a range of values for a variable.\n\n    Linear space range: \"linspace:1,2,10\" (start, stop, num) as in numpy.linspace\n    Pythonic range: \"range:1,10,2\" (start, stop[, step]) as in Python's range\n    Case range: \"case:a,b,c\" (comma-separated strings)\n    '''\n    key, value = arg.split('=', maxsplit=1)\n    assert _rx_range_key.match(key), 'The key must be a valid slug string.'\n    try:\n        if value.startswith('case:'):\n            return key, value[5:].split(',')\n        elif value.startswith('linspace:'):\n            start, stop, num = value[9:].split(',')\n            return key, tuple(drange(Decimal(start), Decimal(stop), int(num)))\n        elif value.startswith('range:'):\n            range_args = map(int, value[6:].split(','))\n            return key, tuple(range(*range_args))\n        else:\n            raise ArgumentTypeError('Unrecognized range expression type')\n    except ValueError as e:\n        raise ArgumentTypeError(str(e))", "response": "Generates a range expression which generates a range of values for a variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def exec_loop(stdout, stderr, kernel, mode, code, *, opts=None,\n                    vprint_done=print_done, is_multi=False):\n    '''\n    Fully streamed asynchronous version of the execute loop.\n    '''\n    async with kernel.stream_execute(code, mode=mode, opts=opts) as stream:\n        async for result in stream:\n            if result.type == aiohttp.WSMsgType.TEXT:\n                result = json.loads(result.data)\n            else:\n                # future extension\n                continue\n            for rec in result.get('console', []):\n                if rec[0] == 'stdout':\n                    print(rec[1], end='', file=stdout)\n                elif rec[0] == 'stderr':\n                    print(rec[1], end='', file=stderr)\n                else:\n                    print('----- output record (type: {0}) -----'.format(rec[0]),\n                          file=stdout)\n                    print(rec[1], file=stdout)\n                    print('----- end of record -----', file=stdout)\n            stdout.flush()\n            files = result.get('files', [])\n            if files:\n                print('--- generated files ---', file=stdout)\n                for item in files:\n                    print('{0}: {1}'.format(item['name'], item['url']), file=stdout)\n                print('--- end of generated files ---', file=stdout)\n            if result['status'] == 'clean-finished':\n                exitCode = result.get('exitCode')\n                msg = 'Clean finished. (exit code = {0})'.format(exitCode)\n                if is_multi:\n                    print(msg, file=stderr)\n                vprint_done(msg)\n            elif result['status'] == 'build-finished':\n                exitCode = result.get('exitCode')\n                msg = 'Build finished. (exit code = {0})'.format(exitCode)\n                if is_multi:\n                    print(msg, file=stderr)\n                vprint_done(msg)\n            elif result['status'] == 'finished':\n                exitCode = result.get('exitCode')\n                msg = 'Execution finished. (exit code = {0})'.format(exitCode)\n                if is_multi:\n                    print(msg, file=stderr)\n                vprint_done(msg)\n                break\n            elif result['status'] == 'waiting-input':\n                if result['options'].get('is_password', False):\n                    code = getpass.getpass()\n                else:\n                    code = input()\n                await stream.send_str(code)\n            elif result['status'] == 'continued':\n                pass", "response": "Execute the code in a single asynchronous thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exec_loop_sync(stdout, stderr, kernel, mode, code, *, opts=None,\n                   vprint_done=print_done):\n    '''\n    Old synchronous polling version of the execute loop.\n    '''\n    opts = opts if opts else {}\n    run_id = None  # use server-assigned run ID\n    while True:\n        result = kernel.execute(run_id, code, mode=mode, opts=opts)\n        run_id = result['runId']\n        opts.clear()  # used only once\n        for rec in result['console']:\n            if rec[0] == 'stdout':\n                print(rec[1], end='', file=stdout)\n            elif rec[0] == 'stderr':\n                print(rec[1], end='', file=stderr)\n            else:\n                print('----- output record (type: {0}) -----'.format(rec[0]),\n                      file=stdout)\n                print(rec[1], file=stdout)\n                print('----- end of record -----', file=stdout)\n        stdout.flush()\n        files = result.get('files', [])\n        if files:\n            print('--- generated files ---', file=stdout)\n            for item in files:\n                print('{0}: {1}'.format(item['name'], item['url']), file=stdout)\n            print('--- end of generated files ---', file=stdout)\n        if result['status'] == 'clean-finished':\n            exitCode = result.get('exitCode')\n            vprint_done('Clean finished. (exit code = {0}'.format(exitCode),\n                        file=stdout)\n            mode = 'continue'\n            code = ''\n        elif result['status'] == 'build-finished':\n            exitCode = result.get('exitCode')\n            vprint_done('Build finished. (exit code = {0})'.format(exitCode),\n                        file=stdout)\n            mode = 'continue'\n            code = ''\n        elif result['status'] == 'finished':\n            exitCode = result.get('exitCode')\n            vprint_done('Execution finished. (exit code = {0})'.format(exitCode),\n                        file=stdout)\n            break\n        elif result['status'] == 'waiting-input':\n            mode = 'input'\n            if result['options'].get('is_password', False):\n                code = getpass.getpass()\n            else:\n                code = input()\n        elif result['status'] == 'continued':\n            mode = 'continue'\n            code = ''", "response": "Execute a single kernel loop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(lang, files, session_id, cluster_size, code, clean, build, exec, terminal,\n        basedir, rm, env, env_range, build_range, exec_range, max_parallel, mount,\n        stats, tag, resources, quiet):\n    '''\n    Run the given code snippet or files in a session.\n    Depending on the session ID you give (default is random),\n    it may reuse an existing session or create a new one.\n\n    \\b\n    LANG: The name (and version/platform tags appended after a colon) of session\n          runtime or programming language.')\n    FILES: The code file(s). Can be added multiple times.\n    '''\n    if quiet:\n        vprint_info = vprint_wait = vprint_done = _noop\n    else:\n        vprint_info = print_info\n        vprint_wait = print_wait\n        vprint_done = print_done\n    if files and code:\n        print('You can run only either source files or command-line '\n              'code snippet.', file=sys.stderr)\n        sys.exit(1)\n    if not files and not code:\n        print('You should provide the command-line code snippet using '\n              '\"-c\" option if run without files.', file=sys.stderr)\n        sys.exit(1)\n\n    envs = _prepare_env_arg(env)\n    resources = _prepare_resource_arg(resources)\n    mount = _prepare_mount_arg(mount)\n\n    if not (1 <= cluster_size < 4):\n        print('Invalid cluster size.', file=sys.stderr)\n        sys.exit(1)\n\n    if env_range is None: env_range = []      # noqa\n    if build_range is None: build_range = []  # noqa\n    if exec_range is None: exec_range = []    # noqa\n\n    env_ranges = {v: r for v, r in env_range}\n    build_ranges = {v: r for v, r in build_range}\n    exec_ranges = {v: r for v, r in exec_range}\n\n    env_var_maps = [dict(zip(env_ranges.keys(), values))\n                    for values in itertools.product(*env_ranges.values())]\n    build_var_maps = [dict(zip(build_ranges.keys(), values))\n                      for values in itertools.product(*build_ranges.values())]\n    exec_var_maps = [dict(zip(exec_ranges.keys(), values))\n                     for values in itertools.product(*exec_ranges.values())]\n    case_set = collections.OrderedDict()\n    vmaps_product = itertools.product(env_var_maps, build_var_maps, exec_var_maps)\n    build_template = string.Template(build)\n    exec_template = string.Template(exec)\n    env_templates = {k: string.Template(v) for k, v in envs.items()}\n    for env_vmap, build_vmap, exec_vmap in vmaps_product:\n        interpolated_envs = tuple((k, vt.substitute(env_vmap))\n                                  for k, vt in env_templates.items())\n        if build:\n            interpolated_build = build_template.substitute(build_vmap)\n        else:\n            interpolated_build = '*'\n        if exec:\n            interpolated_exec = exec_template.substitute(exec_vmap)\n        else:\n            interpolated_exec = '*'\n        case_set[(interpolated_envs, interpolated_build, interpolated_exec)] = 1\n\n    is_multi = (len(case_set) > 1)\n    if is_multi:\n        if max_parallel <= 0:\n            print('The number maximum parallel sessions must be '\n                  'a positive integer.', file=sys.stderr)\n            sys.exit(1)\n        if terminal:\n            print('You cannot run multiple cases with terminal.', file=sys.stderr)\n            sys.exit(1)\n        if not quiet:\n            vprint_info('Running multiple sessions for the following combinations:')\n            for case in case_set.keys():\n                pretty_env = ' '.join('{}={}'.format(item[0], item[1])\n                                      for item in case[0])\n                print('env = {!r}, build = {!r}, exec = {!r}'\n                      .format(pretty_env, case[1], case[2]))\n\n    def _run_legacy(session, idx, session_id, envs,\n                    clean_cmd, build_cmd, exec_cmd):\n        try:\n            kernel = session.Kernel.get_or_create(\n                lang,\n                client_token=session_id,\n                cluster_size=cluster_size,\n                mounts=mount,\n                envs=envs,\n                resources=resources,\n                tag=tag)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if kernel.created:\n            vprint_done('[{0}] Session {0} is ready.'.format(idx, kernel.kernel_id))\n        else:\n            vprint_done('[{0}] Reusing session {0}...'.format(idx, kernel.kernel_id))\n        if kernel.service_ports:\n            print_info('This session provides the following app services: '\n                       ', '.join(sport['name'] for sport in kernel.service_ports))\n\n        try:\n            if files:\n                vprint_wait('[{0}] Uploading source files...'.format(idx))\n                ret = kernel.upload(files, basedir=basedir,\n                                    show_progress=True)\n                if ret.status // 100 != 2:\n                    print_fail('[{0}] Uploading source files failed!'.format(idx))\n                    print('{0}: {1}\\n{2}'.format(\n                        ret.status, ret.reason, ret.text()))\n                    return\n                vprint_done('[{0}] Uploading done.'.format(idx))\n                opts = {\n                    'clean': clean_cmd,\n                    'build': build_cmd,\n                    'exec': exec_cmd,\n                }\n                if not terminal:\n                    exec_loop_sync(sys.stdout, sys.stderr, kernel, 'batch', '',\n                                   opts=opts,\n                                   vprint_done=vprint_done)\n            if terminal:\n                raise NotImplementedError('Terminal access is not supported in '\n                                          'the legacy synchronous mode.')\n            if code:\n                exec_loop_sync(sys.stdout, sys.stderr, kernel, 'query', code,\n                               vprint_done=vprint_done)\n            vprint_done('[{0}] Execution finished.'.format(idx))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        finally:\n            if rm:\n                vprint_wait('[{0}] Cleaning up the session...'.format(idx))\n                ret = kernel.destroy()\n                vprint_done('[{0}] Cleaned up the session.'.format(idx))\n                if stats:\n                    _stats = ret.get('stats', None) if ret else None\n                    if _stats:\n                        _stats.pop('precpu_used', None)\n                        _stats.pop('precpu_system_used', None)\n                        _stats.pop('cpu_system_used', None)\n                        print('[{0}] Statistics:\\n{1}'\n                              .format(idx, _format_stats(_stats)))\n                    else:\n                        print('[{0}] Statistics is not available.'.format(idx))\n\n    async def _run(session, idx, session_id, envs,\n                   clean_cmd, build_cmd, exec_cmd,\n                   is_multi=False):\n        try:\n            kernel = await session.Kernel.get_or_create(\n                lang,\n                client_token=session_id,\n                cluster_size=cluster_size,\n                mounts=mount,\n                envs=envs,\n                resources=resources,\n                tag=tag)\n        except BackendError as e:\n            print_fail('[{0}] {1}'.format(idx, e))\n            return\n        if kernel.created:\n            vprint_done('[{0}] Session {1} is ready.'.format(idx, kernel.kernel_id))\n        else:\n            vprint_done('[{0}] Reusing session {1}...'.format(idx, kernel.kernel_id))\n\n        if not is_multi:\n            stdout = sys.stdout\n            stderr = sys.stderr\n        else:\n            log_dir = Path.home() / '.cache' / 'backend.ai' / 'client-logs'\n            log_dir.mkdir(parents=True, exist_ok=True)\n            stdout = open(log_dir / '{0}.stdout.log'.format(session_id),\n                          'w', encoding='utf-8')\n            stderr = open(log_dir / '{0}.stderr.log'.format(session_id),\n                          'w', encoding='utf-8')\n\n        try:\n            def indexed_vprint_done(msg):\n                vprint_done('[{0}] '.format(idx) + msg)\n            if files:\n                if not is_multi:\n                    vprint_wait('[{0}] Uploading source files...'.format(idx))\n                ret = await kernel.upload(files, basedir=basedir,\n                                          show_progress=not is_multi)\n                if ret.status // 100 != 2:\n                    print_fail('[{0}] Uploading source files failed!'.format(idx))\n                    print('{0}: {1}\\n{2}'.format(\n                        ret.status, ret.reason, ret.text()), file=stderr)\n                    raise RuntimeError('Uploading source files has failed!')\n                if not is_multi:\n                    vprint_done('[{0}] Uploading done.'.format(idx))\n                opts = {\n                    'clean': clean_cmd,\n                    'build': build_cmd,\n                    'exec': exec_cmd,\n                }\n                if not terminal:\n                    await exec_loop(stdout, stderr, kernel, 'batch', '',\n                                    opts=opts,\n                                    vprint_done=indexed_vprint_done,\n                                    is_multi=is_multi)\n            if terminal:\n                await exec_terminal(kernel)\n                return\n            if code:\n                await exec_loop(stdout, stderr, kernel, 'query', code,\n                                vprint_done=indexed_vprint_done,\n                                is_multi=is_multi)\n        except BackendError as e:\n            print_fail('[{0}] {1}'.format(idx, e))\n            raise RuntimeError(e)\n        except Exception as e:\n            print_fail('[{0}] Execution failed!'.format(idx))\n            traceback.print_exc()\n            raise RuntimeError(e)\n        finally:\n            try:\n                if rm:\n                    if not is_multi:\n                        vprint_wait('[{0}] Cleaning up the session...'.format(idx))\n                    ret = await kernel.destroy()\n                    vprint_done('[{0}] Cleaned up the session.'.format(idx))\n                    if stats:\n                        _stats = ret.get('stats', None) if ret else None\n                        if _stats:\n                            _stats.pop('precpu_used', None)\n                            _stats.pop('precpu_system_used', None)\n                            _stats.pop('cpu_system_used', None)\n                            stats_str = _format_stats(_stats)\n                            print(format_info('[{0}] Statistics:'.format(idx)) +\n                                  '\\n{0}'.format(stats_str))\n                            if is_multi:\n                                print('Statistics:\\n{0}'.format(stats_str),\n                                      file=stderr)\n                        else:\n                            print_warn('[{0}] Statistics: unavailable.'.format(idx))\n                            if is_multi:\n                                print('Statistics: unavailable.', file=stderr)\n            finally:\n                if is_multi:\n                    stdout.close()\n                    stderr.close()\n\n    def _run_cases_legacy():\n        if session_id is None:\n            session_id_prefix = token_hex(5)\n        else:\n            session_id_prefix = session_id\n        vprint_info('Session token prefix: {0}'.format(session_id_prefix))\n        vprint_info('In the legacy mode, all cases will run serially!')\n        with Session() as session:\n            for idx, case in enumerate(case_set.keys()):\n                if is_multi:\n                    _session_id = '{0}-{1}'.format(session_id_prefix, idx)\n                else:\n                    _session_id = session_id_prefix\n                envs = dict(case[0])\n                clean_cmd = clean if clean else '*'\n                build_cmd = case[1]\n                exec_cmd = case[2]\n                _run_legacy(session, idx, _session_id, envs,\n                            clean_cmd, build_cmd, exec_cmd)\n\n    async def _run_cases():\n        loop = current_loop()\n        if session_id is None:\n            session_id_prefix = token_hex(5)\n        else:\n            session_id_prefix = session_id\n        vprint_info('Session token prefix: {0}'.format(session_id_prefix))\n        if is_multi:\n            print_info('Check out the stdout/stderr logs stored in '\n                       '~/.cache/backend.ai/client-logs directory.')\n        async with AsyncSession() as session:\n            tasks = []\n            # TODO: limit max-parallelism using aiojobs\n            for idx, case in enumerate(case_set.keys()):\n                if is_multi:\n                    _session_id = '{0}-{1}'.format(session_id_prefix, idx)\n                else:\n                    _session_id = session_id_prefix\n                envs = dict(case[0])\n                clean_cmd = clean if clean else '*'\n                build_cmd = case[1]\n                exec_cmd = case[2]\n                t = loop.create_task(\n                    _run(session, idx, _session_id, envs,\n                         clean_cmd, build_cmd, exec_cmd,\n                         is_multi=is_multi))\n                tasks.append(t)\n            results = await asyncio.gather(*tasks, return_exceptions=True)\n            if any(map(lambda r: isinstance(r, Exception), results)):\n                if is_multi:\n                    print_fail('There were failed cases!')\n                sys.exit(1)\n\n    if is_legacy_server():\n        _run_cases_legacy()\n    else:\n        loop = asyncio.get_event_loop()\n        try:\n            loop.run_until_complete(_run_cases())\n        finally:\n            loop.close()", "response": "Runs the given code snippet or files in a session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a single compute session.", "response": "def start(lang, session_id, owner, env, mount, tag, resources, cluster_size):\n    '''\n    Prepare and start a single compute session without executing codes.\n    You may use the created session to execute codes using the \"run\" command\n    or connect to an application service provided by the session using the \"app\"\n    command.\n\n\n    \\b\n    LANG: The name (and version/platform tags appended after a colon) of session\n          runtime or programming language.\n    '''\n    if session_id is None:\n        session_id = token_hex(5)\n    else:\n        session_id = session_id\n\n    ######\n    envs = _prepare_env_arg(env)\n    resources = _prepare_resource_arg(resources)\n    mount = _prepare_mount_arg(mount)\n    with Session() as session:\n        try:\n            kernel = session.Kernel.get_or_create(\n                lang,\n                client_token=session_id,\n                cluster_size=cluster_size,\n                mounts=mount,\n                envs=envs,\n                resources=resources,\n                owner_access_key=owner,\n                tag=tag)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        else:\n            if kernel.created:\n                print_info('Session ID {0} is created and ready.'\n                           .format(session_id))\n            else:\n                print_info('Session ID {0} is already running and ready.'\n                           .format(session_id))\n            if kernel.service_ports:\n                print_info('This session provides the following app services: ' +\n                           ', '.join(sport['name']\n                                     for sport in kernel.service_ports))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef terminate(sess_id_or_alias, owner, stats):\n    '''\n    Terminate the given session.\n\n    SESSID: session ID or its alias given when creating the session.\n    '''\n    print_wait('Terminating the session(s)...')\n    with Session() as session:\n        has_failure = False\n        for sess in sess_id_or_alias:\n            try:\n                kernel = session.Kernel(sess, owner)\n                ret = kernel.destroy()\n            except BackendAPIError as e:\n                print_error(e)\n                if e.status == 404:\n                    print_info(\n                        'If you are an admin, use \"-o\" / \"--owner\" option '\n                        'to terminate other user\\'s session.')\n                has_failure = True\n            except Exception as e:\n                print_error(e)\n                has_failure = True\n            if has_failure:\n                sys.exit(1)\n        else:\n            print_done('Done.')\n            if stats:\n                stats = ret.get('stats', None) if ret else None\n                if stats:\n                    print(_format_stats(stats))\n                else:\n                    print('Statistics is not available.')", "response": "Terminate the given session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_custom_view_details(name, auth, url):\n    view_id = get_custom_views(auth, url, name=name)[0]['symbolId']\n    get_custom_view_details_url = '/imcrs/plat/res/view/custom/' + str(view_id)\n    f_url = url + get_custom_view_details_url\n    r = requests.get(f_url, auth=auth,\n                     headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 200:\n            current_devices = (json.loads(r.text))\n            if 'device' in current_devices:\n                return current_devices['device']\n            else:\n                return []\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + ' get_custom_views: An Error has occured'", "response": "function takes name auth object and url and returns a list of dictionaries containing the details of the custom views"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning to add a list of devices to a specific custom views from HPE IMC", "response": "def add_devs_custom_views(custom_view_name, dev_list, auth, url):\n    \"\"\"\n    function takes a list of devIDs from devices discovered in the HPE IMC platform and and issues a RESTFUL call to\n     add the list of devices to a specific custom views from HPE IMC.\n\n    :param dev_list: list containing the devID of all devices to be contained in this custom view.\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: str of creation results ( \"view \" + name + \"created successfully\"\n\n    :rtype: str\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.groups import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    \"\"\"\n    view_id = get_custom_views(auth, url, name=custom_view_name)[0]['symbolId']\n    add_devs_custom_views_url = '/imcrs/plat/res/view/custom/'+str(view_id)\n    payload = '''{\"device\" : '''+ json.dumps(dev_list) + '''}'''\n    f_url = url + add_devs_custom_views_url\n    r = requests.put(f_url, data = payload, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 204:\n            print ('View ' + custom_view_name +' : Devices Successfully Added')\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_custom_views: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning takes input of auth, url, and name and issues a RESTFUL call to delete a specific of custom views from HPE IMC. :param name: string containg the name of the desired custom view :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: str of creation results ( \"view \" + name + \"created successfully\" :rtype: str >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.groups import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> delete_custom_view(auth.creds, auth.url, name = \"L1 View\") 'View L1 View deleted successfully' >>> view_1 =get_custom_views( auth.creds, auth.url, name = 'L1 View') >>> assert view_1 == None >>> delete_custom_view(auth.creds, auth.url, name = \"L2 View\") 'View L2 View deleted successfully' >>> view_2 =get_custom_views( auth.creds, auth.url, name = 'L2 View') >>> assert view_2 == None", "response": "def delete_custom_view(auth, url, name):\n    \"\"\"\n    function takes input of auth, url, and name and issues a RESTFUL call to delete a specific of custom views from HPE\n    IMC.\n    :param name: string containg the name of the desired custom view\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: str of creation results ( \"view \" + name + \"created successfully\"\n\n    :rtype: str\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.groups import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> delete_custom_view(auth.creds, auth.url, name = \"L1 View\")\n    'View L1 View deleted successfully'\n\n    >>> view_1 =get_custom_views( auth.creds, auth.url, name = 'L1 View')\n\n    >>> assert view_1 == None\n\n    >>> delete_custom_view(auth.creds, auth.url, name = \"L2 View\")\n    'View L2 View deleted successfully'\n\n    >>> view_2 =get_custom_views( auth.creds, auth.url, name = 'L2 View')\n\n    >>> assert view_2 == None\n\n    \"\"\"\n    view_id  = get_custom_views(auth, url,name )[0]['symbolId']\n    delete_custom_view_url = '/imcrs/plat/res/view/custom/'+str(view_id)\n    f_url = url + delete_custom_view_url\n    r = requests.delete(f_url, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 204:\n            return 'View ' + name +' deleted successfully'\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' delete_custom_view: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nliking unicode. split but accept several separators and regexes.", "response": "def multisplit(string,  # type: unicode\n               *separators,  # type: unicode\n               **kwargs  # type: Union[unicode, C[..., I[unicode]]]\n               ):  # type: (...) -> I\n    \"\"\" Like unicode.split, but accept several separators and regexes\n\n        Args:\n            string: the string to split.\n            separators: strings you can split on. Each string can be a\n                        regex.\n            maxsplit: max number of time you wish to split. default is 0,\n                      which means no limit.\n            flags: flags you wish to pass if you use regexes. You should\n                   pass them as a string containing a combination of:\n\n                    - 'm' for re.MULTILINE\n                    - 'x' for re.VERBOSE\n                    - 'v' for re.VERBOSE\n                    - 's' for re.DOTALL\n                    - '.' for re.DOTALL\n                    - 'd' for re.DEBUG\n                    - 'i' for re.IGNORECASE\n                    - 'u' for re.UNICODE\n                    - 'l' for re.LOCALE\n            cast: what to cast the result to\n\n        Returns:\n            An iterable of substrings.\n\n        Raises:\n            ValueError: if you pass a flag without separators.\n            TypeError: if you pass something else than unicode strings.\n\n        Example:\n\n            >>> for word in multisplit(u'fat     black cat, big'): print(word)\n            fat\n            black\n            cat,\n            big\n            >>> string = u'a,b;c/d=a,b;c/d'\n            >>> chunks = multisplit(string, u',', u';', u'[/=]', maxsplit=4)\n            >>> for chunk in chunks: print(chunk)\n            a\n            b\n            c\n            d\n            a,b;c/d\n\n    \"\"\"\n\n    cast = kwargs.pop('cast', list)\n    flags = parse_re_flags(kwargs.get('flags', 0))\n    # 0 means \"no limit\" for re.split\n    maxsplit = require_positive_number(kwargs.get('maxsplit', 0),\n                                       'maxsplit')\n\n    # no separator means we use the default unicode.split behavior\n    if not separators:\n        if flags:\n            raise ValueError(ww.s >> \"\"\"\n                             You can't pass flags without passing\n                             a separator. Flags only have sense if\n                             you split using a regex.\n                            \"\"\")\n\n        maxsplit = maxsplit or -1  # -1 means \"no limit\" for unicode.split\n        return unicode.split(string, None, maxsplit)\n\n    # Check that all separators are strings\n    for i, sep in enumerate(separators):\n        if not isinstance(sep, unicode):\n            raise TypeError(ww.s >> \"\"\"\n                '{!r}', the separator at index '{}', is of type '{}'.\n                multisplit() only accepts unicode strings.\n            \"\"\".format(sep, i, type(sep)))\n\n    # TODO: split let many empty strings in the result. Fix it.\n\n    seps = list(separators)  # cast to list so we can slice it\n\n    # simple code for when you need to split the whole string\n    if maxsplit == 0:\n        return cast(_split(string, seps, flags))\n\n    # slow implementation with checks for recursive maxsplit\n    return cast(_split_with_max(string, seps, maxsplit, flags))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multireplace(string,  # type: unicode\n                 patterns,  # type: str_or_str_iterable\n                 substitutions,  # type: str_istr_icallable\n                 maxreplace=0,  # type: int\n                 flags=0  # type: unicode\n                 ):  # type: (...) -> bool\n    \"\"\" Like unicode.replace() but accept several substitutions and regexes\n\n        Args:\n            string: the string to split on.\n            patterns: a string, or an iterable of strings to be replaced.\n            substitutions: a string or an iterable of string to use as a\n                           replacement. You can pass either one string, or\n                           an iterable containing the same number of\n                           sustitutions that you passed as patterns. You can\n                           also pass a callable instead of a string. It\n                           should expact a match object as a parameter.\n            maxreplace: the max number of replacement to make. 0 is no limit,\n                        which is the default.\n            flags: flags you wish to pass if you use regexes. You should\n                   pass them as a string containing a combination of:\n\n                    - 'm' for re.MULTILINE\n                    - 'x' for re.VERBOSE\n                    - 'v' for re.VERBOSE\n                    - 's' for re.DOTALL\n                    - '.' for re.DOTALL\n                    - 'd' for re.DEBUG\n                    - 'i' for re.IGNORECASE\n                    - 'u' for re.UNICODE\n                    - 'l' for re.LOCALE\n\n        Returns:\n            The string with replaced bits.\n\n        Raises:\n            ValueError: if you pass the wrong number of substitution.\n\n        Example:\n\n            >>> print(multireplace(u'a,b;c/d', (u',', u';', u'/'), u','))\n            a,b,c,d\n            >>> print(multireplace(u'a1b33c-d', u'\\d+', u','))\n            a,b,c-d\n            >>> print(multireplace(u'a-1,b-3,3c-d', u',|-', u'', maxreplace=3))\n            a1b3,3c-d\n            >>> def upper(match):\n            ...     return match.group().upper()\n            ...\n            >>> print(multireplace(u'a-1,b-3,3c-d', u'[ab]', upper))\n            A-1,B-3,3c-d\n    \"\"\"\n\n    # we can pass either a string or an iterable of strings\n    patterns = ensure_tuple(patterns)\n    substitutions = ensure_tuple(substitutions)\n\n    # you can either have:\n    # - many patterns, one substitution\n    # - many patterns, exactly as many substitutions\n    # anything else is an error\n    num_of_subs = len(substitutions)\n    num_of_patterns = len(patterns)\n\n    if num_of_subs == 1 and num_of_patterns > 0:\n        substitutions *= num_of_patterns\n    elif len(patterns) != num_of_subs:\n            raise ValueError(\"You must have exactly one substitution \"\n                             \"for each pattern or only one substitution\")\n\n    flags = parse_re_flags(flags)\n\n    # no limit for replacing, use a simple code\n    if not maxreplace:\n        for pattern, sub in zip(patterns, substitutions):\n            string, count = re.subn(pattern, sub, string, flags=flags)\n        return string\n\n    # ensure we respect the max number of replace accross substitutions\n    for pattern, sub in zip(patterns, substitutions):\n        string, count = re.subn(pattern, sub, string,\n                                count=maxreplace, flags=flags)\n        maxreplace -= count\n        if maxreplace == 0:\n            break\n\n    return string", "response": "Like unicode. replace but accept several substitutions and regexes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status():\n    '''Show the manager's current status.'''\n    with Session() as session:\n        resp = session.Manager.status()\n        print(tabulate([('Status', 'Active Sessions'),\n                        (resp['status'], resp['active_sessions'])],\n                       headers='firstrow'))", "response": "Show the manager s current status."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dev_vlans(auth, url, devid=None, devip=None):\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    get_dev_vlans_url = \"/imcrs/vlan?devId=\" + str(devid) + \"&start=0&size=5000&total=false\"\n    f_url = url + get_dev_vlans_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_vlans = (json.loads(response.text))\n            return dev_vlans['vlan']\n        elif response.status_code == 409:\n            return {'vlan': 'no vlans'}\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_dev_vlans: An Error has occured'", "response": "Function takes input of devId to issue RESTUL call to HP IMC API to get list of vlans on the target device"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to RESTFULL call to HP IMC API to get list of trunk interfaces", "response": "def get_trunk_interfaces(auth, url, devid=None, devip=None):\n    \"\"\"Function takes devId as input to RESTFULL call to HP IMC platform\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devid: str requires devid of the target device\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: list of dictionaries where each element of the list represents an interface which\n    has been configured as a\n    VLAN trunk port\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vlanm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> trunk_interfaces = get_trunk_interfaces('10', auth.creds, auth.url)\n\n    >>> assert type(trunk_interfaces) is list\n\n    >>> assert len(trunk_interfaces[0]) == 3\n\n    >>> assert 'allowedVlans' in trunk_interfaces[0]\n\n    >>> assert 'ifIndex' in trunk_interfaces[0]\n\n    >>> assert 'pvid' in trunk_interfaces[0]\n\n    >>> get_trunk_interfaces('350', auth.creds, auth.url)\n    ['No trunk inteface']\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    get_trunk_interfaces_url = \"/imcrs/vlan/trunk?devId=\" + str(devid) + \\\n                               \"&start=1&size=5000&total=false\"\n    f_url = url + get_trunk_interfaces_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_trunk_interfaces = (json.loads(response.text))\n            if len(dev_trunk_interfaces) == 2:\n                if isinstance(dev_trunk_interfaces['trunkIf'], list):\n                    return dev_trunk_interfaces['trunkIf']\n                elif isinstance(dev_trunk_interfaces['trunkIf'], dict):\n                    return [dev_trunk_interfaces['trunkIf']]\n            else:\n                dev_trunk_interfaces['trunkIf'] = [\"No trunk inteface\"]\n                return dev_trunk_interfaces['trunkIf']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_trunk_interfaces: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning returns list of dicts where each element of the list represents an interface which has been configured as a VLAN access port", "response": "def get_device_access_interfaces(auth, url, devid=None, devip=None):\n    \"\"\"\n    Function takes devid pr devip as input to RESTFUL call to HP IMC platform\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devid: str requires devid of the target device\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: list of dictionaries where each element of the list represents an interface which\n    has been configured as a\n    VLAN access port\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vlanm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> access_interfaces = get_device_access_interfaces('10', auth.creds, auth.url)\n\n    >>> assert type(access_interfaces) is list\n\n    >>> assert (len(access_interfaces[0])) is 2\n\n    >>> assert 'ifIndex' in access_interfaces[0]\n\n    >>> assert 'pvid' in access_interfaces[0]\n\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    get_access_interface_vlan_url = \"/imcrs/vlan/access?devId=\" + str(devid) + \\\n                                    \"&start=1&size=500&total=false\"\n    f_url = url + get_access_interface_vlan_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_access_interfaces = (json.loads(response.text))\n            if type(dev_access_interfaces['accessIf']) is dict:\n                return [dev_access_interfaces['accessIf']]\n            if len(dev_access_interfaces) == 2:\n                return dev_access_interfaces['accessIf']\n            else:\n                dev_access_interfaces['accessIf'] = [\"No access inteface\"]\n                return dev_access_interfaces['accessIf']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_device_access_interfaces: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction returns list of hybrid interfaces for a device", "response": "def get_device_hybrid_interfaces(auth, url, devid=None, devip=None):\n    \"\"\"\n    Function takes devId as input to RESTFUL call to HP IMC platform\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devid: str requires devid of the target device\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: list of dictionaries where each element of the list represents an interface which\n    has been configured as a\n    VLAN access port\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vlanm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> hybrid_interfaces = get_device_hybrid_interfaces('10', auth.creds, auth.url)\n\n    >>> assert type(access_interfaces) is list\n\n    >>> assert (len(access_interfaces[0])) is 2\n\n    >>> assert 'ifIndex' in access_interfaces[0]\n\n    >>> assert 'pvid' in access_interfaces[0]\n\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    get_hybrid_interface_vlan_url = \"/imcrs/vlan/hybrid?devId=\" + str(devid) + \\\n                                    \"&start=1&size=500&total=false\"\n    f_url = url + get_hybrid_interface_vlan_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            dev_hybrid_interfaces = (json.loads(response.text))\n            if len(dev_hybrid_interfaces) == 2:\n                dev_hybrid = dev_hybrid_interfaces['hybridIf']\n                if isinstance(dev_hybrid, dict):\n                    dev_hybrid = [dev_hybrid]\n                return dev_hybrid\n            else:\n                dev_hybrid_interfaces['hybridIf'] = [\"No hybrid inteface\"]\n                return dev_hybrid_interfaces['hybridIf']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_device_hybrid_interfaces: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_hybrid_interface(ifindex, pvid, taggedvlans, untaggedvlans, auth, url, devip=None,\n                         devid=None):\n    \"\"\"\n    Function takes ifindex, pvid, tagged vlans untagged vlans as input values to add a hybrid\n    port to a HPE Comware based switch. These functions only apply to HPE Comware based devices.\n    :param ifindex: str ifIndex value of target interface\n    :param pvid: str 802.1q value (1-4094) of target VLAN\n    :param taggedvlans:  str 802.1q value, seperated by commas, of target tagged VLANs\n    :param untaggedvlans:  str 802.1q value, seperated by commas, of target untagged VLANs\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n    :param devid: str requires devid of the target device\n    :param devip: str of ipv4 address of the target device\n    :return int of http response code\n    :rtype int\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    add_hybrid_interface_url = \"/imcrs/vlan/hybrid?devId=\" + str(devid) +  \\\n                               \"&start=1&size=500&total=false\"\n    f_url = url + add_hybrid_interface_url\n    payload = '''{\"ifIndex\": \"''' + ifindex + '''\",\n        \"pvid\": \"''' + pvid + '''\",\n        \"taggedVlans\": \"''' + taggedvlans + '''\",\n        \"untagVlanFlag\": \"true\",\n        \"untaggedVlans\": \"''' + untaggedvlans + '''\"\n    }'''\n    response = requests.post(f_url, auth=auth, data=payload, headers=HEADERS)\n    try:\n        if response.status_code == 201:\n            return 201\n        if response.status_code == 409:\n            return 409\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_device_hybrid_interfaces: An Error has occured\"", "response": "Function adds a hybrid interface to a HPE Comware based switch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction deletes a hybrid interface from the specified device.", "response": "def delete_hybrid_interface(ifindex, auth, url, devip=None, devid=None):\n    \"\"\"\n     Function takes devip ( ipv4 address ), ifIndex and pvid (vlanid) of specific device and\n     802.1q VLAN tag and issues a RESTFUL call to remove the specified VLAN from the target device.\n\n    :param ifindex: str value of ifIndex for a specific interface on the device\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devid: str requires devid of the target device\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: int of 204 if successful or 409 if not succesful\n\n    :rtype: int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vlanm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> delete_hybrid_interface('9', auth.creds, auth.url, devip='10.101.0.221')\n    409\n\n    >>> add_hybrid = add_hybrid_interface('9', '1', '10', '1', auth.creds, auth.url,\n                                           devip='10.101.0.221')\n\n    >>> delete_hybrid = delete_hybrid_interface('9', auth.creds, auth.url, devip='10.101.0.221')\n\n    >>> assert type(delete_hybrid) is int\n\n    >>> assert delete_hybrid == 204\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    f_url = url + \"/imcrs/vlan/hybrid?devId=\" + devid + \"&ifIndex=\" + ifindex\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            return 204\n        if response.status_code == 409:\n            return 409\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_device_hybrid_interfaces: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning sets the access interface for the specified VLAN on the specified device.", "response": "def set_access_interface_pvid(ifindex, pvid, auth, url, devip=None, devid=None):\n    \"\"\"\n    Function takes devip ( ipv4 address ), ifIndex and pvid (vlanid) of specific device and\n    802.1q VLAN tag and issues a RESTFUL call to remove the specified VLAN from the target device.\n\n    :param ifindex: str value of ifIndex for a specific interface on the device\n\n    :param pvid:  str value of dot1q VLAN desired to apply to the device\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devid: str requires devid of the target device\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: int of 204 if successful or 409 if not succesful\n\n    :rtype: int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vlanm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> set_access_int_vlan = set_access_interface_pvid('9', '1', auth.creds, auth.url,\n                                                        devip='10.101.0.221')\n\n    >>> set_access_int_vlan = set_access_interface_pvid('9', '10', auth.creds, auth.url,\n                                                        devip='10.101.0.221')\n\n    >>> assert type(set_access_int_vlan) is int\n\n    >>> assert set_access_int_vlan == 204\n\n    >>> set_access_int_vlan = set_access_interface_pvid('9', '1', auth.creds, auth.url,\n                                                        devip='10.101.0.221')\n\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    set_access_interface_pvid_url = \"/imcrs/vlan/access?devId=\" + devid + \"&destVlanId=\" + pvid \\\n                                    + \"&ifIndex=\" + str(ifindex)\n    f_url = url + set_access_interface_pvid_url\n    response = requests.put(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            return 204\n        if response.status_code == 409:\n            return 409\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" set_access_interface_pvid: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning takes devid and vlanid vlan_name of specific device and 802.1q VLAN tag and issues a RESTFUL call to add the specified VLAN from the target device. VLAN Name MUST be valid on target device. :param vlanid:int or str value of target 802.1q VLAN :param vlan_name: str value of the target 802.1q VLAN name. MUST be valid name on target device. :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param devid: str requires devid of the target device :param devip: str of ipv4 address of the target device :return: str HTTP Response code. Should be 201 if successfully created :rtype: str >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.vlanm import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> create_dev_vlan = create_dev_vlan('350', '200', 'test vlan', auth.creds, auth.url)", "response": "def create_dev_vlan(vlanid, vlan_name, auth, url, devid=None, devip=None):\n    \"\"\"\n    function takes devid and vlanid vlan_name of specific device and 802.1q VLAN tag\n    and issues a RESTFUL call to add the specified VLAN from the target device. VLAN Name\n    MUST be valid on target device.\n\n    :param vlanid:int or str value of target 802.1q VLAN\n\n    :param vlan_name: str value of the target 802.1q VLAN name. MUST be valid name on target device.\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param devid: str requires devid of the target device\n\n    :param devip: str of ipv4 address of the target device\n\n    :return: str HTTP Response code. Should be 201 if successfully created\n\n    :rtype: str\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vlanm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> create_dev_vlan = create_dev_vlan('350', '200', 'test vlan', auth.creds, auth.url)\n\n\n    \"\"\"\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    create_dev_vlan_url = \"/imcrs/vlan?devId=\" + str(devid)\n    f_url = url + create_dev_vlan_url\n    payload = '''{\"vlanId\":\"%s\", \"vlanName\":\"%s\"}''' % (str(vlanid), vlan_name)\n    response = requests.post(f_url, data=payload, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 201:\n            print('Vlan Created')\n            return 201\n        elif response.status_code == 409:\n            print('''Unable to create VLAN.\\nVLAN Already Exists\\nDevice does not support  VLAN\n            function''')\n            return 409\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" create_dev_vlan: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_dev_vlans(vlanid, auth, url, devid=None, devip=None):\n    if devip is not None:\n        devid = get_dev_details(devip, auth, url)['id']\n    remove_dev_vlan_url = \"/imcrs/vlan/delvlan?devId=\" + str(devid) + \"&vlanId=\" + str(vlanid)\n    f_url = url + remove_dev_vlan_url\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            print('Vlan deleted')\n            return response.status_code\n        elif response.status_code == 409:\n            print('Unable to delete VLAN.\\nVLAN does not Exist\\nDevice does not support  VLAN '\n                  'function')\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" delete_dev_vlans: An Error has occured\"", "response": "This function deletes a specific VLAN from the specified device and 802. 1q VLAN tag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse the HouseCanary API Python Client to access the API", "response": "def _get_results_from_api(identifiers, endpoints, api_key, api_secret):\n    \"\"\"Use the HouseCanary API Python Client to access the API\"\"\"\n\n    if api_key is not None and api_secret is not None:\n        client = housecanary.ApiClient(api_key, api_secret)\n    else:\n        client = housecanary.ApiClient()\n\n    wrapper = getattr(client, endpoints[0].split('/')[0])\n\n    if len(endpoints) > 1:\n        # use component_mget to request multiple endpoints in one call\n        return wrapper.component_mget(identifiers, endpoints)\n    else:\n        return wrapper.fetch_identifier_component(endpoints[0], identifiers)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef images():\n    '''\n    Show the list of registered images in this cluster.\n    '''\n    fields = [\n        ('Name', 'name'),\n        ('Registry', 'registry'),\n        ('Tag', 'tag'),\n        ('Digest', 'digest'),\n        ('Size', 'size_bytes'),\n        ('Aliases', 'aliases'),\n    ]\n    with Session() as session:\n        try:\n            items = session.Image.list(fields=(item[1] for item in fields))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if len(items) == 0:\n            print('There are no registered images.')\n            return\n        print(tabulate((item.values() for item in items),\n                       headers=(item[0] for item in fields),\n                       floatfmt=',.0f'))", "response": "Show the list of registered images in this cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the kernel image metadata from all configured docker registries.", "response": "def rescan_images(registry):\n    '''Update the kernel image metadata from all configured docker registries.'''\n    with Session() as session:\n        try:\n            result = session.Image.rescanImages(registry)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if result['ok']:\n            print(\"kernel image metadata updated\")\n        else:\n            print(\"rescanning failed: {0}\".format(result['msg']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an image alias.", "response": "def alias_image(alias, target):\n    '''Add an image alias.'''\n    with Session() as session:\n        try:\n            result = session.Image.aliasImage(alias, target)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if result['ok']:\n            print(\"alias {0} created for target {1}\".format(alias, target))\n        else:\n            print(result['msg'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove an image alias.", "response": "def dealias_image(alias):\n    '''Remove an image alias.'''\n    with Session() as session:\n        try:\n            result = session.Image.dealiasImage(alias)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if result['ok']:\n            print(\"alias {0} removed.\".format(alias))\n        else:\n            print(result['msg'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions takes in ipaddress as input to fetch device assett details from HP IMC RESTFUL API", "response": "def get_dev_asset_details(ipaddress):\n    \"\"\"Takes in ipaddress as input to fetch device assett details from HP IMC RESTFUL API\n    :param ipaddress: IP address of the device you wish to gather the asset details\n    :return: object of type list containing the device asset details\n    \"\"\"\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_asset_url = \"/imcrs/netasset/asset?assetDevice.ip=\" + str(ipaddress)\n    f_url = url + get_dev_asset_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        dev_asset_info = (json.loads(r.text))\n        if len(dev_asset_info) > 0:\n            dev_asset_info = dev_asset_info['netAsset']\n        if type(dev_asset_info) == dict:\n            dev_asset_info = [dev_asset_info]\n        if type(dev_asset_info) == list:\n            dev_asset_info[:] = [dev for dev in dev_asset_info if dev.get('deviceIp') == ipaddress]\n        return dev_asset_info\n    else:\n        print(\"get_dev_asset_details:  An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of dictionaries containing the serial numbers of the asset list.", "response": "def get_serial_numbers(assetList):\n    \"\"\"\n    Helper function: Uses return of get_dev_asset_details function to evaluate to evaluate for multipe serial objects.\n    :param assetList: output of get_dev_asset_details function\n    :return: the serial_list object of list type which contains one or more dictionaries of the asset details\n    \"\"\"\n    serial_list = []\n    if type(assetList) == list:\n        for i in assetList:\n            if len(i['serialNum']) > 0:\n                serial_list.append(i)\n    return serial_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_trunk_interfaces(devId):\n\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_trunk_interfaces_url = \"/imcrs/vlan/trunk?devId=\" + str(devId) + \"&start=1&size=5000&total=false\"\n    f_url = url + get_trunk_interfaces_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        dev_trunk_interfaces = (json.loads(r.text))\n        if len(dev_trunk_interfaces) == 2:\n            return dev_trunk_interfaces['trunkIf']\n        else:\n            dev_trunk_interfaces['trunkIf'] = [\"No trunk inteface\"]\n            return dev_trunk_interfaces['trunkIf']", "response": "Function takes devId as input to HP IMC platform\n    returns list of dictionaries containing of trunk interfaces configured as an 802. 1q trunk\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_device_access_interfaces(devId):\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_access_interface_vlan_url = \"/imcrs/vlan/access?devId=\" + str(devId) + \"&start=1&size=500&total=false\"\n    f_url = url + get_access_interface_vlan_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        dev_access_interfaces = (json.loads(r.text))\n        if len(dev_access_interfaces) == 2:\n            return dev_access_interfaces['accessIf']\n        else:\n            dev_access_interfaces['accessIf'] = [\"No access inteface\"]\n            return dev_access_interfaces['accessIf']\n    else:\n        print(\"get_device_access_interfaces: An Error has occured\")", "response": "Function takes devId as input to RESTFUL call to HP IMC platform\n    function returns list of dictionaries containing interfaces configured as access ports\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dev_details(ip_address):\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_details_url = \"/imcrs/plat/res/device?resPrivilegeFilter=false&ip=\" + \\\n                          str(ip_address) + \"&start=0&size=1000&orderBy=id&desc=false&total=false\"\n    f_url = url + get_dev_details_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        dev_details = (json.loads(r.text))\n        if len(dev_details) == 0:\n            print(\"Device not found\")\n            return \"Device not found\"\n        elif type(dev_details['device']) == list:\n            for i in dev_details['device']:\n                if i['ip'] == ip_address:\n                    dev_details = i\n                    return dev_details\n        elif type(dev_details['device']) == dict:\n            return dev_details['device']\n    else:\n        print(\"dev_details: An Error has occured\")", "response": "This function returns a dictionary of device details for a given IP address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dev_vlans(devId):\n\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_vlans_url = \"/imcrs/vlan?devId=\" + str(devId) + \"&start=0&size=5000&total=false\"\n    f_url = url + get_dev_vlans_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        dev_details = (json.loads(r.text))['vlan']\n        return dev_details\n    elif r.status_code == 409:\n        return [{'vlan': 'None'}]\n    else:\n        print(\"get_dev_vlans: An Error has occured\")", "response": "Function takes input of devId to issue RESTUL call to HP IMC\n    API call to HP IMC\n    API"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning takes devid as input to RESTFUL call to HP IMC platform function returns a list object which contains a dictionary per interface", "response": "def get_dev_interface(devid):\n    \"\"\"\n    Function takes devid as input to RESTFUL call to HP IMC platform\n    :param devid: requires devid as the only input\n    :return: list object which contains a dictionary per interface\n    \"\"\"\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_interface_url = \"/imcrs/plat/res/device/\" + str(devid) + \\\n                            \"/interface?start=0&size=1000&desc=false&total=false\"\n    f_url = url + get_dev_interface_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        int_list = (json.loads(r.text))['interface']\n        return int_list\n    else:\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dev_run_config(devId):\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_run_url = \"/imcrs/icc/deviceCfg/\" + str(devId) + \"/currentRun\"\n    f_url = url + get_dev_run_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # print (r.status_code)\n    if r.status_code == 200:\n        run_conf = (json.loads(r.text))['content']\n        type(run_conf)\n        if run_conf is None:\n            return \"This features is no supported on this device\"\n        else:\n            return run_conf\n    else:\n        return \"This features is not supported on this device\"", "response": "This function returns the most current running config file for a specific device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning takes the devId of a specific device and issues a RESTFUL call to get the most current startup config file as known by the HP IMC Base Platform ICC module for the target device. :param devId: int or str value of the target device :return: str which contains the entire content of the target device startup configuration. If the device is not currently supported in the HP IMC Base Platform ICC module, this call returns a string of \"This feature is not supported on this device\"", "response": "def get_dev_start_config(devId):\n    \"\"\"\n    function takes the devId of a specific device and issues a RESTFUL call to get the most current startup config\n    file as known by the HP IMC Base Platform ICC module for the target device.\n    :param devId:  int or str value of the target device\n    :return: str which contains the entire content of the target device startup configuration. If the device is not\n    currently supported in the HP IMC Base Platform ICC module, this call returns a string of \"This feature is not\n    supported on this device\"\n    \"\"\"\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_run_url = \"/imcrs/icc/deviceCfg/\" + str(devId) + \"/currentStart\"\n    f_url = url + get_dev_run_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    if r.status_code == 200:\n        start_conf = (json.loads(r.text))['content']\n        return start_conf\n    else:\n        # print (r.status_code)\n        return \"This feature is not supported on this device\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dev_alarms(devId):\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_dev_alarm_url = \"/imcrs/fault/alarm?operatorName=admin&deviceId=\" + \\\n                        str(devId) + \"&desc=false\"\n    f_url = url + get_dev_alarm_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    if r.status_code == 200:\n        dev_alarm = (json.loads(r.text))\n        if 'alarm' in dev_alarm:\n            return dev_alarm['alarm']\n        else:\n            return \"Device has no alarms\"", "response": "function takes the devId of a specific device and issues a RESTFUL call to get the current alarms for that device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction takes the ipAddress of a specific host and issues a RESTFUL call to get the device and interface that the target host is currently connected to.", "response": "def get_real_time_locate(ipAddress):\n    \"\"\"\n    function takes the ipAddress of a specific host and issues a RESTFUL call to get the device and interface that the\n    target host is currently connected to.\n    :param ipAddress: str value valid IPv4 IP address\n    :return: dictionary containing hostIp, devId, deviceIP, ifDesc, ifIndex\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    real_time_locate_url = \"/imcrs/res/access/realtimeLocate?type=2&value=\" + str(ipAddress) + \"&total=false\"\n    f_url = url + real_time_locate_url\n    r = requests.get(f_url, auth=auth, headers=headers)  # creates the URL using the payload variable as the contents\n    if r.status_code == 200:\n        return json.loads(r.text)['realtimeLocation']\n\n    else:\n        print(r.status_code)\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning takes devId of specific device and issues a RESTFUL call to get the IP MAC ARP list from the target device.", "response": "def get_ip_mac_arp_list(devId):\n    \"\"\"\n    function takes devid of specific device and issues a RESTFUL call to get the IP/MAC/ARP list from the target device.\n    :param devId: int or str value of the target device.\n    :return: list of dictionaries containing the IP/MAC/ARP list of the target device.\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    ip_mac_arp_list_url = \"/imcrs/res/access/ipMacArp/\" + str(devId)\n    f_url = url + ip_mac_arp_list_url\n    r = requests.get(f_url, auth=auth, headers=headers)  # creates the URL using the payload variable as the contents\n    if r.status_code == 200:\n        macarplist = (json.loads(r.text))\n        if len(macarplist) > 1:\n            return macarplist['ipMacArp']\n        else:\n            return ['this function is unsupported']\n\n    else:\n        print(r.status_code)\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions takes no input and issues a RESTFUL call to get a list of custom views from HPE IMC. Optioanl Name input will return only the specified view.", "response": "def get_custom_views(name=None):\n    \"\"\"\n    function takes no input and issues a RESTFUL call to get a list of custom views from HPE IMC. Optioanl Name input\n    will return only the specified view.\n    :param name: string containg the name of the desired custom view\n    :return: list of dictionaries containing attributes of the custom views.\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    if name is None:\n        get_custom_views_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&desc=false&total=false'\n    elif name is not None:\n        get_custom_views_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&name='+ name + '&desc=false&total=false'\n    f_url = url + get_custom_views_url\n    r = requests.get(f_url, auth=auth, headers=headers)  # creates the URL using the payload variable as the contents\n    if r.status_code == 200:\n        customviewlist = (json.loads(r.text))['customView']\n        if type(customviewlist) is dict:\n            customviewlist = [customviewlist]\n            return customviewlist\n        else:\n            return customviewlist\n    else:\n        print(r.status_code)\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning creates a list of custom views from HPE IMC. Optioanl Name input is a list of custom views. It returns only the specified view.", "response": "def create_custom_views(name=None, upperview=None):\n    \"\"\"\n    function takes no input and issues a RESTFUL call to get a list of custom views from HPE IMC. Optioanl Name input\n    will return only the specified view.\n    :param name: string containg the name of the desired custom view\n    :return: list of dictionaries containing attributes of the custom views.\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    create_custom_views_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&desc=false&total=falsee'\n    f_url = url + create_custom_views_url\n    if upperview is None:\n        payload = '''{ \"name\": \"''' + name + '''\",\n         \"upLevelSymbolId\" : \"\"}'''\n    else:\n        parentviewid = get_custom_views(upperview)[0]['symbolId']\n        payload = '''{\n                         \"name\": \"'''+name+ '''\"upperview\" : \"'''+str(parentviewid)+'''\"}'''\n        print (payload)\n    r = requests.post(f_url, data = payload, auth=auth, headers=headers)  # creates the URL using the payload variable as the contents\n    if r.status_code == 201:\n        return 'View ' + name +' created successfully'\n    else:\n        print(r.status_code)\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_dev_vlan(devid, vlanid, vlan_name):\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    create_dev_vlan_url = \"/imcrs/vlan?devId=\" + str(devid)\n    f_url = url + create_dev_vlan_url\n    payload = '''{ \"vlanId\": \"''' + str(vlanid) + '''\", \"vlanName\" : \"''' + str(vlan_name) + '''\"}'''\n    r = requests.post(f_url, data=payload, auth=auth,\n                      headers=headers)  # creates the URL using the payload variable as the contents\n    print (r.status_code)\n    if r.status_code == 201:\n        print ('Vlan Created')\n        return r.status_code\n    elif r.status_code == 409:\n        return '''Unable to create VLAN.\\nVLAN Already Exists\\nDevice does not support VLAN function'''\n    else:\n        print(\"An Error has occured\")", "response": "function creates a VLAN from a specific device and 802. 1q VLAN tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_dev_vlans(devid, vlanid):\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    remove_dev_vlan_url = \"/imcrs/vlan/delvlan?devId=\" + str(devid) + \"&vlanId=\" + str(vlanid)\n    f_url = url + remove_dev_vlan_url\n    payload = None\n    r = requests.delete(f_url, auth=auth,\n                        headers=headers)  # creates the URL using the payload variable as the contents\n    print (r.status_code)\n    if r.status_code == 204:\n        print ('Vlan deleted')\n        return r.status_code\n    elif r.status_code == 409:\n        print ('Unable to delete VLAN.\\nVLAN does not Exist\\nDevice does not support VLAN function')\n        return r.status_code\n    else:\n        print(\"An Error has occured\")", "response": "function deletes the specified VLAN from the target device and 802. 1q VLAN tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction takest devid and ifindex of specific device and interface and issues a RESTFUL call to shut the specifie d interface on the target device.", "response": "def set_inteface_down(devid, ifindex):\n    \"\"\"\n    function takest devid and ifindex of specific device and interface and issues a RESTFUL call to \" shut\" the specifie\n    d interface on the target device.\n    :param devid: int or str value of the target device\n    :param ifindex: int or str value of the target interface\n    :return: HTTP status code 204 with no values.\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    set_int_down_url = \"/imcrs/plat/res/device/\" + str(devid) + \"/interface/\" + str(ifindex) + \"/down\"\n    f_url = url + set_int_down_url\n    payload = None\n    r = requests.put(f_url, auth=auth,\n                     headers=headers)  # creates the URL using the payload variable as the contents\n    print(r.status_code)\n    if r.status_code == 204:\n        return r.status_code\n    else:\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction takest devid and ifindex of specific device and interface and issues a RESTFUL call to undo shut the spec ified interface on the target device.", "response": "def set_inteface_up(devid, ifindex):\n    \"\"\"\n    function takest devid and ifindex of specific device and interface and issues a RESTFUL call to \"undo shut\" the spec\n    ified interface on the target device.\n    :param devid: int or str value of the target device\n    :param ifindex: int or str value of the target interface\n    :return: HTTP status code 204 with no values.\n    \"\"\"\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    set_int_up_url = \"/imcrs/plat/res/device/\" + str(devid) + \"/interface/\" + str(ifindex) + \"/up\"\n    f_url = url + set_int_up_url\n    payload = None\n    r = requests.put(f_url, auth=auth,\n                     headers=headers)  # creates the URL using the payload variable as the contents\n    print(r.status_code)\n    if r.status_code == 204:\n        return r.status_code\n    else:\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction takes hostId as input to RESTFUL call to HP IMC function returns the VM Host information for the target hypervisor", "response": "def get_vm_host_info(hostId):\n    \"\"\"\n    function takes hostId as input to RESTFUL call to HP IMC\n    :param hostId: int or string of HostId of Hypervisor host\n    :return:list of dictionatires contraining the VM Host information for the target hypervisor\n    \"\"\"\n    global r\n    if auth is None or url is None:  # checks to see if the imc credentials are already available\n        set_imc_creds()\n    get_vm_host_info_url = \"/imcrs/vrm/host?hostId=\" + str(hostId)\n    f_url = url + get_vm_host_info_url\n    payload = None\n    r = requests.get(f_url, auth=auth,\n                     headers=headers)  # creates the URL using the payload variable as the contents\n    # print(r.status_code)\n    if r.status_code == 200:\n        if len(r.text) > 0:\n            return json.loads(r.text)\n    elif r.status_code == 204:\n        print(\"Device is not a supported Hypervisor\")\n        return \"Device is not a supported Hypervisor\"\n    else:\n        print(\"An Error has occured\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_trap_definitions():\n    # checks to see if the imc credentials are already available\n    if auth is None or url is None:\n        set_imc_creds()\n    global r\n    get_trap_def_url = \"/imcrs/fault/trapDefine/sync/query?enterpriseId=1.3.6.1.4.1.11&size=10000\"\n    f_url = url + get_trap_def_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    # r.status_code\n    if r.status_code == 200:\n        trap_def_list = (json.loads(r.text))\n        return trap_def_list['trapDefine']\n    else:\n        print(\"get_dev_asset_details:  An Error has occured\")", "response": "function takes in no param as input to fetch SNMP TRAP definitions from HP IMC RESTFUL API\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rate_limits(self):\n        if not self._rate_limits:\n            self._rate_limits = utilities.get_rate_limits(self._response)\n        return self._rate_limits", "response": "Returns list of rate limit information from the response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_custom_views(auth, url, name=None):\n    get_custom_view_url = None\n    if name is None:\n        get_custom_view_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&desc=false' \\\n                               '&total=false'\n    elif name is not None:\n        get_custom_view_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&name=' + \\\n                               name + '&desc=false&total=false'\n    f_url = url + get_custom_view_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            custom_view_list = (json.loads(response.text))\n            if 'customView' in custom_view_list:\n                custom_view_list = custom_view_list['customView']\n                if isinstance(custom_view_list, dict):\n                    custom_view_list = [custom_view_list]\n                    return custom_view_list\n                else:\n                    return custom_view_list\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_custom_views: An Error has occured'", "response": "function returns a list of dictionaries containing attributes of the custom views of the HPE\n    IMC."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_custom_view_details(name, auth, url):\n    view_id = get_custom_views(auth, url, name=name)\n    if view_id is None:\n        return view_id\n    view_id = get_custom_views(auth, url, name=name)[0]['symbolId']\n    get_custom_view_details_url = '/imcrs/plat/res/view/custom/' + str(view_id)\n    f_url = url + get_custom_view_details_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            current_devices = (json.loads(response.text))\n            if 'device' in current_devices:\n                if isinstance(current_devices['device'], dict):\n                    return [current_devices['device']]\n                else:\n                    return current_devices['device']\n            else:\n                return []\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_custom_views: An Error has occured'", "response": "function returns a list of dictionaries of custom views from an HPE\n    IMC"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions takes no input and issues a RESTFUL call to get a list of custom views from HPE IMC. Optional Name input will return only the specified view. :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param name: string containg the name of the desired custom view :param upperview: str contraining the name of the desired parent custom view :return: str of creation results ( \"view \" + name + \"created successfully\" :rtype: str >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.groups import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") #Create L1 custom view >>> create_custom_views(auth.creds, auth.url, name='L1 View') 'View L1 View created successfully' >>> view_1 =get_custom_views( auth.creds, auth.url, name = 'L1 View') >>> assert type(view_1) is list >>> assert view_1[0]['name'] == 'L1 View' #Create Nested custome view >>> create_custom_views(auth.creds, auth.url, name='L2 View', upperview='L1 View') 'View L2 View created successfully' >>> view_2 = get_custom_views( auth.creds, auth.url, name = 'L2 View') >>> assert type(view_2) is list >>> assert view_2[0]['name'] == 'L2 View'", "response": "def create_custom_views(auth, url, name=None, upperview=None):\n    \"\"\"\n    function takes no input and issues a RESTFUL call to get a list of custom views from HPE IMC.\n    Optional Name input will return only the specified view.\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param name: string containg the name of the desired custom view\n\n    :param upperview: str contraining the name of the desired parent custom view\n\n    :return: str of creation results ( \"view \" + name + \"created successfully\"\n\n    :rtype: str\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.groups import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    #Create L1 custom view\n    >>> create_custom_views(auth.creds, auth.url, name='L1 View')\n    'View L1 View created successfully'\n\n    >>> view_1 =get_custom_views( auth.creds, auth.url, name = 'L1 View')\n\n    >>> assert type(view_1) is list\n\n    >>> assert view_1[0]['name'] == 'L1 View'\n\n    #Create Nested custome view\n    >>> create_custom_views(auth.creds, auth.url, name='L2 View', upperview='L1 View')\n    'View L2 View created successfully'\n\n    >>> view_2 = get_custom_views( auth.creds, auth.url, name = 'L2 View')\n\n    >>> assert type(view_2) is list\n\n    >>> assert view_2[0]['name'] == 'L2 View'\n\n    \"\"\"\n    create_custom_views_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&desc=false' \\\n                               '&total=false'\n    f_url = url + create_custom_views_url\n    if upperview is None:\n        payload = '''{ \"name\": \"''' + name + '''\",\n         \"upLevelSymbolId\" : \"\"}'''\n    else:\n        parentviewid = get_custom_views(auth, url, upperview)[0]['symbolId']\n        payload = '''{ \"name\": \"''' + name + '''\",\n        \"upLevelSymbolId\" : \"''' + str(parentviewid) + '''\"}'''\n    response = requests.post(f_url, data=payload, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 201:\n            print('View ' + name + ' created successfully')\n            return response.status_code\n        elif response.status_code == 409:\n            print(\"View \" + name + \" already exists\")\n            return response.status_code\n        else:\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_custom_views: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_devs_custom_views(custom_view_name, dev_list, auth, url):\n    view_id = get_custom_views(auth, url, name=custom_view_name)\n    if view_id is None:\n        print(\"View \" + custom_view_name + \" doesn't exist\")\n        return view_id\n    view_id = get_custom_views(auth, url, name=custom_view_name)[0]['symbolId']\n    add_devs_custom_views_url = '/imcrs/plat/res/view/custom/' + str(view_id)\n    device_list = []\n    for dev in dev_list:\n        new_dev = {\"id\": dev}\n        device_list.append(new_dev)\n    payload = '''{\"device\" : ''' + json.dumps(device_list) + '''}'''\n    print(payload)\n    f_url = url + add_devs_custom_views_url\n    response = requests.put(f_url, data=payload, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            print('View ' + custom_view_name + ' : Devices Successfully Added')\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' get_custom_views: An Error has occured'", "response": "This function creates a specific custom view from a list of devices discovered in the HPE IMC platform and issues a RESTFUL call to add the list of devices to the specific custom views."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning takes input of auth, url, and name and issues a RESTFUL call to delete a specific of custom views from HPE IMC. :param name: string containg the name of the desired custom view :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: str of creation results ( \"view \" + name + \"created successfully\" :rtype: str >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.groups import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> delete_custom_view(auth.creds, auth.url, name = \"L1 View\") 'View L1 View deleted successfully' >>> view_1 =get_custom_views( auth.creds, auth.url, name = 'L1 View') >>> assert view_1 is None >>> delete_custom_view(auth.creds, auth.url, name = \"L2 View\") 'View L2 View deleted successfully' >>> view_2 =get_custom_views( auth.creds, auth.url, name = 'L2 View') >>> assert view_2 is None", "response": "def delete_custom_view(auth, url, name):\n    \"\"\"\n    function takes input of auth, url, and name and issues a RESTFUL call to delete a specific\n    of custom views from HPE\n    IMC.\n    :param name: string containg the name of the desired custom view\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: str of creation results ( \"view \" + name + \"created successfully\"\n\n    :rtype: str\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.groups import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> delete_custom_view(auth.creds, auth.url, name = \"L1 View\")\n    'View L1 View deleted successfully'\n\n    >>> view_1 =get_custom_views( auth.creds, auth.url, name = 'L1 View')\n\n    >>> assert view_1 is None\n\n    >>> delete_custom_view(auth.creds, auth.url, name = \"L2 View\")\n    'View L2 View deleted successfully'\n\n    >>> view_2 =get_custom_views( auth.creds, auth.url, name = 'L2 View')\n\n    >>> assert view_2 is None\n\n    \"\"\"\n    view_id = get_custom_views(auth, url, name)\n    if view_id is None:\n        print(\"View \" + name + \" doesn't exists\")\n        return view_id\n    view_id = get_custom_views(auth, url, name)[0]['symbolId']\n    delete_custom_view_url = '/imcrs/plat/res/view/custom/' + str(view_id)\n    f_url = url + delete_custom_view_url\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            print('View ' + name + ' deleted successfully')\n            return response.status_code\n        else:\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' delete_custom_view: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the token for make request.", "response": "def _get_token(self):\r\n        \"\"\"\r\n            Get token for make request. The The data obtained herein are used \r\n            in the variable header.\r\n\r\n            Returns:\r\n                To perform the request, receive in return a dictionary\r\n                with several keys. With this method only return the token\r\n                as it will use it for subsequent requests, such as a \r\n                sentence translate. Returns one string type.\r\n        \"\"\"\r\n        informations = self._set_format_oauth()\r\n        oauth_url = \"https://datamarket.accesscontrol.windows.net/v2/OAuth2-13\"\r\n        token = requests.post(oauth_url, informations).json()\r\n        return token[\"access_token\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_format_oauth(self):\r\n        format_oauth = urllib.parse.urlencode({\r\n            'client_id': self._client_id,\r\n            'client_secret': self._client_secret,\r\n            'scope': self._url_request,\r\n            'grant_type': self._grant_type\r\n        }).encode(\"utf-8\")\r\n        return format_oauth", "response": "Returns a dict that can be used to make the request for OAuth."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_request(self, params, translation_url, headers):\r\n        resp = requests.get(translation_url, params=params, headers=headers)\r\n        resp.encoding = \"UTF-8-sig\"\r\n        result = resp.json()\r\n        return result", "response": "Make a request to the specified URL and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary of language information on the given text.", "response": "def detect_language(self, text):\r\n        \"\"\"\r\n            Params:\r\n                ::text = Text for identify language.\r\n            \r\n            Returns:\r\n                Returns language present on text.\r\n        \"\"\"\r\n        infos_translate = TextDetectLanguageModel(text).to_dict()\r\n        mode_translate = TranslatorMode.Detect.value\r\n        return self._get_content(infos_translate, mode_translate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of languages present on array of texts.", "response": "def detect_languages(self, texts):\r\n        \"\"\"\r\n            Params:\r\n                ::texts = Array of texts for detect languages\r\n\r\n            Returns:\r\n                Returns language present on array of text.\r\n        \"\"\"\r\n        text_list = TextUtils.format_list_to_send(texts)\r\n        infos_translate = TextDetectLanguageModel(text_list).to_dict()\r\n        texts_for_detect = TextUtils.change_key(infos_translate, \"text\",\r\n                                                    \"texts\", infos_translate[\"text\"])\r\n        mode_translate = TranslatorMode.DetectArray.value\r\n        return self._get_content(texts_for_detect, mode_translate)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating a text to a language.", "response": "def translate(self, text, to_lang, from_lang=None, \r\n                content_type=\"text/plain\", category=None):\r\n        \"\"\"\r\n            This method takes as a parameter the desired text to be translated\r\n            and the language to which should be translated. To find the code \r\n            for each language just go to the library home page.\r\n            The parameter ::from_lang:: is optional because the api microsoft \r\n            recognizes the language used in a sentence automatically.\r\n            The parameter ::content_type:: defaults to \"text/plain\". In fact\r\n            it can be of two types: the very \"text/plain\" or \"text/html\".\r\n            By default the parameter ::category:: is defined as \"general\", \r\n            we do not touch it.\r\n        \"\"\"\r\n        infos_translate = TextModel(text, to_lang,\r\n            from_lang, content_type, category).to_dict()\r\n        mode_translate = TranslatorMode.Translate.value\r\n        return self._get_content(infos_translate, mode_translate)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to get information for the target VM", "response": "def get_vm_host_info(hostip, auth, url):\n    \"\"\"\n    function takes hostId as input to RESTFUL call to HP IMC\n\n    :param hostip: int or string of hostip of Hypervisor host\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: Dictionary contraining the information for the target VM host\n\n    :rtype: dict\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.vrm import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> host_info = get_vm_host_info('10.101.0.6', auth.creds, auth.url)\n\n    >>> assert type(host_info) is dict\n\n    >>> assert len(host_info) == 10\n\n    >>> assert 'cpuFeg' in host_info\n\n    >>> assert 'cpuNum' in host_info\n\n    >>> assert 'devId' in host_info\n\n    >>> assert 'devIp' in host_info\n\n    >>> assert 'diskSize' in host_info\n\n    >>> assert 'memory' in host_info\n\n    >>> assert 'parentDevId' in host_info\n\n    >>> assert 'porductFlag' in host_info\n\n    >>> assert 'serverName' in host_info\n\n    >>> assert 'vendor' in host_info\n\n    \"\"\"\n    hostid = get_dev_details(hostip, auth, url)['id']\n    f_url = url + \"/imcrs/vrm/host?hostId=\" + str(hostid)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            if len(response.text) > 0:\n                return json.loads(response.text)\n        elif response.status_code == 204:\n            print(\"Device is not a supported Hypervisor\")\n            return \"Device is not a supported Hypervisor\"\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_vm_host_info: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions takes no inputs and returns a list of dictionaries of all of the operators currently configured on the HPE IMC system", "response": "def get_plat_operator(auth, url,headers=HEADERS):\n    '''\n    Funtion takes no inputs and returns a list of dictionaties of all of the operators currently configured on the HPE\n    IMC system\n    :return: list of dictionaries\n    '''\n    get_operator_url = '/imcrs/plat/operator?start=0&size=1000&orderBy=id&desc=false&total=false'\n    f_url = url + get_operator_url\n    try:\n        r = requests.get(f_url, auth=auth, headers=headers)\n        plat_oper_list = json.loads(r.text)\n        return plat_oper_list['operator']\n    except requests.exceptions.RequestException as e:\n        print (\"Error:\\n\" + str(e) + ' get_plat_operator: An Error has occured')\n        return \"Error:\\n\" + str(e) + ' get_plat_operator: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to set the password of an existing operator account", "response": "def delete_plat_operator(operator,auth, url, headers=HEADERS):\n    \"\"\"\n    Function to set the password of an existing operator\n    :param operator: str Name of the operator account\n    :param password: str New password\n    :param url: str url of IMC server, see requests library docs for more info\n    :param auth: str see requests library docs for more info\n    :param headers: json formated string. default values set in module\n    :return:\n    \"\"\"\n    #oper_id = None\n    plat_oper_list = get_plat_operator(auth, url)\n    for i in plat_oper_list:\n        if operator == i['name']:\n            oper_id = i['id']\n    if oper_id == None:\n        return(\"\\n User does not exist\")\n    delete_plat_operator_url = \"/imcrs/plat/operator/\"\n    f_url = url + delete_plat_operator_url + str(oper_id)\n    r = requests.delete(f_url, auth=auth, headers=headers)\n    try:\n        if r.status_code == 204:\n            print(\"\\n Operator: \" + operator +\n                  \" was successfully deleted\")\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n        print (\"Error:\\n\" + str(e) + ' delete_plat_operator: An Error has occured')\n        return \"Error:\\n\" + str(e) + ' delete_plat_operator: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the index of the value in the list", "response": "def index(self, value):\n        \"\"\"\n        Args:\n            value: index\n\n        Returns: index of the values\n\n        Raises:\n            ValueError: value is not in list\n        \"\"\"\n\n        for i, x in enumerate(self):\n            if x == value:\n                return i\n\n        raise ValueError(\"{} is not in list\".format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a dictionary update sequence element into a dictionary update sequence element that stems from self.", "response": "def to_d(self):\n        \"\"\"\n        Args: self\n\n        Returns: a d that stems from self\n\n        Raises:\n            ValueError: dictionary update sequence element #index has length\n            len(tuple); 2 is required\n\n            TypeError: cannot convert dictionary update sequence element\n            #index to a sequence\n        \"\"\"\n\n        try:\n            return ww.d(self)\n        except (TypeError, ValueError):\n\n            for i, element in enumerate(self):\n                try:\n                    iter(element)\n\n                # TODO: find out why we can't cover this branch. The code\n                # is tested but don't appear in coverage\n                except TypeError:  # pragma: no cover\n                    # TODO: use raise_from ?\n                    raise ValueError((\"'{}' (position {}) is not iterable. You\"\n                                      \" can only create a dictionary from a \"\n                                      \"elements that are iterables, such as \"\n                                      \"tuples, lists, etc.\")\n                                     .format(element, i))\n\n                try:\n                    size = len(element)\n                except TypeError:  # ignore generators, it's already consummed\n                    pass\n                else:\n                    raise ValueError((\"'{}' (position {}) contains {} \"\n                                      \"elements. You can only create a \"\n                                      \"dictionary from iterables containing \"\n                                      \"2 elements.\").format(element, i, size))\n\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions takes no input and returns a list of dictionaries containing the configuration templates in the root folder of the ICC configuration template library.", "response": "def get_cfg_template(auth, url, folder = None):\n    '''\n    Function takes no input and returns a list of dictionaries containing the configuration templates in the root folder\n    of the icc configuration template library.\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: List of Dictionaries containing folders and configuration files in the ICC library.\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.icc import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> config_templates = get_cfg_template(auth.creds, auth.url)\n\n    >>> assert type(config_templates) is list\n\n    >>> assert 'confFileName' in config_templates[0]\n\n\n    >>> config_templates_folder = get_cfg_template(auth.creds, auth.url, folder='ADP_Configs')\n\n    >>> assert type(config_templates_folder) is list\n\n    >>> assert 'confFileName' in config_templates_folder[0]\n\n    >>> config_template_no_folder = get_cfg_template(auth.creds, auth.url, folder='Doesnt_Exist')\n\n    >>> assert config_template_no_folder == None\n    '''\n    if folder == None:\n        get_cfg_template_url = \"/imcrs/icc/confFile/list\"\n    else:\n        folder_id = get_folder_id(folder, auth, url)\n        get_cfg_template_url = \"/imcrs/icc/confFile/list/\"+str(folder_id)\n    f_url = url + get_cfg_template_url\n    r = requests.get(f_url,auth=auth, headers=HEADERS)\n    #print (r.status_code)\n    try:\n        if r.status_code == 200:\n            cfg_template_list = (json.loads(r.text))\n            return cfg_template_list['confFile']\n\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_cfg_template: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to create a configuration segment in the IMC RS.", "response": "def create_cfg_segment(filename, filecontent, description, auth, url):\n    '''\n    Takes a str into var filecontent which represents the entire content of a configuration segment, or partial\n    configuration file. Takes a str into var description which represents the description of the configuration segment\n    :param filename: str containing the name of the configuration segment.\n\n    :param filecontent: str containing the entire contents of the configuration segment\n\n    :param description: str contrianing the description of the configuration segment\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: If successful, Boolena of type True\n\n    :rtype: Boolean\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.icc import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> filecontent = (\"\"\"sample file content\"\"\")\n     >>> create_new_file = create_cfg_segment('CW7SNMP.cfg', filecontent, 'My New Template', auth.creds, auth.url)\n\n     >>> template_id = get_template_id('CW7SNMP.cfg', auth.creds, auth.url)\n\n     >>> assert type(template_id) is str\n\n     >>>\n    '''\n    payload = {\"confFileName\": filename,\n               \"confFileType\": \"2\",\n               \"cfgFileParent\": \"-1\",\n               \"confFileDesc\": description,\n               \"content\": filecontent}\n    create_cfg_segment_url = \"/imcrs/icc/confFile\"\n    f_url = url + create_cfg_segment_url\n    # creates the URL using the payload variable as the contents\n    r = requests.post(f_url,data= (json.dumps(payload)), auth=auth, headers=HEADERS)\n    try:\n        if r.status_code == 201:\n            return True\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" create_cfg_segment: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_template_id(template_name, auth, url):\n    object_list = get_cfg_template(auth=auth, url=url)\n    for object in object_list:\n        if object['confFileName'] == template_name:\n            return object['confFileId']\n    return \"template not found\"", "response": "Helper function takes str input of folder name and returns str numerical id of the folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses the get_template_id() funct to gather the template_id to craft a url which is sent to the IMC server using a Delete Method :param template_name: str containing the entire contents of the configuration segment :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: If successful, Boolean of type True :rtype: Boolean >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.icc import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> delete_cfg_template('CW7SNMP.cfg', auth.creds, auth.url) True >>> get_template_id('CW7SNMP.cfg', auth.creds, auth.url) 'template not found'", "response": "def delete_cfg_template(template_name, auth, url):\n    '''Uses the get_template_id() funct to gather the template_id to craft a url which is sent to the IMC server using\n    a Delete Method\n    :param template_name: str containing the entire contents of the configuration segment\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: If successful, Boolean of type True\n\n    :rtype: Boolean\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.icc import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> delete_cfg_template('CW7SNMP.cfg', auth.creds, auth.url)\n    True\n\n    >>> get_template_id('CW7SNMP.cfg', auth.creds, auth.url)\n    'template not found'\n\n    '''\n    file_id = get_template_id(template_name, auth, url)\n    delete_cfg_template_url = \"/imcrs/icc/confFile/\"+str(file_id)\n    f_url = url + delete_cfg_template_url\n    # creates the URL using the payload variable as the contents\n    r = requests.delete(f_url, auth=auth, headers=HEADERS)\n    #print (r.status_code)\n    try:\n        if r.status_code == 204:\n            return True\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" delete_cfg_template: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_folder_id(folder_name, auth, url):\n    object_list = get_cfg_template(auth=auth, url=url)\n    for object in object_list:\n        if object['confFileName'] == folder_name:\n            return object['confFileId']\n    return \"Folder not found\"", "response": "This function returns str numerical id of the folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps the given text with bold enable or disable ANSI sequences.", "response": "def bold(text: str) -> str:\n    '''\n    Wraps the given text with bold enable/disable ANSI sequences.\n    '''\n    return (style(text, bold=True, reset=False) +\n            style('', bold=False, reset=False))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def status(cls):\n        '''\n        Returns the current status of the configured API server.\n        '''\n        rqst = Request(cls.session, 'GET', '/manager/status')\n        rqst.set_json({\n            'status': 'running',\n        })\n        async with rqst.fetch() as resp:\n            return await resp.json()", "response": "Returns the current status of the configured API server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def freeze(cls, force_kill: bool = False):\n        '''\n        Freezes the configured API server.\n        Any API clients will no longer be able to create new compute sessions nor\n        create and modify vfolders/keypairs/etc.\n        This is used to enter the maintenance mode of the server for unobtrusive\n        manager and/or agent upgrades.\n\n        :param force_kill: If set ``True``, immediately shuts down all running\n            compute sessions forcibly. If not set, clients who have running compute\n            session are still able to interact with them though they cannot create\n            new compute sessions.\n        '''\n        rqst = Request(cls.session, 'PUT', '/manager/status')\n        rqst.set_json({\n            'status': 'frozen',\n            'force_kill': force_kill,\n        })\n        async with rqst.fetch() as resp:\n            assert resp.status == 204", "response": "Freezes the configured compute keypair store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dev_alarms(devId, auth=auth.creds, url=auth.url):\n    # checks to see if the imc credentials are already available\n    get_dev_alarm_url = \"/imcrs/fault/alarm?operatorName=admin&deviceId=\" + \\\n                        str(devId) + \"&desc=false\"\n    f_url = url + get_dev_alarm_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=headers)\n    try:\n        if r.status_code == 200:\n            dev_alarm = (json.loads(r.text))\n            if 'alarm' in dev_alarm:\n                return dev_alarm['alarm']\n            else:\n                return \"Device has no alarms\"\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_dev_alarms: An Error has occured'", "response": "function takes the devId of a specific device and issues a RESTFUL call to get the current alarms for that device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upload(sess_id_or_alias, files):\n    if len(files) < 1:\n        return\n    with Session() as session:\n        try:\n            print_wait('Uploading files...')\n            kernel = session.Kernel(sess_id_or_alias)\n            kernel.upload(files, show_progress=True)\n            print_done('Uploaded.')\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)", "response": "Upload files to user s home folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload files from a running container.", "response": "def download(sess_id_or_alias, files, dest):\n    \"\"\"\n    Download files from a running container.\n\n    \\b\n    SESSID: Session ID or its alias given when creating the session.\n    FILES: Paths inside container.\n    \"\"\"\n    if len(files) < 1:\n        return\n    with Session() as session:\n        try:\n            print_wait('Downloading file(s) from {}...'\n                       .format(sess_id_or_alias))\n            kernel = session.Kernel(sess_id_or_alias)\n            kernel.download(files, dest, show_progress=True)\n            print_done('Downloaded to {}.'.format(dest.resolve()))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists files in a running container.", "response": "def ls(sess_id_or_alias, path):\n    \"\"\"\n    List files in a path of a running container.\n\n    \\b\n    SESSID: Session ID or its alias given when creating the session.\n    PATH: Path inside container.\n    \"\"\"\n    with Session() as session:\n        try:\n            print_wait('Retrieving list of files in \"{}\"...'.format(path))\n            kernel = session.Kernel(sess_id_or_alias)\n            result = kernel.list_files(path)\n\n            if 'errors' in result and result['errors']:\n                print_fail(result['errors'])\n                sys.exit(1)\n\n            files = json.loads(result['files'])\n            table = []\n            headers = ['file name', 'size', 'modified', 'mode']\n            for file in files:\n                mdt = datetime.fromtimestamp(file['mtime'])\n                mtime = mdt.strftime('%b %d %Y %H:%M:%S')\n                row = [file['filename'], file['size'], mtime, file['mode']]\n                table.append(row)\n            print_done('Retrived.')\n            print('Path in container:', result['abspath'], end='')\n            print(tabulate(table, headers=headers))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    try:\n        # Get the `src` directory's absolute path\n        src_path = os.path.dirname(\n            # `aoiklivereload` directory's absolute path\n            os.path.dirname(\n                # `demo` directory's absolute path\n                os.path.dirname(\n                    # This file's absolute path\n                    os.path.abspath(__file__)\n                )\n            )\n        )\n\n        # If the `src` directory path is not in `sys.path`\n        if src_path not in sys.path:\n            # Add to `sys.path`.\n            #\n            # This aims to save user setting PYTHONPATH when running this demo.\n            #\n            sys.path.append(src_path)\n\n        # Import reloader class\n        from aoiklivereload import LiveReloader\n\n        # Create reloader\n        reloader = LiveReloader()\n\n        # Start watcher thread\n        reloader.start_watcher_thread()\n\n        # Server host\n        server_host = '0.0.0.0'\n\n        # Server port\n        server_port = 8000\n\n        # Get message\n        msg = '# ----- Run server -----\\nHost: {}\\nPort: {}'.format(\n            server_host, server_port\n        )\n\n        # Print message\n        print(msg)\n\n        # Create Sanic app\n        sanic_app = Sanic()\n\n        # Create request handler\n        @sanic_app.route('/')\n        async def hello_handler(request):  # pylint: disable=unused-variable\n            \"\"\"\n            Request handler.\n\n            :return:\n                Response body.\n            \"\"\"\n            # Return response body\n            return text('hello')\n\n        # Run server.\n        #\n        # Notice `KeyboardInterrupt` will be caught inside `sanic_app.run`.\n        #\n        sanic_app.run(\n            host=server_host,\n            port=server_port,\n        )\n\n    # If have `KeyboardInterrupt`\n    except KeyboardInterrupt:\n        # Not treat as error\n        pass", "response": "Main function.\n\n    :return:\n        None."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cfg_template(auth, url, folder=None):\n    if folder is None:\n        get_cfg_template_url = \"/imcrs/icc/confFile/list\"\n    else:\n        folder_id = get_folder_id(folder, auth, url)\n        get_cfg_template_url = \"/imcrs/icc/confFile/list/\" + str(folder_id)\n    f_url = url + get_cfg_template_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            cfg_template_list = (json.loads(response.text))['confFile']\n            if isinstance(cfg_template_list, list):\n                return cfg_template_list\n            elif isinstance(cfg_template_list, dict):\n                return [cfg_template_list]\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_cfg_template: An Error has occured\"", "response": "Function takes no input and returns a list of dictionaries containing the configuration files in the ICC configuration template library."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_cfg_segment(filename, filecontent, description, auth, url):\n    payload = {\"confFileName\": filename,\n               \"confFileType\": \"2\",\n               \"cfgFileParent\": \"-1\",\n               \"confFileDesc\": description,\n               \"content\": filecontent}\n    f_url = url + \"/imcrs/icc/confFile\"\n    response = requests.post(f_url, data=(json.dumps(payload)), auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 201:\n            print(\"Template successfully created\")\n            return response.status_code\n        elif response.status_code is not 201:\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" create_cfg_segment: An Error has occured\"", "response": "Function to create a new configuration segment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_folder_id(folder_name, auth, url):\n    object_list = get_cfg_template(auth=auth, url=url)\n    for template in object_list:\n        if template['confFileName'] == folder_name:\n            return int(template['confFileId'])\n    return \"Folder not found\"", "response": "This function returns the folder id of the folder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse the get_template_id() funct to gather the template_id to craft a url which is sent to the IMC server using a Delete Method :param template_name: str containing the entire contents of the configuration segment :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: If successful, return int of status.code 204. :rtype: Int >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.icc import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> delete_cfg_template('CW7SNMP.cfg', auth.creds, auth.url)", "response": "def delete_cfg_template(template_name, auth, url):\n    \"\"\"Uses the get_template_id() funct to gather the template_id\n    to craft a url which is sent to the IMC server using a Delete Method\n    :param template_name: str containing the entire contents of the configuration segment\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: If successful, return int of status.code 204.\n\n    :rtype: Int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.icc import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> delete_cfg_template('CW7SNMP.cfg', auth.creds, auth.url)\n\n\n    \"\"\"\n    file_id = get_template_id(template_name, auth, url)\n    f_url = url + \"/imcrs/icc/confFile/\" + str(file_id)\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            print(\"Template successfully Deleted\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" delete_cfg_template: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_template_details(template_name, auth, url):\n    file_id = get_template_id(template_name, auth, url)\n    if isinstance(file_id, str):\n        return file_id\n    f_url = url + \"/imcrs/icc/confFile/\" + str(file_id)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            template_details = json.loads(response.text)\n            return template_details\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_template_contents: An Error has occured\"", "response": "Uses the get_template_id method to gather the template_id to craft a\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning takes input of devId to issue RESTUL call to HP IMC to get the list of vlans on the devices.", "response": "def get_dev_vlans(devid, auth, url):\n    \"\"\"Function takes input of devID to issue RESTUL call to HP IMC\n    :param devid: requires devId as the only input parameter\n    :return: dictionary of existing vlans on the devices. Device must be supported in HP IMC platform VLAN manager module\n    \"\"\"\n\n    # checks to see if the imc credentials are already available\n    get_dev_vlans_url = \"/imcrs/vlan?devId=\" + str(devid) + \"&start=0&size=5000&total=false\"\n    f_url = url + get_dev_vlans_url\n\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_vlans = (json.loads(r.text))\n            return dev_vlans['vlan']\n        elif r.status_code == 409:\n            return {'vlan': 'no vlans'}\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_dev_vlans: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_trunk_interfaces(devId, auth, url):\n\n    # checks to see if the imc credentials are already available\n    get_trunk_interfaces_url = \"/imcrs/vlan/trunk?devId=\" + str(devId) + \"&start=1&size=5000&total=false\"\n    f_url = url + get_trunk_interfaces_url\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_trunk_interfaces = (json.loads(r.text))\n        if len(dev_trunk_interfaces) == 2:\n            return dev_trunk_interfaces['trunkIf']\n        else:\n            dev_trunk_interfaces['trunkIf'] = [\"No trunk inteface\"]\n            return dev_trunk_interfaces['trunkIf']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_trunk_interfaces: An Error has occured'", "response": "Function takes devId as input to RESTFULL call to HP IMC platform\n    and returns a list of dictionaries containing of trunk interfaces configured as an 802. 1q trunk ifeface"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning takes devId as input to RESTFUL call to HP IMC platform and returns the list of access interfaces configured as access ports", "response": "def get_device_access_interfaces(devId, auth, url):\n    \"\"\"Function takes devId as input to RESTFUL call to HP IMC platform\n    :param devId: requires deviceID as the only input parameter\n    :return: list of dictionaries containing interfaces configured as access ports\n    \"\"\"\n    # checks to see if the imc credentials are already available\n    get_access_interface_vlan_url = \"/imcrs/vlan/access?devId=\" + str(devId) + \"&start=1&size=500&total=false\"\n    f_url = url + get_access_interface_vlan_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_access_interfaces = (json.loads(r.text))\n            if len(dev_access_interfaces) == 2:\n                return dev_access_interfaces['accessIf']\n            else:\n                dev_access_interfaces['accessIf'] = [\"No access inteface\"]\n                return dev_access_interfaces['accessIf']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_device_access_interfaces: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction creates a VLAN from a specific device and 802. 1q VLAN tag", "response": "def create_dev_vlan(devid, vlanid, vlan_name, auth, url):\n    \"\"\"\n    function takes devid and vlanid vlan_name of specific device and 802.1q VLAN tag and issues a RESTFUL call to add the\n    specified VLAN from the target device. VLAN Name MUST be valid on target device.\n    :param devid: int or str value of the target device\n    :param vlanid:int or str value of target 802.1q VLAN\n    :param vlan_name: str value of the target 802.1q VLAN name. MUST be valid name on target device.\n    :return:HTTP Status code of 201 with no values.\n    \"\"\"\n    create_dev_vlan_url = \"/imcrs/vlan?devId=\" + str(devid)\n    f_url = url + create_dev_vlan_url\n    payload = '''{ \"vlanId\": \"''' + str(vlanid) + '''\", \"vlanName\" : \"''' + str(vlan_name) + '''\"}'''\n    r = requests.post(f_url, data=payload, auth=auth,\n                      headers=HEADERS)  # creates the URL using the payload variable as the contents\n    return r\n    try:\n\n        if r.status_code == 201:\n            print ('Vlan Created')\n            return r.status_code\n        elif r.status_code == 409:\n            return '''Unable to create VLAN.\\nVLAN Already Exists\\nDevice does not support VLAN function'''\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" create_dev_vlan: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_dev_vlans(devid, vlanid, auth, url):\n    remove_dev_vlan_url = \"/imcrs/vlan/delvlan?devId=\" + str(devid) + \"&vlanId=\" + str(vlanid)\n    f_url = url + remove_dev_vlan_url\n    payload = None\n    r = requests.delete(f_url, auth=auth,\n                        headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 204:\n            print ('Vlan deleted')\n            return r.status_code\n        elif r.status_code == 409:\n            print ('Unable to delete VLAN.\\nVLAN does not Exist\\nDevice does not support VLAN function')\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" delete_dev_vlans: An Error has occured\"", "response": "function deletes the specified VLAN from the target device and 802. 1q VLAN tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_operator(operator, auth, url):\n    f_url = url + '/imcrs/plat/operator'\n    payload = json.dumps(operator, indent=4)\n    response = requests.post(f_url, data=payload, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 409:\n            return response.status_code\n        elif response.status_code == 201:\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' create_operator: An Error has occured'", "response": "Function creates a new operator in the HPE IMC Restful API"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to set the password of an existing operator", "response": "def set_operator_password(operator, password, auth, url):\n    \"\"\"\n    Function to set the password of an existing operator\n\n    :param operator: str Name of the operator account\n\n    :param password: str New password\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: int of 204 if successfull,\n\n    :rtype: int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.operator import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> operator = { \"fullName\" : \"test administrator\", \"sessionTimeout\" : \"30\",\n                     \"password\" :  \"password\",\"operatorGroupId\" : \"1\",\n                     \"name\" : \"testadmin\",\"desc\" : \"test admin account\",\n                     \"defaultAcl\" : \"\",\"authType\"  : \"0\"}\n\n    >>> new_operator = create_operator(operator, auth.creds, auth.url)\n\n    >>> set_new_password = set_operator_password('testadmin', 'newpassword', auth.creds, auth.url)\n\n    >>> assert type(set_new_password) is int\n\n    >>> assert set_new_password == 204\n\n       \"\"\"\n    if operator is None:\n        operator = input(\n            '''\\n What is the username you wish to change the password?''')\n    oper_id = ''\n    authtype = None\n    plat_oper_list = get_plat_operator(auth, url)\n    for i in plat_oper_list:\n        if i['name'] == operator:\n            oper_id = i['id']\n            authtype = i['authType']\n    if oper_id == '':\n        return \"User does not exist\"\n    change_pw_url = \"/imcrs/plat/operator/\"\n    f_url = url + change_pw_url + oper_id\n    if password is None:\n        password = input(\n            '''\\n ============ Please input the operators new password:\\n ============  ''')\n    payload = json.dumps({'password': password, 'authType': authtype})\n    response = requests.put(f_url, data=payload, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            # print(\"Operator:\" + operator +\n            # \" password was successfully changed\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' set_operator_password: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_plat_operator(auth, url):\n    f_url = url + '/imcrs/plat/operator?start=0&size=1000&orderBy=id&desc=false&total=false'\n    try:\n        response = requests.get(f_url, auth=auth, headers=HEADERS)\n        plat_oper_list = json.loads(response.text)['operator']\n        if isinstance(plat_oper_list, dict):\n            oper_list = [plat_oper_list]\n            return oper_list\n        return plat_oper_list\n    except requests.exceptions.RequestException as error:\n        print(\"Error:\\n\" + str(error) + ' get_plat_operator: An Error has occured')\n        return \"Error:\\n\" + str(error) + ' get_plat_operator: An Error has occured'", "response": "Function takes no inputs and returns a list of dictionaries where each element represents one operator currently holding the HPE IMC system and each element represents one of the operators currently holding the HPE IMC system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to set the password of an existing operator account", "response": "def delete_plat_operator(operator, auth, url):\n    \"\"\"\n    Function to set the password of an existing operator\n    :param operator: str Name of the operator account\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: int of 204 if successfull\n\n    :rtype: int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.operator import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> success_delete_operator = delete_plat_operator('testadmin', auth.creds, auth.url)\n\n    >>> assert type(success_delete_operator) is int\n\n    >>> assert success_delete_operator == 204\n\n    >>> fail_delete_operator = delete_plat_operator('testadmin', auth.creds, auth.url)\n\n    >>> assert type(fail_delete_operator) is int\n\n    >>> assert fail_delete_operator == 409\n\n    \"\"\"\n    oper_id = None\n    plat_oper_list = get_plat_operator(auth, url)\n    for i in plat_oper_list:\n        if operator == i['name']:\n            oper_id = i['id']\n        else:\n            oper_id = None\n    if oper_id is None:\n        # print (\"User does not exist\")\n        return 409\n    f_url = url + \"/imcrs/plat/operator/\" + str(oper_id)\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            # print(\"Operator: \" + operator +\n            #  \" was successfully deleted\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + ' delete_plat_operator: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute_request(self, url, http_method, query_params, post_data):\n\n        response = requests.request(http_method, url, params=query_params,\n                                    auth=self._auth, json=post_data,\n                                    headers={'User-Agent': USER_AGENT})\n\n        if isinstance(self._output_generator, str) and self._output_generator.lower() == \"json\":\n            # shortcut for just getting json back\n            return response.json()\n        elif self._output_generator is not None:\n            return self._output_generator.process_response(response)\n        else:\n            return response", "response": "Makes a request to the specified url endpoint with the specified http method params and post data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a POST request to the specified url endpoint.", "response": "def post(self, url, post_data, query_params=None):\n        \"\"\"Makes a POST request to the specified url endpoint.\n\n        Args:\n            url (string): The url to the API without query params.\n                          Example: \"https://api.housecanary.com/v2/property/value\"\n            post_data: Json post data to send in the body of the request.\n            query_params (dict): Optional. Dictionary of query params to add to the request.\n\n        Returns:\n            The result of calling this instance's OutputGenerator process_response method\n            on the requests.Response object.\n            If no OutputGenerator is specified for this instance, returns the requests.Response.\n        \"\"\"\n        if query_params is None:\n            query_params = {}\n\n        return self.execute_request(url, \"POST\", query_params, post_data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning which takes in a CSV file and creates a list of custom voices for each item in the CSV file.", "response": "def import_custom_views(filename):\n    \"\"\"\n    Function which takes in a csv files as input to the create_custom_views function from the pyhpeimc python module\n    available at https://github.com/HPNetworking/HP-Intelligent-Management-Center\n    :param filename: user-defined filename which contains two column named \"name\" and \"upperview\" as input into the\n    create_custom_views function from the pyhpeimc module.\n    :return: returns output of the create_custom_vies function (str) for each item in the CSV file.\n    \"\"\"\n    with open(filename) as csvfile:\n        # decodes file as csv as a python dictionary\n        reader = csv.DictReader(csvfile)\n        for view in reader:\n            # loads each row of the CSV as a JSON string\n            name = view['name']\n            upperview = view['upperview']\n            if len(upperview) is 0:\n                upperview = None\n            create_custom_views(name,upperview,auth=auth.creds, url=auth.url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction takes the ipAddress of a specific host and issues a RESTFUL call to get the device and interface that the target host is currently connected to. Note: Although intended to return a single location, Multiple locations may be returned for a single host due to a partially discovered network or misconfigured environment. :param host_ipaddress: str value valid IPv4 IP address :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: list of dictionaries where each element of the list represents the location of the target host :rtype: list >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.termaccess import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> found_device = get_real_time_locate('10.101.0.51', auth.creds, auth.url) >>> assert type(found_device) is list >>> assert 'deviceId' in found_device[0] >>> assert 'deviceId' in found_device[0] >>> assert 'deviceId' in found_device[0] >>> assert 'deviceId' in found_device[0] >>> no_device = get_real_time_locate('192.168.254.254', auth.creds, auth.url) >>> assert type(no_device) is dict >>> assert len(no_device) == 0", "response": "def get_real_time_locate(host_ipaddress, auth, url):\n    \"\"\"\n    function takes the ipAddress of a specific host and issues a RESTFUL call to get the device and\n    interface that the target host is currently connected to. Note: Although intended to return a\n    single location, Multiple locations may be returned for a single host due to a partially\n    discovered network or misconfigured environment.\n\n    :param host_ipaddress: str value valid IPv4 IP address\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: list of dictionaries where each element of the list represents the location of the\n    target host\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.termaccess import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> found_device = get_real_time_locate('10.101.0.51', auth.creds, auth.url)\n\n    >>> assert type(found_device) is list\n\n    >>> assert 'deviceId' in found_device[0]\n\n    >>> assert 'deviceId' in found_device[0]\n\n    >>> assert 'deviceId' in found_device[0]\n\n    >>> assert 'deviceId' in found_device[0]\n\n    >>> no_device = get_real_time_locate('192.168.254.254', auth.creds, auth.url)\n\n    >>> assert type(no_device) is dict\n\n    >>> assert len(no_device) == 0\n\n    \"\"\"\n    f_url = url + \"/imcrs/res/access/realtimeLocate?type=2&value=\" + str(host_ipaddress)  + \\\n            \"&total=false\"\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            response = json.loads(response.text)\n            if 'realtimeLocation' in response:\n                real_time_locate = response['realtimeLocation']\n                if isinstance(real_time_locate, dict):\n                    real_time_locate = [real_time_locate]\n                    return real_time_locate\n                else:\n                    return json.loads(response)['realtimeLocation']\n            else:\n                print(\"Host not found\")\n                return 403\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_real_time_locate: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ip_mac_arp_list(auth, url, devid=None, devip=None):\n    if devip is not None:\n        dev_details = get_dev_details(devip, auth, url)\n        if isinstance(dev_details, str):\n            print(\"Device not found\")\n            return 403\n        else:\n            devid = get_dev_details(devip, auth, url)['id']\n    f_url = url + \"/imcrs/res/access/ipMacArp/\" + str(devid)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            ipmacarplist = (json.loads(response.text))\n            if 'ipMacArp' in ipmacarplist:\n                return ipmacarplist['ipMacArp']\n            else:\n                return ['this function is unsupported']\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_ip_mac_arp_list: An Error has occured\"", "response": "function takes devid of specific device and issues a RESTFUL call to get the IP MAC ARP list of the target device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ip_scope(auth, url, scopeid=None, ):\n    if scopeid is None:\n        get_ip_scope_url = \"/imcrs/res/access/assignedIpScope\"\n    else:\n        get_ip_scope_url = \"/imcrs/res/access/assignedIpScope/ip?ipScopeId=\" + str(scopeid)\n\n    f_url = url + get_ip_scope_url\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            ipscopelist = (json.loads(response.text))['assignedIpScope']\n            if isinstance(ipscopelist, list):\n                return ipscopelist\n            elif isinstance(ipscopelist, dict):\n                return [ipscopelist]\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_ip_scope: An Error has occured\"", "response": "function returns all IP address scopes currently configured on the HPE\n    IMC server"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to add new Ip Scope to terminal access in HPE IMC base platform", "response": "def add_ip_scope(name, description, auth, url, startip=None, endip=None, network_address=None):\n    \"\"\"\n    Function takes input of four strings Start Ip, endIp, name, and description to add new Ip Scope\n    to terminal access in the HPE IMC base platform\n\n    :param name: str Name of the owner of this IP scope  ex. 'admin'\n\n    :param description: str description of the Ip scope\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param startip: str Start of IP address scope ex. '10.101.0.1'\n\n    :param endip: str End of IP address scope ex. '10.101.0.254'\n\n    :param network_address: ipv4 network address + subnet bits of target scope\n\n    :return: 200 if successfull\n\n    :rtype:\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.termaccess import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> delete_ip_scope('10.50.0.0/24', auth.creds, auth.url)\n    <Response [204]>\n\n    >>> new_scope = add_ip_scope('10.50.0.1', '10.50.0.254', 'cyoung', 'test group', auth.creds, auth.url)\n\n    >>> assert type(new_scope) is int\n\n    >>> assert new_scope == 200\n\n    >>> existing_scope = add_ip_scope('10.50.0.1', '10.50.0.254', 'cyoung', 'test group', auth.creds, auth.url)\n\n    >>> assert type(existing_scope) is int\n\n    >>> assert existing_scope == 409\n\n\n    \"\"\"\n    if network_address is not None:\n        nw_address = ipaddress.IPv4Network(network_address)\n        startip = nw_address[1]\n        endip = nw_address[-2]\n    f_url = url + \"/imcrs/res/access/assignedIpScope\"\n    payload = ('''{  \"startIp\": \"%s\", \"endIp\": \"%s\",\"name\": \"%s\",\"description\": \"%s\" }'''\n               % (str(startip), str(endip), str(name), str(description)))\n    response = requests.post(f_url, auth=auth, headers=HEADERS, data=payload)\n    try:\n        if response.status_code == 200:\n            # print(\"IP Scope Successfully Created\")\n            return response.status_code\n        elif response.status_code == 409:\n            # print (\"IP Scope Already Exists\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" add_ip_scope: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_ip_scope(network_address, auth, url):\n    scope_id = get_scope_id(network_address, auth, url)\n    if scope_id == \"Scope Doesn't Exist\":\n        return scope_id\n    f_url = url + '''/imcrs/res/access/assignedIpScope/''' + str(scope_id)\n    response = requests.delete(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 204:\n            # print(\"IP Segment Successfully Deleted\")\n            return 204\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" delete_ip_scope: An Error has occured\"", "response": "Function to delete an entire IP segment from the IMC IP Address management under terminal access"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_scope_ip(hostipaddress, name, description, auth, url, scopeid=None, network_address=None):\n    if network_address is not None:\n        scopeid = get_scope_id(network_address, auth, url)\n        if scopeid == \"Scope Doesn't Exist\":\n            return scopeid\n    new_ip = {\"ip\": hostipaddress,\n              \"name\": name,\n              \"description\": description}\n    f_url = url + '/imcrs/res/access/assignedIpScope/ip?ipScopeId=' + str(scopeid)\n    payload = json.dumps(new_ip)\n    response = requests.post(f_url, auth=auth, headers=HEADERS, data=payload)\n    try:\n        if response.status_code == 200:\n            # print(\"IP Host Successfully Created\")\n            return response.status_code\n        elif response.status_code == 409:\n            # print(\"IP Host Already Exists\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" add_ip_scope: An Error has occured\"", "response": "Function to add new host IP address allocation to existing scope ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_scope_ip(hostid, auth, url):\n    f_url = url + '/imcrs/res/access/assignedIpScope/ip/' + str(hostid)\n    response = requests.delete(f_url, auth=auth, headers=HEADERS, )\n    try:\n        if response.status_code == 204:\n            # print(\"Host Successfully Deleted\")\n            return response.status_code\n        elif response.status_code == 409:\n            # print(\"IP Scope Already Exists\")\n            return response.status_code\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" add_ip_scope: An Error has occured\"", "response": "Function to add remove IP address allocation to the base url of the IMC RS interface"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction returns list of allocated IP address for the specified scope ID and network address", "response": "def get_ip_scope_hosts(auth, url, scopeid=None, network_address=None):\n    \"\"\"\n    Function requires input of scope ID and returns list of allocated IP address for the\n    specified scope\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param scopeid: Integer of the desired scope id\n\n    :param network_address: ipv4 network address + subnet bits of target scope\n\n    :return: list of dictionary objects where each element of the list represents a single host\n    assigned to the IP scope\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.termaccess import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> scope_id = get_scope_id('10.50.0.0/24', auth.creds, auth.url)\n\n    >>> ip_scope_hosts = get_ip_scope_hosts(scope_id, auth.creds, auth.url)\n\n    >>> assert type(ip_scope_hosts) is list\n\n    >>> assert 'name' in ip_scope_hosts[0]\n\n    >>> assert 'description' in ip_scope_hosts[0]\n\n    >>> assert 'ip' in ip_scope_hosts[0]\n\n    >>> assert 'id' in ip_scope_hosts[0]\n\n    \"\"\"\n    if network_address is not None:\n        scopeid = get_scope_id(network_address, auth, url)\n        if scopeid == \"Scope Doesn't Exist\":\n            return scopeid\n    f_url = url + \"/imcrs/res/access/assignedIpScope/ip?size=10000&ipScopeId=\" + str(scopeid)\n    response = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if response.status_code == 200:\n            ipscopelist = (json.loads(response.text))\n            if ipscopelist == {}:\n                return [ipscopelist]\n            else:\n                ipscopelist = ipscopelist['assignedIpInfo']\n            if isinstance(ipscopelist, dict):\n                ipscope = [ipscopelist]\n                return ipscope\n            return ipscopelist\n    except requests.exceptions.RequestException as error:\n        return \"Error:\\n\" + str(error) + \" get_ip_scope: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef allow_attribute_comments(chain, node):\n\n    # TODO: find the relevant citation for why this is the correct way to comment attributes\n    if isinstance(node.previous_sibling(), astroid.Assign) and \\\n            isinstance(node.parent, (astroid.Class, astroid.Module)) and \\\n            isinstance(node.value, astroid.Const) and \\\n            isinstance(node.value.value, BASESTRING):\n        return\n\n    chain()", "response": "Augment the chain to allow comments on class attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(self, url, path, name_audio):\n        if path is not None:\n            with open(str(path+name_audio), 'wb') as handle:\n                response = requests.get(url, stream = True)\n                if not response.ok:\n                    raise Exception(\"Error in audio download.\")\n                for block in response.iter_content(1024):\n                    if not block:\n                        break\n                    handle.write(block)", "response": "Download the audio file from the url and save it to the path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dev_asset_details(ipaddress, auth, url):\n    get_dev_asset_url = \"/imcrs/netasset/asset?assetDevice.ip=\" + str(ipaddress)\n    f_url = url + get_dev_asset_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_asset_info = (json.loads(r.text))\n            if len(dev_asset_info) > 0:\n                dev_asset_info = dev_asset_info['netAsset']\n            if type(dev_asset_info) == dict:\n                dev_asset_info = [dev_asset_info]\n            if type(dev_asset_info) == list:\n                dev_asset_info[:] = [dev for dev in dev_asset_info if dev.get('deviceIp') == ipaddress]\n            return dev_asset_info\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_dev_asset_details: An Error has occured'", "response": "Takes in ipaddress as input to fetch device assett details from HP IMC RESTFUL API"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction takes no input to fetch device assett details from HP IMC RESTFUL API and returns a list of device asset details", "response": "def get_dev_asset_details_all(auth, url):\n    \"\"\"Takes no input to fetch device assett details from HP IMC RESTFUL API\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: list of dictionatires containing the device asset details\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.netassets import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> all_assets = get_dev_asset_details_all( auth.creds, auth.url)\n\n    >>> assert type(all_assets) is list\n\n    >>> assert 'asset' in all_assets[0]\n\n    \"\"\"\n    get_dev_asset_details_all_url = \"/imcrs/netasset/asset?start=0&size=15000\"\n    f_url = url + get_dev_asset_details_all_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_asset_info = (json.loads(r.text))['netAsset']\n            return dev_asset_info\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_dev_asset_details: An Error has occured'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_database_connected(db):\n    from sqlalchemy.exc import DBAPIError, SQLAlchemyError\n\n    errors = []\n    try:\n        with db.engine.connect() as connection:\n            connection.execute('SELECT 1;')\n    except DBAPIError as e:\n        msg = 'DB-API error: {!s}'.format(e)\n        errors.append(Error(msg, id=health.ERROR_DB_API_EXCEPTION))\n    except SQLAlchemyError as e:\n        msg = 'Database misconfigured: \"{!s}\"'.format(e)\n        errors.append(Error(msg, id=health.ERROR_SQLALCHEMY_EXCEPTION))\n    return errors", "response": "Check if the connection to the configured default database backend succeeds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_migrations_applied(migrate):\n    errors = []\n\n    from alembic.migration import MigrationContext\n    from alembic.script import ScriptDirectory\n    from sqlalchemy.exc import DBAPIError, SQLAlchemyError\n\n    # pass in Migrate.directory here explicitly to be compatible with\n    # older versions of Flask-Migrate that required the directory to be passed\n    config = migrate.get_config(directory=migrate.directory)\n    script = ScriptDirectory.from_config(config)\n\n    try:\n        with migrate.db.engine.connect() as connection:\n            context = MigrationContext.configure(connection)\n            db_heads = set(context.get_current_heads())\n            script_heads = set(script.get_heads())\n    except (DBAPIError, SQLAlchemyError) as e:\n        msg = \"Can't connect to database to check migrations: {!s}\".format(e)\n        return [Info(msg, id=health.INFO_CANT_CHECK_MIGRATIONS)]\n\n    if db_heads != script_heads:\n        msg = \"Unapplied migrations found: {}\".format(', '.join(script_heads))\n        errors.append(Warning(msg, id=health.WARNING_UNAPPLIED_MIGRATION))\n    return errors", "response": "Check if all migrations have been applied correctly."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_redis_connected(client):\n    import redis\n    errors = []\n\n    try:\n        result = client.ping()\n    except redis.ConnectionError as e:\n        msg = 'Could not connect to redis: {!s}'.format(e)\n        errors.append(Error(msg, id=health.ERROR_CANNOT_CONNECT_REDIS))\n    except redis.RedisError as e:\n        errors.append(Error('Redis error: \"{!s}\"'.format(e),\n                            id=health.ERROR_REDIS_EXCEPTION))\n    else:\n        if not result:\n            errors.append(Error('Redis ping failed',\n                                id=health.ERROR_REDIS_PING_FAILED))\n    return errors", "response": "Check Redis connection and see if it responds to the PING command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_custom_views(auth, url,name=None,headers=HEADERS):\n    if name is None:\n        get_custom_view_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&desc=false&total=false'\n    elif name is not None:\n        get_custom_view_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&name='+name+'&desc=false&total=false'\n    f_url = url + get_custom_view_url\n    r = requests.get(f_url, auth=auth, headers=headers)\n    try:\n        if r.status_code == 200:\n            custom_view_list = (json.loads(r.text))[\"customView\"]\n            if type(custom_view_list) == dict:\n                custom_view_list = [custom_view_list]\n                return custom_view_list\n            else:\n                return custom_view_list\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_custom_views: An Error has occured'", "response": "function takes input and returns a list of dictionaries of custom views from an HPE IMC."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_custom_views(auth, url,name=None, upperview=None):\n    create_custom_views_url = '/imcrs/plat/res/view/custom?resPrivilegeFilter=false&desc=false&total=false'\n    f_url = url + create_custom_views_url\n    if upperview is None:\n        payload = '''{ \"name\": \"''' + name + '''\",\n         \"upLevelSymbolId\" : \"\"}'''\n        print (payload)\n    else:\n        parentviewid = get_custom_views(auth, url, upperview)[0]['symbolId']\n        payload = '''{ \"name\": \"'''+name+ '''\",\n        \"upLevelSymbolId\" : \"'''+str(parentviewid)+'''\"}'''\n        print (payload)\n    r = requests.post(f_url, data = payload, auth=auth, headers=HEADERS)  # creates the URL using the payload variable as the contents\n    try:\n        if r.status_code == 201:\n            return 'View ' + name +' created successfully'\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + ' get_custom_views: An Error has occured'", "response": "function takes no input and issues a RESTFUL call to get a list of custom views from HPE IMC. Optioanl Name input is only return the specified view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning takes the devId of a specific device and issues a RESTFUL call to get the most current running config for that device.", "response": "def get_dev_run_config(devid, auth, url):\n    \"\"\"\n    function takes the devId of a specific device and issues a RESTFUL call to get the most current running config\n    file as known by the HP IMC Base Platform ICC module for the target device.\n    :param devid:  int or str value of the target device\n    :return: str which contains the entire content of the target device running configuration. If the device is not\n    currently supported in the HP IMC Base Platform ICC module, this call returns a string of \"This feature is not\n    supported on this device\"\n    \"\"\"\n    # checks to see if the imc credentials are already available\n    get_dev_run_url = \"/imcrs/icc/deviceCfg/\" + str(devid) + \"/currentRun\"\n    f_url = url + get_dev_run_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # print (r.status_code)\n    try:\n        if r.status_code == 200:\n            try:\n                run_conf = (json.loads(r.text))['content']\n                return run_conf\n            except:\n                return \"This features is no supported on this device\"\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_dev_run_config: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dev_start_config(devId, auth, url):\n    # checks to see if the imc credentials are already available\n    get_dev_run_url = \"/imcrs/icc/deviceCfg/\" + str(devId) + \"/currentStart\"\n    f_url = url + get_dev_run_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    try:\n        if r.status_code == 200:\n            try:\n                start_conf = (json.loads(r.text))['content']\n                return start_conf\n            except:\n                return \"Start Conf not supported on this device\"\n\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_dev_run_config: An Error has occured\"", "response": "function takes the devId of a specific device and issues a RESTFUL call to get the most current startup configuration for the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions takest devid and ifindex of specific device and interface and issues a RESTFUL call to undo shut the spec ified interface on the target device.", "response": "def set_inteface_up(devid, ifindex, auth, url):\n    \"\"\"\n    function takest devid and ifindex of specific device and interface and issues a RESTFUL call to \"undo shut\" the spec\n    ified interface on the target device.\n    :param devid: int or str value of the target device\n    :param ifindex: int or str value of the target interface\n    :return: HTTP status code 204 with no values.\n    \"\"\"\n    set_int_up_url = \"/imcrs/plat/res/device/\" + str(devid) + \"/interface/\" + str(ifindex) + \"/up\"\n    f_url = url + set_int_up_url\n    try:\n        r = requests.put(f_url, auth=auth,\n                     headers=HEADERS)  # creates the URL using the payload variable as the contents\n        if r.status_code == 204:\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" set_inteface_up: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vfolders(access_key):\n    '''\n    List and manage virtual folders.\n    '''\n    fields = [\n        ('Name', 'name'),\n        ('Created At', 'created_at'),\n        ('Last Used', 'last_used'),\n        ('Max Files', 'max_files'),\n        ('Max Size', 'max_size'),\n    ]\n    if access_key is None:\n        q = 'query { vfolders { $fields } }'\n    else:\n        q = 'query($ak:String) { vfolders(access_key:$ak) { $fields } }'\n    q = q.replace('$fields', ' '.join(item[1] for item in fields))\n    v = {'ak': access_key}\n    with Session() as session:\n        try:\n            resp = session.Admin.query(q, v)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        print(tabulate((item.values() for item in resp['vfolders']),\n                       headers=(item[0] for item in fields)))", "response": "List and manage virtual folders."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays the current configuration.", "response": "def config():\n    '''\n    Shows the current configuration.\n    '''\n    config = get_config()\n    print('Client version: {0}'.format(click.style(__version__, bold=True)))\n    print('API endpoint: {0}'.format(click.style(str(config.endpoint), bold=True)))\n    print('API version: {0}'.format(click.style(config.version, bold=True)))\n    print('Access key: \"{0}\"'.format(click.style(config.access_key, bold=True)))\n    masked_skey = config.secret_key[:6] + ('*' * 24) + config.secret_key[-10:]\n    print('Secret key: \"{0}\"'.format(click.style(masked_skey, bold=True)))\n    print('Signature hash type: {0}'.format(\n        click.style(config.hash_type, bold=True)))\n    print('Skip SSL certificate validation? {0}'.format(\n        click.style(str(config.skip_sslcert_validation), bold=True)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning takes string no input to issue RESTUL call to HP IMC API", "response": "def get_system_vendors(auth, url):\n    \"\"\"Takes string no input to issue RESTUL call to HP IMC\\n\n\n      :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n      :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n      :return: list of dictionaries where each dictionary represents a single vendor\n\n      :rtype: list\n\n      >>> from pyhpeimc.auth import *\n\n      >>> from pyhpeimc.plat.device import *\n\n      >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n      >>> vendors = get_system_vendors(auth.creds, auth.url)\n\n      >>> assert type(vendors) is list\n\n      >>> assert 'name' in vendors[0]\n\n\n    \"\"\"\n    get_system_vendors_url = '/imcrs/plat/res/vendor?start=0&size=10000&orderBy=id&desc=false&total=false'\n    f_url = url + get_system_vendors_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            system_vendors = (json.loads(r.text))\n            return system_vendors['deviceVendor']\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" get_dev_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning takes string no input to issue RESTUL call to HP IMC API", "response": "def get_system_category(auth, url):\n    \"\"\"Takes string no input to issue RESTUL call to HP IMC\\n\n\n      :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n      :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n      :return: list of dictionaries where each dictionary represents a single device category\n\n      :rtype: list\n\n      >>> from pyhpeimc.auth import *\n\n      >>> from pyhpeimc.plat.device import *\n\n      >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n      >>> categories = get_system_category(auth.creds, auth.url)\n\n      >>> assert type(categories) is list\n\n      >>> assert 'name' in categories[0]\n\n\n    \"\"\"\n    get_system_category_url = '/imcrs/plat/res/category?start=0&size=10000&orderBy=id&desc=false&total=false'\n    f_url = url + get_system_category_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            system_category = (json.loads(r.text))\n            return system_category['deviceCategory']\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" get_dev_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning takes string no input to issue RESTUL call to HP IMC API", "response": "def get_system_device_models(auth, url):\n    \"\"\"Takes string no input to issue RESTUL call to HP IMC\\n\n\n      :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n      :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n      :return: list of dictionaries where each dictionary represents a single device model\n\n      :rtype: list\n\n      >>> from pyhpeimc.auth import *\n\n      >>> from pyhpeimc.plat.device import *\n\n      >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n      >>> device_models = get_system_device_models(auth.creds, auth.url)\n\n      >>> assert type(device_models) is list\n\n      >>> assert 'virtualDeviceName' in device_models[0]\n\n    \"\"\"\n    get_system_device_model_url = '/imcrs/plat/res/model?start=0&size=10000&orderBy=id&desc=false&total=false'\n    f_url = url + get_system_device_model_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            system_device_model = (json.loads(r.text))\n            return system_device_model['deviceModel']\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" get_dev_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning takes string no input to issue RESTUL call to HP IMC API", "response": "def get_system_series(auth, url):\n    \"\"\"Takes string no input to issue RESTUL call to HP IMC\\n\n\n      :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n      :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n      :return: list of dictionaries where each dictionary represents a single device series\n\n      :rtype: list\n\n      >>> from pyhpeimc.auth import *\n\n      >>> from pyhpeimc.plat.device import *\n\n      >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n      >>> series = get_system_series(auth.creds, auth.url)\n\n      >>> assert type(series) is list\n\n      >>> assert 'name' in series[0]\n\n\n\n    \"\"\"\n    get_system_series_url = '/imcrs/plat/res/series?managedOnly=false&start=0&size=10000&orderBy=id&desc=false&total=false'\n    f_url = url + get_system_series_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            system_series = (json.loads(r.text))\n            return system_series['deviceSeries']\n    except requests.exceptions.RequestException as e:\n        return \"Error:\\n\" + str(e) + \" get_dev_series: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake string input of IP address to issue RESTUL call to HP IMC\\n :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :param network_address= str IPv4 Network Address :return: dictionary of device details :rtype: dict >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.device import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> dev_list = get_all_devs( auth.creds, auth.url, network_address= '10.11.') >>> assert type(dev_list) is list >>> assert 'sysName' in dev_list[0]", "response": "def get_all_devs(auth, url, network_address= None):\n    \"\"\"Takes string input of IP address to issue RESTUL call to HP IMC\\n\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :param network_address= str IPv4 Network Address\n\n    :return: dictionary of device details\n\n    :rtype: dict\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> dev_list = get_all_devs( auth.creds, auth.url, network_address= '10.11.')\n\n    >>> assert type(dev_list) is list\n\n    >>> assert 'sysName' in dev_list[0]\n\n\n    \"\"\"\n\n    if network_address != None:\n        get_all_devs_url = \"/imcrs/plat/res/device?resPrivilegeFilter=false&ip=\" + \\\n                          str(network_address) + \"&start=0&size=1000&orderBy=id&desc=false&total=false\"\n    else:\n        get_all_devs_url = \"/imcrs/plat/res/device?resPrivilegeFilter=false&start=0&size=1000&orderBy=id&desc=false&total=false&exact=false\"\n\n    f_url = url + get_all_devs_url\n        # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_details = (json.loads(r.text))\n            if len(dev_details) == 0:\n                print(\"Device not found\")\n                return \"Device not found\"\n            else:\n                return dev_details['device']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_dev_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking string input of IP address to issue RESTUL call to HP IMC\\n :param ip_address: string object of dotted decimal notation of IPv4 address :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass :return: dictionary of device details :rtype: dict >>> from pyhpeimc.auth import * >>> from pyhpeimc.plat.device import * >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\") >>> dev_1 = get_dev_details('10.101.0.221', auth.creds, auth.url) >>> assert type(dev_1) is dict >>> assert 'sysName' in dev_1 >>> dev_2 = get_dev_details('8.8.8.8', auth.creds, auth.url) Device not found >>> assert type(dev_2) is str", "response": "def get_dev_details(ip_address, auth, url):\n    \"\"\"Takes string input of IP address to issue RESTUL call to HP IMC\\n\n\n    :param ip_address: string object of dotted decimal notation of IPv4 address\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: dictionary of device details\n\n    :rtype: dict\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> dev_1 =  get_dev_details('10.101.0.221', auth.creds, auth.url)\n\n    >>> assert type(dev_1) is dict\n\n    >>> assert 'sysName' in dev_1\n\n    >>> dev_2 = get_dev_details('8.8.8.8', auth.creds, auth.url)\n    Device not found\n\n    >>> assert type(dev_2) is str\n\n\n    \"\"\"\n\n    get_dev_details_url = \"/imcrs/plat/res/device?resPrivilegeFilter=false&ip=\" + \\\n                          str(ip_address) + \"&start=0&size=1000&orderBy=id&desc=false&total=false\"\n    f_url = url + get_dev_details_url\n        # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_details = (json.loads(r.text))\n            if len(dev_details) == 0:\n                print(\"Device not found\")\n                return \"Device not found\"\n            elif type(dev_details['device']) == list:\n                for i in dev_details['device']:\n                    if i['ip'] == ip_address:\n                        dev_details = i\n                        return dev_details\n            elif type(dev_details['device']) == dict:\n                return dev_details['device']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_dev_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dev_interface(devid, auth, url):\n\n    get_dev_interface_url = \"/imcrs/plat/res/device/\" + str(devid) + \\\n                            \"/interface?start=0&size=1000&desc=false&total=false\"\n    f_url = url + get_dev_interface_url\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            int_list = (json.loads(r.text))['interface']\n            return int_list\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_dev_interface: An Error has occured\"", "response": "Function takes devid as input to RESTFUL call to HP IMC platform and returns list of device interfaces"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction takes devid of specific device and issues a RESTFUL call to gather the current IP - MAC learning entries on the target device.", "response": "def get_dev_mac_learn(devid, auth, url):\n    '''\n    function takes devid of specific device and issues a RESTFUL call to gather the current IP-MAC learning entries on\n    the target device.\n\n    :param devid: int value of the target device\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: list of dict objects which contain the mac learn table of target device id\n\n    :rtype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> dev_mac_learn = get_dev_mac_learn('10', auth.creds, auth.url)\n\n    >>> assert type(dev_mac_learn) is list\n\n    >>> assert 'deviceId' in dev_mac_learn[0]\n\n    '''\n    get_dev_mac_learn_url='/imcrs/res/access/ipMacLearn/'+str(devid)\n    f_url = url+get_dev_mac_learn_url\n    try:\n        r = requests.get(f_url, auth=auth, headers=HEADERS)\n        if r.status_code == 200:\n            if len(r.text) < 1:\n                mac_learn_query = {}\n                return mac_learn_query\n            else:\n                mac_learn_query = (json.loads(r.text))['ipMacLearnResult']\n                return mac_learn_query\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_dev_mac_learn: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction runs the specific commands on the target device and returns the output of the commands.", "response": "def run_dev_cmd(devid, cmd_list, auth, url):\n    '''\n    Function takes devid of target device and a sequential list of strings which define the specific commands to be run\n    on the target device and returns a str object containing the output of the commands.\n    :param devid: int devid of the target device\n\n    :param cmd_list: list of strings\n\n    :return: str containing the response of the commands\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> cmd_list = ['display version']\n\n    >>> cmd_output = run_dev_cmd('10', cmd_list, auth.creds, auth.url)\n\n    >>> assert type(cmd_output) is dict\n\n    >>> assert 'cmdlist' in cmd_output\n\n    >>> assert 'success' in cmd_output\n\n\n    '''\n    run_dev_cmd_url = '/imcrs/icc/confFile/executeCmd'\n    f_url = url + run_dev_cmd_url\n    cmd_list = _make_cmd_list(cmd_list)\n    payload = '''{ \"deviceId\" : \"'''+str(devid) + '''\",\n                   \"cmdlist\" : { \"cmd\" :\n                   ['''+ cmd_list + ''']\n\n                   }\n                   }'''\n    r = requests.post(f_url, data=payload, auth=auth, headers=HEADERS)\n    if r.status_code == 200:\n        if len(r.text) < 1:\n            return ''\n        else:\n            return json.loads(r.text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction takes devId of a specific device and the ifindex value assigned to a specific interface and issues a RESTFUL call to get the details of all interfaces on the target device.", "response": "def get_all_interface_details(devId, auth, url):\n    \"\"\"\n    function takes the devId of a specific device and the ifindex value assigned to a specific interface\n    and issues a RESTFUL call to get the interface details\n    file as known by the HP IMC Base Platform ICC module for the target device.\n\n    :param devId:  int or str value of the devId of the target device\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: list of dict objects which contains the details of all interfaces on the target device\n\n    :retype: list\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> all_interface_details = get_all_interface_details('10', auth.creds, auth.url)\n\n    >>> assert type(all_interface_details) is list\n\n    >>> assert 'ifAlias' in all_interface_details[0]\n\n\n     \"\"\"\n\n    get_all_interface_details_url = \"/imcrs/plat/res/device/\" + str(devId) + \"/interface/?start=0&size=1000&desc=false&total=false\"\n    f_url = url + get_all_interface_details_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_details = (json.loads(r.text))\n            return dev_details['interface']\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_interface_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions takes devId and ifIndex and issues a RESTFUL call to get the details of the target interface", "response": "def get_interface_details(devId, ifIndex, auth, url):\n    \"\"\"\n    function takes the devId of a specific device and the ifindex value assigned to a specific interface\n    and issues a RESTFUL call to get the interface details\n    file as known by the HP IMC Base Platform ICC module for the target device.\n\n    :param devId:  int or str value of the devId of the target device\n\n    :param ifIndex: int or str value of the ifIndex of the target interface\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: dict which contains the details of the target interface\"\n\n    :retype: dict\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> interface_details = get_interface_details('10', '1', auth.creds, auth.url)\n\n    >>> assert type(interface_details) is dict\n\n    >>> assert 'ifAlias' in interface_details\n\n\n     \"\"\"\n    get_interface_details_url = \"/imcrs/plat/res/device/\" + str(devId) + \"/interface/\" + str(ifIndex)\n    f_url = url + get_interface_details_url\n    payload = None\n    # creates the URL using the payload variable as the contents\n    r = requests.get(f_url, auth=auth, headers=HEADERS)\n    # r.status_code\n    try:\n        if r.status_code == 200:\n            dev_details = (json.loads(r.text))\n            return dev_details\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" get_interface_details: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction to shut the specifie d interface on the target device.", "response": "def set_interface_down(devid, ifindex, auth, url):\n    \"\"\"\n    function takest devid and ifindex of specific device and interface and issues a RESTFUL call to \" shut\" the specifie\n    d interface on the target device.\n    :param devid: int or str value of the target device\n\n    :param ifindex: int or str value of the target interface\n\n    :param auth: requests auth object #usually auth.creds from auth pyhpeimc.auth.class\n\n    :param url: base url of IMC RS interface #usually auth.url from pyhpeimc.auth.authclass\n\n    :return: HTTP status code 204 with no values.\n\n    :rtype:int\n\n    >>> from pyhpeimc.auth import *\n\n    >>> from pyhpeimc.plat.device import *\n\n    >>> auth = IMCAuth(\"http://\", \"10.101.0.203\", \"8080\", \"admin\", \"admin\")\n\n    >>> int_down_response = set_interface_down('10', '9', auth.creds, auth.url)\n    204\n\n    >>> assert type(int_down_response) is int\n\n    >>> assert int_down_response is 204\n    \"\"\"\n    set_int_down_url = \"/imcrs/plat/res/device/\" + str(devid) + \"/interface/\" + str(ifindex) + \"/down\"\n    f_url = url + set_int_down_url\n    try:\n        r = requests.put(f_url, auth=auth,\n                         headers=HEADERS)  # creates the URL using the payload variable as the contents\n        print(r.status_code)\n        if r.status_code == 204:\n            return r.status_code\n    except requests.exceptions.RequestException as e:\n            return \"Error:\\n\" + str(e) + \" set_inteface_down: An Error has occured\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def create(cls, name: str,\n                     default_for_unspecified: int,\n                     total_resource_slots: int,\n                     max_concurrent_sessions: int,\n                     max_containers_per_session: int,\n                     max_vfolder_count: int,\n                     max_vfolder_size: int,\n                     idle_timeout: int,\n                     allowed_vfolder_hosts: Sequence[str],\n                     fields: Iterable[str] = None) -> dict:\n        \"\"\"\n        Creates a new keypair resource policy with the given options.\n        You need an admin privilege for this operation.\n        \"\"\"\n        if fields is None:\n            fields = ('name',)\n        q = 'mutation($name: String!, $input: CreateKeyPairResourcePolicyInput!) {' \\\n            + \\\n            '  create_keypair_resource_policy(name: $name, props: $input) {' \\\n            '    ok msg resource_policy { $fields }' \\\n            '  }' \\\n            '}'\n        q = q.replace('$fields', ' '.join(fields))\n        variables = {\n            'name': name,\n            'input': {\n                'default_for_unspecified': default_for_unspecified,\n                'total_resource_slots': total_resource_slots,\n                'max_concurrent_sessions': max_concurrent_sessions,\n                'max_containers_per_session': max_containers_per_session,\n                'max_vfolder_count': max_vfolder_count,\n                'max_vfolder_size': max_vfolder_size,\n                'idle_timeout': idle_timeout,\n                'allowed_vfolder_hosts': allowed_vfolder_hosts,\n            },\n        }\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n            'variables': variables,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['create_keypair_resource_policy']", "response": "Create a new keypair resource policy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def list(cls, fields: Iterable[str] = None) -> Sequence[dict]:\n        '''\n        Lists the keypair resource policies.\n        You need an admin privilege for this operation.\n        '''\n        if fields is None:\n            fields = (\n                'name', 'created_at',\n                'total_resource_slots', 'max_concurrent_sessions',\n                'max_vfolder_count', 'max_vfolder_size',\n                'idle_timeout',\n            )\n        q = 'query {' \\\n            '  keypair_resource_policies {' \\\n            '    $fields' \\\n            '  }' \\\n            '}'\n        q = q.replace('$fields', ' '.join(fields))\n        rqst = Request(cls.session, 'POST', '/admin/graphql')\n        rqst.set_json({\n            'query': q,\n        })\n        async with rqst.fetch() as resp:\n            data = await resp.json()\n            return data['keypair_resource_policies']", "response": "Lists the keypair resource policies."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keypair():\n    '''\n    Show the server-side information of the currently configured access key.\n    '''\n    fields = [\n        ('User ID', 'user_id'),\n        ('Access Key', 'access_key'),\n        ('Secret Key', 'secret_key'),\n        ('Active?', 'is_active'),\n        ('Admin?', 'is_admin'),\n        ('Created At', 'created_at'),\n        ('Last Used', 'last_used'),\n        ('Res.Policy', 'resource_policy'),\n        ('Rate Limit', 'rate_limit'),\n        ('Concur.Limit', 'concurrency_limit'),\n        ('Concur.Used', 'concurrency_used'),\n    ]\n    with Session() as session:\n        try:\n            kp = session.KeyPair(session.config.access_key)\n            info = kp.info(fields=(item[1] for item in fields))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        rows = []\n        for name, key in fields:\n            rows.append((name, info[key]))\n        print(tabulate(rows, headers=('Field', 'Value')))", "response": "Show the server - side information of the currently configured access key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keypairs(ctx, user_id, is_active):\n    '''\n    List and manage keypairs.\n    To show all keypairs or other user's, your access key must have the admin\n    privilege.\n    (admin privilege required)\n    '''\n    if ctx.invoked_subcommand is not None:\n        return\n    fields = [\n        ('User ID', 'user_id'),\n        ('Access Key', 'access_key'),\n        ('Secret Key', 'secret_key'),\n        ('Active?', 'is_active'),\n        ('Admin?', 'is_admin'),\n        ('Created At', 'created_at'),\n        ('Last Used', 'last_used'),\n        ('Res.Policy', 'resource_policy'),\n        ('Rate Limit', 'rate_limit'),\n        ('Concur.Limit', 'concurrency_limit'),\n        ('Concur.Used', 'concurrency_used'),\n    ]\n    try:\n        user_id = int(user_id)\n    except (TypeError, ValueError):\n        pass  # string-based user ID for Backend.AI v1.4+\n    with Session() as session:\n        try:\n            items = session.KeyPair.list(user_id, is_active,\n                                         fields=(item[1] for item in fields))\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if len(items) == 0:\n            print('There are no matching keypairs associated '\n                  'with the user ID {0}'.format(user_id))\n            return\n        print(tabulate((item.values() for item in items),\n                       headers=(item[0] for item in fields)))", "response": "List and manage keypairs associated with a user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(user_id, resource_policy, admin, inactive,  rate_limit):\n    '''\n    Add a new keypair.\n\n    USER_ID: User ID of a new key pair.\n    RESOURCE_POLICY: resource policy for new key pair.\n    '''\n    try:\n        user_id = int(user_id)\n    except ValueError:\n        pass  # string-based user ID for Backend.AI v1.4+\n    with Session() as session:\n        try:\n            data = session.KeyPair.create(\n                user_id,\n                is_active=not inactive,\n                is_admin=admin,\n                resource_policy=resource_policy,\n                rate_limit=rate_limit)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if not data['ok']:\n            print_fail('KeyPair creation has failed: {0}'.format(data['msg']))\n            sys.exit(1)\n        item = data['keypair']\n        print('Access Key: {0}'.format(item['access_key']))\n        print('Secret Key: {0}'.format(item['secret_key']))", "response": "Add a new keypair."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating an existing keypair.", "response": "def update(access_key, resource_policy, is_admin, is_active,  rate_limit):\n    '''\n    Update an existing keypair.\n\n    ACCESS_KEY: Access key of an existing key pair.\n    '''\n    with Session() as session:\n        try:\n            data = session.KeyPair.update(\n                access_key,\n                is_active=is_active,\n                is_admin=is_admin,\n                resource_policy=resource_policy,\n                rate_limit=rate_limit)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if not data['ok']:\n            print_fail('KeyPair creation has failed: {0}'.format(data['msg']))\n            sys.exit(1)\n        print('Key pair is updated: ' + access_key + '.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete an existing keypair.", "response": "def delete(access_key):\n    \"\"\"\n    Delete an existing keypair.\n\n    ACCESSKEY: ACCESSKEY for a keypair to delete.\n    \"\"\"\n    with Session() as session:\n        try:\n            data = session.KeyPair.delete(access_key)\n        except Exception as e:\n            print_error(e)\n            sys.exit(1)\n        if not data['ok']:\n            print_fail('KeyPair deletion has failed: {0}'.format(data['msg']))\n            sys.exit(1)\n        print('Key pair is deleted: ' + access_key + '.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms API auth test returning user and team", "response": "def login(self):\n        \"\"\" perform API auth test returning user and team \"\"\"\n        log.debug('performing auth test')\n        test = self._get(urls['test'])\n        user = User({ 'name': test['user'], 'id': test['user_id'] })\n        self._refresh()\n        return test['team'], user"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a User object for a given Slack ID or name", "response": "def user(self, match):\n        \"\"\" Return User object for a given Slack ID or name \"\"\"\n        if len(match) == 9 and match[0] == 'U':\n            return self._lookup(User, 'id', match)\n        return self._lookup(User, 'name', match)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef channel(self, match):\n        if len(match) == 9 and match[0] in ('C','G','D'):\n            return self._lookup(Channel, 'id', match)\n        return self._lookup(Channel, 'name', match)", "response": "Return a Channel object for a given Slack ID or name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh internal directory cache", "response": "def _refresh(self):\n        \"\"\" refresh internal directory cache \"\"\"\n        log.debug('refreshing directory cache')\n        self._users.update(list(self._user_gen()))\n        self._channels.update(list(self._channel_gen()))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef match(self, attr, val):\n        self._lock.acquire()\n        try:\n            for x in self:\n                if getattr(x, attr) == val:\n                    return x\n        finally:\n            self._lock.release()", "response": "lookup object in directory with attribute matching value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _groups_of_size(iterable, n, fillvalue=None):\n    # _groups_of_size('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n    args = [iter(iterable)] * n\n    return zip_longest(fillvalue=fillvalue, *args)", "response": "Collect data into fixed - length chunks or blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef slice_repr(slice_instance):\n    if not isinstance(slice_instance, slice):\n        raise TypeError('Unhandled type {}'.format(type(slice_instance)))\n    start = slice_instance.start or ''\n    stop = slice_instance.stop or ''\n    step = slice_instance.step or ''\n\n    msg = '{}:'.format(start)\n    if stop:\n        msg += '{}'.format(stop)\n        if step:\n            msg += ':'\n    if step:\n        msg += '{}'.format(step)\n    return msg", "response": "Convert a slice into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef biggus_chunk(chunk_key, biggus_array, masked):\n        if masked:\n            array = biggus_array.masked_array()\n        else:\n            array = biggus_array.ndarray()\n\n        return biggus._init.Chunk(chunk_key, array)", "response": "A function that lazily evaluates a biggus. Chunk."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nproduces the nodes for the streams handler for the array.", "response": "def _make_stream_handler_nodes(self, dsk_graph, array, iteration_order,\n                                   masked):\n        \"\"\"\n        Produce task graph entries for an array that comes from a biggus\n        StreamsHandler.\n\n        This is essentially every type of array that isn't already a thing on\n        disk/in-memory. StreamsHandler arrays include all aggregations and\n        elementwise operations.\n\n        \"\"\"\n        nodes = {}\n        handler = array.streams_handler(masked)\n        input_iteration_order = handler.input_iteration_order(iteration_order)\n\n        def input_keys_transform(input_array, keys):\n            if hasattr(input_array, 'streams_handler'):\n                handler = input_array.streams_handler(masked)\n                # Get the transformer of the input array, and apply it to the\n                # keys.\n                input_transformer = getattr(handler,\n                                            'output_keys', None)\n                if input_transformer is not None:\n                    keys = input_transformer(keys)\n            return keys\n\n        sources_keys = []\n        sources_chunks = []\n        for input_array in array.sources:\n            # Bring together all chunks that influence the same part of this\n            # (resultant) array.\n            source_chunks_by_key = {}\n            sources_chunks.append(source_chunks_by_key)\n            source_keys = []\n            sources_keys.append(source_keys)\n\n            # Make nodes for the source arrays (if they don't already exist)\n            # before we do anything else.\n            input_nodes = self._make_nodes(dsk_graph, input_array,\n                                           input_iteration_order, masked)\n\n            for chunk_id, task in input_nodes.items():\n                chunk_keys = task[1]\n                t_keys = chunk_keys\n                t_keys = input_keys_transform(array, t_keys)\n                source_keys.append(t_keys)\n                this_key = str(t_keys)\n                source_chunks_by_key.setdefault(this_key,\n                                                []).append([chunk_id, task])\n\n        sources_keys_grouped = key_grouper.group_keys(array.shape,\n                                                      *sources_keys)\n        for slice_group, sources_keys_group in sources_keys_grouped.items():\n            # Each group is entirely independent and can have its own task\n            # without knowledge of results from items in other groups.\n\n            t_keys = tuple(slice(*slice_tuple) for slice_tuple in slice_group)\n\n            all_chunks = []\n            for source_keys, source_chunks_by_key in zip(sources_keys_group,\n                                                         sources_chunks):\n                dependencies = tuple(\n                        the_id\n                        for keys in source_keys\n                        for the_id, task in source_chunks_by_key[str(keys)])\n                # Uniquify source_keys, but keep the order.\n                dependencies = tuple(_unique_everseen(dependencies))\n\n                def normalize_keys(keys, shape):\n                    result = []\n                    for key, dim_length in zip(keys, shape):\n                        result.append(key_grouper.normalize_slice(key,\n                                                                  dim_length))\n                    return tuple(result)\n\n                # If we don't have the same chunks for all inputs then we\n                # should combine them before passing them on to the handler.\n                # TODO: Fix slice equality to deal with 0 and None etc.\n                if not all(t_keys == normalize_keys(keys, array.shape)\n                           for keys in source_keys):\n                    combined = self.collect(array[t_keys], masked, chunk=True)\n                    new_task = (combined, ) + dependencies\n                    new_id = ('chunk shape: {}\\n\\n{}'\n                              ''.format(array[t_keys].shape, uuid.uuid()))\n                    dsk_graph[new_id] = new_task\n                    dependencies = (new_id, )\n\n                all_chunks.append(dependencies)\n\n            pivoted = all_chunks\n\n            sub_array = array[t_keys]\n            handler = sub_array.streams_handler(masked)\n            name = getattr(handler, 'nice_name', handler.__class__.__name__)\n\n            if hasattr(handler, 'axis'):\n                name += '\\n(axis={})'.format(handler.axis)\n            # For ElementwiseStreams handlers, use the function that they wrap\n            # (e.g \"add\")\n            if hasattr(handler, 'operator'):\n                name = handler.operator.__name__\n\n            n_sources = len(array.sources)\n            handler_of_chunks_fn = self.create_chunks_handler_fn(handler,\n                                                                 n_sources,\n                                                                 name)\n\n            shape = sub_array.shape\n            if all(key == slice(None) for key in t_keys):\n                subset = ''\n            else:\n                pretty_index = ', '.join(map(slice_repr, t_keys))\n                subset = 'target subset [{}]\\n'.format(pretty_index)\n\n            # Flatten out the pivot so that dask can dereferences the IDs\n            source_chunks = [item for sublist in pivoted for item in sublist]\n            task = tuple([handler_of_chunks_fn, t_keys] + source_chunks)\n            shape_repr = ', '.join(map(str, shape))\n            chunk_id = 'chunk shape: ({})\\n\\n{}{}'.format(shape_repr,\n                                                          subset,\n                                                          uuid.uuid4())\n            assert chunk_id not in dsk_graph\n            dsk_graph[chunk_id] = task\n            nodes[chunk_id] = task\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lazy_chunk_creator(name):\n        # TODO: Could this become a LazyChunk class?\n        def biggus_chunk(chunk_key, biggus_array, masked):\n            \"\"\"\n            A function that lazily evaluates a biggus.Chunk. This is useful for\n            passing through as a dask task so that we don't have to compute the\n            chunk in order to compute the graph.\n\n            \"\"\"\n            if masked:\n                array = biggus_array.masked_array()\n            else:\n                array = biggus_array.ndarray()\n\n            return biggus._init.Chunk(chunk_key, array)\n        biggus_chunk.__name__ = name\n        return biggus_chunk", "response": "Create a lazy chunk creating function that lazily evaluates a biggus. Chunk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_password(prompt='Password: ', confirm=False):\n\n  # Are the arguments the expected type?\n  # If not, raise 'securesystemslib.exceptions.FormatError'.\n  securesystemslib.formats.TEXT_SCHEMA.check_match(prompt)\n  securesystemslib.formats.BOOLEAN_SCHEMA.check_match(confirm)\n\n  while True:\n    # getpass() prompts the user for a password without echoing\n    # the user input.\n    password = getpass.getpass(prompt, sys.stderr)\n\n    if not confirm:\n      return password\n    password2 = getpass.getpass('Confirm: ', sys.stderr)\n\n    if password == password2:\n      return password\n\n    else:\n      print('Mismatch; try again.')", "response": "Get a password from the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport a RSA private key from a PEM file.", "response": "def import_rsa_privatekey_from_file(filepath, password=None,\n    scheme='rsassa-pss-sha256', prompt=False):\n  \"\"\"\n  <Purpose>\n    Import the PEM file in 'filepath' containing the private key.\n\n    If password is passed use passed password for decryption.\n    If prompt is True use entered password for decryption.\n    If no password is passed and either prompt is False or if the password\n    entered at the prompt is an empty string, omit decryption, treating the\n    key as if it is not encrypted.\n    If password is passed and prompt is True, an error is raised. (See below.)\n\n    The returned key is an object in the\n    'securesystemslib.formats.RSAKEY_SCHEMA' format.\n\n  <Arguments>\n    filepath:\n      <filepath> file, an RSA encrypted PEM file.  Unlike the public RSA PEM\n      key file, 'filepath' does not have an extension.\n\n    password:\n      The passphrase to decrypt 'filepath'.\n\n    scheme:\n      The signature scheme used by the imported key.\n\n    prompt:\n      If True the user is prompted for a passphrase to decrypt 'filepath'.\n      Default is False.\n\n  <Exceptions>\n    ValueError, if 'password' is passed and 'prompt' is True.\n\n    ValueError, if 'password' is passed and it is an empty string.\n\n    securesystemslib.exceptions.FormatError, if the arguments are improperly\n    formatted.\n\n    securesystemslib.exceptions.FormatError, if the entered password is\n    improperly formatted.\n\n    IOError, if 'filepath' can't be loaded.\n\n    securesystemslib.exceptions.CryptoError, if a password is available\n    and 'filepath' is not a valid key file encrypted using that password.\n\n    securesystemslib.exceptions.CryptoError, if no password is available\n    and 'filepath' is not a valid non-encrypted key file.\n\n  <Side Effects>\n    The contents of 'filepath' are read, optionally decrypted, and returned.\n\n  <Returns>\n    An RSA key object, conformant to 'securesystemslib.formats.RSAKEY_SCHEMA'.\n\n  \"\"\"\n\n  # Does 'filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.RSA_SCHEME_SCHEMA.check_match(scheme)\n\n  if password and prompt:\n    raise ValueError(\"Passing 'password' and 'prompt' True is not allowed.\")\n\n  # If 'password' was passed check format and that it is not empty.\n  if password is not None:\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n    # TODO: PASSWORD_SCHEMA should be securesystemslib.schema.AnyString(min=1)\n    if not len(password):\n      raise ValueError('Password must be 1 or more characters')\n\n  elif prompt:\n    # Password confirmation disabled here, which should ideally happen only\n    # when creating encrypted key files (i.e., improve usability).\n    # It is safe to specify the full path of 'filepath' in the prompt and not\n    # worry about leaking sensitive information about the key's location.\n    # However, care should be taken when including the full path in exceptions\n    # and log files.\n    # NOTE: A user who gets prompted for a password, can only signal that the\n    # key is not encrypted by entering no password in the prompt, as opposed\n    # to a programmer who can call the function with or without a 'password'.\n    # Hence, we treat an empty password here, as if no 'password' was passed.\n    password = get_password('Enter a password for an encrypted RSA'\n        ' file \\'' + Fore.RED + filepath + Fore.RESET + '\\': ',\n        confirm=False) or None\n\n  if password is not None:\n    # This check will not fail, because a mal-formatted passed password fails\n    # above and an entered password will always be a string (see get_password)\n    # However, we include it in case PASSWORD_SCHEMA or get_password changes.\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n  else:\n    logger.debug('No password was given. Attempting to import an'\n        ' unencrypted file.')\n\n  # Read the contents of 'filepath' that should be a PEM formatted private key.\n  with open(filepath, 'rb') as file_object:\n    pem_key = file_object.read().decode('utf-8')\n\n  # Convert 'pem_key' to 'securesystemslib.formats.RSAKEY_SCHEMA' format.\n  # Raise 'securesystemslib.exceptions.CryptoError' if 'pem_key' is invalid.\n  # If 'password' is None decryption will be omitted.\n  rsa_key = securesystemslib.keys.import_rsakey_from_private_pem(pem_key,\n      scheme, password)\n\n  return rsa_key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_rsa_publickey_from_file(filepath):\n\n  # Does 'filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  # Read the contents of the key file that should be in PEM format and contains\n  # the public portion of the RSA key.\n  with open(filepath, 'rb') as file_object:\n    rsa_pubkey_pem = file_object.read().decode('utf-8')\n\n  # Convert 'rsa_pubkey_pem' to 'securesystemslib.formats.RSAKEY_SCHEMA' format.\n  try:\n    rsakey_dict = securesystemslib.keys.import_rsakey_from_public_pem(rsa_pubkey_pem)\n\n  except securesystemslib.exceptions.FormatError as e:\n    raise securesystemslib.exceptions.Error('Cannot import improperly formatted'\n      ' PEM file.' + repr(str(e)))\n\n  return rsakey_dict", "response": "Imports the RSA public key stored in filepath into a dict key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport the ed25519 public key from a file.", "response": "def import_ed25519_publickey_from_file(filepath):\n  \"\"\"\n  <Purpose>\n    Load the ED25519 public key object (conformant to\n    'securesystemslib.formats.KEY_SCHEMA') stored in 'filepath'.  Return\n    'filepath' in securesystemslib.formats.ED25519KEY_SCHEMA format.\n\n    If the key object in 'filepath' contains a private key, it is discarded.\n\n  <Arguments>\n    filepath:\n      <filepath>.pub file, a public key file.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'filepath' is improperly\n    formatted or is an unexpected key type.\n\n  <Side Effects>\n    The contents of 'filepath' is read and saved.\n\n  <Returns>\n    An ED25519 key object conformant to\n    'securesystemslib.formats.ED25519KEY_SCHEMA'.\n  \"\"\"\n\n  # Does 'filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  # ED25519 key objects are saved in json and metadata format.  Return the\n  # loaded key object in securesystemslib.formats.ED25519KEY_SCHEMA' format that\n  # also includes the keyid.\n  ed25519_key_metadata = securesystemslib.util.load_json_file(filepath)\n  ed25519_key, junk = \\\n    securesystemslib.keys.format_metadata_to_key(ed25519_key_metadata)\n\n  # Raise an exception if an unexpected key type is imported.  Redundant\n  # validation of 'keytype'.  'securesystemslib.keys.format_metadata_to_key()'\n  # should have fully validated 'ed25519_key_metadata'.\n  if ed25519_key['keytype'] != 'ed25519': # pragma: no cover\n    message = 'Invalid key type loaded: ' + repr(ed25519_key['keytype'])\n    raise securesystemslib.exceptions.FormatError(message)\n\n  return ed25519_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_ed25519_privatekey_from_file(filepath, password=None, prompt=False):\n\n  # Does 'filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  if password and prompt:\n    raise ValueError(\"Passing 'password' and 'prompt' True is not allowed.\")\n\n  # If 'password' was passed check format and that it is not empty.\n  if password is not None:\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n    # TODO: PASSWORD_SCHEMA should be securesystemslib.schema.AnyString(min=1)\n    if not len(password):\n      raise ValueError('Password must be 1 or more characters')\n\n  elif prompt:\n    # Password confirmation disabled here, which should ideally happen only\n    # when creating encrypted key files (i.e., improve usability).\n    # It is safe to specify the full path of 'filepath' in the prompt and not\n    # worry about leaking sensitive information about the key's location.\n    # However, care should be taken when including the full path in exceptions\n    # and log files.\n    # NOTE: A user who gets prompted for a password, can only signal that the\n    # key is not encrypted by entering no password in the prompt, as opposed\n    # to a programmer who can call the function with or without a 'password'.\n    # Hence, we treat an empty password here, as if no 'password' was passed.\n    password = get_password('Enter a password for an encrypted RSA'\n        ' file \\'' + Fore.RED + filepath + Fore.RESET + '\\': ',\n        confirm=False)\n\n    # If user sets an empty string for the password, explicitly set the\n    # password to None, because some functions may expect this later.\n    if len(password) == 0: # pragma: no cover\n      password = None\n\n  # Finally, regardless of password, try decrypting the key, if necessary.\n  # Otherwise, load it straight from the disk.\n  with open(filepath, 'rb') as file_object:\n    json_str = file_object.read()\n    return securesystemslib.keys.\\\n           import_ed25519key_from_private_json(json_str, password=password)", "response": "Imports an ed25519 private key from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_and_write_ecdsa_keypair(filepath=None, password=None):\n\n  # Generate a new ECDSA key object.  The 'cryptography' library is currently\n  # supported and performs the actual cryptographic operations.\n  ecdsa_key = securesystemslib.keys.generate_ecdsa_key()\n\n  if not filepath:\n    filepath = os.path.join(os.getcwd(), ecdsa_key['keyid'])\n\n  else:\n    logger.debug('The filepath has been specified.  Not using the key\\'s'\n        ' KEYID as the default filepath.')\n\n  # Does 'filepath' have the correct format?\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  # If the caller does not provide a password argument, prompt for one.\n  if password is None: # pragma: no cover\n\n    # It is safe to specify the full path of 'filepath' in the prompt and not\n    # worry about leaking sensitive information about the key's location.\n    # However, care should be taken when including the full path in exceptions\n    # and log files.\n    password = get_password('Enter a password for the ECDSA'\n        ' key (' + Fore.RED + filepath + Fore.RESET + '): ',\n        confirm=True)\n\n  else:\n    logger.debug('The password has been specified.  Not prompting for one')\n\n  # Does 'password' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n  # If the parent directory of filepath does not exist,\n  # create it (and all its parent directories, if necessary).\n  securesystemslib.util.ensure_parent_dir(filepath)\n\n  # Create a temporary file, write the contents of the public key, and move\n  # to final destination.\n  file_object = securesystemslib.util.TempFile()\n\n  # Generate the ECDSA public key file contents in metadata format (i.e., does\n  # not include the keyid portion).\n  keytype = ecdsa_key['keytype']\n  keyval = ecdsa_key['keyval']\n  scheme = ecdsa_key['scheme']\n  ecdsakey_metadata_format = securesystemslib.keys.format_keyval_to_metadata(\n      keytype, scheme, keyval, private=False)\n\n  file_object.write(json.dumps(ecdsakey_metadata_format).encode('utf-8'))\n\n  # Write the public key (i.e., 'public', which is in PEM format) to\n  # '<filepath>.pub'.  (1) Create a temporary file, (2) write the contents of\n  # the public key, and (3) move to final destination.\n  file_object.move(filepath + '.pub')\n\n  # Write the encrypted key string, conformant to\n  # 'securesystemslib.formats.ENCRYPTEDKEY_SCHEMA', to '<filepath>'.\n  file_object = securesystemslib.util.TempFile()\n  # Raise 'securesystemslib.exceptions.CryptoError' if 'ecdsa_key' cannot be\n  # encrypted.\n  encrypted_key = securesystemslib.keys.encrypt_key(ecdsa_key, password)\n  file_object.write(encrypted_key.encode('utf-8'))\n  file_object.move(filepath)\n\n  return filepath", "response": "This function generates an ECDSA keypair and writes it to the file at filepath."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_ecdsa_publickey_from_file(filepath):\n\n  # Does 'filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  # ECDSA key objects are saved in json and metadata format.  Return the\n  # loaded key object in securesystemslib.formats.ECDSAKEY_SCHEMA' format that\n  # also includes the keyid.\n  ecdsa_key_metadata = securesystemslib.util.load_json_file(filepath)\n  ecdsa_key, junk = \\\n    securesystemslib.keys.format_metadata_to_key(ecdsa_key_metadata)\n\n  # Raise an exception if an unexpected key type is imported.  Redundant\n  # validation of 'keytype'.  'securesystemslib.keys.format_metadata_to_key()'\n  # should have fully validated 'ecdsa_key_metadata'.\n  if ecdsa_key['keytype'] != 'ecdsa-sha2-nistp256': # pragma: no cover\n    message = 'Invalid key type loaded: ' + repr(ecdsa_key['keytype'])\n    raise securesystemslib.exceptions.FormatError(message)\n\n  return ecdsa_key", "response": "Imports a public key from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport an encrypted ECDSA key file in filepath and returns the object in the format of the ECDSAKEYSCHEMA format.", "response": "def import_ecdsa_privatekey_from_file(filepath, password=None):\n  \"\"\"\n  <Purpose>\n    Import the encrypted ECDSA key file in 'filepath', decrypt it, and return\n    the key object in 'securesystemslib.formats.ECDSAKEY_SCHEMA' format.\n\n    The 'cryptography' library is currently supported and performs the actual\n    cryptographic routine.\n\n  <Arguments>\n    filepath:\n      <filepath> file, an ECDSA encrypted key file.\n\n    password:\n      The password, or passphrase, to import the private key (i.e., the\n      encrypted key file 'filepath' must be decrypted before the ECDSA key\n      object can be returned.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if the arguments are improperly\n    formatted or the imported key object contains an invalid key type (i.e.,\n    not 'ecdsa-sha2-nistp256').\n\n    securesystemslib.exceptions.CryptoError, if 'filepath' cannot be decrypted.\n\n  <Side Effects>\n    'password' is used to decrypt the 'filepath' key file.\n\n  <Returns>\n    An ECDSA key object of the form: 'securesystemslib.formats.ECDSAKEY_SCHEMA'.\n  \"\"\"\n\n  # Does 'filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  # If the caller does not provide a password argument, prompt for one.\n  # Password confirmation disabled here, which should ideally happen only\n  # when creating encrypted key files (i.e., improve usability).\n  if password is None: # pragma: no cover\n\n    # It is safe to specify the full path of 'filepath' in the prompt and not\n    # worry about leaking sensitive information about the key's location.\n    # However, care should be taken when including the full path in exceptions\n    # and log files.\n    password = get_password('Enter a password for the encrypted ECDSA'\n        ' key (' + Fore.RED + filepath + Fore.RESET + '): ',\n        confirm=False)\n\n  # Does 'password' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n  # Store the encrypted contents of 'filepath' prior to calling the decryption\n  # routine.\n  encrypted_key = None\n\n  with open(filepath, 'rb') as file_object:\n    encrypted_key = file_object.read()\n\n  # Decrypt the loaded key file, calling the 'cryptography' library to generate\n  # the derived encryption key from 'password'.  Raise\n  # 'securesystemslib.exceptions.CryptoError' if the decryption fails.\n  key_object = securesystemslib.keys.decrypt_key(encrypted_key.decode('utf-8'),\n      password)\n\n  # Raise an exception if an unexpected key type is imported.\n  if key_object['keytype'] != 'ecdsa-sha2-nistp256':\n    message = 'Invalid key type loaded: ' + repr(key_object['keytype'])\n    raise securesystemslib.exceptions.FormatError(message)\n\n  # Add \"keyid_hash_algorithms\" so that equal ecdsa keys with different keyids\n  # can be associated using supported keyid_hash_algorithms.\n  key_object['keyid_hash_algorithms'] = \\\n      securesystemslib.settings.HASH_ALGORITHMS\n\n  return key_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits until the element identified by locator has focus.", "response": "def wait_until_element_has_focus(self, locator, timeout=None):\n\t\t\"\"\"Waits until the element identified by `locator` has focus.\n\t\tYou might rather want to use `Element Focus Should Be Set`\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| timeout | maximum time to wait before the function throws an element not found error (default=None) | 5s |\"\"\"\n\n\t\tself._info(\"Waiting for focus on '%s'\" % (locator))\n\t\tself._wait_until_no_error(timeout, self._check_element_focus_exp, True, locator, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait until the element identified by locator does not have focus.", "response": "def wait_until_element_does_not_have_focus(self, locator, timeout=None):\n\t\t\"\"\"Waits until the element identified by `locator` doesn't have focus.\n\t\tYou might rather want to use `Element Focus Should Not Be Set`\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| timeout | maximum time to wait before the function throws an element not found error (default=None) | 5s |\"\"\"\n\n\t\tself._info(\"Waiting until '%s' does not have focus\" % (locator))\n\t\tself._wait_until_no_error(timeout, self._check_element_focus_exp, False, locator, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait_until_element_value_is(self, locator, expected, strip=False, timeout=None):\n\n\t\tself._info(\"Waiting for '%s' value to be '%s'\" % (locator, expected))\n\t\tself._wait_until_no_error(timeout, self._check_element_value_exp, False, locator, expected, strip, timeout)", "response": "Waits until the element identified by locator value is exactly the expected value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_until_element_value_contains(self, locator, expected, timeout=None):\n\n\t\tself._info(\"Waiting for '%s' value to contain '%s'\" % (locator, expected))\n\t\tself._wait_until_no_error(timeout, self._check_element_value_exp, True, locator, expected, False, timeout)", "response": "Waits until the element identified by locator contains the expected value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting focus on the element identified by locator.", "response": "def set_element_focus(self, locator):\n\t\t\"\"\"Sets focus on the element identified by `locator`. Should\n\t\tbe used with elements meant to have focus only, such as\n\t\ttext fields. This keywords also waits for the focus to be\n\t\tactive by calling the `Wait Until Element Has Focus` keyword.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\"\"\"\n\n\t\tself._info(\"Setting focus on element '%s'\" % (locator))\n\t\t\n\t\telement = self._element_find(locator, True, True)\n\t\telement.send_keys(Keys.NULL)\n\n\t\tself._wait_until_no_error(None, self._check_element_focus, True, locator)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear the input field identified by locator.", "response": "def clear_input_field(self, locator, method=0):\n\t\t\"\"\"Clears the text field identified by `locator`\n\n\t\tThe element.clear() method doesn't seem to work properly on\n\t\tall browsers, so this keyword was created to offer alternatives.\n\n\t\tThe `method` argument defines the method it should use in order\n\t\tto clear the target field.\n\n\t\t0 = Uses the selenium method by doing element.clear \\n\n\t\t1 = Sets focus on the field and presses CTRL + A, and then DELETE \\n\n\t\t2 = Repeatedly presses BACKSPACE until the field is empty\n\n\t\tThis keyword, when using a method other than '2' does not validate it\n\t\tsuccessfully cleared the field, you should handle this verification by yourself.\n\t\tWhen using the method '2', it presses delete until the field's value is empty.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| method | the clearing method that should be used | no example provided |\"\"\"\n\n\t\telement = self._element_find(locator, True, True)\n\t\t\n\t\tif (int(method) == 0):\n\n\t\t\tself._info(\"Clearing input on element '%s'\" % (locator))\n\t\t\telement.clear()\n\n\t\telif (int(method) == 1):\n\n\t\t\tself._info(\"Clearing input on element '%s' by pressing 'CTRL + A + DELETE'\" % (locator))\n\t\t\telement.send_keys(Keys.CONTROL + 'a')\n\t\t\telement.send_keys(Keys.DELETE)\n\n\t\telif (int(method) == 2):\n\n\t\t\tself._info(\"Clearing input on element '%s' by repeatedly pressing BACKSPACE\" % (locator))\n\t\t\twhile (len(element.get_attribute('value')) != 0):\n\n\t\t\t\telement.send_keys(Keys.BACKSPACE)\n\n\t\telse: element.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef element_text_color_should_be(self, locator, expected):\n\n\t\tself._info(\"Verifying element '%s' has text color '%s'\" % (locator, expected))\n\t\tself._check_element_css_value(locator, 'color', expected)", "response": "Verifies the element identified by locator has the expected text color."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies the element identified by locator has the expected background color.", "response": "def element_background_color_should_be(self, locator, expected):\n\t\t\"\"\"Verifies the element identified by `locator` has the expected\n\t\tbackground color (it verifies the CSS attribute background-color). Color should\n\t\tbe in RGBA format.\n\n\t\tExample of rgba format: rgba(RED, GREEN, BLUE, ALPHA)\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| expected | expected color | rgba(0, 128, 0, 1) |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' has background color '%s'\" % (locator, expected))\n\t\tself._check_element_css_value(locator, 'background-color', expected)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying the element identified by locator has the expected width.", "response": "def element_width_should_be(self, locator, expected):\n\t\t\"\"\"Verifies the element identified by `locator` has the expected\n\t\twidth. Expected width should be in pixels.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| expected | expected width | 800 |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' width is '%s'\" % (locator, expected))\n\t\tself._check_element_size(locator, 'width', expected)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying the element identified by locator has the expected height.", "response": "def element_height_should_be(self, locator, expected):\n\t\t\"\"\"Verifies the element identified by `locator` has the expected\n\t\theight. Expected height should be in pixels.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| expected | expected height | 600 |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' height is '%s'\" % (locator, expected))\n\t\tself._check_element_size(locator, 'height', expected)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef element_value_should_be(self, locator, expected, strip=False):\n\n\t\tself._info(\"Verifying element '%s' value is '%s'\" % (locator, expected))\n\t\t\n\t\telement = self._element_find(locator, True, True)\n\t\tvalue = element.get_attribute('value')\n\n\t\tif (strip):\n\t\t\tvalue = value.strip()\n\t\t\n\t\tif str(value) == expected:\n\t\t\treturn\n\t\t\n\t\telse:\n\t\t\traise AssertionError(\"Element '%s' value was not '%s', it was '%s'\" % (locator, expected, value))", "response": "Verifies the element identified by locator has the expected value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying the element identified by locator is not the specified value.", "response": "def element_value_should_not_be(self, locator, value, strip=False):\n\t\t\"\"\"Verifies the element identified by `locator` is not the specified value.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| value | value it should not be | My Name Is Slim Shady |\n\t\t| strip | Boolean, determines whether it should strip the field's value before comparison or not | ${True} / ${False} |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' value is not '%s'\" % (locator, value))\n\t\t\n\t\telement = self._element_find(locator, True, True)\n\t\telem_value = str(element.get_attribute('value'))\n\n\t\tif (strip):\n\t\t\telem_value = elem_value.strip()\n\t\t\n\t\tif elem_value == value:\n\t\t\traise AssertionError(\"Value was '%s' for element '%s' while it shouldn't have\" % (elem_value, locator))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying the element identified by locator contains the expected value.", "response": "def element_value_should_contain(self, locator, expected):\n\t\t\"\"\"Verifies the element identified by `locator` contains the expected value.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| expected | expected value | Slim Shady |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' value contains '%s'\" % (locator, expected))\n\t\t\n\t\telement = self._element_find(locator, True, True)\n\t\tvalue = str(element.get_attribute('value'))\n\t\t\n\t\tif expected in value:\n\t\t\treturn\n\t\t\n\t\telse:\n\t\t\traise AssertionError(\"Value '%s' did not appear in element '%s'. It's value was '%s'\" % (expected, locator, value))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify the element identified by locator does not contain the specified value.", "response": "def element_value_should_not_contain(self, locator, value):\n\t\t\"\"\"Verifies the element identified by `locator` does not contain the specified value.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\n\t\t| value | value it should not contain | Slim Shady |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' value does not contain '%s'\" % (locator, value))\n\t\t\n\t\telement = self._element_find(locator, True, True)\n\t\telem_value = str(element.get_attribute('value'))\n\t\t\n\t\tif value in elem_value:\n\t\t\traise AssertionError(\"Value '%s' was found in element '%s' while it shouldn't have\" % (value, locator))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies the element identified by locator has focus.", "response": "def element_focus_should_be_set(self, locator):\n\t\t\"\"\"Verifies the element identified by `locator` has focus.\n\n\t\t| *Argument* | *Description* | *Example* |\n\t\t| locator | Selenium 2 element locator | id=my_id |\"\"\"\n\n\t\tself._info(\"Verifying element '%s' focus is set\" % locator)\n\t\tself._check_element_focus(True, locator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef element_focus_should_not_be_set(self, locator):\n\n\t\tself._info(\"Verifying element '%s' focus is not set\" % locator)\n\t\tself._check_element_focus(False, locator)", "response": "Verifies the element identified by locator has focus."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef element_css_attribute_should_be(self, locator, prop, expected):\n\n\t\tself._info(\"Verifying element '%s' has css attribute '%s' with a value of '%s'\" % (locator, prop, expected))\n\t\tself._check_element_css_value(locator, prop, expected)", "response": "Verifies the element identified by locator has the expected css attribute for the targeted prop."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_until_page_contains_one_of_these_elements(self, timeout, *locators):\n\t\t\n\t\tself._wait_until_no_error(timeout, self._wait_for_at_least_one_element, locators)", "response": "Waits until at least one of the specified elements is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_until_page_does_not_contain_these_elements(self, timeout, *locators):\n\n\t\tself._wait_until_no_error(timeout, self._wait_for_elements_to_go_away, locators)", "response": "Waits until all of the specified elements are not found on the page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tap_key(self, key, complementKey=None) :\n\n\t\tdriver = self._current_browser()\n\n\t\tif (complementKey is not None) :\n\t\t\tActionChains(driver).key_down(complementKey).send_keys(key).key_up(complementKey).perform()\n\n\t\telse :\n\t\t\tActionChains(driver).send_keys(key).perform()", "response": "Presses the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclicking the element specified by locator until the operation succeeds.", "response": "def wait_until_element_is_clickable(self, locator, timeout=None):\n\t\t\"\"\"Clicks the element specified by `locator` until the operation succeeds. This should be\n\t\tused with buttons that are generated in real-time and that don't have their click handling available\n\t\timmediately. This keyword avoids unclickable element exceptions.\n\n\t\t| =Argument= | =Description= | =Example= |\n\t\t| locator | Selenium 2 element locator(s) | id=MyId |\n\t\t| timeout | maximum time to wait, if set to ${None} it will use Selenium's default timeout | 5s |\"\"\"\n\n\t\tself._wait_until_no_error(timeout, self._wait_for_click_to_succeed, locator)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _visitor_impl(self, arg):\n    if (_qualname(type(self)), type(arg)) in _methods:\n        method = _methods[(_qualname(type(self)), type(arg))]\n        return method(self, arg)\n    else:\n        # if no visitor method found for this arg type,\n        # search in parent arg type:\n        arg_parent_type = arg.__class__.__bases__[0]\n        while arg_parent_type != object:\n            if (_qualname(type(self)), arg_parent_type) in _methods:\n                method = _methods[(_qualname(type(self)), arg_parent_type)]\n                return method(self, arg)\n            else:\n                arg_parent_type = arg_parent_type.__bases__[0]\n    raise VisitorException('No visitor found for class ' + str(type(arg)))", "response": "Actual visitor method implementation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visitor(arg_type):\n\n    def decorator(fn):\n        declaring_class = _declaring_class(fn)\n        _methods[(declaring_class, arg_type)] = fn\n\n        # Replace all decorated methods with _visitor_impl\n        return _visitor_impl\n\n    return decorator", "response": "Decorator that creates a visitor method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a full absolute URL based on the request host.", "response": "def absolute(parser, token):\n    '''\n    Returns a full absolute URL based on the request host.\n\n    This template tag takes exactly the same paramters as url template tag.\n    '''\n    node = url(parser, token)\n    return AbsoluteUrlNode(\n        view_name=node.view_name,\n        args=node.args,\n        kwargs=node.kwargs,\n        asvar=node.asvar\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef site(parser, token):\n    '''\n    Returns a full absolute URL based on the current site.\n\n    This template tag takes exactly the same paramters as url template tag.\n    '''\n    node = url(parser, token)\n    return SiteUrlNode(\n        view_name=node.view_name,\n        args=node.args,\n        kwargs=node.kwargs,\n        asvar=node.asvar\n    )", "response": "Returns a full absolute URL based on the current site."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _wait_until_exp(self, timeout, error, function, *args):\n\t\n\t\terror = error.replace('<TIMEOUT>', self._format_timeout(timeout))\n\t\n\t\tdef wait_func():\n\t\t\treturn None if function(*args) else error\n\t\t\t\n\t\tself._wait_until_no_error_exp(timeout, wait_func)", "response": "This method will wait until the timeout is reached or the function returns False."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rst(filename):\n    '''\n    Load rst file and sanitize it for PyPI.\n    Remove unsupported github tags:\n     - code-block directive\n    '''\n    content = open(filename).read()\n    return re.sub(r'\\.\\.\\s? code-block::\\s*(\\w|\\+)+', '::', content)", "response": "Load an rst file and sanitize it for PyPI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of callable methods of object obj.", "response": "def get_callable_method_dict(obj):\n    \"\"\"Returns a dictionary of callable methods of object `obj`.\n\n    @param obj: ZOS API Python COM object\n    @return: a dictionary of callable methods\n    \n    Notes: \n    the function only returns the callable attributes that are listed by dir() \n    function. Properties are not returned.\n    \"\"\"\n    methodDict = {}\n    for methodStr in dir(obj):\n        method = getattr(obj, methodStr, 'none')\n        if callable(method) and not methodStr.startswith('_'):\n            methodDict[methodStr] = method\n    return methodDict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplicates callable methods from a source object to a destination object.", "response": "def replicate_methods(srcObj, dstObj):\n    \"\"\"Replicate callable methods from a `srcObj` to `dstObj` (generally a wrapper object). \n    \n    @param srcObj: source object\n    @param dstObj: destination object of the same type.\n    @return : none\n    \n    Implementer notes: \n    1. Once the methods are mapped from the `srcObj` to the `dstObj`, the method calls will \n       not get \"routed\" through `__getattr__` method (if implemented) in `type(dstObj)` class.\n    2. An example of what a 'key' and 'value' look like:\n       key: MakeSequential\n       value: <bound method IOpticalSystem.MakeSequential of \n              <win32com.gen_py.ZOSAPI_Interfaces.IOpticalSystem instance at 0x77183968>>\n    \"\"\"\n    # prevent methods that we intend to specialize from being mapped. The specialized \n    # (overridden) methods are methods with the same name as the corresponding method in \n    # the source ZOS API COM object written for each ZOS API COM object in an associated \n    # python script such as i_analyses_methods.py for I_Analyses\n    overridden_methods = get_callable_method_dict(type(dstObj)).keys()\n    #overridden_attrs = [each for each in type(dstObj).__dict__.keys() if not each.startswith('_')]\n    # \n\n    def zos_wrapper_deco(func):\n        def wrapper(*args, **kwargs):\n            return wrapped_zos_object(func(*args, **kwargs))\n        varnames = func.im_func.func_code.co_varnames # alternative is to use inspect.getargspec\n        params = [par for par in varnames if par not in ('self', 'ret')] # removes 'self' and 'ret'\n        wrapper.__doc__ = func.im_func.func_name + '(' + ', '.join(params) + ')' \n        return wrapper \n    #\n    for key, value in get_callable_method_dict(srcObj).items():\n        if key not in overridden_methods:\n            setattr(dstObj, key, zos_wrapper_deco(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of properties that are only getters and setters", "response": "def get_properties(zos_obj):\n    \"\"\"Returns a lists of properties bound to the object `zos_obj`\n\n    @param zos_obj: ZOS API Python COM object\n    @return prop_get: list of properties that are only getters\n    @return prop_set: list of properties that are both getters and setters\n    \"\"\"\n    prop_get = set(zos_obj._prop_map_get_.keys())\n    prop_set = set(zos_obj._prop_map_put_.keys())\n    if prop_set.issubset(prop_get):\n        prop_get = prop_get.difference(prop_set)\n    else:\n        msg = 'Assumption all getters are also setters is incorrect!'\n        raise NotImplementedError(msg)\n    return list(prop_get), list(prop_set)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef managed_wrapper_class_factory(zos_obj):\n    cls_name = repr(zos_obj).split()[0].split('.')[-1]  \n    dispatch_attr = '_' + cls_name.lower()  # protocol to be followed to store the ZOS COM object\n    \n    cdict = {}  # class dictionary\n\n    # patch the properties of the base objects \n    base_cls_list = inheritance_dict.get(cls_name, None)\n    if base_cls_list:\n        for base_cls_name in base_cls_list:\n            getters, setters = get_properties(_CastTo(zos_obj, base_cls_name))\n            for each in getters:\n                exec(\"p{} = ZOSPropMapper('{}', '{}', cast_to='{}')\".format(each, dispatch_attr, each, base_cls_name), globals(), cdict)\n            for each in setters:\n                exec(\"p{} = ZOSPropMapper('{}', '{}', setter=True, cast_to='{}')\".format(each, dispatch_attr, each, base_cls_name), globals(), cdict)\n\n    # patch the property attributes of the given ZOS object\n    getters, setters = get_properties(zos_obj)\n    for each in getters:\n        exec(\"p{} = ZOSPropMapper('{}', '{}')\".format(each, dispatch_attr, each), globals(), cdict)\n    for each in setters:\n        exec(\"p{} = ZOSPropMapper('{}', '{}', setter=True)\".format(each, dispatch_attr, each), globals(), cdict)\n    \n    def __init__(self, zos_obj):\n        \n        # dispatcher attribute\n        cls_name = repr(zos_obj).split()[0].split('.')[-1] \n        dispatch_attr = '_' + cls_name.lower()    # protocol to be followed to store the ZOS COM object\n        self.__dict__[dispatch_attr] = zos_obj\n        self._dispatch_attr_value = dispatch_attr # used in __getattr__\n        \n        # Store base class object \n        self._base_cls_list = inheritance_dict.get(cls_name, None)\n\n        # patch the methods of the base class(s) of the given ZOS object\n        if self._base_cls_list:\n            for base_cls_name in self._base_cls_list:\n                replicate_methods(_CastTo(zos_obj, base_cls_name), self)\n\n        # patch the methods of given ZOS object \n        replicate_methods(zos_obj, self)\n\n        # mark object as wrapped to prevent it from being wrapped subsequently\n        self._wrapped = True\n    \n    # Provide a way to make property calls without the prefix p\n    def __getattr__(self, attrname):\n        return wrapped_zos_object(getattr(self.__dict__[self._dispatch_attr_value], attrname))\n\n    def __repr__(self):\n        if type(self).__name__ == 'IZOSAPI_Application':\n            repr_str = \"{.__name__}(NumberOfOpticalSystems = {})\".format(type(self), self.pNumberOfOpticalSystems)\n        else:\n            repr_str = \"{.__name__}\".format(type(self))\n        return repr_str\n        \n    cdict['__init__'] = __init__\n    cdict['__getattr__'] = __getattr__\n    cdict['__repr__'] = __repr__\n    \n    # patch custom methods from python files imported as modules\n    module_import_str = \"\"\"\ntry: \n    from pyzos.zos_obj_override.{module:} import *\nexcept ImportError:\n    pass\n\"\"\".format(module=cls_name.lower() + '_methods')\n    exec(module_import_str, globals(), cdict)\n\n    _ = cdict.pop('print_function', None)\n    _ = cdict.pop('division', None)\n    \n    return type(cls_name, (), cdict)", "response": "Creates and returns a wrapper class of a ZOS object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_public_and_private(scheme='ecdsa-sha2-nistp256'):\n\n  # Does 'scheme' have the correct format?\n  # Verify that 'scheme' is of the correct type, and that it's one of the\n  # supported ECDSA .  It must conform to\n  # 'securesystemslib.formats.ECDSA_SCHEME_SCHEMA'.  Raise\n  # 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.ECDSA_SCHEME_SCHEMA.check_match(scheme)\n\n  public_key = None\n  private_key = None\n\n  # An if-clause is strictly not needed, since 'ecdsa_sha2-nistp256' is the\n  # only currently supported ECDSA signature scheme.  Nevertheness, include the\n  # conditional statement to accomodate any schemes that might be added.\n  if scheme == 'ecdsa-sha2-nistp256':\n    private_key = ec.generate_private_key(ec.SECP256R1, default_backend())\n    public_key = private_key.public_key()\n\n  # The ECDSA_SCHEME_SCHEMA.check_match() above should have detected any\n  # invalid 'scheme'.  This is a defensive check.\n  else: #pragma: no cover\n    raise securesystemslib.exceptions.UnsupportedAlgorithmError('An unsupported'\n      ' scheme specified: ' + repr(scheme) + '.\\n  Supported'\n      ' algorithms: ' + repr(_SUPPORTED_ECDSA_SCHEMES))\n\n  private_pem = private_key.private_bytes(encoding=serialization.Encoding.PEM,\n    format=serialization.PrivateFormat.TraditionalOpenSSL,\n    encryption_algorithm=serialization.NoEncryption())\n\n  public_pem = public_key.public_bytes(encoding=serialization.Encoding.PEM,\n    format=serialization.PublicFormat.SubjectPublicKeyInfo)\n\n  return public_pem.decode('utf-8'), private_pem.decode('utf-8')", "response": "Generate a pair of public and private ECDSA keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_signature(public_key, private_key, data, scheme='ecdsa-sha2-nistp256'):\n\n  # Do 'public_key' and 'private_key' have the correct format?\n  # This check will ensure that the arguments conform to\n  # 'securesystemslib.formats.PEMECDSA_SCHEMA'.  Raise\n  # 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMECDSA_SCHEMA.check_match(public_key)\n\n  # Is 'private_key' properly formatted?\n  securesystemslib.formats.PEMECDSA_SCHEMA.check_match(private_key)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.ECDSA_SCHEME_SCHEMA.check_match(scheme)\n\n  # 'ecdsa-sha2-nistp256' is the only currently supported ECDSA scheme, so this\n  # if-clause isn't strictly needed.  Nevertheless, the conditional statement\n  # is included to accommodate multiple schemes that can potentially be added\n  # in the future.\n  if scheme == 'ecdsa-sha2-nistp256':\n    try:\n      private_key = load_pem_private_key(private_key.encode('utf-8'),\n        password=None, backend=default_backend())\n\n      signature = private_key.sign(data, ec.ECDSA(hashes.SHA256()))\n\n    except TypeError as e:\n      raise securesystemslib.exceptions.CryptoError('Could not create'\n        ' signature: ' + str(e))\n\n  # A defensive check for an invalid 'scheme'.  The\n  # ECDSA_SCHEME_SCHEMA.check_match() above should have already validated it.\n  else: #pragma: no cover\n    raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n      ' signature scheme is specified: ' + repr(scheme))\n\n  return signature, scheme", "response": "Create a signature for a public key and private key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_signature(public_key, scheme, signature, data):\n\n  # Are the arguments properly formatted?\n  # If not, raise 'securesystemslib.exceptions.FormatError'.\n  securesystemslib.formats.PEMECDSA_SCHEMA.check_match(public_key)\n  securesystemslib.formats.ECDSA_SCHEME_SCHEMA.check_match(scheme)\n  securesystemslib.formats.ECDSASIGNATURE_SCHEMA.check_match(signature)\n\n  ecdsa_key = load_pem_public_key(public_key.encode('utf-8'),\n      backend=default_backend())\n\n  if not isinstance(ecdsa_key, ec.EllipticCurvePublicKey):\n    raise securesystemslib.exceptions.FormatError('Invalid ECDSA public'\n      ' key: ' + repr(public_key))\n\n  else:\n    logger.debug('Loaded a valid ECDSA public key.')\n\n  # verify() raises an 'InvalidSignature' exception if 'signature'\n  # is invalid.\n  try:\n    ecdsa_key.verify(signature, data, ec.ECDSA(hashes.SHA256()))\n    return True\n\n  except (TypeError, cryptography.exceptions.InvalidSignature):\n    return False", "response": "Verifies that the signature of data was generated by the private key associated with public_key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_ecdsa_public_and_private_from_pem(pem, password=None):\n\n  # Does 'pem' have the correct format?\n  # This check will ensure 'pem' conforms to\n  # 'securesystemslib.formats.ECDSARSA_SCHEMA'.\n  securesystemslib.formats.PEMECDSA_SCHEMA.check_match(pem)\n\n  if password is not None:\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n    password = password.encode('utf-8')\n\n  else:\n    logger.debug('The password/passphrase is unset.  The PEM is expected'\n      ' to be unencrypted.')\n\n  public = None\n  private = None\n\n  # Generate the public and private ECDSA keys.  The pyca/cryptography library\n  # performs the actual import operation.\n  try:\n    private = load_pem_private_key(pem.encode('utf-8'), password=password,\n      backend=default_backend())\n\n  except (ValueError, cryptography.exceptions.UnsupportedAlgorithm) as e:\n    raise securesystemslib.exceptions.CryptoError('Could not import private'\n      ' PEM.\\n' + str(e))\n\n  public = private.public_key()\n\n  # Serialize public and private keys to PEM format.\n  private = private.private_bytes(encoding=serialization.Encoding.PEM,\n    format=serialization.PrivateFormat.TraditionalOpenSSL,\n    encryption_algorithm=serialization.NoEncryption())\n\n  public = public.public_bytes(encoding=serialization.Encoding.PEM,\n    format=serialization.PublicFormat.SubjectPublicKeyInfo)\n\n  return public.decode('utf-8'), private.decode('utf-8')", "response": "Create public and private ECDSA keys from a PEM formatted private key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_ecdsa_encrypted_pem(private_pem, passphrase):\n\n  # Does 'private_key' have the correct format?\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(private_pem)\n\n  # Does 'passphrase' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(passphrase)\n\n  encrypted_pem = None\n\n  private = load_pem_private_key(private_pem.encode('utf-8'), password=None,\n    backend=default_backend())\n\n  encrypted_private_pem = \\\n    private.private_bytes(encoding=serialization.Encoding.PEM,\n    format=serialization.PrivateFormat.TraditionalOpenSSL,\n    encryption_algorithm=serialization.BestAvailableEncryption(passphrase.encode('utf-8')))\n\n  return encrypted_private_pem", "response": "Create a private part of the ECDSA key in PEM format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclean any processing data and prepare object for reuse", "response": "def reset(self):\n        \"\"\"Clean any processing data, and prepare object for reuse\n        \"\"\"\n        self.current_table = None\n        self.tables = []\n        self.data = [{}]\n        self.additional_data = {}\n        self.lines = []\n        self.set_state('document')\n        self.current_file = None\n        self.set_of_energies = set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a single line of a file into a set of key - value pairs.", "response": "def _parse_line(self, file):\n        \"\"\"Parse single line (or more if particular keyword actually demands it)\n\n        :param file:\n        :type file: file\n        \"\"\"\n\n        line = self._strip_comments(file.readline())\n        # check if the file ended\n        if not line:\n            return False\n\n        # line was empty or it was a comment, continue\n        if line.strip() == '':\n            return True\n\n        # retrieve keyword and its value\n        reg = re.search(\"^\\*(?P<key>[^:#]*)(:\\s*(?P<value>.*)\\s*)?$\", line)\n        if reg:\n            key = reg.group('key').strip()\n            value = reg.group('value')\n\n            if key in self.mapping[self.current_state]:\n                self.mapping[self.current_state][key](value)\n            elif self.strict:\n                raise BadFormat(\"unknown key: *%s\" % key)\n        else:\n            raise BadFormat(\"line can not be parsed: %s\" % line)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset current parsing state to table create new table object and add it to data collection", "response": "def _set_table(self, data):\n        \"\"\"Set current parsing state to 'table',\n        create new table object and add it to tables collection\n        \"\"\"\n        self.set_state('table')\n        self.current_table = HEPTable(index=len(self.tables) + 1)\n        self.tables.append(self.current_table)\n        self.data.append(self.current_table.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_table_data(self, data):\n        header = data.split(':')\n\n        self.current_table.data_header = header\n\n        for i, h in enumerate(header):\n            header[i] = h.strip()\n\n        x_count = header.count('x')\n        y_count = header.count('y')\n\n        if not self.current_table.xheaders:\n            raise BadFormat(\"*xheader line needs to appear before *data: %s\" % data)\n\n        if not self.current_table.yheaders:\n            raise BadFormat(\"*yheader line needs to appear before *data: %s\" % data)\n\n        # use deepcopy to avoid references in yaml... may not be required, and will very probably be refactored\n        # TODO - is this appropriate behavior, or are references in YAML files acceptable, they are certainly less human readable\n        self.current_table.data = {'independent_variables': [{'header': self.current_table.xheaders[i] if i < len(self.current_table.xheaders) else copy.deepcopy(self.current_table.xheaders[-1]),\n                                                              'values': []} for i in range(x_count)],\n                                      'dependent_variables': [{'header': self.current_table.yheaders[i] if i < len(self.current_table.yheaders) else copy.deepcopy(self.current_table.yheaders[-1]),\n                                                               'qualifiers': [self.current_table.qualifiers[j][i] if i < len(self.current_table.qualifiers[j]) else copy.deepcopy(self.current_table.qualifiers[j][-1]) for j in range(len(self.current_table.qualifiers)) ],\n                                                               'values': []} for i in range(y_count)]}\n\n        xy_mapping = []\n\n        current_x_count = 0\n        current_y_count = 0\n\n        for h in header:\n            if h == 'x':\n                xy_mapping.append(current_x_count)\n                current_x_count += 1\n            if h == 'y':\n                xy_mapping.append(current_y_count)\n                current_y_count += 1\n\n        last_index = self.current_file.tell()\n        line = self._strip_comments(self.current_file.readline())\n\n        while line and not line.startswith('*'):\n            data_entry_elements = line.split(';')[:-1] # split and also strip newline character at the end\n\n            if len(data_entry_elements) == len(header):\n            # this is kind of a big stretch... I assume that x is always first\n                for i, h in enumerate(header):\n                    single_element = data_entry_elements[i].strip()\n\n                    # number patterns copied from old subs.pl parsing script\n                    pmnum1 = '[-+]?[\\d]+\\.?[\\d]*'\n                    pmnum2 = '[-+]?\\.[\\d]+'\n                    pmnum3 = '[-+]?[\\d]+\\.?[\\d]*\\s*[eE]+\\s*[+-]?\\s*[\\d]+'\n                    pmnum = '(' + pmnum1 + '|' + pmnum2 + '|' + pmnum3 + ')'\n\n                    # implement same regular expression matching as in old subs.pl parsing script\n\n                    if h == 'x': # independent variables\n\n                        r = re.search('^(?P<value>' + pmnum + ')$', single_element)\n                        if r: # \"value\"\n                            single_element = {'value': r.group('value')}\n                        else:\n                            r = re.search('^(?P<value>' + pmnum + ')\\s*\\(\\s*BIN\\s*=\\s*(?P<low>' + pmnum + \\\n                                          ')\\s+TO\\s+(?P<high>' + pmnum + ')\\s*\\)$', single_element)\n                            if r: # \"value (BIN=low TO high)\"\n                                single_element = {'value': float(r.group('value')),\n                                                  'low': float(r.group('low')), 'high': float(r.group('high'))}\n                            else:\n                                r = re.search('^(?P<low>' + pmnum + ')\\s+TO\\s+(?P<high>' + pmnum + ')$',\n                                              single_element)\n                                if r: # \"low TO high\"\n                                    single_element = {'low': float(r.group('low')), 'high': float(r.group('high'))}\n                                else: # everything else: don't try to convert to float\n                                    single_element = {'value': single_element}\n\n                        # TO DO: subs.pl also parses other formats such as \"low high\", \"value low high\" (sorted),\n                        # \"value +- err\", and \"value -err_m, +err_p\".  Do we need to support these formats here?\n                        # Probably not: unsupported formats will just be written as a text string.\n\n                        self.current_table.data['independent_variables'][xy_mapping[i]]['values'].append(single_element)\n\n                        # extract energy if SQRT(S) is one of the 'x' variables\n                        xheader = self.current_table.data['independent_variables'][xy_mapping[i]]['header']\n                        if xheader['name'].startswith('SQRT(S)') and lower(xheader['units']) in ('gev'):\n                            for energy in single_element.values():\n                                try:\n                                    energy = float(energy)\n                                    self.set_of_energies.add(energy)\n                                except:\n                                    pass\n\n                    elif h == 'y': # dependent variable\n\n                        pmnum_pct = pmnum + '(\\s*PCT)?' # errors can possibly be given as percentages\n\n                        r = re.search('^(?P<value>' + pmnum + ')\\s+(?P<err_p>' + pmnum_pct + '|-)\\s*,\\s*(?P<err_m>' +\n                                      pmnum_pct + '|-)\\s*(?P<err_sys>\\(\\s*DSYS=[^()]+\\s*\\))?$', single_element)\n                        element = {'errors': []}\n                        if r: # asymmetric first error\n                            element['value'] = r.group('value').strip()\n                            err_p = r.group('err_p').strip().lstrip('+')\n                            if err_p == '-': err_p = '' # represent missing error as '-' in oldhepdata format\n                            err_p = err_p[:-3].strip() + '%' if err_p[-3:] == 'PCT' else err_p\n                            err_m = r.group('err_m').strip().lstrip('+')\n                            if err_m == '-': err_m = '' # represent missing error as '-' in oldhepdata format\n                            err_m = err_m[:-3].strip() + '%' if err_m[-3:] == 'PCT' else err_m\n                            if err_p and err_m and err_p[-1] != '%' and err_m[-1] == '%':\n                                err_p = err_p + '%'\n                            if not err_p and not err_m:\n                                raise ValueError(\"Both asymmetric errors cannot be '-': %s\" % line)\n                            if r.group('err_sys'):\n                                element['errors'] += [{'label': 'stat', 'asymerror': {'plus': err_p, 'minus': err_m}}]\n                            else:\n                                element['errors'] += [{'asymerror': {'plus': err_p, 'minus': err_m}}]\n\n                        else:\n                            r = re.search('^(?P<value>' + pmnum + ')\\s*(\\+-\\s*(?P<error>' +\n                                          pmnum_pct + '))?\\s*(?P<err_sys>\\(\\s*DSYS=[^()]+\\s*\\))?$', single_element)\n                            if r: # symmetric first error\n                                element['value'] = r.group('value').strip()\n                                if r.group('error'):\n                                    error = r.group('error').strip().lstrip('+')\n                                    error = error[:-3].strip() + '%' if error[-3:] == 'PCT' else error\n                                    if r.group('err_sys'):\n                                        element['errors'] += [{'label': 'stat', 'symerror': error}]\n                                    else:\n                                        element['errors'] += [{'symerror': error}]\n                            else: # everything else\n                                element['value'] = single_element\n\n                        err_sys = []\n                        if r and r.group('err_sys'):\n                            err_sys = r.group('err_sys').strip(' \\t()').split('DSYS=')\n\n                        for err in err_sys + self.current_table.dserrors:\n                            err = err.strip(' \\t,')\n                            if not err:\n                                continue\n                            error = {}\n                            label = 'sys'\n                            r = re.search('^(\\+-)?\\s*(?P<error>' + pmnum_pct + ')\\s*(\\:\\s*(?P<label>.+))?$', err)\n                            if r: # symmetric systematic error\n                                if r.group('label'):\n                                    label += ',' + r.group('label')\n                                error = r.group('error').strip().lstrip('+')\n                                error = error[:-3].strip() + '%' if error[-3:] == 'PCT' else error\n                                error = {'symerror': error}\n\n                            else:\n                                r = re.search('^(?P<err_p>' + pmnum_pct + '|-)\\s*,\\s*(?P<err_m>' +\n                                              pmnum_pct + '|-)\\s*(\\:\\s*(?P<label>.+))?$', err)\n                                if r: # asymmetric systematic error\n                                    if r.group('label'):\n                                        label += ',' + r.group('label')\n                                    err_p = r.group('err_p').strip().lstrip('+')\n                                    if err_p == '-': err_p = '' # represent missing error as '-' in oldhepdata format\n                                    err_p = err_p[:-3].strip() + '%' if err_p[-3:] == 'PCT' else err_p\n                                    err_m = r.group('err_m').strip().lstrip('+')\n                                    if err_m == '-': err_m = '' # represent missing error as '-' in oldhepdata format\n                                    err_m = err_m[:-3].strip() + '%' if err_m[-3:] == 'PCT' else err_m\n                                    if err_p and err_m and err_p[-1] != '%' and err_m[-1] == '%':\n                                        err_p = err_p + '%'\n                                    if not err_p and not err_m:\n                                        raise ValueError(\"Both asymmetric errors cannot be '-': %s\" % line)\n                                    error = {'asymerror': {'plus': err_p, 'minus': err_m}}\n                            if not r:\n                                # error happened\n                                raise ValueError(\"Error while parsing data line: %s\" % line)\n\n                            error['label'] = label\n                            if element['value'] != single_element:\n                                element['errors'].append(error)\n                        self.current_table.data['dependent_variables'][xy_mapping[i]]['values'].append(element)\n\n            elif data_entry_elements:\n                raise BadFormat(\"%s data entry elements but %s expected: %s\" %\n                                (len(data_entry_elements), len(header), line))\n\n            last_index = self.current_file.tell()\n            l = self.current_file.readline()\n            line = self._strip_comments(l)\n\n        self.current_file.seek(last_index)\n\n        # extract minimum and maximum from set of energies\n        if self.set_of_energies:\n            energy_min = min(self.set_of_energies)\n            energy_max = max(self.set_of_energies)\n            if energy_max > energy_min:\n                energy = str(energy_min) + '-' + str(energy_max)\n            else:\n                energy = energy_min\n            self._parse_energies(energy)\n\n        if self.current_table.description:\n            if any(word in self.current_table.description.lower() for word in ['covariance', 'correlation', 'matrix']):\n                reformatted = self._reformat_matrix()", "response": "Parse the data of the original HEPData format and store the result in self. current_table. data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming a square matrix into a format with two independent variables and one dependent variable.", "response": "def _reformat_matrix(self):\n        \"\"\"Transform a square matrix into a format with two independent variables and one dependent variable.\n        \"\"\"\n        nxax = len(self.current_table.data['independent_variables'])\n        nyax = len(self.current_table.data['dependent_variables'])\n        npts = len(self.current_table.data['dependent_variables'][0]['values'])\n\n        # check if 1 x-axis, and npts (>=2) equals number of y-axes\n        if nxax != 1 or nyax != npts or npts < 2:\n            return False\n\n        # add second independent variable with each value duplicated npts times\n        if len(self.current_table.xheaders) == 2:\n            xheader = self.current_table.xheaders[1]\n        else:\n            xheader = copy.deepcopy(self.current_table.data['independent_variables'][0]['header'])\n        self.current_table.data['independent_variables'].append({'header': xheader, 'values': []})\n        for value in self.current_table.data['independent_variables'][0]['values']:\n            self.current_table.data['independent_variables'][1]['values'].extend([copy.deepcopy(value) for npt in range(npts)])\n\n        # duplicate values of first independent variable npts times\n        self.current_table.data['independent_variables'][0]['values'] \\\n            = [copy.deepcopy(value) for npt in range(npts) for value in self.current_table.data['independent_variables'][0]['values']]\n\n        # suppress header if different for second y-axis\n        if self.current_table.data['dependent_variables'][0]['header'] != \\\n                self.current_table.data['dependent_variables'][1]['header']:\n            self.current_table.data['dependent_variables'][0]['header'] = {'name': ''}\n\n        # remove qualifier if different for second y-axis\n        iqdel = [] # list of qualifier indices to be deleted\n        for iq, qualifier in enumerate(self.current_table.data['dependent_variables'][0]['qualifiers']):\n            if qualifier != self.current_table.data['dependent_variables'][1]['qualifiers'][iq]:\n                iqdel.append(iq)\n        for iq in iqdel[::-1]: # need to delete in reverse order\n            del self.current_table.data['dependent_variables'][0]['qualifiers'][iq]\n\n        # append values of second and subsequent y-axes to first dependent variable\n        for iy in range(1, nyax):\n            for value in self.current_table.data['dependent_variables'][iy]['values']:\n                self.current_table.data['dependent_variables'][0]['values'].append(value)\n\n        # finally, delete the second and subsequent y-axes in reverse order\n        for iy in range(nyax-1, 0, -1):\n            del self.current_table.data['dependent_variables'][iy]\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the qual attribute of the old HEPData format", "response": "def _parse_qual(self, data):\n        \"\"\"Parse qual attribute of the old HEPData format\n\n        example qual:\n        *qual: RE : P P --> Z0 Z0 X\n\n        :param data: data to be parsed\n        :type data: str\n        \"\"\"\n        list = []\n        headers = data.split(':')\n        name = headers[0].strip()\n\n        name = re.split(' IN ', name, flags=re.I) # ignore case\n        units = None\n        if len(name) > 1:\n            units = name[1].strip()\n        name = name[0].strip()\n\n        if len(headers) < 2:\n            raise BadFormat(\"*qual line must contain a name and values: %s\" % data)\n\n        for header in headers[1:]:\n            xheader = {'name': name}\n            if units:\n                xheader['units'] = units\n\n            xheader['value'] = header.strip()\n            list.append(xheader)\n\n            # extract energy if SQRT(S) is one of the qualifiers\n            if name.startswith('SQRT(S)') and lower(units) in ('gev'):\n                energies = re.split(' TO ', xheader['value'], flags=re.I)\n                for energy in energies:\n                    try:\n                        energy = float(energy)\n                        self.set_of_energies.add(energy)\n                    except:\n                        pass\n\n        self.current_table.qualifiers.append(list)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_header(self, data):\n        return_list = []\n\n        headers = data.split(':')\n\n        for header in headers:\n            header = re.split(' IN ', header, flags=re.I) # ignore case\n            xheader = {'name': header[0].strip()}\n            if len(header) > 1:\n                xheader['units'] = header[1].strip()\n            return_list.append(xheader)\n\n        return return_list", "response": "Parse the header of the nacms table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _strip_comments(line):\n        if line == '':\n            return line\n        r = re.search('(?P<line>[^#]*)(#(?P<comment>.*))?', line)\n        if r:\n            line = r.group('line')\n            if not line.endswith('\\n'):\n                line += '\\n'\n            return line\n        return '\\n'", "response": "Processes a line with any comments from it\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_multiline(self, init_data):\n        result = init_data\n\n        first = True\n        while True:\n            last_index = self.current_file.tell()\n            line_raw = self.current_file.readline()\n\n            # don't add newlines from full line comments\n            if line_raw[0] == '#':\n                continue\n\n            # now strip comments\n            # TODO - is it appropriate behavior?\n            data = self._strip_comments(line_raw)\n            # EOF, stop here\n            if not data:\n                break\n\n            # we arrived to the next command, step back and break\n            if len(data.strip()) >= 1 and data.strip()[0] == '*':\n                self.current_file.seek(last_index)\n                break\n\n            if first:\n                result += '\\n'\n                first = False\n\n            result += data\n\n        result = result.strip()\n        if result and not result.endswith('.'):\n            result += '.'\n\n        return result", "response": "Reads a multiline symbol from the current file and returns the parsed value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn parsing function which will parse data as text and add it to the table. metadata with the provided key and multiline attributes.", "response": "def _bind_set_table_metadata(self, key,  multiline=False):\n        \"\"\"Returns parsing function which will parse data as text, and add it to the table metatadata dictionary\n        with the provided key\n\n        :param key: dictionary key under which parsed data will be added to table.metadata\n        :type key: str\n        :param multiline: if True this attribute will be treated as multiline\n        :type multiline: bool\n        :return: function with bound key and multiline attributes\n        :rtype: Function\n        \"\"\"\n        def set_table_metadata(self, data):\n            if multiline:\n                data = self._read_multiline(data)\n            if key == 'location' and data:\n                data = 'Data from ' + data\n            self.current_table.metadata[key] = data.strip()\n\n        # method must be bound, so we use __get__\n        return set_table_metadata.__get__(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _bind_parse_additional_data(self, key, multiline=False):\n\n        def _set_additional_data_bound(self, data):\n            \"\"\"Concrete method for setting additional data\n            :param self:\n            :type self: OldHEPData\n            \"\"\"\n            # if it's multiline, parse it\n            if multiline:\n                data = self._read_multiline(data)\n\n            if key not in self.additional_data:\n                self.additional_data[key] = []\n            self.additional_data[key].append(data)\n\n        # method must be bound, so we use __get__\n        return _set_additional_data_bound.__get__(self)", "response": "Returns parsing function which will parse data as text and add it to the table additional data dictionary with the provided key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef error_value_processor(value, error):\n    if isinstance(error, (str, unicode)):\n        try:\n            if \"%\" in error:\n                error_float = float(error.replace(\"%\", \"\"))\n                error_abs = (value/100) * error_float\n                return error_abs\n            elif error == \"\":\n                error = 0.0\n            else:\n                error = float(error)\n        except:\n            pass\n\n    return error", "response": "Process an error value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the length and hash of a file.", "response": "def get_file_details(filepath, hash_algorithms=['sha256']):\n  \"\"\"\n  <Purpose>\n    To get file's length and hash information.  The hash is computed using the\n    sha256 algorithm.  This function is used in the signerlib.py and updater.py\n    modules.\n\n  <Arguments>\n    filepath:\n      Absolute file path of a file.\n\n    hash_algorithms:\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError: If hash of the file does not match\n    HASHDICT_SCHEMA.\n\n    securesystemslib.exceptions.Error: If 'filepath' does not exist.\n\n  <Returns>\n    A tuple (length, hashes) describing 'filepath'.\n  \"\"\"\n\n  # Making sure that the format of 'filepath' is a path string.\n  # 'securesystemslib.exceptions.FormatError' is raised on incorrect format.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n  securesystemslib.formats.HASHALGORITHMS_SCHEMA.check_match(hash_algorithms)\n\n  # The returned file hashes of 'filepath'.\n  file_hashes = {}\n\n  # Does the path exists?\n  if not os.path.exists(filepath):\n    raise securesystemslib.exceptions.Error('Path ' + repr(filepath) + ' doest'\n        ' not exist.')\n\n  filepath = os.path.abspath(filepath)\n\n  # Obtaining length of the file.\n  file_length = os.path.getsize(filepath)\n\n  # Obtaining hash of the file.\n  for algorithm in hash_algorithms:\n    digest_object = securesystemslib.hash.digest_filename(filepath, algorithm)\n    file_hashes.update({algorithm: digest_object.hexdigest()})\n\n  # Performing a format check to ensure 'file_hash' corresponds HASHDICT_SCHEMA.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.HASHDICT_SCHEMA.check_match(file_hashes)\n\n  return file_length, file_hashes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that the parent directory of filename exists.", "response": "def ensure_parent_dir(filename):\n  \"\"\"\n  <Purpose>\n    To ensure existence of the parent directory of 'filename'.  If the parent\n    directory of 'name' does not exist, create it.\n\n    Example: If 'filename' is '/a/b/c/d.txt', and only the directory '/a/b/'\n    exists, then directory '/a/b/c/d/' will be created.\n\n  <Arguments>\n    filename:\n      A path string.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError: If 'filename' is improperly\n    formatted.\n\n  <Side Effects>\n    A directory is created whenever the parent directory of 'filename' does not\n    exist.\n\n  <Return>\n    None.\n  \"\"\"\n\n  # Ensure 'filename' corresponds to 'PATH_SCHEMA'.\n  # Raise 'securesystemslib.exceptions.FormatError' on a mismatch.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filename)\n\n  # Split 'filename' into head and tail, check if head exists.\n  directory = os.path.split(filename)[0]\n\n  if directory and not os.path.exists(directory):\n    # mode = 'rwx------'. 448 (decimal) is 700 in octal.\n    os.makedirs(directory, 448)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the filepath is in the list of confined directories.", "response": "def file_in_confined_directories(filepath, confined_directories):\n  \"\"\"\n  <Purpose>\n    Check if the directory containing 'filepath' is in the list/tuple of\n    'confined_directories'.\n\n  <Arguments>\n    filepath:\n      A string representing the path of a file.  The following example path\n      strings are viewed as files and not directories: 'a/b/c', 'a/b/c.txt'.\n\n    confined_directories:\n      A list, or a tuple, of directory strings.\n\n  <Exceptions>\n   securesystemslib.exceptions.FormatError: On incorrect format of the input.\n\n  <Return>\n    Boolean.  True, if path is either the empty string\n    or in 'confined_paths'; False, otherwise.\n  \"\"\"\n\n  # Do the arguments have the correct format?\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.RELPATH_SCHEMA.check_match(filepath)\n  securesystemslib.formats.RELPATHS_SCHEMA.check_match(confined_directories)\n\n  for confined_directory in confined_directories:\n    # The empty string (arbitrarily chosen) signifies the client is confined\n    # to all directories and subdirectories.  No need to check 'filepath'.\n    if confined_directory == '':\n      return True\n\n    # Normalized paths needed, to account for up-level references, etc.\n    # TUF clients have the option of setting the list of directories in\n    # 'confined_directories'.\n    filepath = os.path.normpath(filepath)\n    confined_directory = os.path.normpath(confined_directory)\n\n    # A TUF client may restrict himself to specific directories on the\n    # remote repository.  The list of paths in 'confined_path', not including\n    # each path's subdirectories, are the only directories the client will\n    # download targets from.\n    if os.path.dirname(filepath) == confined_directory:\n      return True\n\n  return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the index of a given delegated role in a list of roles.", "response": "def find_delegated_role(roles, delegated_role):\n  \"\"\"\n  <Purpose>\n    Find the index, if any, of a role with a given name in a list of roles.\n\n  <Arguments>\n    roles:\n      The list of roles, each of which must have a 'name' attribute.\n\n    delegated_role:\n      The name of the role to be found in the list of roles.\n\n  <Exceptions>\n    securesystemslib.exceptions.RepositoryError, if the list of roles has\n    invalid data.\n\n  <Side Effects>\n    No known side effects.\n\n  <Returns>\n    The unique index, an interger, in the list of roles.  if 'delegated_role'\n    does not exist, 'None' is returned.\n  \"\"\"\n\n  # Do the arguments have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.  Raise\n  # 'securesystemslib.exceptions.FormatError' if any are improperly formatted.\n  securesystemslib.formats.ROLELIST_SCHEMA.check_match(roles)\n  securesystemslib.formats.ROLENAME_SCHEMA.check_match(delegated_role)\n\n  # The index of a role, if any, with the same name.\n  role_index = None\n\n  for index in six.moves.xrange(len(roles)):\n    role = roles[index]\n    name = role.get('name')\n\n    # This role has no name.\n    if name is None:\n      no_name_message = 'Role with no name.'\n      raise securesystemslib.exceptions.RepositoryError(no_name_message)\n\n    # Does this role have the same name?\n    else:\n      # This role has the same name, and...\n      if name == delegated_role:\n        # ...it is the only known role with the same name.\n        if role_index is None:\n          role_index = index\n\n        # ...there are at least two roles with the same name.\n        else:\n          duplicate_role_message = 'Duplicate role (' + str(delegated_role) + ').'\n          raise securesystemslib.exceptions.RepositoryError(\n              'Duplicate role (' + str(delegated_role) + ').')\n\n      # This role has a different name.\n      else:\n        logger.debug('Skipping delegated role: ' + repr(delegated_role))\n\n  return role_index"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef paths_are_consistent_with_hash_prefixes(paths, path_hash_prefixes):\n\n  # Do the arguments have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.  Raise\n  # 'securesystemslib.exceptions.FormatError' if any are improperly formatted.\n  securesystemslib.formats.RELPATHS_SCHEMA.check_match(paths)\n  securesystemslib.formats.PATH_HASH_PREFIXES_SCHEMA.check_match(path_hash_prefixes)\n\n  # Assume that 'paths' and 'path_hash_prefixes' are inconsistent until\n  # proven otherwise.\n  consistent = False\n\n  # The format checks above ensure the 'paths' and 'path_hash_prefix' lists\n  # have lengths greater than zero.\n  for path in paths:\n    path_hash = get_target_hash(path)\n\n    # Assume that every path is inconsistent until proven otherwise.\n    consistent = False\n\n    for path_hash_prefix in path_hash_prefixes:\n      if path_hash.startswith(path_hash_prefix):\n        consistent = True\n        break\n\n    # This path has no matching path_hash_prefix. Stop looking further.\n    if not consistent:\n      break\n\n  return consistent", "response": "Checks if a list of paths are consistent with the given list of path hash prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the hash of the target file on the repository.", "response": "def get_target_hash(target_filepath):\n  \"\"\"\n  <Purpose>\n    Compute the hash of 'target_filepath'. This is useful in conjunction with\n    the \"path_hash_prefixes\" attribute in a delegated targets role, which tells\n    us which paths it is implicitly responsible for.\n\n    The repository may optionally organize targets into hashed bins to ease\n    target delegations and role metadata management.  The use of consistent\n    hashing allows for a uniform distribution of targets into bins.\n\n  <Arguments>\n    target_filepath:\n      The path to the target file on the repository. This will be relative to\n      the 'targets' (or equivalent) directory on a given mirror.\n\n  <Exceptions>\n    None.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    The hash of 'target_filepath'.\n  \"\"\"\n\n  # Does 'target_filepath' have the correct format?\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.RELPATH_SCHEMA.check_match(target_filepath)\n\n  # Calculate the hash of the filepath to determine which bin to find the\n  # target.  The client currently assumes the repository uses\n  # 'HASH_FUNCTION' to generate hashes and 'utf-8'.\n  digest_object = securesystemslib.hash.digest(HASH_FUNCTION)\n  encoded_target_filepath = target_filepath.encode('utf-8')\n  digest_object.update(encoded_target_filepath)\n  target_filepath_hash = digest_object.hexdigest()\n\n  return target_filepath_hash"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting the json module and returns it.", "response": "def import_json():\n  \"\"\"\n  <Purpose>\n    Tries to import json module. We used to fall back to the simplejson module,\n    but we have dropped support for that module. We are keeping this interface\n    intact for backwards compatibility.\n\n  <Arguments>\n    None.\n\n  <Exceptions>\n    ImportError: on failure to import the json module.\n\n  <Side Effects>\n    None.\n\n  <Return>\n    json module\n  \"\"\"\n\n  global _json_module\n\n  if _json_module is not None:\n    return _json_module\n\n  else:\n    try:\n      module = __import__('json')\n\n    # The 'json' module is available in Python > 2.6, and thus this exception\n    # should not occur in all supported Python installations (> 2.6) of TUF.\n    except ImportError: #pragma: no cover\n      raise ImportError('Could not import the json module')\n\n    else:\n      _json_module = module\n      return module"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_json_string(data):\n\n  deserialized_object = None\n\n  try:\n    deserialized_object = json.loads(data)\n\n  except TypeError:\n    message = 'Invalid JSON string: ' + repr(data)\n    raise securesystemslib.exceptions.Error(message)\n\n  except ValueError:\n    message = 'Cannot deserialize to a Python object: ' + repr(data)\n    raise securesystemslib.exceptions.Error(message)\n\n  else:\n    return deserialized_object", "response": "Deserialize a JSON string into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a JSON file containing the object.", "response": "def load_json_file(filepath):\n  \"\"\"\n  <Purpose>\n    Deserialize a JSON object from a file containing the object.\n\n  <Arguments>\n    filepath:\n      Absolute path of JSON file.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError: If 'filepath' is improperly\n    formatted.\n\n    securesystemslib.exceptions.Error: If 'filepath' cannot be deserialized to\n    a Python object.\n\n    IOError in case of runtime IO exceptions.\n\n  <Side Effects>\n    None.\n\n  <Return>\n    Deserialized object.  For example, a dictionary.\n  \"\"\"\n\n  # Making sure that the format of 'filepath' is a path string.\n  # securesystemslib.exceptions.FormatError is raised on incorrect format.\n  securesystemslib.formats.PATH_SCHEMA.check_match(filepath)\n\n  deserialized_object = None\n\n  # The file is mostly likely gzipped.\n  if filepath.endswith('.gz'):\n    logger.debug('gzip.open(' + str(filepath) + ')')\n    fileobject = six.StringIO(gzip.open(filepath).read().decode('utf-8'))\n\n  else:\n    logger.debug('open(' + str(filepath) + ')')\n    fileobject = open(filepath)\n\n  try:\n    deserialized_object = json.load(fileobject)\n\n  except (ValueError, TypeError) as e:\n    raise securesystemslib.exceptions.Error('Cannot deserialize to a'\n      ' Python object: ' + repr(filepath))\n\n  else:\n    fileobject.close()\n    return deserialized_object\n\n  finally:\n    fileobject.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine if two hexadecimal arguments are equal.", "response": "def digests_are_equal(digest1, digest2):\n  \"\"\"\n  <Purpose>\n    While protecting against timing attacks, compare the hexadecimal arguments\n    and determine if they are equal.\n\n  <Arguments>\n    digest1:\n      The first hexadecimal string value to compare.\n\n    digest2:\n      The second hexadecimal string value to compare.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError: If the arguments are improperly\n    formatted.\n\n  <Side Effects>\n    None.\n\n  <Return>\n    Return True if 'digest1' is equal to 'digest2', False otherwise.\n  \"\"\"\n\n  # Ensure the arguments have the appropriate number of objects and object\n  # types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.HEX_SCHEMA.check_match(digest1)\n  securesystemslib.formats.HEX_SCHEMA.check_match(digest2)\n\n  if len(digest1) != len(digest2):\n    return False\n\n  are_equal = True\n\n  for element in range(len(digest1)):\n    if digest1[element] != digest2[element]:\n      are_equal = False\n\n  return are_equal"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _default_temporary_directory(self, prefix):\n    try:\n      self.temporary_file = tempfile.NamedTemporaryFile(prefix=prefix)\n\n    except OSError as err: # pragma: no cover\n      logger.critical('Cannot create a system temporary directory: '+repr(err))\n      raise securesystemslib.exceptions.Error(err)", "response": "__init__ helper. Creates a temporary directory with the given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, size=None):\n\n    if size is None:\n      self.temporary_file.seek(0)\n      data = self.temporary_file.read()\n      self.temporary_file.seek(0)\n\n      return data\n\n    else:\n      if not (isinstance(size, int) and size > 0):\n        raise securesystemslib.exceptions.FormatError\n\n      return self.temporary_file.read(size)", "response": "Reads the specified number of bytes from the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, data, auto_flush=True):\n\n    self.temporary_file.write(data)\n    if auto_flush:\n      self.flush()", "response": "Writes a string to the temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove the file from self. temporary_file to destination_path.", "response": "def move(self, destination_path):\n    \"\"\"\n    <Purpose>\n      Copies 'self.temporary_file' to a non-temp file at 'destination_path' and\n      closes 'self.temporary_file' so that it is removed.\n\n    <Arguments>\n      destination_path:\n        Path to store the file in.\n\n    <Exceptions>\n      None.\n\n    <Return>\n      None.\n    \"\"\"\n\n    self.flush()\n    self.seek(0)\n    destination_file = open(destination_path, 'wb')\n    shutil.copyfileobj(self.temporary_file, destination_file)\n    # Force the destination file to be written to disk from Python's internal\n    # and the operation system's buffers.  os.fsync() should follow flush().\n    destination_file.flush()\n    os.fsync(destination_file.fileno())\n    destination_file.close()\n\n    # 'self.close()' closes temporary file which destroys itself.\n    self.close_temp_file()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecompress a compressed temp file object.", "response": "def decompress_temp_file_object(self, compression):\n    \"\"\"\n    <Purpose>\n      To decompress a compressed temp file object.  Decompression is performed\n      on a temp file object that is compressed, this occurs after downloading\n      a compressed file.  For instance if a compressed version of some meta\n      file in the repository is downloaded, the temp file containing the\n      compressed meta file will be decompressed using this function.\n      Note that after calling this method, write() can no longer be called.\n\n                            meta.json.gz\n                               |...[download]\n                        temporary_file (containing meta.json.gz)\n                        /             \\\n               temporary_file          _orig_file\n          containing meta.json          containing meta.json.gz\n          (decompressed data)\n\n    <Arguments>\n      compression:\n        A string indicating the type of compression that was used to compress\n        a file.  Only gzip is allowed.\n\n    <Exceptions>\n      securesystemslib.exceptions.FormatError: If 'compression' is improperly formatted.\n\n      securesystemslib.exceptions.Error: If an invalid compression is given.\n\n      securesystemslib.exceptions.DecompressionError: If the compression failed for any reason.\n\n    <Side Effects>\n      'self._orig_file' is used to store the original data of 'temporary_file'.\n\n    <Return>\n      None.\n    \"\"\"\n\n    # Does 'compression' have the correct format?\n    # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n    securesystemslib.formats.NAME_SCHEMA.check_match(compression)\n\n    if self._orig_file is not None:\n      raise securesystemslib.exceptions.Error('Can only set compression on a'\n          ' TempFile once.')\n\n    if compression != 'gzip':\n      raise securesystemslib.exceptions.Error('Only gzip compression is'\n          ' supported.')\n\n    self.seek(0)\n    self._compression = compression\n    self._orig_file = self.temporary_file\n\n    try:\n      gzip_file_object = gzip.GzipFile(fileobj=self.temporary_file, mode='rb')\n      uncompressed_content = gzip_file_object.read()\n      self.temporary_file = tempfile.NamedTemporaryFile()\n      self.temporary_file.write(uncompressed_content)\n      self.flush()\n\n    except Exception as exception:\n      raise securesystemslib.exceptions.DecompressionError(exception)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close_temp_file(self):\n\n    self.temporary_file.close()\n    # If compression has been set, we need to explicitly close the original\n    # file object.\n    if self._orig_file is not None:\n      self._orig_file.close()", "response": "Closes the temporary file and the original file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef matches(self, object):\n\n    try:\n      self.check_match(object)\n    except securesystemslib.exceptions.FormatError:\n      return False\n    else:\n      return True", "response": "Returns True if object matches this schema False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_event(self, *etypes, timeout=None):\n        self._validate_etypes(*etypes)\n        start = time.time()\n        e = self._eventq.get(timeout=timeout)\n\n        if isinstance(e, Exception):\n            raise e\n\n        self._stats['events_recieved'] += 1\n        if etypes and e.type not in etypes:\n            if timeout:\n                timeout -= time.time() - start\n            log.debug('ignoring filtered event: {}'.format(e.json))\n            self._stats['events_dropped'] += 1\n            return self.get_event(*etypes, timeout=timeout)\n\n        return e", "response": "Get a single event from the queue or block until one event is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a generator yielding Slack event objects for the specified types.", "response": "def events(self, *etypes, idle_timeout=None):\n        \"\"\"\n        returns a blocking generator yielding Slack event objects\n        params:\n         - etypes(str): If defined, Slack event type(s) not matching\n           the filter will be ignored. See https://api.slack.com/events for\n           a listing of valid event types.\n         - idle_timeout(int): optional maximum amount of time (in seconds)\n           to wait between events before returning\n        \"\"\"\n\n        while self._state != STATE_STOPPED:\n            try:\n                yield self.get_event(*etypes, timeout=idle_timeout)\n            except Queue.Empty:\n                log.info('idle timeout reached for events()')\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_msg(self, text, channel, confirm=True):\n\n        self._send_id += 1\n        msg = SlackMsg(self._send_id, channel.id, text)\n        self.ws.send(msg.json)\n        self._stats['messages_sent'] += 1\n\n        if confirm:\n            # Wait for confirmation our message was received\n            for e in self.events():\n                if e.get('reply_to') == self._send_id:\n                    msg.sent = True\n                    msg.ts = e.ts\n                    return msg\n        else:\n            return msg", "response": "Send a message to a channel or group via Slack RTM socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextends event object with User and Channel objects", "response": "def _process_event(self, event):\n        \"\"\" Extend event object with User and Channel objects \"\"\"\n        if event.get('user'):\n            event.user = self.lookup_user(event.get('user'))\n\n        if event.get('channel'):\n            event.channel = self.lookup_channel(event.get('channel'))\n\n        if self.user.id in event.mentions:\n            event.mentions_me = True\n\n        event.mentions = [ self.lookup_user(uid) for uid in event.mentions ]\n\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert(input, output=None, options={}):\n\n    if 'input_format' not in options and 'output_format' not in options:\n        raise ValueError(\"no input_format and output_format specified!\")\n\n    input_format = options.get('input_format', 'yaml')\n    output_format = options.get('output_format', 'yaml')\n\n    parser = Parser.get_concrete_class(input_format)(**options)\n    writer = Writer.get_concrete_class(output_format)(**options)\n\n    if not output and not writer.single_file_output:\n        raise ValueError(\"this output_format requires specifying 'output' argument\")\n\n    # if no output was specified create proxy output to which writer can insert data\n    _output = output\n    if not _output:\n        _output = StringIO.StringIO()\n\n    writer.write(parser.parse(input), _output)\n\n    # if no output was specified return output\n    if not output:\n        return _output.getvalue()", "response": "Converts a file from one format to another."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_packed_data(self, data_out, table):\n        headers = []\n        data = []\n        qualifiers_marks = []\n        qualifiers = {}\n\n        self._extract_independent_variables(table, headers, data, qualifiers_marks)\n\n        for dependent_variable in table.dependent_variables:\n            self._parse_dependent_variable(dependent_variable, headers, qualifiers, qualifiers_marks, data)\n\n        self._write_metadata(data_out, table)\n        self._write_csv_data(data_out, qualifiers, qualifiers_marks, headers, data)", "response": "This method is used to write the unpacked data to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new object that is a digest of the given algorithm and hash library.", "response": "def digest(algorithm=DEFAULT_HASH_ALGORITHM, hash_library=DEFAULT_HASH_LIBRARY):\n  \"\"\"\n  <Purpose>\n    Provide the caller with the ability to create digest objects without having\n    to worry about crypto library availability or which library to use.  The\n    caller also has the option of specifying which hash algorithm and/or\n    library to use.\n\n    # Creation of a digest object using defaults or by specifying hash\n    # algorithm and library.\n    digest_object = securesystemslib.hash.digest()\n    digest_object = securesystemslib.hash.digest('sha384')\n    digest_object = securesystemslib.hash.digest('sha256', 'hashlib')\n\n    # The expected interface for digest objects.\n    digest_object.digest_size\n    digest_object.hexdigest()\n    digest_object.update('data')\n    digest_object.digest()\n\n    # Added hash routines by this module.\n    digest_object = securesystemslib.hash.digest_fileobject(file_object)\n    digest_object = securesystemslib.hash.digest_filename(filename)\n\n  <Arguments>\n    algorithm:\n      The hash algorithm (e.g., 'md5', 'sha1', 'sha256').\n\n    hash_library:\n      The crypto library to use for the given hash algorithm (e.g., 'hashlib').\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if the arguments are\n    improperly formatted.\n\n    securesystemslib.exceptions.UnsupportedAlgorithmError, if an unsupported\n    hashing algorithm is specified, or digest could not be generated with given\n    the algorithm.\n\n    securesystemslib.exceptions.UnsupportedLibraryError, if an unsupported\n    library was requested via 'hash_library'.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    Digest object (e.g., hashlib.new(algorithm)).\n  \"\"\"\n\n  # Are the arguments properly formatted?  If not, raise\n  # 'securesystemslib.exceptions.FormatError'.\n  securesystemslib.formats.NAME_SCHEMA.check_match(algorithm)\n  securesystemslib.formats.NAME_SCHEMA.check_match(hash_library)\n\n  # Was a hashlib digest object requested and is it supported?\n  # If so, return the digest object.\n  if hash_library == 'hashlib' and hash_library in SUPPORTED_LIBRARIES:\n    try:\n      return hashlib.new(algorithm)\n\n    except ValueError:\n      raise securesystemslib.exceptions.UnsupportedAlgorithmError(algorithm)\n\n  # Was a pyca_crypto digest object requested and is it supported?\n  elif hash_library == 'pyca_crypto' and hash_library in SUPPORTED_LIBRARIES: #pragma: no cover\n    # TODO: Add support for pyca/cryptography's hashing routines.\n    pass\n\n  # The requested hash library is not supported.\n  else:\n    raise securesystemslib.exceptions.UnsupportedLibraryError('Unsupported'\n        ' library requested.  Supported hash'\n        ' libraries: ' + repr(SUPPORTED_LIBRARIES))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef digest_fileobject(file_object, algorithm=DEFAULT_HASH_ALGORITHM,\n    hash_library=DEFAULT_HASH_LIBRARY, normalize_line_endings=False):\n  \"\"\"\n  <Purpose>\n    Generate a digest object given a file object.  The new digest object\n    is updated with the contents of 'file_object' prior to returning the\n    object to the caller.\n\n  <Arguments>\n    file_object:\n      File object whose contents will be used as the data\n      to update the hash of a digest object to be returned.\n\n    algorithm:\n      The hash algorithm (e.g., 'md5', 'sha1', 'sha256').\n\n    hash_library:\n      The library providing the hash algorithms (e.g., 'hashlib').\n\n    normalize_line_endings: (default False)\n      Whether or not to normalize line endings for cross-platform support.\n      Note that this results in ambiguous hashes (e.g. 'abc\\n' and 'abc\\r\\n'\n      will produce the same hash), so be careful to only apply this to text\n      files (not binary), when that equivalence is desirable and cannot result\n      in easily-maliciously-corrupted files producing the same hash as a valid\n      file.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if the arguments are\n    improperly formatted.\n\n    securesystemslib.exceptions.UnsupportedAlgorithmError, if an unsupported\n    hashing algorithm was specified via 'algorithm'.\n\n    securesystemslib.exceptions.UnsupportedLibraryError, if an unsupported\n    crypto library was specified via 'hash_library'.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    Digest object (e.g., hashlib.new(algorithm)).\n  \"\"\"\n\n  # Are the arguments properly formatted?  If not, raise\n  # 'securesystemslib.exceptions.FormatError'.\n  securesystemslib.formats.NAME_SCHEMA.check_match(algorithm)\n  securesystemslib.formats.NAME_SCHEMA.check_match(hash_library)\n\n  # Digest object returned whose hash will be updated using 'file_object'.\n  # digest() raises:\n  # securesystemslib.exceptions.UnsupportedAlgorithmError\n  # securesystemslib.exceptions.UnsupportedLibraryError\n  digest_object = digest(algorithm, hash_library)\n\n  # Defensively seek to beginning, as there's no case where we don't\n  # intend to start from the beginning of the file.\n  file_object.seek(0)\n\n  # Read the contents of the file object in at most 4096-byte chunks.\n  # Update the hash with the data read from each chunk and return after\n  # the entire file is processed.\n  while True:\n    data = file_object.read(DEFAULT_CHUNK_SIZE)\n    if not data:\n      break\n\n    if normalize_line_endings:\n      while data[-1:] == b'\\r':\n        c = file_object.read(1)\n        if not c:\n          break\n\n        data += c\n\n      data = (\n          data\n          # First Windows\n          .replace(b'\\r\\n', b'\\n')\n          # Then Mac\n          .replace(b'\\r', b'\\n')\n      )\n\n    if not isinstance(data, six.binary_type):\n      digest_object.update(data.encode('utf-8'))\n\n    else:\n      digest_object.update(data)\n\n  return digest_object", "response": "Returns a digest object given a file object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a digest object for the given filename.", "response": "def digest_filename(filename, algorithm=DEFAULT_HASH_ALGORITHM,\n    hash_library=DEFAULT_HASH_LIBRARY, normalize_line_endings=False):\n  \"\"\"\n  <Purpose>\n    Generate a digest object, update its hash using a file object\n    specified by filename, and then return it to the caller.\n\n  <Arguments>\n    filename:\n      The filename belonging to the file object to be used.\n\n    algorithm:\n      The hash algorithm (e.g., 'md5', 'sha1', 'sha256').\n\n    hash_library:\n      The library providing the hash algorithms (e.g., 'hashlib').\n\n    normalize_line_endings:\n      Whether or not to normalize line endings for cross-platform support.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if the arguments are\n    improperly formatted.\n\n    securesystemslib.exceptions.UnsupportedAlgorithmError, if the given\n    'algorithm' is unsupported.\n\n    securesystemslib.exceptions.UnsupportedLibraryError, if the given\n    'hash_library' is unsupported.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    Digest object (e.g., hashlib.new(algorithm)).\n  \"\"\"\n  # Are the arguments properly formatted?  If not, raise\n  # 'securesystemslib.exceptions.FormatError'.\n  securesystemslib.formats.RELPATH_SCHEMA.check_match(filename)\n  securesystemslib.formats.NAME_SCHEMA.check_match(algorithm)\n  securesystemslib.formats.NAME_SCHEMA.check_match(hash_library)\n\n  digest_object = None\n\n  # Open 'filename' in read+binary mode.\n  with open(filename, 'rb') as file_object:\n    # Create digest_object and update its hash data from file_object.\n    # digest_fileobject() raises:\n    # securesystemslib.exceptions.UnsupportedAlgorithmError\n    # securesystemslib.exceptions.UnsupportedLibraryError\n    digest_object = digest_fileobject(\n        file_object, algorithm, hash_library, normalize_line_endings)\n\n  return digest_object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the antlr token stream.", "response": "def get_token_stream(source: str) -> CommonTokenStream:\n    \"\"\" Get the antlr token stream.\n    \"\"\"\n    lexer = LuaLexer(InputStream(source))\n    stream = CommonTokenStream(lexer)\n    return stream"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Evolution Stone object containing the details about the the evolution stone.", "response": "def get_evolution_stone(self, slug):\n        \"\"\"\n        Returns a Evolution Stone object containing the details about the\n        evolution stone.\n        \"\"\"\n        endpoint = '/evolution-stone/' + slug\n        return self.make_request(self.BASE_URL + endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Pokemon League object containing the details about the specified league.", "response": "def get_league(self, slug):\n        \"\"\"\n        Returns a Pokemon League object containing the details about the\n        league.\n        \"\"\"\n        endpoint = '/league/' + slug\n        return self.make_request(self.BASE_URL + endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_pokemon_by_name(self, name):\n        endpoint = '/pokemon/' + str(name)\n        return self.make_request(self.BASE_URL + endpoint)", "response": "Returns an array of Pokemon objects containing all the forms of the Pokemon specified the name of the Pokemon."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pokemon_by_number(self, number):\n        endpoint = '/pokemon/' + str(number)\n        return self.make_request(self.BASE_URL + endpoint)", "response": "Returns an array of Pokemon objects containing all the forms of the Pokemon specified the Pokedex number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_rsa_public_and_private(bits=_DEFAULT_RSA_KEY_BITS):\n\n  # Does 'bits' have the correct format?\n  # This check will ensure 'bits' conforms to\n  # 'securesystemslib.formats.RSAKEYBITS_SCHEMA'.  'bits' must be an integer\n  # object, with a minimum value of 2048.  Raise\n  # 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.RSAKEYBITS_SCHEMA.check_match(bits)\n\n  # Generate the public and private RSA keys.  The pyca/cryptography 'rsa'\n  # module performs the actual key generation.  The 'bits' argument is used,\n  # and a 2048-bit minimum is enforced by\n  # securesystemslib.formats.RSAKEYBITS_SCHEMA.check_match().\n  private_key = rsa.generate_private_key(public_exponent=65537, key_size=bits,\n      backend=default_backend())\n\n  # Extract the public & private halves of the RSA key and generate their\n  # PEM-formatted representations.  Return the key pair as a (public, private)\n  # tuple, where each RSA is a string in PEM format.\n  private_pem = private_key.private_bytes(encoding=serialization.Encoding.PEM,\n      format=serialization.PrivateFormat.TraditionalOpenSSL,\n      encryption_algorithm=serialization.NoEncryption())\n\n  # Need to generate the public pem from the private key before serialization\n  # to PEM.\n  public_key = private_key.public_key()\n  public_pem = public_key.public_bytes(encoding=serialization.Encoding.PEM,\n      format=serialization.PublicFormat.SubjectPublicKeyInfo)\n\n  return public_pem.decode('utf-8'), private_pem.decode('utf-8')", "response": "Generate public and private RSA keys in PEM format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a signature of a data string.", "response": "def create_rsa_signature(private_key, data, scheme='rsassa-pss-sha256'):\n  \"\"\"\n  <Purpose>\n    Generate a 'scheme' signature.  The signature, and the signature scheme\n    used, is returned as a (signature, scheme) tuple.\n\n    The signing process will use 'private_key' to generate the signature of\n    'data'.\n\n    RFC3447 - RSASSA-PSS\n    http://www.ietf.org/rfc/rfc3447.txt\n\n    >>> public, private = generate_rsa_public_and_private(2048)\n    >>> data = 'The quick brown fox jumps over the lazy dog'.encode('utf-8')\n    >>> scheme = 'rsassa-pss-sha256'\n    >>> signature, scheme = create_rsa_signature(private, data, scheme)\n    >>> securesystemslib.formats.NAME_SCHEMA.matches(scheme)\n    True\n    >>> scheme == 'rsassa-pss-sha256'\n    True\n    >>> securesystemslib.formats.PYCACRYPTOSIGNATURE_SCHEMA.matches(signature)\n    True\n\n  <Arguments>\n    private_key:\n      The private RSA key, a string in PEM format.\n\n    data:\n      Data (string) used by create_rsa_signature() to generate the signature.\n\n    scheme:\n      The signature scheme used to generate the signature.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'private_key' is improperly\n    formatted.\n\n    ValueError, if 'private_key' is unset.\n\n    securesystemslib.exceptions.CryptoError, if the signature cannot be\n    generated.\n\n  <Side Effects>\n    pyca/cryptography's 'RSAPrivateKey.signer()' called to generate the\n    signature.\n\n  <Returns>\n    A (signature, scheme) tuple, where the signature is a string and the scheme\n    is one of the supported RSA signature schemes. For example:\n    'rsassa-pss-sha256'.\n  \"\"\"\n\n  # Does the arguments have the correct format?\n  # If not, raise 'securesystemslib.exceptions.FormatError' if any of the\n  # checks fail.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(private_key)\n  securesystemslib.formats.DATA_SCHEMA.check_match(data)\n  securesystemslib.formats.RSA_SCHEME_SCHEMA.check_match(scheme)\n\n  # Signing 'data' requires a private key.  'rsassa-pss-sha256' is the only\n  # currently supported signature scheme.\n  signature = None\n\n  # Verify the signature, but only if the private key has been set.  The\n  # private key is a NULL string if unset.  Although it may be clearer to\n  # explicitly check that 'private_key' is not '', we can/should check for a\n  # value and not compare identities with the 'is' keyword.  Up to this point\n  # 'private_key' has variable size and can be an empty string.\n  if len(private_key):\n\n    # An if-clause isn't strictly needed here, since 'rsasssa-pss-sha256' is\n    # the only currently supported RSA scheme.  Nevertheless, include the\n    # conditional statement to accomodate future schemes that might be added.\n    if scheme == 'rsassa-pss-sha256':\n      # Generate an RSSA-PSS signature.  Raise\n      # 'securesystemslib.exceptions.CryptoError' for any of the expected\n      # exceptions raised by pyca/cryptography.\n      try:\n        # 'private_key' (in PEM format) must first be converted to a\n        # pyca/cryptography private key object before a signature can be\n        # generated.\n        private_key_object = load_pem_private_key(private_key.encode('utf-8'),\n            password=None, backend=default_backend())\n\n        signature = private_key_object.sign(\n            data, padding.PSS(mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=hashes.SHA256().digest_size), hashes.SHA256())\n\n      # If the PEM data could not be decrypted, or if its structure could not\n      # be decoded successfully.\n      except ValueError:\n        raise securesystemslib.exceptions.CryptoError('The private key'\n          ' (in PEM format) could not be deserialized.')\n\n      # 'TypeError' is raised if a password was given and the private key was\n      # not encrypted, or if the key was encrypted but no password was\n      # supplied.  Note: A passphrase or password is not used when generating\n      # 'private_key', since it should not be encrypted.\n      except TypeError:\n        raise securesystemslib.exceptions.CryptoError('The private key was'\n          ' unexpectedly encrypted.')\n\n      # 'cryptography.exceptions.UnsupportedAlgorithm' is raised if the\n      # serialized key is of a type that is not supported by the backend, or if\n      # the key is encrypted with a symmetric cipher that is not supported by\n      # the backend.\n      except cryptography.exceptions.UnsupportedAlgorithm: #pragma: no cover\n        raise securesystemslib.exceptions.CryptoError('The private key is'\n          ' encrypted with an unsupported algorithm.')\n\n    # The RSA_SCHEME_SCHEMA.check_match() above should have validated 'scheme'.\n    # This is a defensive check check..\n    else: #pragma: no cover\n      raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n        ' signature scheme is specified: ' + repr(scheme))\n\n  else:\n    raise ValueError('The required private key is unset.')\n\n  return signature, scheme"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_rsa_signature(signature, signature_scheme, public_key, data):\n\n  # Does 'public_key' have the correct format?\n  # This check will ensure 'public_key' conforms to\n  # 'securesystemslib.formats.PEMRSA_SCHEMA'.  Raise\n  # 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(public_key)\n\n  # Does 'signature_scheme' have the correct format?\n  securesystemslib.formats.RSA_SCHEME_SCHEMA.check_match(signature_scheme)\n\n  # Does 'signature' have the correct format?\n  securesystemslib.formats.PYCACRYPTOSIGNATURE_SCHEMA.check_match(signature)\n\n  # What about 'data'?\n  securesystemslib.formats.DATA_SCHEMA.check_match(data)\n\n  # Verify whether the private key of 'public_key' produced 'signature'.\n  # Before returning the 'valid_signature' Boolean result, ensure 'RSASSA-PSS'\n  # was used as the signature scheme.\n  valid_signature = False\n\n  # Verify the RSASSA-PSS signature with pyca/cryptography.\n  try:\n    public_key_object = serialization.load_pem_public_key(public_key.encode('utf-8'),\n        backend=default_backend())\n\n    # verify() raises 'cryptography.exceptions.InvalidSignature' if the\n    # signature is invalid. 'salt_length' is set to the digest size of the\n    # hashing algorithm.\n    try:\n      public_key_object.verify(signature, data,\n          padding.PSS(mgf=padding.MGF1(hashes.SHA256()),\n          salt_length=hashes.SHA256().digest_size),\n          hashes.SHA256())\n      return True\n\n    except cryptography.exceptions.InvalidSignature:\n      return False\n\n  # Raised by load_pem_public_key().\n  except (ValueError, cryptography.exceptions.UnsupportedAlgorithm) as e:\n    raise securesystemslib.exceptions.CryptoError('The PEM could not be'\n      ' decoded successfully, or contained an unsupported key type: ' + str(e))", "response": "Verify the RSA signature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_rsa_encrypted_pem(private_key, passphrase):\n\n  # This check will ensure 'private_key' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(private_key)\n\n  # Does 'passphrase' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(passphrase)\n\n  # 'private_key' may still be a NULL string after the\n  # 'securesystemslib.formats.PEMRSA_SCHEMA' so we need an additional check\n  if len(private_key):\n    try:\n      private_key = load_pem_private_key(private_key.encode('utf-8'),\n          password=None, backend=default_backend())\n    except ValueError:\n      raise securesystemslib.exceptions.CryptoError('The private key'\n          ' (in PEM format) could not be deserialized.')\n\n  else:\n    raise ValueError('The required private key is unset.')\n\n  encrypted_pem = private_key.private_bytes(\n      encoding=serialization.Encoding.PEM,\n      format=serialization.PrivateFormat.TraditionalOpenSSL,\n      encryption_algorithm=serialization.BestAvailableEncryption(\n      passphrase.encode('utf-8')))\n\n  return encrypted_pem.decode()", "response": "Creates a private part of RSA key encrypted using the passphrase."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_rsa_public_and_private_from_pem(pem, passphrase=None):\n\n  # Does 'encryped_pem' have the correct format?\n  # This check will ensure 'pem' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(pem)\n\n  # If passed, does 'passphrase' have the correct format?\n  if passphrase is not None:\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(passphrase)\n    passphrase = passphrase.encode('utf-8')\n\n  # Generate a pyca/cryptography key object from 'pem'.  The generated\n  # pyca/cryptography key contains the required export methods needed to\n  # generate the PEM-formatted representations of the public and private RSA\n  # key.\n  try:\n    private_key = load_pem_private_key(pem.encode('utf-8'),\n        passphrase, backend=default_backend())\n\n  # pyca/cryptography's expected exceptions for 'load_pem_private_key()':\n  # ValueError: If the PEM data could not be decrypted.\n  # (possibly because the passphrase is wrong).\"\n  # TypeError: If a password was given and the private key was not encrypted.\n  # Or if the key was encrypted but no password was supplied.\n  # UnsupportedAlgorithm: If the private key (or if the key is encrypted with\n  # an unsupported symmetric cipher) is not supported by the backend.\n  except (ValueError, TypeError, cryptography.exceptions.UnsupportedAlgorithm) as e:\n    # Raise 'securesystemslib.exceptions.CryptoError' and pyca/cryptography's\n    # exception message.  Avoid propogating pyca/cryptography's exception trace\n    # to avoid revealing sensitive error.\n    raise securesystemslib.exceptions.CryptoError('RSA (public, private) tuple'\n      ' cannot be generated from the encrypted PEM string: ' + str(e))\n\n  # Export the public and private halves of the pyca/cryptography RSA key\n  # object.  The (public, private) tuple returned contains the public and\n  # private RSA keys in PEM format, as strings.\n  # Extract the public & private halves of the RSA key and generate their\n  # PEM-formatted representations.  Return the key pair as a (public, private)\n  # tuple, where each RSA is a string in PEM format.\n  private_pem = private_key.private_bytes(encoding=serialization.Encoding.PEM,\n      format=serialization.PrivateFormat.TraditionalOpenSSL,\n      encryption_algorithm=serialization.NoEncryption())\n\n  # Need to generate the public key from the private one before serializing\n  # to PEM format.\n  public_key = private_key.public_key()\n  public_pem = public_key.public_bytes(encoding=serialization.Encoding.PEM,\n      format=serialization.PublicFormat.SubjectPublicKeyInfo)\n\n  return public_pem.decode(), private_pem.decode()", "response": "This method generates public and private RSA keys from a PEM file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_derived_key(password, salt=None, iterations=None):\n\n  # Use pyca/cryptography's default backend (e.g., openSSL, CommonCrypto, etc.)\n  # The default backend is not fixed and can be changed by pyca/cryptography\n  # over time.\n  backend = default_backend()\n\n  # If 'salt' and 'iterations' are unspecified, a new derived key is generated.\n  # If specified, a deterministic key is derived according to the given\n  # 'salt' and 'iterrations' values.\n  if salt is None:\n    salt = os.urandom(_SALT_SIZE)\n\n  if iterations is None:\n    iterations = _PBKDF2_ITERATIONS\n\n  # Derive an AES key with PBKDF2.  The  'length' is the desired key length of\n  # the derived key.\n  pbkdf_object = PBKDF2HMAC(algorithm=hashes.SHA256(), length=32, salt=salt,\n       iterations=iterations, backend=backend)\n\n  derived_key = pbkdf_object.derive(password.encode('utf-8'))\n\n  return salt, iterations, derived_key", "response": "Generate a derived key from a password."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _encrypt(key_data, derived_key_information):\n\n  # Generate a random Initialization Vector (IV).  Follow the provably secure\n  # encrypt-then-MAC approach, which affords the ability to verify ciphertext\n  # without needing to decrypt it and preventing an attacker from feeding the\n  # block cipher malicious data.  Modes like GCM provide both encryption and\n  # authentication, whereas CTR only provides encryption.\n\n  # Generate a random 128-bit IV.  Random bits of data is needed for salts and\n  # initialization vectors suitable for the encryption algorithms used in\n  # 'pyca_crypto_keys.py'.\n  iv = os.urandom(16)\n\n  # Construct an AES-CTR Cipher object with the given key and a randomly\n  # generated IV.\n  symmetric_key = derived_key_information['derived_key']\n  encryptor = Cipher(algorithms.AES(symmetric_key), modes.CTR(iv),\n      backend=default_backend()).encryptor()\n\n  # Encrypt the plaintext and get the associated ciphertext.\n  # Do we need to check for any exceptions?\n  ciphertext = encryptor.update(key_data.encode('utf-8')) + encryptor.finalize()\n\n  # Generate the hmac of the ciphertext to ensure it has not been modified.\n  # The decryption routine may verify a ciphertext without having to perform\n  # a decryption operation.\n  symmetric_key = derived_key_information['derived_key']\n  salt = derived_key_information['salt']\n  hmac_object = \\\n    cryptography.hazmat.primitives.hmac.HMAC(symmetric_key, hashes.SHA256(),\n        backend=default_backend())\n  hmac_object.update(ciphertext)\n  hmac_value = binascii.hexlify(hmac_object.finalize())\n\n  # Store the number of PBKDF2 iterations used to derive the symmetric key so\n  # that the decryption routine can regenerate the symmetric key successfully.\n  # The PBKDF2 iterations are allowed to vary for the keys loaded and saved.\n  iterations = derived_key_information['iterations']\n\n  # Return the salt, iterations, hmac, initialization vector, and ciphertext\n  # as a single string.  These five values are delimited by\n  # '_ENCRYPTION_DELIMITER' to make extraction easier.  This delimiter is\n  # arbitrarily chosen and should not occur in the hexadecimal representations\n  # of the fields it is separating.\n  return binascii.hexlify(salt).decode() + _ENCRYPTION_DELIMITER + \\\n      str(iterations) + _ENCRYPTION_DELIMITER + \\\n      hmac_value.decode() + _ENCRYPTION_DELIMITER + \\\n      binascii.hexlify(iv).decode() + _ENCRYPTION_DELIMITER + \\\n      binascii.hexlify(ciphertext).decode()", "response": "Encrypt the given key_data using the AES - 256 algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _decrypt(file_contents, password):\n\n  # Extract the salt, iterations, hmac, initialization vector, and ciphertext\n  # from 'file_contents'.  These five values are delimited by\n  # '_ENCRYPTION_DELIMITER'.  This delimiter is arbitrarily chosen and should\n  # not occur in the hexadecimal representations of the fields it is\n  # separating.  Raise 'securesystemslib.exceptions.CryptoError', if\n  # 'file_contents' does not contains the expected data layout.\n  try:\n    salt, iterations, hmac, iv, ciphertext = \\\n      file_contents.split(_ENCRYPTION_DELIMITER)\n\n  except ValueError:\n    raise securesystemslib.exceptions.CryptoError('Invalid encrypted file.')\n\n  # Ensure we have the expected raw data for the delimited cryptographic data.\n  salt = binascii.unhexlify(salt.encode('utf-8'))\n  iterations = int(iterations)\n  iv = binascii.unhexlify(iv.encode('utf-8'))\n  ciphertext = binascii.unhexlify(ciphertext.encode('utf-8'))\n\n  # Generate derived key from 'password'.  The salt and iterations are\n  # specified so that the expected derived key is regenerated correctly.\n  # Discard the old \"salt\" and \"iterations\" values, as we only need the old\n  # derived key.\n  junk_old_salt, junk_old_iterations, symmetric_key = \\\n    _generate_derived_key(password, salt, iterations)\n\n  # Verify the hmac to ensure the ciphertext is valid and has not been altered.\n  # See the encryption routine for why we use the encrypt-then-MAC approach.\n  # The decryption routine may verify a ciphertext without having to perform\n  # a decryption operation.\n  generated_hmac_object = \\\n    cryptography.hazmat.primitives.hmac.HMAC(symmetric_key, hashes.SHA256(),\n        backend=default_backend())\n  generated_hmac_object.update(ciphertext)\n  generated_hmac = binascii.hexlify(generated_hmac_object.finalize())\n\n\n  if not securesystemslib.util.digests_are_equal(generated_hmac.decode(), hmac):\n    raise securesystemslib.exceptions.CryptoError('Decryption failed.')\n\n  # Construct a Cipher object, with the key and iv.\n  decryptor = Cipher(algorithms.AES(symmetric_key), modes.CTR(iv),\n      backend=default_backend()).decryptor()\n\n  # Decryption gets us the authenticated plaintext.\n  plaintext = decryptor.update(ciphertext) + decryptor.finalize()\n\n  return plaintext", "response": "Decrypt the file_contents using the password and return the ciphertext."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_environment(home_dir, site_packages=True, clear=False,\n                       unzip_setuptools=False, use_distribute=False):\n    \"\"\"\n    Creates a new environment in ``home_dir``.\n\n    If ``site_packages`` is true (the default) then the global\n    ``site-packages/`` directory will be on the path.\n\n    If ``clear`` is true (default False) then the environment will\n    first be cleared.\n    \"\"\"\n    home_dir, lib_dir, inc_dir, bin_dir = path_locations(home_dir)\n\n    py_executable = os.path.abspath(install_python(\n        home_dir, lib_dir, inc_dir, bin_dir,\n        site_packages=site_packages, clear=clear))\n\n    install_distutils(lib_dir, home_dir)\n\n    if use_distribute or os.environ.get('VIRTUALENV_USE_DISTRIBUTE'):\n        install_distribute(py_executable, unzip=unzip_setuptools)\n    else:\n        install_setuptools(py_executable, unzip=unzip_setuptools)\n\n    install_pip(py_executable)\n\n    install_activate(home_dir, bin_dir)", "response": "Creates a new environment in home_dir."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef path_locations(home_dir):\n    # XXX: We'd use distutils.sysconfig.get_python_inc/lib but its\n    # prefix arg is broken: http://bugs.python.org/issue3386\n    if sys.platform == 'win32':\n        # Windows has lots of problems with executables with spaces in\n        # the name; this function will remove them (using the ~1\n        # format):\n        mkdir(home_dir)\n        if ' ' in home_dir:\n            try:\n                import win32api\n            except ImportError:\n                print 'Error: the path \"%s\" has a space in it' % home_dir\n                print 'To handle these kinds of paths, the win32api module must be installed:'\n                print '  http://sourceforge.net/projects/pywin32/'\n                sys.exit(3)\n            home_dir = win32api.GetShortPathName(home_dir)\n        lib_dir = join(home_dir, 'Lib')\n        inc_dir = join(home_dir, 'Include')\n        bin_dir = join(home_dir, 'Scripts')\n    elif is_jython:\n        lib_dir = join(home_dir, 'Lib')\n        inc_dir = join(home_dir, 'Include')\n        bin_dir = join(home_dir, 'bin')\n    else:\n        lib_dir = join(home_dir, 'lib', py_version)\n        inc_dir = join(home_dir, 'include', py_version)\n        bin_dir = join(home_dir, 'bin')\n    return home_dir, lib_dir, inc_dir, bin_dir", "response": "Return the path locations for the environment"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninstall the python modules in the specified bin directory.", "response": "def install_python(home_dir, lib_dir, inc_dir, bin_dir, site_packages, clear):\n    \"\"\"Install just the base environment, no distutils patches etc\"\"\"\n    if sys.executable.startswith(bin_dir):\n        print 'Please use the *system* python to run this script'\n        return\n\n    if clear:\n        rmtree(lib_dir)\n        ## FIXME: why not delete it?\n        ## Maybe it should delete everything with #!/path/to/venv/python in it\n        logger.notify('Not deleting %s', bin_dir)\n\n    if hasattr(sys, 'real_prefix'):\n        logger.notify('Using real prefix %r' % sys.real_prefix)\n        prefix = sys.real_prefix\n    else:\n        prefix = sys.prefix\n    mkdir(lib_dir)\n    fix_lib64(lib_dir)\n    stdlib_dirs = [os.path.dirname(os.__file__)]\n    if sys.platform == 'win32':\n        stdlib_dirs.append(join(os.path.dirname(stdlib_dirs[0]), 'DLLs'))\n    elif sys.platform == 'darwin':\n        stdlib_dirs.append(join(stdlib_dirs[0], 'site-packages'))\n    for stdlib_dir in stdlib_dirs:\n        if not os.path.isdir(stdlib_dir):\n            continue\n        if hasattr(os, 'symlink'):\n            logger.info('Symlinking Python bootstrap modules')\n        else:\n            logger.info('Copying Python bootstrap modules')\n        logger.indent += 2\n        try:\n            for fn in os.listdir(stdlib_dir):\n                if fn != 'site-packages' and os.path.splitext(fn)[0] in REQUIRED_MODULES:\n                    copyfile(join(stdlib_dir, fn), join(lib_dir, fn))\n        finally:\n            logger.indent -= 2\n    mkdir(join(lib_dir, 'site-packages'))\n    writefile(join(lib_dir, 'site.py'), SITE_PY)\n    writefile(join(lib_dir, 'orig-prefix.txt'), prefix)\n    site_packages_filename = join(lib_dir, 'no-global-site-packages.txt')\n    if not site_packages:\n        writefile(site_packages_filename, '')\n    else:\n        if os.path.exists(site_packages_filename):\n            logger.info('Deleting %s' % site_packages_filename)\n            os.unlink(site_packages_filename)\n\n    stdinc_dir = join(prefix, 'include', py_version)\n    if os.path.exists(stdinc_dir):\n        copyfile(stdinc_dir, inc_dir)\n    else:\n        logger.debug('No include dir %s' % stdinc_dir)\n\n    if sys.exec_prefix != prefix:\n        if sys.platform == 'win32':\n            exec_dir = join(sys.exec_prefix, 'lib')\n        elif is_jython:\n            exec_dir = join(sys.exec_prefix, 'Lib')\n        else:\n            exec_dir = join(sys.exec_prefix, 'lib', py_version)\n        for fn in os.listdir(exec_dir):\n            copyfile(join(exec_dir, fn), join(lib_dir, fn))\n\n    if is_jython:\n        # Jython has either jython-dev.jar and javalib/ dir, or just\n        # jython.jar\n        for name in 'jython-dev.jar', 'javalib', 'jython.jar':\n            src = join(prefix, name)\n            if os.path.exists(src):\n                copyfile(src, join(home_dir, name))\n        # XXX: registry should always exist after Jython 2.5rc1\n        src = join(prefix, 'registry')\n        if os.path.exists(src):\n            copyfile(src, join(home_dir, 'registry'), symlink=False)\n        copyfile(join(prefix, 'cachedir'), join(home_dir, 'cachedir'),\n                 symlink=False)\n\n    mkdir(bin_dir)\n    py_executable = join(bin_dir, os.path.basename(sys.executable))\n    if 'Python.framework' in prefix:\n        if re.search(r'/Python(?:-32|-64)*$', py_executable):\n            # The name of the python executable is not quite what\n            # we want, rename it.\n            py_executable = os.path.join(\n                    os.path.dirname(py_executable), 'python')\n\n    logger.notify('New %s executable in %s', expected_exe, py_executable)\n    if sys.executable != py_executable:\n        ## FIXME: could I just hard link?\n        executable = sys.executable\n        if sys.platform == 'cygwin' and os.path.exists(executable + '.exe'):\n            # Cygwin misreports sys.executable sometimes\n            executable += '.exe'\n            py_executable += '.exe'\n            logger.info('Executable actually exists in %s' % executable)\n        shutil.copyfile(executable, py_executable)\n        make_exe(py_executable)\n        if sys.platform == 'win32' or sys.platform == 'cygwin':\n            pythonw = os.path.join(os.path.dirname(sys.executable), 'pythonw.exe')\n            if os.path.exists(pythonw):\n                logger.info('Also created pythonw.exe')\n                shutil.copyfile(pythonw, os.path.join(os.path.dirname(py_executable), 'pythonw.exe'))\n\n    if os.path.splitext(os.path.basename(py_executable))[0] != expected_exe:\n        secondary_exe = os.path.join(os.path.dirname(py_executable),\n                                     expected_exe)\n        py_executable_ext = os.path.splitext(py_executable)[1]\n        if py_executable_ext == '.exe':\n            # python2.4 gives an extension of '.4' :P\n            secondary_exe += py_executable_ext\n        if os.path.exists(secondary_exe):\n            logger.warn('Not overwriting existing %s script %s (you must use %s)'\n                        % (expected_exe, secondary_exe, py_executable))\n        else:\n            logger.notify('Also creating executable in %s' % secondary_exe)\n            shutil.copyfile(sys.executable, secondary_exe)\n            make_exe(secondary_exe)\n\n    if 'Python.framework' in prefix:\n        logger.debug('MacOSX Python framework detected')\n\n        # Make sure we use the the embedded interpreter inside\n        # the framework, even if sys.executable points to\n        # the stub executable in ${sys.prefix}/bin\n        # See http://groups.google.com/group/python-virtualenv/\n        #                              browse_thread/thread/17cab2f85da75951\n        shutil.copy(\n                os.path.join(\n                    prefix, 'Resources/Python.app/Contents/MacOS/%s' % os.path.basename(sys.executable)),\n                py_executable)\n\n        # Copy the framework's dylib into the virtual\n        # environment\n        virtual_lib = os.path.join(home_dir, '.Python')\n\n        if os.path.exists(virtual_lib):\n            os.unlink(virtual_lib)\n        copyfile(\n            os.path.join(prefix, 'Python'),\n            virtual_lib)\n\n        # And then change the install_name of the copied python executable\n        try:\n            call_subprocess(\n                [\"install_name_tool\", \"-change\",\n                 os.path.join(prefix, 'Python'),\n                 '@executable_path/../.Python',\n                 py_executable])\n        except:\n            logger.fatal(\n                \"Could not call install_name_tool -- you must have Apple's development tools installed\")\n            raise\n\n        # Some tools depend on pythonX.Y being present\n        py_executable_version = '%s.%s' % (\n            sys.version_info[0], sys.version_info[1])\n        if not py_executable.endswith(py_executable_version):\n            # symlinking pythonX.Y > python\n            pth = py_executable + '%s.%s' % (\n                    sys.version_info[0], sys.version_info[1])\n            if os.path.exists(pth):\n                os.unlink(pth)\n            os.symlink('python', pth)\n        else:\n            # reverse symlinking python -> pythonX.Y (with --python)\n            pth = join(bin_dir, 'python')\n            if os.path.exists(pth):\n                os.unlink(pth)\n            os.symlink(os.path.basename(py_executable), pth)\n\n    if sys.platform == 'win32' and ' ' in py_executable:\n        # There's a bug with subprocess on Windows when using a first\n        # argument that has a space in it.  Instead we have to quote\n        # the value:\n        py_executable = '\"%s\"' % py_executable\n    cmd = [py_executable, '-c', 'import sys; print sys.prefix']\n    logger.info('Testing executable with %s %s \"%s\"' % tuple(cmd))\n    proc = subprocess.Popen(cmd,\n                            stdout=subprocess.PIPE)\n    proc_stdout, proc_stderr = proc.communicate()\n    proc_stdout = os.path.normcase(os.path.abspath(proc_stdout.strip()))\n    if proc_stdout != os.path.normcase(os.path.abspath(home_dir)):\n        logger.fatal(\n            'ERROR: The executable %s is not functioning' % py_executable)\n        logger.fatal(\n            'ERROR: It thinks sys.prefix is %r (should be %r)'\n            % (proc_stdout, os.path.normcase(os.path.abspath(home_dir))))\n        logger.fatal(\n            'ERROR: virtualenv is not compatible with this system or executable')\n        if sys.platform == 'win32':\n            logger.fatal(\n                'Note: some Windows users have reported this error when they installed Python for \"Only this user\".  The problem may be resolvable if you install Python \"For all users\".  (See https://bugs.launchpad.net/virtualenv/+bug/352844)')\n        sys.exit(100)\n    else:\n        logger.info('Got sys.prefix result: %r' % proc_stdout)\n\n    pydistutils = os.path.expanduser('~/.pydistutils.cfg')\n    if os.path.exists(pydistutils):\n        logger.notify('Please make sure you remove any previous custom paths from '\n                      'your %s file.' % pydistutils)\n    ## FIXME: really this should be calculated earlier\n    return py_executable"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fix_lib64(lib_dir):\n    if [p for p in distutils.sysconfig.get_config_vars().values()\n        if isinstance(p, basestring) and 'lib64' in p]:\n        logger.debug('This system uses lib64; symlinking lib64 to lib')\n        assert os.path.basename(lib_dir) == 'python%s' % sys.version[:3], (\n            \"Unexpected python lib dir: %r\" % lib_dir)\n        lib_parent = os.path.dirname(lib_dir)\n        assert os.path.basename(lib_parent) == 'lib', (\n            \"Unexpected parent dir: %r\" % lib_parent)\n        copyfile(lib_parent, os.path.join(os.path.dirname(lib_parent), 'lib64'))", "response": "Fixes lib64 symlink in lib64"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_interpreter(exe):\n    if os.path.abspath(exe) != exe:\n        paths = os.environ.get('PATH', '').split(os.pathsep)\n        for path in paths:\n            if os.path.exists(os.path.join(path, exe)):\n                exe = os.path.join(path, exe)\n                break\n    if not os.path.exists(exe):\n        logger.fatal('The executable %s (from --python=%s) does not exist' % (exe, exe))\n        sys.exit(3)\n    return exe", "response": "Resolve the interpreter to a valid path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_environment_relocatable(home_dir):\n    activate_this = os.path.join(home_dir, 'bin', 'activate_this.py')\n    if not os.path.exists(activate_this):\n        logger.fatal(\n            'The environment doesn\\'t have a file %s -- please re-run virtualenv '\n            'on this environment to update it' % activate_this)\n    fixup_scripts(home_dir)\n    fixup_pth_and_egg_link(home_dir)", "response": "Makes the environment relocatable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_rsa_key(bits=_DEFAULT_RSA_KEY_BITS, scheme='rsassa-pss-sha256'):\n\n  # Does 'bits' have the correct format?  This check will ensure 'bits'\n  # conforms to 'securesystemslib.formats.RSAKEYBITS_SCHEMA'.  'bits' must be\n  # an integer object, with a minimum value of 2048.  Raise\n  # 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.RSAKEYBITS_SCHEMA.check_match(bits)\n  securesystemslib.formats.RSA_SCHEME_SCHEMA.check_match(scheme)\n\n  # Begin building the RSA key dictionary.\n  rsakey_dict = {}\n  keytype = 'rsa'\n  public = None\n  private = None\n\n  # Generate the public and private RSA keys.  The pyca/cryptography module is\n  # used to generate the actual key.  Raise 'ValueError' if 'bits' is less than\n  # 1024, although a 2048-bit minimum is enforced by\n  # securesystemslib.formats.RSAKEYBITS_SCHEMA.check_match().\n  public, private = securesystemslib.pyca_crypto_keys.generate_rsa_public_and_private(bits)\n\n  # When loading in PEM keys, extract_pem() is called, which strips any\n  # leading or trailing new line characters. Do the same here before generating\n  # the keyid.\n  public =  extract_pem(public, private_pem=False)\n  private = extract_pem(private, private_pem=True)\n\n  # Generate the keyid of the RSA key.  Note: The private key material is not\n  # included in the generation of the 'keyid' identifier.  Convert any '\\r\\n'\n  # (e.g., Windows) newline characters to '\\n' so that a consistent keyid is\n  # generated.\n  key_value = {'public': public.replace('\\r\\n', '\\n'),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  # Build the 'rsakey_dict' dictionary.  Update 'key_value' with the RSA\n  # private key prior to adding 'key_value' to 'rsakey_dict'.\n  key_value['private'] = private\n\n  rsakey_dict['keytype'] = keytype\n  rsakey_dict['scheme'] = scheme\n  rsakey_dict['keyid'] = keyid\n  rsakey_dict['keyid_hash_algorithms'] = securesystemslib.settings.HASH_ALGORITHMS\n  rsakey_dict['keyval'] = key_value\n\n  return rsakey_dict", "response": "<Purpose>\n    Generate public and private RSA keys, with modulus length 'bits'.  In\n    addition, a keyid identifier for the RSA key is generated.  The object\n    returned conforms to 'securesystemslib.formats.RSAKEY_SCHEMA' and has the\n    form:\n\n    {'keytype': 'rsa',\n     'scheme': 'rsassa-pss-sha256',\n     'keyid': keyid,\n     'keyval': {'public': '-----BEGIN RSA PUBLIC KEY----- ...',\n                'private': '-----BEGIN RSA PRIVATE KEY----- ...'}}\n\n    The public and private keys are strings in PEM format.\n\n    Although the PyCA cryptography library and/or its crypto backend might set\n    a minimum key size, generate() enforces a minimum key size of 2048 bits.\n    If 'bits' is unspecified, a 3072-bit RSA key is generated, which is the key\n    size recommended by securesystemslib.  These key size restrictions are only\n    enforced for keys generated within securesystemslib.  RSA keys with sizes\n    lower than what we recommended may still be imported (e.g., with\n    import_rsakey_from_pem().\n\n    >>> rsa_key = generate_rsa_key(bits=2048)\n    >>> securesystemslib.formats.RSAKEY_SCHEMA.matches(rsa_key)\n    True\n\n    >>> public = rsa_key['keyval']['public']\n    >>> private = rsa_key['keyval']['private']\n    >>> securesystemslib.formats.PEMRSA_SCHEMA.matches(public)\n    True\n    >>> securesystemslib.formats.PEMRSA_SCHEMA.matches(private)\n    True\n\n  <Arguments>\n    bits:\n      The key size, or key length, of the RSA key.  'bits' must be 2048, or\n      greater, and a multiple of 256.\n\n    scheme:\n      The signature scheme used by the key.  It must be one of\n      ['rsassa-pss-sha256'].\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'bits' is improperly or invalid\n    (i.e., not an integer and not at least 2048).\n\n    ValueError, if an exception occurs after calling the RSA key generation\n    routine.  The 'ValueError' exception is raised by the key generation\n    function of the cryptography library called.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    A dictionary containing the RSA keys and other identifying information.\n    Conforms to 'securesystemslib.formats.RSAKEY_SCHEMA'."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_ecdsa_key(scheme='ecdsa-sha2-nistp256'):\n\n  # Does 'scheme' have the correct format?\n  # This check will ensure 'scheme' is properly formatted and is a supported\n  # ECDSA signature scheme.  Raise 'securesystemslib.exceptions.FormatError' if\n  # the check fails.\n  securesystemslib.formats.ECDSA_SCHEME_SCHEMA.check_match(scheme)\n\n  # Begin building the ECDSA key dictionary.\n  ecdsa_key = {}\n  keytype = 'ecdsa-sha2-nistp256'\n  public = None\n  private = None\n\n  # Generate the public and private ECDSA keys with one of the supported\n  # libraries.\n  public, private = \\\n    securesystemslib.ecdsa_keys.generate_public_and_private(scheme)\n\n  # Generate the keyid of the Ed25519 key.  'key_value' corresponds to the\n  # 'keyval' entry of the 'Ed25519KEY_SCHEMA' dictionary.  The private key\n  # information is not included in the generation of the 'keyid' identifier.\n  # Convert any '\\r\\n' (e.g., Windows) newline characters to '\\n' so that a\n  # consistent keyid is generated.\n  key_value = {'public': public.replace('\\r\\n', '\\n'),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  # Build the 'ed25519_key' dictionary.  Update 'key_value' with the Ed25519\n  # private key prior to adding 'key_value' to 'ed25519_key'.\n\n  key_value['private'] = private\n\n  ecdsa_key['keytype'] = keytype\n  ecdsa_key['scheme'] = scheme\n  ecdsa_key['keyid'] = keyid\n  ecdsa_key['keyval'] = key_value\n\n  # Add \"keyid_hash_algorithms\" so that equal ECDSA keys with different keyids\n  # can be associated using supported keyid_hash_algorithms.\n  ecdsa_key['keyid_hash_algorithms'] = \\\n      securesystemslib.settings.HASH_ALGORITHMS\n\n  return ecdsa_key", "response": "Generate public and private ECDSA keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a new ed25519 key.", "response": "def generate_ed25519_key(scheme='ed25519'):\n  \"\"\"\n  <Purpose>\n    Generate public and private ED25519 keys, both of length 32-bytes, although\n    they are hexlified to 64 bytes.  In addition, a keyid identifier generated\n    for the returned ED25519 object.  The object returned conforms to\n    'securesystemslib.formats.ED25519KEY_SCHEMA' and has the form:\n\n    {'keytype': 'ed25519',\n     'scheme': 'ed25519',\n     'keyid': 'f30a0870d026980100c0573bd557394f8c1bbd6...',\n     'keyval': {'public': '9ccf3f02b17f82febf5dd3bab878b767d8408...',\n                'private': 'ab310eae0e229a0eceee3947b6e0205dfab3...'}}\n\n    >>> ed25519_key = generate_ed25519_key()\n    >>> securesystemslib.formats.ED25519KEY_SCHEMA.matches(ed25519_key)\n    True\n    >>> len(ed25519_key['keyval']['public'])\n    64\n    >>> len(ed25519_key['keyval']['private'])\n    64\n\n  <Arguments>\n    scheme:\n      The signature scheme used by the generated Ed25519 key.\n\n  <Exceptions>\n    None.\n\n  <Side Effects>\n    The ED25519 keys are generated by calling either the optimized pure Python\n    implementation of ed25519, or the ed25519 routines provided by 'pynacl'.\n\n  <Returns>\n    A dictionary containing the ED25519 keys and other identifying information.\n    Conforms to 'securesystemslib.formats.ED25519KEY_SCHEMA'.\n  \"\"\"\n\n  # Are the arguments properly formatted?  If not, raise an\n  # 'securesystemslib.exceptions.FormatError' exceptions.\n  securesystemslib.formats.ED25519_SIG_SCHEMA.check_match(scheme)\n\n  # Begin building the Ed25519 key dictionary.\n  ed25519_key = {}\n  keytype = 'ed25519'\n  public = None\n  private = None\n\n  # Generate the public and private Ed25519 key with the 'pynacl' library.\n  # Unlike in the verification of Ed25519 signatures, do not fall back to the\n  # optimized, pure python implementation provided by PyCA.  Ed25519 should\n  # always be generated with a backend like libsodium to prevent side-channel\n  # attacks.\n  public, private = \\\n    securesystemslib.ed25519_keys.generate_public_and_private()\n\n  # Generate the keyid of the Ed25519 key.  'key_value' corresponds to the\n  # 'keyval' entry of the 'Ed25519KEY_SCHEMA' dictionary.  The private key\n  # information is not included in the generation of the 'keyid' identifier.\n  key_value = {'public': binascii.hexlify(public).decode(),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  # Build the 'ed25519_key' dictionary.  Update 'key_value' with the Ed25519\n  # private key prior to adding 'key_value' to 'ed25519_key'.\n  key_value['private'] = binascii.hexlify(private).decode()\n\n  ed25519_key['keytype'] = keytype\n  ed25519_key['scheme'] = scheme\n  ed25519_key['keyid'] = keyid\n  ed25519_key['keyid_hash_algorithms'] = securesystemslib.settings.HASH_ALGORITHMS\n  ed25519_key['keyval'] = key_value\n\n  return ed25519_key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary that contains the keyval formatted as described by the keytype scheme and key_value.", "response": "def format_keyval_to_metadata(keytype, scheme, key_value, private=False):\n  \"\"\"\n  <Purpose>\n    Return a dictionary conformant to 'securesystemslib.formats.KEY_SCHEMA'.\n    If 'private' is True, include the private key.  The dictionary\n    returned has the form:\n\n    {'keytype': keytype,\n     'scheme' : scheme,\n     'keyval': {'public': '...',\n                'private': '...'}}\n\n    or if 'private' is False:\n\n    {'keytype': keytype,\n     'scheme': scheme,\n     'keyval': {'public': '...',\n                'private': ''}}\n\n    >>> ed25519_key = generate_ed25519_key()\n    >>> key_val = ed25519_key['keyval']\n    >>> keytype = ed25519_key['keytype']\n    >>> scheme = ed25519_key['scheme']\n    >>> ed25519_metadata = \\\n    format_keyval_to_metadata(keytype, scheme, key_val, private=True)\n    >>> securesystemslib.formats.KEY_SCHEMA.matches(ed25519_metadata)\n    True\n\n  <Arguments>\n    key_type:\n      The 'rsa' or 'ed25519' strings.\n\n    scheme:\n      The signature scheme used by the key.\n\n    key_value:\n      A dictionary containing a private and public keys.\n      'key_value' is of the form:\n\n      {'public': '...',\n       'private': '...'}},\n\n      conformant to 'securesystemslib.formats.KEYVAL_SCHEMA'.\n\n    private:\n      Indicates if the private key should be included in the dictionary\n      returned.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'key_value' does not conform to\n    'securesystemslib.formats.KEYVAL_SCHEMA', or if the private key is not\n    present in 'key_value' if requested by the caller via 'private'.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    A 'securesystemslib.formats.KEY_SCHEMA' dictionary.\n  \"\"\"\n\n  # Does 'keytype' have the correct format?\n  # This check will ensure 'keytype' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.KEYTYPE_SCHEMA.check_match(keytype)\n\n  # Does 'scheme' have the correct format?\n  securesystemslib.formats.SCHEME_SCHEMA.check_match(scheme)\n\n  # Does 'key_value' have the correct format?\n  securesystemslib.formats.KEYVAL_SCHEMA.check_match(key_value)\n\n  if private is True:\n    # If the caller requests (via the 'private' argument) to include a private\n    # key in the returned dictionary, ensure the private key is actually\n    # present in 'key_val' (a private key is optional for 'KEYVAL_SCHEMA'\n    # dicts).\n    if 'private' not in key_value:\n      raise securesystemslib.exceptions.FormatError('The required private key'\n        ' is missing from: ' + repr(key_value))\n\n    else:\n      return {'keytype': keytype, 'scheme': scheme, 'keyval': key_value}\n\n  else:\n    public_key_value = {'public': key_value['public']}\n\n    return {'keytype': keytype,\n            'scheme': scheme,\n            'keyid_hash_algorithms': securesystemslib.settings.HASH_ALGORITHMS,\n            'keyval': public_key_value}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_metadata_to_key(key_metadata):\n\n  # Does 'key_metadata' have the correct format?\n  # This check will ensure 'key_metadata' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.KEY_SCHEMA.check_match(key_metadata)\n\n  # Construct the dictionary to be returned.\n  key_dict = {}\n  keytype = key_metadata['keytype']\n  scheme = key_metadata['scheme']\n  key_value = key_metadata['keyval']\n\n  # Convert 'key_value' to 'securesystemslib.formats.KEY_SCHEMA' and generate\n  # its hash The hash is in hexdigest form.\n  default_keyid = _get_keyid(keytype, scheme, key_value)\n  keyids = set()\n  keyids.add(default_keyid)\n\n  for hash_algorithm in securesystemslib.settings.HASH_ALGORITHMS:\n    keyid = _get_keyid(keytype, scheme, key_value, hash_algorithm)\n    keyids.add(keyid)\n\n  # All the required key values gathered.  Build 'key_dict'.\n  # 'keyid_hash_algorithms'\n  key_dict['keytype'] = keytype\n  key_dict['scheme'] = scheme\n  key_dict['keyid'] = default_keyid\n  key_dict['keyid_hash_algorithms'] = securesystemslib.settings.HASH_ALGORITHMS\n  key_dict['keyval'] = key_value\n\n  return key_dict, keyids", "response": "This function formats the key_metadata dictionary into a key dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_keyid(keytype, scheme, key_value, hash_algorithm = 'sha256'):\n\n  # 'keyid' will be generated from an object conformant to KEY_SCHEMA,\n  # which is the format Metadata files (e.g., root.json) store keys.\n  # 'format_keyval_to_metadata()' returns the object needed by _get_keyid().\n  key_meta = format_keyval_to_metadata(keytype, scheme, key_value, private=False)\n\n  # Convert the key to JSON Canonical format, suitable for adding\n  # to digest objects.\n  key_update_data = securesystemslib.formats.encode_canonical(key_meta)\n\n  # Create a digest object and call update(), using the JSON\n  # canonical format of 'rskey_meta' as the update data.\n  digest_object = securesystemslib.hash.digest(hash_algorithm)\n  digest_object.update(key_update_data.encode('utf-8'))\n\n  # 'keyid' becomes the hexadecimal representation of the hash.\n  keyid = digest_object.hexdigest()\n\n  return keyid", "response": "Return the keyid of key_value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_signature(key_dict, data):\n\n  # Does 'key_dict' have the correct format?\n  # This check will ensure 'key_dict' has the appropriate number of objects\n  # and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  # The key type of 'key_dict' must be either 'rsa' or 'ed25519'.\n  securesystemslib.formats.ANYKEY_SCHEMA.check_match(key_dict)\n\n  # Signing the 'data' object requires a private key.  'rsassa-pss-sha256',\n  # 'ed25519', and 'ecdsa-sha2-nistp256' are the only signing schemes currently\n  # supported.  RSASSA-PSS keys and signatures can be generated and verified by\n  # pyca_crypto_keys.py, and Ed25519 keys by PyNaCl and PyCA's optimized, pure\n  # python implementation of Ed25519.\n  signature = {}\n  keytype = key_dict['keytype']\n  scheme = key_dict['scheme']\n  public = key_dict['keyval']['public']\n  private = key_dict['keyval']['private']\n  keyid = key_dict['keyid']\n  sig = None\n\n  if keytype == 'rsa':\n    if scheme == 'rsassa-pss-sha256':\n      private = private.replace('\\r\\n', '\\n')\n      sig, scheme = securesystemslib.pyca_crypto_keys.create_rsa_signature(\n          private, data, scheme)\n\n    else:\n      raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n        ' RSA signature scheme specified: ' + repr(scheme))\n\n  elif keytype == 'ed25519':\n    public = binascii.unhexlify(public.encode('utf-8'))\n    private = binascii.unhexlify(private.encode('utf-8'))\n    sig, scheme = securesystemslib.ed25519_keys.create_signature(\n        public, private, data, scheme)\n\n  elif keytype == 'ecdsa-sha2-nistp256':\n    sig, scheme = securesystemslib.ecdsa_keys.create_signature(\n        public, private, data, scheme)\n\n  # 'securesystemslib.formats.ANYKEY_SCHEMA' should have detected invalid key\n  # types.  This is a defensive check against an invalid key type.\n  else: # pragma: no cover\n    raise TypeError('Invalid key type.')\n\n  # Build the signature dictionary to be returned.\n  # The hexadecimal representation of 'sig' is stored in the signature.\n  signature['keyid'] = keyid\n  signature['sig'] = binascii.hexlify(sig).decode()\n\n  return signature", "response": "Create a signature for a key in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify the signature of a key_dict.", "response": "def verify_signature(key_dict, signature, data):\n  \"\"\"\n  <Purpose>\n    Determine whether the private key belonging to 'key_dict' produced\n    'signature'.  verify_signature() will use the public key found in\n    'key_dict', the 'sig' objects contained in 'signature', and 'data' to\n    complete the verification.\n\n    >>> ed25519_key = generate_ed25519_key()\n    >>> data = 'The quick brown fox jumps over the lazy dog'\n    >>> signature = create_signature(ed25519_key, data)\n    >>> verify_signature(ed25519_key, signature, data)\n    True\n    >>> verify_signature(ed25519_key, signature, 'bad_data')\n    False\n    >>> rsa_key = generate_rsa_key()\n    >>> signature = create_signature(rsa_key, data)\n    >>> verify_signature(rsa_key, signature, data)\n    True\n    >>> verify_signature(rsa_key, signature, 'bad_data')\n    False\n    >>> ecdsa_key = generate_ecdsa_key()\n    >>> signature = create_signature(ecdsa_key, data)\n    >>> verify_signature(ecdsa_key, signature, data)\n    True\n    >>> verify_signature(ecdsa_key, signature, 'bad_data')\n    False\n\n  <Arguments>\n    key_dict:\n      A dictionary containing the keys and other identifying information.\n      If 'key_dict' is an RSA key, it has the form:\n\n      {'keytype': 'rsa',\n       'scheme': 'rsassa-pss-sha256',\n       'keyid': 'f30a0870d026980100c0573bd557394f8c1bbd6...',\n       'keyval': {'public': '-----BEGIN RSA PUBLIC KEY----- ...',\n                  'private': '-----BEGIN RSA PRIVATE KEY----- ...'}}\n\n      The public and private keys are strings in PEM format.\n\n    signature:\n      The signature dictionary produced by one of the key generation functions.\n      'signature' has the form:\n\n      {'keyid': 'f30a0870d026980100c0573bd557394f8c1bbd6...',\n       'sig': sig}.\n\n      Conformant to 'securesystemslib.formats.SIGNATURE_SCHEMA'.\n\n    data:\n      Data that the signature is expected to be over.  This should be a bytes\n      object; data should be encoded/serialized before it is passed here.)\n      This is the same value that can be passed into\n      securesystemslib.create_signature() in order to create the signature.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, raised if either 'key_dict' or\n    'signature' are improperly formatted.\n\n    securesystemslib.exceptions.UnsupportedAlgorithmError, if 'key_dict' or\n    'signature' specifies an unsupported algorithm.\n\n    securesystemslib.exceptions.CryptoError, if the KEYID in the given\n    'key_dict' does not match the KEYID in 'signature'.\n\n  <Side Effects>\n    The cryptography library specified in 'settings' called to do the actual\n    verification.\n\n  <Returns>\n    Boolean.  True if the signature is valid, False otherwise.\n  \"\"\"\n\n  # Does 'key_dict' have the correct format?\n  # This check will ensure 'key_dict' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.ANYKEY_SCHEMA.check_match(key_dict)\n\n  # Does 'signature' have the correct format?\n  securesystemslib.formats.SIGNATURE_SCHEMA.check_match(signature)\n\n  # Verify that the KEYID in 'key_dict' matches the KEYID listed in the\n  # 'signature'.\n  if key_dict['keyid'] != signature['keyid']:\n    raise securesystemslib.exceptions.CryptoError('The KEYID ('\n        ' ' + repr(key_dict['keyid']) + ' ) in the given key does not match'\n        ' the KEYID ( ' + repr(signature['keyid']) + ' ) in the signature.')\n\n  else:\n    logger.debug('The KEYIDs of key_dict and the signature match.')\n\n  # Using the public key belonging to 'key_dict'\n  # (i.e., rsakey_dict['keyval']['public']), verify whether 'signature'\n  # was produced by key_dict's corresponding private key\n  # key_dict['keyval']['private'].\n  sig = signature['sig']\n  sig = binascii.unhexlify(sig.encode('utf-8'))\n  public = key_dict['keyval']['public']\n  keytype = key_dict['keytype']\n  scheme = key_dict['scheme']\n  valid_signature = False\n\n\n  if keytype == 'rsa':\n    if scheme == 'rsassa-pss-sha256':\n      valid_signature = securesystemslib.pyca_crypto_keys.verify_rsa_signature(sig,\n        scheme, public, data)\n\n    else:\n      raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n          ' signature scheme is specified: ' + repr(scheme))\n\n  elif keytype == 'ed25519':\n    if scheme == 'ed25519':\n      public = binascii.unhexlify(public.encode('utf-8'))\n      valid_signature = securesystemslib.ed25519_keys.verify_signature(public,\n          scheme, sig, data, use_pynacl=USE_PYNACL)\n\n    else:\n      raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n          ' signature scheme is specified: ' + repr(scheme))\n\n  elif keytype == 'ecdsa-sha2-nistp256':\n    if scheme == 'ecdsa-sha2-nistp256':\n      valid_signature = securesystemslib.ecdsa_keys.verify_signature(public,\n        scheme, sig, data)\n\n    else:\n      raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n          ' signature scheme is specified: ' + repr(scheme))\n\n  # 'securesystemslib.formats.ANYKEY_SCHEMA' should have detected invalid key\n  # types.  This is a defensive check against an invalid key type.\n  else: # pragma: no cover\n    raise TypeError('Unsupported key type.')\n\n  return valid_signature"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports the private RSA key stored in PEM format and generates a public key and RSA key.", "response": "def import_rsakey_from_private_pem(pem, scheme='rsassa-pss-sha256', password=None):\n  \"\"\"\n  <Purpose>\n    Import the private RSA key stored in 'pem', and generate its public key\n    (which will also be included in the returned rsakey object).  In addition,\n    a keyid identifier for the RSA key is generated.  The object returned\n    conforms to 'securesystemslib.formats.RSAKEY_SCHEMA' and has the form:\n\n    {'keytype': 'rsa',\n     'scheme': 'rsassa-pss-sha256',\n     'keyid': keyid,\n     'keyval': {'public': '-----BEGIN RSA PUBLIC KEY----- ...',\n                'private': '-----BEGIN RSA PRIVATE KEY----- ...'}}\n\n    The private key is a string in PEM format.\n\n    >>> rsa_key = generate_rsa_key()\n    >>> scheme = rsa_key['scheme']\n    >>> private = rsa_key['keyval']['private']\n    >>> passphrase = 'secret'\n    >>> encrypted_pem = create_rsa_encrypted_pem(private, passphrase)\n    >>> rsa_key2 = import_rsakey_from_private_pem(encrypted_pem, scheme, passphrase)\n    >>> securesystemslib.formats.RSAKEY_SCHEMA.matches(rsa_key)\n    True\n    >>> securesystemslib.formats.RSAKEY_SCHEMA.matches(rsa_key2)\n    True\n\n  <Arguments>\n    pem:\n      A string in PEM format.  The private key is extracted and returned in\n      an rsakey object.\n\n    scheme:\n      The signature scheme used by the imported key.\n\n    password: (optional)\n      The password, or passphrase, to decrypt the private part of the RSA key\n      if it is encrypted.  'password' is not used directly as the encryption\n      key, a stronger encryption key is derived from it.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if the arguments are improperly\n    formatted.\n\n    securesystemslib.exceptions.UnsupportedAlgorithmError, if 'pem' specifies\n    an unsupported key type.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    A dictionary containing the RSA keys and other identifying information.\n    Conforms to 'securesystemslib.formats.RSAKEY_SCHEMA'.\n  \"\"\"\n\n  # Does 'pem' have the correct format?\n  # This check will ensure 'pem' conforms to\n  # 'securesystemslib.formats.PEMRSA_SCHEMA'.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(pem)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.RSA_SCHEME_SCHEMA.check_match(scheme)\n\n  if password is not None:\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n  else:\n    logger.debug('The password/passphrase is unset.  The PEM is expected'\n      ' to be unencrypted.')\n\n  # Begin building the RSA key dictionary.\n  rsakey_dict = {}\n  keytype = 'rsa'\n  public = None\n  private = None\n\n  # Generate the public and private RSA keys.  The pyca/cryptography library\n  # performs the actual crypto operations.\n  public, private = \\\n    securesystemslib.pyca_crypto_keys.create_rsa_public_and_private_from_pem(\n    pem, password)\n\n  public =  extract_pem(public, private_pem=False)\n  private = extract_pem(private, private_pem=True)\n\n  # Generate the keyid of the RSA key.  'key_value' corresponds to the\n  # 'keyval' entry of the 'RSAKEY_SCHEMA' dictionary.  The private key\n  # information is not included in the generation of the 'keyid' identifier.\n  # Convert any '\\r\\n' (e.g., Windows) newline characters to '\\n' so that a\n  # consistent keyid is generated.\n  key_value = {'public': public.replace('\\r\\n', '\\n'),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  # Build the 'rsakey_dict' dictionary.  Update 'key_value' with the RSA\n  # private key prior to adding 'key_value' to 'rsakey_dict'.\n  key_value['private'] = private\n\n  rsakey_dict['keytype'] = keytype\n  rsakey_dict['scheme'] = scheme\n  rsakey_dict['keyid'] = keyid\n  rsakey_dict['keyval'] = key_value\n\n  return rsakey_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports an RSA key from a PEM formatted public portion of a PEM file.", "response": "def import_rsakey_from_public_pem(pem, scheme='rsassa-pss-sha256'):\n  \"\"\"\n  <Purpose>\n    Generate an RSA key object from 'pem'.  In addition, a keyid identifier for\n    the RSA key is generated.  The object returned conforms to\n    'securesystemslib.formats.RSAKEY_SCHEMA' and has the form:\n\n    {'keytype': 'rsa',\n     'keyid': keyid,\n     'keyval': {'public': '-----BEGIN PUBLIC KEY----- ...',\n                'private': ''}}\n\n    The public portion of the RSA key is a string in PEM format.\n\n    >>> rsa_key = generate_rsa_key()\n    >>> public = rsa_key['keyval']['public']\n    >>> rsa_key['keyval']['private'] = ''\n    >>> rsa_key2 = import_rsakey_from_public_pem(public)\n    >>> securesystemslib.formats.RSAKEY_SCHEMA.matches(rsa_key)\n    True\n    >>> securesystemslib.formats.RSAKEY_SCHEMA.matches(rsa_key2)\n    True\n\n  <Arguments>\n    pem:\n      A string in PEM format (it should contain a public RSA key).\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'pem' is improperly formatted.\n\n  <Side Effects>\n    Only the public portion of the PEM is extracted.  Leading or trailing\n    whitespace is not included in the PEM string stored in the rsakey object\n    returned.\n\n  <Returns>\n    A dictionary containing the RSA keys and other identifying information.\n    Conforms to 'securesystemslib.formats.RSAKEY_SCHEMA'.\n  \"\"\"\n\n  # Does 'pem' have the correct format?\n  # This check will ensure arguments has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(pem)\n\n  # Does 'scheme' have the correct format?\n  securesystemslib.formats.RSA_SCHEME_SCHEMA.check_match(scheme)\n\n  # Ensure the PEM string has a public header and footer.  Although a simple\n  # validation of 'pem' is performed here, a fully valid PEM string is needed\n  # later to successfully verify signatures.  Performing stricter validation of\n  # PEMs are left to the external libraries that use 'pem'.\n\n  if is_pem_public(pem):\n    public_pem = extract_pem(pem, private_pem=False)\n\n  else:\n    raise securesystemslib.exceptions.FormatError('Invalid public'\n        ' pem: ' + repr(pem))\n\n  # Begin building the RSA key dictionary.\n  rsakey_dict = {}\n  keytype = 'rsa'\n\n  # Generate the keyid of the RSA key.  'key_value' corresponds to the\n  # 'keyval' entry of the 'RSAKEY_SCHEMA' dictionary.  The private key\n  # information is not included in the generation of the 'keyid' identifier.\n  # Convert any '\\r\\n' (e.g., Windows) newline characters to '\\n' so that a\n  # consistent keyid is generated.\n  key_value = {'public': public_pem.replace('\\r\\n', '\\n'),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  rsakey_dict['keytype'] = keytype\n  rsakey_dict['scheme'] = scheme\n  rsakey_dict['keyid'] = keyid\n  rsakey_dict['keyval'] = key_value\n\n  # Add \"keyid_hash_algorithms\" so that equal RSA keys with different keyids\n  # can be associated using supported keyid_hash_algorithms.\n  rsakey_dict['keyid_hash_algorithms'] = \\\n      securesystemslib.settings.HASH_ALGORITHMS\n\n  return rsakey_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_pem(pem, private_pem=False):\n\n  if private_pem:\n    pem_header = '-----BEGIN RSA PRIVATE KEY-----'\n    pem_footer = '-----END RSA PRIVATE KEY-----'\n\n  else:\n    pem_header = '-----BEGIN PUBLIC KEY-----'\n    pem_footer = '-----END PUBLIC KEY-----'\n\n  header_start = 0\n  footer_start = 0\n\n  # Raise error message if the expected header or footer is not found in 'pem'.\n  try:\n    header_start = pem.index(pem_header)\n\n  except ValueError:\n    # Be careful not to print private key material in exception message.\n    if not private_pem:\n      raise securesystemslib.exceptions.FormatError('Required PEM'\n        ' header ' + repr(pem_header) + '\\n not found in PEM'\n        ' string: ' + repr(pem))\n\n    else:\n      raise securesystemslib.exceptions.FormatError('Required PEM'\n        ' header ' + repr(pem_header) + '\\n not found in private PEM string.')\n\n  try:\n    # Search for 'pem_footer' after the PEM header.\n    footer_start = pem.index(pem_footer, header_start + len(pem_header))\n\n  except ValueError:\n    # Be careful not to print private key material in exception message.\n    if not private_pem:\n      raise securesystemslib.exceptions.FormatError('Required PEM'\n        ' footer ' + repr(pem_footer) + '\\n not found in PEM'\n        ' string ' + repr(pem))\n\n    else:\n      raise securesystemslib.exceptions.FormatError('Required PEM'\n        ' footer ' + repr(pem_footer) + '\\n not found in private PEM string.')\n\n  # Extract only the public portion of 'pem'.  Leading or trailing whitespace\n  # is excluded.\n  pem = pem[header_start:footer_start + len(pem_footer)]\n\n  return pem", "response": "Extracts the public and private portion of a PEM string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encrypt_key(key_object, password):\n\n  # Does 'key_object' have the correct format?\n  # This check will ensure 'key_object' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.ANYKEY_SCHEMA.check_match(key_object)\n\n  # Does 'password' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n  # Encrypted string of 'key_object'.  The encrypted string may be safely saved\n  # to a file and stored offline.\n  encrypted_key = None\n\n  # Generate an encrypted string of 'key_object' using AES-256-CTR-Mode, where\n  # 'password' is strengthened with PBKDF2-HMAC-SHA256.\n  encrypted_key = securesystemslib.pyca_crypto_keys.encrypt_key(key_object, password)\n\n  return encrypted_key", "response": "Encrypt a key object with a password."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decrypt_key(encrypted_key, passphrase):\n\n  # Does 'encrypted_key' have the correct format?\n  # This check ensures 'encrypted_key' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.ENCRYPTEDKEY_SCHEMA.check_match(encrypted_key)\n\n  # Does 'passphrase' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(passphrase)\n\n  # Store and return the decrypted key object.\n  key_object = None\n\n  # Decrypt 'encrypted_key' so that the original key object is restored.\n  # encrypt_key() generates an encrypted string of the key object using\n  # AES-256-CTR-Mode, where 'password' is strengthened with PBKDF2-HMAC-SHA256.\n  key_object = \\\n    securesystemslib.pyca_crypto_keys.decrypt_key(encrypted_key, passphrase)\n\n  # The corresponding encrypt_key() encrypts and stores key objects in\n  # non-metadata format (i.e., original format of key object argument to\n  # encrypt_key()) prior to returning.\n\n  return key_object", "response": "This function decrypts the encrypted key and returns the decrypted key in non - encrypted form."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_rsa_encrypted_pem(private_key, passphrase):\n\n  # Does 'private_key' have the correct format?\n  # This check will ensure 'private_key' has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(private_key)\n\n  # Does 'passphrase' have the correct format?\n  securesystemslib.formats.PASSWORD_SCHEMA.check_match(passphrase)\n\n  encrypted_pem = None\n\n  # Generate the public and private RSA keys. A 2048-bit minimum is enforced by\n  # create_rsa_encrypted_pem() via a\n  # securesystemslib.formats.RSAKEYBITS_SCHEMA.check_match().\n  encrypted_pem = securesystemslib.pyca_crypto_keys.create_rsa_encrypted_pem(\n      private_key, passphrase)\n\n  return encrypted_pem", "response": "Creates a PEM - encoded private key in PEM format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a string is a public key.", "response": "def is_pem_public(pem):\n  \"\"\"\n  <Purpose>\n    Checks if a passed PEM formatted string is a PUBLIC key, by looking for the\n    following pattern:\n\n    '-----BEGIN PUBLIC KEY----- ... -----END PUBLIC KEY-----'\n\n    >>> rsa_key = generate_rsa_key()\n    >>> public = rsa_key['keyval']['public']\n    >>> private = rsa_key['keyval']['private']\n    >>> is_pem_public(public)\n    True\n    >>> is_pem_public(private)\n    False\n\n  <Arguments>\n    pem:\n      A string in PEM format.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'pem' is improperly formatted.\n\n  <Side Effects>\n    None\n\n  <Returns>\n    True if 'pem' is public and false otherwise.\n  \"\"\"\n\n  # Do the arguments have the correct format?\n  # This check will ensure arguments have the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(pem)\n\n  pem_header = '-----BEGIN PUBLIC KEY-----'\n  pem_footer = '-----END PUBLIC KEY-----'\n\n  try:\n    header_start = pem.index(pem_header)\n    pem.index(pem_footer, header_start + len(pem_header))\n\n  except ValueError:\n    return False\n\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a string is a private key.", "response": "def is_pem_private(pem, keytype='rsa'):\n  \"\"\"\n  <Purpose>\n    Checks if a passed PEM formatted string is a PRIVATE key, by looking for\n    the following patterns:\n\n    '-----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY-----'\n    '-----BEGIN EC PRIVATE KEY----- ... -----END EC PRIVATE KEY-----'\n\n    >>> rsa_key = generate_rsa_key()\n    >>> private = rsa_key['keyval']['private']\n    >>> public = rsa_key['keyval']['public']\n    >>> is_pem_private(private)\n    True\n    >>> is_pem_private(public)\n    False\n\n  <Arguments>\n    pem:\n      A string in PEM format.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if any of the arguments are\n    improperly formatted.\n\n  <Side Effects>\n    None\n\n  <Returns>\n    True if 'pem' is private and false otherwise.\n  \"\"\"\n\n  # Do the arguments have the correct format?\n  # This check will ensure arguments have the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMRSA_SCHEMA.check_match(pem)\n  securesystemslib.formats.NAME_SCHEMA.check_match(keytype)\n\n  if keytype == 'rsa':\n    pem_header = '-----BEGIN RSA PRIVATE KEY-----'\n    pem_footer = '-----END RSA PRIVATE KEY-----'\n\n  elif keytype == 'ec':\n    pem_header = '-----BEGIN EC PRIVATE KEY-----'\n    pem_footer = '-----END EC PRIVATE KEY-----'\n\n  else:\n    raise securesystemslib.exceptions.FormatError('Unsupported key'\n      ' type: ' + repr(keytype) + '.  Supported keytypes: [\"rsa\", \"ec\"]')\n\n  try:\n    header_start = pem.index(pem_header)\n    pem.index(pem_footer, header_start + len(pem_header))\n\n  except ValueError:\n    return False\n\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_ecdsakey_from_private_pem(pem, scheme='ecdsa-sha2-nistp256', password=None):\n\n  # Does 'pem' have the correct format?\n  # This check will ensure 'pem' conforms to\n  # 'securesystemslib.formats.ECDSARSA_SCHEMA'.\n  securesystemslib.formats.PEMECDSA_SCHEMA.check_match(pem)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.ECDSA_SCHEME_SCHEMA.check_match(scheme)\n\n  if password is not None:\n    securesystemslib.formats.PASSWORD_SCHEMA.check_match(password)\n\n  else:\n    logger.debug('The password/passphrase is unset.  The PEM is expected'\n      ' to be unencrypted.')\n\n  # Begin building the ECDSA key dictionary.\n  ecdsakey_dict = {}\n  keytype = 'ecdsa-sha2-nistp256'\n  public = None\n  private = None\n\n  public, private = \\\n      securesystemslib.ecdsa_keys.create_ecdsa_public_and_private_from_pem(pem,\n      password)\n\n  # Generate the keyid of the ECDSA key.  'key_value' corresponds to the\n  # 'keyval' entry of the 'ECDSAKEY_SCHEMA' dictionary.  The private key\n  # information is not included in the generation of the 'keyid' identifier.\n  # Convert any '\\r\\n' (e.g., Windows) newline characters to '\\n' so that a\n  # consistent keyid is generated.\n  key_value = {'public': public.replace('\\r\\n', '\\n'),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  # Build the 'ecdsakey_dict' dictionary.  Update 'key_value' with the ECDSA\n  # private key prior to adding 'key_value' to 'ecdsakey_dict'.\n  key_value['private'] = private\n\n  ecdsakey_dict['keytype'] = keytype\n  ecdsakey_dict['scheme'] = scheme\n  ecdsakey_dict['keyid'] = keyid\n  ecdsakey_dict['keyval'] = key_value\n\n  # Add \"keyid_hash_algorithms\" so equal ECDSA keys with\n  # different keyids can be associated using supported keyid_hash_algorithms\n  ecdsakey_dict['keyid_hash_algorithms'] = \\\n    securesystemslib.settings.HASH_ALGORITHMS\n\n  return ecdsakey_dict", "response": "Imports the private ECDSA key stored in PEM format and generates a public key and returns the ECDSA key object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport an ECDSA key from a PEM string.", "response": "def import_ecdsakey_from_pem(pem, scheme='ecdsa-sha2-nistp256'):\n  \"\"\"\n  <Purpose>\n    Import either a public or private ECDSA PEM.  In contrast to the other\n    explicit import functions (import_ecdsakey_from_public_pem and\n    import_ecdsakey_from_private_pem), this function is useful for when it is\n    not known whether 'pem' is private or public.\n\n  <Arguments>\n    pem:\n      A string in PEM format.\n\n    scheme:\n      The signature scheme used by the imported key.\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'pem' is improperly formatted.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    A dictionary containing the ECDSA keys and other identifying information.\n    Conforms to 'securesystemslib.formats.ECDSAKEY_SCHEMA'.\n  \"\"\"\n\n  # Does 'pem' have the correct format?\n  # This check will ensure arguments has the appropriate number\n  # of objects and object types, and that all dict keys are properly named.\n  # Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.PEMECDSA_SCHEMA.check_match(pem)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.ECDSA_SCHEME_SCHEMA.check_match(scheme)\n\n  public_pem = ''\n  private_pem = ''\n\n  # Ensure the PEM string has a public or private header and footer.  Although\n  # a simple validation of 'pem' is performed here, a fully valid PEM string is\n  # needed later to successfully verify signatures.  Performing stricter\n  # validation of PEMs are left to the external libraries that use 'pem'.\n  if is_pem_public(pem):\n    public_pem = extract_pem(pem, private_pem=False)\n\n  elif is_pem_private(pem, 'ec'):\n    # Return an ecdsakey object (ECDSAKEY_SCHEMA) with the private key included.\n    return import_ecdsakey_from_private_pem(pem, password=None)\n\n  else:\n    raise securesystemslib.exceptions.FormatError('PEM contains neither a public'\n      ' nor private key: ' + repr(pem))\n\n  # Begin building the ECDSA key dictionary.\n  ecdsakey_dict = {}\n  keytype = 'ecdsa-sha2-nistp256'\n\n  # Generate the keyid of the ECDSA key.  'key_value' corresponds to the\n  # 'keyval' entry of the 'ECDSAKEY_SCHEMA' dictionary.  The private key\n  # information is not included in the generation of the 'keyid' identifier.\n  # If a PEM is found to contain a private key, the generated rsakey object\n  # should be returned above.  The following key object is for the case of a\n  # PEM with only a public key.  Convert any '\\r\\n' (e.g., Windows) newline\n  # characters to '\\n' so that a consistent keyid is generated.\n  key_value = {'public': public_pem.replace('\\r\\n', '\\n'),\n               'private': ''}\n  keyid = _get_keyid(keytype, scheme, key_value)\n\n  ecdsakey_dict['keytype'] = keytype\n  ecdsakey_dict['scheme'] = scheme\n  ecdsakey_dict['keyid'] = keyid\n  ecdsakey_dict['keyval'] = key_value\n\n  return ecdsakey_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the function body.", "response": "def parse_func_body(self):\n        \"\"\"If success, return a tuple (args, body)\"\"\"\n        self.save()\n        self._expected = []\n        if self.next_is_rc(Tokens.OPAR, False):  # do not render right hidden\n            self.handle_hidden_right()  # render hidden after new level\n            args = self.parse_param_list()\n            if args is not None:  # may be an empty table\n                if self.next_is_rc(Tokens.CPAR, False):  # do not render right hidden\n                    self.handle_hidden_right()  # render hidden after new level\n                    body = self.parse_block()\n                    if body:\n                        self._expected = []\n                        token = self.next_is_rc(Tokens.END, False)\n                        if token:\n                            body.stop_char = token.stop\n                            self.success()\n                            return args, body\n                        else:\n                            self.abort()\n                else:\n                    self.abort()\n        return self.failure()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_concrete_class(cls, class_name):\n        def recurrent_class_lookup(cls):\n            for cls in cls.__subclasses__():\n                if lower(cls.__name__) == lower(class_name):\n                    return cls\n                elif len(cls.__subclasses__()) > 0:\n                    r = recurrent_class_lookup(cls)\n                    if r is not None:\n                        return r\n            return None\n\n        cls = recurrent_class_lookup(cls)\n        if cls:\n            return cls\n        else:\n            raise ValueError(\"'class_name '%s' is invalid\" % class_name)", "response": "This method provides easier access to all writers inheriting Writer class\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving pupil data from iLens data editor", "response": "def GetPupil(self):\n    \"\"\"Retrieve pupil data\n    \"\"\"\n    pupil_data = _co.namedtuple('pupil_data', ['ZemaxApertureType',\n                                               'ApertureValue',\n                                               'entrancePupilDiameter',\n                                               'entrancePupilPosition',\n                                               'exitPupilDiameter',\n                                               'exitPupilPosition',\n                                               'ApodizationType',\n                                               'ApodizationFactor'])\n    data = self._ilensdataeditor.GetPupil()\n    return pupil_data(*data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npings a list of hosts or networks.", "response": "def ping(self, targets=list(), filename=str(), status=str()):\n        \"\"\"\n        Attempt to ping a list of hosts or networks (can be a single host)\n        :param targets: List - Name(s) or IP(s) of the host(s).\n        :param filename: String - name of the file containing hosts to ping\n        :param status: String - if one of ['alive', 'dead', 'noip'] then only\n        return results that have that status. If this is not specified,\n        then all results will be returned.\n        :return: Type and results depends on whether status is specified:\n                 if status == '': return dict: {targets: results}\n                 if status != '': return list: targets if targets == status\n        \"\"\"\n\n        if targets and filename:\n            raise SyntaxError(\"You must specify only one of either targets=[] \"\n                              \"or filename=''.\")\n        elif not targets and not filename:\n            raise SyntaxError(\"You must specify either a list of targets or \"\n                              \"filename='', but not both.\")\n        elif filename:\n            targets = self.read_file(filename)\n\n        my_targets = {'hosts': [], 'nets': []}\n        addresses = []\n\n        # Check for valid networks and add hosts and nets to my_targets\n        for target in targets:\n            # Targets may include networks in the format \"network mask\", or,\n            # a file could contain multiple hosts or IP's on a single line.\n            if len(target.split()) > 1:\n                target_items = target.split()\n                for item in target_items:\n                    try:\n                        ip = IPAddress(item)\n                        # If it is an IPv4 address or mask put in in addresses\n                        if ip.version == 4:\n                            addresses.append(str(ip))\n                    except AddrFormatError:\n                        # IP Address not detected, so assume it's a host name\n                        my_targets['hosts'].append(item)\n                    except ValueError:\n                        # CIDR network detected\n                        net = IPNetwork(item)\n                        # Make sure it is a CIDR address acceptable to fping\n                        if net.ip.is_unicast() and net.version == 4 and \\\n                                net.netmask.netmask_bits() in range(8, 31):\n                            my_targets['nets'].append(target_items[0])\n                        else:\n                            msg = str(str(net) + ':Only IPv4 unicast addresses'\n                                      ' with bit masks\\n               '\n                                      ' from 8 to 30 are supported.')\n                            raise AttributeError(msg)\n                # Iterate over the IP strings in addresses\n                while len(addresses) > 1:\n                    ip = IPAddress(addresses[0])\n                    mask = IPAddress(addresses[1])\n                    # Test to see if IP is unicast, and mask is an actual mask\n                    if ip.is_unicast() and mask.is_netmask():\n                        net = IPNetwork(str(ip) + '/' + str(\n                            mask.netmask_bits()))\n                        # Convert ip and mask to CIDR and remove from addresses\n                        my_targets['nets'].append(str(net.cidr))\n                        addresses.pop(0)\n                        addresses.pop(0)\n                    elif ip.is_unicast() and not ip.is_netmask():\n                        # mask was not a mask so only remove IP and start over\n                        my_targets['hosts'].append(str(ip))\n                        addresses.pop(0)\n                # There could be one more item in addresses, so check it\n                if addresses:\n                    ip = IPAddress(addresses[0])\n                    if ip.is_unicast() and not ip.is_netmask():\n                        my_targets['hosts'].append(addresses[0])\n                        addresses.pop()\n            # target has only one item, so check it\n            else:\n                try:\n                    ip = IPAddress(target)\n                    if ip.version == 4 and ip.is_unicast() and \\\n                            not ip.is_netmask():\n                        my_targets['hosts'].append(target)\n                    else:\n                        msg = str(target + 'Only IPv4 unicast addresses are '\n                                  'supported.')\n                        raise AttributeError(msg)\n                except AddrFormatError:\n                    # IP Address not detected, so assume it's a host name\n                    my_targets['hosts'].append(target)\n                except ValueError:\n                    # CIDR network detected\n                    net = IPNetwork(target)\n                    if net.ip.is_unicast() and net.version == 4 and \\\n                            net.netmask.netmask_bits() in range(8, 31):\n                        my_targets['nets'].append(target)\n                    else:\n                        msg = str(str(net) + ':Only IPv4 unicast addresses'\n                                  ' with bit masks\\n               '\n                                  ' from 8 to 30 are supported.')\n                        raise AttributeError(msg)\n\n        \"\"\"\n        Build the list of commands to run.\n        \"\"\"\n        commands = []\n        if len(my_targets['hosts']) != 0:\n            for target in range(len(my_targets['hosts'])):\n                commands.append([self.fping, '-nV', my_targets['hosts'][\n                    target]])\n        if len(my_targets['nets']) != 0:\n            for target in range(len(my_targets['nets'])):\n                commands.append([self.fping, '-ngV', my_targets['nets'][\n                    target]])\n\n        \"\"\"\n        Start pinging each item in my_targets and return the requested results\n        when done.\n        \"\"\"\n        pool = ThreadPool(self.num_pools)\n        raw_results = pool.map(self.get_results, commands)\n        pool.close()\n        pool.join()\n        self.results = {host: result for host, result in csv.reader(\n            ''.join(raw_results).splitlines())}\n        if not status:\n            return self.results\n        elif status == 'alive':\n            return self.alive\n        elif status == 'dead':\n            return self.dead\n        elif status == 'noip':\n            return self.noip\n        else:\n            raise SyntaxError(\"Valid status options are 'alive', 'dead' or \"\n                              \"'noip'\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_results(cmd):\n        try:\n            return subprocess.check_output(cmd)\n        except subprocess.CalledProcessError as e:\n            return e.output", "response": "Get the ping results using fping."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_file(filename):\n        lines = []\n        with open(filename) as f:\n            for line in f:\n                if len(line.strip()) != 0:\n                    lines.append(line.strip())\n        return lines", "response": "Reads the lines of a file into a list and returns the list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data_in, data_out, *args, **kwargs):\n        self._get_tables(data_in)\n\n        self.file_emulation = False\n        outputs = []\n        self._prepare_outputs(data_out, outputs)\n        output = outputs[0]\n        for i in xrange(len(self.tables)):\n            table = self.tables[i]\n\n            self._write_table(output, table)\n\n        if data_out != output and hasattr(data_out, 'write'):\n            output.Flush()\n            output.ReOpen('read')\n            file_size = output.GetSize()\n            buff = bytearray(file_size)\n            output.ReadBuffer(buff, file_size)\n            data_out.write(buff)\n\n        if self.file_emulation:\n            filename = output.GetName()\n            output.Close()", "response": "Writes the object containing the current set of related tables to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator of tuples for slicing in length chunks.", "response": "def _groups_of(length, total_length):\n    \"\"\"\n    Return an iterator of tuples for slicing, in 'length' chunks.\n\n    Parameters\n    ----------\n    length : int\n        Length of each chunk.\n    total_length : int\n        Length of the object we are slicing\n\n    Returns\n    -------\n    iterable of tuples\n        Values defining a slice range resulting in length 'length'.\n\n    \"\"\"\n    indices = tuple(range(0, total_length, length)) + (None, )\n    return _pairwise(indices)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(sources, targets, masked=False):\n    # TODO: Remove restriction\n    assert len(sources) == 1 and len(targets) == 1\n    array = sources[0]\n    target = targets[0]\n\n    # Request bitesize pieces of the source and assign them to the\n    # target.\n    # NB. This algorithm does not use the minimal number of chunks.\n    #   e.g. If the second dimension could be sliced as 0:99, 99:100\n    #       then clearly the first dimension would have to be single\n    #       slices for the 0:99 case, but could be bigger slices for the\n    #       99:100 case.\n    # It's not yet clear if this really matters.\n    all_slices = _all_slices(array)\n    for index in np.ndindex(*[len(slices) for slices in all_slices]):\n        keys = tuple(slices[i] for slices, i in zip(all_slices, index))\n        if masked:\n            target[keys] = array[keys].masked_array()\n        else:\n            target[keys] = array[keys].ndarray()", "response": "Save the numeric results of each source into its corresponding target."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef count(a, axis=None):\n    axes = _normalise_axis(axis, a)\n    if axes is None or len(axes) != 1:\n        msg = \"This operation is currently limited to a single axis\"\n        raise AxisSupportError(msg)\n    return _Aggregation(a, axes[0],\n                        _CountStreamsHandler, _CountMaskedStreamsHandler,\n                        np.dtype('i'), {})", "response": "Count the non - masked elements of the array along the given axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequest the minimum of an Array over any number of axes.", "response": "def min(a, axis=None):\n    \"\"\"\n    Request the minimum of an Array over any number of axes.\n\n    .. note:: Currently limited to operating on a single axis.\n\n    Parameters\n    ----------\n    a : Array object\n        The object whose minimum is to be found.\n    axis : None, or int, or iterable of ints\n        Axis or axes along which the operation is performed. The default\n        (axis=None) is to perform the operation over all the dimensions of the\n        input array. The axis may be negative, in which case it counts from\n        the last to the first axis. If axis is a tuple of ints, the operation\n        is performed over multiple axes.\n\n    Returns\n    -------\n    out : Array\n        The Array representing the requested mean.\n    \"\"\"\n    axes = _normalise_axis(axis, a)\n    assert axes is not None and len(axes) == 1\n    return _Aggregation(a, axes[0],\n                        _MinStreamsHandler, _MinMaskedStreamsHandler,\n                        a.dtype, {})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef max(a, axis=None):\n    axes = _normalise_axis(axis, a)\n    assert axes is not None and len(axes) == 1\n    return _Aggregation(a, axes[0],\n                        _MaxStreamsHandler, _MaxMaskedStreamsHandler,\n                        a.dtype, {})", "response": "Request the maximum of an Array over any number of axes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sum(a, axis=None):\n    axes = _normalise_axis(axis, a)\n    assert axes is not None and len(axes) == 1\n    return _Aggregation(a, axes[0],\n                        _SumStreamsHandler, _SumMaskedStreamsHandler,\n                        a.dtype, {})", "response": "Request the sum of an Array over any number of axes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting the mean of an array over any number of axes.", "response": "def mean(a, axis=None, mdtol=1):\n    \"\"\"\n    Request the mean of an Array over any number of axes.\n\n    .. note:: Currently limited to operating on a single axis.\n\n    :param axis: Axis or axes along which the operation is performed.\n                 The default (axis=None) is to perform the operation\n                 over all the dimensions of the input array.\n                 The axis may be negative, in which case it counts from\n                 the last to the first axis.\n                 If axis is a tuple of ints, the operation is performed\n                 over multiple axes.\n    :type axis: None, or int, or iterable of ints.\n    :param float mdtol: Tolerance of missing data. The value in each\n                        element of the resulting array will be masked if the\n                        fraction of masked data contributing to that element\n                        exceeds mdtol. mdtol=0 means no missing data is\n                        tolerated while mdtol=1 will mean the resulting\n                        element will be masked if and only if all the\n                        contributing elements of the source array are masked.\n                        Defaults to 1.\n    :return: The Array representing the requested mean.\n    :rtype: Array\n\n    \"\"\"\n    axes = _normalise_axis(axis, a)\n    if axes is None or len(axes) != 1:\n        msg = \"This operation is currently limited to a single axis\"\n        raise AxisSupportError(msg)\n    dtype = (np.array([0], dtype=a.dtype) / 1.).dtype\n    kwargs = dict(mdtol=mdtol)\n    return _Aggregation(a, axes[0],\n                        _MeanStreamsHandler, _MeanMaskedStreamsHandler,\n                        dtype, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the standard deviation of an array over any number of axes.", "response": "def std(a, axis=None, ddof=0):\n    \"\"\"\n    Request the standard deviation of an Array over any number of axes.\n\n    .. note:: Currently limited to operating on a single axis.\n\n    :param axis: Axis or axes along which the operation is performed.\n                 The default (axis=None) is to perform the operation\n                 over all the dimensions of the input array.\n                 The axis may be negative, in which case it counts from\n                 the last to the first axis.\n                 If axis is a tuple of ints, the operation is performed\n                 over multiple axes.\n    :type axis: None, or int, or iterable of ints.\n    :param int ddof: Delta Degrees of Freedom. The divisor used in\n                     calculations is N - ddof, where N represents the\n                     number of elements. By default ddof is zero.\n    :return: The Array representing the requested standard deviation.\n    :rtype: Array\n\n    \"\"\"\n    axes = _normalise_axis(axis, a)\n    if axes is None or len(axes) != 1:\n        msg = \"This operation is currently limited to a single axis\"\n        raise AxisSupportError(msg)\n    dtype = (np.array([0], dtype=a.dtype) / 1.).dtype\n    return _Aggregation(a, axes[0],\n                        _StdStreamsHandler, _StdMaskedStreamsHandler,\n                        dtype, dict(ddof=ddof))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef var(a, axis=None, ddof=0):\n    axes = _normalise_axis(axis, a)\n    if axes is None or len(axes) != 1:\n        msg = \"This operation is currently limited to a single axis\"\n        raise AxisSupportError(msg)\n    dtype = (np.array([0], dtype=a.dtype) / 1.).dtype\n    return _Aggregation(a, axes[0],\n                        _VarStreamsHandler, _VarMaskedStreamsHandler,\n                        dtype, dict(ddof=ddof))", "response": "Request the variance of an array over any number of axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sliced_shape(shape, keys):\n    keys = _full_keys(keys, len(shape))\n\n    sliced_shape = []\n    shape_dim = -1\n    for key in keys:\n        shape_dim += 1\n        if _is_scalar(key):\n            continue\n        elif isinstance(key, slice):\n            size = len(range(*key.indices(shape[shape_dim])))\n            sliced_shape.append(size)\n        elif isinstance(key, np.ndarray) and key.dtype == np.dtype('bool'):\n            # Numpy boolean indexing.\n            sliced_shape.append(builtins.sum(key))\n        elif isinstance(key, (tuple, np.ndarray)):\n            sliced_shape.append(len(key))\n        elif key is np.newaxis:\n            shape_dim -= 1\n            sliced_shape.append(1)\n        else:\n            raise ValueError('Invalid indexing object \"{}\"'.format(key))\n\n    sliced_shape = tuple(sliced_shape)\n    return sliced_shape", "response": "Returns the shape that results from slicing an array of the given shape by the given keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a list of keys return a fully expanded tuple of keys.", "response": "def _full_keys(keys, ndim):\n    \"\"\"\n    Given keys such as those passed to ``__getitem__`` for an\n    array of ndim, return a fully expanded tuple of keys.\n\n    In all instances, the result of this operation should follow:\n\n        array[keys] == array[_full_keys(keys, array.ndim)]\n\n    \"\"\"\n    if not isinstance(keys, tuple):\n        keys = (keys,)\n\n    # Make keys mutable, and take a copy.\n    keys = list(keys)\n\n    # Count the number of keys which actually slice a dimension.\n    n_keys_non_newaxis = len([key for key in keys if key is not np.newaxis])\n\n    # Numpy allows an extra dimension to be an Ellipsis, we remove it here\n    # if Ellipsis is in keys, if this doesn't trigger we will raise an\n    # IndexError.\n    is_ellipsis = [key is Ellipsis for key in keys]\n    if n_keys_non_newaxis - 1 >= ndim and any(is_ellipsis):\n        # Remove the left-most Ellipsis, as numpy does.\n        keys.pop(is_ellipsis.index(True))\n        n_keys_non_newaxis -= 1\n\n    if n_keys_non_newaxis > ndim:\n        raise IndexError('Dimensions are over specified for indexing.')\n\n    lh_keys = []\n    # Keys, with the last key first.\n    rh_keys = []\n\n    take_from_left = True\n    while keys:\n        if take_from_left:\n            next_key = keys.pop(0)\n            keys_list = lh_keys\n        else:\n            next_key = keys.pop(-1)\n            keys_list = rh_keys\n\n        if next_key is Ellipsis:\n            next_key = slice(None)\n            take_from_left = not take_from_left\n        keys_list.append(next_key)\n\n    middle = [slice(None)] * (ndim - n_keys_non_newaxis)\n    return tuple(lh_keys + middle + rh_keys[::-1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_array(array):\n    if not isinstance(array, Array):\n        if isinstance(array, np.ndarray):\n            array = NumpyArrayAdapter(array)\n        elif np.isscalar(array):\n            array = ConstantArray([], array)\n        else:\n            raise TypeError('The given array should be a `biggus.Array` '\n                            'instance, got {}.'.format(type(array)))\n    return array", "response": "Ensures that the given array is a subclass of Array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a human - readable description of the number of bytes required to store the data of the given array.", "response": "def size(array):\n    \"\"\"\n    Return a human-readable description of the number of bytes required\n    to store the data of the given array.\n\n    For example::\n\n        >>> array.nbytes\n        14000000\n        >> biggus.size(array)\n        '13.35 MiB'\n\n    Parameters\n    ----------\n    array : array-like object\n        The array object must provide an `nbytes` property.\n\n    Returns\n    -------\n    out : str\n        The Array representing the requested mean.\n\n    \"\"\"\n    nbytes = array.nbytes\n    if nbytes < (1 << 10):\n        size = '{} B'.format(nbytes)\n    elif nbytes < (1 << 20):\n        size = '{:.02f} KiB'.format(nbytes / (1 << 10))\n    elif nbytes < (1 << 30):\n        size = '{:.02f} MiB'.format(nbytes / (1 << 20))\n    elif nbytes < (1 << 40):\n        size = '{:.02f} GiB'.format(nbytes / (1 << 30))\n    else:\n        size = '{:.02f} TiB'.format(nbytes / (1 << 40))\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output(self, chunk):\n        if chunk is not None:\n            for queue in self.output_queues:\n                queue.put(chunk)", "response": "Dispatch the given Chunk onto all the output queues."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nemitting the Chunk instances which cover the underlying Array.", "response": "def run(self):\n        \"\"\"\n        Emit the Chunk instances which cover the underlying Array.\n\n        The Array is divided into chunks with a size limit of\n        MAX_CHUNK_SIZE which are emitted into all registered output\n        queues.\n\n        \"\"\"\n        try:\n            chunk_index = self.chunk_index_gen(self.array.shape,\n                                               self.iteration_order)\n            for key in chunk_index:\n                # Now we have the slices that describe the next chunk.\n                # For example, key might be equivalent to\n                # `[11:12, 0:3, :, :]`.\n                # Simply \"realise\" the data for that region and emit it\n                # as a Chunk to all registered output queues.\n                if self.masked:\n                    data = self.array[key].masked_array()\n                else:\n                    data = self.array[key].ndarray()\n                output_chunk = Chunk(key, data)\n                self.output(output_chunk)\n        except:\n            self.abort()\n            raise\n        else:\n            for queue in self.output_queues:\n                queue.put(QUEUE_FINISHED)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the given nodes as inputs for this node.", "response": "def add_input_nodes(self, input_nodes):\n        \"\"\"\n        Set the given nodes as inputs for this node.\n\n        Creates a limited-size queue.Queue for each input node and\n        registers each queue as an output of its corresponding node.\n\n        \"\"\"\n        self.input_queues = [queue.Queue(maxsize=3) for _ in input_nodes]\n        for input_node, input_queue in zip(input_nodes, self.input_queues):\n            input_node.add_output_queue(input_queue)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the input queues in lock - step and push any results to the registered output queues.", "response": "def run(self):\n        \"\"\"\n        Process the input queues in lock-step, and push any results to\n        the registered output queues.\n\n        \"\"\"\n        try:\n            while True:\n                input_chunks = [input.get() for input in self.input_queues]\n                for input in self.input_queues:\n                    input.task_done()\n                if any(chunk is QUEUE_ABORT for chunk in input_chunks):\n                    self.abort()\n                    return\n                if any(chunk is QUEUE_FINISHED for chunk in input_chunks):\n                    break\n                self.output(self.process_chunks(input_chunks))\n            # Finalise the final chunk (process_chunks does this for all\n            # but the last chunk).\n            self.output(self.finalise())\n        except:\n            self.abort()\n            raise\n        else:\n            for queue in self.output_queues:\n                queue.put(QUEUE_FINISHED)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstoring the incoming data in the result array.", "response": "def process_chunks(self, chunks):\n        \"\"\"\n        Store the incoming chunk at the corresponding position in the\n        result array.\n\n        \"\"\"\n        chunk, = chunks\n        if chunk.keys:\n            self.result[chunk.keys] = chunk.data\n        else:\n            self.result[...] = chunk.data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans up a new key for the given size.", "response": "def _cleanup_new_key(self, key, size, axis):\n        \"\"\"\n        Return a key of type int, slice, or tuple that is guaranteed\n        to be valid for the given dimension size.\n\n        Raises IndexError/TypeError for invalid keys.\n\n        \"\"\"\n        if _is_scalar(key):\n            if key >= size or key < -size:\n                msg = 'index {0} is out of bounds for axis {1} with' \\\n                      ' size {2}'.format(key, axis, size)\n                raise IndexError(msg)\n        elif isinstance(key, slice):\n            pass\n        elif isinstance(key, np.ndarray) and key.dtype == np.dtype('bool'):\n            if key.size > size:\n                msg = 'too many boolean indices. Boolean index array ' \\\n                      'of size {0} is greater than axis {1} with ' \\\n                      'size {2}'.format(key.size, axis, size)\n                raise IndexError(msg)\n        elif isinstance(key, collections.Iterable) and \\\n                not isinstance(key, six.string_types):\n            # Make sure we capture the values in case we've\n            # been given a one-shot iterable, like a generator.\n            key = tuple(key)\n            for sub_key in key:\n                if sub_key >= size or sub_key < -size:\n                    msg = 'index {0} is out of bounds for axis {1}' \\\n                          ' with size {2}'.format(sub_key, axis, size)\n                    raise IndexError(msg)\n        else:\n            raise TypeError('invalid key {!r}'.format(key))\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a key of type int, slice, or tuple that represents the combination of new_key with the given indices. Raises IndexError/TypeError for invalid keys.", "response": "def _remap_new_key(self, indices, new_key, axis):\n        \"\"\"\n        Return a key of type int, slice, or tuple that represents the\n        combination of new_key with the given indices.\n\n        Raises IndexError/TypeError for invalid keys.\n\n        \"\"\"\n        size = len(indices)\n        if _is_scalar(new_key):\n            if new_key >= size or new_key < -size:\n                msg = 'index {0} is out of bounds for axis {1}' \\\n                      ' with size {2}'.format(new_key, axis, size)\n                raise IndexError(msg)\n            result_key = indices[new_key]\n        elif isinstance(new_key, slice):\n            result_key = indices.__getitem__(new_key)\n        elif isinstance(new_key, np.ndarray) and \\\n                new_key.dtype == np.dtype('bool'):\n            # Numpy boolean indexing.\n            if new_key.size > size:\n                msg = 'too many boolean indices. Boolean index array ' \\\n                      'of size {0} is greater than axis {1} with ' \\\n                      'size {2}'.format(new_key.size, axis, size)\n                raise IndexError(msg)\n            result_key = tuple(np.array(indices)[new_key])\n        elif isinstance(new_key, collections.Iterable) and \\\n                not isinstance(new_key, six.string_types):\n            # Make sure we capture the values in case we've\n            # been given a one-shot iterable, like a generator.\n            new_key = tuple(new_key)\n            for sub_key in new_key:\n                if sub_key >= size or sub_key < -size:\n                    msg = 'index {0} is out of bounds for axis {1}' \\\n                          ' with size {2}'.format(sub_key, axis, size)\n                    raise IndexError(msg)\n            result_key = tuple(indices[key] for key in new_key)\n        else:\n            raise TypeError('invalid key {!r}'.format(new_key))\n        return result_key"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply the transposition to the target iterable.", "response": "def _apply_axes_mapping(self, target, inverse=False):\n        \"\"\"\n        Apply the transposition to the target iterable.\n\n        Parameters\n        ----------\n        target - iterable\n            The iterable to transpose. This would be suitable for things\n            such as a shape as well as a list of ``__getitem__`` keys.\n        inverse - bool\n            Whether to map old dimension to new dimension (forward), or\n            new dimension to old dimension (inverse). Default is False\n            (forward).\n\n        Returns\n        -------\n        A tuple derived from target which has been ordered based on the new\n        axes.\n\n        \"\"\"\n        if len(target) != self.ndim:\n            raise ValueError('The target iterable is of length {}, but '\n                             'should be of length {}.'.format(len(target),\n                                                              self.ndim))\n        if inverse:\n            axis_map = self._inverse_axes_map\n        else:\n            axis_map = self._forward_axes_map\n\n        result = [None] * self.ndim\n        for axis, item in enumerate(target):\n            result[axis_map[axis]] = item\n        return tuple(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output_keys(self, source_keys):\n        keys = list(source_keys)\n        # Remove the aggregated axis from the keys.\n        del keys[self.axis]\n        return tuple(keys)", "response": "Given input chunk keys compute what keys will be needed to put\n        the result into the result array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scalarmult_B(e):\n    # scalarmult(B, l) is the identity\n    e = e % l\n    P = ident\n    for i in range(253):\n        if e & 1:\n            P = edwards_add(P, Bpow[i])\n        e = e // 2\n    assert e == 0, e\n    return P", "response": "Implements scalarmult B more efficiently."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_public_and_private():\n\n  # Generate ed25519's seed key by calling os.urandom().  The random bytes\n  # returned should be suitable for cryptographic use and is OS-specific.\n  # Raise 'NotImplementedError' if a randomness source is not found.\n  # ed25519 seed keys are fixed at 32 bytes (256-bit keys).\n  # http://blog.mozilla.org/warner/2011/11/29/ed25519-keys/\n  seed = os.urandom(32)\n  public = None\n\n  # Generate the public key.  PyNaCl (i.e., 'nacl' module) performs the actual\n  # key generation.\n  try:\n    nacl_key = nacl.signing.SigningKey(seed)\n    public = nacl_key.verify_key.encode(encoder=nacl.encoding.RawEncoder())\n\n  except NameError: # pragma: no cover\n    raise securesystemslib.exceptions.UnsupportedLibraryError('The PyNaCl'\n        ' library and/or its dependencies unavailable.')\n\n\n  return public, seed", "response": "Generate a pair of ed25519 public and private keys with PyNaCl."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_signature(public_key, private_key, data, scheme):\n\n  # Does 'public_key' have the correct format?\n  # This check will ensure 'public_key' conforms to\n  # 'securesystemslib.formats.ED25519PUBLIC_SCHEMA', which must have length 32\n  # bytes.  Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.ED25519PUBLIC_SCHEMA.check_match(public_key)\n\n  # Is 'private_key' properly formatted?\n  securesystemslib.formats.ED25519SEED_SCHEMA.check_match(private_key)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.ED25519_SIG_SCHEMA.check_match(scheme)\n\n  # Signing the 'data' object requires a seed and public key.\n  # nacl.signing.SigningKey.sign() generates the signature.\n  public = public_key\n  private = private_key\n\n  signature = None\n\n  # An if-clause is not strictly needed here, since 'ed25519' is the only\n  # currently supported scheme.  Nevertheless, include the conditional\n  # statement to accommodate schemes that might be added in the future.\n  if scheme == 'ed25519':\n    try:\n      nacl_key = nacl.signing.SigningKey(private)\n      nacl_sig = nacl_key.sign(data)\n      signature = nacl_sig.signature\n\n    # The unit tests expect required libraries to be installed.\n    except NameError: # pragma: no cover\n      raise securesystemslib.exceptions.UnsupportedLibraryError('The PyNaCl'\n          ' library and/or its dependencies unavailable.')\n\n    except (ValueError, TypeError, nacl.exceptions.CryptoError) as e:\n      raise securesystemslib.exceptions.CryptoError('An \"ed25519\" signature'\n          ' could not be created with PyNaCl.' + str(e))\n\n  # This is a defensive check for a valid 'scheme', which should have already\n  # been validated in the check_match() above.\n  else: #pragma: no cover\n    raise securesystemslib.exceptions.UnsupportedAlgorithmError('Unsupported'\n      ' signature scheme is specified: ' + repr(scheme))\n\n  return signature, scheme", "response": "Create a signature for the given public key and private key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_signature(public_key, scheme, signature, data, use_pynacl=False):\n\n  # Does 'public_key' have the correct format?\n  # This check will ensure 'public_key' conforms to\n  # 'securesystemslib.formats.ED25519PUBLIC_SCHEMA', which must have length 32\n  # bytes.  Raise 'securesystemslib.exceptions.FormatError' if the check fails.\n  securesystemslib.formats.ED25519PUBLIC_SCHEMA.check_match(public_key)\n\n  # Is 'scheme' properly formatted?\n  securesystemslib.formats.ED25519_SIG_SCHEMA.check_match(scheme)\n\n  # Is 'signature' properly formatted?\n  securesystemslib.formats.ED25519SIGNATURE_SCHEMA.check_match(signature)\n\n  # Is 'use_pynacl' properly formatted?\n  securesystemslib.formats.BOOLEAN_SCHEMA.check_match(use_pynacl)\n\n  # Verify 'signature'.  Before returning the Boolean result, ensure 'ed25519'\n  # was used as the signature scheme.  Raise\n  # 'securesystemslib.exceptions.UnsupportedLibraryError' if 'use_pynacl' is\n  # True but 'nacl' is unavailable.\n  public = public_key\n  valid_signature = False\n\n  if scheme in _SUPPORTED_ED25519_SIGNING_SCHEMES:\n    if use_pynacl:\n      try:\n        nacl_verify_key = nacl.signing.VerifyKey(public)\n        nacl_message = nacl_verify_key.verify(data, signature)\n        valid_signature = True\n\n      # The unit tests expect PyNaCl to be installed.\n      except NameError: # pragma: no cover\n        raise securesystemslib.exceptions.UnsupportedLibraryError('The PyNaCl'\n            ' library and/or its dependencies unavailable.')\n\n      except nacl.exceptions.BadSignatureError:\n        pass\n\n    # Verify 'ed25519' signature with the pure Python implementation.\n    else:\n      try:\n        securesystemslib._vendor.ed25519.ed25519.checkvalid(signature,\n            data, public)\n        valid_signature = True\n\n      # The pure Python implementation raises 'Exception' if 'signature' is\n      # invalid.\n      except Exception as e:\n        pass\n\n  # This is a defensive check for a valid 'scheme', which should have already\n  # been validated in the ED25519_SIG_SCHEMA.check_match(scheme) above.\n  else: #pragma: no cover\n    message = 'Unsupported ed25519 signature scheme: ' + repr(scheme) + '.\\n' + \\\n      'Supported schemes: ' + repr(_SUPPORTED_ED25519_SIGNING_SCHEMES) + '.'\n    raise securesystemslib.exceptions.UnsupportedAlgorithmError(message)\n\n  return valid_signature", "response": "Verify the signature of a public key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitiates link with OpticStudio DDE server and conversation", "response": "def zDDEInit(self):\n        \"\"\"Initiates link with OpticStudio DDE server\"\"\"\n        self.pyver = _get_python_version()\n        # do this only one time or when there is no channel\n        if _PyZDDE.liveCh==0:\n            try:\n                _PyZDDE.server = _dde.CreateServer()\n                _PyZDDE.server.Create(\"ZCLIENT\")   \n            except Exception as err:\n                _sys.stderr.write(\"{}: DDE server may be in use!\".format(str(err)))\n                return -1\n        # Try to create individual conversations for each ZEMAX application.\n        self.conversation = _dde.CreateConversation(_PyZDDE.server)\n        try:\n            self.conversation.ConnectTo(self.appName, \" \")\n        except Exception as err:\n            _sys.stderr.write(\"{}.\\nOpticStudio UI may not be running!\\n\".format(str(err)))\n            # should close the DDE server if it exist\n            self.zDDEClose()\n            return -1\n        else:\n            _PyZDDE.liveCh += 1 \n            self.connection = True\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zDDEClose(self):\n        if _PyZDDE.server and not _PyZDDE.liveCh:\n            _PyZDDE.server.Shutdown(self.conversation)\n            _PyZDDE.server = 0\n        elif _PyZDDE.server and self.connection and _PyZDDE.liveCh == 1:\n            _PyZDDE.server.Shutdown(self.conversation)\n            self.connection = False\n            self.appName = ''\n            _PyZDDE.liveCh -= 1  \n            _PyZDDE.server = 0  \n        elif self.connection:  \n            _PyZDDE.server.Shutdown(self.conversation)\n            self.connection = False\n            self.appName = ''\n            _PyZDDE.liveCh -= 1\n        return 0", "response": "Close the DDE link with Zemax server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset global DDE timeout value in seconds for all DDE calls", "response": "def setTimeout(self, time):\n        \"\"\"Set global timeout value, in seconds, for all DDE calls\"\"\"\n        self.conversation.SetDDETimeout(round(time))\n        return self.conversation.GetDDETimeout()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend command to DDE client", "response": "def _sendDDEcommand(self, cmd, timeout=None):\n        \"\"\"Send command to DDE client\"\"\"\n        reply = self.conversation.Request(cmd, timeout)\n        if self.pyver > 2:\n            reply = reply.decode('ascii').rstrip()\n        return reply"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a zmx file into the DDE server", "response": "def zLoadFile(self, fileName, append=None):\n        \"\"\"Loads a zmx file into the DDE server\"\"\"\n        reply = None\n        if append:\n            cmd = \"LoadFile,{},{}\".format(fileName, append)\n        else:\n            cmd = \"LoadFile,{}\".format(fileName)\n        reply = self._sendDDEcommand(cmd)\n        if reply:\n            return int(reply) #Note: Zemax returns -999 if update fails.\n        else:\n            return -998"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zPushLens(self, update=None, timeout=None):\n        reply = None\n        if update == 1:\n            reply = self._sendDDEcommand('PushLens,1', timeout)\n        elif update == 0 or update is None:\n            reply = self._sendDDEcommand('PushLens,0', timeout)\n        else:\n            raise ValueError('Invalid value for flag')\n        if reply:\n            return int(reply)   # Note: Zemax returns -999 if push lens fails\n        else:\n            return -998", "response": "Push lens in the Zemax DDE server into LDE"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current lens currently loaded in the server to a Zemax file", "response": "def zSaveFile(self, fileName):\n        \"\"\"Saves the lens currently loaded in the server to a Zemax file \"\"\"\n        cmd = \"SaveFile,{}\".format(fileName)\n        reply = self._sendDDEcommand(cmd)\n        return int(float(reply.rstrip()))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning on sync - with - ui", "response": "def zSyncWithUI(self):\n        \"\"\"Turn on sync-with-ui\"\"\"\n        if not OpticalSystem._dde_link:\n            OpticalSystem._dde_link = _get_new_dde_link()\n        if not self._sync_ui_file:\n            self._sync_ui_file = _get_sync_ui_filename()\n        self._sync_ui = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zPushLens(self, update=None):\n        self.SaveAs(self._sync_ui_file)\n        OpticalSystem._dde_link.zLoadFile(self._sync_ui_file)\n        OpticalSystem._dde_link.zPushLens(update)", "response": "Push lens in ZOS COM server to UI"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zGetRefresh(self):\n        OpticalSystem._dde_link.zGetRefresh()\n        OpticalSystem._dde_link.zSaveFile(self._sync_ui_file)\n        self._iopticalsystem.LoadFile (self._sync_ui_file, False)", "response": "Copy lens in UI to headless ZOS COM server"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the current system to the specified file.", "response": "def SaveAs(self, filename):\n        \"\"\"Saves the current system to the specified file. \n\n        @param filename: absolute path (string)\n        @return: None\n        @raise: ValueError if path (excluding the zemax file name) is not valid\n\n        All future calls to `Save()`  will use the same file.\n        \"\"\"\n        directory, zfile = _os.path.split(filename)\n        if zfile.startswith('pyzos_ui_sync_file'):\n            self._iopticalsystem.SaveAs(filename)\n        else: # regular file\n            if not _os.path.exists(directory):\n                raise ValueError('{} is not valid.'.format(directory))\n            else:\n                self._file_to_save_on_Save = filename   # store to use in Save()\n                self._iopticalsystem.SaveAs(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the current system", "response": "def Save(self):\n        \"\"\"Saves the current system\"\"\"\n        # This method is intercepted to allow ui_sync\n        if self._file_to_save_on_Save:\n            self._iopticalsystem.SaveAs(self._file_to_save_on_Save)\n        else:\n            self._iopticalsystem.Save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zGetSurfaceData(self, surfNum):\n        if self.pMode == 0: # Sequential mode\n            surf_data = _co.namedtuple('surface_data', ['radius', 'thick', 'material', 'semidia', \n                                                        'conic', 'comment'])\n            surf = self.pLDE.GetSurfaceAt(surfNum)\n            return surf_data(surf.pRadius, surf.pThickness, surf.pMaterial, surf.pSemiDiameter,\n                             surf.pConic, surf.pComment)\n        else:\n            raise NotImplementedError('Function not implemented for non-sequential mode')", "response": "Return surface data for a single object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zSetSurfaceData(self, surfNum, radius=None, thick=None, material=None, semidia=None, \n                        conic=None, comment=None):\n        \"\"\"Sets surface data\"\"\"\n        if self.pMode == 0: # Sequential mode\n            surf = self.pLDE.GetSurfaceAt(surfNum)\n            if radius is not None:\n                surf.pRadius = radius\n            if thick is not None:\n                surf.pThickness = thick\n            if material is not None:\n                surf.pMaterial = material\n            if semidia is not None:\n                surf.pSemiDiameter = semidia\n            if conic is not None:\n                surf.pConic = conic\n            if comment is not None:\n                surf.pComment = comment\n        else:\n            raise NotImplementedError('Function not implemented for non-sequential mode')", "response": "Sets the surface data for the specified entry in the LDE."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the default merit function for Sequential Merit Function Editor", "response": "def zSetDefaultMeritFunctionSEQ(self, ofType=0, ofData=0, ofRef=0, pupilInteg=0, rings=0,\n                                    arms=0, obscuration=0, grid=0, delVignetted=False, useGlass=False, \n                                    glassMin=0, glassMax=1000, glassEdge=0, useAir=False, airMin=0, \n                                    airMax=1000, airEdge=0, axialSymm=True, ignoreLatCol=False, \n                                    addFavOper=False, startAt=1, relativeXWgt=1.0, overallWgt=1.0, \n                                    configNum=0):\n        \"\"\"Sets the default merit function for Sequential Merit Function Editor\n\n        Parameters\n        ----------\n        ofType : integer\n            optimization function type (0=RMS, ...)\n        ofData : integer \n            optimization function data (0=Wavefront, 1=Spot Radius, ...)\n        ofRef : integer\n            optimization function reference (0=Centroid, ...)\n        pupilInteg : integer\n            pupil integration method (0=Gaussian Quadrature, 1=Rectangular Array)\n        rings : integer\n            rings (0=1, 1=2, 2=3, 3=4, ...)\n        arms : integer \n            arms (0=6, 1=8, 2=10, 3=12)\n        obscuration : real\n            obscuration\n        delVignetted : boolean \n            delete vignetted ?\n        useGlass : boolean \n            whether to use Glass settings for thickness boundary\n        glassMin : real\n            glass mininum thickness \n        glassMax : real \n            glass maximum thickness\n        glassEdge : real\n            glass edge thickness\n        useAir : boolean\n            whether to use Air settings for thickness boundary\n        airMin : real\n            air minimum thickness      \n        airMax : real \n            air maximum thickness\n        airEdge : real \n            air edge thickness\n        axialSymm : boolean \n            assume axial symmetry \n        ignoreLatCol : boolean\n            ignore latent color\n        addFavOper : boolean\n            add favorite color\n        configNum : integer\n            configuration number (0=All)\n        startAt : integer \n            start at\n        relativeXWgt : real \n            relative X weight\n        overallWgt : real\n            overall weight\n        \"\"\"\n        mfe = self.pMFE\n        wizard = mfe.pSEQOptimizationWizard\n        wizard.pType = ofType\n        wizard.pData = ofData\n        wizard.pReference = ofRef\n        wizard.pPupilIntegrationMethod = pupilInteg \n        wizard.pRing = rings\n        wizard.pArm = arms\n        wizard.pObscuration = obscuration\n        wizard.pGrid = grid\n        wizard.pIsDeleteVignetteUsed =  delVignetted\n        wizard.pIsGlassUsed = useGlass \n        wizard.pGlassMin = glassMin\n        wizard.pGlassMax = glassMax\n        wizard.pGlassEdge = glassEdge\n        wizard.pIsAirUsed = useAir\n        wizard.pAirMin = airMin\n        wizard.pAirMax = airMax \n        wizard.pAirEdge = airEdge \n        wizard.pIsAssumeAxialSymmetryUsed = axialSymm\n        wizard.pIsIgnoreLateralColorUsed = ignoreLatCol\n        wizard.pConfiguration = configNum \n        wizard.pIsAddFavoriteOperandsUsed = addFavOper\n        wizard.pStartAt = startAt\n        wizard.pRelativeXWeight = relativeXWgt\n        wizard.pOverallWeight = overallWgt\n        wizard.CommonSettings.OK()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef datetime_to_unix_timestamp(datetime_object):\n\n  # Is 'datetime_object' a datetime.datetime() object?\n  # Raise 'securesystemslib.exceptions.FormatError' if not.\n  if not isinstance(datetime_object, datetime.datetime):\n    message = repr(datetime_object) + ' is not a datetime.datetime() object.'\n    raise securesystemslib.exceptions.FormatError(message)\n\n  unix_timestamp = calendar.timegm(datetime_object.timetuple())\n\n  return unix_timestamp", "response": "Convert a datetime. datetime object to a Unix timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unix_timestamp_to_datetime(unix_timestamp):\n\n  # Is 'unix_timestamp' properly formatted?\n  # Raise 'securesystemslib.exceptions.FormatError' if there is a mismatch.\n  securesystemslib.formats.UNIX_TIMESTAMP_SCHEMA.check_match(unix_timestamp)\n\n  # Convert 'unix_timestamp' to a 'time.struct_time',  in UTC.  The Daylight\n  # Savings Time (DST) flag is set to zero.  datetime.fromtimestamp() is not\n  # used because it returns a local datetime.\n  struct_time = time.gmtime(unix_timestamp)\n\n  # Extract the (year, month, day, hour, minutes, seconds) arguments for the\n  # datetime object to be returned.\n  datetime_object = datetime.datetime(*struct_time[:6])\n\n  return datetime_object", "response": "Converts a UNIX timestamp to a datetime. datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat the base64 encoding of data.", "response": "def format_base64(data):\n  \"\"\"\n  <Purpose>\n    Return the base64 encoding of 'data' with whitespace and '=' signs omitted.\n\n  <Arguments>\n    data:\n      Binary or buffer of data to convert.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if the base64 encoding fails or the\n    argument is invalid.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    A base64-encoded string.\n  \"\"\"\n\n  try:\n    return binascii.b2a_base64(data).decode('utf-8').rstrip('=\\n ')\n\n  except (TypeError, binascii.Error) as e:\n    raise securesystemslib.exceptions.FormatError('Invalid base64'\n      ' encoding: ' + str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a base64 encoded string into a byte string.", "response": "def parse_base64(base64_string):\n  \"\"\"\n  <Purpose>\n    Parse a base64 encoding with whitespace and '=' signs omitted.\n\n  <Arguments>\n    base64_string:\n      A string holding a base64 value.\n\n  <Exceptions>\n    securesystemslib.exceptions.FormatError, if 'base64_string' cannot be parsed\n    due to an invalid base64 encoding.\n\n  <Side Effects>\n    None.\n\n  <Returns>\n    A byte string representing the parsed based64 encoding of\n    'base64_string'.\n  \"\"\"\n\n  if not isinstance(base64_string, six.string_types):\n    message = 'Invalid argument: '+repr(base64_string)\n    raise securesystemslib.exceptions.FormatError(message)\n\n  extra = len(base64_string) % 4\n  if extra:\n    padding = '=' * (4 - extra)\n    base64_string = base64_string + padding\n\n  try:\n    return binascii.a2b_base64(base64_string.encode('utf-8'))\n\n  except (TypeError, binascii.Error) as e:\n    raise securesystemslib.exceptions.FormatError('Invalid base64'\n      ' encoding: ' + str(e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode_canonical(object, output_function=None):\n\n  result = None\n  # If 'output_function' is unset, treat it as\n  # appending to a list.\n  if output_function is None:\n    result = []\n    output_function = result.append\n\n  try:\n    _encode_canonical(object, output_function)\n\n  except (TypeError, securesystemslib.exceptions.FormatError) as e:\n    message = 'Could not encode ' + repr(object) + ': ' + str(e)\n    raise securesystemslib.exceptions.FormatError(message)\n\n  # Return the encoded 'object' as a string.\n  # Note: Implies 'output_function' is None,\n  # otherwise results are sent to 'output_function'.\n  if result is not None:\n    return ''.join(result)", "response": "Encodes a JSON object in canonical JSON form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_error_labels(value):\n\n        observed_error_labels = {}\n        for error in value.get('errors', []):\n            label = error.get('label', 'error')\n\n            if label not in observed_error_labels:\n                observed_error_labels[label] = 0\n            observed_error_labels[label] += 1\n\n            if observed_error_labels[label] > 1:\n                error['label'] = label + '_' + str(observed_error_labels[label])\n\n            # append \"_1\" to first error label that has a duplicate\n            if observed_error_labels[label] == 2:\n                for error1 in value.get('errors', []):\n                    error1_label = error1.get('label', 'error')\n                    if error1_label == label:\n                        error1['label'] = label + \"_1\"\n                        break", "response": "Process the error labels of a dependent variable value to ensure uniqueness."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a raw string representation of text", "response": "def raw(text):\n    \"\"\"Returns a raw string representation of text\"\"\"\n    new_string = ''\n    for char in text:\n        try:\n            new_string += escape_dict[char]\n        except KeyError:\n            new_string += char\n    return new_string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_winfunc(libname, funcname, restype=None, argtypes=(), _libcache={}):\n    if libname not in _libcache:\n        _libcache[libname] = windll.LoadLibrary(libname)\n    func = getattr(_libcache[libname], funcname)\n    func.argtypes = argtypes\n    func.restype = restype\n    return func", "response": "Retrieve a function from a library / DLL and set the data types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef WinMSGLoop():\n    LPMSG = POINTER(MSG)\n    LRESULT = c_ulong\n    GetMessage = get_winfunc(\"user32\", \"GetMessageW\", BOOL, (LPMSG, HWND, UINT, UINT))\n    TranslateMessage = get_winfunc(\"user32\", \"TranslateMessage\", BOOL, (LPMSG,))\n    # restype = LRESULT\n    DispatchMessage = get_winfunc(\"user32\", \"DispatchMessageW\", LRESULT, (LPMSG,))\n\n    msg = MSG()\n    lpmsg = byref(msg)\n    while GetMessage(lpmsg, HWND(), 0, 0) > 0:\n        TranslateMessage(lpmsg)\n        DispatchMessage(lpmsg)", "response": "Run the main windows message loop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ConnectTo(self, appName, data=None):\n        global number_of_apps_communicating\n        self.ddeServerName = appName\n        try:\n            self.ddec = DDEClient(self.ddeServerName, self.ddeClientName) # establish conversation\n        except DDEError:\n            raise\n        else:\n            number_of_apps_communicating +=1", "response": "Connect to a DDE server and set the attributes of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests DDE client and return reply.", "response": "def Request(self, item, timeout=None):\n        \"\"\"Request DDE client\n        timeout in seconds\n        Note ... handle the exception within this function.\n        \"\"\"\n        if not timeout:\n            timeout = self.ddetimeout\n        try:\n            reply = self.ddec.request(item, int(timeout*1000)) # convert timeout into milliseconds\n        except DDEError:\n            err_str = str(sys.exc_info()[1])\n            error = err_str[err_str.find('err=')+4:err_str.find('err=')+10]\n            if error == hex(DMLERR_DATAACKTIMEOUT):\n                print(\"TIMEOUT REACHED. Please use a higher timeout.\\n\")\n            if (sys.version_info > (3, 0)): #this is only evaluated in case of an error\n                reply = b'-998' #Timeout error value\n            else:\n                reply = '-998' #Timeout error value\n        return reply"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequest updates when DDE data changes.", "response": "def advise(self, item, stop=False):\n        \"\"\"Request updates when DDE data changes.\"\"\"\n        hszItem = DDE.CreateStringHandle(self._idInst, item, CP_WINUNICODE)\n        hDdeData = DDE.ClientTransaction(LPBYTE(), 0, self._hConv, hszItem, CF_TEXT, XTYP_ADVSTOP if stop else XTYP_ADVSTART, TIMEOUT_ASYNC, LPDWORD())\n        DDE.FreeStringHandle(self._idInst, hszItem)\n        if not hDdeData:\n            raise DDEError(\"Unable to %s advise\" % (\"stop\" if stop else \"start\"), self._idInst)\n        DDE.FreeDataHandle(hDdeData)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a DDE command.", "response": "def execute(self, command):\n        \"\"\"Execute a DDE command.\"\"\"\n        pData = c_char_p(command)\n        cbData = DWORD(len(command) + 1)\n        hDdeData = DDE.ClientTransaction(pData, cbData, self._hConv, HSZ(), CF_TEXT, XTYP_EXECUTE, TIMEOUT_ASYNC, LPDWORD())\n        if not hDdeData:\n            raise DDEError(\"Unable to send command\", self._idInst)\n        DDE.FreeDataHandle(hDdeData)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(self, item, timeout=5000):\n        hszItem = DDE.CreateStringHandle(self._idInst, item, CP_WINUNICODE)\n        #hDdeData = DDE.ClientTransaction(LPBYTE(), 0, self._hConv, hszItem, CF_TEXT, XTYP_REQUEST, timeout, LPDWORD())\n        pdwResult = DWORD(0)\n        hDdeData = DDE.ClientTransaction(LPBYTE(), 0, self._hConv, hszItem, CF_TEXT, XTYP_REQUEST, timeout, byref(pdwResult))\n        DDE.FreeStringHandle(self._idInst, hszItem)\n        if not hDdeData:\n            raise DDEError(\"Unable to request item\", self._idInst)\n\n        if timeout != TIMEOUT_ASYNC:\n            pdwSize = DWORD(0)\n            pData = DDE.AccessData(hDdeData, byref(pdwSize))\n            if not pData:\n                DDE.FreeDataHandle(hDdeData)\n                raise DDEError(\"Unable to access data in request function\", self._idInst)\n            DDE.UnaccessData(hDdeData)\n        else:\n            pData = None\n        DDE.FreeDataHandle(hDdeData)\n        return pData", "response": "Request data from DDE service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _callback(self, wType, uFmt, hConv, hsz1, hsz2, hDdeData, dwData1, dwData2):\n        if wType == XTYP_ADVDATA:  # value of the data item has changed [hsz1 = topic; hsz2 = item; hDdeData = data]\n            dwSize = DWORD(0)\n            pData = DDE.AccessData(hDdeData, byref(dwSize))\n            if pData:\n                item = create_string_buffer('\\000' * 128)\n                DDE.QueryString(self._idInst, hsz2, item, 128, CP_WINANSI)\n                self.callback(pData, item.value)\n                DDE.UnaccessData(hDdeData)\n                return DDE_FACK\n            else:\n                print(\"Error: AccessData returned NULL! (err = %s)\"% (hex(DDE.GetLastError(self._idInst))))\n        if wType == XTYP_DISCONNECT:\n            print(\"Disconnect notification received from server\")\n\n        return 0", "response": "This function is called by DDEM when a new DDE event is received."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, data_in, *args, **kwargs):\n        if not os.path.exists(data_in):\n            raise ValueError(\"File / Directory does not exist: %s\" % data_in)\n\n        if os.path.isdir(data_in):\n            submission_filepath = os.path.join(data_in, 'submission.yaml')\n            if not os.path.exists(submission_filepath):\n                submission_filepath = os.path.join(data_in, 'submission.yml')\n                if not os.path.exists(submission_filepath):\n                    raise ValueError(\"No submission file in %s\" % data_in)\n            data_in = submission_filepath\n\n        # first validate submission file:\n        with open(data_in, 'r') as submission_file:\n            submission_data = list(yaml.load_all(submission_file, Loader=Loader))\n\n            if len(submission_data) == 0:\n                raise RuntimeError(\"Submission file (%s) is empty\" % data_in)\n\n            submission_file_validator = SubmissionFileValidator()\n            if not submission_file_validator.validate(file_path=data_in,\n                                                      data=submission_data):\n                raise RuntimeError(\n                    \"Submission file (%s) did not pass validation: %s\" %\n                    (data_in, self._pretty_print_errors(\n                        submission_file_validator.get_messages())))\n\n        metadata = {}\n        tables = []\n\n        # validator for table data\n        data_file_validator = DataFileValidator()\n\n        index = 0\n        for i in range(0, len(submission_data)):\n            if not submission_data[i]: # empty YAML document\n                continue\n            if 'data_file' not in submission_data[i]:\n                metadata = submission_data[i] # information about whole submission\n                continue\n            table_filepath = os.path.join(os.path.dirname(data_in),\n                                          submission_data[i]['data_file'])\n            with open(table_filepath, 'r') as table_file:\n                if not os.path.exists(table_filepath):\n                    raise ValueError(\n                        \"table file: %s does not exist\" % table.data_file)\n\n                table_data = yaml.load(table_file, Loader=Loader)\n\n                if not data_file_validator.validate(data=table_data,\n                                                    file_path=table_filepath):\n                    raise RuntimeError(\n                        \"Data file (%s) did not pass validation: %s\" %\n                        (table_filepath, self._pretty_print_errors(\n                            data_file_validator.get_messages())))\n\n                index = index + 1\n                table = Table(index=index, metadata=submission_data[i],\n                              data=table_data)\n                tables.append(table)\n\n        return ParsedData(metadata, tables)", "response": "Parse the submission file and return a dictionary of the submission data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_ai_request(\n        predict_rows,\n        req_dict=None,\n        req_file=ANTINEX_PUBLISH_REQUEST_FILE,\n        features=ANTINEX_FEATURES_TO_PROCESS,\n        ignore_features=ANTINEX_IGNORE_FEATURES,\n        sort_values=ANTINEX_SORT_VALUES,\n        ml_type=ANTINEX_ML_TYPE,\n        use_model_name=ANTINEX_USE_MODEL_NAME,\n        predict_feature=ANTINEX_PREDICT_FEATURE,\n        seed=ANTINEX_SEED,\n        test_size=ANTINEX_TEST_SIZE,\n        batch_size=ANTINEX_BATCH_SIZE,\n        epochs=ANTINEX_EPOCHS,\n        num_splits=ANTINEX_NUM_SPLITS,\n        loss=ANTINEX_LOSS,\n        optimizer=ANTINEX_OPTIMIZER,\n        metrics=ANTINEX_METRICS,\n        histories=ANTINEX_HISTORIES,\n        filter_features_dict=FILTER_FEATURES_DICT,\n        filter_features=FILTER_FEATURES,\n        convert_enabled=ANTINEX_CONVERT_DATA,\n        convert_to_type=ANTINEX_CONVERT_DATA_TYPE,\n        include_failed_conversions=ANTINEX_INCLUDE_FAILED_CONVERSIONS,\n        value_for_missing=ANTINEX_MISSING_VALUE,\n        version=ANTINEX_VERSION,\n        publish_to_core=ANTINEX_PUBLISH_TO_CORE,\n        check_missing_predict_feature=ANTINEX_CHECK_MISSING_PREDICT,\n        debug=ANTINEX_CLIENT_DEBUG):\n    \"\"\"generate_ai_request\n\n    :param predict_rows: list of predict rows to build into the request\n    :param req_dict: request dictionary to update - for long-running clients\n    :param req_file: file holding a request dict to update - one-off tests\n    :param features: features to process in the data\n    :param ignore_features: features to ignore in the data (non-numerics)\n    :param sort_values: optional - order rows for scaler normalization\n    :param ml_type: machine learning type - classification/regression\n    :param use_model_name: use a pre-trained model by name\n    :param predict_feature: predict the values of this feature\n    :param seed: seed for randomness reproducability\n    :param test_size: split train/test data\n    :param batch_size: batch size for processing\n    :param epochs: test epochs\n    :param num_splits: test splits for cross validation\n    :param loss: loss function\n    :param optimizer: optimizer\n    :param metrics: metrics to apply\n    :param histories: historical values to test\n    :param filter_features_dict: dictionary of features to use\n    :param filter_features: list of features to use\n    :param convert_to_type: convert predict_row values to scaler-ready values\n    :param include_failed_conversions: should the predict rows include fails\n    :param value_for_missing: set this value to any columns that are missing\n    :param version: version of the API request\n    :param publish_to_core: want to publish it to the core or the worker\n    :param debug: log debug messages\n    \"\"\"\n\n    status = NOT_SET\n    err = \"not-set\"\n    data = None\n\n    if not ANTINEX_PUBLISH_ENABLED:\n        log.info((\"publish disabled ANTINEX_PUBLISH_ENABLED={}\")\n                 .format(\n                    ANTINEX_PUBLISH_ENABLED))\n        status = DISABLED\n        err = \"disabled\"\n        return {\n            \"status\": status,\n            \"error\": err,\n            \"data\": None}\n    # stop if not enabled\n\n    try:\n\n        err = \"checking number of predict rows\"\n        if len(predict_rows) == 0:\n            err = \"please provide a list of predict_rows\"\n            log.error(err)\n            status = FAILED\n            res = {\n                \"status\": status,\n                \"error\": err,\n                \"data\": None}\n            return res\n        # stop if there's no new rows\n\n        body = None\n        if not req_dict:\n            if os.path.exists(req_file):\n                with open(req_file, \"r\") as f:\n                    body = json.loads(f.read())\n        else:\n            body = copy.deepcopy(\n                req_dict)\n        # end of loading body from requested\n\n        if not body:\n            err = (\"failed to load request body \"\n                   \"req_dict={} req_file={}\").format(\n                       req_dict,\n                       req_file)\n            log.error(err)\n            status = FAILED\n\n            res = {\n                \"status\": status,\n                \"error\": err,\n                \"data\": None}\n            return res\n        # if body is empty\n\n        err = (\"setting values rows={} body={} features={}\").format(\n            len(predict_rows),\n            body,\n            filter_features)\n\n        if debug:\n            log.info(err)\n\n        use_predict_rows = []\n        for r in predict_rows:\n            new_row = {}\n            for col in r:\n                cur_value = r[col]\n                if col in filter_features_dict:\n                    if not cur_value:\n                        cur_value = value_for_missing\n                    if ANTINEX_CONVERT_DATA:\n                        try:\n                            if convert_to_type == \"float\":\n                                new_row[col] = float(cur_value)\n                            elif convert_to_type == \"int\":\n                                new_row[col] = int(cur_value)\n                        except Exception as e:\n                            if include_failed_conversions:\n                                new_row[col] = cur_value\n                            else:\n                                log.error((\"failed converting {}={} type={}\")\n                                          .format(\n                                            col,\n                                            cur_value,\n                                            convert_to_type))\n                        # if conversion failed\n                    else:\n                        new_row[col] = cur_value\n                    # if not converting data\n                # if the column is in the filtered features\n            # for all columns in the row dictionary\n\n            for col in filter_features:\n                if col not in new_row:\n                    new_row[col] = value_for_missing\n            # make sure to fill in missing columns with a default\n\n            if check_missing_predict_feature:\n                if predict_feature not in new_row:\n                    new_row[predict_feature] = value_for_missing\n\n            use_predict_rows.append(new_row)\n        # for all predict rows to convert and fileter\n\n        err = (\"converted rows={} to use_rows={}\").format(\n            len(predict_rows),\n            len(use_predict_rows))\n\n        log.info(err)\n\n        body[\"label\"] = use_model_name\n        body[\"predict_feature\"] = predict_feature\n        body[\"predict_rows\"] = use_predict_rows\n        body[\"publish_to_core\"] = publish_to_core\n        body[\"seed\"] = seed\n        body[\"test_size\"] = test_size\n        body[\"batch_size\"] = batch_size\n        body[\"epochs\"] = epochs\n        body[\"num_splits\"] = num_splits\n        body[\"loss\"] = loss\n        body[\"optimizer\"] = optimizer\n        body[\"metrics\"] = metrics\n        body[\"histories\"] = histories\n        body[\"ml_type\"] = ml_type\n        if sort_values:\n            body[\"sort_values\"] = sort_values\n        if filter_features:\n            body[\"features_to_process\"] = filter_features\n        if ignore_features:\n            body[\"ignore_features\"] = ignore_features\n\n        data = body\n\n        if debug:\n            log.info((\"req={}\")\n                     .format(\n                        ppj(data)))\n\n        status = SUCCESS\n        err = \"\"\n    except Exception as e:\n        log.error((\"failed last_step='{}' with ex={}\")\n                  .format(\n                    err,\n                    e))\n        status = ERROR\n    # end of try/ex\n\n    res = {\n        \"status\": status,\n        \"error\": err,\n        \"data\": data}\n    return res", "response": "Generate an AI request for the current cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an MLJob by ID.", "response": "def get_ml_job():\n    \"\"\"get_ml_job\n\n    Get an ``MLJob`` by database id.\n\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\n            description=(\"Python client get AI Job by ID\"))\n    parser.add_argument(\n        \"-u\",\n        help=\"username\",\n        required=False,\n        dest=\"user\")\n    parser.add_argument(\n        \"-p\",\n        help=\"user password\",\n        required=False,\n        dest=\"password\")\n    parser.add_argument(\n        \"-e\",\n        help=\"user email\",\n        required=False,\n        dest=\"email\")\n    parser.add_argument(\n        \"-a\",\n        help=\"url endpoint with default http://localhost:8010\",\n        required=False,\n        dest=\"url\")\n    parser.add_argument(\n        \"-i\",\n        help=\"User's MLJob.id to look up\",\n        required=False,\n        dest=\"job_id\")\n    parser.add_argument(\n        \"-b\",\n        help=(\n            \"optional - path to CA bundle directory for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"ca_dir\")\n    parser.add_argument(\n        \"-c\",\n        help=(\n            \"optional - path to x509 certificate for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"cert_file\")\n    parser.add_argument(\n        \"-k\",\n        help=(\n            \"optional - path to x509 key file for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"key_file\")\n    parser.add_argument(\n        \"-s\",\n        help=\"silent\",\n        required=False,\n        dest=\"silent\",\n        action=\"store_true\")\n    parser.add_argument(\n        \"-d\",\n        help=\"debug\",\n        required=False,\n        dest=\"debug\",\n        action=\"store_true\")\n    args = parser.parse_args()\n\n    user = ev(\n        \"API_USER\",\n        \"user-not-set\")\n    password = ev(\n        \"API_PASSWORD\",\n        \"password-not-set\")\n    email = ev(\n        \"API_EMAIL\",\n        \"email-not-set\")\n    url = ev(\n        \"API_URL\",\n        \"http://localhost:8010\")\n    job_id = ev(\n        \"JOB_ID\",\n        \"job_id-not-set\")\n    ca_dir = os.getenv(\n        \"API_CA_BUNDLE_DIR\",\n        None)\n    cert_file = os.getenv(\n        \"API_CERT_FILE\",\n        None)\n    key_file = os.getenv(\n        \"API_KEY_FILE\",\n        None)\n    verbose = bool(str(ev(\n        \"API_VERBOSE\",\n        \"true\")).lower() == \"true\")\n    debug = bool(str(ev(\n        \"API_DEBUG\",\n        \"false\")).lower() == \"true\")\n\n    if args.user:\n        user = args.user\n    if args.password:\n        password = args.password\n    if args.email:\n        email = args.email\n    if args.url:\n        url = args.url\n    if args.job_id:\n        job_id = args.job_id\n    if args.ca_dir:\n        ca_dir = args.ca_dir\n    if args.cert_file:\n        cert_file = args.cert_file\n    if args.key_file:\n        key_file = args.key_file\n    if args.silent:\n        verbose = False\n    if args.debug:\n        debug = True\n\n    usage = (\n        \"Please run with \"\n        \"-u <username> \"\n        \"-p <password> \"\n        \"-a <AntiNex URL http://localhost:8010> \"\n        \"-i <job_id> \"\n        \"-b <optional - path to CA bundle directory> \"\n        \"-c <optional - path to x509 ssl certificate file> \"\n        \"-k <optional - path to x509 ssl key file>\")\n\n    valid = True\n    if not user or user == \"user-not-set\":\n        log.error(\"missing user\")\n        valid = False\n    if not password or password == \"password-not-set\":\n        log.error(\"missing password\")\n        valid = False\n    if not job_id or job_id == \"job_id-not-set\":\n        log.error(\"missing job_id\")\n        valid = False\n    else:\n        try:\n            job_id = int(job_id)\n        except Exception as e:\n            log.error(\"please use -i <job_id with an integer>\")\n            valid = False\n    if not valid:\n        log.error(usage)\n        sys.exit(1)\n\n    if verbose:\n        log.info((\n            \"creating client user={} url={} job_id={} \"\n            \"ca_dir={} cert_file={} key_file={}\").format(\n                user,\n                url,\n                job_id,\n                ca_dir,\n                cert_file,\n                key_file))\n\n    client = AIClient(\n        user=user,\n        email=email,\n        password=password,\n        url=url,\n        ca_dir=ca_dir,\n        cert_file=cert_file,\n        key_file=key_file,\n        verbose=verbose,\n        debug=debug)\n\n    if verbose:\n        log.info((\"loading request in job_id={}\")\n                 .format(\n                    job_id))\n\n    response = client.get_job_by_id(\n        job_id=job_id)\n\n    if response[\"status\"] == SUCCESS:\n        if debug:\n            log.info((\"got a job response={}\")\n                     .format(\n                        response[\"data\"]))\n    elif response[\"status\"] == FAILED:\n        log.error((\"job failed with error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n        sys.exit(1)\n    elif response[\"status\"] == ERROR:\n        if \"missing \" in response[\"error\"]:\n            log.error((\"Did not find a job with id={} for user={}\")\n                      .format(\n                        job_id,\n                        user))\n        else:\n            log.error((\"job had an error='{}' with response={}\")\n                      .format(\n                        response[\"error\"],\n                        response[\"data\"]))\n        sys.exit(1)\n    elif response[\"status\"] == LOGIN_FAILED:\n        log.error((\"job reported user was not able to log in \"\n                   \"with an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n        sys.exit(1)\n\n    job_data = response[\"data\"]\n\n    if len(job_data) == 0:\n        log.error((\"Did not find a job with id={} for user={}\")\n                  .format(\n                    job_id,\n                    user))\n        sys.exit(1)\n\n    job_id = job_data.get(\"id\", None)\n    job_status = job_data.get(\"status\", None)\n\n    log.info((\"job={}\")\n             .format(\n                ppj(job_data)))\n\n    log.info((\"done getting job.id={} status={}\")\n             .format(\n                job_id,\n                job_status))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a limited set of comments for a given object.", "response": "def get_molo_comments(parser, token):\n    \"\"\"\n    Get a limited set of comments for a given object.\n    Defaults to a limit of 5. Setting the limit to -1 disables limiting.\n    Set the amount of comments to\n\n    usage:\n\n        {% get_molo_comments for object as variable_name %}\n        {% get_molo_comments for object as variable_name limit amount %}\n        {% get_molo_comments for object as variable_name limit amount child_limit amount %} # noqa\n\n    \"\"\"\n    keywords = token.contents.split()\n    if len(keywords) != 5 and len(keywords) != 7 and len(keywords) != 9:\n        raise template.TemplateSyntaxError(\n            \"'%s' tag takes exactly 2,4 or 6 arguments\" % (keywords[0],))\n    if keywords[1] != 'for':\n        raise template.TemplateSyntaxError(\n            \"first argument to '%s' tag must be 'for'\" % (keywords[0],))\n    if keywords[3] != 'as':\n        raise template.TemplateSyntaxError(\n            \"first argument to '%s' tag must be 'as'\" % (keywords[0],))\n    if len(keywords) > 5 and keywords[5] != 'limit':\n        raise template.TemplateSyntaxError(\n            \"third argument to '%s' tag must be 'limit'\" % (keywords[0],))\n    if len(keywords) == 7:\n        return GetMoloCommentsNode(keywords[2], keywords[4], keywords[6])\n    if len(keywords) > 7 and keywords[7] != 'child_limit':\n        raise template.TemplateSyntaxError(\n            \"third argument to '%s' tag must be 'child_limit'\"\n            % (keywords[0],))\n    if len(keywords) > 7:\n        return GetMoloCommentsNode(keywords[2], keywords[4],\n                                   keywords[6], keywords[8])\n    return GetMoloCommentsNode(keywords[2], keywords[4])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_comments_content_object(parser, token):\n    keywords = token.contents.split()\n    if len(keywords) != 5:\n        raise template.TemplateSyntaxError(\n            \"'%s' tag takes exactly 2 arguments\" % (keywords[0],))\n    if keywords[1] != 'for':\n        raise template.TemplateSyntaxError(\n            \"first argument to '%s' tag must be 'for'\" % (keywords[0],))\n    if keywords[3] != 'as':\n        raise template.TemplateSyntaxError(\n            \"first argument to '%s' tag must be 'as'\" % (keywords[0],))\n    return GetCommentsContentObject(keywords[2], keywords[4])", "response": "Get a limited set of comments for a given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a comment is reported and if so checks it.", "response": "def report(request, comment_id):\n    \"\"\"\n    Flags a comment on GET.\n\n    Redirects to whatever is provided in request.REQUEST['next'].\n    \"\"\"\n\n    comment = get_object_or_404(\n        django_comments.get_model(), pk=comment_id, site__pk=settings.SITE_ID)\n    if comment.parent is not None:\n        messages.info(request, _('Reporting comment replies is not allowed.'))\n    else:\n        perform_flag(request, comment)\n        messages.info(request, _('The comment has been reported.'))\n\n    next = request.GET.get('next') or comment.get_absolute_url()\n    return HttpResponseRedirect(next)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post_molo_comment(request, next=None, using=None):\n    data = request.POST.copy()\n    if 'submit_anonymously' in data:\n        data['name'] = 'Anonymous'\n    # replace with our changed POST data\n\n    # ensure we always set an email\n    data['email'] = request.user.email or 'blank@email.com'\n\n    request.POST = data\n    return post_comment(request, next=next, using=next)", "response": "Allows for posting of a Molo Comment to the Molo News Site"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds an AIClient object from environment variables.", "response": "def build_ai_client_from_env(\n        verbose=ANTINEX_CLIENT_VERBOSE,\n        debug=ANTINEX_CLIENT_DEBUG,\n        ca_dir=None,\n        cert_file=None,\n        key_file=None):\n    \"\"\"build_ai_client_from_env\n\n    Use environment variables to build a client\n\n    :param verbose: verbose logging\n    :param debug: debug internal client calls\n    :param ca_dir: optional path to CA bundle dir\n    :param cert_file: optional path to x509 ssl cert file\n    :param key_file: optional path to x509 ssl key file\n    \"\"\"\n\n    if not ANTINEX_PUBLISH_ENABLED:\n        log.info((\n            \"publish disabled ANTINEX_PUBLISH_ENABLED={}\").format(\n                ANTINEX_PUBLISH_ENABLED))\n        return None\n\n    use_ca_dir = ca_dir\n    use_cert_file = cert_file\n    use_key_file = key_file\n\n    if ANTINEX_CA_FILE or ANTINEX_KEY_FILE or ANTINEX_CERT_FILE:\n        use_ca_dir = ANTINEX_CA_FILE\n        use_cert_file = ANTINEX_CERT_FILE\n        use_key_file = ANTINEX_KEY_FILE\n        log.info((\n            \"creating env client user={} url={} \"\n            \"ca={} cert={} key={}\").format(\n                ANTINEX_USER,\n                ANTINEX_URL,\n                ANTINEX_CA_FILE,\n                ANTINEX_CERT_FILE,\n                ANTINEX_KEY_FILE))\n    else:\n        log.info((\n            \"creating client user={} url={} \"\n            \"ca={} cert={} key={}\").format(\n                ANTINEX_USER,\n                ANTINEX_URL,\n                use_ca_dir,\n                use_cert_file,\n                use_key_file))\n    # if secure or dev\n\n    return AIClient(\n        user=ANTINEX_USER,\n        email=ANTINEX_EMAIL,\n        password=ANTINEX_PASSWORD,\n        url=ANTINEX_URL,\n        ca_dir=use_ca_dir,\n        cert_file=use_cert_file,\n        key_file=use_key_file,\n        verbose=verbose,\n        debug=debug)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train_new_deep_neural_network():\n\n    parser = argparse.ArgumentParser(\n        description=(\n            \"Python client to Train a Deep Neural Network \"\n            \"with AntiNex Django Rest Framework\"))\n    parser.add_argument(\n        \"-u\",\n        help=\"username\",\n        required=False,\n        dest=\"user\")\n    parser.add_argument(\n        \"-p\",\n        help=\"user password\",\n        required=False,\n        dest=\"password\")\n    parser.add_argument(\n        \"-e\",\n        help=\"user email\",\n        required=False,\n        dest=\"email\")\n    parser.add_argument(\n        \"-a\",\n        help=\"url endpoint with default http://localhost:8010\",\n        required=False,\n        dest=\"url\")\n    parser.add_argument(\n        \"-f\",\n        help=\"file to use default ./examples/test-keras-dnn.json\",\n        required=False,\n        dest=\"datafile\")\n    parser.add_argument(\n        \"-b\",\n        help=(\n            \"optional - path to CA bundle directory for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"ca_dir\")\n    parser.add_argument(\n        \"-c\",\n        help=(\n            \"optional - path to x509 certificate for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"cert_file\")\n    parser.add_argument(\n        \"-k\",\n        help=(\n            \"optional - path to x509 key file for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"key_file\")\n    parser.add_argument(\n        \"-s\",\n        help=\"silent\",\n        required=False,\n        dest=\"silent\",\n        action=\"store_true\")\n    parser.add_argument(\n        \"-d\",\n        help=\"debug\",\n        required=False,\n        dest=\"debug\",\n        action=\"store_true\")\n    args = parser.parse_args()\n\n    user = ev(\n        \"API_USER\",\n        \"user-not-set\")\n    password = ev(\n        \"API_PASSWORD\",\n        \"password-not-set\")\n    email = ev(\n        \"API_EMAIL\",\n        \"email-not-set\")\n    url = ev(\n        \"API_URL\",\n        \"http://localhost:8010\")\n    datafile = ev(\n        \"DATAFILE\",\n        \"datafile-not-set\")\n    ca_dir = os.getenv(\n        \"API_CA_BUNDLE_DIR\",\n        None)\n    cert_file = os.getenv(\n        \"API_CERT_FILE\",\n        None)\n    key_file = os.getenv(\n        \"API_KEY_FILE\",\n        None)\n    verbose = bool(str(ev(\n        \"API_VERBOSE\",\n        \"true\")).lower() == \"true\")\n    debug = bool(str(ev(\n        \"API_DEBUG\",\n        \"false\")).lower() == \"true\")\n\n    if args.user:\n        user = args.user\n    if args.password:\n        password = args.password\n    if args.email:\n        email = args.email\n    if args.url:\n        url = args.url\n    if args.datafile:\n        datafile = args.datafile\n    if args.ca_dir:\n        ca_dir = args.ca_dir\n    if args.cert_file:\n        cert_file = args.cert_file\n    if args.key_file:\n        key_file = args.key_file\n    if args.silent:\n        verbose = False\n    if args.debug:\n        debug = True\n\n    usage = (\n        \"Please run with \"\n        \"-u <username> \"\n        \"-p <password> \"\n        \"-a <AntiNex URL http://localhost:8010> \"\n        \"-f <path to json file> \"\n        \"-b <optional - path to CA bundle directory> \"\n        \"-c <optional - path to x509 ssl certificate file> \"\n        \"-k <optional - path to x509 ssl key file>\")\n\n    valid = True\n    if not user or user == \"user-not-set\":\n        log.error(\"missing user\")\n        valid = False\n    if not password or password == \"password-not-set\":\n        log.error(\"missing password\")\n        valid = False\n    if not datafile or datafile == \"datafile-not-set\":\n        log.error(\"missing datafile\")\n        valid = False\n    else:\n        if not os.path.exists(datafile):\n            log.error((\"did not find datafile={} on disk\")\n                      .format(\n                        datafile))\n            valid = False\n    if not valid:\n        log.error(usage)\n        sys.exit(1)\n\n    if verbose:\n        log.info((\n            \"creating client user={} url={} file={} \"\n            \"ca_dir={} cert_file={} key_file={}\").format(\n                user,\n                url,\n                datafile,\n                ca_dir,\n                cert_file,\n                key_file))\n\n    client = AIClient(\n        user=user,\n        email=email,\n        password=password,\n        url=url,\n        ca_dir=ca_dir,\n        cert_file=cert_file,\n        key_file=key_file,\n        verbose=verbose,\n        debug=debug)\n\n    if verbose:\n        log.info((\"loading request in datafile={}\")\n                 .format(\n                    datafile))\n\n    req_body = None\n    with open(datafile, \"r\") as f:\n        req_body = json.loads(f.read())\n\n    if verbose:\n        log.info(\"running job\")\n\n    job_was_started = False\n    response = client.run_job(\n        body=req_body)\n\n    if response[\"status\"] == SUCCESS:\n        log.info((\"job started with response={}\")\n                 .format(\n                    response[\"data\"]))\n        job_was_started = True\n    elif response[\"status\"] == FAILED:\n        log.error((\"job failed with error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n    elif response[\"status\"] == ERROR:\n        log.error((\"job had an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n    elif response[\"status\"] == LOGIN_FAILED:\n        log.error((\"job reported user was not able to log in \"\n                   \"with an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n\n    if not job_was_started:\n        sys.exit(1)\n\n    if debug:\n        log.info((\"parsing response data={}\")\n                 .format(\n                    response[\"data\"]))\n    else:\n        if verbose:\n            log.info(\"parsing data\")\n\n    res_data = response[\"data\"]\n\n    job_data = res_data.get(\n        \"job\",\n        None)\n    result_data = res_data.get(\n        \"results\",\n        None)\n\n    if not job_data:\n        log.error((\"missing job dictionary in response data={}\")\n                  .format(\n                    response[\"data\"]))\n        sys.exit(1)\n    if not result_data:\n        log.error((\"missing results dictionary in response data={}\")\n                  .format(\n                    response[\"data\"]))\n        sys.exit(1)\n\n    job_id = job_data.get(\"id\", None)\n    job_status = job_data.get(\"status\", None)\n    result_id = result_data.get(\"id\", None)\n    result_status = result_data.get(\"status\", None)\n\n    log.info((\"started job.id={} job.status={} with \"\n              \"result.id={} result.status={}\")\n             .format(\n                job_id,\n                job_status,\n                result_id,\n                result_status))\n\n    job_results = client.wait_for_job_to_finish(\n        job_id=job_id)\n\n    if job_results[\"status\"] != SUCCESS:\n        log.error((\"failed waiting for job.id={} to finish error={} data={}\")\n                  .format(\n                    job_id,\n                    job_results[\"error\"],\n                    job_results[\"data\"]))\n        sys.exit(1)\n\n    final_job = job_results[\"data\"][\"job\"]\n    final_result = job_results[\"data\"][\"result\"]\n\n    if verbose:\n        log.info((\"job={}\")\n                 .format(\n                    ppj(final_job)))\n    else:\n        log.info((\"job={}\")\n                 .format(\n                    str(final_job)[0:10]))\n\n    if verbose:\n        log.info((\"result={}\")\n                 .format(\n                    ppj(final_result)))\n    else:\n        log.info((\"result={}\")\n                 .format(\n                    str(final_result)[0:10]))\n\n    log.info((\"job.id={} is done\")\n             .format(\n                job_id))\n\n    predictions = final_result[\"predictions_json\"].get(\n        \"predictions\",\n        [])\n\n    log.info((\"loading predictions={} into pandas dataframe\")\n             .format(\n                len(predictions)))\n\n    df = pd.DataFrame(predictions)\n\n    if verbose:\n        log.info((\"dataframe={}\")\n                 .format(\n                    df))", "response": "Train a new deep neural network and store the results as a new MLJob and MLJobResult database records."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_new_dataset():\n\n    parser = argparse.ArgumentParser(\n        description=(\n            \"Python client to Prepare a dataset\"))\n    parser.add_argument(\n        \"-u\",\n        help=\"username\",\n        required=False,\n        dest=\"user\")\n    parser.add_argument(\n        \"-p\",\n        help=\"user password\",\n        required=False,\n        dest=\"password\")\n    parser.add_argument(\n        \"-e\",\n        help=\"user email\",\n        required=False,\n        dest=\"email\")\n    parser.add_argument(\n        \"-a\",\n        help=\"url endpoint with default http://localhost:8010\",\n        required=False,\n        dest=\"url\")\n    parser.add_argument(\n        \"-f\",\n        help=\"file to use default ./examples/test-keras-dnn.json\",\n        required=False,\n        dest=\"prepare_file\")\n    parser.add_argument(\n        \"-b\",\n        help=(\n            \"optional - path to CA bundle directory for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"ca_dir\")\n    parser.add_argument(\n        \"-c\",\n        help=(\n            \"optional - path to x509 certificate for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"cert_file\")\n    parser.add_argument(\n        \"-k\",\n        help=(\n            \"optional - path to x509 key file for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"key_file\")\n    parser.add_argument(\n        \"-s\",\n        help=\"silent\",\n        required=False,\n        dest=\"silent\",\n        action=\"store_true\")\n    parser.add_argument(\n        \"-d\",\n        help=\"debug\",\n        required=False,\n        dest=\"debug\",\n        action=\"store_true\")\n    args = parser.parse_args()\n\n    user = ev(\n        \"API_USER\",\n        \"user-not-set\")\n    password = ev(\n        \"API_PASSWORD\",\n        \"password-not-set\")\n    email = ev(\n        \"API_EMAIL\",\n        \"email-not-set\")\n    url = ev(\n        \"API_URL\",\n        \"http://localhost:8010\")\n    prepare_file = ev(\n        \"DATAFILE\",\n        \"prepare_file-not-set\")\n    ca_dir = os.getenv(\n        \"API_CA_BUNDLE_DIR\",\n        None)\n    cert_file = os.getenv(\n        \"API_CERT_FILE\",\n        None)\n    key_file = os.getenv(\n        \"API_KEY_FILE\",\n        None)\n    verbose = bool(str(ev(\n        \"API_VERBOSE\",\n        \"true\")).lower() == \"true\")\n    debug = bool(str(ev(\n        \"API_DEBUG\",\n        \"false\")).lower() == \"true\")\n\n    if args.user:\n        user = args.user\n    if args.password:\n        password = args.password\n    if args.email:\n        email = args.email\n    if args.url:\n        url = args.url\n    if args.prepare_file:\n        prepare_file = args.prepare_file\n    if args.ca_dir:\n        ca_dir = args.ca_dir\n    if args.cert_file:\n        cert_file = args.cert_file\n    if args.key_file:\n        key_file = args.key_file\n    if args.silent:\n        verbose = False\n    if args.debug:\n        debug = True\n\n    usage = (\n        \"Please run with \"\n        \"-u <username> \"\n        \"-p <password> \"\n        \"-a <AntiNex URL http://localhost:8010> \"\n        \"-f <path to prepare file> \"\n        \"-b <optional - path to CA bundle directory> \"\n        \"-c <optional - path to x509 ssl certificate file> \"\n        \"-k <optional - path to x509 ssl key file>\")\n\n    valid = True\n    if not user or user == \"user-not-set\":\n        log.error(\"missing user\")\n        valid = False\n    if not password or password == \"password-not-set\":\n        log.error(\"missing password\")\n        valid = False\n    if not prepare_file or prepare_file == \"prepare_file-not-set\":\n        log.error(\"missing prepare_file\")\n        valid = False\n    else:\n        if not os.path.exists(prepare_file):\n            log.error((\"did not find prepare_file={} on disk\")\n                      .format(\n                        prepare_file))\n            valid = False\n    if not valid:\n        log.error(usage)\n        sys.exit(1)\n\n    if verbose:\n        log.info((\"creating client user={} url={} file={}\")\n                 .format(\n                    user,\n                    url,\n                    prepare_file))\n\n    client = AIClient(\n        user=user,\n        email=email,\n        password=password,\n        url=url,\n        ca_dir=ca_dir,\n        cert_file=cert_file,\n        key_file=key_file,\n        verbose=verbose,\n        debug=debug)\n\n    if verbose:\n        log.info((\"loading request in prepare_file={}\")\n                 .format(\n                    prepare_file))\n\n    req_body = None\n    with open(prepare_file, \"r\") as f:\n        req_body = json.loads(f.read())\n\n    if verbose:\n        log.info(\"running prepare\")\n\n    prepare_was_started = False\n    response = client.run_prepare(\n        body=req_body)\n\n    if response[\"status\"] == SUCCESS:\n        log.info((\"prepare started with response={}\")\n                 .format(\n                    response[\"data\"]))\n        prepare_was_started = True\n    elif response[\"status\"] == FAILED:\n        log.error((\"prepare failed with error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n    elif response[\"status\"] == ERROR:\n        log.error((\"prepare had an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n    elif response[\"status\"] == LOGIN_FAILED:\n        log.error((\"prepare reported user was not able to log in \"\n                   \"with an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n\n    if not prepare_was_started:\n        sys.exit(1)\n\n    if debug:\n        log.info((\"parsing response data={}\")\n                 .format(\n                    response[\"data\"]))\n    else:\n        if verbose:\n            log.info(\"parsing data\")\n\n    prepare_data = response[\"data\"]\n\n    if not prepare_data:\n        log.error((\"missing prepare dictionary in response data={}\")\n                  .format(\n                    response[\"data\"]))\n        sys.exit(1)\n\n    prepare_id = prepare_data.get(\"id\", None)\n    prepare_status = prepare_data.get(\"status\", None)\n\n    log.info((\"started prepare.id={} prepare.status={}\")\n             .format(\n                prepare_id,\n                prepare_status))\n\n    prepare_results = client.wait_for_prepare_to_finish(\n        prepare_id=prepare_id)\n\n    if prepare_results[\"status\"] != SUCCESS:\n        log.error((\"failed waiting for prepare.id={} to finish \"\n                   \"error={} data={}\")\n                  .format(\n                    prepare_id,\n                    prepare_results[\"error\"],\n                    prepare_results[\"data\"]))\n        sys.exit(1)\n\n    final_prepare = prepare_results[\"data\"]\n\n    log.info((\"prepare={}\")\n             .format(\n                ppj(final_prepare)))\n\n    log.info((\"prepare.id={} is done\")\n             .format(\n                prepare_id))", "response": "Prepare a new MLPrepare record and dataset files on disk."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drape(raster, feature):\n    coords = feature['geometry']['coordinates']\n    geom_type = feature['geometry']['type']\n\n    if geom_type == 'Point':\n        xyz = sample(raster, [coords])\n        result = Point(xyz[0])\n    elif geom_type == 'LineString':\n        xyz = sample(raster, coords)\n        points = [Point(x, y, z) for x, y, z in xyz]\n        result = LineString(points)\n    else:\n        logging.error('drape not implemented for {}'.format(geom_type))\n\n    return result", "response": "Convert a 2D feature to a 3D feature by sampling a rasterio raster"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsample a raster at given coordinates Return a list of x y z triples with z coordinates sampled from an input raster", "response": "def sample(raster, coords):\n    \"\"\"Sample a raster at given coordinates\n\n    Given a list of coordinates, return a list of x,y,z triples with z coordinates sampled from an input raster\n\n    Parameters:\n        raster (rasterio): raster dataset to sample\n        coords: array of tuples containing coordinate pairs (x,y) or triples (x,y,z)\n\n    Returns:\n        result: array of tuples containing coordinate triples (x,y,z)\n        \n    \"\"\"\n    if len(coords[0]) == 3:\n        logging.info('Input is a 3D geometry, z coordinate will be updated.')\n        z = raster.sample([(x, y) for x, y, z in coords], indexes=raster.indexes)\n    else:\n        z = raster.sample(coords, indexes=raster.indexes)\n\n    result = [(vert[0], vert[1], vert_z) for vert, vert_z in zip(coords, z)]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a logger object from the environment variables", "response": "def build_logger(\n    name=os.getenv(\n        \"LOG_NAME\",\n        \"client\"),\n    config=\"logging.json\",\n    log_level=logging.INFO,\n    log_config_path=\"{}/logging.json\".format(\n        os.getenv(\n            \"LOG_CFG\",\n            os.path.dirname(os.path.realpath(__file__))))):\n    \"\"\"build_logger\n\n    :param name: name that shows in the logger\n    :param config: name of the config file\n    :param log_level: level to log\n    :param log_config_path: path to log config file\n    \"\"\"\n    use_config = (\"./log/{}\").format(\n                    \"{}\".format(\n                        config))\n    if not os.path.exists(use_config):\n        use_config = log_config_path\n        if not os.path.exists(use_config):\n            use_config = (\"./antinex_client/log/{}\").format(\n                            \"logging.json\")\n    # find the log processing\n\n    setup_logging(\n        default_level=log_level,\n        default_path=use_config)\n\n    return logging.getLogger(name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_colorized_logger(\n    name=os.getenv(\n        \"LOG_NAME\",\n        \"client\"),\n    config=\"colors-logging.json\",\n    log_level=logging.INFO,\n    log_config_path=\"{}/logging.json\".format(\n        os.getenv(\n            \"LOG_CFG\",\n            os.path.dirname(os.path.realpath(__file__))))):\n    \"\"\"build_colorized_logger\n\n    :param name: name that shows in the logger\n    :param config: name of the config file\n    :param log_level: level to log\n    :param log_config_path: path to log config file\n    \"\"\"\n\n    override_config = os.getenv(\n        \"SHARED_LOG_CFG\",\n        None)\n    debug_log_config = bool(os.getenv(\n        \"DEBUG_SHARED_LOG_CFG\",\n        \"0\") == \"1\")\n    if override_config:\n        if debug_log_config:\n            print((\n                \"creating logger config env var: \"\n                \"SHARED_LOG_CFG={}\".format(\n                    override_config)))\n        if os.path.exists(override_config):\n            setup_logging(\n                default_level=log_level,\n                default_path=override_config)\n            return logging.getLogger(name)\n        if debug_log_config:\n            print((\n                \"Failed to find log config using env var: \"\n                \"SHARED_LOG_CFG={}\".format(\n                    override_config)))\n    else:\n        if debug_log_config:\n            print((\n                \"Not using shared logging env var: \"\n                \"SHARED_LOG_CFG={}\".format(\n                    override_config)))\n    # allow a shared log config across all components\n\n    use_config = (\"{}\").format(\n        config)\n\n    if not os.path.exists(use_config):\n        use_config = (\"./antinex_client/log/{}\").format(\n                            config)\n        if not os.path.exists(use_config):\n            use_config = log_config_path\n            if not os.path.exists(use_config):\n                use_config = (\"./log/{}\").format(\n                            config)\n                if not os.path.exists(use_config):\n                    use_config = (\"./antinex_client/log/{}\").format(\n                                \"logging.json\")\n                # find the last log config backup from the base of the repo\n            # find the log config from the defaults with the env LOG_CFG\n        # find the log config from the base of the repo\n    # find the log config by the given path\n\n    setup_logging(\n        default_level=log_level,\n        default_path=use_config)\n\n    return logging.getLogger(name)", "response": "Build a colorized logger for the current log level and config file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef authenticate(self, request: HttpRequest, auth_route: str, actual_params: dict) -> bool:\n        if auth_route and actual_params:\n            self.auth_data = {}\n        return True", "response": "This method is used to authenticate the user with the AuhtService."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting 2D geometries to 3D using GEOS sample through fiona.", "response": "def cli(source_f, raster_f, output, verbose):\n    \"\"\"\n    Converts 2D geometries to 3D using GEOS sample through fiona.\n\n    \\b\n    Example:\n    drape point.shp elevation.tif -o point_z.shp\n\n    \"\"\"\n    with fiona.open(source_f, 'r') as source:\n        source_driver = source.driver\n        source_crs = source.crs\n        sink_schema = source.schema.copy()\n\n        source_geom = source.schema['geometry']\n        if source_geom == 'Point':\n            sink_schema['geometry'] = '3D Point'\n        elif source_geom == 'LineString':\n            sink_schema['geometry'] = '3D LineString'\n        elif source_geom == '3D Point' or source_geom == '3D LineString':\n            pass\n        else:\n            click.BadParameter(\"Source geometry type {} not implemented\".format(source_geom))\n\n        with rasterio.open(raster_f) as raster:\n            if source_crs != raster.crs:\n                click.BadParameter(\"Features and raster have different CRS.\")\n            if raster.count > 1:\n                warnings.warn(\"Found {0} bands in {1}, expected a single band raster\".format(raster.bands, raster_f))\n            supported = ['int16', 'int32', 'float32', 'float64']\n            if raster.dtypes[0] not in supported:\n                warnings.warn(\"Found {0} type in {1}, expected one of {2}\".format(raster.dtypes[0]), raster_f, supported)\n            with fiona.open(\n                output, 'w',\n                driver=source_driver,\n                crs=source_crs,\n                schema=sink_schema) as sink:\n\n                for feature in source:\n                    try:\n                        feature_z = drapery.drape(raster, feature)\n                        sink.write({\n                            'geometry': mapping(feature_z),\n                            'properties': feature['properties'],\n                        })\n                    except Exception:\n                        logging.exception(\"Error processing feature %s:\", feature['id'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a QuerySet for all comments for a particular model.", "response": "def for_model(self, model):\n        \"\"\"\n        QuerySet for all comments for a particular model (either an instance or\n        a class).\n        \"\"\"\n        ct = ContentType.objects.get_for_model(model)\n        qs = self.get_queryset().filter(content_type=ct)\n        if isinstance(model, models.Model):\n            qs = qs.filter(object_pk=force_text(model._get_pk_val()))\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eval(self, command):\n        'Blocking call, returns the value of the execution in JS'\n        event = threading.Event()\n        # TODO: Add event to server\n        #job_id = str(id(command))\n        import random\n        job_id = str(random.random())\n        server.EVALUATIONS[job_id] = event\n\n        message = '?' + job_id + '=' + command\n        logging.info(('message:', [message]))\n        for listener in server.LISTENERS.get(self.path, []):\n            logging.debug(('listener:', listener))\n            listener.write_message(message)\n\n        success = event.wait(timeout=30)\n\n        if success:\n            value_parser = server.RESULTS[job_id]\n            del server.EVALUATIONS[job_id]\n            del server.RESULTS[job_id]\n            return value_parser()\n        else:\n            del server.EVALUATIONS[job_id]\n            if job_id in server.RESULTS:\n                del server.RESULTS[job_id]\n            raise IOError('Evaluation failed.')", "response": "Blocking call returns the value of the execution in JS"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a callback on server and on connected clients.", "response": "def register(self, callback, name):\n        'Register a callback on server and on connected clients.'\n        server.CALLBACKS[name] = callback\n        self.run('''\n            window.skink.%s = function(args=[])\u00a0{\n                window.skink.call(\"%s\", args);\n            }''' % (name, name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_exception(message):\n    error_name = message['name']\n    error_descr = message['description']\n    mapping = {\n        'ReferenceError': NameError,\n    }\n    if message['name'] in mapping:\n        raise mapping[error_name](error_descr)\n    else:\n        raise Exception('{}: {}'.format(error_name, error_descr))", "response": "Launch an exception from an error that took place in the browser."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_predictions():\n\n    parser = argparse.ArgumentParser(\n        description=(\n            \"Python client to make Predictions \"\n            \"using a Pre-trained Deep Neural Network \"\n            \"with AntiNex Django Rest Framework\"))\n    parser.add_argument(\n        \"-f\",\n        help=(\n            \"file to use default ./examples/\"\n            \"predict-rows-scaler-full-django.json\"),\n        required=False,\n        dest=\"datafile\")\n    parser.add_argument(\n        \"-m\",\n        help=\"send mock data\",\n        required=False,\n        dest=\"use_fake_rows\",\n        action=\"store_true\")\n    parser.add_argument(\n        \"-b\",\n        help=(\n            \"optional - path to CA bundle directory for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"ca_dir\")\n    parser.add_argument(\n        \"-c\",\n        help=(\n            \"optional - path to x509 certificate for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"cert_file\")\n    parser.add_argument(\n        \"-k\",\n        help=(\n            \"optional - path to x509 key file for \"\n            \"client encryption over HTTP\"),\n        required=False,\n        dest=\"key_file\")\n    parser.add_argument(\n        \"-s\",\n        help=\"silent\",\n        required=False,\n        dest=\"silent\",\n        action=\"store_true\")\n    parser.add_argument(\n        \"-d\",\n        help=\"debug\",\n        required=False,\n        dest=\"debug\",\n        action=\"store_true\")\n    args = parser.parse_args()\n\n    datafile = ev(\n        \"DATAFILE\",\n        \"./examples/predict-rows-scaler-full-django.json\")\n    ca_dir = os.getenv(\n        \"API_CA_BUNDLE_DIR\",\n        None)\n    cert_file = os.getenv(\n        \"API_CERT_FILE\",\n        None)\n    key_file = os.getenv(\n        \"API_KEY_FILE\",\n        None)\n    verbose = bool(str(ev(\n        \"API_CLIENT_VERBOSE\",\n        \"1\")).lower() == \"1\")\n    debug = bool(str(ev(\n        \"API_CLIENT_DEBUG\",\n        \"0\")).lower() == \"1\")\n\n    use_fake_rows = False\n\n    if args.use_fake_rows:\n        use_fake_rows = True\n    if args.datafile:\n        datafile = args.datafile\n    if args.ca_dir:\n        ca_dir = args.ca_dir\n    if args.cert_file:\n        cert_file = args.cert_file\n    if args.key_file:\n        key_file = args.key_file\n    if args.silent:\n        verbose = False\n    if args.debug:\n        debug = True\n\n    if verbose:\n        log.info(\"creating client\")\n\n    client = build_ai_client_from_env(\n        ca_dir=ca_dir,\n        cert_file=cert_file,\n        key_file=key_file,\n        verbose=verbose,\n        debug=debug)\n\n    if verbose:\n        log.info((\"loading request in datafile={}\")\n                 .format(\n                    datafile))\n\n    # pass in full or partial prediction record dictionaries\n    # the generate_ai_request will fill in gaps with defaults\n    fake_rows_for_predicting = [\n        {\n            \"tcp_seq\": 1\n        },\n        {\n            \"tcp_seq\": 2\n        },\n        {\n            \"tcp_seq\": 3\n        },\n        {\n            \"tcp_seq\": 4\n        }\n    ]\n\n    res_gen = None\n    if use_fake_rows:\n        res_gen = generate_ai_request(\n            predict_rows=fake_rows_for_predicting)\n    else:\n        req_with_org_rows = None\n        with open(datafile, \"r\") as f:\n            req_with_org_rows = json.loads(f.read())\n\n        res_gen = generate_ai_request(\n            predict_rows=req_with_org_rows[\"predict_rows\"])\n    # end of sending mock data from this file or a file on disk\n\n    if res_gen[\"status\"] != SUCCESS:\n        log.error((\"failed generate_ai_request with error={}\")\n                  .format(\n                    res_gen[\"error\"]))\n        sys.exit(1)\n\n    req_body = res_gen[\"data\"]\n\n    if verbose:\n        log.info(\"running job\")\n\n    job_was_started = False\n    response = client.run_job(\n        body=req_body)\n\n    if response[\"status\"] == SUCCESS:\n        log.info((\"job started with response={}\")\n                 .format(\n                    response[\"data\"]))\n        job_was_started = True\n    elif response[\"status\"] == FAILED:\n        log.error((\"job failed with error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n    elif response[\"status\"] == ERROR:\n        log.error((\"job had an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n    elif response[\"status\"] == LOGIN_FAILED:\n        log.error((\"job reported user was not able to log in \"\n                   \"with an error='{}' with response={}\")\n                  .format(\n                    response[\"error\"],\n                    response[\"data\"]))\n\n    if not job_was_started:\n        sys.exit(1)\n\n    if debug:\n        log.info((\"parsing response data={}\")\n                 .format(\n                    response[\"data\"]))\n    else:\n        if verbose:\n            log.info(\"parsing data\")\n\n    res_data = response[\"data\"]\n\n    job_data = res_data.get(\n        \"job\",\n        None)\n    result_data = res_data.get(\n        \"results\",\n        None)\n\n    if not job_data:\n        log.error((\"missing job dictionary in response data={}\")\n                  .format(\n                    response[\"data\"]))\n        sys.exit(1)\n    if not result_data:\n        log.error((\"missing results dictionary in response data={}\")\n                  .format(\n                    response[\"data\"]))\n        sys.exit(1)\n\n    job_id = job_data.get(\"id\", None)\n    job_status = job_data.get(\"status\", None)\n    result_id = result_data.get(\"id\", None)\n    result_status = result_data.get(\"status\", None)\n\n    log.info((\"started job.id={} job.status={} with \"\n              \"result.id={} result.status={}\")\n             .format(\n                job_id,\n                job_status,\n                result_id,\n                result_status))\n\n    job_results = client.wait_for_job_to_finish(\n        job_id=job_id)\n\n    if job_results[\"status\"] != SUCCESS:\n        log.error((\"failed waiting for job.id={} to finish error={} data={}\")\n                  .format(\n                    job_id,\n                    job_results[\"error\"],\n                    job_results[\"data\"]))\n        sys.exit(1)\n\n    final_job = job_results[\"data\"][\"job\"]\n    final_result = job_results[\"data\"][\"result\"]\n\n    log.info((\"job={}\")\n             .format(\n                ppj(final_job)))\n\n    log.info((\"result={}\")\n             .format(\n                ppj(final_result)))\n\n    log.info((\"job.id={} is done\")\n             .format(\n                job_id))\n\n    predictions = final_result[\"predictions_json\"].get(\n        \"predictions\",\n        [])\n\n    log.info((\"loading predictions={} into pandas dataframe\")\n             .format(\n                len(predictions)))\n\n    df = pd.DataFrame(predictions)\n\n    log.info((\"dataframe={}\")\n             .format(\n                df))", "response": "Start predictions on a deep neural network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlogin to the user", "response": "def login(\n            self):\n        \"\"\"login\"\"\"\n\n        auth_url = self.api_urls[\"login\"]\n\n        if self.verbose:\n            log.info((\"log in user={} url={} ca_dir={} cert={}\")\n                     .format(\n                        self.user,\n                        auth_url,\n                        self.ca_dir,\n                        self.cert))\n\n        use_headers = {\n            \"Content-type\": \"application/json\"\n        }\n        login_data = {\n            \"username\": self.user,\n            \"password\": self.password\n        }\n\n        if self.debug:\n            log.info((\n                \"LOGIN with body={} headers={} url={} \"\n                \"verify={} cert={}\").format(\n                    login_data,\n                    use_headers,\n                    auth_url,\n                    self.use_verify,\n                    self.cert))\n\n        response = requests.post(\n            auth_url,\n            verify=self.use_verify,\n            cert=self.cert,\n            data=json.dumps(login_data),\n            headers=use_headers)\n\n        if self.debug:\n            log.info((\"LOGIN response status_code={} text={} reason={}\")\n                     .format(\n                        response.status_code,\n                        response.text,\n                        response.reason))\n\n        user_token = \"\"\n        if response.status_code == 200:\n            user_token = json.loads(response.text)[\"token\"]\n\n        if user_token != \"\":\n            self.token = user_token\n            self.login_status = LOGIN_SUCCESS\n\n            if self.verbose:\n                log.debug(\"login success\")\n        else:\n            log.error((\"failed to login user={} to url={} text={}\")\n                      .format(\n                        self.user,\n                        auth_url,\n                        response.text))\n            self.login_status = LOGIN_FAILED\n        # if the user token exists\n\n        return self.login_status"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_response(\n            self,\n            status=NOT_SET,\n            error=\"\",\n            data=None):\n        \"\"\"build_response\n\n        :param status: status code\n        :param error: error message\n        :param data: dictionary to send back\n        \"\"\"\n\n        res_node = {\n            \"status\": status,\n            \"error\": error,\n            \"data\": data\n        }\n        return res_node", "response": "Builds a response node from the status code error message and data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the prepare record by ID.", "response": "def get_prepare_by_id(\n            self,\n            prepare_id=None):\n        \"\"\"get_prepare_by_id\n\n        :param prepare_id: MLJob.id in the database\n        \"\"\"\n\n        if not prepare_id:\n            log.error(\"missing prepare_id for get_prepare_by_id\")\n            return self.build_response(\n                status=ERROR,\n                error=\"missing prepare_id for get_prepare_by_id\")\n\n        if self.debug:\n            log.info((\"user={} getting prepare={}\")\n                     .format(\n                        self.user,\n                        prepare_id))\n\n        url = \"{}{}\".format(\n                self.api_urls[\"prepare\"],\n                prepare_id)\n\n        not_done = True\n        while not_done:\n\n            if self.debug:\n                log.info((\n                    \"JOB attempting to get={} to url={} \"\n                    \"verify={} cert={}\").format(\n                        prepare_id,\n                        url,\n                        self.use_verify,\n                        self.cert))\n\n            response = requests.get(\n                url,\n                verify=self.use_verify,\n                cert=self.cert,\n                headers=self.get_auth_header())\n\n            if self.debug:\n                log.info((\"JOB response status_code={} text={} reason={}\")\n                         .format(\n                            response.status_code,\n                            response.text,\n                            response.reason))\n\n            if response.status_code == 401:\n                login_res = self.retry_login()\n                if login_res[\"status\"] != SUCCESS:\n                    if self.verbose:\n                        log.error(\n                            \"retry login attempts failed\")\n                    return self.build_response(\n                        status=login_res[\"status\"],\n                        error=login_res[\"error\"])\n                # if able to log back in just retry the call\n            elif response.status_code == 200:\n\n                if self.verbose:\n                    log.debug(\"deserializing\")\n\n                prepare_data = json.loads(\n                    response.text)\n\n                prepare_id = prepare_data.get(\n                    \"id\",\n                    None)\n\n                if not prepare_id:\n                    return self.build_response(\n                        status=ERROR,\n                        error=\"missing prepare.id\",\n                        data=\"text={} reason={}\".format(\n                            response.reason,\n                            response.text))\n\n                self.all_prepares[str(prepare_id)] = prepare_data\n\n                if self.debug:\n                    log.info((\"added prepare={} all_prepares={}\")\n                             .format(\n                                prepare_id,\n                                len(self.all_prepares)))\n\n                return self.build_response(\n                    status=SUCCESS,\n                    error=\"\",\n                    data=prepare_data)\n            else:\n                err_msg = (\"failed with \"\n                           \"status_code={} text={} reason={}\").format(\n                               response.status_code,\n                               response.text,\n                               response.reason)\n                if self.verbose:\n                    log.error(err_msg)\n                return self.build_response(\n                    status=ERROR,\n                    error=err_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait_for_prepare_to_finish(\n            self,\n            prepare_id,\n            sec_to_sleep=5.0,\n            max_retries=100000):\n        \"\"\"wait_for_prepare_to_finish\n\n        :param prepare_id: MLPrepare.id to wait on\n        :param sec_to_sleep: seconds to sleep during polling\n        :param max_retries: max retires until stopping\n        \"\"\"\n\n        not_done = True\n        retry_attempt = 1\n        while not_done:\n\n            if self.debug:\n                log.info((\"PREPSTATUS getting prepare.id={} details\")\n                         .format(\n                            prepare_id))\n\n            response = self.get_prepare_by_id(prepare_id)\n\n            if self.debug:\n                log.info((\"PREPSTATUS got prepare.id={} response={}\")\n                         .format(\n                            prepare_id,\n                            response))\n\n            if response[\"status\"] != SUCCESS:\n                log.error((\"PREPSTATUS failed to get prepare.id={} \"\n                           \"with error={}\")\n                          .format(\n                            prepare_id,\n                            response[\"error\"]))\n                return self.build_response(\n                    status=ERROR,\n                    error=response[\"error\"],\n                    data=response[\"data\"])\n            # stop if this failed getting the prepare details\n\n            prepare_data = response.get(\n                \"data\",\n                None)\n\n            if not prepare_data:\n                return self.build_response(\n                    status=ERROR,\n                    error=\"failed to find prepare dictionary in response\",\n                    data=response[\"data\"])\n\n            prepare_status = prepare_data[\"status\"]\n\n            if prepare_status == \"finished\" \\\n               or prepare_status == \"completed\":\n\n                not_done = False\n                return self.build_response(\n                    status=SUCCESS,\n                    error=\"\",\n                    data=prepare_data)\n            else:\n\n                retry_attempt += 1\n                if retry_attempt > max_retries:\n                    err_msg = (\"failed waiting \"\n                               \"for prepare.id={} to finish\").format(\n                                   prepare_id)\n                    log.error(err_msg)\n                    return self.build_response(\n                        status=ERROR,\n                        error=err_msg)\n                else:\n                    if self.verbose:\n                        if retry_attempt % 100 == 0:\n                            log.info((\"waiting on prepare.id={} retry={}\")\n                                     .format(\n                                        prepare_id,\n                                        retry_attempt))\n                    # if logging just to show this is running\n                    time.sleep(sec_to_sleep)", "response": "wait_for_prepare_to_finish returns a response object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_comment_object(self):\n        if not self.is_valid():\n            raise ValueError(\n                \"get_comment_object may only be called on valid forms\")\n\n        CommentModel = self.get_comment_model()\n        new = CommentModel(**self.get_comment_create_data())\n\n        user_model = get_user_model()\n        try:\n            user = user_model.objects.get(username=new.user_name)\n            if not user.is_staff:\n                new = self.check_for_duplicate_comment(new)\n        except user_model.DoesNotExist:\n            # post_molo_comment may have set the username to 'Anonymous'\n            new = self.check_for_duplicate_comment(new)\n\n        return new", "response": "Returns a CommentModel object based on the information in the form of a Request object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef boot(app_name) -> Rinzler:\n    app = Rinzler(app_name)\n    app.log.info(\"App booted =)\")\n\n    return app", "response": "Boots an application into the Rinzler app."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a url that maps a route namespace with the given params and point it s requests to the especified controller.", "response": "def mount(self, route: str, controller: callable) -> url:\n        \"\"\"\n        Maps a route namespace with the given params and point it's requests to the especified controller.\n        :param route: str Namespace route to be mapped\n        :param controller: callback Controller callable to map end-points\n        :rtype: url\n        \"\"\"\n        if issubclass(controller, TemplateView):\n            return url(\n                r\"%s\" % route,\n                Router(self, route, controller).handle\n            )\n        else:\n            raise TypeError(\"The controller %s must be a subclass of %s\" % (\n                    controller, TemplateView\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the authentication service for this object.", "response": "def set_auth_service(self, auth_service: BaseAuthService):\n        \"\"\"\n        Sets the authentication service\n        :param auth_service: BaseAuthService Authentication service\n        :raises: TypeError If the auth_service object is not a subclass of rinzler.auth.BaseAuthService\n        :rtype: Rinzler\n        \"\"\"\n        if issubclass(auth_service.__class__, BaseAuthService):\n            self.auth_service = auth_service\n            return self\n        else:\n            raise TypeError(\"Your auth service object must be a subclass of rinzler.auth.BaseAuthService.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle(self, request: HttpRequest) -> HttpResponse:\n        self.__request_start = datetime.now()\n        self.__request = request\n        self.__uri = request.path[1:]\n        self.__method = request.method\n\n        # Initializes the callable controller and call it's connect method to get the mapped end-points.\n        controller: RouteMapping = self.__controller().connect(self.app)\n\n        self.__end_points = controller.get_routes()\n\n        indent = self.get_json_ident(request.META)\n\n        if self.set_end_point_uri() is False:\n            return self.set_response_headers(self.no_route_found(self.__request).render(indent))\n\n        response = HttpResponse(None)\n        try:\n            response = self.exec_route_callback()\n        except RinzlerHttpException as e:\n            client.captureException()\n            self.app.log.error(f\"< {e.status_code}\", exc_info=True)\n            response = Response(None, status=e.status_code)\n        except RequestDataTooBig:\n            client.captureException()\n            self.app.log.error(\"< 413\", exc_info=True)\n            response = Response(None, status=413)\n        except BaseException:\n            client.captureException()\n            self.app.log.error(\"< 500\", exc_info=True)\n            response = Response(None, status=500)\n        finally:\n            if type(response) == Response:\n                return self.set_response_headers(response.render(indent))\n            else:\n                return self.set_response_headers(response)", "response": "Handles the request and returns the response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the route callback.", "response": "def exec_route_callback(self) -> Response or object:\n        \"\"\"\n        Executes the resolved end-point callback, or its fallback\n        :rtype: Response or object\n        \"\"\"\n        if self.__method.lower() in self.__end_points:\n            for bound in self.__end_points[self.__method.lower()]:\n\n                route = list(bound)[0]\n                expected_params = self.get_url_params(route)\n                actual_params = self.get_url_params(self.get_end_point_uri())\n\n                if self.request_matches_route(self.get_end_point_uri(), route):\n                    self.app.log.info(\"> {0} {1}\".format(self.__method, self.__uri))\n                    if self.authenticate(route, actual_params):\n                        self.app.log.debug(\n                            \"%s(%d) %s\" % (\"body \", len(self.__request.body), self.__request.body.decode('utf-8'))\n                        )\n                        pattern_params = self.get_callback_pattern(expected_params, actual_params)\n                        self.app.request_handle_time = (\n                            lambda d: int((d.days * 24 * 60 * 60 * 1000) + (d.seconds * 1000) + (d.microseconds / 1000))\n                        )(datetime.now() - self.__request_start)\n\n                        return bound[route](self.__request, self.app, **pattern_params)\n                    else:\n                        raise AuthException(\"Authentication failed.\")\n\n        if self.__method == \"OPTIONS\":\n            self.app.log.info(\"Route matched: {0} {1}\".format(self.__method, self.__uri))\n            return self.default_route_options()\n\n        if self.__route == '' and self.__uri == '':\n            return self.welcome_page()\n        else:\n            return self.no_route_found(self.__request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine whether a route matches the expected route or not.", "response": "def request_matches_route(self, actual_route: str, expected_route: str):\n        \"\"\"\n        Determines whether a route matches the actual requested route or not\n        :param actual_route str\n        :param expected_route\n        :rtype: Boolean\n        \"\"\"\n        expected_params = self.get_url_params(expected_route)\n        actual_params = self.get_url_params(actual_route)\n        i = 0\n\n        if len(expected_params) == len(actual_params):\n            for param in actual_params:\n                if expected_params[i][0] != \"{\":\n                    if param != expected_params[i]:\n                        return False\n                i += 1\n        else:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticate(self, bound_route, actual_params) -> bool:\n        if self.__auth_service is not None:\n            auth_route = \"{0}_{1}{2}\".format(self.__method, self.__route, bound_route)\n            auth_data = self.__auth_service.authenticate(self.__request, auth_route, actual_params)\n            if auth_data is True:\n                self.app.auth_data = self.__auth_service.auth_data\n            else:\n                return False\n\n        return True", "response": "Runs the pre - defined authenticaton service\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_callback_pattern(expected_params, actual_params):\n        pattern = dict()\n        key = 0\n        for exp_param in expected_params:\n            if exp_param[0] == '{' and exp_param[-1:] == '}':\n                pattern[exp_param[1:-1]] = actual_params[key]\n            key = key + 1\n        return pattern", "response": "Assembles a dictionary whith the parameters schema defined for this route\n        and the actual url parameters schema defined for this route\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the parameters of the current url", "response": "def get_url_params(end_point: str) -> list:\n        \"\"\"\n        Gets route parameters as dictionary\n        :param end_point str target route\n        :rtype: list\n        \"\"\"\n        var_params = end_point.split('/')\n\n        if len(var_params) == 1 and var_params[0] == '':\n            return []\n\n        elif len(var_params) == 1 and var_params[0] != '':\n            return [var_params[0]]\n        else:\n            params = list()\n            for param in var_params:\n                if len(param) > 0:\n                    params.append(param)\n            return params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the end - point URI of the accessed URL.", "response": "def set_end_point_uri(self) -> bool:\n        \"\"\"\n        Extracts the route from the accessed URL and sets it to __end_point_uri\n        :rtype: bool\n        \"\"\"\n        expected_parts = self.__route.split(\"/\")\n        actual_parts = self.__uri.split(\"/\")\n\n        i = 0\n        for part in expected_parts:\n            if part != actual_parts[i]:\n                return False\n            i = i + 1\n\n        uri_prefix = len(self.__route)\n        self.__end_point_uri = self.__uri[uri_prefix:]\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef no_route_found(self, request):\n        response_obj = OrderedDict()\n        response_obj[\"status\"] = False\n        response_obj[\"exceptions\"] = {\n            \"message\": \"No route found for {0} {1}\".format(self.__method, self.__uri),\n        }\n        response_obj[\"request\"] = {\n            \"method\": self.__method,\n            \"path_info\": self.__uri,\n            \"content\": request.body.decode(\"utf-8\")\n        }\n        response_obj[\"message\"] = \"We are sorry, but something went terribly wrong.\"\n\n        return Response(response_obj, content_type=\"application/json\", status=404, charset=\"utf-8\")", "response": "Default callback for route not found"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a welcome page with the application name and the application name.", "response": "def welcome_page(self):\n        \"\"\"\n        Defaulf welcome page when the route / is note mapped yet\n        :rtype: HttpResponse\n        \"\"\"\n        message = \"HTTP/1.1 200 OK RINZLER FRAMEWORK\"\n        return HttpResponse(\n            \"<center><h1>{0}({1})</h1></center>\".format(message, self.app.app_name),\n            content_type=\"text/html\", charset=\"utf-8\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef default_route_options():\n        response_obj = OrderedDict()\n\n        response_obj[\"status\"] = True\n        response_obj[\"data\"] = \"Ok\"\n\n        return Response(response_obj, content_type=\"application/json\", charset=\"utf-8\")", "response": "Default callback for OPTIONS request"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend default headers to every response returned by the API.", "response": "def set_response_headers(self, response: HttpResponse) -> HttpResponse:\n        \"\"\"\n        Appends default headers to every response returned by the API\n        :param response HttpResponse\n        :rtype: HttpResponse\n        \"\"\"\n        public_name = os.environ.get('SERVER_PUBLIC_NAME')\n        response_headers = {\n            'access-control-allow-headers': self.app.allowed_headers,\n            'access-control-allow-methods': self.app.allowed_methods,\n            'access-control-allow-origin': self.app.allowed_origins,\n            'access-control-allow-credentials': True,\n            'www-authenticate': \"Bearer\",\n            'server-public-name': public_name if public_name else \"No one\",\n            'user-info': \"Rinzler Framework rulez!\"\n        }\n\n        response_headers.update(self.app.default_headers)\n\n        for key in response_headers:\n            response[key] = response_headers[key]\n\n        status = response.status_code\n        if status != 404:\n            self.app.log.info(\"< {0}\".format(status))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_json_ident(request_headers: dict) -> int:\n        if 'HTTP_USER_AGENT' in request_headers:\n            indent = 2 if re.match(\"[Mozilla]{7}\", request_headers['HTTP_USER_AGENT']) else 0\n        else:\n            indent = 0\n\n        return indent", "response": "Determines whether the JSON response should be indented or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if all dct values pass f", "response": "def all_pass_dict(f, dct):\n    \"\"\"\n        Returns true if all dct values pass f\n    :param f: binary lambda predicate\n    :param dct:\n    :return: True or false\n    \"\"\"\n    return all(map_with_obj_to_values(\n        lambda key, value: f(key, value),\n        dct\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value of item_path with a default value.", "response": "def item_path_or(default, keys, dict_or_obj):\n    \"\"\"\n    Optional version of item_path with a default value. keys can be dict keys or object attributes, or a combination\n    :param default:\n    :param keys: List of keys or dot-separated string\n    :param dict_or_obj: A dict or obj\n    :return:\n    \"\"\"\n    if not keys:\n        raise ValueError(\"Expected at least one key, got {0}\".format(keys))\n    resolved_keys = keys.split('.') if isinstance(str, keys) else keys\n    current_value = dict_or_obj\n    for key in resolved_keys:\n        current_value = prop_or(default, key, default_to({}, current_value))\n    return current_value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef item_str_path(keys, dct):\n    return item_path(map(lambda segment: int(segment) if isint(segment) else segment, keys.split('.')), dct)", "response": "Given a string of path segments separated by. splits them into an array of Int strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef item_str_path_or(default, keys, dct):\n    return item_path_or(default, map(lambda segment: int(segment) if isint(segment) else segment, keys.split('.')), dct)", "response": "Given a string of path segments separated by. splits them into an array. Int strings are converted to numbers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has(prop, object_or_dct):\n    return prop in object_or_dct if isinstance(dict, object_or_dct) else hasattr(object_or_dct, prop)", "response": "Implementation of ramda has"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef omit_deep(omit_props, dct):\n\n    omit_partial = omit_deep(omit_props)\n\n    if isinstance(dict, dct):\n        # Filter out keys and then recurse on each value that wasn't filtered out\n        return map_dict(omit_partial, compact_dict(omit(omit_props, dct)))\n    if isinstance((list, tuple), dct):\n        # run omit_deep on each value\n        return map(omit_partial, dct)\n    # scalar\n    return dct", "response": "Implementation of omit that recurses on each key in dct and returns a new dict with omit_props removed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_keys_deep(f, dct):\n    return _map_deep(lambda k, v: [f(k, v), v], dct)", "response": "Implementation of map that recurses on keys at every level of dict and returns a modified dct with matching props"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _map_deep(f, dct):\n\n    if isinstance(dict, dct):\n        return map_key_values(lambda k, v: f(k, _map_deep(f, v)), dct)\n    elif isinstance((list, tuple), dct):\n        # Call each value with the index as the key. Since f returns a key value discard the key that it returns\n        # Even if this is called with map_keys_deep we can't manipulate index values here\n        return map(lambda iv: f(iv[0], _map_deep(f, iv[1]))[1], enumerate(dct))\n    # scalar\n    return dct", "response": "A recursive version of map_deep that returns a dict with the keys and values as keys and the values as values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dict_matches_params_deep(params_dct, dct):\n\n    def recurse_if_param_exists(params, key, value):\n        \"\"\"\n            If a param[key] exists, recurse. Otherwise return True since there is no param to contest value\n        :param params:\n        :param key:\n        :param value:\n        :return:\n        \"\"\"\n        return dict_matches_params_deep(\n            prop(key, params),\n            value\n        ) if has(key, params) else True\n\n    def recurse_if_array_param_exists(params, index, value):\n        \"\"\"\n            If a param[key] exists, recurse. Otherwise return True since there is no param to contest value\n        :param params:\n        :param index:\n        :param value:\n        :return:\n        \"\"\"\n        return dict_matches_params_deep(\n            params[index],\n            value\n        ) if isinstance((list, tuple), params_dct) and index < length(params_dct) else True\n\n    if isinstance(dict, dct):\n        # Filter out keys and then recurse on each value\n        return all_pass_dict(\n            # Recurse on each value if there is a corresponding filter_dct[key]. If not we pass\n            lambda key, value: recurse_if_param_exists(params_dct, key, value),\n            # We shallow merge, giving dct priority with (hopefully) unmatchable values\n            merge(map_with_obj(lambda k, v: 1 / (-e * pi), params_dct), dct)\n        )\n\n    if isinstance((list, tuple), dct):\n        if isinstance((list, tuple), params_dct) and length(dct) < length(params_dct):\n            # if there are more param items then dct items fail\n            return False\n        # run map_deep on each value\n        return all(map(\n            lambda ivalue: recurse_if_array_param_exists(params_dct, *ivalue),\n            enumerate(dct)\n        ))\n    # scalar. Not that anything not truthy, False, None, 0, are considered equal\n    return params_dct == dct", "response": "Returns True if dict matches params_dct."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\njoin a sequence of strings with a list of items.", "response": "def join(strin, items):\n    \"\"\"\n        Ramda implementation of join\n    :param strin:\n    :param items:\n    :return:\n    \"\"\"\n    return strin.join(map(lambda item: str(item), items))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_with_obj(f, dct):\n    f_dict = {}\n    for k, v in dct.items():\n        f_dict[k] = f(k, v)\n    return f_dict", "response": "Implementation of Ramda s mapObjIndexed without the final argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_keys(f, dct):\n    f_dict = {}\n    for k, v in dct.items():\n        f_dict[f(k)] = v\n    return f_dict", "response": "Returns a new dct with keys that are not modified"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_keys_with_obj(f, dct):\n    f_dict = {}\n    for k, v in dct.items():\n        f_dict[f(k, v)] = v\n    return f_dict", "response": "Returns a dict with keys and values mapped to the keys in dct."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_deep(dct1, dct2, merger=None):\n    my_merger = merger or Merger(\n        # pass in a list of tuples,with the\n        # strategies you are looking to apply\n        # to each type.\n        [\n            (list, [\"append\"]),\n            (dict, [\"merge\"])\n        ],\n        # next, choose the fallback strategies,\n        # applied to all other types:\n        [\"override\"],\n        # finally, choose the strategies in\n        # the case where the types conflict:\n        [\"override\"]\n    )\n    return my_merger.merge(dct1, dct2)", "response": "Merge two dict objects into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshallowing merge all the dcts together", "response": "def merge_all(dcts):\n    \"\"\"\n        Shallow merge all the dcts\n    :param dcts:\n    :return:\n    \"\"\"\n    return reduce(\n        lambda accum, dct: merge(accum, dct),\n        dict(),\n        dcts\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_pairs_to_array_values(pairs):\n    result = {}\n    for pair in pairs:\n        result[pair[0]] = concat(prop_or([], pair[0], result), [pair[1]])\n    return result", "response": "Like from_pairs but combines duplicate key values into arrays\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the given prop of each item in the list", "response": "def map_prop_value_as_index(prp, lst):\n    \"\"\"\n        Returns the given prop of each item in the list\n    :param prp:\n    :param lst:\n    :return:\n    \"\"\"\n    return from_pairs(map(lambda item: (prop(prp, item), item), lst))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key_string_to_lens_path(key_string):\n    return map(\n        if_else(\n            isinstance(int),\n            # convert to int\n            lambda s: int(s),\n            # Leave the string alone\n            identity\n        ),\n        key_string.split('.')\n    )", "response": "Converts a dot - separated key string like foo. bar. 0. wopper to a list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimulating R. view with a lens_path since we don t have lens functions", "response": "def fake_lens_path_view(lens_path, obj):\n    \"\"\"\n    Simulates R.view with a lens_path since we don't have lens functions\n    :param lens_path: Array of string paths\n    :param obj: Object containing the given path\n    :return: The value at the path or None\n    \"\"\"\n    segment = head(lens_path)\n    return if_else(\n        both(lambda _: identity(segment), has(segment)),\n        # Recurse on the rest of the path\n        compose(fake_lens_path_view(tail(lens_path)), getitem(segment)),\n        # Give up\n        lambda _: None\n    )(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsimulate R. set with a lens_path and a value at the given object.", "response": "def fake_lens_path_set(lens_path, value, obj):\n    \"\"\"\n    Simulates R.set with a lens_path since we don't have lens functions\n    :param lens_path: Array of string paths\n    :param value: The value to set at the lens path\n    :param obj: Object containing the given path\n    :return: The value at the path or None\n    \"\"\"\n    segment = head(lens_path)\n    obj_copy = copy.copy(obj)\n\n    def set_array_index(i, v, l):\n        # Fill the array with None up to the given index and set the index to v\n        try:\n            l[i] = v\n        except IndexError:\n            for _ in range(i - len(l) + 1):\n                l.append(None)\n            l[i] = v\n\n    if not (length(lens_path) - 1):\n        # Done\n        new_value = value\n    else:\n        # Find the value at the path or create a {} or [] at obj[segment]\n        found_or_created = item_path_or(\n            if_else(\n                lambda segment: segment.isnumeric(),\n                always([]),\n                always({})\n            )(head(tail(lens_path))),\n            segment,\n            obj\n        )\n        # Recurse on the rest of the path\n        new_value = fake_lens_path_set(tail(lens_path), value, found_or_created)\n\n    # Set or replace\n    if segment.isnumeric():\n        set_array_index(int(segment), new_value, obj_copy)\n    else:\n        obj_copy[segment] = new_value\n    return obj_copy"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unflatten_dct(obj):\n\n    def reduce_func(accum, key_string_and_value):\n        key_string = key_string_and_value[0]\n        value = key_string_and_value[1]\n        item_key_path = key_string_to_lens_path(key_string)\n        # All but the last segment gives us the item container len\n        container_key_path = init(item_key_path)\n        container = unless(\n            # If the path has any length (not []) and the value is set, don't do anything\n            both(always(length(container_key_path)), fake_lens_path_view(container_key_path)),\n            # Else we are at the top level, so use the existing accum or create a [] or {}\n            # depending on if our item key is a number or not\n            lambda x: default_to(\n                if_else(\n                    lambda segment: segment.isnumeric(),\n                    always([]),\n                    always({})\n                )(head(item_key_path))\n            )(x)\n        )(accum)\n        # Finally set the container at the itemLensPath\n        return fake_lens_path_set(\n            item_key_path,\n            value,\n            container\n        )\n\n    return compose(\n        reduce(\n            reduce_func,\n            # null initial value\n            None\n        ),\n        to_pairs\n    )(obj)", "response": "Unflattens the object into a single object that is a dictionary with the keys of the items in the tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ppj(json_data):\n    return str(json.dumps(\n                json_data,\n                sort_keys=True,\n                indent=4,\n                separators=(',', ': ')))", "response": "Pretty print a dictionary to a file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride change view to add extra context enabling moderate tool.", "response": "def change_view(self, request, object_id, form_url='', extra_context=None):\n        \"\"\"\n        Override change view to add extra context enabling moderate tool.\n        \"\"\"\n        context = {\n            'has_moderate_tool': True\n        }\n        if extra_context:\n            context.update(extra_context)\n        return super(AdminModeratorMixin, self).change_view(\n            request=request,\n            object_id=object_id,\n            form_url=form_url,\n            extra_context=context\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urls(self):\n        from django.conf.urls import url\n        urls = super(AdminModeratorMixin, self).get_urls()\n        info = self.model._meta.app_label, self.model._meta.model_name\n        return [\n            url(r'^(.+)/moderate/$',\n                self.admin_site.admin_view(self.moderate_view),\n                name='%s_%s_moderate' % info),\n        ] + urls", "response": "Add aditional moderate url."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders a HttpResponse for the ongoing request", "response": "def render(self, indent=0):\n        \"\"\"\n        Renders a HttpResponse for the ongoing request\n        :param indent int\n        :rtype: HttpResponse\n        \"\"\"\n        self.__indent = indent\n        return HttpResponse(\n            str(self), content_type=self.__content_type, charset=self.__charset, **self.__kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbind a GET route with the given callback", "response": "def get(self, route: str(), callback: object()):\n        \"\"\"\n        Binds a GET route with the given callback \n        :rtype: object\n        \"\"\"\n        self.__set_route('get', {route: callback})\n        return RouteMapping"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, route: str(), callback: object()):\n        self.__set_route('post', {route: callback})\n        return RouteMapping", "response": "Binds a POST route with the given callback"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put(self, route: str(), callback: object()):\n        self.__set_route('put', {route: callback})\n        return RouteMapping", "response": "Binds a PUT route with the given callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef patch(self, route: str(), callback: object()):\n        self.__set_route('patch', {route: callback})\n        return RouteMapping", "response": "Binds a PATCH route with the given callback"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbind a PUT route with the given callback", "response": "def delete(self, route: str(), callback: object()):\n        \"\"\"\n        Binds a PUT route with the given callback\n        :rtype: object\n        \"\"\"\n        self.__set_route('delete', {route: callback})\n        return RouteMapping"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef head(self, route: str(), callback: object()):\n        self.__set_route('head', {route: callback})\n        return RouteMapping", "response": "Binds a HEAD route with the given callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbind a OPTIONS route with the given callback", "response": "def options(self, route: str(), callback: object()):\n        \"\"\"\n        Binds a OPTIONS route with the given callback\n        :rtype: object\n        \"\"\"\n        self.__set_route('options', {route: callback})\n        return RouteMapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __set_route(self, type_route, route):\n        if type_route in self.__routes:\n            if not self.verify_route_already_bound(type_route, route):\n                self.__routes[type_route].append(route)\n        else:\n            self.__routes[type_route] = [route]\n        return RouteMapping", "response": "Sets the given type_route and route to the route mapping."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string identifying the operating system of the application .", "response": "def operating_system():\n    \"\"\"Return a string identifying the operating system the application\n    is running on.\n\n    :rtype: str\n\n    \"\"\"\n    if platform.system() == 'Darwin':\n        return 'OS X Version %s' % platform.mac_ver()[0]\n    distribution = ' '.join(platform.linux_distribution()).strip()\n    os_platform = platform.platform(True, True)\n    if distribution:\n        os_platform += ' (%s)' % distribution\n    return os_platform"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n        if self._is_already_running():\n            LOGGER.error('Is already running')\n            sys.exit(1)\n        try:\n            self._daemonize()\n            self.controller.start()\n        except Exception as error:\n            sys.stderr.write('\\nERROR: Startup of %s Failed\\n.' %\n                             sys.argv[0].split('/')[-1])\n            exception_log = self._get_exception_log_path()\n            if exception_log:\n                with open(exception_log, 'a') as handle:\n                    timestamp = datetime.datetime.now().isoformat()\n                    handle.write('{:->80}\\n'.format(' [START]'))\n                    handle.write('%s Exception [%s]\\n' % (sys.argv[0],\n                                                          timestamp))\n                    handle.write('{:->80}\\n'.format(' [INFO]'))\n                    handle.write('Interpreter: %s\\n' % sys.executable)\n                    handle.write('CLI arguments: %s\\n' % ' '.join(sys.argv))\n                    handle.write('Exception: %s\\n' % error)\n                    handle.write('Traceback:\\n')\n                    output = traceback.format_exception(*sys.exc_info())\n                    _dev_null = [(handle.write(line),\n                                 sys.stdout.write(line)) for line in output]\n                    handle.write('{:->80}\\n'.format(' [END]'))\n                    handle.flush()\n                sys.stderr.write('\\nException log: %s\\n\\n' % exception_log)\n            sys.exit(1)", "response": "Daemonize if the process is not already running."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the group id that the daemon will run with", "response": "def gid(self):\n        \"\"\"Return the group id that the daemon will run with\n\n        :rtype: int\n\n        \"\"\"\n        if not self._gid:\n            if self.controller.config.daemon.group:\n                self._gid = grp.getgrnam(self.config.daemon.group).gr_gid\n            else:\n                self._gid = os.getgid()\n        return self._gid"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the user id that the process will run as", "response": "def uid(self):\n        \"\"\"Return the user id that the process will run as\n\n        :rtype: int\n\n        \"\"\"\n        if not self._uid:\n            if self.config.daemon.user:\n                self._uid = pwd.getpwnam(self.config.daemon.user).pw_uid\n            else:\n                self._uid = os.getuid()\n        return self._uid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nforking into a background process and setup the process.", "response": "def _daemonize(self):\n        \"\"\"Fork into a background process and setup the process, copied in part\n        from http://www.jejik.com/files/examples/daemon3x.py\n\n        \"\"\"\n        LOGGER.info('Forking %s into the background', sys.argv[0])\n\n        # Write the pidfile if current uid != final uid\n        if os.getuid() != self.uid:\n            fd = open(self.pidfile_path, 'w')\n            os.fchmod(fd.fileno(), 0o644)\n            os.fchown(fd.fileno(), self.uid, self.gid)\n            fd.close()\n\n        try:\n            pid = os.fork()\n            if pid > 0:\n                    sys.exit(0)\n        except OSError as error:\n                raise OSError('Could not fork off parent: %s', error)\n\n        # Set the user id\n        if self.uid != os.getuid():\n            os.setuid(self.uid)\n\n        # Set the group id\n        if self.gid != os.getgid():\n            try:\n                os.setgid(self.gid)\n            except OSError as error:\n                LOGGER.error('Could not set group: %s', error)\n\n        # Decouple from parent environment\n        os.chdir('/')\n        os.setsid()\n        os.umask(0o022)\n\n        # Fork again\n        try:\n            pid = os.fork()\n            if pid > 0:\n                sys.exit(0)\n        except OSError as error:\n            raise OSError('Could not fork child: %s', error)\n\n        # redirect standard file descriptors\n        sys.stdout.flush()\n        sys.stderr.flush()\n        si = open(os.devnull, 'r')\n        so = open(os.devnull, 'a+')\n        se = open(os.devnull, 'a+')\n        os.dup2(si.fileno(), sys.stdin.fileno())\n        os.dup2(so.fileno(), sys.stdout.fileno())\n        os.dup2(se.fileno(), sys.stderr.fileno())\n\n        # Automatically call self._remove_pidfile when the app exits\n        atexit.register(self._remove_pidfile)\n        self._write_pidfile()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the normalized path for the connection log raising an exception if it can not written to.", "response": "def _get_exception_log_path():\n        \"\"\"Return the normalized path for the connection log, raising an\n        exception if it can not written to.\n\n        :return: str\n\n        \"\"\"\n        app = sys.argv[0].split('/')[-1]\n        for exception_log in ['/var/log/%s.errors' % app,\n                              '/var/tmp/%s.errors' % app,\n                              '/tmp/%s.errors' % app]:\n            if os.access(path.dirname(exception_log), os.W_OK):\n                return exception_log\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_pidfile_path(self):\n        if self.config.daemon.pidfile:\n            pidfile = path.abspath(self.config.daemon.pidfile)\n            if not os.access(path.dirname(pidfile), os.W_OK):\n                raise ValueError('Cannot write to specified pid file path'\n                                 ' %s' % pidfile)\n            return pidfile\n        app = sys.argv[0].split('/')[-1]\n        for pidfile in ['%s/pids/%s.pid' % (os.getcwd(), app),\n                        '/var/run/%s.pid' % app,\n                        '/var/run/%s/%s.pid' % (app, app),\n                        '/var/tmp/%s.pid' % app,\n                        '/tmp/%s.pid' % app,\n                        '%s.pid' % app]:\n            if os.access(path.dirname(pidfile), os.W_OK):\n                return pidfile\n        raise OSError('Could not find an appropriate place for a pid file')", "response": "Return the normalized path for the pidfile"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_already_running(self):\n        # Look for the pidfile, if exists determine if the process is alive\n        pidfile = self._get_pidfile_path()\n        if os.path.exists(pidfile):\n            pid = open(pidfile).read().strip()\n            try:\n                os.kill(int(pid), 0)\n                sys.stderr.write('Process already running as pid # %s\\n' % pid)\n                return True\n            except OSError as error:\n                LOGGER.debug('Found pidfile, no process # %s', error)\n                os.unlink(pidfile)\n\n        # Check the os for a process that is not this one that looks the same\n        pattern = ' '.join(sys.argv)\n        pattern = '[%s]%s' % (pattern[0], pattern[1:])\n        try:\n            output = subprocess.check_output('ps a | grep \"%s\"' % pattern,\n                                             shell=True)\n        except AttributeError:\n            # Python 2.6\n            stdin, stdout, stderr = os.popen3('ps a | grep \"%s\"' % pattern)\n            output = stdout.read()\n        except subprocess.CalledProcessError:\n            return False\n        pids = [int(pid) for pid in (re.findall(r'^([0-9]+)\\s',\n                                                output.decode('latin-1')))]\n        if os.getpid() in pids:\n            pids.remove(os.getpid())\n        if not pids:\n            return False\n        if len(pids) == 1:\n            pids = pids[0]\n        sys.stderr.write('Process already running as pid # %s\\n' % pids)\n        return True", "response": "Check to see if the process is already running."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the pid file from the filesystem", "response": "def _remove_pidfile(self):\n        \"\"\"Remove the pid file from the filesystem\"\"\"\n        LOGGER.debug('Removing pidfile: %s', self.pidfile_path)\n        try:\n            os.unlink(self.pidfile_path)\n        except OSError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_pidfile(self):\n        LOGGER.debug('Writing pidfile: %s', self.pidfile_path)\n        with open(self.pidfile_path, \"w\") as handle:\n            handle.write(str(os.getpid()))", "response": "Write the pid file out with the process number in the pid file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_camel_case(snake_case_string):\n    parts = snake_case_string.lstrip('_').split('_')\n    return parts[0] + ''.join([i.title() for i in parts[1:]])", "response": "Convert a string from snake case to camel case."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_capitalized_camel_case(snake_case_string):\n    parts = snake_case_string.split('_')\n    return ''.join([i.title() for i in parts])", "response": "Convert a string from snake case to camel case with the first letter capitalized."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a string from camel case to snake case.", "response": "def to_snake_case(camel_case_string):\n    \"\"\"\n    Convert a string from camel case to snake case. From example, \"someVar\" would become \"some_var\".\n\n    :param camel_case_string: Camel-cased string to convert to snake case.\n    :return: Snake-cased version of camel_case_string.\n    \"\"\"\n    first_pass = _first_camel_case_regex.sub(r'\\1_\\2', camel_case_string)\n    return _second_camel_case_regex.sub(r'\\1_\\2', first_pass).lower()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keys_to_snake_case(camel_case_dict):\n    return dict((to_snake_case(key), value) for (key, value) in camel_case_dict.items())", "response": "Converts all keys in a dictionary to snake case."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_functions(awsclient):\n    client_lambda = awsclient.get_client('lambda')\n    response = client_lambda.list_functions()\n    for function in response['Functions']:\n        log.info(function['FunctionName'])\n        log.info('\\t' 'Memory: ' + str(function['MemorySize']))\n        log.info('\\t' 'Timeout: ' + str(function['Timeout']))\n        log.info('\\t' 'Role: ' + str(function['Role']))\n        log.info('\\t' 'Current Version: ' + str(function['Version']))\n        log.info('\\t' 'Last Modified: ' + str(function['LastModified']))\n        log.info('\\t' 'CodeSha256: ' + str(function['CodeSha256']))\n\n        log.info('\\n')\n    return 0", "response": "List the deployed lambda functions and print configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeploys a lambda function to the cloudwatch server", "response": "def deploy_lambda(awsclient, function_name, role, handler_filename,\n                  handler_function,\n                  folders, description, timeout, memory, subnet_ids=None,\n                  security_groups=None, artifact_bucket=None,\n                  zipfile=None,\n                  fail_deployment_on_unsuccessful_ping=False,\n                  runtime='python2.7', settings=None, environment=None,\n                  retention_in_days=None\n                  ):\n    \"\"\"Create or update a lambda function.\n\n    :param awsclient:\n    :param function_name:\n    :param role:\n    :param handler_filename:\n    :param handler_function:\n    :param folders:\n    :param description:\n    :param timeout:\n    :param memory:\n    :param subnet_ids:\n    :param security_groups:\n    :param artifact_bucket:\n    :param zipfile:\n    :param environment: environment variables\n    :param retention_in_days: retention time of the cloudwatch logs\n    :return: exit_code\n    \"\"\"\n    # TODO: the signature of this function is too big, clean this up\n    # also consolidate create, update, config and add waiters!\n    if lambda_exists(awsclient, function_name):\n        function_version = _update_lambda(awsclient, function_name,\n                                          handler_filename,\n                                          handler_function, folders, role,\n                                          description, timeout, memory,\n                                          subnet_ids, security_groups,\n                                          artifact_bucket=artifact_bucket,\n                                          zipfile=zipfile,\n                                          environment=environment\n                                          )\n    else:\n        if not zipfile:\n            return 1\n        log.info('buffer size: %0.2f MB' % float(len(zipfile) / 1000000.0))\n        function_version = _create_lambda(awsclient, function_name, role,\n                                          handler_filename, handler_function,\n                                          folders, description, timeout,\n                                          memory, subnet_ids, security_groups,\n                                          artifact_bucket, zipfile,\n                                          runtime=runtime,\n                                          environment=environment)\n    # configure cloudwatch logs\n    if retention_in_days:\n        log_group_name = '/aws/lambda/%s' % function_name\n        put_retention_policy(awsclient, log_group_name, retention_in_days)\n\n    pong = ping(awsclient, function_name, version=function_version)\n    if 'alive' in str(pong):\n        log.info(colored.green('Great you\\'re already accepting a ping ' +\n                            'in your Lambda function'))\n    elif fail_deployment_on_unsuccessful_ping and not 'alive' in pong:\n        log.info(colored.red('Pinging your lambda function failed'))\n        # we do not deploy alias and fail command\n        return 1\n    else:\n        log.info(colored.red('Please consider adding a reaction to a ' +\n                          'ping event to your lambda function'))\n    _deploy_alias(awsclient, function_name, function_version)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting zipfile contents to file.", "response": "def bundle_lambda(zipfile):\n    \"\"\"Write zipfile contents to file.\n\n    :param zipfile:\n    :return: exit_code\n    \"\"\"\n    # TODO have 'bundle.zip' as default config\n    if not zipfile:\n        return 1\n    with open('bundle.zip', 'wb') as zfile:\n        zfile.write(zipfile)\n    log.info('Finished - a bundle.zip is waiting for you...')\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_metrics(awsclient, name):\n    metrics = ['Duration', 'Errors', 'Invocations', 'Throttles']\n    client_cw = awsclient.get_client('cloudwatch')\n    for metric in metrics:\n        response = client_cw.get_metric_statistics(\n            Namespace='AWS/Lambda',\n            MetricName=metric,\n            Dimensions=[\n                {\n                    'Name': 'FunctionName',\n                    'Value': name\n                },\n            ],\n            # StartTime=datetime.now() + timedelta(days=-1),\n            # EndTime=datetime.now(),\n            StartTime=maya.now().subtract(days=1).datetime(),\n            EndTime=maya.now().datetime(),\n            Period=3600,\n            Statistics=[\n                'Sum',\n            ],\n            Unit=unit(metric)\n        )\n        log.info('\\t%s %s' % (metric,\n                           repr(aggregate_datapoints(response['Datapoints']))))\n    return 0", "response": "Print out cloudformation metrics for a lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_lambda(awsclient, function_name, events=None, delete_logs=False):\n    if events is not None:\n        unwire(awsclient, events, function_name, alias_name=ALIAS_NAME)\n    client_lambda = awsclient.get_client('lambda')\n    response = client_lambda.delete_function(FunctionName=function_name)\n    if delete_logs:\n        log_group_name = '/aws/lambda/%s' % function_name\n        delete_log_group(awsclient, log_group_name)\n\n    # TODO remove event source first and maybe also needed for permissions\n    log.info(json2table(response))\n    return 0", "response": "Delete a lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_lambda_deprecated(awsclient, function_name, s3_event_sources=[],\n                             time_event_sources=[], delete_logs=False):\n    # FIXME: mutable default arguments!\n    \"\"\"Deprecated: please use delete_lambda!\n\n    :param awsclient:\n    :param function_name:\n    :param s3_event_sources:\n    :param time_event_sources:\n    :param delete_logs:\n    :return: exit_code\n    \"\"\"\n    unwire_deprecated(awsclient, function_name, s3_event_sources=s3_event_sources,\n                      time_event_sources=time_event_sources,\n                      alias_name=ALIAS_NAME)\n    client_lambda = awsclient.get_client('lambda')\n    response = client_lambda.delete_function(FunctionName=function_name)\n    if delete_logs:\n        log_group_name = '/aws/lambda/%s' % function_name\n        delete_log_group(awsclient, log_group_name)\n\n    # TODO remove event source first and maybe also needed for permissions\n    log.info(json2table(response))\n    return 0", "response": "Deprecated. Please use delete_lambda!"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup_bundle():\n    paths = ['./vendored', './bundle.zip']\n    for path in paths:\n        if os.path.exists(path):\n            log.debug(\"Deleting %s...\" % path)\n            if os.path.isdir(path):\n                shutil.rmtree(path)\n            else:\n                os.remove(path)", "response": "Deletes files used for creating bundle."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a ping request to a lambda function.", "response": "def ping(awsclient, function_name, alias_name=ALIAS_NAME, version=None):\n    \"\"\"Send a ping request to a lambda function.\n\n    :param awsclient:\n    :param function_name:\n    :param alias_name:\n    :param version:\n    :return: ping response payload\n    \"\"\"\n    log.debug('sending ping to lambda function: %s', function_name)\n    payload = '{\"ramuda_action\": \"ping\"}'  # default to ping event\n    # reuse invoke\n    return invoke(awsclient, function_name, payload, invocation_type=None,\n                  alias_name=alias_name, version=version)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a ping request to a lambda function.", "response": "def invoke(awsclient, function_name, payload, invocation_type=None,\n           alias_name=ALIAS_NAME, version=None, outfile=None):\n    \"\"\"Send a ping request to a lambda function.\n\n    :param awsclient:\n    :param function_name:\n    :param payload:\n    :param invocation_type:\n    :param alias_name:\n    :param version:\n    :param outfile: write response to file\n    :return: ping response payload\n    \"\"\"\n    log.debug('invoking lambda function: %s', function_name)\n    client_lambda = awsclient.get_client('lambda')\n    if invocation_type is None:\n        invocation_type = 'RequestResponse'\n    if payload.startswith('file://'):\n        log.debug('reading payload from file: %s' % payload)\n        with open(payload[7:], 'r') as pfile:\n            payload = pfile.read()\n\n    if version:\n        response = client_lambda.invoke(\n            FunctionName=function_name,\n            InvocationType=invocation_type,\n            Payload=payload,\n            Qualifier=version\n        )\n    else:\n        response = client_lambda.invoke(\n            FunctionName=function_name,\n            InvocationType=invocation_type,\n            Payload=payload,\n            Qualifier=alias_name\n        )\n\n    results = response['Payload'].read()  # payload is a 'StreamingBody'\n    log.debug('invoke completed')\n    # write to file\n    if outfile:\n        with open(outfile, 'w') as ofile:\n            ofile.write(str(results))\n            ofile.flush()\n        return\n    else:\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logs(awsclient, function_name, start_dt, end_dt=None, tail=False):\n    log.debug('Getting cloudwatch logs for: %s', function_name)\n    log_group_name = '/aws/lambda/%s' % function_name\n\n    current_date = None\n    start_ts = datetime_to_timestamp(start_dt)\n    if end_dt:\n        end_ts = datetime_to_timestamp(end_dt)\n    else:\n        end_ts = None\n\n    # tail mode\n    # we assume that logs can arrive late but not out of order\n    # so we hold the timestamp of the last logentry and start the next iteration\n    # from there\n    while True:\n        logentries = filter_log_events(awsclient, log_group_name,\n                                       start_ts=start_ts, end_ts=end_ts)\n        if logentries:\n            for e in logentries:\n                actual_date, actual_time = decode_format_timestamp(e['timestamp'])\n                if current_date != actual_date:\n                    # print the date only when it changed\n                    current_date = actual_date\n                    log.info(current_date)\n                log.info('%s  %s' % (actual_time, e['message'].strip()))\n        if tail:\n            if logentries:\n                start_ts = logentries[-1]['timestamp'] + 1\n            time.sleep(2)\n            continue\n        break", "response": "Send a ping request to a lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the datetime string.", "response": "def __validate_datetime_string(self):\n        \"\"\"\n        This will require validating version string (such as \"3.3.5\").\n        A version string could be converted to a datetime value if this\n        validation is not executed.\n        \"\"\"\n\n        try:\n            try:\n                StrictVersion(self._value)\n                raise TypeConversionError(\n                    \"invalid datetime string: version string found {}\".format(self._value)\n                )\n            except ValueError:\n                pass\n        except TypeError:\n            raise TypeConversionError(\"invalid datetime string: type={}\".format(type(self._value)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction ADR Ra Rb Rc", "response": "def ADR(self, params):\n        \"\"\"\n        ADR Ra, [PC, #imm10_4]\n        ADR Ra, label\n\n        Load the address of label or the PC offset into Ra\n        Ra must be a low register\n        \"\"\"\n        # TODO may need to rethink how I do PC, may need to be byte alligned\n        # TODO This is wrong as each address is a word, not a byte. The filled value with its location (Do we want that, or the value at that location [Decompiled instruction])\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_WITH_BRACKETS, params)\n        except iarm.exceptions.ParsingError:\n            Ra, label = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n\n            # TODO the address must be within 1020 bytes of current PC\n            self.check_arguments(low_registers=(Ra,), label_exists=(label,))\n\n            def ADR_func():\n                self.register[Ra] = self.labels[label]  # TODO is this correct?\n\n            return ADR_func\n\n        self.check_arguments(low_registers=(Ra,), imm10_4=(Rc,))\n        if Rb != 'PC':\n            raise iarm.exceptions.IarmError(\"Second position argument is not PC: {}\".format(Rb))\n\n        def ADR_func():\n            self.register[Ra] = self.register[Rb] + self.convert_to_integer(Rc[1:])\n\n        return ADR_func"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef LDR(self, params):\n        # TODO definition for PC is Ra <- M[PC + Imm10_4], Imm10_4 = PC - label, need to figure this one out\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_WITH_BRACKETS, params)\n        except iarm.exceptions.ParsingError:\n            Ra, label_name = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n\n            if label_name.startswith('='):\n                # This is a pseudoinstructions\n                label_name = label_name[1:]\n                # TODO add check that label is a 32 bit number\n                # TODO This does not work on instruction loading. This interpreter follows a harvard like architecture,\n                # TODO while ARMv6-M (Cortex-M0+) is a Von Neumann architeture. Instructions will not be decompiled\n                self.check_arguments(low_registers=(Ra,))\n                if label_name in self.labels:\n                    label_value = self.labels[label_name]\n                elif label_name in self.equates:\n                    label_value = self.equates[label_name]\n                else:\n                    try:\n                        label_value = int(self.convert_to_integer(label_name))\n                    except ValueError:\n                        warnings.warn(iarm.exceptions.LabelDoesNotExist(\"Label `{}` does not exist or is not a parsable number. If it is a label, make sure it exists before running\".format(label_name)))\n                        label_value = None\n\n                if label_value is not None and int(label_value) % 4 != 0:\n                    # Make sure we are word aligned\n                    raise iarm.exceptions.IarmError(\"Memory access not word aligned; Immediate: {}\".format(int(label_value)))\n            elif label_name.startswith('[') and label_name.endswith(']'):\n                # TODO improve this\n                Rb = label_name[1:-1]\n                if Rb == 'SP' or Rb == 'R13':\n                    self.check_arguments(low_registers=(Ra,))\n                else:\n                    self.check_arguments(low_registers=(Ra, label_name))\n\n                def LDR_func():\n                    if self.memory[Rb] % 4 != 0:\n                        raise iarm.exceptions.HardFault(\n                            \"Memory access not word aligned; Register: {}  Immediate: {}\".format(self.register[Rb],\n                                                                                                 self.convert_to_integer(\n                                                                                                     Rc[1:])))\n                    self.register[Ra] = 0\n                    for i in range(4):\n                        self.register[Ra] |= (self.memory[self.register[Rb] + i] << (8 * i))\n                return LDR_func\n            else:\n                self.check_arguments(low_registers=(Ra,), label_exists=(label_name,))\n                try:\n                    label_value = self.labels[label_name]\n                    if label_value >= 1024:\n                        raise iarm.exceptions.IarmError(\"Label {} has value {} and is greater than 1020\".format(label_name, label_value))\n                    if label_value % 4 != 0:\n                        raise iarm.exceptions.IarmError(\"Label {} has value {} and is not word aligned\".format(label_name, label_value))\n                except KeyError:\n                    # Label doesn't exist, nothing we can do about that except maybe raise an exception now,\n                    # But we're avoiding that elsewhere, might as well avoid it here too\n                    pass\n\n            def LDR_func():\n                nonlocal label_value\n                # Since we can get a label that didn't exist in the creation step, We need to check it here\n                # TODO is there a way for label_value to not exist?\n                if label_value is None:\n                    # Try to get it again\n                    if label_name in self.labels:\n                        label_value = self.labels[label_name]\n                    elif label_name in self.equates:\n                        label_value = self.equates[label_name]\n\n                    # If it is still None, then it never got allocated\n                    if label_value is None:\n                        raise iarm.exceptions.IarmError(\"label `{}` does not exist. Was space allocated?\".format(label_name))\n                    # It does exist, make sure its word aligned\n                    if int(label_value) % 4 != 0:\n                        raise iarm.exceptions.IarmError(\"Memory access not word aligned; Immediate: {}\".format(int(label_value)))\n\n                try:\n                    self.register[Ra] = int(label_value)\n                except ValueError:\n                    # TODO Can we even get to this path now?\n                    self.register[Ra] = self.labels[label_name]\n\n            return LDR_func\n\n        if self.is_immediate(Rc):\n            if Rb == 'SP' or Rb == 'R15':\n                self.check_arguments(low_registers=(Ra,), imm10_4=(Rc,))\n            else:\n                self.check_arguments(low_registers=(Ra, Rb), imm7_4=(Rc,))\n\n            def LDR_func():\n                # TODO does memory read up?\n                if (self.register[Rb] + self.convert_to_integer(Rc[1:])) % 4 != 0:\n                    raise iarm.exceptions.HardFault(\"Memory access not word aligned; Register: {}  Immediate: {}\".format(self.register[Rb], self.convert_to_integer(Rc[1:])))\n                self.register[Ra] = 0\n                for i in range(4):\n                    self.register[Ra] |= (self.memory[self.register[Rb] + self.convert_to_integer(Rc[1:]) + i] << (8 * i))\n        else:\n            self.check_arguments(low_registers=(Ra, Rb, Rc))\n\n            def LDR_func():\n                # TODO does memory read up?\n                if (self.register[Rb] + self.register[Rc]) % 4 != 0:\n                    raise iarm.exceptions.HardFault(\n                        \"Memory access not word aligned; Register: {}  Immediate: {}\".format(self.register[Rb],\n                                                                                             self.convert_to_integer(\n                                                                                                 Rc[1:])))\n                self.register[Ra] = 0\n                for i in range(4):\n                    self.register[Ra] |= (self.memory[self.register[Rb] + self.register[Rc] + i] << (8 * i))\n\n        return LDR_func", "response": "Function LDR Load a word from memory into Ra Rb and Rc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef LDRH(self, params):\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_WITH_BRACKETS, params)\n        except iarm.exceptions.ParsingError:\n            # LDRB Rn, [Rk] translates to an offset of zero\n            Ra, Rb = self.get_two_parameters(r'\\s*([^\\s,]*),\\s*\\[([^\\s,]*)\\](,\\s*[^\\s,]*)*\\s*', params)\n            Rc = '#0'\n\n        if self.is_immediate(Rc):\n            self.check_arguments(low_registers=(Ra, Rb), imm6_2=(Rc,))\n\n            def LDRH_func():\n                # TODO does memory read up?\n                if (self.register[Rb]) % 2 != 0:\n                    raise iarm.exceptions.HardFault(\n                        \"Memory access not half word aligned; Register: {}  Immediate: {}\".format(self.register[Rb],\n                                                                                                  self.convert_to_integer(\n                                                                                                      Rc[1:])))\n                self.register[Ra] = 0\n                for i in range(2):\n                    self.register[Ra] |= (self.memory[self.register[Rb] + self.convert_to_integer(Rc[1:]) + i] << (8 * i))\n        else:\n            self.check_arguments(low_registers=(Ra, Rb, Rc))\n\n            def LDRH_func():\n                # TODO does memory read up?\n                if (self.register[Rb] + self.register[Rc]) % 2 != 0:\n                    raise iarm.exceptions.HardFault(\n                        \"Memory access not half word aligned; Register: {}  Immediate: {}\".format(self.register[Rb],\n                                                                                                  self.register[Rc]))\n                self.register[Ra] = 0\n                for i in range(2):\n                    self.register[Ra] |= (self.memory[self.register[Rb] + self.register[Rc] + i] << (8 * i))\n\n        return LDRH_func", "response": "LDRH Ra Rb Rc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop - function to pop from the stack into the list of registers", "response": "def POP(self, params):\n        \"\"\"\n        POP {RPopList}\n\n        Pop from the stack into the list of registers\n        List must contain only low registers or PC\n        \"\"\"\n        # TODO verify pop order\n        # TODO pop list is comma separate, right?\n        # TODO what registeres are allowed to POP to? Low Registers and PC\n        # TODO need to support ranges, ie {R2, R5-R7}\n        # TODO PUSH should reverse the list, not POP\n        RPopList = self.get_one_parameter(r'\\s*{(.*)}(.*)', params).split(',')\n        RPopList.reverse()\n        RPopList = [i.strip() for i in RPopList]\n\n        def POP_func():\n            for register in RPopList:\n                # Get 4 bytes\n                value = 0\n                for i in range(4):\n                    # TODO use memory width instead of constants\n                    value |= self.memory[self.register['SP'] + i] << (8 * i)\n\n                self.register[register] = value\n                self.register['SP'] += 4\n\n        return POP_func"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef PUSH(self, params):\n        # TODO what registers are allowed to PUSH to? Low registers and LR\n        # TODO PUSH should reverse the list, not POP\n        RPushList = self.get_one_parameter(r'\\s*{(.*)}(.*)', params).split(',')\n        RPushList = [i.strip() for i in RPushList]\n        # TODO should we make sure the register exists? probably not\n\n        def PUSH_func():\n            for register in RPushList:\n                self.register['SP'] -= 4\n\n                for i in range(4):\n                    # TODO is this the same as with POP?\n                    self.memory[self.register['SP'] + i] = ((self.register[register] >> (8 * i)) & 0xFF)\n\n        return PUSH_func", "response": "function to push to the stack from a list of registers and LR\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a function that stores multiple STM registers into memory.", "response": "def STM(self, params):\n        \"\"\"\n        STM Ra!, {RLoList}\n\n        Store multiple registers into memory\n        \"\"\"\n        # TODO what registers can be stored?\n        Ra, RLoList = self.get_two_parameters(r'\\s*([^\\s,]*)!,\\s*{(.*)}(.*)', params).split(',')\n        RLoList = RLoList.split(',')\n        RLoList = [i.strip() for i in RLoList]\n\n        self.check_arguments(low_registers=[Ra] + RLoList)\n\n        def STM_func():\n            for i in range(len(RLoList)):\n                for j in range(4):\n                    self.memory[self.register[Ra] + 4*i + j] = ((self.register[RLoList[i]] >> (8 * j)) & 0xFF)\n            self.register[Ra] += 4*len(RLoList)\n\n        return STM_func"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef STR(self, params):\n        Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_WITH_BRACKETS, params)\n\n        if self.is_immediate(Rc):\n            if Rb == 'SP' or Rb == 'FP':\n                self.check_arguments(low_registers=(Ra,), imm10_4=(Rc,))\n            else:\n                self.check_arguments(low_registers=(Ra, Rb), imm7_4=(Rc,))\n\n            def STR_func():\n                for i in range(4):\n                    self.memory[self.register[Rb] + self.convert_to_integer(Rc[1:]) + i] = ((self.register[Ra] >> (8 * i)) & 0xFF)\n        else:\n            self.check_arguments(low_registers=(Ra, Rb, Rc))\n\n            def STR_func():\n                for i in range(4):\n                    self.memory[self.register[Rb] + self.register[Rc] + i] = ((self.register[Ra] >> (8 * i)) & 0xFF)\n\n        return STR_func", "response": "STR Ra Rb and Rc"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _stop_ec2_instances(awsclient, ec2_instances, wait=True):\n    if len(ec2_instances) == 0:\n        return\n    client_ec2 = awsclient.get_client('ec2')\n\n    # get running instances\n    running_instances = all_pages(\n        client_ec2.describe_instance_status,\n        {\n            'InstanceIds': ec2_instances,\n            'Filters': [{\n                'Name': 'instance-state-name',\n                'Values': ['pending', 'running']\n            }]\n        },\n        lambda r: [i['InstanceId'] for i in r.get('InstanceStatuses', [])],\n    )\n\n    if running_instances:\n        log.info('Stopping EC2 instances: %s', running_instances)\n        client_ec2.stop_instances(InstanceIds=running_instances)\n\n        if wait:\n            # wait for instances to stop\n            waiter_inst_stopped = client_ec2.get_waiter('instance_stopped')\n            waiter_inst_stopped.wait(InstanceIds=running_instances)", "response": "Helper to stop EC2 instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _start_ec2_instances(awsclient, ec2_instances, wait=True):\n    if len(ec2_instances) == 0:\n        return\n    client_ec2 = awsclient.get_client('ec2')\n\n    # get stopped instances\n    stopped_instances = all_pages(\n        client_ec2.describe_instance_status,\n        {\n            'InstanceIds': ec2_instances,\n            'Filters': [{\n                'Name': 'instance-state-name',\n                'Values': ['stopping', 'stopped']\n            }],\n            'IncludeAllInstances': True\n        },\n        lambda r: [i['InstanceId'] for i in r.get('InstanceStatuses', [])],\n    )\n\n    if stopped_instances:\n        # start all stopped instances\n        log.info('Starting EC2 instances: %s', stopped_instances)\n        client_ec2.start_instances(InstanceIds=stopped_instances)\n\n        if wait:\n            # wait for instances to come up\n            waiter_inst_running = client_ec2.get_waiter('instance_running')\n            waiter_inst_running.wait(InstanceIds=stopped_instances)\n\n            # wait for status checks\n            waiter_status_ok = client_ec2.get_waiter('instance_status_ok')\n            waiter_status_ok.wait(InstanceIds=stopped_instances)", "response": "Helper function to start EC2 instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops an existing stack on AWS cloud.", "response": "def stop_stack(awsclient, stack_name, use_suspend=False):\n    \"\"\"Stop an existing stack on AWS cloud.\n\n    :param awsclient:\n    :param stack_name:\n    :param use_suspend: use suspend and resume on the autoscaling group\n    :return: exit_code\n    \"\"\"\n    exit_code = 0\n\n    # check for DisableStop\n    #disable_stop = conf.get('deployment', {}).get('DisableStop', False)\n    #if disable_stop:\n    #    log.warn('\\'DisableStop\\' is set - nothing to do!')\n    #else:\n    if not stack_exists(awsclient, stack_name):\n        log.warn('Stack \\'%s\\' not deployed - nothing to do!', stack_name)\n    else:\n        client_cfn = awsclient.get_client('cloudformation')\n        client_autoscaling = awsclient.get_client('autoscaling')\n        client_rds = awsclient.get_client('rds')\n        client_ec2 = awsclient.get_client('ec2')\n\n        resources = all_pages(\n            client_cfn.list_stack_resources,\n            { 'StackName': stack_name },\n            lambda r: r['StackResourceSummaries']\n        )\n\n        autoscaling_groups = [\n            r for r in resources\n            if r['ResourceType'] == 'AWS::AutoScaling::AutoScalingGroup'\n        ]\n\n        # lookup all types of scaling processes\n        #    [Launch, Terminate, HealthCheck, ReplaceUnhealthy, AZRebalance\n        #     AlarmNotification, ScheduledActions, AddToLoadBalancer]\n        response = client_autoscaling.describe_scaling_process_types()\n        scaling_process_types = [t['ProcessName'] for t in response.get('Processes', [])]\n\n        for asg in autoscaling_groups:\n            # find instances in autoscaling group\n            ec2_instances = all_pages(\n                client_autoscaling.describe_auto_scaling_instances,\n                {},\n                lambda r: [i['InstanceId'] for i in r.get('AutoScalingInstances', [])\n                           if i['AutoScalingGroupName'] == asg['PhysicalResourceId']],\n            )\n\n            if use_suspend:\n                # alternative implementation to speed up start\n                # only problem is that instances must survive stop & start\n                # suspend all autoscaling processes\n                log.info('Suspending all autoscaling processes for \\'%s\\'',\n                         asg['LogicalResourceId'])\n                response = client_autoscaling.suspend_processes(\n                    AutoScalingGroupName=asg['PhysicalResourceId'],\n                    ScalingProcesses=scaling_process_types\n                )\n\n                _stop_ec2_instances(awsclient, ec2_instances)\n            else:\n                # resize autoscaling group (min, max = 0)\n                log.info('Resize autoscaling group \\'%s\\' to minSize=0, maxSize=0',\n                         asg['LogicalResourceId'])\n                response = client_autoscaling.update_auto_scaling_group(\n                    AutoScalingGroupName=asg['PhysicalResourceId'],\n                    MinSize=0,\n                    MaxSize=0\n                )\n                if ec2_instances:\n                    running_instances = all_pages(\n                        client_ec2.describe_instance_status,\n                        {\n                            'InstanceIds': ec2_instances,\n                            'Filters': [{\n                                'Name': 'instance-state-name',\n                                'Values': ['pending', 'running']\n                            }]\n                        },\n                        lambda r: [i['InstanceId'] for i in r.get('InstanceStatuses', [])],\n                    )\n                    if running_instances:\n                        # wait for instances to terminate\n                        waiter_inst_terminated = client_ec2.get_waiter('instance_terminated')\n                        waiter_inst_terminated.wait(InstanceIds=running_instances)\n\n        # setting ECS desiredCount to zero\n        services = [\n            r for r in resources\n            if r['ResourceType'] == 'AWS::ECS::Service'\n        ]\n        if services:\n            template, parameters = _get_template_parameters(awsclient, stack_name)\n            _stop_ecs_services(awsclient, services, template, parameters)\n\n        # stopping ec2 instances\n        instances = [\n            r['PhysicalResourceId'] for r in resources\n            if r['ResourceType'] == 'AWS::EC2::Instance'\n        ]\n        _stop_ec2_instances(awsclient, instances)\n\n        # stopping db instances\n        db_instances = [\n            r['PhysicalResourceId'] for r in resources\n            if r['ResourceType'] == 'AWS::RDS::DBInstance'\n        ]\n        running_db_instances = _filter_db_instances_by_status(\n            awsclient, db_instances, ['available']\n        )\n        for db in running_db_instances:\n            log.info('Stopping RDS instance \\'%s\\'', db)\n            client_rds.stop_db_instance(DBInstanceIdentifier=db)\n\n    return exit_code"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_stack(awsclient, stack_name, use_suspend=False):\n    exit_code = 0\n\n    # check for DisableStop\n    #disable_stop = conf.get('deployment', {}).get('DisableStop', False)\n    #if disable_stop:\n    #    log.warn('\\'DisableStop\\' is set - nothing to do!')\n    #else:\n    if not stack_exists(awsclient, stack_name):\n        log.warn('Stack \\'%s\\' not deployed - nothing to do!', stack_name)\n    else:\n        client_cfn = awsclient.get_client('cloudformation')\n        client_autoscaling = awsclient.get_client('autoscaling')\n        client_rds = awsclient.get_client('rds')\n\n        resources = all_pages(\n            client_cfn.list_stack_resources,\n            { 'StackName': stack_name },\n            lambda r: r['StackResourceSummaries']\n        )\n\n        autoscaling_groups = [\n            r for r in resources\n            if r['ResourceType'] == 'AWS::AutoScaling::AutoScalingGroup'\n        ]\n\n        # lookup all types of scaling processes\n        #    [Launch, Terminate, HealthCheck, ReplaceUnhealthy, AZRebalance\n        #     AlarmNotification, ScheduledActions, AddToLoadBalancer]\n        response = client_autoscaling.describe_scaling_process_types()\n        scaling_process_types = [t['ProcessName'] for t in response.get('Processes', [])]\n\n        # starting db instances\n        db_instances = [\n            r['PhysicalResourceId'] for r in resources\n            if r['ResourceType'] == 'AWS::RDS::DBInstance'\n        ]\n        stopped_db_instances = _filter_db_instances_by_status(\n            awsclient, db_instances, ['stopped']\n        )\n        for db in stopped_db_instances:\n            log.info('Starting RDS instance \\'%s\\'', db)\n            client_rds.start_db_instance(DBInstanceIdentifier=db)\n\n        # wait for db instances to become available\n        for db in stopped_db_instances:\n            waiter_db_available = client_rds.get_waiter('db_instance_available')\n            waiter_db_available.wait(DBInstanceIdentifier=db)\n\n        # starting ec2 instances\n        instances = [\n            r['PhysicalResourceId'] for r in resources\n            if r['ResourceType'] == 'AWS::EC2::Instance'\n        ]\n        _start_ec2_instances(awsclient, instances)\n\n        services = [\n            r for r in resources\n            if r['ResourceType'] == 'AWS::ECS::Service'\n        ]\n\n        if (autoscaling_groups and not use_suspend) or services:\n            template, parameters = _get_template_parameters(awsclient, stack_name)\n\n        # setting ECS desiredCount back\n        if services:\n            _start_ecs_services(awsclient, services, template, parameters)\n\n        for asg in autoscaling_groups:\n            if use_suspend:\n                # alternative implementation to speed up start\n                # only problem is that instances must survive stop & start\n                # find instances in autoscaling group\n                instances = all_pages(\n                    client_autoscaling.describe_auto_scaling_instances,\n                    {},\n                    lambda r: [i['InstanceId'] for i in r.get('AutoScalingInstances', [])\n                               if i['AutoScalingGroupName'] == asg['PhysicalResourceId']],\n                )\n                _start_ec2_instances(awsclient, instances)\n\n                # resume all autoscaling processes\n                log.info('Resuming all autoscaling processes for \\'%s\\'',\n                         asg['LogicalResourceId'])\n                response = client_autoscaling.resume_processes(\n                    AutoScalingGroupName=asg['PhysicalResourceId'],\n                    ScalingProcesses=scaling_process_types\n                )\n            else:\n                # resize autoscaling group back to its original values\n                log.info('Resize autoscaling group \\'%s\\' back to original values',\n                         asg['LogicalResourceId'])\n                min, max = _get_autoscaling_min_max(\n                    template, parameters, asg['LogicalResourceId'])\n                response = client_autoscaling.update_auto_scaling_group(\n                    AutoScalingGroupName=asg['PhysicalResourceId'],\n                    MinSize=min,\n                    MaxSize=max\n                )\n\n    return exit_code", "response": "Start an existing stack on AWS cloud."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_running(self):\n        return self._state in [self.STATE_ACTIVE,\n                               self.STATE_IDLE,\n                               self.STATE_INITIALIZING]", "response": "Property method that returns a bool indicating if the process is currently running. This method returns a bool indicating if the process is in the idle state or initializing state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_signal(self, signum):\n        if signum == signal.SIGTERM:\n            LOGGER.info('Received SIGTERM, initiating shutdown')\n            self.stop()\n        elif signum == signal.SIGHUP:\n            LOGGER.info('Received SIGHUP')\n            if self.config.reload():\n                LOGGER.info('Configuration reloaded')\n                logging.config.dictConfig(self.config.logging)\n                self.on_configuration_reloaded()\n        elif signum == signal.SIGUSR1:\n            self.on_sigusr1()\n        elif signum == signal.SIGUSR2:\n            self.on_sigusr2()", "response": "Invoked whenever a signal is added to the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        for signum in [signal.SIGHUP, signal.SIGTERM,\n                       signal.SIGUSR1, signal.SIGUSR2]:\n            signal.signal(signum, self._on_signal)\n        self.run()", "response": "Important:\n\n            Do not extend this method, rather redefine Controller.run"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_state(self, state):\n        if state == self._state:\n            return\n        elif state not in self._STATES.keys():\n            raise ValueError('Invalid state {}'.format(state))\n\n        # Check for invalid transitions\n\n        if self.is_waiting_to_stop and state not in [self.STATE_STOPPING,\n                                                     self.STATE_STOPPED]:\n            LOGGER.warning('Attempt to set invalid state while waiting to '\n                           'shutdown: %s ', self._STATES[state])\n            return\n\n        elif self.is_stopping and state != self.STATE_STOPPED:\n            LOGGER.warning('Attempt to set invalid post shutdown state: %s',\n                           self._STATES[state])\n            return\n\n        elif self.is_running and state not in [self.STATE_ACTIVE,\n                                               self.STATE_IDLE,\n                                               self.STATE_SLEEPING,\n                                               self.STATE_STOP_REQUESTED,\n                                               self.STATE_STOPPING]:\n            LOGGER.warning('Attempt to set invalid post running state: %s',\n                           self._STATES[state])\n            return\n\n        elif self.is_sleeping and state not in [self.STATE_ACTIVE,\n                                                self.STATE_IDLE,\n                                                self.STATE_STOP_REQUESTED,\n                                                self.STATE_STOPPING]:\n            LOGGER.warning('Attempt to set invalid post sleeping state: %s',\n                           self._STATES[state])\n            return\n\n        LOGGER.debug('State changed from %s to %s',\n                     self._STATES[self._state], self._STATES[state])\n        self._state = state", "response": "Sets the runtime state of the controller."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride to implement shutdown steps.", "response": "def stop(self):\n        \"\"\"Override to implement shutdown steps.\"\"\"\n        LOGGER.info('Attempting to stop the process')\n        self.set_state(self.STATE_STOP_REQUESTED)\n\n        # Call shutdown for classes to add shutdown steps\n        self.shutdown()\n\n        # Wait for the current run to finish\n        while self.is_running and self.is_waiting_to_stop:\n            LOGGER.info('Waiting for the process to finish')\n            time.sleep(self.SLEEP_UNIT)\n\n        # Change the state to shutting down\n        if not self.is_stopping:\n            self.set_state(self.STATE_STOPPING)\n\n        # Call a method that may be overwritten to cleanly shutdown\n        self.on_shutdown()\n\n        # Change our state\n        self.set_state(self.STATE_STOPPED)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing timestamp in ISO8601 format.", "response": "def parse_ts(ts):\n    \"\"\"\n    parse timestamp.\n    \n    :param ts: timestamp in ISO8601 format\n    :return: tbd!!!\n    \"\"\"\n    # ISO8601 = '%Y-%m-%dT%H:%M:%SZ'\n    # ISO8601_MS = '%Y-%m-%dT%H:%M:%S.%fZ'\n    # RFC1123 = '%a, %d %b %Y %H:%M:%S %Z'\n    dt = maya.parse(ts.strip())\n    return dt.datetime(naive=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_outputs_for_stack(awsclient, stack_name):\n    client_cf = awsclient.get_client('cloudformation')\n    response = client_cf.describe_stacks(StackName=stack_name)\n    if response['Stacks'] and 'Outputs' in response['Stacks'][0]:\n        result = {}\n        for output in response['Stacks'][0]['Outputs']:\n            result[output['OutputKey']] = output['OutputValue']\n        return result", "response": "Get the outputs for a given stack."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the latest AMI that is part of our base AMI.", "response": "def get_base_ami(awsclient, owners):\n    \"\"\"\n    DEPRECATED!!!\n    return the latest version of our base AMI\n    we can't use tags for this, so we have only the name as resource\n    note: this functionality is deprecated since this only works for \"old\"\n    baseami. \n    \"\"\"\n    client_ec2 = awsclient.get_client('ec2')\n    image_filter = [\n        {\n            'Name': 'state',\n            'Values': [\n                'available',\n            ]\n        },\n    ]\n\n    latest_ts = maya.MayaDT(0).datetime(naive=True)\n    latest_version = StrictVersion('0.0.0')\n    latest_id = None\n    for i in client_ec2.describe_images(\n            Owners=owners,\n            Filters=image_filter\n            )['Images']:\n        m = re.search(r'(Ops_Base-Image)_(\\d+.\\d+.\\d+)_(\\d+)$', i['Name'])\n        if m:\n            version = StrictVersion(m.group(2))\n            #timestamp = m.group(3)\n            creation_date = parse_ts(i['CreationDate'])\n\n            if creation_date > latest_ts and version >=latest_version:\n                latest_id = i['ImageId']\n                latest_ts = creation_date\n                latest_version = version\n\n    return latest_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the default arguments to the argument parser.", "response": "def _add_default_arguments(parser):\n    \"\"\"Add the default arguments to the parser.\n\n    :param argparse.ArgumentParser parser: The argument parser\n\n    \"\"\"\n    parser.add_argument('-c', '--config', action='store', dest='config',\n                        help='Path to the configuration file')\n    parser.add_argument('-f', '--foreground', action='store_true', dest='foreground',\n                        help='Run the application interactively')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string representation of the given value.", "response": "def _str(val):\n    \"\"\"\n    Ensures that the val is the default str() type for python2 or 3\n    \"\"\"\n    if str == bytes:\n        if isinstance(val, str):\n            return val\n        else:\n            return str(val)\n    else:\n        if isinstance(val, str):\n            return val\n        else:\n            return str(val, 'ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares a long request.", "response": "def _prepare_long_request(self, url, api_query):\n        \"\"\"\n        Use requests.Request and requests.PreparedRequest to produce the\n        body (and boundary value) of a multipart/form-data; POST request as\n        detailed in https://www.mediawiki.org/wiki/API:Edit#Large_texts\n        \"\"\"\n\n        partlist = []\n        for k, v in iteritems(api_query):\n            if k in ('title', 'text', 'summary'):\n                # title,  text and summary values in the request\n                # should be utf-8 encoded\n\n                part = (k,\n                        (None, v.encode('utf-8'),\n                         'text/plain; charset=UTF-8',\n                         {'Content-Transfer-Encoding': '8bit'}\n                         )\n                        )\n            else:\n                part = (k, (None, v))\n            partlist.append(part)\n\n        auth1 = OAuth1(\n            self.consumer_token.key,\n            client_secret=self.consumer_token.secret,\n            resource_owner_key=session['mwoauth_access_token']['key'],\n            resource_owner_secret=session['mwoauth_access_token']['secret'])\n        return Request(\n            url=url, files=partlist, auth=auth1, method=\"post\").prepare()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a single Physical Information Object or a list of such objects into a JSON - encoded text file.", "response": "def dump(pif, fp, **kwargs):\n    \"\"\"\n    Convert a single Physical Information Object, or a list of such objects, into a JSON-encoded text file.\n\n    :param pif: Object or list of objects to serialize.\n    :param fp: File-like object supporting .write() method to write the serialized object(s) to.\n    :param kwargs: Any options available to json.dump().\n    \"\"\"\n    return json.dump(pif, fp, cls=PifEncoder, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(fp, class_=None, **kwargs):\n    return loado(json.load(fp, **kwargs), class_=class_)", "response": "Convert content in a JSON - encoded text file to a Physical Information Object or a list of such objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loads(s, class_=None, **kwargs):\n    return loado(json.loads(s, **kwargs), class_=class_)", "response": "Convert content in a JSON - encoded string to a Physical Information Object or a list of such objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a dictionary or a list of dictionaries into a single Physical Information Object or a list of such objects.", "response": "def loado(obj, class_=None):\n    \"\"\"\n    Convert a dictionary or a list of dictionaries into a single Physical Information Object or a list of such objects.\n\n    :param obj: Dictionary or list to convert to Physical Information Objects.\n    :param class_: Subclass of :class:`.Pio` to produce, if not unambiguous\n    :return: Single object derived from :class:`.Pio` or a list of such object.\n    \"\"\"\n    if isinstance(obj, list):\n        return [_dict_to_pio(i, class_=class_) for i in obj]\n    elif isinstance(obj, dict):\n        return _dict_to_pio(obj, class_=class_)\n    else:\n        raise ValueError('expecting list or dictionary as outermost structure')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dict_to_pio(d, class_=None):\n    d = keys_to_snake_case(d)\n    if class_:\n        return class_(**d)\n    if 'category' not in d:\n        raise ValueError('Dictionary does not contains a category field: ' + ', '.join(d.keys()))\n    elif d['category'] == 'system':\n        return System(**d)\n    elif d['category'] == 'system.chemical':\n        return ChemicalSystem(**d)\n    elif d['category'] == 'system.chemical.alloy':  # Legacy support\n        return Alloy(**d)\n    elif d['category'] == 'system.chemical.alloy.phase':  # Legacy support\n        return ChemicalSystem(**d)\n    raise ValueError('Dictionary does not contain a valid top-level category: ' + str(d['category']))", "response": "Convert a dictionary object to a Physical Information Object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_command(arguments):\n    cmds = list(filter(lambda k: not (k.startswith('-') or\n                                 k.startswith('<')) and arguments[k],\n                  arguments.keys()))\n    if len(cmds) != 1:\n        raise Exception('invalid command line!')\n    return cmds[0]", "response": "Utility function to extract command from docopt arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndispatches arguments parsed by docopt to the cmd with matching spec.", "response": "def dispatch(cls, arguments, **kwargs):\n        \"\"\"Dispatch arguments parsed by docopt to the cmd with matching spec.\n\n        :param arguments:\n        :param kwargs:\n        :return: exit_code\n        \"\"\"\n        # first match wins\n        # spec: all '-' elements must match, all others are False;\n        #       '<sth>' elements are converted to call args on order of\n        #       appearance\n        #\n        # kwargs are provided to dispatch call and used in func call\n        for spec, func in cls._specs:\n            # if command and arguments.get(command) and match(args):\n            args = []  # specified args in order of appearance\n            options = list(filter(lambda k: k.startswith('-') and\n                                       (arguments[k] or k in spec),\n                             arguments.keys()))\n            cmds = list(filter(lambda k: not (k.startswith('-') or\n                                         k.startswith('<')) and arguments[k],\n                          arguments.keys()))\n            args_spec = list(filter(lambda k: k.startswith('<'), spec))\n            cmd_spec = list(filter(lambda k: not (k.startswith('-') or\n                                             k.startswith('<')), spec))\n            for element in spec:\n                if element.startswith('-'):\n                    # element is an option\n                    if element in options:\n                        args.append(arguments.get(element, False))\n                        options.remove(element)\n                elif element.startswith('<') and \\\n                        not arguments.get(element) is False:\n                    # element is an argument\n                    args.append(arguments.get(element))\n                    if element in args_spec:\n                        args_spec.remove(element)\n                else:\n                    # element is a command\n                    if element in cmds and element in cmd_spec:\n                        cmds.remove(element)\n                        cmd_spec.remove(element)\n\n            if options:\n                continue  # not all options have been matched\n            if cmds:\n                continue  # not all cmds from command line have been matched\n            if args_spec:\n                continue  # not all args from spec have been provided\n            if cmd_spec:\n                continue  # not all cmds from spec have been provided\n            # all options and cmds matched : call the cmd\n            # TODO leave out all args to deal with \"empty\" signature\n            exit_code = func(*args, **kwargs)\n            return exit_code\n        # no matching spec found\n        raise Exception('No implementation for spec: %s' % arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve an attribute from an existing stack.", "response": "def get_att(self, parameter, as_reference=True):\n        \"\"\"Retrieves an attribute from an existing stack\n        :param parameter: The output parameter which should be retrieved\n        :param as_reference: Is the parameter a reference (Default) or a string\n        :return: Value of parameter to retrieve\n        \"\"\"\n        if as_reference:\n            return troposphere.GetAtt(\n                self.__custom_stack_obj,\n                troposphere.Ref(parameter)\n            )\n        else:\n            return troposphere.GetAtt(\n                self.__custom_stack_obj,\n                parameter\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_notification_spec(self, lambda_arn):\n        lambda_name = base.get_lambda_name(lambda_arn)\n        notification_spec = {\n            'Id': self._make_notification_id(lambda_name),\n            'Events': [e for e in self._config['events']],\n            'LambdaFunctionArn': lambda_arn\n        }\n\n        # Add S3 key filters\n        filter_rules = []\n        # look for filter rules\n        for filter_type in ['prefix', 'suffix']:\n            if filter_type in self._config:\n                rule = {'Name': filter_type.capitalize(), 'Value': self._config[filter_type] }\n                filter_rules.append(rule)\n\n        if filter_rules:\n            notification_spec['Filter'] = {'Key': {'FilterRules': filter_rules } }\n        '''\n        if 'key_filters' in self._config:\n            filters_spec = {'Key': {'FilterRules': [] } }\n            # I do not think this is a useful structure:\n            for filter in self._config['key_filters']:\n                if 'type' in filter and 'value' in filter and filter['type'] in ('prefix', 'suffix'):\n                    rule = {'Name': filter['type'].capitalize(), 'Value': filter['value'] }\n                    filters_spec['Key']['FilterRules'].append(rule)\n\n            notification_spec['Filter'] = filters_spec\n        '''\n        return notification_spec", "response": "Returns a dict that represents the notification spec for the given lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the given integer to the proper representation for the given integer.", "response": "def convert_representation(self, i):\n        \"\"\"\n        Return the proper representation for the given integer\n        \"\"\"\n        if self.number_representation == 'unsigned':\n            return i\n        elif self.number_representation == 'signed':\n            if i & (1 << self.interpreter._bit_width - 1):\n                return -((~i + 1) & (2**self.interpreter._bit_width - 1))\n            else:\n                return i\n        elif self.number_representation == 'hex':\n            return hex(i)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef magic_generate_random(self, line):\n        line = line.strip().lower()\n        if not line or line == 'true':\n            self.interpreter.generate_random = True\n        elif line == 'false':\n            self.interpreter.generate_random = False\n        else:\n            stream_content = {'name': 'stderr', 'text': \"unknwon value '{}'\".format(line)}\n            self.send_response(self.iopub_socket, 'stream', stream_content)\n            return {'status': 'error',\n                    'execution_count': self.execution_count,\n                    'ename': ValueError.__name__,\n                    'evalue': \"unknwon value '{}'\".format(line),\n                    'traceback': '???'}", "response": "This function is used to generate random values for the current system entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef magic_postpone_execution(self, line):\n        line = line.strip().lower()\n        if not line or line == 'true':\n            self.interpreter.postpone_execution = True\n        elif line == 'false':\n            self.interpreter.postpone_execution = False\n        else:\n            stream_content = {'name': 'stderr', 'text': \"unknwon value '{}'\".format(line)}\n            self.send_response(self.iopub_socket, 'stream', stream_content)\n            return {'status': 'error',\n                    'execution_count': self.execution_count,\n                    'ename': ValueError.__name__,\n                    'evalue': \"unknwon value '{}'\".format(line),\n                    'traceback': '???'}", "response": "Postpone execution of instructions until explicitly run\n       ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef magic_register(self, line):\n        message = \"\"\n        for reg in [i.strip() for i in line.replace(',', '').split()]:\n            if '-' in reg:\n                # We have a range (Rn-Rk)\n                r1, r2 = reg.split('-')\n                # TODO do we want to allow just numbers?\n                n1 = re.search(self.interpreter.REGISTER_REGEX, r1).groups()[0]\n                n2 = re.search(self.interpreter.REGISTER_REGEX, r2).groups()[0]\n                n1 = self.interpreter.convert_to_integer(n1)\n                n2 = self.interpreter.convert_to_integer(n2)\n                for i in range(n1, n2+1):\n                    val = self.interpreter.register[r1[0] + str(i)]\n                    val = self.convert_representation(val)\n                    message += \"{}: {}\\n\".format(r1[0] + str(i), val)\n            else:\n                val = self.interpreter.register[reg]\n                val = self.convert_representation(val)\n                message += \"{}: {}\\n\".format(reg, val)\n        stream_content = {'name': 'stdout', 'text': message}\n        self.send_response(self.iopub_socket, 'stream', stream_content)", "response": "Print out the current value of a register"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef magic_memory(self, line):\n        # TODO add support for directives\n        message = \"\"\n        for address in [i.strip() for i in line.replace(',', '').split()]:\n            if '-' in address:\n                # We have a range (n-k)\n                m1, m2 = address.split('-')\n                n1 = re.search(self.interpreter.IMMEDIATE_NUMBER, m1).groups()[0]\n                n2 = re.search(self.interpreter.IMMEDIATE_NUMBER, m2).groups()[0]\n                n1 = self.interpreter.convert_to_integer(n1)\n                n2 = self.interpreter.convert_to_integer(n2)\n                for i in range(n1, n2 + 1):\n                    val = self.interpreter.memory[i]\n                    val = self.convert_representation(val)\n                    message += \"{}: {}\\n\".format(str(i), val)\n            else:\n                # TODO fix what is the key for memory (currently it's an int, but registers are strings, should it be the same?)\n                val = self.interpreter.memory[self.interpreter.convert_to_integer(address)]\n                val = self.convert_representation(val)\n                message += \"{}: {}\\n\".format(address, val)\n        stream_content = {'name': 'stdout', 'text': message}\n        self.send_response(self.iopub_socket, 'stream', stream_content)", "response": "Print out the current value of memory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef magic_run(self, line):\n        i = float('inf')\n        if line.strip():\n            i = int(line)\n\n        try:\n            with warnings.catch_warnings(record=True) as w:\n                self.interpreter.run(i)\n                for warning_message in w:\n                    # TODO should this be stdout or stderr\n                    stream_content = {'name': 'stdout', 'text': 'Warning: ' + str(warning_message.message) + '\\n'}\n                    self.send_response(self.iopub_socket, 'stream', stream_content)\n        except iarm.exceptions.EndOfProgram as e:\n            f_name = self.interpreter.program[self.interpreter.register['PC'] - 1].__name__\n            f_name = f_name[:f_name.find('_')]\n            message = \"Error in {}: \".format(f_name)\n            stream_content = {'name': 'stdout', 'text': message + str(e) + '\\n'}\n            self.send_response(self.iopub_socket, 'stream', stream_content)\n        except Exception as e:\n            for err in e.args:\n                stream_content = {'name': 'stderr', 'text': str(err)}\n                self.send_response(self.iopub_socket, 'stream', stream_content)\n            return {'status': 'error',\n                    'execution_count': self.execution_count,\n                    'ename': type(e).__name__,\n                    'evalue': str(e),\n                    'traceback': '???'}", "response": "This function is used to run the current program and return the result of the current program."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint out the help for the specified magic and instruction.", "response": "def magic_help(self, line):\n        \"\"\"\n        Print out the help for magics\n\n        Usage:\n        Call help with no arguments to list all magics,\n        or call it with a magic to print out it's help info.\n\n        `%help`\n        or\n        `%help run\n        \"\"\"\n        line = line.strip()\n        if not line:\n            for magic in self.magics:\n                stream_content = {'name': 'stdout', 'text': \"%{}\\n\".format(magic)}\n                self.send_response(self.iopub_socket, 'stream', stream_content)\n        elif line in self.magics:\n            # its a magic\n            stream_content = {'name': 'stdout', 'text': \"{}\\n{}\".format(line, self.magics[line].__doc__)}\n            self.send_response(self.iopub_socket, 'stream', stream_content)\n        elif line in self.interpreter.ops:\n            # it's an instruction\n            stream_content = {'name': 'stdout', 'text': \"{}\\n{}\".format(line, self.interpreter.ops[line].__doc__)}\n            self.send_response(self.iopub_socket, 'stream', stream_content)\n        else:\n            stream_content = {'name': 'stderr', 'text': \"'{}' not a known magic or instruction\".format(line)}\n            self.send_response(self.iopub_socket, 'stream', stream_content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting the API design as swagger file.", "response": "def export_to_swagger(awsclient, api_name, stage_name, api_description,\n                      lambdas, custom_hostname=False, custom_base_path=False):\n    \"\"\"Export the API design as swagger file. \n    \n    :param api_name: \n    :param stage_name: \n    :param api_description: \n    :param lambdas: \n    :param custom_hostname: \n    :param custom_base_path: \n    \"\"\"\n    print('Exporting to swagger...')\n\n    api = _api_by_name(awsclient, api_name)\n    if api is not None:\n\n        print(json2table(api))\n        api_id = api['id']\n        client_api = awsclient.get_client('apigateway')\n        template_variables = _template_variables_to_dict(\n            client_api,\n            api_name,\n            api_description,\n            stage_name,\n            api_id,\n            lambdas,\n            custom_hostname,\n            custom_base_path)\n        content = _compile_template(SWAGGER_FILE, template_variables)\n        swagger_file = open('swagger_export.yaml', 'w')\n\n        swagger_file.write(content)\n    else:\n        print('API name unknown')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists APIs in account.", "response": "def list_apis(awsclient):\n    \"\"\"List APIs in account.\"\"\"\n    client_api = awsclient.get_client('apigateway')\n\n    apis = client_api.get_rest_apis()['items']\n\n    for api in apis:\n        print(json2table(api))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deploy_api(awsclient, api_name, api_description, stage_name, api_key,\n               lambdas, cache_cluster_enabled, cache_cluster_size, method_settings=None):\n    \"\"\"Deploy API Gateway to AWS cloud.\n\n    :param awsclient:\n    :param api_name:\n    :param api_description:\n    :param stage_name:\n    :param api_key:\n    :param lambdas:\n    :param cache_cluster_enabled:\n    :param cache_cluster_size:\n    :param method_settings:\n    \"\"\"\n    if not _api_exists(awsclient, api_name):\n        if os.path.isfile(SWAGGER_FILE):\n            # this does an import from swagger file\n            # the next step does not make sense since there is a check in\n            # _import_from_swagger for if api is existent!\n            # _create_api(api_name=api_name, api_description=api_description)\n            _import_from_swagger(awsclient, api_name, api_description,\n                                 stage_name, lambdas)\n        else:\n            print('No swagger file (%s) found' % SWAGGER_FILE)\n\n        api = _api_by_name(awsclient, api_name)\n        if api is not None:\n            _ensure_lambdas_permissions(awsclient, lambdas, api)\n            _create_deployment(awsclient, api_name, stage_name, cache_cluster_enabled, cache_cluster_size)\n            _update_stage(awsclient, api['id'], stage_name, method_settings)\n            _wire_api_key(awsclient, api_name, api_key, stage_name)\n        else:\n            print('API name unknown')\n    else:\n        if os.path.isfile(SWAGGER_FILE):\n            _update_from_swagger(awsclient, api_name, api_description,\n                                 stage_name, lambdas)\n        else:\n            _update_api()\n\n        api = _api_by_name(awsclient, api_name)\n        if api is not None:\n            _ensure_lambdas_permissions(awsclient, lambdas, api)\n            _create_deployment(awsclient, api_name, stage_name, cache_cluster_enabled, cache_cluster_size)\n            _update_stage(awsclient, api['id'], stage_name, method_settings)\n        else:\n            print('API name unknown')", "response": "Deploy API Gateway to AWS cloud."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_api(awsclient, api_name):\n    _sleep()\n    client_api = awsclient.get_client('apigateway')\n\n    print('deleting api: %s' % api_name)\n    api = _api_by_name(awsclient, api_name)\n\n    if api is not None:\n        print(json2table(api))\n\n        response = client_api.delete_rest_api(\n            restApiId=api['id']\n        )\n\n        print(json2table(response))\n    else:\n        print('API name unknown')", "response": "Delete the API.\n\n    :param api_name:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new API key as reference for api. conf.", "response": "def create_api_key(awsclient, api_name, api_key_name):\n    \"\"\"Create a new API key as reference for api.conf.\n\n    :param api_name:\n    :param api_key_name:\n    :return: api_key\n    \"\"\"\n    _sleep()\n    client_api = awsclient.get_client('apigateway')\n    print('create api key: %s' % api_key_name)\n\n    response = client_api.create_api_key(\n        name=api_key_name,\n        description='Created for ' + api_name,\n        enabled=True\n    )\n\n    #print(json2table(response))\n\n    print('Add this api key \\'%s\\' to your api.conf' % response['id'])\n    return response['id']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove API key. :param api_key:", "response": "def delete_api_key(awsclient, api_key):\n    \"\"\"Remove API key.\n\n    :param api_key:\n    \"\"\"\n    _sleep()\n    client_api = awsclient.get_client('apigateway')\n    print('delete api key: %s' % api_key)\n\n    response = client_api.delete_api_key(\n        apiKey=api_key\n    )\n\n    print(json2table(response))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_api_keys(awsclient):\n    _sleep()\n    client_api = awsclient.get_client('apigateway')\n    print('listing api keys')\n\n    response = client_api.get_api_keys()['items']\n\n    for item in response:\n        print(json2table(item))", "response": "Print the defined API keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deploy_custom_domain(awsclient, api_name, api_target_stage,\n                         api_base_path, domain_name, route_53_record,\n                         cert_name, cert_arn, hosted_zone_id, ensure_cname):\n    \"\"\"Add custom domain to your API.\n\n    :param api_name:\n    :param api_target_stage:\n    :param api_base_path:\n    :param domain_name:\n    :param route_53_record:\n    :param ssl_cert:\n    :param cert_name:\n    :param cert_arn:\n    :param hosted_zone_id:\n    :return: exit_code\n    \"\"\"\n    api_base_path = _basepath_to_string_if_null(api_base_path)\n    api = _api_by_name(awsclient, api_name)\n\n    if not api:\n        print(\"Api %s does not exist, aborting...\" % api_name)\n        # exit(1)\n        return 1\n\n    domain = _custom_domain_name_exists(awsclient, domain_name)\n\n    if not domain:\n        response = _create_custom_domain(awsclient, domain_name, cert_name, cert_arn)\n        cloudfront_distribution = response['distributionDomainName']\n    else:\n        response = _update_custom_domain(awsclient, domain_name, cert_name, cert_arn)\n        cloudfront_distribution = response['distributionDomainName']\n\n    if _base_path_mapping_exists(awsclient, domain_name, api_base_path):\n        _ensure_correct_base_path_mapping(awsclient, domain_name,\n                                          api_base_path, api['id'],\n                                          api_target_stage)\n    else:\n        _create_base_path_mapping(awsclient, domain_name, api_base_path,\n                                  api_target_stage, api['id'])\n\n    if ensure_cname:\n        record_exists, record_correct = \\\n            _record_exists_and_correct(awsclient, hosted_zone_id,\n                                       route_53_record,\n                                       cloudfront_distribution)\n        if record_correct:\n            print('Route53 record correctly set: %s --> %s' % (route_53_record,\n                                                               cloudfront_distribution))\n        else:\n            _ensure_correct_route_53_record(awsclient, hosted_zone_id,\n                                            record_name=route_53_record,\n                                            record_value=cloudfront_distribution)\n            print('Route53 record set: %s --> %s' % (route_53_record,\n                                                     cloudfront_distribution))\n    else:\n        print('Skipping creating and checking DNS record')\n\n    return 0", "response": "Deploy a custom domain to your API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of lambda functions.", "response": "def get_lambdas(awsclient, config, add_arn=False):\n    \"\"\"Get the list of lambda functions.\n\n    :param config:\n    :param add_arn:\n    :return: list containing lambda entries\n    \"\"\"\n    if 'lambda' in config:\n        client_lambda = awsclient.get_client('lambda')\n        lambda_entries = config['lambda'].get('entries', [])\n        lmbdas = []\n        for lambda_entry in lambda_entries:\n            lmbda = {\n                'name': lambda_entry.get('name', None),\n                'alias': lambda_entry.get('alias', None),\n                'swagger_ref': lambda_entry.get('swaggerRef', None)\n            }\n            if add_arn:\n                _sleep()\n                response_lambda = client_lambda.get_function(\n                    FunctionName=lmbda['name'])\n                lmbda['arn'] = response_lambda['Configuration']['FunctionArn']\n            lmbdas.append(lmbda)\n        return lmbdas\n    else:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_stage(awsclient, api_id, stage_name, method_settings):\n    # settings docs in response: https://botocore.readthedocs.io/en/latest/reference/services/apigateway.html#APIGateway.Client.update_stage\n    client_api = awsclient.get_client('apigateway')\n    operations = _convert_method_settings_into_operations(method_settings)\n    if operations:\n        print('update method settings for stage')\n        _sleep()\n        response = client_api.update_stage(\n            restApiId=api_id,\n            stageName=stage_name,\n            patchOperations=operations)", "response": "Helper to apply method_settings to stage\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _convert_method_settings_into_operations(method_settings=None):\n    # operations docs here: https://tools.ietf.org/html/rfc6902#section-4\n    operations = []\n    if method_settings:\n        for method in method_settings.keys():\n            for key, value in method_settings[method].items():\n                if isinstance(value, bool):\n                    if value:\n                        value = 'true'\n                    else:\n                        value = 'false'\n                operations.append({\n                    'op': 'replace',\n                    'path': method + _resolve_key(key),\n                    'value': value\n                })\n    return operations", "response": "Helper to handle the conversion of method_settings to operations\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_settings():\n    conf_file = os.path.join(os.path.dirname(base_settings.__file__),\n                             'example', 'conf.py')\n    conf_template = open(conf_file).read()\n    default_url = 'http://salmon.example.com'\n    site_url = raw_input(\"What will be the URL for Salmon? [{0}]\".format(\n        default_url))\n    site_url = site_url or default_url\n    secret_key = base64.b64encode(os.urandom(KEY_LENGTH))\n    api_key = base64.b64encode(os.urandom(KEY_LENGTH))\n    output = conf_template.format(api_key=api_key, secret_key=secret_key,\n                                  site_url=site_url)\n    return output", "response": "This command generates the default settings file for the current site."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configure_app(**kwargs):\n    sys_args = sys.argv\n    args, command, command_args = parse_args(sys_args[1:])\n    parser = OptionParser()\n    parser.add_option('--config', metavar='CONFIG')\n    (options, logan_args) = parser.parse_args(args)\n    config_path = options.config\n    logan_configure(config_path=config_path, **kwargs)", "response": "Builds up the settings using the same method as logan"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _reset_changes(self):\n        self._original = {}\n        if self.last_updated is not None:\n            self._original['last_updated'] = self.last_updated", "response": "Stores current values for comparison later"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a file path to the Whisper database", "response": "def whisper_filename(self):\n        \"\"\"Build a file path to the Whisper database\"\"\"\n        source_name = self.source_id and self.source.name or ''\n        return get_valid_filename(\"{0}__{1}.wsp\".format(source_name,\n                                                        self.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value_display(self):\n        if self.display_as == 'percentage':\n            return '{0}%'.format(self.latest_value)\n        if self.display_as == 'boolean':\n            return bool(self.latest_value)\n        if self.display_as == 'byte':\n            return defaultfilters.filesizeformat(self.latest_value)\n        if self.display_as == 'second':\n            return time.strftime('%H:%M:%S', time.gmtime(self.latest_value))\n        return self.latest_value", "response": "Human friendly value output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef time_between_updates(self):\n        if 'last_updated' not in self._original:\n            return 0\n        last_update = self._original['last_updated']\n        this_update = self.last_updated\n        return this_update - last_update", "response": "Time between current last_updated and previous last_updated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying the transformation to the latest value", "response": "def do_transform(self):\n        \"\"\"Apply the transformation (if it exists) to the latest_value\"\"\"\n        if not self.transform:\n            return\n        try:\n            self.latest_value = utils.Transform(\n                expr=self.transform, value=self.latest_value,\n                timedelta=self.time_between_updates().total_seconds()).result()\n        except (TypeError, ValueError):\n            logger.warn(\"Invalid transformation '%s' for metric %s\",\n                        self.transfrom, self.pk)\n        self.transform = ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the latest value to the diff between it and the previous value", "response": "def do_counter_conversion(self):\n        \"\"\"Update latest value to the diff between it and the previous value\"\"\"\n        if self.is_counter:\n            if self._previous_counter_value is None:\n                prev_value = self.latest_value\n            else:\n                prev_value = self._previous_counter_value\n            self._previous_counter_value = self.latest_value\n            self.latest_value = self.latest_value - prev_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef source_group_receiver(self, sender, source, signal, **kwargs):\n\n        from imagekit.cachefiles import ImageCacheFile\n        source_group = sender\n\n        # Ignore signals from unregistered groups.\n        if source_group not in self._source_groups:\n            return\n\n\n        #OVERRIDE HERE -- pass specs into generator object\n        specs = [generator_registry.get(id, source=source, specs=spec_data_field_hash[id]) for id in\n                self._source_groups[source_group]]\n        callback_name = self._signals[signal]\n        #END OVERRIDE\n\n        for spec in specs:\n            file = ImageCacheFile(spec)\n            call_strategy_method(file, callback_name)", "response": "Receives a signal from a source group."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsubstitutes variables with numeric values", "response": "def replace_variable(self, variable):\n        \"\"\"Substitute variables with numeric values\"\"\"\n        if variable == 'x':\n            return self.value\n        if variable == 't':\n            return self.timedelta\n        raise ValueError(\"Invalid variable %s\", variable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef result(self):\n        # Module(body=[Expr(value=...)])\n        return self.eval_(ast.parse(self.expr).body[0].value)", "response": "Evaluate expression and return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_people(self, user_alias=None):\n        user_alias = user_alias or self.api.user_alias\n        content = self.api.req(API_PEOPLE_HOME % user_alias).content\n        xml = self.api.to_xml(re.sub(b'<br />', b'\\n', content))\n        try:\n            xml_user = xml.xpath('//*[@id=\"profile\"]')\n            if not xml_user:\n                return None\n            else:\n                xml_user = xml_user[0]\n            avatar = first(xml_user.xpath('.//img/@src'))\n            city = first(xml_user.xpath('.//div[@class=\"user-info\"]/a/text()'))\n            city_url = first(xml_user.xpath('.//div[@class=\"user-info\"]/a/@href'))\n            text_created_at = xml_user.xpath('.//div[@class=\"pl\"]/text()')[1]\n            created_at = re.match(r'.+(?=\u52a0\u5165)', text_created_at.strip()).group()\n            xml_intro = first(xml.xpath('//*[@id=\"intro_display\"]'))\n            intro = xml_intro.xpath('string(.)') if xml_intro is not None else None\n            nickname = first(xml.xpath('//*[@id=\"db-usr-profile\"]//h1/text()'), '').strip() or None\n            signature = first(xml.xpath('//*[@id=\"display\"]/text()'))\n            xml_contact_count = xml.xpath('//*[@id=\"friend\"]/h2')[0]\n            contact_count = int(re.search(r'\u6210\u5458(\\d+)', xml_contact_count.xpath('string(.)')).groups()[0])\n            text_rev_contact_count = xml.xpath('//p[@class=\"rev-link\"]/a/text()')[0]\n            rev_contact_count = int(re.search(r'(\\d+)\u4eba\u5173\u6ce8', text_rev_contact_count.strip()).groups()[0])\n            return {\n                'alias': user_alias,\n                'url': API_PEOPLE_HOME % user_alias,\n                'avatar': avatar,\n                'city': city,\n                'city_url': city_url,\n                'created_at': created_at,\n                'intro': intro,\n                'nickname': nickname,\n                'signature': signature,\n                'contact_count': contact_count,\n                'rev_contact_count': rev_contact_count,\n            }\n        except Exception as e:\n            self.api.logger.exception('parse people meta error: %s' % e)", "response": "Get all people in a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs in a user with an email address.", "response": "def email_login(request, *, email, **kwargs):\n    \"\"\"\n    Given a request, an email and optionally some additional data, ensure that\n    a user with the email address exists, and authenticate & login them right\n    away if the user is active.\n\n    Returns a tuple consisting of ``(user, created)`` upon success or ``(None,\n    None)`` when authentication fails.\n    \"\"\"\n    _u, created = auth.get_user_model()._default_manager.get_or_create(email=email)\n    user = auth.authenticate(request, email=email)\n    if user and user.is_active:  # The is_active check is possibly redundant.\n        auth.login(request, user)\n        return user, created\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the latest results for each source", "response": "def dashboard(request):\n    \"\"\"Shows the latest results for each source\"\"\"\n    sources = (models.Source.objects.all().prefetch_related('metric_set')\n                                          .order_by('name'))\n    metrics = SortedDict([(src, src.metric_set.all()) for src in sources])\n    no_source_metrics = models.Metric.objects.filter(source__isnull=True)\n    if no_source_metrics:\n        metrics[''] = no_source_metrics\n\n    if request.META.get('HTTP_X_PJAX', False):\n        parent_template = 'pjax.html'\n    else:\n        parent_template = 'base.html'\n    return render(request, 'metrics/dashboard.html', {\n        'source_metrics': metrics,\n        'parent_template': parent_template\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create(self):\n        if not os.path.exists(settings.SALMON_WHISPER_DB_PATH):\n            os.makedirs(settings.SALMON_WHISPER_DB_PATH)\n        archives = [whisper.parseRetentionDef(retentionDef)\n                    for retentionDef in settings.ARCHIVES.split(\",\")]\n        whisper.create(self.path, archives,\n                       xFilesFactor=settings.XFILEFACTOR,\n                       aggregationMethod=settings.AGGREGATION_METHOD)", "response": "Create the Whisper file on disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(self, from_time, until_time=None):\n        until_time = until_time or datetime.now()\n        time_info, values = whisper.fetch(self.path,\n                                          from_time.strftime('%s'),\n                                          until_time.strftime('%s'))\n        # build up a list of (timestamp, value)\n        start_time, end_time, step = time_info\n        current = start_time\n        times = []\n        while current <= end_time:\n            times.append(current)\n            current += step\n        return zip(times, values)", "response": "This method fetches data from the database according to the period\n        from_time until_time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a list result from the results and xml.", "response": "def build_list_result(results, xml):\n    \"\"\"\n    \u6784\u5efa\u5e26\u7ffb\u9875\u7684\u5217\u8868\n    \n    :param results: \u5df2\u83b7\u53d6\u7684\u6570\u636e\u5217\u8868\n    :param xml: \u539f\u59cb\u9875\u9762xml\n    :return: {'results': list, 'count': int, 'next_start': int|None}\n            \u5982\u679ccount\u4e0eresults\u957f\u5ea6\u4e0d\u540c\uff0c\u5219\u6709\u66f4\u591a\n            \u5982\u679cnext_start\u4e0d\u4e3aNone\uff0c\u5219\u53ef\u4ee5\u5230\u4e0b\u4e00\u9875\n    \"\"\"\n    xml_count = xml.xpath('//div[@class=\"paginator\"]/span[@class=\"count\"]/text()')\n    xml_next = xml.xpath('//div[@class=\"paginator\"]/span[@class=\"next\"]/a/@href')\n    count = int(re.search(r'\\d+', xml_count[0]).group()) if xml_count else len(results)\n    next_start = int(re.search(r'start=(\\d+)', xml_next[0]).groups()[0]) if xml_next else None\n    return {'results': results, 'count': count, 'next_start': next_start}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning to set the NZCV flag for the current entry Ra Rb and Rc", "response": "def ADCS(self, params):\n        \"\"\"\n        ADCS [Ra,] Rb, Rc\n\n        Add Rb and Rc + the carry bit and store the result in Ra\n        Ra, Rb, and Rc must be low registers\n        if Ra is omitted, then it is assumed to be Rb\n        \"\"\"\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        self.check_arguments(low_registers=(Ra, Rc))\n        self.match_first_two_parameters(Ra, Rb)\n\n        # ADCS Ra, Ra, Rb\n        def ADCS_func():\n            # TODO need to rethink the set_NZCV with the C flag\n            oper_1 = self.register[Ra]\n            oper_2 = self.register[Rc]\n            self.register[Ra] = oper_1 + oper_2\n            self.register[Ra] += 1 if self.is_C_set() else 0\n            self.set_NZCV_flags(oper_1, oper_2, self.register[Ra], 'add')\n\n        return ADCS_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds [Rx,] Ry, [Rz, PC] ADD [Rx,] [SP, PC], #imm10_4 ADD [SP,] SP, #imm9_4 Add Ry and Rz and store the result in Rx Rx, Ry, and Rz can be any register If Rx is omitted, then it is assumed to be Ry", "response": "def ADD(self, params):\n        \"\"\"\n        ADD [Rx,] Ry, [Rz, PC]\n        ADD [Rx,] [SP, PC], #imm10_4\n        ADD [SP,] SP, #imm9_4\n\n        Add Ry and Rz and store the result in Rx\n        Rx, Ry, and Rz can be any register\n        If Rx is omitted, then it is assumed to be Ry\n        \"\"\"\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        # TODO can we have ADD SP, #imm9_4?\n        try:\n            Rx, Ry, Rz = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Ry, Rz = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Rx = Ry\n\n        if self.is_register(Rz):\n            # ADD Rx, Ry, Rz\n            self.check_arguments(any_registers=(Rx, Ry, Rz))\n            if Rx != Ry:\n                raise iarm.exceptions.RuleError(\"Second parameter {} does not equal first parameter {}\". format(Ry, Rx))\n\n            def ADD_func():\n                self.register[Rx] = self.register[Ry] + self.register[Rz]\n        else:\n            if Rx == 'SP':\n                # ADD SP, SP, #imm9_4\n                self.check_arguments(imm9_4=(Rz,))\n                if Rx != Ry:\n                    raise iarm.exceptions.RuleError(\"Second parameter {} is not SP\".format(Ry))\n            else:\n                # ADD Rx, [SP, PC], #imm10_4\n                self.check_arguments(any_registers=(Rx,), imm10_4=(Rz,))\n                if Ry not in ('SP', 'PC'):\n                    raise iarm.exceptions.RuleError(\"Second parameter {} is not SP or PC\".format(Ry))\n\n            def ADD_func():\n                self.register[Rx] = self.register[Ry] + self.convert_to_integer(Rz[1:])\n\n        return ADD_func"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CMP(self, params):\n        Rm, Rn = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n\n        if self.is_register(Rn):\n            # CMP Rm, Rn\n            self.check_arguments(R0_thru_R14=(Rm, Rn))\n\n            def CMP_func():\n                self.set_NZCV_flags(self.register[Rm], self.register[Rn],\n                                    self.register[Rm] - self.register[Rn], 'sub')\n        else:\n            # CMP Rm, #imm8\n            self.check_arguments(R0_thru_R14=(Rm,), imm8=(Rn,))\n\n            def CMP_func():\n                tmp = self.convert_to_integer(Rn[1:])\n                self.set_NZCV_flags(self.register[Rm], tmp,\n                                    self.register[Rm] - tmp, 'sub')\n\n        return CMP_func", "response": "CMP - related function for handling the CMP related tables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SUB(self, params):\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        self.check_arguments(imm9_4=(Rc,))\n        if Ra != 'SP':\n            raise iarm.exceptions.RuleError(\"First parameter {} is not equal to SP\".format(Ra))\n        if Rb != 'SP':\n            raise iarm.exceptions.RuleError(\"Second parameter {} is not equal to SP\".format(Rb))\n\n        # SUB SP, SP, #imm9_4\n        def SUB_func():\n            self.register[Ra] = self.register[Rb] - self.convert_to_integer(Rc[1:])\n\n        return SUB_func", "response": "SUB instruction for subtracting an immediate from the Stack Pointer\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SUBS(self, params):\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        if self.is_register(Rc):\n            # SUBS Ra, Rb, Rc\n            self.check_arguments(low_registers=(Ra, Rb, Rc))\n\n            def SUBS_func():\n                oper_1 = self.register[Rb]\n                oper_2 = self.register[Rc]\n                self.register[Ra] = self.register[Rb] - self.register[Rc]\n                self.set_NZCV_flags(oper_1, oper_2, self.register[Ra], 'sub')\n        else:\n            if Ra == Rb:\n                # SUBS Ra, Ra, #imm8\n                self.check_arguments(low_registers=(Ra,), imm8=(Rc,))\n\n                def SUBS_func():\n                    oper_1 = self.register[Ra]\n                    self.register[Ra] = self.register[Ra] - self.convert_to_integer(Rc[1:])\n                    self.set_NZCV_flags(oper_1, self.convert_to_integer(Rc[1:]), self.register[Ra], 'sub')\n            else:\n                # SUBS Ra, Rb, #imm3\n                self.check_arguments(low_registers=(Ra, Rb), imm3=(Rc,))\n\n                def SUBS_func():\n                    oper_1 = self.register[Rb]\n                    self.register[Ra] = self.register[Rb] - self.convert_to_integer(Rc[1:])\n                    self.set_NZCV_flags(oper_1, self.convert_to_integer(Rc[1:]), self.register[Ra], 'sub')\n\n        return SUBS_func", "response": "SUBS Ra Rb Rc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initialize(template, service_name, environment='dev'):\n    template.SERVICE_NAME = os.getenv('SERVICE_NAME', service_name)\n    template.SERVICE_ENVIRONMENT = os.getenv('ENV', environment).lower()\n    template.DEFAULT_TAGS = troposphere.Tags(**{\n        'service-name': template.SERVICE_NAME,\n        'environment': template.SERVICE_ENVIRONMENT\n    })\n    template.add_version(\"2010-09-09\")\n    template.add_description(\"Stack for %s microservice\" % service_name)", "response": "Initializes the template with the given service_name and environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting dist for installed version of dist_name avoiding pkg_resources cache", "response": "def get_dist(dist_name, lookup_dirs=None):\n    \"\"\"Get dist for installed version of dist_name avoiding pkg_resources cache\n    \"\"\"\n    # note: based on pip/utils/__init__.py, get_installed_version(...)\n\n    # Create a requirement that we'll look for inside of setuptools.\n    req = pkg_resources.Requirement.parse(dist_name)\n\n    # We want to avoid having this cached, so we need to construct a new\n    # working set each time.\n    if lookup_dirs is None:\n        working_set = pkg_resources.WorkingSet()\n    else:\n        working_set = pkg_resources.WorkingSet(lookup_dirs)\n\n    # Get the installed distribution from our working set\n    return working_set.find(req)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the package version information which is comparable.", "response": "def get_package_versions(package):\n    \"\"\"Get the package version information (=SetuptoolsVersion) which is\n    comparable.\n    note: we use the pip list_command implementation for this\n\n    :param package: name of the package\n    :return: installed version, latest available version\n    \"\"\"\n    list_command = ListCommand()\n    options, args = list_command.parse_args([])\n    packages = [get_dist(package)]\n    dists = list_command.iter_packages_latest_infos(packages, options)\n    try:\n        dist = next(dists)\n        return dist.parsed_version, dist.latest_version\n    except StopIteration:\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_hooks(path):\n    module = imp.load_source(os.path.splitext(os.path.basename(path))[0], path)\n    if not check_hook_mechanism_is_intact(module):\n        # no hooks - do nothing\n        log.debug('No valid hook configuration: \\'%s\\'. Not using hooks!', path)\n    else:\n        if check_register_present(module):\n            # register the template hooks so they listen to gcdt_signals\n            module.register()\n    return module", "response": "Load a module and register signals."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lifecycle(awsclient, env, tool, command, arguments):\n    log.debug('### init')\n    load_plugins()\n    context = get_context(awsclient, env, tool, command, arguments)\n    # every tool needs a awsclient so we provide this via the context\n    context['_awsclient'] = awsclient\n    log.debug('### context:')\n    log.debug(context)\n    if 'error' in context:\n        # no need to send an 'error' signal here\n        return 1\n\n    ## initialized\n    gcdt_signals.initialized.send(context)\n    log.debug('### initialized')\n    if 'error' in context:\n        log.error(context['error'])\n        return 1\n    check_gcdt_update()\n\n    # config is \"assembled\" by config_reader NOT here!\n    config = {}\n\n    gcdt_signals.config_read_init.send((context, config))\n    log.debug('### config_read_init')\n    gcdt_signals.config_read_finalized.send((context, config))\n    log.debug('### config_read_finalized')\n    # TODO we might want to be able to override config via env variables?\n    # here would be the right place to do this\n    if 'hookfile' in config:\n        # load hooks from hookfile\n        _load_hooks(config['hookfile'])\n    if 'kumo' in config:\n        # deprecated: this needs to be removed once all old-style \"cloudformation\" entries are gone\n        fix_old_kumo_config(config)\n\n    # check_credentials\n    gcdt_signals.check_credentials_init.send((context, config))\n    log.debug('### check_credentials_init')\n    gcdt_signals.check_credentials_finalized.send((context, config))\n    log.debug('### check_credentials_finalized')\n    if 'error' in context:\n        log.error(context['error'])\n        gcdt_signals.error.send((context, config))\n        return 1\n\n    ## lookup\n    gcdt_signals.lookup_init.send((context, config))\n    log.debug('### lookup_init')\n    gcdt_signals.lookup_finalized.send((context, config))\n    log.debug('### lookup_finalized')\n    log.debug('### config after lookup:')\n    log.debug(config)\n\n    ## config validation\n    gcdt_signals.config_validation_init.send((context, config))\n    log.debug('### config_validation_init')\n    gcdt_signals.config_validation_finalized.send((context, config))\n    if context['command'] in \\\n            DEFAULT_CONFIG.get(context['tool'], {}).get('non_config_commands', []):\n        pass  # we do not require a config for this command\n    elif tool not in config and tool != 'gcdt':\n        context['error'] = 'Configuration missing for \\'%s\\'.' % tool\n        log.error(context['error'])\n        gcdt_signals.error.send((context, config))\n        return 1\n    log.debug('### config_validation_finalized')\n\n    ## check credentials are valid (AWS services)\n    # DEPRECATED, use gcdt-logon plugin instead\n    if are_credentials_still_valid(awsclient):\n        context['error'] = \\\n            'Your credentials have expired... Please renew and try again!'\n        log.error(context['error'])\n        gcdt_signals.error.send((context, config))\n        return 1\n\n    ## bundle step\n    gcdt_signals.bundle_pre.send((context, config))\n    log.debug('### bundle_pre')\n    gcdt_signals.bundle_init.send((context, config))\n    log.debug('### bundle_init')\n    gcdt_signals.bundle_finalized.send((context, config))\n    log.debug('### bundle_finalized')\n    if 'error' in context:\n        log.error(context['error'])\n        gcdt_signals.error.send((context, config))\n        return 1\n\n    ## dispatch command providing context and config (= tooldata)\n    gcdt_signals.command_init.send((context, config))\n    log.debug('### command_init')\n    try:\n        if tool == 'gcdt':\n            conf = config  # gcdt works on the whole config\n        else:\n            conf = config.get(tool, {})\n        exit_code = cmd.dispatch(arguments,\n                                 context=context,\n                                 config=conf)\n    except GracefulExit:\n        raise\n    except Exception as e:\n        log.debug(traceback.format_exc())\n        context['error'] = str(e)\n        log.error(context['error'])\n        exit_code = 1\n    if exit_code:\n        if 'error' not in context or context['error'] == '':\n            context['error'] = '\\'%s\\' command failed with exit code 1' % command\n        gcdt_signals.error.send((context, config))\n        return 1\n\n    gcdt_signals.command_finalized.send((context, config))\n    log.debug('### command_finalized')\n\n    # TODO reporting (in case you want to get a summary / output to the user)\n\n    gcdt_signals.finalized.send(context)\n    log.debug('### finalized')\n    return 0", "response": "Tool lifecycle which provides hooks into different stages of the command execution. See signals for hook details."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(doc, tool, dispatch_only=None):\n    # Use signal handler to throw exception which can be caught to allow\n    # graceful exit.\n    # here: https://stackoverflow.com/questions/26414704/how-does-a-python-process-exit-gracefully-after-receiving-sigterm-while-waiting\n    signal.signal(signal.SIGTERM, signal_handler)  # Jenkins\n    signal.signal(signal.SIGINT, signal_handler)   # Ctrl-C\n\n    try:\n        arguments = docopt(doc, sys.argv[1:])\n        command = get_command(arguments)\n        # DEBUG mode (if requested)\n        verbose = arguments.pop('--verbose', False)\n        if verbose:\n            logging_config['loggers']['gcdt']['level'] = 'DEBUG'\n        dictConfig(logging_config)\n\n        if dispatch_only is None:\n            dispatch_only = ['version']\n        assert tool in ['gcdt', 'kumo', 'tenkai', 'ramuda', 'yugen']\n\n        if command in dispatch_only:\n            # handle commands that do not need a lifecycle\n            # Note: `dispatch_only` commands do not have a check for ENV variable!\n            check_gcdt_update()\n            return cmd.dispatch(arguments)\n        else:\n            env = get_env()\n            if not env:\n                log.error('\\'ENV\\' environment variable not set!')\n                return 1\n\n            awsclient = AWSClient(botocore.session.get_session())\n            return lifecycle(awsclient, env, tool, command, arguments)\n    except GracefulExit as e:\n        log.info('Received %s signal - exiting command \\'%s %s\\'',\n                 str(e), tool, command)\n        return 1", "response": "main function for gcdt tools parametrized main function to initiate gcdt lifecycle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef MOVS(self, params):\n        Ra, Rb = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n\n        if self.is_immediate(Rb):\n            self.check_arguments(low_registers=[Ra], imm8=[Rb])\n\n            def MOVS_func():\n                self.register[Ra] = self.convert_to_integer(Rb[1:])\n\n                # Set N and Z status flags\n                self.set_NZ_flags(self.register[Ra])\n\n            return MOVS_func\n        elif self.is_register(Rb):\n            self.check_arguments(low_registers=(Ra, Rb))\n\n            def MOVS_func():\n                self.register[Ra] = self.register[Rb]\n\n                self.set_NZ_flags(self.register[Ra])\n\n            return MOVS_func\n        else:\n            raise iarm.exceptions.ParsingError(\"Unknown parameter: {}\".format(Rb))", "response": "MOVS Ra Rb MOVS Ra imm8"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef MVNS(self, params):\n        Ra, Rb = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n\n        self.check_arguments(low_registers=(Ra, Rb))\n\n        def MVNS_func():\n            self.register[Ra] = ~self.register[Rb]\n            self.set_NZ_flags(self.register[Ra])\n\n        return MVNS_func", "response": "MVNS Ra Rb Negate the value in Rb and store it in Ra\n        Ra and Rb\n        Rb must be a low register"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrevs Ra, Rb Reverse the byte order in register Rb and store the result in Ra", "response": "def REV(self, params):\n        \"\"\"\n        REV Ra, Rb\n\n        Reverse the byte order in register Rb and store the result in Ra\n        \"\"\"\n        Ra, Rb = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n\n        self.check_arguments(low_registers=(Ra, Rb))\n\n        def REV_func():\n            self.register[Ra] = ((self.register[Rb] & 0xFF000000) >> 24) | \\\n                                ((self.register[Rb] & 0x00FF0000) >> 8) | \\\n                                ((self.register[Rb] & 0x0000FF00) << 8) | \\\n                                ((self.register[Rb] & 0x000000FF) << 24)\n\n        return REV_func"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SXTB(self, params):\n        Ra, Rb = self.get_two_parameters(r'\\s*([^\\s,]*),\\s*([^\\s,]*)(,\\s*[^\\s,]*)*\\s*', params)\n\n        self.check_arguments(low_registers=(Ra, Rb))\n\n        def SXTB_func():\n            if self.register[Rb] & (1 << 7):\n                self.register[Ra] = 0xFFFFFF00 + (self.register[Rb] & 0xFF)\n            else:\n                self.register[Ra] = (self.register[Rb] & 0xFF)\n\n        return SXTB_func", "response": "STXB Ra, Rb\n\n        Sign extend the byte in Rb and store the result in Ra"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef SXTH(self, params):\n        Ra, Rb = self.get_two_parameters(r'\\s*([^\\s,]*),\\s*([^\\s,]*)(,\\s*[^\\s,]*)*\\s*', params)\n\n        self.check_arguments(low_registers=(Ra, Rb))\n\n        def SXTH_func():\n            if self.register[Rb] & (1 << 15):\n                self.register[Ra] = 0xFFFF0000 + (self.register[Rb] & 0xFFFF)\n            else:\n                self.register[Ra] = (self.register[Rb] & 0xFFFF)\n\n        return SXTH_func", "response": "SXH Ra Rb Sign extend the half word in Rb and store the result in Ra\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting type of event e. g. s3 events kinesis log_group_name_prefix etc.", "response": "def _get_event_type(evt_source):\n    \"\"\"Get type of event e.g. 's3', 'events', 'kinesis',...\n\n    :param evt_source:\n    :return:\n    \"\"\"\n    if 'schedule' in evt_source:\n        return 'events'\n    elif 'pattern' in evt_source:\n        return 'events'\n    elif 'log_group_name_prefix' in evt_source:\n        return 'cloudwatch_logs'\n    else:\n        arn = evt_source['arn']\n        _, _, svc, _ = arn.split(':', 3)\n        return svc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_event_source_obj(awsclient, evt_source):\n    event_source_map = {\n        'dynamodb': event_source.dynamodb_stream.DynamoDBStreamEventSource,\n        'kinesis': event_source.kinesis.KinesisEventSource,\n        's3': event_source.s3.S3EventSource,\n        'sns': event_source.sns.SNSEventSource,\n        'events': event_source.cloudwatch.CloudWatchEventSource,\n        'cloudfront': event_source.cloudfront.CloudFrontEventSource,\n        'cloudwatch_logs': event_source.cloudwatch_logs.CloudWatchLogsEventSource,\n    }\n\n    evt_type = _get_event_type(evt_source)\n    event_source_func = event_source_map.get(evt_type, None)\n    if not event_source:\n        raise ValueError('Unknown event source: {0}'.format(\n            evt_source['arn']))\n\n    return event_source_func(awsclient, evt_source)", "response": "Given an awsclient event_source dictionary item\n    create an event_source object of the appropriate event type\n    and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_event_source(awsclient, evt_source, lambda_arn):\n    event_source_obj = _get_event_source_obj(awsclient, evt_source)\n\n    # (where zappa goes like remove, add)\n    # we go with update and add like this:\n    if event_source_obj.exists(lambda_arn):\n        event_source_obj.update(lambda_arn)\n    else:\n        event_source_obj.add(lambda_arn)", "response": "Given an event_source dictionary create the object and add the event source."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving an event source from the event source dictionary.", "response": "def _remove_event_source(awsclient, evt_source, lambda_arn):\n    \"\"\"\n    Given an event_source dictionary, create the object and remove the event source.\n    \"\"\"\n    event_source_obj = _get_event_source_obj(awsclient, evt_source)\n    if event_source_obj.exists(lambda_arn):\n        event_source_obj.remove(lambda_arn)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving an event source dictionary create the object and get the event source status.", "response": "def _get_event_source_status(awsclient, evt_source, lambda_arn):\n    \"\"\"\n    Given an event_source dictionary, create the object and get the event source status.\n    \"\"\"\n    event_source_obj = _get_event_source_obj(awsclient, evt_source)\n    return event_source_obj.status(lambda_arn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wire_deprecated(awsclient, function_name, s3_event_sources=None,\n                    time_event_sources=None,\n                    alias_name=ALIAS_NAME):\n    \"\"\"Deprecated! Please use wire!\n\n\n    :param awsclient:\n    :param function_name:\n    :param s3_event_sources: dictionary\n    :param time_event_sources:\n    :param alias_name:\n    :return: exit_code\n    \"\"\"\n    if not lambda_exists(awsclient, function_name):\n        log.error(colored.red('The function you try to wire up doesn\\'t ' +\n                          'exist... Bailing out...'))\n        return 1\n    client_lambda = awsclient.get_client('lambda')\n    lambda_function = client_lambda.get_function(FunctionName=function_name)\n    lambda_arn = client_lambda.get_alias(FunctionName=function_name,\n                                         Name=alias_name)['AliasArn']\n    log.info('wiring lambda_arn %s ...' % lambda_arn)\n\n    if lambda_function is not None:\n        s3_events_ensure_exists, s3_events_ensure_absent = filter_events_ensure(\n            s3_event_sources)\n        cloudwatch_events_ensure_exists, cloudwatch_events_ensure_absent = \\\n            filter_events_ensure(time_event_sources)\n\n        for s3_event_source in s3_events_ensure_absent:\n            _ensure_s3_event(awsclient, s3_event_source, function_name,\n                             alias_name, lambda_arn, s3_event_source['ensure'])\n        for s3_event_source in s3_events_ensure_exists:\n            _ensure_s3_event(awsclient, s3_event_source, function_name,\n                             alias_name, lambda_arn, s3_event_source['ensure'])\n\n        for time_event in cloudwatch_events_ensure_absent:\n            _ensure_cloudwatch_event(awsclient, time_event, function_name,\n                                     alias_name, lambda_arn,\n                                     time_event['ensure'])\n        for time_event in cloudwatch_events_ensure_exists:\n            _ensure_cloudwatch_event(awsclient, time_event, function_name,\n                                     alias_name, lambda_arn,\n                                     time_event['ensure'])\n    return 0", "response": "Deprecated! Please use wire!"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unwire_deprecated(awsclient, function_name, s3_event_sources=None,\n                      time_event_sources=None, alias_name=ALIAS_NAME):\n    \"\"\"Deprecated! Please use unwire!\n\n    :param awsclient:\n    :param function_name:\n    :param s3_event_sources: dictionary\n    :param time_event_sources:\n    :param alias_name:\n    :return: exit_code\n    \"\"\"\n    if not lambda_exists(awsclient, function_name):\n        log.error(colored.red('The function you try to wire up doesn\\'t ' +\n                          'exist... Bailing out...'))\n        return 1\n\n    client_lambda = awsclient.get_client('lambda')\n    lambda_function = client_lambda.get_function(FunctionName=function_name)\n    lambda_arn = client_lambda.get_alias(FunctionName=function_name,\n                                         Name=alias_name)['AliasArn']\n    log.info('UN-wiring lambda_arn %s ' % lambda_arn)\n    policies = None\n    try:\n        result = client_lambda.get_policy(FunctionName=function_name,\n                                          Qualifier=alias_name)\n        policies = json.loads(result['Policy'])\n    except ClientError as e:\n        if e.response['Error']['Code'] == 'ResourceNotFoundException':\n            log.warn(\"Permission policies not found\")\n        else:\n            raise e\n\n    if lambda_function is not None:\n        #### S3 Events\n        # for every permission - delete it and corresponding rule (if exists)\n        if policies:\n            for statement in policies['Statement']:\n                if statement['Principal']['Service'] == 's3.amazonaws.com':\n                    source_bucket = get_bucket_from_s3_arn(\n                        statement['Condition']['ArnLike']['AWS:SourceArn'])\n                    log.info('\\tRemoving S3 permission {} invoking {}'.format(\n                        source_bucket, lambda_arn))\n                    _remove_permission(awsclient, function_name,\n                                       statement['Sid'], alias_name)\n                    log.info('\\tRemoving All S3 events {} invoking {}'.format(\n                        source_bucket, lambda_arn))\n                    _remove_events_from_s3_bucket(awsclient, source_bucket,\n                                                  lambda_arn)\n\n        # Case: s3 events without permissions active \"safety measure\"\n        for s3_event_source in s3_event_sources:\n            bucket_name = s3_event_source.get('bucket')\n            _remove_events_from_s3_bucket(awsclient, bucket_name, lambda_arn)\n\n        #### CloudWatch Events\n        # for every permission - delete it and corresponding rule (if exists)\n        if policies:\n            for statement in policies['Statement']:\n                if statement['Principal']['Service'] == 'events.amazonaws.com':\n                    rule_name = get_rule_name_from_event_arn(\n                        statement['Condition']['ArnLike']['AWS:SourceArn'])\n                    log.info(\n                        '\\tRemoving Cloudwatch permission {} invoking {}'.format(\n                            rule_name, lambda_arn))\n                    _remove_permission(awsclient, function_name,\n                                       statement['Sid'], alias_name)\n                    log.info('\\tRemoving Cloudwatch rule {} invoking {}'.format(\n                        rule_name, lambda_arn))\n                    _remove_cloudwatch_rule_event(awsclient, rule_name,\n                                                  lambda_arn)\n        # Case: rules without permissions active, \"safety measure\"\n        for time_event in time_event_sources:\n            rule_name = time_event.get('ruleName')\n            _remove_cloudwatch_rule_event(awsclient, rule_name, lambda_arn)\n\n    return 0", "response": "Unwire a function from the given AWS API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _lambda_add_s3_event_source(awsclient, arn, event, bucket, prefix,\n                                suffix):\n    \"\"\"Use only prefix OR suffix\n\n    :param arn:\n    :param event:\n    :param bucket:\n    :param prefix:\n    :param suffix:\n    :return:\n    \"\"\"\n    json_data = {\n        'LambdaFunctionConfigurations': [{\n            'LambdaFunctionArn': arn,\n            'Id': str(uuid.uuid1()),\n            'Events': [event]\n        }]\n    }\n\n    filter_rules = build_filter_rules(prefix, suffix)\n\n    json_data['LambdaFunctionConfigurations'][0].update({\n        'Filter': {\n            'Key': {\n                'FilterRules': filter_rules\n            }\n        }\n    })\n    # http://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-notification-configuration.html\n    # http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html\n    client_s3 = awsclient.get_client('s3')\n\n    bucket_configurations = client_s3.get_bucket_notification_configuration(\n        Bucket=bucket)\n    bucket_configurations.pop('ResponseMetadata')\n\n    if 'LambdaFunctionConfigurations' in bucket_configurations:\n        bucket_configurations['LambdaFunctionConfigurations'].append(\n            json_data['LambdaFunctionConfigurations'][0]\n        )\n    else:\n        bucket_configurations['LambdaFunctionConfigurations'] = json_data[\n            'LambdaFunctionConfigurations']\n\n    response = client_s3.put_bucket_notification_configuration(\n        Bucket=bucket,\n        NotificationConfiguration=bucket_configurations\n    )\n    # TODO don't return a table, but success state\n    return json2table(response)", "response": "Add an event source to a list of events in a bucket."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_eigen(hint=None):\n  r'''\nTry to find the Eigen library. If successful the include directory is returned.\n  '''\n\n  # search with pkgconfig\n  # ---------------------\n\n  try:\n\n    import pkgconfig\n\n    if pkgconfig.installed('eigen3','>3.0.0'):\n      return pkgconfig.parse('eigen3')['include_dirs'][0]\n\n  except:\n    pass\n\n  # manual search\n  # -------------\n\n  search_dirs = [] if hint is None else hint\n  search_dirs += [\n    \"/usr/local/include/eigen3\",\n    \"/usr/local/homebrew/include/eigen3\",\n    \"/opt/local/var/macports/software/eigen3\",\n    \"/opt/local/include/eigen3\",\n    \"/usr/include/eigen3\",\n    \"/usr/include/local\",\n    \"/usr/include\",\n  ]\n\n  for d in search_dirs:\n    path = os.path.join(d, \"Eigen\", \"Dense\")\n    if os.path.exists(path):\n      vf = os.path.join(d, \"Eigen\", \"src\", \"Core\", \"util\", \"Macros.h\")\n      if not os.path.exists(vf):\n        continue\n      src = open(vf, \"r\").read()\n      v1 = re.findall(\"#define EIGEN_WORLD_VERSION (.+)\", src)\n      v2 = re.findall(\"#define EIGEN_MAJOR_VERSION (.+)\", src)\n      v3 = re.findall(\"#define EIGEN_MINOR_VERSION (.+)\", src)\n      if not len(v1) or not len(v2) or not len(v3):\n        continue\n      v = \"{0}.{1}.{2}\".format(v1[0], v2[0], v3[0])\n      print(\"Found Eigen version {0} in: {1}\".format(v, d))\n      return d\n\n  return None", "response": "r Try to find the Eigen library. If it fails return None."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads a file to AWS S3 bucket.", "response": "def upload_file_to_s3(awsclient, bucket, key, filename):\n    \"\"\"Upload a file to AWS S3 bucket.\n\n    :param awsclient:\n    :param bucket:\n    :param key:\n    :param filename:\n    :return:\n    \"\"\"\n    client_s3 = awsclient.get_client('s3')\n    transfer = S3Transfer(client_s3)\n    # Upload /tmp/myfile to s3://bucket/key and print upload progress.\n    transfer.upload_file(filename, bucket, key)\n    response = client_s3.head_object(Bucket=bucket, Key=key)\n    etag = response.get('ETag')\n    version_id = response.get('VersionId', None)\n    return etag, version_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_file_from_s3(awsclient, bucket, key):\n    client_s3 = awsclient.get_client('s3')\n    response = client_s3.delete_object(Bucket=bucket, Key=key)", "response": "Remove a file from an AWS S3 bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists the contents of a bucket.", "response": "def ls(awsclient, bucket, prefix=None):\n    \"\"\"List bucket contents\n\n    :param awsclient:\n    :param bucket:\n    :param prefix:\n    :return:\n    \"\"\"\n    # this works until 1000 keys!\n    params = {'Bucket': bucket}\n    if prefix:\n        params['Prefix'] = prefix\n    client_s3 = awsclient.get_client('s3')\n    objects = client_s3.list_objects_v2(**params)\n    if objects['KeyCount'] > 0:\n        keys = [k['Key'] for k in objects['Contents']]\n        return keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a mail and returns a new EmailMultiAlternatives instance.", "response": "def render_to_mail(template, context, **kwargs):\n    \"\"\"\n    Renders a mail and returns the resulting ``EmailMultiAlternatives``\n    instance\n\n    * ``template``: The base name of the text and HTML (optional) version of\n      the mail.\n    * ``context``: The context used to render the mail. This context instance\n      should contain everything required.\n    * Additional keyword arguments are passed to the ``EmailMultiAlternatives``\n      instantiation. Use those to specify the ``to``, ``headers`` etc.\n      arguments.\n\n    Usage example::\n\n        # Render the template myproject/hello_mail.txt (first non-empty line\n        # contains the subject, third to last the body) and optionally the\n        # template myproject/hello_mail.html containing the alternative HTML\n        # representation.\n        message = render_to_mail('myproject/hello_mail', {}, to=[email])\n        message.send()\n    \"\"\"\n    lines = iter(\n        line.rstrip()\n        for line in render_to_string(\"%s.txt\" % template, context).splitlines()\n    )\n\n    subject = \"\"\n    try:\n        while True:\n            line = next(lines)\n            if line:\n                subject = line\n                break\n    except StopIteration:  # if lines is empty\n        pass\n\n    body = \"\\n\".join(lines).strip(\"\\n\")\n    message = EmailMultiAlternatives(subject=subject, body=body, **kwargs)\n\n    try:\n        message.attach_alternative(\n            render_to_string(\"%s.html\" % template, context), \"text/html\"\n        )\n    except TemplateDoesNotExist:\n        pass\n\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the confirmation URL for the given email.", "response": "def get_confirmation_url(email, request, name=\"email_registration_confirm\", **kwargs):\n    \"\"\"\n    Returns the confirmation URL\n    \"\"\"\n    return request.build_absolute_uri(\n        reverse(name, kwargs={\"code\": get_confirmation_code(email, request, **kwargs)})\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends the registration mail to the given email address.", "response": "def send_registration_mail(email, *, request, **kwargs):\n    \"\"\"send_registration_mail(email, *, request, **kwargs)\n    Sends the registration mail\n\n    * ``email``: The email address where the registration link should be\n      sent to.\n    * ``request``: A HTTP request instance, used to construct the complete\n      URL (including protocol and domain) for the registration link.\n    * Additional keyword arguments for ``get_confirmation_url`` respectively\n      ``get_confirmation_code``.\n\n    The mail is rendered using the following two templates:\n\n    * ``registration/email_registration_email.txt``: The first line of this\n      template will be the subject, the third to the last line the body of the\n      email.\n    * ``registration/email_registration_email.html``: The body of the HTML\n      version of the mail. This template is **NOT** available by default and\n      is not required either.\n    \"\"\"\n\n    render_to_mail(\n        \"registration/email_registration_email\",\n        {\"url\": get_confirmation_url(email, request, **kwargs)},\n        to=[email],\n    ).send()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(code, *, max_age):\n    try:\n        data = get_signer().unsign(code, max_age=max_age)\n    except signing.SignatureExpired:\n        raise ValidationError(\n            _(\"The link is expired. Please request another registration link.\"),\n            code=\"email_registration_expired\",\n        )\n\n    except signing.BadSignature:\n        raise ValidationError(\n            _(\n                \"Unable to verify the signature. Please request a new\"\n                \" registration link.\"\n            ),\n            code=\"email_registration_signature\",\n        )\n\n    return data.split(\":\", 1)", "response": "Decode the code from the registration link and returns a tuple consisting of the email address and the payload which was passed through to the get_confirmation_code method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_some_work(\n        self,\n        work_dict):\n    \"\"\"do_some_work\n\n    :param work_dict: dictionary for key/values\n    \"\"\"\n\n    label = \"do_some_work\"\n\n    log.info((\"task - {} - start \"\n              \"work_dict={}\")\n             .format(label,\n                     work_dict))\n\n    ret_data = {\n        \"job_results\": (\"some response key={}\").format(\n                            str(uuid.uuid4()))\n    }\n\n    log.info((\"task - {} - result={} done\")\n             .format(\n                 ret_data,\n                 label))\n\n    return ret_data", "response": "This function is called by the task manager to do some work on the resource in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_record(awsclient, name_prefix, instance_reference, type=\"A\", host_zone_name=None):\n\n    # Only fetch the host zone from the COPS stack if nessary\n    if host_zone_name is None:\n        host_zone_name = _retrieve_stack_host_zone_name(awsclient)\n\n    if not (type == \"A\" or type == \"CNAME\"):\n        raise Exception(\"Record set type is not supported!\")\n\n    name_of_record = name_prefix \\\n                         .replace('.', '') \\\n                         .replace('-', '') \\\n                         .title() + \"HostRecord\"\n\n    # Reference EC2 instance automatically to their private IP\n    if isinstance(instance_reference, Instance):\n        resource_record = troposphere.GetAtt(\n                instance_reference,\n                \"PrivateIp\"\n        )\n    else:\n        resource_record = instance_reference\n\n    return RecordSetType(\n            name_of_record,\n            HostedZoneName=host_zone_name,\n            Name=troposphere.Join(\"\", [\n                name_prefix + \".\",\n                host_zone_name,\n            ]),\n            Type=type,\n            TTL=TTL_DEFAULT,\n            ResourceRecords=[\n                resource_record\n            ],\n    )", "response": "Creates a new record set for a given instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the host zone name from the default stack.", "response": "def _retrieve_stack_host_zone_name(awsclient, default_stack_name=None):\n    \"\"\"\n    Use service discovery to get the host zone name from the default stack\n\n    :return: Host zone name as string\n    \"\"\"\n    global _host_zone_name\n\n    if _host_zone_name is not None:\n        return _host_zone_name\n\n    env = get_env()\n\n    if env is None:\n        print(\"Please set environment...\")\n        # TODO: why is there a sys.exit in library code used by cloudformation!!!\n        sys.exit()\n\n    if default_stack_name is None:\n        # TODO why 'dp-<env>'? - this should not be hardcoded!\n        default_stack_name = 'dp-%s' % env\n    default_stack_output = get_outputs_for_stack(awsclient, default_stack_name)\n\n    if HOST_ZONE_NAME__STACK_OUTPUT_NAME not in default_stack_output:\n        print(\"Please debug why default stack '{}' does not contain '{}'...\".format(\n                default_stack_name,\n                HOST_ZONE_NAME__STACK_OUTPUT_NAME,\n        ))\n        # TODO: why is there a sys.exit in library code used by cloudformation!!!\n        sys.exit()\n\n    _host_zone_name = default_stack_output[HOST_ZONE_NAME__STACK_OUTPUT_NAME] + \".\"\n    return _host_zone_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading and register installed gcdt plugins.", "response": "def load_plugins(group='gcdt10'):\n    \"\"\"Load and register installed gcdt plugins.\n    \"\"\"\n    # on using entrypoints:\n    # http://stackoverflow.com/questions/774824/explain-python-entry-points\n    # TODO: make sure we do not have conflicting generators installed!\n    for ep in pkg_resources.iter_entry_points(group, name=None):\n        plugin = ep.load()  # load the plugin\n        if check_hook_mechanism_is_intact(plugin):\n            if check_register_present(plugin):\n                plugin.register()   # register the plugin so it listens to gcdt_signals\n        else:\n            log.warning('No valid hook configuration: %s. Not using hooks!', plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads and register installed gcdt plugins.", "response": "def get_plugin_versions(group='gcdt10'):\n    \"\"\"Load and register installed gcdt plugins.\n    \"\"\"\n    versions = {}\n    for ep in pkg_resources.iter_entry_points(group, name=None):\n        versions[ep.dist.project_name] = ep.dist.version\n\n    return versions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_log_group(awsclient, log_group_name):\n    client_logs = awsclient.get_client('logs')\n\n    response = client_logs.delete_log_group(\n        logGroupName=log_group_name\n    )", "response": "Delete the specified log group"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef put_retention_policy(awsclient, log_group_name, retention_in_days):\n    try:\n        # Note: for AWS Lambda the log_group is created once the first\n        # log event occurs. So if the log_group does not exist we create it\n        create_log_group(awsclient, log_group_name)\n    except GracefulExit:\n        raise\n    except Exception:\n        # TODO check that it is really a ResourceAlreadyExistsException\n        pass\n\n    client_logs = awsclient.get_client('logs')\n    response = client_logs.put_retention_policy(\n        logGroupName=log_group_name,\n        retentionInDays=retention_in_days\n    )", "response": "Sets the retention of the specified log group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters logs in ramuda.", "response": "def filter_log_events(awsclient, log_group_name, start_ts, end_ts=None):\n    \"\"\"\n    Note: this is used to retrieve logs in ramuda.\n\n    :param log_group_name: log group name\n    :param start_ts: timestamp\n    :param end_ts: timestamp\n    :return: list of log entries\n    \"\"\"\n    client_logs = awsclient.get_client('logs')\n    # TODO use all_pages instead!\n    logs = []\n    next_token = None\n    while True:\n        request = {\n            'logGroupName': log_group_name,\n            'startTime': start_ts\n        }\n        if end_ts:\n            request['endTime'] = end_ts\n        if next_token:\n            request['nextToken'] = next_token\n        response = client_logs.filter_log_events(**request)\n        logs.extend(\n            [{'timestamp': e['timestamp'], 'message': e['message']}\n             for e in response['events']]\n        )\n        if 'nextToken' not in response:\n            break\n        next_token = response['nextToken']\n    return logs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef describe_log_group(awsclient, log_group_name):\n    client_logs = awsclient.get_client('logs')\n\n    request = {\n        'logGroupNamePrefix': log_group_name,\n        'limit': 1\n    }\n    response = client_logs.describe_log_groups(**request)\n    if response['logGroups']:\n        return response['logGroups'][0]\n    else:\n        return", "response": "Get info on the specified log group"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef describe_log_stream(awsclient, log_group_name, log_stream_name):\n    client_logs = awsclient.get_client('logs')\n\n    response = client_logs.describe_log_streams(\n        logGroupName=log_group_name,\n        logStreamNamePrefix=log_stream_name,\n        limit=1\n    )\n    if response['logStreams']:\n        return response['logStreams'][0]\n    else:\n        return", "response": "Get info on the specified log stream"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a log group with the specified name.", "response": "def create_log_group(awsclient, log_group_name):\n    \"\"\"Creates a log group with the specified name.\n\n    :param log_group_name: log group name\n    :return:\n    \"\"\"\n    client_logs = awsclient.get_client('logs')\n\n    response = client_logs.create_log_group(\n        logGroupName=log_group_name,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a log stream for the specified log group.", "response": "def create_log_stream(awsclient, log_group_name, log_stream_name):\n    \"\"\"Creates a log stream for the specified log group.\n\n    :param log_group_name: log group name\n    :param log_stream_name: log stream name\n    :return:\n    \"\"\"\n    client_logs = awsclient.get_client('logs')\n\n    response = client_logs.create_log_stream(\n        logGroupName=log_group_name,\n        logStreamName=log_stream_name\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nputs log events for the specified log group and stream.", "response": "def put_log_events(awsclient, log_group_name, log_stream_name, log_events,\n                   sequence_token=None):\n    \"\"\"Put log events for the specified log group and stream.\n\n    :param log_group_name: log group name\n    :param log_stream_name: log stream name\n    :param log_events: [{'timestamp': 123, 'message': 'string'}, ...]\n    :param sequence_token: the sequence token\n    :return: next_token\n    \"\"\"\n    client_logs = awsclient.get_client('logs')\n    request = {\n        'logGroupName': log_group_name,\n        'logStreamName': log_stream_name,\n        'logEvents': log_events\n    }\n    if sequence_token:\n        request['sequenceToken'] = sequence_token\n\n    response = client_logs.put_log_events(**request)\n    if 'rejectedLogEventsInfo' in response:\n        log.warn(response['rejectedLogEventsInfo'])\n    if 'nextSequenceToken' in response:\n        return response['nextSequenceToken']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_log_events(awsclient, log_group_name, log_stream_name, start_ts=None):\n    client_logs = awsclient.get_client('logs')\n\n    request = {\n        'logGroupName': log_group_name,\n        'logStreamName': log_stream_name\n    }\n    if start_ts:\n        request['startTime'] = start_ts\n\n    # TODO exhaust the events!\n    # TODO use all_pages !\n    response = client_logs.get_log_events(**request)\n\n    if 'events' in response and response['events']:\n        return [{'timestamp': e['timestamp'], 'message': e['message']}\n                for e in response['events']]", "response": "Get log events for the specified log group and stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a log stream exists in the log group.", "response": "def check_log_stream_exists(awsclient, log_group_name, log_stream_name):\n    \"\"\"Check\n\n    :param log_group_name: log group name\n    :param log_stream_name: log stream name\n    :return: True / False\n    \"\"\"\n    lg = describe_log_group(awsclient, log_group_name)\n    if lg and lg['logGroupName'] == log_group_name:\n        stream = describe_log_stream(awsclient, log_group_name, log_stream_name)\n        if stream and stream['logStreamName'] == log_stream_name:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode_format_timestamp(timestamp):\n    dt = maya.MayaDT(timestamp / 1000).datetime(naive=True)\n    return dt.strftime('%Y-%m-%d'), dt.strftime('%H:%M:%S')", "response": "Convert unix timestamp into date and time we use in logs output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reload(self):\n        config = self._default_configuration()\n        if self._file_path:\n            config.update(self._load_config_file())\n        if config != self._values:\n            self._values = config\n            return True\n        return False", "response": "Reload the configuration from disk returning True if the configuration has changed from the previous values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_config_file(self):\n        LOGGER.info('Loading configuration from %s', self._file_path)\n        if self._file_path.endswith('json'):\n            config = self._load_json_config()\n        else:\n            config = self._load_yaml_config()\n        for key, value in [(k, v) for k, v in config.items()]:\n            if key.title() != key:\n                config[key.title()] = value\n                del config[key]\n        return flatdict.FlatDict(config)", "response": "Load the configuration file into memory returning the content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_json_config(self):\n        try:\n            return json.loads(self._read_config())\n        except ValueError as error:\n            raise ValueError(\n                'Could not read configuration file: {}'.format(error))", "response": "Load the configuration file in JSON format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_yaml_config(self):\n        try:\n            config = self._read_config()\n        except OSError as error:\n            raise ValueError('Could not read configuration file: %s' % error)\n        try:\n            return yaml.safe_load(config)\n        except yaml.YAMLError as error:\n            message = '\\n'.join(['    > %s' % line\n                                 for line in str(error).split('\\n')])\n            sys.stderr.write('\\n\\n  Error in the configuration file:\\n\\n'\n                             '{}\\n\\n'.format(message))\n            sys.stderr.write('  Configuration should be a valid YAML file.\\n')\n            sys.stderr.write('  YAML format validation available at '\n                             'http://yamllint.com\\n')\n            raise ValueError(error)", "response": "Loads the configuration file from a. yaml or. yml file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _normalize_file_path(file_path):\n        if not file_path:\n            return None\n        elif file_path.startswith('s3://') or \\\n                file_path.startswith('http://') or \\\n                file_path.startswith('https://'):\n            return file_path\n        return path.abspath(file_path)", "response": "Normalizes the file path value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the configuration from the various places it may be read from.", "response": "def _read_config(self):\n        \"\"\"Read the configuration from the various places it may be read from.\n\n        :rtype: str\n        :raises: ValueError\n\n        \"\"\"\n        if not self._file_path:\n            return None\n        elif self._file_path.startswith('s3://'):\n            return self._read_s3_config()\n        elif self._file_path.startswith('http://') or \\\n                self._file_path.startswith('https://'):\n            return self._read_remote_config()\n        elif not path.exists(self._file_path):\n            raise ValueError(\n                'Configuration file not found: {}'.format(self._file_path))\n\n        with open(self._file_path, 'r') as handle:\n            return handle.read()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_remote_config(self):\n        try:\n            import requests\n        except ImportError:\n            requests = None\n        if not requests:\n            raise ValueError(\n                'Remote config URL specified but requests not installed')\n        result = requests.get(self._file_path)\n        if not result.ok:\n            raise ValueError(\n                'Failed to retrieve remote config: {}'.format(\n                    result.status_code))\n        return result.text", "response": "Read a remote config via HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_s3_config(self):\n        try:\n            import boto3\n            import botocore.exceptions\n        except ImportError:\n            boto3, botocore = None, None\n\n        if not boto3:\n            raise ValueError(\n                's3 URL specified for configuration but boto3 not installed')\n        parsed = parse.urlparse(self._file_path)\n        try:\n            response = boto3.client(\n                's3', endpoint_url=os.environ.get('S3_ENDPOINT')).get_object(\n                    Bucket=parsed.netloc, Key=parsed.path.lstrip('/'))\n        except botocore.exceptions.ClientError as e:\n            raise ValueError(\n                'Failed to download configuration from S3: {}'.format(e))\n        return response['Body'].read().decode('utf-8')", "response": "Read in the value of the configuration file in Amazon S3."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the internal configuration values removing debug_only handlers if debug is False. Returns True if the configuration has changed from previous configuration values. Returns False if the configuration has changed from previous configuration values. Returns True if the configuration has changed from previous configuration values.", "response": "def update(self, configuration, debug=None):\n        \"\"\"Update the internal configuration values, removing debug_only\n        handlers if debug is False. Returns True if the configuration has\n        changed from previous configuration values.\n\n        :param dict configuration: The logging configuration\n        :param bool debug: Toggles use of debug_only loggers\n        :rtype: bool\n\n        \"\"\"\n        if self.config != dict(configuration) and debug != self.debug:\n            self.config = dict(configuration)\n            self.debug = debug\n            self.configure()\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configure(self):\n        if self.debug is not None and not self.debug:\n            self._remove_debug_handlers()\n        self._remove_debug_only()\n        logging.config.dictConfig(self.config)\n        try:\n            logging.captureWarnings(True)\n        except AttributeError:\n            pass", "response": "Configure the Python stdlib logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _remove_debug_handlers(self):\n        remove = list()\n        for handler in self.config[self.HANDLERS]:\n            if self.config[self.HANDLERS][handler].get('debug_only'):\n                remove.append(handler)\n        for handler in remove:\n            del self.config[self.HANDLERS][handler]\n            for logger in self.config[self.LOGGERS].keys():\n                logger = self.config[self.LOGGERS][logger]\n                if handler in logger[self.HANDLERS]:\n                    logger[self.HANDLERS].remove(handler)\n        self._remove_debug_only()", "response": "Remove any handlers with an attribute of debug_only that is True and\n        remove any references to said handlers that are\n        referencing them."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating through each handler removing the invalid dictConfig key of debug_only.", "response": "def _remove_debug_only(self):\n        \"\"\"Iterate through each handler removing the invalid dictConfig key of\n        debug_only.\n\n        \"\"\"\n        LOGGER.debug('Removing debug only from handlers')\n        for handler in self.config[self.HANDLERS]:\n            if self.DEBUG_ONLY in self.config[self.HANDLERS][handler]:\n                del self.config[self.HANDLERS][handler][self.DEBUG_ONLY]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_dictionary(self):\n        return {to_camel_case(i): Serializable._convert_to_dictionary(self.__dict__[i])\n                for i in self.__dict__ if self.__dict__[i] is not None}", "response": "Convert this object to a dictionary with formatting appropriate for a PIF."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_to_dictionary(obj):\n        if isinstance(obj, list):\n            return [Serializable._convert_to_dictionary(i) for i in obj]\n        elif hasattr(obj, 'as_dictionary'):\n            return obj.as_dictionary()\n        else:\n            return obj", "response": "Converts obj to a dictionary with formatting appropriate for a PIO object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_object(class_, obj):\n        if isinstance(obj, list):\n            return [Serializable._get_object(class_, i) for i in obj]\n        elif isinstance(obj, dict):\n            return class_(**keys_to_snake_case(obj))\n        else:\n            return obj", "response": "Helper function that returns an object or a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef damping(temp, relhum, freq, pres=101325):\n    temp += 273.15  # convert to kelvin\n    pres = pres / 101325.0  # convert to relative pressure\n    c_humid = 4.6151 - 6.8346 * pow((273.15 / temp), 1.261)\n    hum = relhum * pow(10.0, c_humid) * pres\n    tempr = temp / 293.15  # convert to relative air temp (re 20 deg C)\n    frO = pres * (24.0 + 4.04e4 * hum * (0.02 + hum) / (0.391 + hum))\n    frN = (pres * pow(tempr, -0.5) * (9.0 + 280.0 * hum * math.exp(-4.17 *\n        (pow(tempr, (-1.0 / 3.0)) - 1.0))))\n    damp = (8.686 * freq * freq * (\n            1.84e-11 * (1.0 / pres) * math.sqrt(tempr) +\n            pow(tempr, -2.5) *\n            (\n                0.01275 * (math.exp(-2239.1 / temp) * 1.0 /\n                (frO + freq * freq / frO)) +\n                0.1068 * (\n                    math.exp(-3352 / temp) * 1.0 /\n                    (frN + freq * freq / frN)\n                )\n            )\n        )\n    )\n    return damp", "response": "Calculates the damping factor for sound in dB based on temperature humidity and sound frequency."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef total_level(source_levels):\n    sums = 0.0\n    for l in source_levels:\n        if l is None:\n            continue\n        if l == 0:\n            continue\n        sums += pow(10.0, float(l) / 10.0)\n    level = 10.0 * math.log10(sums)\n    return level", "response": "Calculates the total sound pressure level based on multiple source levels\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef total_rated_level(octave_frequencies):\n    sums = 0.0\n    for band in OCTAVE_BANDS.keys():\n        if band not in octave_frequencies:\n            continue\n        if octave_frequencies[band] is None:\n            continue\n        if octave_frequencies[band] == 0:\n            continue\n        sums += pow(10.0, ((float(octave_frequencies[band]) + OCTAVE_BANDS[band][1]) / 10.0))\n    level = 10.0 * math.log10(sums)\n    return level", "response": "Calculates the A - rated total sound pressure level based on octave frequencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef leq3(levels):\n    n = float(len(levels))\n    sums = 0.0\n    if sum(levels) == 0.0:\n        return 0.0\n    for l in levels:\n        if l == 0:\n            continue\n        sums += pow(10.0, float(l) / 10.0)\n    leq3 = 10.0 * math.log10((1.0 / n) * sums)\n    leq3 = max(0.0, leq3)\n    return leq3", "response": "Calculates the energy - equivalent ( Leq3 ) value for a given set of regular measurement intervals."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the sound pressure level in dependence of a distance between a perfect ball - shaped source and spread.", "response": "def distant_level(reference_level, distance, reference_distance=1.0):\n    \"\"\"\n    Calculates the sound pressure level\n    in dependence of a distance\n    where a perfect ball-shaped source and spread is assumed.\n\n    reference_level: Sound pressure level in reference distance in dB\n    distance: Distance to calculate sound pressure level for, in meters\n    reference_distance: reference distance in meters (defaults to 1)\n    \"\"\"\n    rel_dist = float(reference_distance) / float(distance)\n    level = float(reference_level) + 20.0 * (math.log(rel_dist) / math.log(10))\n    return level"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the damped A - rated total sound pressure level in a given distance temperature and relative humidity from octave frequency sound pressure levels in a given reference distance.", "response": "def distant_total_damped_rated_level(\n            octave_frequencies,\n            distance,\n            temp,\n            relhum,\n            reference_distance=1.0):\n    \"\"\"\n    Calculates the damped, A-rated total sound pressure level\n    in a given distance, temperature and relative humidity\n    from octave frequency sound pressure levels in a reference distance\n    \"\"\"\n    damping_distance = distance - reference_distance\n    sums = 0.0\n    for band in OCTAVE_BANDS.keys():\n        if band not in octave_frequencies:\n            continue\n        if octave_frequencies[band] is None:\n            continue\n        # distance-adjusted level per band\n        distant_val = distant_level(\n            reference_level=float(octave_frequencies[band]),\n            distance=distance,\n            reference_distance=reference_distance\n        )\n        # damping\n        damp_per_meter = damping(\n            temp=temp,\n            relhum=relhum,\n            freq=OCTAVE_BANDS[band][0])\n        distant_val = distant_val - (damping_distance * damp_per_meter)\n        # applyng A-rating\n        distant_val += OCTAVE_BANDS[band][1]\n        sums += pow(10.0, (distant_val / 10.0))\n    level = 10.0 * math.log10(sums)\n    return level"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ASRS(self, params):\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        if self.is_register(Rc):\n            # ASRS Ra, Ra, Rb\n            self.check_arguments(low_registers=(Ra, Rc))\n            self.match_first_two_parameters(Ra, Rb)\n\n            def ASRS_func():\n                # Set the C flag, or the last shifted out bit\n                if (self.register[Rc] > 0) and (self.register[Rb] & (1 << (self.register[Rc] - 1))):\n                    self.set_APSR_flag_to_value('C', 1)\n                else:\n                    self.set_APSR_flag_to_value('C', 0)\n\n                if self.register[Ra] & (1 << (self._bit_width - 1)):\n                    self.register[Ra] = (self.register[Ra] >> self.register[Rc]) | (\n                        int('1' * self.register[Rc], 2) << (self._bit_width - self.register[Rc]))\n                else:\n                    self.register[Ra] = self.register[Ra] >> self.register[Rc]\n                self.set_NZ_flags(self.register[Ra])\n        else:\n            # ASRS Ra, Rb, #imm5_counting\n            self.check_arguments(low_registers=(Ra, Rb), imm5_counting=(Rc,))\n            shift_amount = self.check_immediate(Rc)\n\n            def ASRS_func():\n                # Set the C flag, or the last shifted out bit\n                if self.register[Rb] & (1 << (shift_amount - 1)):\n                    self.set_APSR_flag_to_value('C', 1)\n                else:\n                    self.set_APSR_flag_to_value('C', 0)\n\n                if self.register[Ra] & (1 << (self._bit_width - 1)):\n                    self.register[Ra] = (self.register[Ra] >> shift_amount) | (\n                        int('1' * shift_amount, 2) << (self._bit_width - shift_amount))\n                else:\n                    self.register[Ra] = self.register[Rb] >> shift_amount\n                self.set_NZ_flags(self.register[Ra])\n\n        return ASRS_func", "response": "AsRS Ra Rb Rc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef LSLS(self, params):\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        if self.is_register(Rc):\n            # LSLS Ra, Ra, Rb\n            self.check_arguments(low_registers=(Ra, Rc))\n            self.match_first_two_parameters(Ra, Rb)\n\n            def LSLS_func():\n                # Set the C flag, or the last shifted out bit\n                if (self.register[Rc] < self._bit_width) and (self.register[Ra] & (1 << (self._bit_width - self.register[Rc]))):\n                    self.set_APSR_flag_to_value('C', 1)\n                else:\n                    self.set_APSR_flag_to_value('C', 0)\n\n                self.register[Ra] = self.register[Ra] << self.register[Rc]\n                self.set_NZ_flags(self.register[Ra])\n        else:\n            # LSLS Ra, Rb, #imm5\n            self.check_arguments(low_registers=(Ra, Rb), imm5=(Rc,))\n            shift_amount = self.check_immediate(Rc)\n\n            def LSLS_func():\n                # Set the C flag, or the last shifted out bit\n                if (shift_amount < self._bit_width) and (self.register[Rb] & (1 << (self._bit_width - shift_amount))):\n                    self.set_APSR_flag_to_value('C', 1)\n                else:\n                    self.set_APSR_flag_to_value('C', 0)\n\n                self.register[Ra] = self.register[Rb] << shift_amount\n                self.set_NZ_flags(self.register[Ra])\n\n        return LSLS_func", "response": "Function LSLS Ra Rb Rc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef LSRS(self, params):\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        if self.is_register(Rc):\n            # LSRS Ra, Ra, Rb\n            self.check_arguments(low_registers=(Ra, Rc))\n            self.match_first_two_parameters(Ra, Rb)\n\n            def LSRS_func():\n                # Set the C flag, or the last shifted out bit\n                if (self.register[Rc] > 0) and (self.register[Rb] & (1 << (self.register[Rc] - 1))):\n                    self.set_APSR_flag_to_value('C', 1)\n                else:\n                    self.set_APSR_flag_to_value('C', 0)\n\n                self.register[Ra] = self.register[Ra] >> self.register[Rc]\n                self.set_NZ_flags(self.register[Ra])\n        else:\n            # LSRS Ra, Rb, #imm5_counting\n            self.check_arguments(low_registers=(Ra, Rb), imm5_counting=(Rc,))\n            shift_amount = self.check_immediate(Rc)\n\n            def LSRS_func():\n                # Set the C flag, or the last shifted out bit\n                if self.register[Rb] & (1 << (shift_amount - 1)):\n                    self.set_APSR_flag_to_value('C', 1)\n                else:\n                    self.set_APSR_flag_to_value('C', 0)\n\n                self.register[Ra] = self.register[Rb] >> shift_amount\n                self.set_NZ_flags(self.register[Ra])\n\n        return LSRS_func", "response": "Function LSRS Ra Rb Rc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a function that rotates right Ra by Rc or imm5 and store the result in Ra", "response": "def RORS(self, params):\n        \"\"\"\n        RORS [Ra,] Ra, Rc\n\n        Rotate shift right Rb by Rc or imm5 and store the result in Ra\n        The first two operands must be the same register\n        Ra and Rc must be low registers\n        The first register is optional\n        \"\"\"\n        # This instruction allows for an optional destination register\n        # If it is omitted, then it is assumed to be Rb\n        # As defined in http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0662b/index.html\n        try:\n            Ra, Rb, Rc = self.get_three_parameters(self.THREE_PARAMETER_COMMA_SEPARATED, params)\n        except iarm.exceptions.ParsingError:\n            Rb, Rc = self.get_two_parameters(self.TWO_PARAMETER_COMMA_SEPARATED, params)\n            Ra = Rb\n\n        # TODO implement this function\n        # TODO figure out the last shifted bit\n        # TODO figure out how to wrap bits around\n        raise iarm.exceptions.NotImplementedError\n\n        # RORS Ra, Ra, Rb\n        self.check_arguments(low_registers=(Ra, Rc))\n        self.match_first_two_parameters(Ra, Rb)\n\n        def RORS_func():\n            raise NotImplementedError\n\n        return RORS_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the topic table.", "response": "def _parse_topic_table(self, xml, tds='title,created,comment,group', selector='//table[@class=\"olt\"]//tr'):\n        \"\"\"\n        \u89e3\u6790\u8bdd\u9898\u5217\u8868\n        \n        :internal\n        :param xml: \u9875\u9762XML \n        :param tds: \u6bcf\u5217\u7684\u542b\u4e49\uff0c\u53ef\u4ee5\u662ftitle, created, comment, group, updated, author, time, rec\n        :param selector: \u8868\u5728\u9875\u9762\u4e2d\u7684\u4f4d\u7f6e\n        :return: \n        \"\"\"\n        xml_results = xml.xpath(selector)\n        results = []\n        tds = tds.split(',')\n        for item in xml_results:\n            try:\n                result = {}\n                index = 0\n                for td in tds:\n                    index += 1\n                    if td == 'title':\n                        xml_title = item.xpath('.//td[position()=%s]/a' % index)[0]\n                        url = xml_title.get('href')\n                        tid = int(slash_right(url))\n                        title = xml_title.text\n                        result.update({'id': tid, 'url': url, 'title': title})\n                    elif td == 'created':\n                        xml_created = item.xpath('.//td[position()=%s]/a' % index) \\\n                                      or item.xpath('.//td[position()=%s]' % index)\n                        created_at = xml_created[0].get('title')\n                        result['created_at'] = created_at\n                    elif td == 'comment':\n                        xml_comment = item.xpath('.//td[position()=%s]/span' % index) \\\n                                      or item.xpath('.//td[position()=%s]' % index)\n                        comment_count = int(re.match(r'\\d+', xml_comment[0].text).group())\n                        result['comment_count'] = comment_count\n                    elif td == 'group':\n                        xml_group = item.xpath('.//td[position()=%s]/a' % index)[0]\n                        group_url = xml_group.get('href')\n                        group_alias = slash_right(group_url)\n                        group_name = xml_group.text\n                        result.update({'group_alias': group_alias, 'group_url': group_url, 'group_name': group_name})\n                    elif td == 'author':\n                        xml_author = item.xpath('.//td[position()=%s]/a' % index)[0]\n                        author_url = xml_author.get('href')\n                        author_alias = slash_right(author_url)\n                        author_nickname = xml_author.text\n                        result.update({\n                            'author_url': author_url,\n                            'author_alias': author_alias,\n                            'author_nickname': author_nickname,\n                        })\n                    elif td == 'updated':\n                        result['updated_at'] = item.xpath('.//td[position()=%s]/text()' % index)[0]\n                    elif td == 'time':\n                        result['time'] = item.xpath('.//td[position()=%s]/text()' % index)[0]\n                    elif td == 'rec':\n                        xml_rec = item.xpath('.//td[position()=%s]//a[@class=\"lnk-remove\"]/@href' % (index - 1))[0]\n                        result['rec_id'] = re.search(r'rec_id=(\\d+)', xml_rec).groups()[0]\n                results.append(result)\n            except Exception as e:\n                self.api.api.logger.exception('parse topic table exception: %s' % e)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for group by keyword", "response": "def search_groups(self, keyword, start=0):\n        \"\"\"\n        \u641c\u7d22\u5c0f\u7ec4\n        \n        :param keyword: \u641c\u7d22\u7684\u5173\u952e\u5b57\n        :param start: \u7ffb\u9875\n        :return: \u542b\u603b\u6570\u7684\u5217\u8868\n        \"\"\"\n        xml = self.api.xml(API_GROUP_SEARCH_GROUPS % (start, keyword))\n        xml_results = xml.xpath('//div[@class=\"groups\"]/div[@class=\"result\"]')\n        results = []\n        for item in xml_results:\n            try:\n                url = item.xpath('.//h3/a/@href')[0]\n                info = item.xpath('.//div[@class=\"content\"]/div[@class=\"info\"]/text()')[0].strip(' ')\n                onclick = item.xpath('.//h3/a/@onclick')[0]\n                meta = {\n                    'icon': item.xpath('.//img/@src')[0],\n                    'id': re.search(r'sid[^\\d]+(\\d+)', onclick).groups()[0],\n                    'url': url,\n                    'alias': url.rstrip('/').rsplit('/', 1)[1],\n                    'name': item.xpath('.//h3/a/text()')[0],\n                    'user_count': int(re.match(r'\\d+', info).group()),\n                    'user_alias': re.search(r'\u4e2a(.+)\\s*\u5728\u6b64', info).groups()[0],\n                }\n                results.append(meta)\n            except Exception as e:\n                self.api.logger.exception('parse search groups result error: %s' % e)\n        return build_list_result(results, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\njoining group return status", "response": "def join_group(self, group_alias, message=None):\n        \"\"\"\n        \u52a0\u5165\u5c0f\u7ec4\n        \n        :param group_alias: \u5c0f\u7ec4ID\n        :param message: \u5982\u679c\u8981\u9a8c\u8bc1\uff0c\u7559\u8a00\u4fe1\u606f\n        :return: \u679a\u4e3e\n                - joined: \u52a0\u5165\u6210\u529f\n                - waiting: \u7b49\u5f85\u5ba1\u6838\n                - initial: \u52a0\u5165\u5931\u8d25\n        \"\"\"\n        xml = self.api.xml(API_GROUP_GROUP_HOME % group_alias, params={\n            'action': 'join',\n            'ck': self.api.ck(),\n        })\n        misc = xml.xpath('//div[@class=\"group-misc\"]')[0]\n        intro = misc.xpath('string(.)') or ''\n        if intro.find('\u9000\u51fa\u5c0f\u7ec4') > -1:\n            return 'joined'\n        elif intro.find('\u4f60\u5df2\u7ecf\u7533\u8bf7\u52a0\u5165\u5c0f\u7ec4') > -1:\n            return 'waiting'\n        elif intro.find('\u7533\u8bf7\u52a0\u5165\u5c0f\u7ec4') > -1:\n            res = self.api.xml(API_GROUP_GROUP_HOME % group_alias, 'post', data={\n                'ck': self.api.ck(),\n                'action': 'request_join',\n                'message': message,\n                'send': '\u53d1\u9001',\n            })\n            misc = res.xpath('//div[@class=\"group-misc\"]')[0]\n            intro = misc.xpath('string(.)') or ''\n            if intro.find('\u4f60\u5df2\u7ecf\u7533\u8bf7\u52a0\u5165\u5c0f\u7ec4') > -1:\n                return 'waiting'\n            else:\n                return 'initial'\n        else:\n            return 'initial'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for topics by keyword.", "response": "def search_topics(self, keyword, sort='relevance', start=0):\n        \"\"\"\n        \u641c\u7d22\u8bdd\u9898\n        \n        :param keyword: \u5173\u952e\u5b57\n        :param sort: \u6392\u5e8f\u65b9\u5f0f relevance/newest\n        :param start: \u7ffb\u9875\n        :return: \u5e26\u603b\u6570\u7684\u5217\u8868\n        \"\"\"\n        xml = self.api.xml(API_GROUP_SEARCH_TOPICS % (start, sort, keyword))\n        return build_list_result(self._parse_topic_table(xml), xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all topics in a group.", "response": "def list_topics(self, group_alias, _type='', start=0):\n        \"\"\"\n        \u5c0f\u7ec4\u5185\u8bdd\u9898\u5217\u8868\n        \n        :param group_alias: \u5c0f\u7ec4ID\n        :param _type: \u7c7b\u578b \u9ed8\u8ba4\u6700\u65b0\uff0chot:\u6700\u70ed\n        :param start: \u7ffb\u9875\n        :return: \u5e26\u4e0b\u4e00\u9875\u7684\u5217\u8868\n        \"\"\"\n        xml = self.api.xml(API_GROUP_LIST_GROUP_TOPICS % group_alias, params={\n            'start': start,\n            'type': _type,\n        })\n        return build_list_result(self._parse_topic_table(xml, 'title,author,comment,updated'), xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_user_topics(self, start=0):\n        xml = self.api.xml(API_GROUP_LIST_USER_PUBLISHED_TOPICS % self.api.user_alias, params={'start': start})\n        return build_list_result(self._parse_topic_table(xml, 'title,comment,created,group'), xml)", "response": "List all user topics."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_commented_topics(self, start=0):\n        xml = self.api.xml(API_GROUP_LIST_USER_COMMENTED_TOPICS % self.api.user_alias, params={'start': start})\n        return build_list_result(self._parse_topic_table(xml, 'title,comment,time,group'), xml)", "response": "List all the comments for a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all liked topics for a user.", "response": "def list_liked_topics(self, user_alias=None, start=0):\n        \"\"\"\n        \u559c\u6b22\u8fc7\u7684\u8bdd\u9898\n        \n        :param user_alias: \u6307\u5b9a\u7528\u6237\uff0c\u9ed8\u8ba4\u5f53\u524d\n        :param start: \u7ffb\u9875\n        :return: \u5e26\u4e0b\u4e00\u9875\u7684\u5217\u8868\n        \"\"\"\n        user_alias = user_alias or self.api.user_alias\n        xml = self.api.xml(API_GROUP_LIST_USER_LIKED_TOPICS % user_alias, params={'start': start})\n        return build_list_result(self._parse_topic_table(xml, 'title,comment,time,group'), xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_reced_topics(self, user_alias=None, start=0):\n        user_alias = user_alias or self.api.user_alias\n        xml = self.api.xml(API_GROUP_LIST_USER_RECED_TOPICS % user_alias, params={'start': start})\n        return build_list_result(self._parse_topic_table(xml, 'title,comment,time,group,rec'), xml)", "response": "List all topics that have been marked as being recovered."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_topic(self, group_alias, title, content):\n        xml = self.api.req(API_GROUP_ADD_TOPIC % group_alias, 'post', data={\n            'ck': self.api.ck(),\n            'rev_title': title,\n            'rev_text': content,\n            'rev_submit': '\u597d\u4e86\uff0c\u53d1\u8a00',\n        })\n        return not xml.url.startswith(API_GROUP_ADD_TOPIC % group_alias)", "response": "add topic to group"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a topic from the group.", "response": "def remove_topic(self, topic_id):\n        \"\"\"\n        \u5220\u9664\u8bdd\u9898\uff08\u9700\u8981\u5148\u5220\u9664\u6240\u6709\u8bc4\u8bba\uff0c\u4f7f\u7528\u9ed8\u8ba4\u53c2\u6570\uff09\n        \n        :param topic_id: \u8bdd\u9898ID\n        :return: None\n        \"\"\"\n        comment_start = 0\n        while comment_start is not None:\n            comments = self.list_comments(topic_id, comment_start)\n            for comment in comments['results']:\n                self.remove_comment(topic_id, comment['id'])\n            comment_start = comments['next_start']\n        return self.api.req(API_GROUP_REMOVE_TOPIC % topic_id, params={'ck': self.api.ck()})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_topic(self, topic_id, title, content):\n        xml = self.api.req(API_GROUP_UPDATE_TOPIC % topic_id, 'post', data={\n            'ck': self.api.ck(),\n            'rev_title': title,\n            'rev_text': content,\n            'rev_submit': '\u597d\u4e86\uff0c\u6539\u5427',\n        })\n        return not xml.url.startswith(API_GROUP_UPDATE_TOPIC % topic_id)", "response": "Update the topic with the given title and content."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all comments for a topic.", "response": "def list_comments(self, topic_id, start=0):\n        \"\"\"\n        \u56de\u590d\u5217\u8868\n        \n        :param topic_id: \u8bdd\u9898ID\n        :param start: \u7ffb\u9875\n        :return: \u5e26\u4e0b\u4e00\u9875\u7684\u5217\u8868\n        \"\"\"\n        xml = self.api.xml(API_GROUP_GET_TOPIC % topic_id, params={'start': start})\n        xml_results = xml.xpath('//ul[@id=\"comments\"]/li')\n        results = []\n        for item in xml_results:\n            try:\n                author_avatar = item.xpath('.//img/@src')[0]\n                author_url = item.xpath('.//div[@class=\"user-face\"]/a/@href')[0]\n                author_alias = slash_right(author_url)\n                author_signature = item.xpath('.//h4/text()')[1].strip()\n                author_nickname = item.xpath('.//h4/a/text()')[0].strip()\n                created_at = item.xpath('.//h4/span/text()')[0].strip()\n                content = etree.tostring(item.xpath('.//div[@class=\"reply-doc content\"]/p')[0]).decode('utf8').strip()\n                cid = item.get('id')\n                results.append({\n                    'id': cid,\n                    'author_avatar': author_avatar,\n                    'author_url': author_url,\n                    'author_alias': author_alias,\n                    'author_signature': author_signature,\n                    'author_nickname': author_nickname,\n                    'created_at': created_at,\n                    'content': unescape(content),\n                })\n            except Exception as e:\n                self.api.logger.exception('parse comment exception: %s' % e)\n        return build_list_result(results, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd comment to a topic", "response": "def add_comment(self, topic_id, content, reply_id=None):\n        \"\"\"\n        \u6dfb\u52a0\u8bc4\u8bba\n        \n        :param topic_id: \u8bdd\u9898ID\n        :param content: \u5185\u5bb9\n        :param reply_id: \u56de\u590dID\n        :return: None\n        \"\"\"\n        return self.api.req(API_GROUP_ADD_COMMENT % topic_id, 'post', data={\n            'ck': self.api.ck(),\n            'ref_cid': reply_id,\n            'rv_comment': content,\n            'start': 0,\n            'submit_btn': '\u52a0\u4e0a\u53bb',\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_comment(self, topic_id, comment_id, reason='0', other=None):\n        params = {'cid': comment_id}\n        data = {'cid': comment_id, 'ck': self.api.ck(), 'reason': reason, 'other': other, 'submit': '\u786e\u5b9a'}\n        r = self.api.req(API_GROUP_REMOVE_COMMENT % topic_id, 'post', params, data)\n        if r.text.find('douban_admin') > -1:\n            r = self.api.req(API_GROUP_ADMIN_REMOVE_COMMENT % topic_id, 'post', params, data)\n        self.api.logger.debug('remove comment final url is <%s>' % r.url)\n        return r", "response": "remove a comment from a topic"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_user_comments(self, topic_id, user_alias=None):\n        user_alias = user_alias or self.api.user_alias\n        comment_start = 0\n        results = []\n        while comment_start is not None:\n            comments = self.list_comments(topic_id, comment_start)\n            results += [item for item in comments['results'] if item['author_alias'] == user_alias]\n            comment_start = comments['next_start']\n        return results", "response": "List all user comments for a topic."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_commented_topic(self, topic_id):\n        return [self.remove_comment(topic_id, item['id']) for item in self.list_user_comments(topic_id)]", "response": "Remove all comments for a topic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new click. Command that will be run as callback.", "response": "def shell(name=None, **attrs):\n    \"\"\"Creates a new :class:`Shell` with a function as callback.  This\n    works otherwise the same as :func:`command` just that the `cls`\n    parameter is set to :class:`Shell`.\n    \"\"\"\n    attrs.setdefault('cls', Shell)\n    return click.command(name, **attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getLogger(name):\n    logger = logging.getLogger(name)\n    # note: the level might be adjusted via '-v' option\n    logger.setLevel(logging_config['loggers']['gcdt']['level'])\n    return logger", "response": "This is used by gcdt plugins to get a logger with the right level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndiscovering methods in the XML - RPC API and creates attributes for them on this object.", "response": "def _discover(self):\n        \"\"\"Discovers methods in the XML-RPC API and creates attributes for them\n        on this object. Enables stuff like \"magento.cart.create(...)\" to work\n        without having to define Python methods for each XML-RPC equivalent.\n        \"\"\"\n\n        self._resources = {}\n        resources = self._client.resources(self._session_id)\n        for resource in resources:\n            self._resources[resource['name']] = MagentoResource(\n                self._client, self._session_id, resource['name'],\n                resource['title'], resource['methods'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints discovered resources and their associated methods.", "response": "def help(self):\n        \"\"\"Prints discovered resources and their associated methods. Nice when\n        noodling in the terminal to wrap your head around Magento's insanity.\n        \"\"\"\n\n        print('Resources:')\n        print('')\n        for name in sorted(self._resources.keys()):\n            methods = sorted(self._resources[name]._methods.keys())\n            print('{}: {}'.format(bold(name), ', '.join(methods)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting the controller and run it.", "response": "def run(self):\n        \"\"\"Import the controller and run it.\n\n        This mimics the processing done by :func:`helper.start`\n        when a controller is run in the foreground.  A new instance\n        of ``self.controller`` is created and run until a keyboard\n        interrupt occurs or the controller stops on its own accord.\n\n        \"\"\"\n        segments = self.controller.split('.')\n        controller_class = reduce(getattr, segments[1:],\n                                  __import__('.'.join(segments[:-1])))\n        cmd_line = ['-f']\n        if self.configuration is not None:\n            cmd_line.extend(['-c', self.configuration])\n        args = parser.get().parse_args(cmd_line)\n        controller_instance = controller_class(args, platform)\n        try:\n            controller_instance.start()\n        except KeyboardInterrupt:\n            controller_instance.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the basic info of the current entry in the file system.", "response": "def get_info(self):\n        \"\"\"\n        Scans the input path and automatically determines the optimal\n        piece size based on ~1500 pieces (up to MAX_PIECE_SIZE) along\n        with other basic info, including total size (in bytes), the\n        total number of files, piece size (in bytes), and resulting\n        number of pieces. If ``piece_size`` has already been set, the\n        custom value will be used instead.\n\n        :return: ``(total_size, total_files, piece_size, num_pieces)``\n        \"\"\"\n        if os.path.isfile(self.path):\n            total_size = os.path.getsize(self.path)\n            total_files = 1\n        elif os.path.exists(self.path):\n            total_size = 0\n            total_files = 0\n            for x in os.walk(self.path):\n                for fn in x[2]:\n                    if any(fnmatch.fnmatch(fn, ext) for ext in self.exclude):\n                        continue\n                    fpath = os.path.normpath(os.path.join(x[0], fn))\n                    fsize = os.path.getsize(fpath)\n                    if fsize and not is_hidden_file(fpath):\n                        total_size += fsize\n                        total_files += 1\n        else:\n            raise exceptions.InvalidInputException\n        if not (total_files and total_size):\n            raise exceptions.EmptyInputException\n        if self.piece_size:\n            ps = self.piece_size\n        else:\n            ps = 1 << max(0, math.ceil(math.log(total_size / 1500, 2)))\n            if ps < MIN_PIECE_SIZE:\n                ps = MIN_PIECE_SIZE\n            if ps > MAX_PIECE_SIZE:\n                ps = MAX_PIECE_SIZE\n        return (total_size, total_files, ps, math.ceil(total_size / ps))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self, callback=None):\n        files = []\n        single_file = os.path.isfile(self.path)\n        if single_file:\n            files.append((self.path, os.path.getsize(self.path), {}))\n        elif os.path.exists(self.path):\n            for x in os.walk(self.path):\n                for fn in x[2]:\n                    if any(fnmatch.fnmatch(fn, ext) for ext in self.exclude):\n                        continue\n                    fpath = os.path.normpath(os.path.join(x[0], fn))\n                    fsize = os.path.getsize(fpath)\n                    if fsize and not is_hidden_file(fpath):\n                        files.append((fpath, fsize, {}))\n        else:\n            raise exceptions.InvalidInputException\n        total_size = sum([x[1] for x in files])\n        if not (len(files) and total_size):\n            raise exceptions.EmptyInputException\n        # set piece size if not already set\n        if self.piece_size is None:\n            self.piece_size = self.get_info()[2]\n        if files:\n            self._pieces = bytearray()\n            i = 0\n            num_pieces = math.ceil(total_size / self.piece_size)\n            pc = 0\n            buf = bytearray()\n            while i < len(files):\n                fe = files[i]\n                f = open(fe[0], 'rb')\n                if self.include_md5:\n                    md5_hasher = md5()\n                else:\n                    md5_hasher = None\n                for chunk in iter(lambda: f.read(self.piece_size), b''):\n                    buf += chunk\n                    if len(buf) >= self.piece_size \\\n                            or i == len(files)-1:\n                        piece = buf[:self.piece_size]\n                        self._pieces += sha1(piece).digest()\n                        del buf[:self.piece_size]\n                        pc += 1\n                        if callback:\n                            cancel = callback(fe[0], pc, num_pieces)\n                            if cancel:\n                                f.close()\n                                return False\n                    if self.include_md5:\n                        md5_hasher.update(chunk)\n                if self.include_md5:\n                    fe[2]['md5sum'] = md5_hasher.hexdigest()\n                f.close()\n                i += 1\n            # Add pieces from any remaining data\n            while len(buf):\n                piece = buf[:self.piece_size]\n                self._pieces += sha1(piece).digest()\n                del buf[:self.piece_size]\n                pc += 1\n                if callback:\n                    cancel = callback(fe[0], pc, num_pieces)\n                    if cancel:\n                        return False\n\n        # Create the torrent data structure\n        data = OrderedDict()\n        if len(self.trackers) > 0:\n            data['announce'] = self.trackers[0].encode()\n            if len(self.trackers) > 1:\n                data['announce-list'] = [[x.encode()] for x in self.trackers]\n        if self.comment:\n            data['comment'] = self.comment.encode()\n        if self.created_by:\n            data['created by'] = self.created_by.encode()\n        else:\n            data['created by'] = DEFAULT_CREATOR.encode()\n        if self.creation_date:\n            data['creation date'] = int(self.creation_date.timestamp())\n        if self.web_seeds:\n            data['url-list'] = [x.encode() for x in self.web_seeds]\n        data['info'] = OrderedDict()\n        if single_file:\n            data['info']['length'] = files[0][1]\n            if self.include_md5:\n                data['info']['md5sum'] = files[0][2]['md5sum']\n            data['info']['name'] = files[0][0].split(os.sep)[-1].encode()\n        else:\n            data['info']['files'] = []\n            path_sp = self.path.split(os.sep)\n            for x in files:\n                fx = OrderedDict()\n                fx['length'] = x[1]\n                if self.include_md5:\n                    fx['md5sum'] = x[2]['md5sum']\n                fx['path'] = [y.encode()\n                              for y in x[0].split(os.sep)[len(path_sp):]]\n                data['info']['files'].append(fx)\n            data['info']['name'] = path_sp[-1].encode()\n        data['info']['pieces'] = bytes(self._pieces)\n        data['info']['piece length'] = self.piece_size\n        data['info']['private'] = int(self.private)\n        if self.source:\n            data['info']['source'] = self.source.encode()\n\n        self._data = data\n        return True", "response": "Computes and stores piece data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef info_hash_base32(self):\n        if getattr(self, '_data', None):\n            return b32encode(sha1(bencode(self._data['info'])).digest())\n        else:\n            raise exceptions.TorrentNotGeneratedException", "response": "Returns the base32 info hash of the torrent. Useful for generating\n        magnet links."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info_hash(self):\n        if getattr(self, '_data', None):\n            return sha1(bencode(self._data['info'])).hexdigest()\n        else:\n            raise exceptions.TorrentNotGeneratedException", "response": "Returns the SHA - 1 info hash of the torrent. Useful for generating\n            magnet links."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xml(self, url, method='get', params=None, data=None):\n        r = self.req(url, method, params, data)\n        # this is required for avoid utf8-mb4 lead to encoding error\n        return self.to_xml(r.content, base_url=r.url)", "response": "\u8bf7\u6c42\u5e76\u8fd4\u56dexml\n        \n        :type url: str\n        :param url: API\n        \n        :type method: str\n        :param method: HTTP METHOD\n        \n        :type params: dict\n        :param params: query\n        \n        :type data: dict\n        :param data: body\n        \n        :rtype: html.HtmlElement\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef persist(self):\n        with open(self.persist_file, 'w+') as f:\n            json.dump({\n                'cookies': self.cookies,\n                'user_alias': self.user_alias,\n            }, f, indent=2)\n            self.logger.debug('persist session to <%s>' % self.persist_file)", "response": "persist session to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self):\n        if not os.path.isfile(self.persist_file):\n            return\n        with open(self.persist_file, 'r') as f:\n            cfg = json.load(f) or {}\n            self.cookies = cfg.get('cookies', {})\n            self.user_alias = cfg.get('user_alias') or None\n            self.logger.debug('load session for <%s> from <%s>' % (self.user_alias, self.persist_file))", "response": "load the cookies and user_alias from the persist_file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login(self, username, password):\n        r0 = self.req(API_HOME)\n        time.sleep(1)\n        cookies = dict(r0.cookies)\n        data = {\n            'source': 'index_nav',\n            'form_email': username,\n            'form_password': password,\n            'remember': 'on',\n        }\n        r1 = self.req(API_ACCOUNT_LOGIN, method='post', data=data)\n        cookies.update(dict(r1.cookies))\n        [cookies.update(dict(r.cookies)) for r in r1.history]\n        if 'dbcl2' not in cookies:\n            raise Exception('Authorization failed for <%s>: %s' % (username, r1.url))\n        cookies.update(dict(r1.cookies))\n        self.logger.info('login with username <%s>' % username)\n        self.use(cookies)\n        return self", "response": "Login to the AMI"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset cookies to self", "response": "def use(self, cookies):\n        \"\"\"\n        \u5982\u679c\u906d\u9047\u9a8c\u8bc1\u7801\uff0c\u7528\u8fd9\u4e2a\u63a5\u53e3\n        \n        :type cookies: str|dict\n        :param cookies: cookie\u5b57\u7b26\u4e32\u6216\u8005\u5b57\u5178\n        :return: self\n        \"\"\"\n        self.cookies = dict([item.split('=', 1) for item in re.split(r'; *', cookies)]) \\\n            if isinstance(cookies, str) else cookies\n        self.flush()\n        self.persist()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logout(self):\n        self.req(API_ACCOUNT_LOGOUT % self.ck())\n        self.cookies = {}\n        self.user_alias = None\n        self.persist()", "response": "Logout from the API"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading bundle and deploy to deployment group.", "response": "def deploy(awsclient, applicationName, deploymentGroupName,\n           deploymentConfigName, bucket, bundlefile):\n    \"\"\"Upload bundle and deploy to deployment group.\n    This includes the bundle-action.\n\n    :param applicationName:\n    :param deploymentGroupName:\n    :param deploymentConfigName:\n    :param bucket:\n    :param bundlefile:\n    :return: deploymentId from create_deployment\n    \"\"\"\n    etag, version = upload_file_to_s3(awsclient, bucket,\n                                      _build_bundle_key(applicationName),\n                                      bundlefile)\n\n    client_codedeploy = awsclient.get_client('codedeploy')\n    response = client_codedeploy.create_deployment(\n        applicationName=applicationName,\n        deploymentGroupName=deploymentGroupName,\n        revision={\n            'revisionType': 'S3',\n            's3Location': {\n                'bucket': bucket,\n                'key': _build_bundle_key(applicationName),\n                'bundleType': 'tgz',\n                'eTag': etag,\n                'version': version,\n            },\n        },\n        deploymentConfigName=deploymentConfigName,\n        description='deploy with tenkai',\n        ignoreApplicationStopFailures=True\n    )\n\n    log.info(\n        \"Deployment: {} -> URL: https://{}.console.aws.amazon.com/codedeploy/home?region={}#/deployments/{}\".format(\n            Fore.MAGENTA + response['deploymentId'] + Fore.RESET,\n            client_codedeploy.meta.region_name,\n            client_codedeploy.meta.region_name,\n            response['deploymentId'],\n        ))\n\n    return response['deploymentId']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output_deployment_status(awsclient, deployment_id, iterations=100):\n    counter = 0\n    steady_states = ['Succeeded', 'Failed', 'Stopped']\n    client_codedeploy = awsclient.get_client('codedeploy')\n\n    while counter <= iterations:\n        response = client_codedeploy.get_deployment(deploymentId=deployment_id)\n        status = response['deploymentInfo']['status']\n\n        if status not in steady_states:\n            log.info('Deployment: %s - State: %s' % (deployment_id, status))\n            time.sleep(10)\n        elif status == 'Failed':\n            log.info(\n                colored.red('Deployment: {} failed: {}'.format(\n                    deployment_id,\n                    json.dumps(response['deploymentInfo']['errorInformation'],\n                               indent=2)\n                ))\n            )\n            return 1\n        else:\n            log.info('Deployment: %s - State: %s' % (deployment_id, status))\n            break\n\n    return 0", "response": "Wait until an deployment is in a steady state and output information."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops tenkai deployment. :param awsclient: :param deployment_id:", "response": "def stop_deployment(awsclient, deployment_id):\n    \"\"\"stop tenkai deployment.\n\n    :param awsclient:\n    :param deployment_id:\n    \"\"\"\n    log.info('Deployment: %s - stopping active deployment.', deployment_id)\n    client_codedeploy = awsclient.get_client('codedeploy')\n\n    response = client_codedeploy.stop_deployment(\n        deploymentId=deployment_id,\n        autoRollbackEnabled=True\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _list_deployment_instances(awsclient, deployment_id):\n    client_codedeploy = awsclient.get_client('codedeploy')\n\n    instances = []\n    next_token = None\n\n    # TODO refactor generic exhaust_function from this\n    while True:\n        request = {\n            'deploymentId': deployment_id\n        }\n        if next_token:\n            request['nextToken'] = next_token\n        response = client_codedeploy.list_deployment_instances(**request)\n        instances.extend(response['instancesList'])\n        if 'nextToken' not in response:\n            break\n        next_token = response['nextToken']\n    return instances", "response": "list deployment instances.\n\n    :param awsclient:\n    :param deployment_id:"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the status of the deployment instance", "response": "def _get_deployment_instance_summary(awsclient, deployment_id, instance_id):\n    \"\"\"instance summary.\n\n    :param awsclient:\n    :param deployment_id:\n    :param instance_id:\n    return: status, last_event\n    \"\"\"\n    client_codedeploy = awsclient.get_client('codedeploy')\n    request = {\n        'deploymentId': deployment_id,\n        'instanceId': instance_id\n    }\n    response = client_codedeploy.get_deployment_instance(**request)\n    return response['instanceSummary']['status'], \\\n           response['instanceSummary']['lifecycleEvents'][-1]['lifecycleEventName']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting you the diagnostics details for the first Failed event.", "response": "def _get_deployment_instance_diagnostics(awsclient, deployment_id, instance_id):\n    \"\"\"Gets you the diagnostics details for the first 'Failed' event.\n\n    :param awsclient:\n    :param deployment_id:\n    :param instance_id:\n    return: None or (error_code, script_name, message, log_tail)\n    \"\"\"\n    client_codedeploy = awsclient.get_client('codedeploy')\n    request = {\n        'deploymentId': deployment_id,\n        'instanceId': instance_id\n    }\n    response = client_codedeploy.get_deployment_instance(**request)\n    # find first 'Failed' event\n    for i, event in enumerate(response['instanceSummary']['lifecycleEvents']):\n        if event['status'] == 'Failed':\n            return event['diagnostics']['errorCode'], \\\n                   event['diagnostics']['scriptName'], \\\n                   event['diagnostics']['message'], \\\n                   event['diagnostics']['logTail']\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the deployment summary.", "response": "def output_deployment_summary(awsclient, deployment_id):\n    \"\"\"summary\n\n    :param awsclient:\n    :param deployment_id:\n    \"\"\"\n    log.info('\\ndeployment summary:')\n    log.info('%-22s %-12s %s', 'Instance ID', 'Status', 'Most recent event')\n    for instance_id in _list_deployment_instances(awsclient, deployment_id):\n        status, last_event = \\\n            _get_deployment_instance_summary(awsclient, deployment_id, instance_id)\n        log.info(Fore.MAGENTA + '%-22s' + Fore.RESET + ' %-12s %s',\n                 instance_id, status, last_event)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the diagnostics of the specified deployment.", "response": "def output_deployment_diagnostics(awsclient, deployment_id, log_group, start_time=None):\n    \"\"\"diagnostics\n\n    :param awsclient:\n    :param deployment_id:\n    \"\"\"\n    headline = False\n    for instance_id in _list_deployment_instances(awsclient, deployment_id):\n        diagnostics = _get_deployment_instance_diagnostics(\n            awsclient, deployment_id, instance_id)\n        #if error_code != 'Success':\n        if diagnostics is not None:\n            error_code, script_name, message, log_tail = diagnostics\n            # header\n            if not headline:\n                headline = True\n                log.info('\\ndeployment diagnostics:')\n            # event logs\n            log.info('Instance ID: %s', Fore.MAGENTA + instance_id + Fore.RESET)\n            log.info('Error Code:  %s', error_code)\n            log.info('Script Name: %s', script_name)\n            log.info('Message:     %s', message)\n            log.info('Log Tail:    %s', log_tail)\n            # cloudwatch logs\n            if check_log_stream_exists(awsclient, log_group, instance_id):\n                logentries = get_log_events(\n                    awsclient, log_group, instance_id,\n                    datetime_to_timestamp(start_time))\n                if logentries:\n                    log.info('instance %s logentries', instance_id)\n                    for e in logentries:\n                        log.info(e['message'].strip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_type(self):\n\n        if self.__is_type_result is not None:\n            return self.__is_type_result\n\n        self.__is_type_result = self.__is_type()\n\n        return self.__is_type_result", "response": "Returns True if the object is of type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, error_message=None):\n\n        if self.is_type():\n            return\n\n        if not error_message:\n            error_message = \"invalid value type\"\n\n        raise TypeError(\n            \"{}: expected={}, actual={}\".format(error_message, self.typename, type(self._data))\n        )", "response": "Raises TypeError if the value is not a valid type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert(self):\n\n        if self.is_type():\n            return self.force_convert()\n\n        raise TypeConversionError(\n            \"failed to convert from {} to {}\".format(type(self._data).__name__, self.typename)\n        )", "response": "Converts the value from one of the types to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef always_fails(\n        self,\n        work_dict):\n    \"\"\"always_fails\n\n    :param work_dict: dictionary for key/values\n    \"\"\"\n\n    label = \"always_fails\"\n\n    log.info((\"task - {} - start \"\n              \"work_dict={}\")\n             .format(label,\n                     work_dict))\n\n    raise Exception(\n            work_dict.get(\n                \"test_failure\",\n                \"simulating a failure\"))\n\n    log.info((\"task - {} - done\")\n             .format(label))\n\n    return True", "response": "This function checks if the user has not done any work."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds name from prefix and name + type", "response": "def name_build(self, name, is_policy=False, prefix=True):\n        \"\"\"\n        Build name from prefix and name + type\n        :param name: Name of the role/policy\n        :param is_policy: True if policy should be added as suffix\n        :param prefix: True if prefix should be added\n        :return: Joined name\n        \"\"\"\n        str = name\n\n        # Add prefix\n        if prefix:\n            str = self.__role_name_prefix + str\n\n        # Add policy suffix\n        if is_policy:\n            str = str + \"-policy\"\n\n        return str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform a name to AWS valid characters and adds prefix and type", "response": "def name_strip(self, name, is_policy=False, prefix=True):\n        \"\"\"\n        Transforms name to AWS valid characters and adds prefix and type\n        :param name: Name of the role/policy\n        :param is_policy: True if policy should be added as suffix\n        :param prefix: True if prefix should be added\n        :return: Transformed and joined name\n        \"\"\"\n        str = self.name_build(name, is_policy, prefix)\n        str = str.title()\n        str = str.replace('-', '')\n        return str"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_policy(self, name, statements, roles, is_managed_policy=False):\n        if is_managed_policy:\n            policy = ManagedPolicy(\n                self.name_strip(name, True),\n                PolicyDocument={\n                    \"Version\": self.VERSION_IAM,\n                    \"Statement\": statements,\n                },\n                Roles=roles,\n                Path=self.__role_path,\n            )\n        else:\n            policy = PolicyType(\n                self.name_strip(name, True),\n                PolicyName=self.name_strip(name, True),\n                PolicyDocument={\n                    \"Version\": self.VERSION_IAM,\n                    \"Statement\": statements,\n                },\n                Roles=roles,\n            )\n\n        self.__template.add_resource(policy)\n        return policy", "response": "Generate a new policy for IAM cloudformation template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating bucket policy for S3 bucket", "response": "def build_policy_bucket(self, bucket, name, statements):\n        \"\"\"\n        Generate bucket policy for S3 bucket\n        :param bucket: The bucket to attach policy to\n        :param name: The name of the bucket (to generate policy name from it)\n        :param statements: The \"rules\" the policy should have\n        :return: Ref to new policy\n        \"\"\"\n\n        policy = self.__template.add_resource(\n            BucketPolicy(\n                self.name_strip(name, True, False),\n                Bucket=troposphere.Ref(bucket),\n                DependsOn=[\n                    troposphere.Name(bucket)\n                ],\n                PolicyDocument=Policy(\n                    Version=self.VERSION_IAM,\n                    Statement=statements\n                )\n            )\n        )\n\n        return policy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a role for IAM cloudformation template.", "response": "def build_role(self, name, policies=False):\n        \"\"\"\n        Generate role for IAM cloudformation template\n        :param name: Name of role\n        :param policies: List of policies to attach to this role (False = none)\n        :return: Ref to new role\n        \"\"\"\n        # Build role template\n        if policies:\n            role = self.__template.add_resource(\n                Role(\n                    self.name_strip(name),\n                    AssumeRolePolicyDocument=Policy(\n                        Version=self.VERSION_IAM,\n                        Statement=[\n                            Statement(\n                                Effect=Allow,\n                                Principal=Principal(\n                                    \"Service\", self.__role_principals\n                                ),\n                                Action=[AssumeRole],\n                            )\n                        ]\n                    ),\n                    Path=self.__role_path,\n                    ManagedPolicyArns=policies,\n                ))\n            # Add role to list for default policy\n            self.__roles_list.append(troposphere.Ref(role))\n        else:\n            role = self.__template.add_resource(\n                Role(\n                    self.name_strip(name),\n                    AssumeRolePolicyDocument=Policy(\n                        Version=self.VERSION_IAM,\n                        Statement=[\n                            Statement(\n                                Effect=Allow,\n                                Principal=Principal(\n                                    \"Service\", self.__role_principals\n                                ),\n                                Action=[AssumeRole],\n                            )\n                        ]\n                    ),\n                    Path=self.__role_path,\n                ))\n            # Add role to list for default policy\n            self.__roles_list.append(troposphere.Ref(role))\n\n        return role"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate S3 bucket statement", "response": "def build_bucket(self, name, lifecycle_configuration=False,\n                     use_plain_name=False):\n        \"\"\"\n        Generate S3 bucket statement\n        :param name: Name of the bucket\n        :param lifecycle_configuration: Additional lifecycle configuration (default=False)\n        :param use_plain_name: Just use the given name and do not add prefix\n        :return: Ref to new bucket\n        \"\"\"\n        if use_plain_name:\n            name_aws = name_bucket = name\n            name_aws = name_aws.title()\n            name_aws = name_aws.replace('-', '')\n        else:\n            name_aws = self.name_strip(name, False, False)\n            name_bucket = self.name_build(name)\n\n        if lifecycle_configuration:\n            return self.__template.add_resource(\n                Bucket(\n                    name_aws,\n                    BucketName=name_bucket,\n                    LifecycleConfiguration=lifecycle_configuration\n                )\n            )\n        else:\n            return self.__template.add_resource(\n                Bucket(\n                    name_aws,\n                    BucketName=name_bucket,\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlabel SPACE num Allocate space on the stack. `num` is the number of bytes to allocate", "response": "def directive_SPACE(self, label, params):\n        \"\"\"\n        label   SPACE num\n\n        Allocate space on the stack. `num` is the number of bytes to allocate\n        \"\"\"\n        # TODO allow equations\n\n        params = params.strip()\n        try:\n            self.convert_to_integer(params)\n        except ValueError:\n            warnings.warn(\"Unknown parameters; {}\".format(params))\n            return\n\n        self.labels[label] = self.space_pointer\n        if params in self.equates:\n            params = self.equates[params]\n        self.space_pointer += self.convert_to_integer(params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlabel DCD value[, value ...] Allocate a word space in read only memory for the value or list of values", "response": "def directive_DCD(self, label, params):\n        \"\"\"\n        label   DCD value[, value ...]\n\n        Allocate a word space in read only memory for the value or list of values\n        \"\"\"\n        # TODO make this read only\n        # TODO check for param size\n        # TODO can take any length comma separated values (VAL DCD 1, 0x2, 3, 4\n\n        params = params.strip()\n        try:\n            self.convert_to_integer(params)\n        except ValueError:\n            # TODO allow word DCDs (like SP_INIT, Reset_Handler)\n            warnings.warn(\"Cannot reserve constant words; {}\".format(params))\n            return\n\n        # Align address\n        if self.space_pointer % 4 != 0:\n            self.space_pointer += self.space_pointer % 4\n        self.labels[label] = self.space_pointer\n        if params in self.equates:\n            params = self.equates[params]\n        for i in range(4):\n            self.memory[self.space_pointer + i] = (self.convert_to_integer(params) >> (8*i)) & 0xFF\n        self.space_pointer += 4"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlabel DCH value[, value ...] Allocate a half word space in read only memory for the value or list of values", "response": "def directive_DCH(self, label, params):\n        \"\"\"\n        label   DCH value[, value ...]\n\n        Allocate a half word space in read only memory for the value or list of values\n        \"\"\"\n        # TODO make this read only\n        # TODO check for word size\n\n        # Align address\n        if self.space_pointer % 2 != 0:\n            self.space_pointer += self.space_pointer % 2\n        self.labels[label] = self.space_pointer\n        if params in self.equates:\n            params = self.equates[params]\n        for i in range(2):\n            self.memory[self.space_pointer + i] = (self.convert_to_integer(params) >> (8 * i)) & 0xFF\n        self.space_pointer += 2"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef directive_DCB(self, label, params):\n        # TODO make this read only\n        # TODO check for byte size\n        self.labels[label] = self.space_pointer\n        if params in self.equates:\n            params = self.equates[params]\n        self.memory[self.space_pointer] = self.convert_to_integer(params) & 0xFF\n        self.space_pointer += 1", "response": "This is the DCB directive."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the celery application", "response": "def get_celery_app(\n        name=os.getenv(\n            \"CELERY_NAME\",\n            \"worker\"),\n        auth_url=os.getenv(\n            \"BROKER_URL\",\n            \"redis://localhost:6379/9\"),\n        backend_url=os.getenv(\n            \"BACKEND_URL\",\n            \"redis://localhost:6379/10\"),\n        include_tasks=[],\n        ssl_options=None,\n        transport_options=None,\n        path_to_config_module=os.getenv(\n            \"CONFIG_MODULE_PATH\",\n            \"celery_loaders.work_tasks.celery_config\"),\n        worker_log_format=os.getenv(\n            \"WORKER_LOG_FORMAT\",\n            \"%(asctime)s: %(levelname)s %(message)s\"),\n        **kwargs):\n    \"\"\"get_celery_app\n\n    :param name: name for this app\n    :param auth_url: celery broker\n    :param backend_url: celery backend\n    :param include_tasks: list of modules containing tasks to add\n    :param ssl_options: security options dictionary\n    :param trasport_options: transport options dictionary\n    :param path_to_config_module: config module\n    :param worker_log_format: format for logs\n    \"\"\"\n\n    if len(include_tasks) == 0:\n        log.error((\"creating celery app={} MISSING tasks={}\")\n                  .format(\n                    name,\n                    include_tasks))\n    else:\n        log.info((\"creating celery app={} tasks={}\")\n                 .format(\n                    name,\n                    include_tasks))\n\n    # get the Celery application\n    app = celery.Celery(\n        name,\n        broker_url=auth_url,\n        result_backend=backend_url,\n        include=include_tasks)\n\n    app.config_from_object(\n        path_to_config_module,\n        namespace=\"CELERY\")\n\n    app.conf.update(kwargs)\n\n    if transport_options:\n        log.info((\"loading transport_options={}\")\n                 .format(transport_options))\n        app.conf.update(**transport_options)\n    # custom tranport options\n\n    if ssl_options:\n        log.info((\"loading ssl_options={}\")\n                 .format(ssl_options))\n        app.conf.update(**ssl_options)\n    # custom ssl options\n\n    if len(include_tasks) > 0:\n        app.autodiscover_tasks(include_tasks)\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_arguments(self, **kwargs):\n        for key in kwargs:\n            if key in self._rules:\n                for val in kwargs[key]:\n                    self._rules[key](val)\n            else:\n                raise LookupError(\"Rule for {} does not exist. Make sure the rule starts with 'rule_'\".format(key))", "response": "Checks if the arguments meet the specifications\n        kwargs contains lists grouped by their parameter\n        rules are defined by methods starting with rule_."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef link(self, key1, key2):\n        # TODO make this have more than one key linked\n        # TODO Maybe make the value a set?\n        self._linked_keys[key1] = key2\n        self._linked_keys[key2] = key1", "response": "Make these two keys have the same value\n        :param key1:\n        :param key2:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef instance_ik_model_receiver(fn):\n    @wraps(fn)\n    def receiver(self, sender, **kwargs):\n        # print 'inspect.isclass(sender? %s'%(inspect.isclass(sender))\n        if not inspect.isclass(sender):\n            return\n        for src in self._source_groups:\n            if issubclass(sender, src.model_class):\n                fn(self, sender=sender, **kwargs)\n\n                # If we find a match, return. We don't want to handle the signal\n                # more than once.\n                return\n    return receiver", "response": "A decorator that filters out sign_original_specals coming from models that don t have fields that function as ImageFieldSourceGroup sources."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreceives a signal from a source group.", "response": "def source_group_receiver(self, sender, source, signal, **kwargs):\n        \"\"\"\n        Relay source group signals to the appropriate spec strategy.\n\n        \"\"\"\n        from imagekit.cachefiles import ImageCacheFile\n        source_group = sender\n\n        instance = kwargs['instance']\n\n        # Ignore signals from unregistered groups.\n        if source_group not in self._source_groups:\n            return\n\n        #HOOK -- update source to point to image file.\n        for id in self._source_groups[source_group]:\n\n            spec_to_update = generator_registry.get(id, source=source, instance=instance, field=hack_spec_field_hash[id])            \n                        \n        specs = [generator_registry.get(id, source=source, instance=instance, field=hack_spec_field_hash[id]) for id in\n                self._source_groups[source_group]]\n        callback_name = self._signals[signal]\n        # print 'callback_name? %s'%(callback_name)\n\n        for spec in specs:\n            file = ImageCacheFile(spec)\n            # print 'SEPC %s file %s'%(spec, file)\n            call_strategy_method(file, callback_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the source_hashes attribute of the given instance.", "response": "def update_source_hashes(self, instance):\n        \"\"\"\n        Stores hashes of the source image files so that they can be compared\n        later to see whether the source image has changed (and therefore whether\n        the spec file needs to be regenerated).\n\n        \"\"\"\n        self.init_instance(instance)\n        instance._ik['source_hashes'] = dict(\n            (attname, hash(getattr(instance, attname)))\n            for attname in self.get_source_fields(instance))\n        return instance._ik['source_hashes']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_source_fields(self, instance):\n        return set(src.image_field\n                   for src in self._source_groups\n                   if isinstance(instance, src.model_class))", "response": "Returns a list of the source fields for the given instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_success(self, retval, task_id, args, kwargs):\n\n        log.info((\"{} SUCCESS - retval={} task_id={} \"\n                  \"args={} kwargs={}\")\n                 .format(\n                     self.log_label,\n                     retval,\n                     task_id,\n                     args,\n                     kwargs))", "response": "Called when a task is completed and the task is successfully completed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when a task fails.", "response": "def on_failure(self, exc, task_id, args, kwargs, einfo):\n        \"\"\"on_failure\n\n        http://docs.celeryproject.org/en/latest/userguide/tasks.html#task-inheritance\n\n        :param exc: exception\n        :param task_id: task id\n        :param args: arguments passed into task\n        :param kwargs: keyword arguments passed into task\n        :param einfo: exception info\n        \"\"\"\n\n        use_exc = str(exc)\n        log.error((\"{} FAIL - exc={} \"\n                   \"args={} kwargs={}\")\n                  .format(\n                     self.log_label,\n                     use_exc,\n                     args,\n                     kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_hook_mechanism_is_intact(module):\n    result = True\n    if check_register_present(module):\n        result = not result\n    if check_deregister_present(module):\n        result = not result\n    return result", "response": "Check if the hook mechanism is intact."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering dot output for cloudformation. template in json format.", "response": "def cfn_viz(template, parameters={}, outputs={}, out=sys.stdout):\n    \"\"\"Render dot output for cloudformation.template in json format.\n    \"\"\"\n    known_sg, open_sg = _analyze_sg(template['Resources'])\n    (graph, edges) = _extract_graph(template.get('Description', ''),\n                                    template['Resources'], known_sg, open_sg)\n    graph['edges'].extend(edges)\n    _handle_terminals(template, graph, 'Parameters', 'source', parameters)\n    _handle_terminals(template, graph, 'Outputs', 'sink', outputs)\n    graph['subgraphs'].append(_handle_pseudo_params(graph['edges']))\n\n    _render(graph, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining fillcolor for resources in this case", "response": "def _get_fillcolor(resource_type, properties, known_sg=[], open_sg=[]):\n    \"\"\"Determine fillcolor for resources (public ones in this case)\n    \"\"\"\n    fillcolor = None\n    # check security groups\n    if 'SecurityGroups' in properties:\n        # check for external security groups\n        for sg in properties['SecurityGroups']:\n            if 'Ref' in sg and (sg['Ref'] not in known_sg):\n                fillcolor = 'yellow'\n                break\n\n        # check for open security groups\n        for osg in open_sg:\n            if {'Ref': osg} in properties['SecurityGroups']:\n                fillcolor = 'red'\n                break\n\n    # LoadBalancer\n    if resource_type == 'LoadBalancer':\n        if ('Scheme' not in properties) or \\\n                        properties['Scheme'] == 'internet-facing':\n            fillcolor = 'red'\n\n    return fillcolor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef svg_output(dotfile, outfile='cloudformation.svg'):\n    try:\n        cmd = ['dot', '-Tsvg', '-o' + outfile, dotfile]\n        subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n    except subprocess.CalledProcessError as e:\n        sys.stderr.write(\n            '\\033[01;31mError running command: %s resulted in the ' % e.cmd +\n            'following error: \\033[01;32m %s' % e.output)\n        return 1\n\n    return 0", "response": "Render template into svg file using dot command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(controller_class):\n    args = parser.parse()\n    obj = controller_class(args, platform.operating_system())\n    if args.foreground:\n        try:\n            obj.start()\n        except KeyboardInterrupt:\n            obj.stop()\n    else:\n        try:\n            with platform.Daemon(obj) as daemon:\n                daemon.start()\n        except (OSError, ValueError) as error:\n            sys.stderr.write('\\nError starting %s: %s\\n\\n' %\n                             (sys.argv[0], error))\n            sys.exit(1)", "response": "Start the Helper controller either in the foreground or as a daemon process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the sequence of time steps.", "response": "def run(self, steps=float('inf')):\n        \"\"\"\n        Run to the current end of the program or a number of steps\n        :return:\n        \"\"\"\n        while len(self.program) > (self.register['PC'] - 1):\n            steps -= 1\n            if steps < 0:\n                break\n            self.program[self.register['PC'] - 1]()\n            self.register['PC'] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_type(self, name, obj, *args):\n        if obj is None:\n            return\n        for arg in args:\n            if isinstance(obj, arg):\n                return\n        raise TypeError(self.__class__.__name__ + '.' + name + ' is of type ' + type(obj).__name__ +\n                        '. Must be equal to None or one of the following types: ' + str(args))", "response": "This function checks the input object type against each in a list of classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef BL(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n        # TODO check if label is within +- 16 MB\n\n        # BL label\n        def BL_func():\n            self.register['LR'] = self.register['PC']  # No need for the + 1, PC already points to the next instruction\n            self.register['PC'] = self.labels[label]\n\n        return BL_func", "response": "BL is a function that stores the next instruction in the Link Register."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef BLX(self, params):\n        Rj = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(LR_or_general_purpose_registers=(Rj,))\n\n        def BLX_func():\n            self.register['LR'] = self.register['PC']  # No need for the + 1, PC already points to the next instruction\n            self.register['PC'] = self.register[Rj]\n\n        return BLX_func", "response": "BLX Rj\n            Branch to the address in Rj storing the next instruction in the Link Register\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a PEP 440 - compliant version number from VERSION.", "response": "def get_version(version):\n    \"\"\"\n    Returns a PEP 440-compliant version number from VERSION.\n\n    Created by modifying django.utils.version.get_version\n    \"\"\"\n\n    # Now build the two parts of the version number:\n    # major = X.Y[.Z]\n    # sub = .devN - for development releases\n    #     | {a|b|rc}N - for alpha, beta and rc releases\n    #     | .postN - for post-release releases\n\n    assert len(version) == 5\n\n    version_parts = version[:2] if version[2] == 0 else version[:3]\n\n    # Build the first part of the version\n    major = '.'.join(str(x) for x in version_parts)\n\n    # Just return it if this is a final release version\n    if version[3] == 'final':\n        return major\n\n    # Add the rest\n    sub = ''.join(str(x) for x in version[3:5])\n\n    if version[3] == 'dev':\n        # Override the sub part.  Add in a timestamp\n        timestamp = get_git_changeset()\n        sub = 'dev%s' % (timestamp if timestamp else version[4])\n        return '%s.%s' % (major, sub)\n    if version[3] == 'post':\n        # We need a dot for post\n        return '%s.%s' % (major, sub)\n    elif version[3] in ('a', 'b', 'rc'):\n        # No dot for these\n        return '%s%s' % (major, sub)\n    else:\n        raise ValueError('Invalid version: %s' % str(version))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_git_changeset():\n    repo_dir = os.path.dirname(os.path.abspath(__file__))\n    git_log = subprocess.Popen('git log --pretty=format:%ct --quiet -1 HEAD',\n                               stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                               shell=True, cwd=repo_dir, universal_newlines=True)\n    timestamp = git_log.communicate()[0]\n    try:\n        timestamp = datetime.datetime.utcfromtimestamp(int(timestamp))\n        return timestamp.strftime('%Y%m%d%H%M%S')\n    except ValueError:\n        return None", "response": "Returns a numeric identifier of the latest git changeset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the cloudformation template from the given path.", "response": "def load_cloudformation_template(path=None):\n    \"\"\"Load cloudformation template from path.\n\n    :param path: Absolute or relative path of cloudformation template. Defaults to cwd.\n    :return: module, success\n    \"\"\"\n    if not path:\n        path = os.path.abspath('cloudformation.py')\n    else:\n        path = os.path.abspath(path)\n    if isinstance(path, six.string_types):\n        try:\n            sp = sys.path\n            # temporarily add folder to allow relative path\n            sys.path.append(os.path.abspath(os.path.dirname(path)))\n            cloudformation = imp.load_source('cloudformation', path)\n            sys.path = sp  # restore\n            # use cfn template hooks\n            if not check_hook_mechanism_is_intact(cloudformation):\n                # no hooks - do nothing\n                log.debug(\n                    'No valid hook configuration: \\'%s\\'. Not using hooks!',\n                    path)\n            else:\n                if check_register_present(cloudformation):\n                    # register the template hooks so they listen to gcdt_signals\n                    cloudformation.register()\n            return cloudformation, True\n        except GracefulExit:\n            raise\n        except ImportError as e:\n            print('could not find package for import: %s' % e)\n        except Exception as e:\n            print('could not import cloudformation.py, maybe something wrong ',\n                  'with your code?')\n            print(e)\n    return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_parameter_diff(awsclient, config):\n    client_cf = awsclient.get_client('cloudformation')\n    try:\n        stack_name = config['stack']['StackName']\n        if stack_name:\n            response = client_cf.describe_stacks(StackName=stack_name)\n            if response['Stacks']:\n                stack_id = response['Stacks'][0]['StackId']\n                stack = response['Stacks'][0]\n            else:\n                return None\n        else:\n            print(\n                'StackName is not configured, could not create parameter diff')\n            return None\n    except GracefulExit:\n        raise\n    except Exception:\n        # probably the stack is not existent\n        return None\n\n    changed = 0\n    table = []\n    table.append(['Parameter', 'Current Value', 'New Value'])\n\n    # Check if there are parameters for the stack\n    if 'Parameters' in stack:\n        for param in stack['Parameters']:\n            try:\n                old = str(param['ParameterValue'])\n                # can not compare list with str!!\n                # if ',' in old:\n                #    old = old.split(',')\n                new = config['parameters'][param['ParameterKey']]\n                if old != new:\n                    if old.startswith('***'):\n                        # parameter is configured with `NoEcho=True`\n                        # this means we can not really say if the value changed!!\n                        # for security reasons we block viewing the new value\n                        new = old\n                    table.append([param['ParameterKey'], old, new])\n                    changed += 1\n            except GracefulExit:\n                raise\n            except Exception:\n                print('Did not find %s in local config file' % param[\n                    'ParameterKey'])\n\n    if changed > 0:\n        print(tabulate(table, tablefmt='fancy_grid'))\n\n    return changed > 0", "response": "get differences between local config and currently active config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call_pre_hook(awsclient, cloudformation):\n    # TODO: this is deprecated!! move this to glomex_config_reader\n    # no config available\n    if not hasattr(cloudformation, 'pre_hook'):\n        # hook is not present\n        return\n    hook_func = getattr(cloudformation, 'pre_hook')\n    if not hook_func.func_code.co_argcount:\n        hook_func()  # for compatibility with existing templates\n    else:\n        log.error('pre_hock can not have any arguments. The pre_hook it is ' +\n                  'executed BEFORE config is read')", "response": "Invoke the pre_hook before the config is read."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deploy_stack(awsclient, context, conf, cloudformation, override_stack_policy=False):\n    stack_name = _get_stack_name(conf)\n    parameters = _generate_parameters(conf)\n    if stack_exists(awsclient, stack_name):\n        exit_code = _update_stack(awsclient, context, conf, cloudformation,\n                                  parameters, override_stack_policy)\n    else:\n        exit_code = _create_stack(awsclient, context, conf, cloudformation,\n                                  parameters)\n    # add 'stack_output' to the context so it becomes available\n    # in 'command_finalized' hook\n    context['stack_output'] = _get_stack_outputs(\n        awsclient.get_client('cloudformation'), stack_name)\n    _call_hook(awsclient, conf, stack_name, parameters, cloudformation,\n               hook='post_hook',\n               message='CloudFormation is done, now executing post hook...')\n    return exit_code", "response": "Deploy the stack to AWS cloud."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_stack(awsclient, conf, feedback=True):\n    client_cf = awsclient.get_client('cloudformation')\n    stack_name = _get_stack_name(conf)\n    last_event = _get_stack_events_last_timestamp(awsclient, stack_name)\n\n    request = {}\n    dict_selective_merge(request, conf['stack'], ['StackName', 'RoleARN'])\n\n    response = client_cf.delete_stack(**request)\n\n    if feedback:\n        return _poll_stack_events(awsclient, stack_name, last_event)", "response": "Delete the stack from AWS cloud."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint out the list of stacks deployed at AWS cloud.", "response": "def list_stacks(awsclient):\n    \"\"\"Print out the list of stacks deployed at AWS cloud.\n\n    :param awsclient:\n    :return:\n    \"\"\"\n    client_cf = awsclient.get_client('cloudformation')\n    response = client_cf.list_stacks(\n        StackStatusFilter=[\n            'CREATE_IN_PROGRESS', 'CREATE_COMPLETE', 'ROLLBACK_IN_PROGRESS',\n            'ROLLBACK_COMPLETE', 'DELETE_IN_PROGRESS', 'DELETE_FAILED',\n            'UPDATE_IN_PROGRESS', 'UPDATE_COMPLETE_CLEANUP_IN_PROGRESS',\n            'UPDATE_COMPLETE', 'UPDATE_ROLLBACK_IN_PROGRESS',\n            'UPDATE_ROLLBACK_FAILED',\n            'UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS',\n            'UPDATE_ROLLBACK_COMPLETE',\n        ]\n    )\n    result = {}\n    stack_sum = 0\n    for summary in response['StackSummaries']:\n        result['StackName'] = summary[\"StackName\"]\n        result['CreationTime'] = summary['CreationTime']\n        result['StackStatus'] = summary['StackStatus']\n        print(json2table(result))\n        stack_sum += 1\n    print('listed %s stacks' % str(stack_sum))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints out the change_set to console.", "response": "def describe_change_set(awsclient, change_set_name, stack_name):\n    \"\"\"Print out the change_set to console.\n    This needs to run create_change_set first.\n\n    :param awsclient:\n    :param change_set_name:\n    :param stack_name:\n    \"\"\"\n    client = awsclient.get_client('cloudformation')\n\n    status = None\n    while status not in ['CREATE_COMPLETE', 'FAILED']:\n        response = client.describe_change_set(\n            ChangeSetName=change_set_name,\n            StackName=stack_name)\n        status = response['Status']\n        # print('##### %s' % status)\n        if status == 'FAILED':\n            print(response['StatusReason'])\n        elif status == 'CREATE_COMPLETE':\n            for change in response['Changes']:\n                print(json2table(change['ResourceChange']))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_change_set(awsclient, change_set_name, stack_name):\n    client = awsclient.get_client('cloudformation')\n\n    response = client.delete_change_set(\n        ChangeSetName=change_set_name,\n        StackName=stack_name)", "response": "Delete specified change set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_template_to_file(conf, template_body):\n    template_file_name = _get_stack_name(conf) + '-generated-cf-template.json'\n    with open(template_file_name, 'w') as opened_file:\n        opened_file.write(template_body)\n    print('wrote cf-template for %s to disk: %s' % (\n        get_env(), template_file_name))\n    return template_file_name", "response": "Writes the template to disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls cloudformation to generate the template", "response": "def generate_template(context, config, cloudformation):\n    \"\"\"call cloudformation to generate the template (json format).\n\n    :param context:\n    :param config:\n    :param cloudformation:\n    :return:\n    \"\"\"\n    spec = inspect.getargspec(cloudformation.generate_template)[0]\n    if len(spec) == 0:\n        return cloudformation.generate_template()\n    elif spec == ['context', 'config']:\n        return cloudformation.generate_template(context, config)\n    else:\n        raise Exception('Arguments of \\'generate_template\\' not as expected: %s' % spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info(awsclient, config, format=None):\n    if format is None:\n        format = 'tabular'\n    stack_name = _get_stack_name(config)\n    client_cfn = awsclient.get_client('cloudformation')\n\n    resources = all_pages(\n        client_cfn.list_stack_resources,\n        {'StackName': stack_name},\n        lambda x: [(r['ResourceType'], r['LogicalResourceId'], r['ResourceStatus'])\n            for r in x['StackResourceSummaries']]\n    )\n\n    infos = {\n        'stack_output': _get_stack_outputs(client_cfn, stack_name),\n        'stack_state': _get_stack_state(client_cfn, stack_name),\n        'resources': resources\n    }\n    if format == 'json':\n        print(json.dumps(infos))\n    elif format == 'tabular':\n        print('stack output:')\n        print(tabulate(infos['stack_output'], tablefmt='fancy_grid'))\n        print('\\nstack_state: %s' % infos['stack_state'])\n        print('\\nresources:')\n        print(tabulate(infos['resources'], tablefmt='fancy_grid'))", "response": "collect info and output to console"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef BCC(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BCC label\n        def BCC_func():\n            if not self.is_C_set():\n                self.register['PC'] = self.labels[label]\n\n        return BCC_func", "response": "BCC is a helper method that returns a function that will set the PC to the value of the C flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef BEQ(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BEQ label\n        def BEQ_func():\n            if self.is_Z_set():\n                self.register['PC'] = self.labels[label]\n\n        return BEQ_func", "response": "Return a function that sets the PC to the value of the OID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef BGE(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BGE label\n        def BGE_func():\n            if self.is_N_set() == self.is_V_set():\n                self.register['PC'] = self.labels[label]\n\n        return BGE_func", "response": "BGE label\n            = 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbranches to the instruction at the specified label if the N flag is the same as the V flag and the Z flag is not set.", "response": "def BGT(self, params):\n        \"\"\"\n        BGT label\n\n        Branch to the instruction at label if the N flag is the same as the V flag and the Z flag is not set\n        \"\"\"\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BGT label\n        def BGT_func():\n            if (self.is_N_set() == self.is_V_set()) and not self.is_Z_set():\n                self.register['PC'] = self.labels[label]\n\n        return BGT_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbranching to the instruction at label if the C flag is set and the Z flag is not set.", "response": "def BHI(self, params):\n        \"\"\"\n        BHI label\n\n        Branch to the instruction at label if the C flag is set and the Z flag is not set\n        \"\"\"\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BHI label\n        def BHI_func():\n            if self.is_C_set() and not self.is_Z_set():\n                self.register['PC'] = self.labels[label]\n\n        return BHI_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a function that returns the branch to the instruction at the specified label.", "response": "def BHS(self, params):\n        \"\"\"\n        BHS label\n\n        Branch to the instruction at label if the C flag is set\n        \"\"\"\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BHS label\n        def BHS_func():\n            if self.is_C_set():\n                self.register['PC'] = self.labels[label]\n\n        return BHS_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbranches to the instruction at the specified label if the Z flag is set or the N flag is not the same as the V flag.", "response": "def BLE(self, params):\n        \"\"\"\n        BLE label\n\n        Branch to the instruction at label if the Z flag is set or if the N flag is not the same as the V flag\n        \"\"\"\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BLE label\n        def BLE_func():\n            if self.is_Z_set() or (self.is_N_set() != self.is_V_set()):\n                self.register['PC'] = self.labels[label]\n\n        return BLE_func"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef BLO(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BLO label\n        def BLO_func():\n            if not self.is_C_set():\n                self.register['PC'] = self.labels[label]\n\n        return BLO_func", "response": "BLO is a helper function that returns a function that will set the PC to the value of the C flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BLS(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BLS label\n        def BLS_func():\n            if (not self.is_C_set()) or self.is_Z_set():\n                self.register['PC'] = self.labels[label]\n\n        return BLS_func", "response": "Branch to the instruction at the specified label if the C flag is not set and the Z flag is set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef BLT(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BLT label\n        def BLT_func():\n            if self.is_N_set() != self.is_V_set():\n                self.register['PC'] = self.labels[label]\n\n        return BLT_func", "response": "BLT is a branch to the instruction at the instruction at the specified label if the N flag is not the same as the V flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BMI(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BMI label\n        def BMI_func():\n            if self.is_N_set():\n                self.register['PC'] = self.labels[label]\n\n        return BMI_func", "response": "BMI is a function that returns the value of the instruction at the specified label."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef BVS(self, params):\n        label = self.get_one_parameter(self.ONE_PARAMETER, params)\n\n        self.check_arguments(label_exists=(label,))\n\n        # BVS label\n        def BVS_func():\n            if self.is_V_set():\n                self.register['PC'] = self.labels[label]\n\n        return BVS_func", "response": "BVS label\n            = 1 - 31"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_queryset(self, request):\n        queryset = super(MetricGroupAdmin, self).get_queryset(request)\n        # poor-man's DISTINCT ON for Sqlite3\n        qs_values = queryset.values('id', 'name')\n        # 2.7+ only :(\n        # = {metric['name']: metric['id'] for metric in qs_values}\n        distinct_names = {}\n        for metric in qs_values:\n            distinct_names[metric['name']] = metric['id']\n        queryset = self.model.objects.filter(id__in=distinct_names.values())\n        return queryset", "response": "Shows one entry per distinct metric name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate all metrics with the same name", "response": "def save_model(self, request, obj, form, change):\n        \"\"\"Updates all metrics with the same name\"\"\"\n        like_metrics = self.model.objects.filter(name=obj.name)\n        # 2.7+ only :(\n        # = {key: form.cleaned_data[key] for key in form.changed_data}\n        updates = {}\n        for key in form.changed_data:\n            updates[key] = form.cleaned_data[key]\n        like_metrics.update(**updates)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the code into a list of tuples.", "response": "def parse_lines(self, code):\n        \"\"\"\n        Return a list of the parsed code\n\n        For each line, return a three-tuple containing:\n        1. The label\n        2. The instruction\n        3. Any arguments or parameters\n\n        An element in the tuple may be None or '' if it did not find anything\n        :param code: The code to parse\n        :return: A list of tuples in the form of (label, instruction, parameters)\n        \"\"\"\n        remove_comments = re.compile(r'^([^;@\\n]*);?.*$', re.MULTILINE)\n        code = '\\n'.join(remove_comments.findall(code))  # TODO can probably do this better\n        # TODO labels with spaces between pipes is allowed `|label with space| INST OPER`\n        parser = re.compile(r'^(\\S*)?[\\s]*(\\S*)([^\\n]*)$', re.MULTILINE)\n        res = parser.findall(code)\n        # Make all parsing of labels and instructions adhere to all uppercase\n        res = [(label.upper(), instruction.upper(), parameters.strip()) for (label, instruction, parameters) in res]\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the parameter is a valid register and if so returns the register number", "response": "def check_register(self, arg):\n        \"\"\"\n        Is the parameter a register in the form of 'R<d>',\n        and if so is it within the bounds of registers defined\n\n        Raises an exception if\n        1. The parameter is not in the form of 'R<d>'\n        2. <d> is outside the range of registers defined in the init value\n            registers or _max_registers\n        :param arg: The parameter to check\n        :return: The number of the register\n        \"\"\"\n        self.check_parameter(arg)\n        match = re.search(self.REGISTER_REGEX, arg)\n        if match is None:\n            raise iarm.exceptions.RuleError(\"Parameter {} is not a register\".format(arg))\n        try:\n            r_num = int(match.groups()[0])\n        except ValueError:\n            r_num = int(match.groups()[0], 16)\n        except TypeError:\n            if arg in 'lr|LR':\n                return 14\n            elif arg in 'sp|SP':\n                return 13\n            elif arg in 'fp|FP':\n                return 7 ## TODO this could be 7 or 11 depending on THUMB and ARM mode http://www.keil.com/support/man/docs/armcc/armcc_chr1359124947957.htm\n            else:\n                raise\n        if r_num > self._max_registers:\n            raise iarm.exceptions.RuleError(\n                \"Register {} is greater than defined registers of {}\".format(arg, self._max_registers))\n\n        return r_num"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the parameter is an immediate", "response": "def check_immediate(self, arg):\n        \"\"\"\n        Is the parameter an immediate in the form of '#<d>',\n\n        Raises an exception if\n        1. The parameter is not in the form of '#<d>'\n        :param arg: The parameter to check\n        :return: The value of the immediate\n        \"\"\"\n        self.check_parameter(arg)\n        match = re.search(self.IMMEDIATE_REGEX, arg)\n        if match is None:\n            raise iarm.exceptions.RuleError(\"Parameter {} is not an immediate\".format(arg))\n        return self.convert_to_integer(match.groups()[0])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_immediate_unsigned_value(self, arg, bit):\n        i_num = self.check_immediate(arg)\n        if (i_num > (2 ** bit - 1)) or (i_num < 0):\n            raise iarm.exceptions.RuleError(\"Immediate {} is not an unsigned {} bit value\".format(arg, bit))\n        return i_num", "response": "Checks the immediate value of the bit - value of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_immediate_value(self, arg, _max, _min=0):\n        i_num = self.check_immediate(arg)\n        if (i_num > _max) or (i_num < _min):\n            raise iarm.exceptions.RuleError(\"Immediate {} is not within the range of [{}, {}]\".format(arg, _min, _max))\n        return i_num", "response": "Checks that the immediate value is within the range of _min _max."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rule_low_registers(self, arg):\n        r_num = self.check_register(arg)\n        if r_num > 7:\n            raise iarm.exceptions.RuleError(\n                \"Register {} is not a low register\".format(arg))", "response": "Low registers are R0 - R7"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a regex expression and a string with the paramers return a regex match object", "response": "def get_parameters(self, regex_exp, parameters):\n        \"\"\"\n        Given a regex expression and the string with the paramers,\n        either return a regex match object or raise an exception if the regex\n        did not find a match\n        :param regex_exp:\n        :param parameters:\n        :return:\n        \"\"\"\n        # TODO find a better way to do the equate replacement\n        for rep in self.equates:\n            parameters = parameters.replace(rep, str(self.equates[rep]))\n        match = re.match(regex_exp, parameters)\n        if not match:\n            raise iarm.exceptions.ParsingError(\"Parameters are None, did you miss a comma?\")\n\n        return match.groups()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_one_parameter(self, regex_exp, parameters):\n        Rx, other = self.get_parameters(regex_exp, parameters)\n        if other is not None and other.strip():\n            raise iarm.exceptions.ParsingError(\"Extra arguments found: {}\".format(other))\n        return Rx.upper()", "response": "Get three parameters from a given regex expression and return the first one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting two parameters from a given regex expression. Raise an exception if more than two were found.", "response": "def get_two_parameters(self, regex_exp, parameters):\n        \"\"\"\n        Get two parameters from a given regex expression\n\n        Raise an exception if more than two were found\n        :param regex_exp:\n        :param parameters:\n        :return:\n        \"\"\"\n        Rx, Ry, other = self.get_parameters(regex_exp, parameters)\n        if other is not None and other.strip():\n            raise iarm.exceptions.ParsingError(\"Extra arguments found: {}\".format(other))\n        if Rx and Ry:\n            return Rx.upper(), Ry.upper()\n        elif not Rx:\n            raise iarm.exceptions.ParsingError(\"Missing first positional argument\")\n        else:\n            raise iarm.exceptions.ParsingError(\"Missing second positional argument\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets three parameters from a given regex expression.", "response": "def get_three_parameters(self, regex_exp, parameters):\n        \"\"\"\n        Get three parameters from a given regex expression\n\n        Raise an exception if more than three were found\n        :param regex_exp:\n        :param parameters:\n        :return:\n        \"\"\"\n        Rx, Ry, Rz, other = self.get_parameters(regex_exp, parameters)\n        if other is not None and other.strip():\n            raise iarm.exceptions.ParsingError(\"Extra arguments found: {}\".format(other))\n        return Rx.upper(), Ry.upper(), Rz.upper()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_APSR_flag_to_value(self, flag, value):\n        if flag == 'N':\n            bit = 31\n        elif flag == 'Z':\n            bit = 30\n        elif flag == 'C':\n            bit = 29\n        elif flag == 'V':\n            bit = 28\n        else:\n            raise AttributeError(\"Flag {} does not exist in the APSR\".format(flag))\n\n        if value:\n            self.register['APSR'] |= (1 << bit)\n        else:\n            self.register['APSR'] -= (1 << bit) if (self.register['APSR'] & (1 << bit)) else 0", "response": "Set or clear flag in ASPR"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises an exception if the register is not a special register", "response": "def rule_special_registers(self, arg):\n        \"\"\"Raises an exception if the register is not a special register\"\"\"\n        # TODO is PSR supposed to be here?\n        special_registers = \"PSR APSR IPSR EPSR PRIMASK FAULTMASK BASEPRI CONTROL\"\n        if arg not in special_registers.split():\n            raise iarm.exceptions.RuleError(\"{} is not a special register; Must be [{}]\".format(arg, special_registers))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_C_flag(self, oper_1, oper_2, result, type):\n        # TODO is this correct?\n        if type == 'add':\n            if result < oper_1:\n                self.set_APSR_flag_to_value('C', 1)\n            else:\n                self.set_APSR_flag_to_value('C', 0)\n        elif type == 'sub':\n            if oper_1 < oper_2:\n                # If there was a borrow, then set to zero\n                self.set_APSR_flag_to_value('C', 0)\n            else:\n                self.set_APSR_flag_to_value('C', 1)\n        elif type == 'shift-left':\n            if (oper_2 > 0) and (oper_2 < (self._bit_width - 1)):\n                self.set_APSR_flag_to_value('C', oper_1 & (1 << (self._bit_width - oper_2)))\n            else:\n                self.set_APSR_flag_to_value('C', 0)\n        else:\n            raise iarm.exceptions.BrainFart(\"_type is not 'add' or 'sub'\")", "response": "Set the C flag for the set of the A - TOTAL resources."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef version():\n    log.info('gcdt version %s' % __version__)\n    tools = get_plugin_versions('gcdttool10')\n    if tools:\n        log.info('gcdt tools:')\n        for p, v in tools.items():\n            log.info(' * %s version %s' % (p, v))\n    log.info('gcdt plugins:')\n    for p, v in get_plugin_versions().items():\n        log.info(' * %s version %s' % (p, v))\n    generators = get_plugin_versions('gcdtgen10')\n    if generators:\n        log.info('gcdt scaffolding generators:')\n        for p, v in generators.items():\n            log.info(' * %s version %s' % (p, v))", "response": "Output version of gcdt tools and plugins."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction decorator implementing retrying logic. delay: Sleep this many seconds * backoff * try number after failure backoff: Multiply delay by this factor after each failure exceptions: A tuple of exception classes; default (Exception,) hook: A function with the signature: (tries_remaining, exception, mydelay)", "response": "def retries(max_tries, delay=1, backoff=2, exceptions=(Exception,), hook=None):\n    \"\"\"Function decorator implementing retrying logic.\n\n    delay: Sleep this many seconds * backoff * try number after failure\n    backoff: Multiply delay by this factor after each failure\n    exceptions: A tuple of exception classes; default (Exception,)\n    hook: A function with the signature: (tries_remaining, exception, mydelay)\n    \"\"\"\n\n    \"\"\"\n    def example_hook(tries_remaining, exception, delay):\n        '''Example exception handler; prints a warning to stderr.\n\n        tries_remaining: The number of tries remaining.\n        exception: The exception instance which was raised.\n        '''\n        print >> sys.stderr, \"Caught '%s', %d tries remaining, sleeping for %s seconds\" % (exception, tries_remaining, delay)\n\n    The decorator will call the function up to max_tries times if it raises\n    an exception.\n\n    By default it catches instances of the Exception class and subclasses.\n    This will recover after all but the most fatal errors. You may specify a\n    custom tuple of exception classes with the 'exceptions' argument; the\n    function will only be retried if it raises one of the specified\n    exceptions.\n\n    Additionally you may specify a hook function which will be called prior\n    to retrying with the number of remaining tries and the exception instance;\n    see given example. This is primarily intended to give the opportunity to\n    log the failure. Hook is not called after failure if no retries remain.\n    \"\"\"\n    def dec(func):\n        def f2(*args, **kwargs):\n            mydelay = delay\n            #tries = range(max_tries)\n            #tries.reverse()\n            tries = range(max_tries-1, -1, -1)\n            for tries_remaining in tries:\n                try:\n                    return func(*args, **kwargs)\n                except GracefulExit:\n                    raise\n                except exceptions as e:\n                    if tries_remaining > 0:\n                        if hook is not None:\n                            hook(tries_remaining, e, mydelay)\n                        sleep(mydelay)\n                        mydelay *= backoff\n                    else:\n                        raise\n        return f2\n    return dec"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_env():\n    env = os.getenv('ENV', os.getenv('env', None))\n    if env:\n        env = env.lower()\n    return env", "response": "Read environment from ENV and mangle it to a lower case string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_command(arguments):\n    return [k for k, v in arguments.items()\n            if not k.startswith('-') and v is True][0]", "response": "Extract the first argument from arguments parsed by docopt.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether a newer gcdt version is available and output a warning.", "response": "def check_gcdt_update():\n    \"\"\"Check whether a newer gcdt is available and output a warning.\n\n    \"\"\"\n    try:\n        inst_version, latest_version = get_package_versions('gcdt')\n        if inst_version < latest_version:\n            log.warn('Please consider an update to gcdt version: %s' %\n                                 latest_version)\n    except GracefulExit:\n        raise\n    except Exception:\n        log.warn('PyPi appears to be down - we currently can\\'t check for newer gcdt versions')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_selective_merge(a, b, selection, path=None):\n    if path is None:\n        path = []\n    for key in b:\n        if key in selection:\n            if key in a:\n                if isinstance(a[key], dict) and isinstance(b[key], dict):\n                    dict_selective_merge(a[key], b[key], b[key].keys(), path + [str(key)])\n                elif a[key] != b[key]:\n                    # update the value\n                    a[key] = b[key]\n            else:\n                a[key] = b[key]\n    return a", "response": "Conditionally merges b into a if b s keys are contained in selection\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging a into b", "response": "def dict_merge(a, b, path=None):\n    \"\"\"merges b into a\"\"\"\n    return dict_selective_merge(a, b, b.keys(), path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef are_credentials_still_valid(awsclient):\n    client = awsclient.get_client('lambda')\n    try:\n        client.list_functions()\n    except GracefulExit:\n        raise\n    except Exception as e:\n        log.debug(e)\n        log.error(e)\n        return 1\n    return 0", "response": "Check whether the credentials have expired."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a list possibly nested to any level return it flattened.", "response": "def flatten(lis):\n    \"\"\"Given a list, possibly nested to any level, return it flattened.\"\"\"\n    new_lis = []\n    for item in lis:\n        if isinstance(item, collections.Sequence) and not isinstance(item, basestring):\n            new_lis.extend(flatten(item))\n        else:\n            new_lis.append(item)\n    return new_lis"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef signal_handler(signum, frame):\n    # signals are CONSTANTS so there is no mapping from signum to description\n    # so please add to the mapping in case you use more signals!\n    description = '%d' % signum\n    if signum == 2:\n        description = 'SIGINT'\n    elif signum == 15:\n        description = 'SIGTERM'\n    raise GracefulExit(description)", "response": "handle signals.\n    example: 'signal.signal(signal.SIGTERM, signal_handler)'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a random 6 character string.", "response": "def random_string(length=6):\n    \"\"\"Create a random 6 character string.\n\n    note: in case you use this function in a test during test together with\n    an awsclient then this function is altered so you get reproducible results\n    that will work with your recorded placebo json files (see helpers_aws.py).\n    \"\"\"\n    return ''.join([random.choice(string.ascii_lowercase) for i in range(length)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_pages(method, request, accessor, cond=None):\n    if cond is None:\n        cond = lambda x: True\n    result = []\n    next_token = None\n    while True:\n        if next_token:\n            request['nextToken'] = next_token\n        response = method(**request)\n        if cond(response):\n            data = accessor(response)\n            if data:\n                if isinstance(data, list):\n                    result.extend(data)\n                else:\n                    result.append(data)\n        if 'nextToken' not in response:\n            break\n        next_token = response['nextToken']\n\n    return result", "response": "helper function to process all pages using botocore service methods."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the invoke method for the specified click command.", "response": "def get_invoke(command):\n    \"\"\"\n    Get the Cmd main method from the click command\n    :param command: The click Command object\n    :return: the do_* method for Cmd\n    :rtype: function\n    \"\"\"\n\n    assert isinstance(command, click.Command)\n\n    def invoke_(self, arg):  # pylint: disable=unused-argument\n        try:\n            command.main(args=shlex.split(arg),\n                         prog_name=command.name,\n                         standalone_mode=False,\n                         parent=self.ctx)\n        except click.ClickException as e:\n            # Show the error message\n            e.show()\n        except click.Abort:\n            # We got an EOF or Keyboard interrupt.  Just silence it\n            pass\n        except SystemExit:\n            # Catch this an return the code instead. All of click's help commands do a sys.exit(),\n            # and that's not ideal when running in a shell.\n            pass\n        except Exception as e:\n            traceback.print_exception(type(e), e, None)\n            logger.warning(traceback.format_exc())\n\n        # Always return False so the shell doesn't exit\n        return False\n\n    invoke_ = update_wrapper(invoke_, command.callback)\n    invoke_.__name__ = 'do_%s' % command.name\n    return invoke_"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_help(command):\n    assert isinstance(command, click.Command)\n\n    def help_(self):  # pylint: disable=unused-argument\n        extra = {}\n        for key, value in command.context_settings.items():\n            if key not in extra:\n                extra[key] = value\n\n        # Print click's help message\n        with click.Context(command, info_name=command.name, parent=self.ctx, **extra) as ctx:\n            click.echo(ctx.get_help(), color=ctx.color)\n\n    help_.__name__ = 'help_%s' % command.name\n    return help_", "response": "Get the help function from the click command\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the complete function for the click command", "response": "def get_complete(command):\n    \"\"\"\n    Get the Cmd complete function for the click command\n    :param command: The click Command object\n    :return: the complete_* method for Cmd\n    :rtype: function\n    \"\"\"\n\n    assert isinstance(command, click.Command)\n\n    def complete_(self, text, line, begidx, endidx):  # pylint: disable=unused-argument\n        # Parse the args\n        args = shlex.split(line[:begidx])\n        # Strip of the first item which is the name of the command\n        args = args[1:]\n\n        # Then pass them on to the get_choices method that click uses for completion\n        return list(get_choices(command, command.name, args, text))\n\n    complete_.__name__ = 'complete_%s' % command.name\n    return complete_"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_template():\n    cloudformation, found = load_cloudformation_template()\n    if not found:\n        print(colored.red('could not load cloudformation.py, bailing out...'))\n        sys.exit(1)\n    return cloudformation", "response": "Load the cloudformation template."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _import_public_names(module):\n    \"Import public names from module into this module, like import *\"\n    self = sys.modules[__name__]\n    for name in module.__all__:\n        if hasattr(self, name):\n            # don't overwrite existing names\n            continue\n        setattr(self, name, getattr(module, name))", "response": "Import public names from module into this module like import *"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the argument parser for haas.", "response": "def create_argument_parser():\n    \"\"\"Creates the argument parser for haas.\n\n    \"\"\"\n    parser = argparse.ArgumentParser(prog='haas')\n    parser.add_argument('--version', action='version',\n                        version='%(prog)s {0}'.format(haas.__version__))\n    verbosity = parser.add_mutually_exclusive_group()\n    verbosity.add_argument('-v', '--verbose', action='store_const', default=1,\n                           dest='verbosity', const=2, help='Verbose output')\n    verbosity.add_argument('-q', '--quiet', action='store_const', const=0,\n                           dest='verbosity', help='Quiet output')\n    parser.add_argument('-f', '--failfast', action='store_true', default=False,\n                        help='Stop on first fail or error')\n    parser.add_argument('-c', '--catch', dest='catch_interrupt',\n                        action='store_true', default=False,\n                        help=('(Ignored) Catch ctrl-C and display results so '\n                              'far'))\n    parser.add_argument('-b', '--buffer', action='store_true', default=False,\n                        help='Buffer stdout and stderr during tests')\n    parser.add_argument(\n        'start', nargs='*', default=[os.getcwd()],\n        help=('One or more directories or dotted package/module names from '\n              'which to start searching for tests'))\n    parser.add_argument('-p', '--pattern', default='test*.py',\n                        help=\"Pattern to match tests ('test*.py' default)\")\n    parser.add_argument('-t', '--top-level-directory', default=None,\n                        help=('Top level directory of project (defaults to '\n                              'start directory)'))\n    _add_log_level_option(parser)\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the haas test runner. This will load and configure the selected plugins, set up the environment and begin test discovery, loading and running. Parameters ---------- plugin_manager : haas.plugin_manager.PluginManager [Optional] Override the use of the default plugin manager.", "response": "def run(self, plugin_manager=None):\n        \"\"\"Run the haas test runner.\n\n        This will load and configure the selected plugins, set up the\n        environment and begin test discovery, loading and running.\n\n        Parameters\n        ----------\n        plugin_manager : haas.plugin_manager.PluginManager\n            [Optional] Override the use of the default plugin manager.\n\n        \"\"\"\n        if plugin_manager is None:\n            plugin_manager = PluginManager()\n        plugin_manager.add_plugin_arguments(self.parser)\n\n        args = self.parser.parse_args(self.argv[1:])\n\n        environment_plugins = plugin_manager.get_enabled_hook_plugins(\n            plugin_manager.ENVIRONMENT_HOOK, args)\n        runner = plugin_manager.get_driver(\n            plugin_manager.TEST_RUNNER, args)\n\n        with PluginContext(environment_plugins):\n            loader = Loader()\n            discoverer = plugin_manager.get_driver(\n                plugin_manager.TEST_DISCOVERY, args, loader=loader)\n            suites = [\n                discoverer.discover(\n                    start=start,\n                    top_level_directory=args.top_level_directory,\n                    pattern=args.pattern,\n                )\n                for start in args.start\n            ]\n            if len(suites) == 1:\n                suite = suites[0]\n            else:\n                suite = loader.create_suite(suites)\n            test_count = suite.countTestCases()\n            result_handlers = plugin_manager.get_enabled_hook_plugins(\n                plugin_manager.RESULT_HANDLERS, args, test_count=test_count)\n\n            result_collector = ResultCollector(\n                buffer=args.buffer, failfast=args.failfast)\n\n            for result_handler in result_handlers:\n                result_collector.add_result_handler(result_handler)\n\n            result = runner.run(result_collector, suite)\n            return not result.wasSuccessful()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt_password(**kwargs):\n    new_value = kwargs['new_value']\n    field = kwargs['field']\n    min_length = field.params['min_length']\n    if len(new_value) < min_length:\n        raise ValueError(\n            '`{}`: Value length must be more than {}'.format(\n                field.name, field.params['min_length']))\n\n    if new_value and not crypt.match(new_value):\n        new_value = str(crypt.encode(new_value))\n    return new_value", "response": "Crypt :new_value: if it's not crypted yet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating ApiKey model class and connect it with user model.", "response": "def create_apikey_model(user_model):\n    \"\"\" Generate ApiKey model class and connect it with :user_model:.\n\n    ApiKey is generated with relationship to user model class :user_model:\n    as a One-to-One relationship with a backreference.\n    ApiKey is set up to be auto-generated when a new :user_model: is created.\n\n    Returns ApiKey document class. If ApiKey is already defined, it is not\n    generated.\n\n    Arguments:\n        :user_model: Class that represents user model for which api keys will\n            be generated and with which ApiKey will have relationship.\n    \"\"\"\n    try:\n        return engine.get_document_cls('ApiKey')\n    except ValueError:\n        pass\n\n    fk_kwargs = {\n        'ref_column': None,\n    }\n    if hasattr(user_model, '__tablename__'):\n        fk_kwargs['ref_column'] = '.'.join([\n            user_model.__tablename__, user_model.pk_field()])\n        fk_kwargs['ref_column_type'] = user_model.pk_field_type()\n\n    class ApiKey(engine.BaseDocument):\n        __tablename__ = 'nefertari_apikey'\n\n        id = engine.IdField(primary_key=True)\n        token = engine.StringField(default=create_apikey_token)\n        user = engine.Relationship(\n            document=user_model.__name__,\n            uselist=False,\n            backref_name='api_key',\n            backref_uselist=False)\n        user_id = engine.ForeignKeyField(\n            ref_document=user_model.__name__,\n            **fk_kwargs)\n\n        def reset_token(self):\n            self.update({'token': create_apikey_token()})\n            return self.token\n\n    # Setup ApiKey autogeneration on :user_model: creation\n    ApiKey.autogenerate_for(user_model, 'user')\n\n    return ApiKey"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets api token for user with username username.", "response": "def get_token_credentials(cls, username, request):\n        \"\"\" Get api token for user with username of :username:\n\n        Used by Token-based auth as `credentials_callback` kwarg.\n        \"\"\"\n        try:\n            user = cls.get_item(username=username)\n        except Exception as ex:\n            log.error(str(ex))\n            forget(request)\n        else:\n            if user:\n                return user.api_key.token"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets user s groups by token", "response": "def get_groups_by_token(cls, username, token, request):\n        \"\"\" Get user's groups if user with :username: exists and their api key\n        token equals :token:\n\n        Used by Token-based authentication as `check` kwarg.\n        \"\"\"\n        try:\n            user = cls.get_item(username=username)\n        except Exception as ex:\n            log.error(str(ex))\n            forget(request)\n            return\n        else:\n            if user and user.api_key.token == token:\n                return ['g:%s' % g for g in user.groups]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nauthenticating user with login and password from params.", "response": "def authenticate_by_password(cls, params):\n        \"\"\" Authenticate user with login and password from :params:\n\n        Used both by Token and Ticket-based auths (called from views).\n        \"\"\"\n        def verify_password(user, password):\n            return crypt.check(user.password, password)\n\n        success = False\n        user = None\n        login = params['login'].lower().strip()\n        key = 'email' if '@' in login else 'username'\n        try:\n            user = cls.get_item(**{key: login})\n        except Exception as ex:\n            log.error(str(ex))\n\n        if user:\n            password = params.get('password', None)\n            success = (password and verify_password(user, password))\n        return success, user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_groups_by_userid(cls, userid, request):\n        try:\n            cache_request_user(cls, request, userid)\n        except Exception as ex:\n            log.error(str(ex))\n            forget(request)\n        else:\n            if request._user:\n                return ['g:%s' % g for g in request._user.groups]", "response": "Return a list of groups that the user has identified by the given userid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating auth user instance with data from params.", "response": "def create_account(cls, params):\n        \"\"\" Create auth user instance with data from :params:.\n\n        Used by both Token and Ticket-based auths to register a user (\n        called from views).\n        \"\"\"\n        user_params = dictset(params).subset(\n            ['username', 'email', 'password'])\n        try:\n            return cls.get_or_create(\n                email=user_params['email'],\n                defaults=user_params)\n        except JHTTPBadRequest:\n            raise JHTTPBadRequest('Failed to create account.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_authuser_by_userid(cls, request):\n        userid = authenticated_userid(request)\n        if userid:\n            cache_request_user(cls, request, userid)\n            return request._user", "response": "Get user by ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget user by name.", "response": "def get_authuser_by_name(cls, request):\n        \"\"\" Get user by username\n\n        Used by Token-based auth. Is added as request method to populate\n        `request.user`.\n        \"\"\"\n        username = authenticated_userid(request)\n        if username:\n            return cls.get_item(username=username)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwalk the directory like os. path and yield a 3 - tuple of directories and files.", "response": "def walk(self):\n        \"\"\" Walk the directory like os.path\n        (yields a 3-tuple (dirpath, dirnames, filenames)\n        except it exclude all files/directories on the fly. \"\"\"\n        for root, dirs, files in os.walk(self.path, topdown=True):\n            # TODO relative walk, recursive call if root excluder found???\n            #root_excluder = get_root_excluder(root)\n            ndirs = []\n            # First we exclude directories\n            for d in list(dirs):\n                if self.is_excluded(os.path.join(root, d)):\n                    dirs.remove(d)\n                elif not os.path.islink(os.path.join(root, d)):\n                    ndirs.append(d)\n\n            nfiles = []\n            for fpath in (os.path.join(root, f) for f in files):\n                if not self.is_excluded(fpath) and not os.path.islink(fpath):\n                    nfiles.append(os.path.relpath(fpath, root))\n\n            yield root, ndirs, nfiles"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd event subscribers to the base object.", "response": "def includeme(config):\n    \"\"\" Set up event subscribers. \"\"\"\n    from .models import (\n        AuthUserMixin,\n        random_uuid,\n        lower_strip,\n        encrypt_password,\n    )\n    add_proc = config.add_field_processors\n    add_proc(\n        [random_uuid, lower_strip],\n        model=AuthUserMixin, field='username')\n    add_proc([lower_strip], model=AuthUserMixin, field='email')\n    add_proc([encrypt_password], model=AuthUserMixin, field='password')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_request(self, method, params):\n        if self.blocked_until is not None and \\\n                datetime.datetime.utcnow() < self.blocked_until:\n            raise SlackError(\"Too many requests - wait until {0}\" \\\n                    .format(self.blocked_until))\n\n        url = \"%s/%s\" % (SlackClient.BASE_URL, method)\n        params['token'] = self.token\n        response = requests.post(url, data=params, verify=self.verify)\n\n        if response.status_code == 429:\n            # Too many requests\n            retry_after = int(response.headers.get('retry-after', '1'))\n            self.blocked_until = datetime.datetime.utcnow() + \\\n                    datetime.timedelta(seconds=retry_after)\n            raise SlackError(\"Too many requests - retry after {0} second(s)\" \\\n                    .format(retry_after))\n\n        result = response.json()\n        if not result['ok']:\n            raise SlackError(result['error'])\n        return result", "response": "Make a request to the API endpoint and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef channel_name_to_id(self, channel_name, force_lookup=False):\n        if force_lookup or not self.channel_name_id_map:\n            channels = self.channels_list()['channels']\n            self.channel_name_id_map = {channel['name']: channel['id'] for channel in channels}\n        channel = channel_name.startswith('#') and channel_name[1:] or channel_name\n        return self.channel_name_id_map.get(channel)", "response": "Helper name for getting a channel s id from its name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chat_post_message(self, channel, text, **params):\n        method = 'chat.postMessage'\n        params.update({\n            'channel': channel,\n            'text': text,\n        })\n        return self._make_request(method, params)", "response": "This method posts a message to a channel."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef includeme(config):\n    root = config.get_root_resource()\n    root.add('nef_polymorphic', '{collections:.+,.+}',\n             view=PolymorphicESView,\n             factory=PolymorphicACL)", "response": "Connect to route that catches all URIs like\n    something..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting names of collections from request matchdict.", "response": "def get_collections(self):\n        \"\"\" Get names of collections from request matchdict.\n\n        :return: Names of collections\n        :rtype: list of str\n        \"\"\"\n        collections = self.request.matchdict['collections'].split('/')[0]\n        collections = [coll.strip() for coll in collections.split(',')]\n        return set(collections)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget resources that correspond to values from collections.", "response": "def get_resources(self, collections):\n        \"\"\" Get resources that correspond to values from :collections:.\n\n        :param collections: Collection names for which resources should be\n            gathered\n        :type collections: list of str\n        :return: Gathered resources\n        :rtype: list of Resource instances\n        \"\"\"\n        res_map = self.request.registry._model_collections\n        resources = [res for res in res_map.values()\n                     if res.collection_name in collections]\n        resources = [res for res in resources if res]\n        return set(resources)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_least_permissions_aces(self, resources):\n        factories = [res.view._factory for res in resources]\n        contexts = [factory(self.request) for factory in factories]\n        for ctx in contexts:\n            if not self.request.has_permission('view', ctx):\n                return\n        else:\n            return [\n                (Allow, principal, 'view')\n                for principal in self.request.effective_principals\n            ]", "response": "Get ACEs with the least permissions that fit all resources."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_collections_acl(self):\n        acl = [(Allow, 'g:admin', ALL_PERMISSIONS)]\n        collections = self.get_collections()\n        resources = self.get_resources(collections)\n        aces = self._get_least_permissions_aces(resources)\n        if aces is not None:\n            for ace in aces:\n                acl.append(ace)\n        acl.append(DENY_ALL)\n        self.__acl__ = tuple(acl)", "response": "Calculate and set ACL valid for requested collections."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining ES type names from request data.", "response": "def determine_types(self):\n        \"\"\" Determine ES type names from request data.\n\n        In particular `request.matchdict['collections']` is used to\n        determine types names. Its value is comma-separated sequence\n        of collection names under which views have been registered.\n        \"\"\"\n        from nefertari.elasticsearch import ES\n        collections = self.get_collections()\n        resources = self.get_resources(collections)\n        models = set([res.view.Model for res in resources])\n        es_models = [mdl for mdl in models if mdl\n                     and getattr(mdl, '_index_enabled', False)]\n        types = [ES.src2type(mdl.__name__) for mdl in es_models]\n        return types"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_command(domain_name, command_name):\n    def send_command(self, **kwargs):\n        return self.ws.send_message(\n            '{0}.{1}'.format(domain_name, command_name),\n            kwargs\n        )\n\n    return send_command", "response": "Returns a closure function that dispatches a message to the WebSocket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the sha1sum of the file at filepath.", "response": "def path_to_key(filepath):\n        \"\"\"Return the sha1sum (key) belonging to the file at filepath.\"\"\"\n        tmp, last = os.path.split(filepath)\n        tmp, middle = os.path.split(tmp)\n        return '{}{}{}'.format(os.path.basename(tmp), middle,\n                               os.path.splitext(last)[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef key_to_path(self, key):\n        return os.path.join(self.cache_dir, key[:2], key[2:4],\n                            key[4:] + '.pkl')", "response": "Return the fullpath to the file with sha1sum key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noptimizes load and return the parsed version of filename. Uses the on - disk parse cache if the file is located in it.", "response": "def load(self, filename):\n        \"\"\"Optimized load and return the parsed version of filename.\n\n        Uses the on-disk parse cache if the file is located in it.\n\n        \"\"\"\n        # Compute sha1 hash (key)\n        with open(filename) as fp:\n            key = sha1(fp.read()).hexdigest()\n        path = self.key_to_path(key)\n        # Return the cached file if available\n        if key in self.hashes:\n            try:\n                with open(path) as fp:\n                    return cPickle.load(fp)\n            except EOFError:\n                os.unlink(path)\n                self.hashes.remove(key)\n            except IOError:\n                self.hashes.remove(key)\n        # Create the nested cache directory\n        try:\n            os.makedirs(os.path.dirname(path))\n        except OSError as exc:\n            if exc.errno != errno.EEXIST:\n                raise\n        # Process the file and save in the cache\n        scratch = kurt.Project.load(filename)  # can fail\n        with os.fdopen(os.open(path, os.O_WRONLY | os.O_CREAT,\n                               0400), 'w') as fp:\n            # open file for writing but make it immediately read-only\n            cPickle.dump(scratch, fp, cPickle.HIGHEST_PROTOCOL)\n        self.hashes.add(key)\n        return scratch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding filepath to files with the proper extension within paths.", "response": "def hairball_files(self, paths, extensions):\n        \"\"\"Yield filepath to files with the proper extension within paths.\"\"\"\n        def add_file(filename):\n            return os.path.splitext(filename)[1] in extensions\n\n        while paths:\n            arg_path = paths.pop(0)\n            if os.path.isdir(arg_path):\n                found = False\n                for path, dirs, files in os.walk(arg_path):\n                    dirs.sort()  # Traverse in sorted order\n                    for filename in sorted(files):\n                        if add_file(filename):\n                            yield os.path.join(path, filename)\n                            found = True\n                if not found:\n                    if not self.options.quiet:\n                        print('No files found in {}'.format(arg_path))\n            elif add_file(arg_path):\n                yield arg_path\n            elif not self.options.quiet:\n                print('Invalid file {}'.format(arg_path))\n                print('Did you forget to load a Kurt plugin (-k)?')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize_plugins(self):\n        for plugin_name in self.options.plugin:\n            parts = plugin_name.split('.')\n            if len(parts) > 1:\n                module_name = '.'.join(parts[:-1])\n                class_name = parts[-1]\n            else:\n                # Use the titlecase format of the module name as the class name\n                module_name = parts[0]\n                class_name = parts[0].title()\n\n            # First try to load plugins from the passed in plugins_dir and then\n            # from the hairball.plugins package.\n            plugin = None\n            for package in (None, 'hairball.plugins'):\n                if package:\n                    module_name = '{}.{}'.format(package, module_name)\n                try:\n                    module = __import__(module_name, fromlist=[class_name])\n                    # Initializes the plugin by calling its constructor\n                    plugin = getattr(module, class_name)()\n\n                    # Verify plugin is of the correct class\n                    if not isinstance(plugin, HairballPlugin):\n                        sys.stderr.write('Invalid type for plugin {}: {}\\n'\n                                         .format(plugin_name, type(plugin)))\n                        plugin = None\n                    else:\n                        break\n                except (ImportError, AttributeError):\n                    pass\n            if plugin:\n                self.plugins.append(plugin)\n            else:\n                sys.stderr.write('Cannot find plugin {}\\n'.format(plugin_name))\n        if not self.plugins:\n            sys.stderr.write('No plugins loaded. Goodbye!\\n')\n            sys.exit(1)", "response": "Attempt to load and initialize all the plugins."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the analysis across all files found in the given paths.", "response": "def process(self):\n        \"\"\"Run the analysis across all files found in the given paths.\n\n        Each file is loaded once and all plugins are run against it before\n        loading the next file.\n\n        \"\"\"\n        for filename in self.hairball_files(self.paths, self.extensions):\n            if not self.options.quiet:\n                print(filename)\n            try:\n                if self.cache:\n                    scratch = self.cache.load(filename)\n                else:\n                    scratch = kurt.Project.load(filename)\n            except Exception:  # pylint: disable=W0703\n                traceback.print_exc()\n                continue\n            for plugin in self.plugins:\n                # pylint: disable=W0212\n                plugin._process(scratch, filename=filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef maybe_dotted(module, throw=True):\n    try:\n        return Configurator().maybe_dotted(module)\n    except ImportError as e:\n        err = '%s not found. %s' % (module, e)\n        if throw:\n            raise ImportError(err)\n        else:\n            log.error(err)\n            return None", "response": "Returns the module object if it is a dotted string pointing to the module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef issequence(arg):\n    string_behaviour = (\n        isinstance(arg, six.string_types) or\n        isinstance(arg, six.text_type))\n    list_behaviour = hasattr(arg, '__getitem__') or hasattr(arg, '__iter__')\n    return not string_behaviour and list_behaviour", "response": "Return True if arg acts as a list and does not look like a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_dicts(a, b, path=None):\n    if path is None:\n        path = []\n\n    for key in b:\n        if key in a:\n            if isinstance(a[key], dict) and isinstance(b[key], dict):\n                merge_dicts(a[key], b[key], path + [str(key)])\n            elif a[key] == b[key]:\n                pass  # same leaf value\n            else:\n                raise Exception(\n                    'Conflict at %s' % '.'.join(path + [str(key)]))\n        else:\n            a[key] = b[key]\n    return a", "response": "Merge dict b into dict a."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a dotted string to a dict.", "response": "def str2dict(dotted_str, value=None, separator='.'):\n    \"\"\" Convert dotted string to dict splitting by :separator: \"\"\"\n    dict_ = {}\n    parts = dotted_str.split(separator)\n    d, prev = dict_, None\n    for part in parts:\n        prev = d\n        d = d.setdefault(part, {})\n    else:\n        if value is not None:\n            prev[part] = value\n    return dict_"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_data_privacy(request, data, wrapper_kw=None):\n    from nefertari import wrappers\n    if wrapper_kw is None:\n        wrapper_kw = {}\n\n    wrapper = wrappers.apply_privacy(request)\n    allowed_fields = wrapper(result=data, **wrapper_kw).keys()\n    data = data.copy()\n    data.pop('_type', None)\n    not_allowed_fields = set(data.keys()) - set(allowed_fields)\n\n    if not_allowed_fields:\n        raise wrappers.ValidationError(', '.join(not_allowed_fields))", "response": "Validate data for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef drop_reserved_params(params):\n    from nefertari import RESERVED_PARAMS\n    params = params.copy()\n    for reserved_param in RESERVED_PARAMS:\n        if reserved_param in params:\n            params.pop(reserved_param)\n    return params", "response": "Drops reserved params from a list of params."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a command to the TV and return the result.", "response": "def _send_command_raw(self, command, opt=''):\n        \"\"\"\n        Description:\n\n            The TV doesn't handle long running connections very well,\n            so we open a new connection every time.\n            There might be a better way to do this,\n            but it's pretty quick and resilient.\n\n        Returns:\n            If a value is being requested ( opt2 is \"?\" ),\n            then the return value is returned.\n            If a value is being set,\n            it returns True for \"OK\" or False for \"ERR\"\n        \"\"\"\n        # According to the documentation:\n        # http://files.sharpusa.com/Downloads/ForHome/\n        # HomeEntertainment/LCDTVs/Manuals/tel_man_LC40_46_52_60LE830U.pdf\n        # Page 58 - Communication conditions for IP\n        # The connection could be lost (but not only after 3 minutes),\n        # so we need to the remote commands to be sure about states\n        end_time = time.time() + self.timeout\n        while time.time() < end_time:\n            try:\n                # Connect\n                sock_con = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock_con.settimeout(self.connection_timeout)\n                sock_con.connect((self.ip_address, self.port))\n\n                # Authenticate\n                sock_con.send(self.auth)\n                sock_con.recv(1024)\n                sock_con.recv(1024)\n\n                # Send command\n                if opt != '':\n                    command += str(opt)\n                sock_con.send(str.encode(command.ljust(8) + '\\r'))\n                status = bytes.decode(sock_con.recv(1024)).strip()\n            except (OSError, socket.error) as exp:\n                time.sleep(0.1)\n                if time.time() >= end_time:\n                    raise exp\n            else:\n                sock_con.close()\n                # Sometimes the status is empty so\n                # We need to retry\n                if status != u'':\n                    break\n\n        if status == \"OK\":\n            return True\n        elif status == \"ERR\":\n            return False\n        else:\n            try:\n                return int(status)\n            except ValueError:\n                return status"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of information about the TV", "response": "def info(self):\n        \"\"\"\n        Description:\n\n            Returns dict of information about the TV\n            name, model, version\n\n        \"\"\"\n        return {\"name\": self._send_command('name'),\n                \"model\": self._send_command('model'),\n                \"version\": self._send_command('version'),\n                \"ip_version\": self._send_command('ip_version')\n               }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_input_list(self):\n        inputs = [' '] * len(self.command['input'])\n        for key in self.command['input']:\n            inputs[self.command['input'][key]['order']] = {\"key\":key, \"name\":self.command['input'][key]['name']}\n        return inputs", "response": "Returns an ordered list of all available input keys and names\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef input(self, opt):\n\n        for key in self.command['input']:\n            if (key == opt) or (self.command['input'][key]['name'] == opt):\n                return self._send_command(['input', key, 'command'])\n        return False", "response": "This method is used to get the current setting of the input list of the current user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_remote_button_list(self):\n        remote_buttons = []\n        for key in self.command['remote']:\n            if self.command['remote'][key] != '':\n                remote_buttons.append(key)\n        return remote_buttons", "response": "Get remote button list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_results(tmp_):\n        # TODO: Fix this to work with more meaningful names\n        if tmp_['t'] > 0:\n            if tmp_['l'] > 0:\n                if tmp_['rr'] > 0 or tmp_['ra'] > 1:\n                    print 1, 3, tmp_\n                    return 3\n                elif tmp_['cr'] > 0 or tmp_['ca'] > 1:\n                    print 2, 3, tmp_\n                    return 3\n                elif tmp_['mr'] > 0 or tmp_['ma'] > 1:\n                    print 3, 2, tmp_\n                    return 2\n            if tmp_['cr'] > 1 or tmp_['ca'] > 2:\n                print 4, 2, tmp_\n                return 2\n            if tmp_['mr'] > 0 or tmp_['ma'] > 1:\n                if tmp_['cr'] > 0 or tmp_['ca'] > 1:\n                    print 6, 0, tmp_\n                    return 0\n            if tmp_['rr'] > 1 or tmp_['ra'] > 2:\n                print 7, 0, tmp_\n                return 0\n            if tmp_['sr'] > 1 or tmp_['sa'] > 2:\n                print 8, 0, tmp_\n                return 0\n        if tmp_['l'] > 0:\n            if tmp_['rr'] > 0 or tmp_['ra'] > 1:\n                print 9, 2, tmp_\n                return 2\n            if tmp_['cr'] > 0 or tmp_['ca'] > 1:\n                print 10, 0, tmp_\n                return 0\n        return -1", "response": "Return a 3 tuple for something."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_animation(self, last, last_level, gen):\n        tmp_ = Counter()\n        results = Counter()\n        name, level, block = last, last_level, last\n        others = False\n        while name in self.ANIMATION and level >= last_level:\n            if name in self.LOOP:\n                if block != last:\n                    count = self.check_results(tmp_)\n                    if count > -1:\n                        results[count] += 1\n                    tmp_.clear()\n                tmp_['last'] += 1\n\n            for attribute in ('costume', 'orientation', 'position', 'size'):\n                if (name, 'relative') in self.BLOCKMAPPING[attribute]:\n                    tmp_[(attribute, 'relative')] += 1\n                elif (name, 'absolute') in self.BLOCKMAPPING[attribute]:\n                    tmp_[(attribute, 'absolute')] += 1\n            if name in self.TIMING:\n                tmp_['timing'] += 1\n\n            last_level = level\n            name, level, block = next(gen, ('', 0, ''))\n            # allow some exceptions\n            if name not in self.ANIMATION and name != '':\n                if not others:\n                    if block.type.shape != 'stack':\n                        last_level = level\n                        (name, level, block) = next(gen, ('', 0, ''))\n                        others = True\n        count = self.check_results(tmp_)\n        if count > -1:\n            results[count] += 1\n        return gen, results", "response": "Internal helper function to check the animation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef analyze(self, scratch, **kwargs):\n        results = Counter()\n        for script in self.iter_scripts(scratch):\n            gen = self.iter_blocks(script.blocks)\n            name = 'start'\n            level = None\n            while name != '':\n                if name in self.ANIMATION:\n                    gen, count = self._check_animation(name, level, gen)\n                    results.update(count)\n                name, level, _ = next(gen, ('', 0, ''))\n        return {'animation': results}", "response": "Run and return the results from the Animation plugin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of received events contained in script_list.", "response": "def get_receive(self, script_list):\n        \"\"\"Return a list of received events contained in script_list.\"\"\"\n        events = defaultdict(set)\n        for script in script_list:\n            if self.script_start_type(script) == self.HAT_WHEN_I_RECEIVE:\n                event = script.blocks[0].args[0].lower()\n                events[event].add(script)\n        return events"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef analyze(self, scratch, **kwargs):\n        all_scripts = list(self.iter_scripts(scratch))\n        results = defaultdict(set)\n        broadcast = dict((x, self.get_broadcast_events(x))  # Events by script\n                         for x in all_scripts)\n        correct = self.get_receive(all_scripts)\n        results['never broadcast'] = set(correct.keys())\n\n        for script, events in broadcast.items():\n            for event in events.keys():\n                if event is True:  # Remove dynamic broadcasts\n                    results['dynamic broadcast'].add(script.morph.name)\n                    del events[event]\n                elif event in correct:\n                    results['never broadcast'].discard(event)\n                else:\n                    results['never received'].add(event)\n\n        # remove events from correct dict that were never broadcast\n        for event in correct.keys():\n            if event in results['never broadcast']:\n                del correct[event]\n\n        # Find scripts that have more than one broadcast event on any possible\n        # execution path through the program\n        # TODO: Permit mutually exclusive broadcasts\n        for events in broadcast.values():\n            if len(events) > 1:\n                for event in events:\n                    if event in correct:\n                        results['parallel broadcasts'].add(event)\n                        del correct[event]\n\n        # Find events that have two (or more) receivers in which one of the\n        # receivers has a \"delay\" block\n        for event, scripts in correct.items():\n            if len(scripts) > 1:\n                for script in scripts:\n                    for _, _, block in self.iter_blocks(script.blocks):\n                        if block.type.shape == 'stack':\n                            results['multiple receivers with delay'].add(event)\n                            if event in correct:\n                                del correct[event]\n\n        results['success'] = set(correct.keys())\n        return {'broadcast': results}", "response": "Run and return the results from the BroadcastReceive plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nanalyzes the Sound Manager and return a dictionary of the number of errors that occurred.", "response": "def analyze(self, scratch, **kwargs):\n        \"\"\"Categorize instances of attempted say and sound synchronization.\"\"\"\n        errors = Counter()\n        for script in self.iter_scripts(scratch):\n            prev_name, prev_depth, prev_block = '', 0, script.blocks[0]\n            gen = self.iter_blocks(script.blocks)\n            for name, depth, block in gen:\n                if prev_depth == depth:\n                    if prev_name in self.SAY_THINK:\n                        if name == 'play sound %s until done':\n                            if not self.is_blank(prev_block.args[0]):\n                                errors += self.check(gen)\n                        # TODO: What about play sound?\n                    elif prev_name in self.SAY_THINK_DURATION and \\\n                            'play sound %s' in name:\n                        errors['1'] += 1\n                    elif prev_name == 'play sound %s':\n                        if name in self.SAY_THINK:\n                            errors[self.INCORRECT] += 1\n                        elif name in self.SAY_THINK_DURATION:\n                            if self.is_blank(block.args[0]):\n                                errors[self.ERROR] += 1\n                            else:\n                                errors[self.HACKISH] += 1\n                    elif prev_name == 'play sound %s until done' and \\\n                            name in self.ALL_SAY_THINK:\n                        if not self.is_blank(block.args[0]):\n                            errors[self.INCORRECT] += 1\n                        # TODO: Should there be an else clause here?\n                prev_name, prev_depth, prev_block = name, depth, block\n        return {'sound': errors}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check(self, gen):\n        retval = Counter()\n        name, _, block = next(gen, ('', 0, ''))\n        if name in self.SAY_THINK:\n            if self.is_blank(block.args[0]):\n                retval[self.CORRECT] += 1\n            else:\n                name, _, block = next(gen, ('', 0, ''))\n                if name == 'play sound %s until done':\n                    # Increment the correct count because we have at least\n                    # one successful instance\n                    retval[self.CORRECT] += 1\n                    # This block represents the beginning of a second\n                    retval += self.check(gen)\n                else:\n                    retval[self.INCORRECT] += 1\n        else:\n            retval[self.INCORRECT] += 1\n        return retval", "response": "Check that the last part of the chain matches."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a sys. exc_info() - style tuple of values into a string.", "response": "def _format_exception(err, is_failure, stdout=None, stderr=None):\n    \"\"\"Converts a sys.exc_info()-style tuple of values into a string.\"\"\"\n    exctype, value, tb = err\n    # Skip test runner traceback levels\n    while tb and _is_relevant_tb_level(tb):\n        tb = tb.tb_next\n\n    if is_failure:\n        # Skip assert*() traceback levels\n        length = _count_relevant_tb_levels(tb)\n        msgLines = traceback.format_exception(exctype, value, tb, length)\n    else:\n        msgLines = traceback.format_exception(exctype, value, tb)\n\n    encoding = locale.getpreferredencoding()\n    msgLines = [_decode(line, encoding) for line in msgLines]\n\n    if stdout:\n        if not stdout.endswith('\\n'):\n            stdout += '\\n'\n        msgLines.append(STDOUT_LINE % stdout)\n    if stderr:\n        if not stderr.endswith('\\n'):\n            stderr += '\\n'\n        msgLines.append(STDERR_LINE % stderr)\n    return ''.join(msgLines)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhooking stdout and stderr if buffering is enabled.", "response": "def _setup_stdout(self):\n        \"\"\"Hook stdout and stderr if buffering is enabled.\n\n        \"\"\"\n        if self.buffer:\n            if self._stderr_buffer is None:\n                self._stderr_buffer = StringIO()\n                self._stdout_buffer = StringIO()\n            sys.stdout = self._stdout_buffer\n            sys.stderr = self._stderr_buffer"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunhook stdout and stderr if buffering is enabled.", "response": "def _restore_stdout(self):\n        \"\"\"Unhook stdout and stderr if buffering is enabled.\n\n        \"\"\"\n        if self.buffer:\n            if self._mirror_output:\n                output = sys.stdout.getvalue()\n                error = sys.stderr.getvalue()\n                if output:\n                    if not output.endswith('\\n'):\n                        output += '\\n'\n                    self._original_stdout.write(STDOUT_LINE % output)\n                if error:\n                    if not error.endswith('\\n'):\n                        error += '\\n'\n                    self._original_stderr.write(STDERR_LINE % error)\n\n            sys.stdout = self._original_stdout\n            sys.stderr = self._original_stderr\n            self._stdout_buffer.seek(0)\n            self._stdout_buffer.truncate()\n            self._stderr_buffer.seek(0)\n            self._stderr_buffer.truncate()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a new result handler.", "response": "def add_result_handler(self, handler):\n        \"\"\"Register a new result handler.\n\n        \"\"\"\n        self._result_handlers.append(handler)\n        # Reset sorted handlers\n        if self._sorted_handlers:\n            self._sorted_handlers = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_result(self, result):\n        for handler in self._handlers:\n            handler(result)\n        if self._successful and result.status not in _successful_results:\n            self._successful = False", "response": "Add an already - constructed result to this result collector."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_result(self, test, status, exception=None, message=None):\n        if self.buffer:\n            stderr = self._stderr_buffer.getvalue()\n            stdout = self._stdout_buffer.getvalue()\n        else:\n            stderr = stdout = None\n\n        started_time = self._test_timing.get(self._testcase_to_key(test))\n        if started_time is None and isinstance(test, ErrorHolder):\n            started_time = datetime.utcnow()\n        elif started_time is None:\n            raise RuntimeError(\n                'Missing test start! Please report this error as a bug in '\n                'haas.')\n\n        completion_time = datetime.utcnow()\n        duration = TestDuration(started_time, completion_time)\n        result = TestResult.from_test_case(\n            test,\n            status,\n            duration=duration,\n            exception=exception,\n            message=message,\n            stdout=stdout,\n            stderr=stderr,\n        )\n        self.add_result(result)\n        return result", "response": "Handles the result of a test."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister that a test ended in an error.", "response": "def addError(self, test, exception):\n        \"\"\"Register that a test ended in an error.\n\n        Parameters\n        ----------\n        test : unittest.TestCase\n            The test that has completed.\n        exception : tuple\n            ``exc_info`` tuple ``(type, value, traceback)``.\n\n        \"\"\"\n        result = self._handle_result(\n            test, TestCompletionStatus.error, exception=exception)\n        self.errors.append(result)\n        self._mirror_output = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addFailure(self, test, exception):\n        result = self._handle_result(\n            test, TestCompletionStatus.failure, exception=exception)\n        self.failures.append(result)\n        self._mirror_output = True", "response": "Register that a test ended with a failure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister that a test that has completed and was skipped.", "response": "def addSkip(self, test, reason):\n        \"\"\"Register that a test that was skipped.\n\n        Parameters\n        ----------\n        test : unittest.TestCase\n            The test that has completed.\n        reason : str\n            The reason the test was skipped.\n\n        \"\"\"\n        result = self._handle_result(\n            test, TestCompletionStatus.skipped, message=reason)\n        self.skipped.append(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addExpectedFailure(self, test, exception):\n        result = self._handle_result(\n            test, TestCompletionStatus.expected_failure, exception=exception)\n        self.expectedFailures.append(result)", "response": "Register that a test that failed and was expected to fail."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addUnexpectedSuccess(self, test):\n        result = self._handle_result(\n            test, TestCompletionStatus.unexpected_success)\n        self.unexpectedSuccesses.append(result)", "response": "Register a test that passed unexpectedly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_terminal_key(self, encrypted_key):\n        if encrypted_key:\n            try:\n                new_key = bytes.fromhex(encrypted_key)\n                if len(self.terminal_key) != len(new_key):\n                    # The keys must have equal length\n                    return False\n\n                self.terminal_key = self.tmk_cipher.decrypt(new_key)\n                self.store_terminal_key(raw2str(self.terminal_key))\n\n                self.tpk_cipher = DES3.new(self.terminal_key, DES3.MODE_ECB)\n                self.print_keys()\n                return True\n\n            except ValueError:\n                return False\n\n        return False", "response": "Change the terminal key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_encrypted_pin(self, clear_pin, card_number):\n        if not self.terminal_key:\n            print('Terminal key is not set')\n            return ''\n\n        if self.pinblock_format == '01':\n            try:\n                pinblock = bytes.fromhex(get_pinblock(clear_pin, card_number))\n                #print('PIN block: {}'.format(raw2str(pinblock)))\n            except TypeError:\n                return ''\n\n            encrypted_pinblock = self.tpk_cipher.encrypt(pinblock)\n            return raw2str(encrypted_pinblock)\n\n        else:\n            print('Unsupported PIN Block format')\n            return ''", "response": "Get PIN block in ISO 0 format encrypted with the terminal key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_url(string, allowed_schemes=None):\n    if not is_full_string(string):\n        return False\n    valid = bool(URL_RE.search(string))\n    if allowed_schemes:\n        return valid and any([string.startswith(s) for s in allowed_schemes])\n    return valid", "response": "Check if a string is a valid url."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_credit_card(string, card_type=None):\n    if not is_full_string(string):\n        return False\n    if card_type:\n        if card_type not in CREDIT_CARDS:\n            raise KeyError(\n                'Invalid card type \"{}\". Valid types are: {}'.format(card_type, ', '.join(CREDIT_CARDS.keys()))\n            )\n        return bool(CREDIT_CARDS[card_type].search(string))\n    for c in CREDIT_CARDS:\n        if CREDIT_CARDS[c].search(string):\n            return True\n    return False", "response": "Checks if a string is a valid credit card number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a string is formatted as snake case.", "response": "def is_snake_case(string, separator='_'):\n    \"\"\"\n    Checks if a string is formatted as snake case.\n    A string is considered snake case when:\n\n    * it's composed only by lowercase letters ([a-z]), underscores (or provided separator) \\\n    and optionally numbers ([0-9])\n    * it does not start/end with an underscore (or provided separator)\n    * it does not start with a number\n\n\n    :param string: String to test.\n    :type string: str\n    :param separator: String to use as separator.\n    :type separator: str\n    :return: True for a snake case string, false otherwise.\n    :rtype: bool\n    \"\"\"\n    if is_full_string(string):\n        re_map = {\n            '_': SNAKE_CASE_TEST_RE,\n            '-': SNAKE_CASE_TEST_DASH_RE\n        }\n        re_template = '^[a-z]+([a-z\\d]+{sign}|{sign}[a-z\\d]+)+[a-z\\d]+$'\n        r = re_map.get(separator, re.compile(re_template.format(sign=re.escape(separator))))\n        return bool(r.search(string))\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a string is a valid json.", "response": "def is_json(string):\n    \"\"\"\n    Check if a string is a valid json.\n\n    :param string: String to check.\n    :type string: str\n    :return: True if json, false otherwise\n    :rtype: bool\n    \"\"\"\n    if not is_full_string(string):\n        return False\n    if bool(JSON_WRAPPER_RE.search(string)):\n        try:\n            return isinstance(json.loads(string), dict)\n        except (TypeError, ValueError, OverflowError):\n            return False\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the string is a palindrome.", "response": "def is_palindrome(string, strict=True):\n    \"\"\"\n    Checks if the string is a palindrome (https://en.wikipedia.org/wiki/Palindrome).\n\n    :param string: String to check.\n    :type string: str\n    :param strict: True if white spaces matter (default), false otherwise.\n    :type strict: bool\n    :return: True if the string is a palindrome (like \"otto\", or \"i topi non avevano nipoti\" if strict=False),\n    False otherwise\n    \"\"\"\n    if is_full_string(string):\n        if strict:\n            return reverse(string) == string\n        return is_palindrome(SPACES_RE.sub('', string))\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the string is a pangram.", "response": "def is_pangram(string):\n    \"\"\"\n    Checks if the string is a pangram (https://en.wikipedia.org/wiki/Pangram).\n\n    :param string: String to check.\n    :type string: str\n    :return: True if the string is a pangram, False otherwise.\n    \"\"\"\n    return is_full_string(string) and set(SPACES_RE.sub('', string)).issuperset(letters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a given string is a slug.", "response": "def is_slug(string, sign='-'):\n    \"\"\"\n    Checks if a given string is a slug.\n\n    :param string: String to check.\n    :type string: str\n    :param sign: Join sign used by the slug.\n    :type sign: str\n    :return: True if slug, false otherwise.\n    \"\"\"\n    if not is_full_string(string):\n        return False\n    rex = r'^([a-z\\d]+' + re.escape(sign) + r'?)*[a-z\\d]$'\n    return re.match(rex, string) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef camel_case_to_snake(string, separator='_'):\n    if not is_string(string):\n        raise TypeError('Expected string')\n    if not is_camel_case(string):\n        return string\n    return CAMEL_CASE_REPLACE_RE.sub(lambda m: m.group(1) + separator, string).lower()", "response": "Converts a camel case string into a snake case string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a snake case string into a camel case string.", "response": "def snake_case_to_camel(string, upper_case_first=True, separator='_'):\n    \"\"\"\n    Convert a snake case string into a camel case one.\n    (The original string is returned if is not a valid snake case string)\n\n    :param string: String to convert.\n    :type string: str\n    :param upper_case_first: True to turn the first letter into uppercase (default).\n    :type upper_case_first: bool\n    :param separator: Sign to use as separator (default to \"_\").\n    :type separator: str\n    :return: Converted string\n    :rtype: str\n    \"\"\"\n    if not is_string(string):\n        raise TypeError('Expected string')\n    if not is_snake_case(string, separator):\n        return string\n    re_map = {\n        '_': SNAKE_CASE_REPLACE_RE,\n        '-': SNAKE_CASE_REPLACE_DASH_RE\n    }\n    r = re_map.get(separator, re.compile('({sign})([a-z\\d])'.format(sign=re.escape(separator))))\n    string = r.sub(lambda m: m.group(2).upper(), string)\n    if upper_case_first:\n        return string[0].upper() + string[1:]\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shuffle(string):\n    s = sorted(string)  # turn the string into a list of chars\n    random.shuffle(s)  # shuffle the list\n    return ''.join(s)", "response": "Return a new string containing shuffled items.\n\n    :param string: String to shuffle\n    :type string: str\n    :return: Shuffled string\n    :rtype: str"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove html code contained in the given string.", "response": "def strip_html(string, keep_tag_content=False):\n    \"\"\"\n    Remove html code contained into the given string.\n\n    :param string: String to manipulate.\n    :type string: str\n    :param keep_tag_content: True to preserve tag content, False to remove tag and its content too (default).\n    :type keep_tag_content: bool\n    :return: String with html removed.\n    :rtype: str\n    \"\"\"\n    r = HTML_TAG_ONLY_RE if keep_tag_content else HTML_RE\n    return r.sub('', string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an ugly text string into a beautiful one by applying a regex pipeline to ensure that the string is well - formed and that the string is not too long.", "response": "def prettify(string):\n    \"\"\"\n    Turns an ugly text string into a beautiful one by applying a regex pipeline which ensures the following:\n\n    - String cannot start or end with spaces\n    - String cannot have multiple sequential spaces, empty lines or punctuation (except for \"?\", \"!\" and \".\")\n    - Arithmetic operators (+, -, /, \\*, =) must have one, and only one space before and after themselves\n    - The first letter after a dot, an exclamation or a question mark must be uppercase\n    - One, and only one space should follow a dot, an exclamation or a question mark\n    - Text inside double quotes cannot start or end with spaces, but one, and only one space must come first and \\\n    after quotes (foo\" bar\"baz -> foo \"bar\" baz)\n    - Text inside round brackets cannot start or end with spaces, but one, and only one space must come first and \\\n    after brackets (\"foo(bar )baz\" -> \"foo (bar) baz\")\n    - Percentage sign (\"%\") cannot be preceded by a space if there is a number before (\"100 %\" -> \"100%\")\n    - Saxon genitive is correct (\"Dave' s dog\" -> \"Dave's dog\")\n\n\n    :param string: String to manipulate\n    :return: Prettified string.\n    :rtype: str\n    \"\"\"\n\n    def remove_duplicates(regex_match):\n        return regex_match.group(1)[0]\n\n    def uppercase_first_letter_after_sign(regex_match):\n        match = regex_match.group(1)\n        return match[:-1] + match[2].upper()\n\n    def ensure_right_space_only(regex_match):\n        return regex_match.group(1).strip() + ' '\n\n    def ensure_left_space_only(regex_match):\n        return ' ' + regex_match.group(1).strip()\n\n    def ensure_spaces_around(regex_match):\n        return ' ' + regex_match.group(1).strip() + ' '\n\n    def remove_internal_spaces(regex_match):\n        return regex_match.group(1).strip()\n\n    def fix_saxon_genitive(regex_match):\n        return regex_match.group(1).replace(' ', '') + ' '\n\n    p = PRETTIFY_RE['DUPLICATES'].sub(remove_duplicates, string)\n    p = PRETTIFY_RE['RIGHT_SPACE'].sub(ensure_right_space_only, p)\n    p = PRETTIFY_RE['LEFT_SPACE'].sub(ensure_left_space_only, p)\n    p = PRETTIFY_RE['SPACES_AROUND'].sub(ensure_spaces_around, p)\n    p = PRETTIFY_RE['SPACES_INSIDE'].sub(remove_internal_spaces, p)\n    p = PRETTIFY_RE['UPPERCASE_AFTER_SIGN'].sub(uppercase_first_letter_after_sign, p)\n    p = PRETTIFY_RE['SAXON_GENITIVE'].sub(fix_saxon_genitive, p)\n    p = p.strip()\n    try:\n        return p[0].capitalize() + p[1:]\n    except IndexError:\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a string into a slug using provided join sign.", "response": "def slugify(string, sign='-'):\n    \"\"\"\n    Converts a string into a slug using provided join sign.\n    (**(This Is A \"Test\"!)** -> **this-is-a-test**)\n\n    :param string: String to convert.\n    :type string: str\n    :param sign: Sign used to join string tokens (default to \"-\").\n    :type sign: str\n    :return: Slugified string\n    \"\"\"\n    if not is_string(string):\n        raise TypeError('Expected string')\n\n    # unicode casting for python 2 (unicode is default for python 3)\n    try:\n        string = unicode(string, 'utf-8')\n    except NameError:\n        pass\n\n    # replace any character that is NOT letter or number with spaces\n    s = NO_LETTERS_OR_NUMBERS_RE.sub(' ', string.lower()).strip()\n\n    # replace spaces with join sign\n    s = SPACES_RE.sub(sign, s)\n\n    # normalize joins (remove duplicates)\n    s = re.sub(re.escape(sign) + r'+', sign, s)\n\n    # translate non-ascii signs\n    s = unicodedata.normalize('NFD', s).encode('ascii', 'ignore').decode('utf-8')\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, inputstring, document):\n        link = json.loads(inputstring)\n        env = document.settings.env\n        source_dir = os.path.dirname(env.doc2path(env.docname))\n\n        abs_path = os.path.normpath(os.path.join(source_dir, link['path']))\n        path = utils.relative_path(None, abs_path)\n        path = nodes.reprunicode(path)\n\n        document.settings.record_dependencies.add(path)\n        env.note_dependency(path)\n\n        target_root = env.config.nbsphinx_link_target_root\n        target = utils.relative_path(target_root, abs_path)\n        target = nodes.reprunicode(target).replace(os.path.sep, '/')\n        env.metadata[env.docname]['nbsphinx-link-target'] = target\n\n        # Copy parser from nbsphinx for our cutom format\n        try:\n            formats = env.config.nbsphinx_custom_formats\n        except AttributeError:\n            pass\n        else:\n            formats.setdefault(\n                '.nblink',\n                lambda s: nbformat.reads(s, as_version=_ipynbversion))\n\n        try:\n            include_file = io.FileInput(source_path=path, encoding='utf8')\n        except UnicodeEncodeError as error:\n            raise NotebookError(u'Problems with linked notebook \"%s\" path:\\n'\n                                'Cannot encode input file path \"%s\" '\n                                '(wrong locale?).' %\n                                (env.docname, SafeString(path)))\n        except IOError as error:\n            raise NotebookError(u'Problems with linked notebook \"%s\" path:\\n%s.' %\n                                (env.docname, ErrorString(error)))\n\n        try:\n            rawtext = include_file.read()\n        except UnicodeError as error:\n            raise NotebookError(u'Problem with linked notebook \"%s\":\\n%s' %\n                                (env.docname, ErrorString(error)))\n        return super(LinkedNotebookParser, self).parse(rawtext, document)", "response": "Parse the nblink file and add it to the notebook s record_dependencies and add the file as a dependency read the file and pass the content to the notebook parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finalize(self):\n        if self.total_duplicate > 0:\n            print('{} duplicate scripts found'.format(self.total_duplicate))\n            for duplicate in self.list_duplicate:\n                print(duplicate)", "response": "Output the duplicate scripts detected."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, scratch, **kwargs):\n        scripts_set = set()\n        for script in self.iter_scripts(scratch):\n            if script[0].type.text == 'define %s':\n                continue  # Ignore user defined scripts\n            blocks_list = []\n            for name, _, _ in self.iter_blocks(script.blocks):\n                blocks_list.append(name)\n            blocks_tuple = tuple(blocks_list)\n            if blocks_tuple in scripts_set:\n                if len(blocks_list) > 3:\n                    self.total_duplicate += 1\n                    self.list_duplicate.append(blocks_list)\n            else:\n                scripts_set.add(blocks_tuple)", "response": "Run and return the results from the DuplicateScripts plugin."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_content_type(self, system):\n        request = system.get('request')\n        if request:\n            response = request.response\n            ct = response.content_type\n            if ct == response.default_content_type:\n                response.content_type = 'application/json'", "response": "Set response content type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering a response from a dictionary.", "response": "def _render_response(self, value, system):\n        \"\"\" Render a response \"\"\"\n        view = system['view']\n        enc_class = getattr(view, '_json_encoder', None)\n        if enc_class is None:\n            enc_class = get_json_encoder()\n        return json.dumps(value, cls=enc_class)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting kwargs common for all methods.", "response": "def _get_common_kwargs(self, system):\n        \"\"\" Get kwargs common for all methods. \"\"\"\n        enc_class = getattr(system['view'], '_json_encoder', None)\n        if enc_class is None:\n            enc_class = get_json_encoder()\n        return {\n            'request': system['request'],\n            'encoder': enc_class,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting kwargs common to create update replace.", "response": "def _get_create_update_kwargs(self, value, common_kw):\n        \"\"\" Get kwargs common to create, update, replace. \"\"\"\n        kw = common_kw.copy()\n        kw['body'] = value\n        if '_self' in value:\n            kw['headers'] = [('Location', value['_self'])]\n        return kw"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_create(self, value, system, common_kw):\n        kw = self._get_create_update_kwargs(value, common_kw)\n        return JHTTPCreated(**kw)", "response": "Render response for view create method"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender response for view update method", "response": "def render_update(self, value, system, common_kw):\n        \"\"\" Render response for view `update` method (item PATCH) \"\"\"\n        kw = self._get_create_update_kwargs(value, common_kw)\n        return JHTTPOk('Updated', **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering response for view DELETE method", "response": "def render_delete_many(self, value, system, common_kw):\n        \"\"\" Render response for view `delete_many` method (collection DELETE)\n        \"\"\"\n        if isinstance(value, dict):\n            return JHTTPOk(extra=value)\n        msg = 'Deleted {} {}(s) objects'.format(\n            value, system['view'].Model.__name__)\n        return JHTTPOk(msg, **common_kw.copy())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_update_many(self, value, system, common_kw):\n        msg = 'Updated {} {}(s) objects'.format(\n            value, system['view'].Model.__name__)\n        return JHTTPOk(msg, **common_kw.copy())", "response": "Render response for view update_many method"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _render_response(self, value, system):\n        super_call = super(DefaultResponseRendererMixin, self)._render_response\n        try:\n            method_name = 'render_{}'.format(system['request'].action)\n        except (KeyError, AttributeError):\n            return super_call(value, system)\n        method = getattr(self, method_name, None)\n        if method is not None:\n            common_kw = self._get_common_kwargs(system)\n            response = method(value, system, common_kw)\n            system['request'].response = response\n            return\n        return super_call(value, system)", "response": "Handle response rendering.\n\n        Calls mixin methods according to request.action value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of headers that should be used in the Authorization header.", "response": "def remember(self, request, username, **kw):\n        \"\"\" Returns 'WWW-Authenticate' header with a value that should be used\n        in 'Authorization' header.\n        \"\"\"\n        if self.credentials_callback:\n            token = self.credentials_callback(username, request)\n            api_key = 'ApiKey {}:{}'.format(username, token)\n            return [('WWW-Authenticate', api_key)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef callback(self, username, request):\n        credentials = self._get_credentials(request)\n        if credentials:\n            username, api_key = credentials\n            if self.check:\n                return self.check(username, api_key, request)", "response": "Callback function for user s check method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract username and api key from Authorization header", "response": "def _get_credentials(self, request):\n        \"\"\" Extract username and api key token from 'Authorization' header \"\"\"\n        authorization = request.headers.get('Authorization')\n        if not authorization:\n            return None\n        try:\n            authmeth, authbytes = authorization.split(' ', 1)\n        except ValueError:  # not enough values to unpack\n            return None\n        if authmeth.lower() != 'apikey':\n            return None\n\n        if six.PY2 or isinstance(authbytes, bytes):\n            try:\n                auth = authbytes.decode('utf-8')\n            except UnicodeDecodeError:\n                auth = authbytes.decode('latin-1')\n        else:\n            auth = authbytes\n\n        try:\n            username, api_key = auth.split(':', 1)\n        except ValueError:  # not enough values to unpack\n            return None\n        return username, api_key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_event_kwargs(view_obj):\n    request = view_obj.request\n\n    view_method = getattr(view_obj, request.action)\n    do_trigger = not (\n        getattr(view_method, '_silent', False) or\n        getattr(view_obj, '_silent', False))\n\n    if do_trigger:\n        event_kwargs = {\n            'view': view_obj,\n            'model': view_obj.Model,\n            'fields': FieldData.from_dict(\n                view_obj._json_params,\n                view_obj.Model)\n        }\n        ctx = view_obj.context\n        if hasattr(ctx, 'pk_field') or isinstance(ctx, DataProxy):\n            event_kwargs['instance'] = ctx\n        return event_kwargs", "response": "Helper function to get event kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _trigger_events(view_obj, events_map, additional_kw=None):\n    if additional_kw is None:\n        additional_kw = {}\n\n    event_kwargs = _get_event_kwargs(view_obj)\n    if event_kwargs is None:\n        return\n\n    event_kwargs.update(additional_kw)\n    event_cls = _get_event_cls(view_obj, events_map)\n    event = event_cls(**event_kwargs)\n    view_obj.request.registry.notify(event)\n    return event", "response": "Common logic to trigger before and after events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubscribing to events in a Pyramid contig.", "response": "def subscribe_to_events(config, subscriber, events, model=None):\n    \"\"\" Helper function to subscribe to group of events.\n\n    :param config: Pyramid contig instance.\n    :param subscriber: Event subscriber function.\n    :param events: Sequence of events to subscribe to.\n    :param model: Model predicate value.\n    \"\"\"\n    kwargs = {}\n    if model is not None:\n        kwargs['model'] = model\n\n    for evt in events:\n        config.add_subscriber(subscriber, evt, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_field_processors(config, processors, model, field):\n    before_change_events = (\n        BeforeCreate,\n        BeforeUpdate,\n        BeforeReplace,\n        BeforeUpdateMany,\n        BeforeRegister,\n    )\n\n    def wrapper(event, _processors=processors, _field=field):\n        proc_kw = {\n            'new_value': event.field.new_value,\n            'instance': event.instance,\n            'field': event.field,\n            'request': event.view.request,\n            'model': event.model,\n            'event': event,\n        }\n        for proc_func in _processors:\n            proc_kw['new_value'] = proc_func(**proc_kw)\n\n        event.field.new_value = proc_kw['new_value']\n        event.set_field_value(_field, proc_kw['new_value'])\n\n    for evt in before_change_events:\n        config.add_subscriber(wrapper, evt, model=model, field=field)", "response": "Add processors for model field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets value of request field named field_name.", "response": "def set_field_value(self, field_name, value):\n        \"\"\" Set value of request field named `field_name`.\n\n        Use this method to apply changes to object which is affected\n        by request. Values are set on `view._json_params` dict.\n\n        If `field_name` is not affected by request, it is added to\n        `self.fields` which makes field processors which are connected\n        to `field_name` to be triggered, if they are run after this\n        method call(connected to events after handler that performs\n        method call).\n\n        :param field_name: Name of request field value of which should\n            be set.\n        :param value: Value to be set.\n        \"\"\"\n        self.view._json_params[field_name] = value\n        if field_name in self.fields:\n            self.fields[field_name].new_value = value\n            return\n\n        fields = FieldData.from_dict({field_name: value}, self.model)\n        self.fields.update(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets value of response field named field_name to value.", "response": "def set_field_value(self, field_name, value):\n        \"\"\" Set value of response field named `field_name`.\n\n        If response contains single item, its field is set.\n        If response contains multiple items, all the items in response\n        are edited.\n        To edit response meta(e.g. 'count') edit response directly at\n        `event.response`.\n\n        :param field_name: Name of response field value of which should\n            be set.\n        :param value: Value to be set.\n        \"\"\"\n        if self.response is None:\n            return\n\n        if 'data' in self.response:\n            items = self.response['data']\n        else:\n            items = [self.response]\n\n        for item in items:\n            item[field_name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_fields_param(fields):\n    if not fields:\n        return fields\n    if isinstance(fields, six.string_types):\n        fields = split_strip(fields)\n    if '_type' not in fields:\n        fields.append('_type')\n    return {\n        '_source_include': fields,\n        '_source': True,\n    }", "response": "Process 'fields' ES param.\n\n    * Fields list is split if needed\n    * '_type' field is added, if not present, so the actual value is\n      displayed instead of 'None'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncatches and raise index errors which are not critical and thus not raised by elasticsearch - py.", "response": "def _catch_index_error(self, response):\n        \"\"\" Catch and raise index errors which are not critical and thus\n        not raised by elasticsearch-py.\n        \"\"\"\n        code, headers, raw_data = response\n        if not raw_data:\n            return\n        data = json.loads(raw_data)\n        if not data or not data.get('errors'):\n            return\n        try:\n            error_dict = data['items'][0]['index']\n            message = error_dict['error']\n        except (KeyError, IndexError):\n            return\n        raise exception_response(400, detail=message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_chunks(self, documents, operation):\n        chunk_size = self.chunk_size\n        start = end = 0\n        count = len(documents)\n\n        while count:\n            if count < chunk_size:\n                chunk_size = count\n            end += chunk_size\n\n            bulk = documents[start:end]\n            operation(documents_actions=bulk)\n\n            start += chunk_size\n            count -= chunk_size", "response": "Process the bulk of the items in the document list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index_missing_documents(self, documents, request=None):\n        log.info('Trying to index documents of type `{}` missing from '\n                 '`{}` index'.format(self.doc_type, self.index_name))\n        if not documents:\n            log.info('No documents to index')\n            return\n        query_kwargs = dict(\n            index=self.index_name,\n            doc_type=self.doc_type,\n            fields=['_id'],\n            body={'ids': [d['_pk'] for d in documents]},\n        )\n        try:\n            response = self.api.mget(**query_kwargs)\n        except IndexNotFoundException:\n            indexed_ids = set()\n        else:\n            indexed_ids = set(\n                d['_id'] for d in response['docs'] if d.get('found'))\n        documents = [d for d in documents if str(d['_pk']) not in indexed_ids]\n\n        if not documents:\n            log.info('No documents of type `{}` are missing from '\n                     'index `{}`'.format(self.doc_type, self.index_name))\n            return\n\n        self._bulk('index', documents, request)", "response": "Index missing documents from ES index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aggregate(self, **params):\n        _aggregations_params = params.pop('_aggregations_params', None)\n        _raise_on_empty = params.pop('_raise_on_empty', False)\n\n        if not _aggregations_params:\n            raise Exception('Missing _aggregations_params')\n\n        # Set limit so ES won't complain. It is ignored in the end\n        params['_limit'] = 0\n        search_params = self.build_search_params(params)\n        search_params.pop('size', None)\n        search_params.pop('from_', None)\n        search_params.pop('sort', None)\n\n        search_params['body']['aggregations'] = _aggregations_params\n\n        log.debug('Performing aggregation: {}'.format(_aggregations_params))\n        try:\n            response = self.api.search(**search_params)\n        except IndexNotFoundException:\n            if _raise_on_empty:\n                raise JHTTPNotFound(\n                    'Aggregation failed: Index does not exist')\n            return {}\n\n        try:\n            return response['aggregations']\n        except KeyError:\n            raise JHTTPNotFound('No aggregations returned from ES')", "response": "Perform an aggregation on the anatomical cache entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bulk_index_relations(cls, items, request=None, **kwargs):\n        index_map = defaultdict(set)\n        for item in items:\n            relations = item.get_related_documents(**kwargs)\n            for model_cls, related_items in relations:\n                indexable = getattr(model_cls, '_index_enabled', False)\n                if indexable and related_items:\n                    index_map[model_cls.__name__].update(related_items)\n\n        for model_name, instances in index_map.items():\n            cls(model_name).index(to_dicts(instances), request=request)", "response": "Index objects related to items in bulk."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_version(path=\"src/devpy/__init__.py\"):\n    init_content = open(path, \"rt\").read()\n    pattern = r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\"\n    return re.search(pattern, init_content, re.M).group(1)", "response": "Return the version of by with regex intead of importing it"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding plugin arguments to argument parser.", "response": "def add_plugin_arguments(self, parser):\n        \"\"\"Add plugin arguments to argument parser.\n\n        Parameters\n        ----------\n        parser : argparse.ArgumentParser\n            The main haas ArgumentParser.\n\n        \"\"\"\n        for manager in self.hook_managers.values():\n            if len(list(manager)) == 0:\n                continue\n            manager.map(self._add_hook_extension_arguments, parser)\n        for namespace, manager in self.driver_managers.items():\n            choices = list(sorted(manager.names()))\n            if len(choices) == 0:\n                continue\n            option, dest = self._namespace_to_option(namespace)\n            parser.add_argument(\n                option, help=self._help[namespace], dest=dest,\n                choices=choices, default='default')\n            option_prefix = '{0}-'.format(option)\n            dest_prefix = '{0}_'.format(dest)\n            manager.map(self._add_driver_extension_arguments,\n                        parser, option_prefix, dest_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_enabled_hook_plugins(self, hook, args, **kwargs):\n        manager = self.hook_managers[hook]\n        if len(list(manager)) == 0:\n            return []\n        return [\n            plugin for plugin in manager.map(\n                self._create_hook_plugin, args, **kwargs)\n            if plugin is not None\n        ]", "response": "Get enabled plugins for the specified hook name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets mutually - exlusive plugin for plugin namespace.", "response": "def get_driver(self, namespace, parsed_args, **kwargs):\n        \"\"\"Get mutually-exlusive plugin for plugin namespace.\n\n        \"\"\"\n        option, dest = self._namespace_to_option(namespace)\n        dest_prefix = '{0}_'.format(dest)\n        driver_name = getattr(parsed_args, dest, 'default')\n        driver_extension = self.driver_managers[namespace][driver_name]\n        return driver_extension.plugin.from_args(\n            parsed_args, dest_prefix, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting transaction description (for logging purposes)", "response": "def get_description(self):\n        \"\"\"\n        Get transaction description (for logging purposes)\n        \"\"\"\n        if self.card:\n            card_description = self.card.get_description()\n        else:\n            card_description = 'Cardless'\n\n        if card_description:\n            card_description += ' | '\n\n        return card_description + self.description if self.description else card_description + self.type + ' ' + str(self.IsoMessage.FieldData(11))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting amount of data to be sent to the ISO.", "response": "def set_amount(self, amount):\n        \"\"\"\n        Set transaction amount\n        \"\"\"\n        if amount:\n            try:\n                self.IsoMessage.FieldData(4, int(amount))\n            except ValueError:\n                self.IsoMessage.FieldData(4, 0)\n            self.rebuild()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_expected_action(self, expected_response_action):\n        if expected_response_action.upper() not in ['APPROVED', 'APPROVE', 'DECLINED', 'DECLINE']:\n            return False\n\n        self.expected_response_action = expected_response_action.upper()\n        return True", "response": "Sets the expected response action for the log entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the EMEM data for the current application.", "response": "def build_emv_data(self):\n        \"\"\"\n        TODO:\n        95    TVR\n        82    app_int_prof \n        \"\"\"\n        emv_data = ''\n        emv_data += self.TLV.build({'82': self._get_app_interchange_profile()})\n        emv_data += self.TLV.build({'9A': get_date()})\n        emv_data += self.TLV.build({'95': self.term.get_tvr()})\n        emv_data += self.TLV.build({'9F10': self.card.get_iss_application_data()})\n        emv_data += self.TLV.build({'9F26': self.card.get_application_cryptogram()})\n        emv_data += self.TLV.build({'9F36': self.card.get_transaction_counter()})\n        emv_data += self.TLV.build({'9F37': self.term.get_unpredno()})\n        emv_data += self.TLV.build({'9F1A': self.term.get_country_code()})\n        return emv_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the currency code of the current transaction from given currency id", "response": "def set_currency(self, currency_id):\n        \"\"\"\n        Set transaction currency code from given currency id, e.g. set 840 from 'USD'\n        \"\"\"\n        try:\n            self.currency = currency_codes[currency_id]\n            self.IsoMessage.FieldData(49, self.currency)\n            self.rebuild()\n        except KeyError:\n            self.currency = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef finalize(self):\n        for name, count in sorted(self.blocks.items(), key=lambda x: x[1]):\n            print('{:3} {}'.format(count, name))\n        print('{:3} total'.format(sum(self.blocks.values())))", "response": "Output the aggregate block count results."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun and return the results from the BlockCounts plugin.", "response": "def analyze(self, scratch, **kwargs):\n        \"\"\"Run and return the results from the BlockCounts plugin.\"\"\"\n        file_blocks = Counter()\n        for script in self.iter_scripts(scratch):\n            for name, _, _ in self.iter_blocks(script.blocks):\n                file_blocks[name] += 1\n        self.blocks.update(file_blocks)  # Update the overall count\n        return {'types': file_blocks}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, scratch, **kwargs):\n        self.total_instances += 1\n        sprites = {}\n        for sprite, script in self.iter_sprite_scripts(scratch):\n            if not script.reachable:\n                sprites.setdefault(sprite, []).append(script)\n        if sprites:\n            self.dead_code_instances += 1\n            import pprint\n            pprint.pprint(sprites)\n        variable_event = any(True in self.get_broadcast_events(x) for x in\n                             self.iter_scripts(scratch))\n        return {'dead_code': {'sprites': sprites,\n                              'variable_event': variable_event}}", "response": "Run and return the results form the DeadCode plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noutputs the number of instances that contained dead code.", "response": "def finalize(self):\n        \"\"\"Output the number of instances that contained dead code.\"\"\"\n        if self.total_instances > 1:\n            print('{} of {} instances contained dead code.'\n                  .format(self.dead_code_instances, self.total_instances))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing help and basic usage of the given command line", "response": "def show_help(name):\n    \"\"\"\n    Show help and basic usage\n    \"\"\"\n    print('Usage: python3 {} [OPTIONS]... '.format(name))\n    print('ISO8583 message client')\n    print('  -v, --verbose\\t\\tRun transactions verbosely')\n    print('  -p, --port=[PORT]\\t\\tTCP port to connect to, 1337 by default')\n    print('  -s, --server=[IP]\\t\\tIP of the ISO host to connect to, 127.0.0.1 by default')\n    print('  -t, --terminal=[ID]\\t\\tTerminal ID (used in DE 41 ISO field, 10001337 by default)')\n    print('  -m, --merchant=[ID]\\t\\tMerchant ID (used in DE 42 ISO field, 999999999999001 by default)')\n    print('  -k, --terminal-key=[KEY]\\t\\tTerminal key (\\'DEADBEEF DEADBEEF DEADBEEF DEADBEEF\\' by default)')\n    print('  -K, --master-key=[KEY]\\t\\Master key (\\'ABABABAB CDCDCDCD EFEFEFEF AEAEAEAE\\' by default)')\n    print('  -f, --file=[file.xml]\\t\\tUse transaction data from the given XML-file')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_interactive(self):\n        self.term.connect()\n        self._show_available_transactions()\n\n        while True:\n            trxn_type = self._user_input('\\nEnter transaction to send: ')\n        \n            trxn = ''\n            data = ''\n            if trxn_type == 'e':\n                trxn = Transaction('echo', self.card, self.term)\n                trxn.trace()\n        \n            elif trxn_type == 'b':\n                trxn = Transaction('balance', self.card, self.term)\n                trxn.set_PIN(self._user_input('Enter PIN: '))\n                trxn.trace()\n        \n            elif trxn_type == 'p':\n                default_amount = 20000\n                amount = self._user_input('Enter transaction amount ({} by default): '.format(default_amount))\n                if not amount:\n                    amount = default_amount\n\n                trxn = Transaction('purchase', self.card, self.term)\n                trxn.set_PIN(self._user_input('Enter PIN: '))\n                trxn.set_amount(amount)\n                trxn.trace()\n\n            elif trxn_type == 'q':\n                break\n\n            else:\n                print('Unknown transaction. Available transactions are:')\n                self._show_available_transactions()\n                continue\n                \n            self.term.send(trxn.get_data(), show_trace=verbosity)\n            data = self.term.recv(show_trace=verbosity)\n        \n            IsoMessage = ISO8583(data[2:], IsoSpec1987BPC())\n            IsoMessage.Print()\n        \n        self.term.close()", "response": "Run transactions interactively by asking user which one to send and then sending the data to the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the top - level directory of a project given a start directory inside the project.", "response": "def find_top_level_directory(start_directory):\n    \"\"\"Finds the top-level directory of a project given a start directory\n    inside the project.\n\n    Parameters\n    ----------\n    start_directory : str\n        The directory in which test discovery will start.\n\n    \"\"\"\n    top_level = start_directory\n    while os.path.isfile(os.path.join(top_level, '__init__.py')):\n        top_level = os.path.dirname(top_level)\n        if top_level == os.path.dirname(top_level):\n            raise ValueError(\"Can't find top level directory\")\n    return os.path.abspath(top_level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discover(self, start, top_level_directory=None, pattern='test*.py'):\n        logger.debug('Starting test discovery')\n        if os.path.isdir(start):\n            start_directory = start\n            return self.discover_by_directory(\n                start_directory, top_level_directory=top_level_directory,\n                pattern=pattern)\n        elif os.path.isfile(start):\n            start_filepath = start\n            return self.discover_by_file(\n                start_filepath, top_level_directory=top_level_directory)\n        else:\n            package_or_module = start\n            return self.discover_by_module(\n                package_or_module, top_level_directory=top_level_directory,\n                pattern=pattern)", "response": "This method is used to discover all test cases in a directory or a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef discover_by_module(self, module_name, top_level_directory=None,\n                           pattern='test*.py'):\n        \"\"\"Find all tests in a package or module, or load a single test case if\n        a class or test inside a module was specified.\n\n        Parameters\n        ----------\n        module_name : str\n            The dotted package name, module name or TestCase class and\n            test method.\n        top_level_directory : str\n            The path to the top-level directoy of the project.  This is\n            the parent directory of the project'stop-level Python\n            package.\n        pattern : str\n            The glob pattern to match the filenames of modules to search\n            for tests.\n\n        \"\"\"\n        # If the top level directory is given, the module may only be\n        # importable with that in the path.\n        if top_level_directory is not None and \\\n                top_level_directory not in sys.path:\n            sys.path.insert(0, top_level_directory)\n\n        logger.debug('Discovering tests by module: module_name=%r, '\n                     'top_level_directory=%r, pattern=%r', module_name,\n                     top_level_directory, pattern)\n\n        try:\n            module, case_attributes = find_module_by_name(module_name)\n        except ImportError:\n            return self.discover_filtered_tests(\n                module_name, top_level_directory=top_level_directory,\n                pattern=pattern)\n        dirname, basename = os.path.split(module.__file__)\n        basename = os.path.splitext(basename)[0]\n        if len(case_attributes) == 0 and basename == '__init__':\n            # Discover in a package\n            return self.discover_by_directory(\n                dirname, top_level_directory, pattern=pattern)\n        elif len(case_attributes) == 0:\n            # Discover all in a module\n            return self._loader.load_module(module)\n\n        return self.discover_single_case(module, case_attributes)", "response": "Find all tests in a module or a module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds and load a single TestCase or TestCase method from a module.", "response": "def discover_single_case(self, module, case_attributes):\n        \"\"\"Find and load a single TestCase or TestCase method from a module.\n\n        Parameters\n        ----------\n        module : module\n            The imported Python module containing the TestCase to be\n            loaded.\n        case_attributes : list\n            A list (length 1 or 2) of str.  The first component must be\n            the name of a TestCase subclass.  The second component must\n            be the name of a method in the TestCase.\n\n        \"\"\"\n        # Find single case\n        case = module\n        loader = self._loader\n        for index, component in enumerate(case_attributes):\n            case = getattr(case, component, None)\n            if case is None:\n                return loader.create_suite()\n            elif loader.is_test_case(case):\n                rest = case_attributes[index + 1:]\n                if len(rest) > 1:\n                    raise ValueError('Too many components in module path')\n                elif len(rest) == 1:\n                    return loader.create_suite(\n                        [loader.load_test(case, *rest)])\n                return loader.load_case(case)\n\n        # No cases matched, return empty suite\n        return loader.create_suite()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns test discovery in a directory.", "response": "def discover_by_directory(self, start_directory, top_level_directory=None,\n                              pattern='test*.py'):\n        \"\"\"Run test discovery in a directory.\n\n        Parameters\n        ----------\n        start_directory : str\n            The package directory in which to start test discovery.\n        top_level_directory : str\n            The path to the top-level directoy of the project.  This is\n            the parent directory of the project'stop-level Python\n            package.\n        pattern : str\n            The glob pattern to match the filenames of modules to search\n            for tests.\n\n        \"\"\"\n        start_directory = os.path.abspath(start_directory)\n        if top_level_directory is None:\n            top_level_directory = find_top_level_directory(\n                start_directory)\n        logger.debug('Discovering tests in directory: start_directory=%r, '\n                     'top_level_directory=%r, pattern=%r', start_directory,\n                     top_level_directory, pattern)\n\n        assert_start_importable(top_level_directory, start_directory)\n\n        if top_level_directory not in sys.path:\n            sys.path.insert(0, top_level_directory)\n        tests = self._discover_tests(\n            start_directory, top_level_directory, pattern)\n        return self._loader.create_suite(list(tests))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef discover_by_file(self, start_filepath, top_level_directory=None):\n        start_filepath = os.path.abspath(start_filepath)\n        start_directory = os.path.dirname(start_filepath)\n        if top_level_directory is None:\n            top_level_directory = find_top_level_directory(\n                start_directory)\n        logger.debug('Discovering tests in file: start_filepath=%r, '\n                     'top_level_directory=', start_filepath,\n                     top_level_directory)\n\n        assert_start_importable(top_level_directory, start_directory)\n\n        if top_level_directory not in sys.path:\n            sys.path.insert(0, top_level_directory)\n        tests = self._load_from_file(\n            start_filepath, top_level_directory)\n        return self._loader.create_suite(list(tests))", "response": "Run test discovery on a single file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting proper headers. Sets following headers: Allow Access-Control-Allow-Methods Access-Control-Allow-Headers Arguments: :methods: Sequence of HTTP method names that are value for requested URI", "response": "def _set_options_headers(self, methods):\n        \"\"\" Set proper headers.\n\n        Sets following headers:\n            Allow\n            Access-Control-Allow-Methods\n            Access-Control-Allow-Headers\n\n        Arguments:\n            :methods: Sequence of HTTP method names that are value for\n                requested URI\n        \"\"\"\n        request = self.request\n        response = request.response\n\n        response.headers['Allow'] = ', '.join(sorted(methods))\n\n        if 'Access-Control-Request-Method' in request.headers:\n            response.headers['Access-Control-Allow-Methods'] = \\\n                ', '.join(sorted(methods))\n\n        if 'Access-Control-Request-Headers' in request.headers:\n            response.headers['Access-Control-Allow-Headers'] = \\\n                'origin, x-requested-with, content-type'\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_handled_methods(self, actions_map):\n        methods = ('OPTIONS',)\n\n        defined_actions = []\n        for action_name in actions_map.keys():\n            view_method = getattr(self, action_name, None)\n            method_exists = view_method is not None\n            method_defined = view_method != self.not_allowed_action\n            if method_exists and method_defined:\n                defined_actions.append(action_name)\n\n        for action in defined_actions:\n            methods += actions_map[action]\n\n        return methods", "response": "Returns a list of HTTP methods that can be used at the requested URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle collection OPTIONS requests.", "response": "def item_options(self, **kwargs):\n        \"\"\" Handle collection OPTIONS request.\n\n        Singular route requests are handled a bit differently because\n        singular views may handle POST requests despite being registered\n        as item routes.\n        \"\"\"\n        actions = self._item_actions.copy()\n        if self._resource.is_singular:\n            actions['create'] = ('POST',)\n        methods = self._get_handled_methods(actions)\n        return self._set_options_headers(methods)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collection_options(self, **kwargs):\n        methods = self._get_handled_methods(self._collection_actions)\n        return self._set_options_headers(methods)", "response": "Handle collection item OPTIONS request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping :func: to perform aggregation on :func: call. Should be called with view instance methods.", "response": "def wrap(self, func):\n        \"\"\" Wrap :func: to perform aggregation on :func: call.\n\n        Should be called with view instance methods.\n        \"\"\"\n        @six.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                return self.aggregate()\n            except KeyError:\n                return func(*args, **kwargs)\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pop_aggregations_params(self):\n        from nefertari.view import BaseView\n        self._query_params = BaseView.convert_dotted(self.view._query_params)\n\n        for key in self._aggregations_keys:\n            if key in self._query_params:\n                return self._query_params.pop(key)\n        else:\n            raise KeyError('Missing aggregation params')", "response": "Pop and return aggregation params from query string params."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_aggregations_fields(cls, params):\n        fields = []\n        for key, val in params.items():\n            if isinstance(val, dict):\n                fields += cls.get_aggregations_fields(val)\n            if key == 'field':\n                fields.append(val)\n        return fields", "response": "Recursively get values under the field key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_aggregations_privacy(self, aggregations_params):\n        fields = self.get_aggregations_fields(aggregations_params)\n        fields_dict = dictset.fromkeys(fields)\n        fields_dict['_type'] = self.view.Model.__name__\n\n        try:\n            validate_data_privacy(self.view.request, fields_dict)\n        except wrappers.ValidationError as ex:\n            raise JHTTPForbidden(\n                'Not enough permissions to aggregate on '\n                'fields: {}'.format(ex))", "response": "Check per - field privacy rules in aggregations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms aggregation and return response.", "response": "def aggregate(self):\n        \"\"\" Perform aggregation and return response. \"\"\"\n        from nefertari.elasticsearch import ES\n        aggregations_params = self.pop_aggregations_params()\n        if self.view._auth_enabled:\n            self.check_aggregations_privacy(aggregations_params)\n        self.stub_wrappers()\n\n        return ES(self.view.Model.__name__).aggregate(\n            _aggregations_params=aggregations_params,\n            **self._query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef asdict(self, name, _type=None, _set=False):\n\n        if _type is None:\n            _type = lambda t: t\n\n        dict_str = self.pop(name, None)\n        if not dict_str:\n            return {}\n\n        _dict = {}\n        for item in split_strip(dict_str):\n            key, _, val = item.partition(':')\n            val = _type(val)\n            if key in _dict:\n                if isinstance(_dict[key], list):\n                    _dict[key].append(val)\n                else:\n                    _dict[key] = [_dict[key], val]\n            else:\n                _dict[key] = val\n\n        if _set:\n            self[name] = _dict\n\n        return _dict", "response": "Turn this a : 2 b : blabla c : True a : 2 b : blabla c : True a : 2 b : blabla c : True a : 2 b : blabla c : True a : 2 b : blabla c : True a : 2 b : blabla c : True a : 2 b : blabla c : True a : 2 b : blabla c : True b : 2 b : blabla c : True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns random hex string of a given length", "response": "def get_random_hex(length):\n    \"\"\"\n    Return random hex string of a given length\n    \"\"\"\n    if length <= 0:\n        return ''\n    return hexify(random.randint(pow(2, length*2), pow(2, length*4)))[0:length]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns xx1x response for xx0x codes", "response": "def get_response(_code):\n    \"\"\"\n    Return xx1x response for xx0x codes (e.g. 0810 for 0800)\n    \"\"\"\n    if _code:\n        code = str(_code)\n        return code[:-2] + str(int(code[-2:-1]) + 1) + code[-1]\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_case(self, testcase):\n        tests = [self.load_test(testcase, name)\n                 for name in self.find_test_method_names(testcase)]\n        return self.create_suite(tests)", "response": "Load a TestSuite containing all tests in the given testcase."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates and return a test suite containing all cases loaded from the module.", "response": "def load_module(self, module):\n        \"\"\"Create and return a test suite containing all cases loaded from the\n        provided module.\n\n        Parameters\n        ----------\n        module : module\n            A module object containing ``TestCases``\n\n        \"\"\"\n        cases = self.get_test_cases_from_module(module)\n        suites = [self.load_case(case) for case in cases]\n        return self.create_suite(suites)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Field(self, field, Value = None):\n        '''\n        Add field to bitmap\n        '''\n        if Value == None:\n            try:\n                return self.__Bitmap[field]\n            except KeyError:\n                return None\n        elif Value == 1 or Value == 0:\n            self.__Bitmap[field] = Value\n        else:\n            raise ValueError", "response": "Add a field to bitmap."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding field data to the internal data structure.", "response": "def FieldData(self, field, Value = None):\n        '''\n        Add field data\n        '''\n        if Value == None:\n            try:\n                return self.__FieldData[field]\n            except KeyError:\n                return None\n        else:\n            if len(str(Value)) > self.__IsoSpec.MaxLength(field):\n                raise ValueError('Value length larger than field maximum ({0})'.format(self.__IsoSpec.MaxLength(field)))\n            \n            self.Field(field, Value=1)\n            self.__FieldData[field] = Value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticated_userid(request):\n    user = getattr(request, 'user', None)\n    key = user.pk_field()\n    return getattr(user, key)", "response": "Returns the user id of the authenticated user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter_blocks(block_list):\n        # queue the block and the depth of the block\n        queue = [(block, 0) for block in block_list\n                 if isinstance(block, kurt.Block)]\n        while queue:\n            block, depth = queue.pop(0)\n            assert block.type.text\n            yield block.type.text, depth, block\n            for arg in block.args:\n                if hasattr(arg, '__iter__'):\n                    queue[0:0] = [(x, depth + 1) for x in arg\n                                  if isinstance(x, kurt.Block)]\n                elif isinstance(arg, kurt.Block):\n                    queue.append((arg, depth))", "response": "A generator for blocks contained in a block list. Yields tuples containing the block name the depth that the block was\n        found at and finally a handle to the block itself."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_scripts(scratch):\n        for script in scratch.stage.scripts:\n            if not isinstance(script, kurt.Comment):\n                yield script\n        for sprite in scratch.sprites:\n            for script in sprite.scripts:\n                if not isinstance(script, kurt.Comment):\n                    yield script", "response": "A generator for all scripts contained in a scratch file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef script_start_type(script):\n        if script[0].type.text == 'when @greenFlag clicked':\n            return HairballPlugin.HAT_GREEN_FLAG\n        elif script[0].type.text == 'when I receive %s':\n            return HairballPlugin.HAT_WHEN_I_RECEIVE\n        elif script[0].type.text == 'when this sprite clicked':\n            return HairballPlugin.HAT_MOUSE\n        elif script[0].type.text == 'when %s key pressed':\n            return HairballPlugin.HAT_KEY\n        else:\n            return HairballPlugin.NO_HAT", "response": "Return the type of block the script begins with."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_broadcast_events(cls, script):\n        events = Counter()\n        for name, _, block in cls.iter_blocks(script):\n            if 'broadcast %s' in name:\n                if isinstance(block.args[0], kurt.Block):\n                    events[True] += 1\n                else:\n                    events[block.args[0].lower()] += 1\n        return events", "response": "Return a Counter of event - names that were broadcast."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntagging each script with attribute reachable.", "response": "def tag_reachable_scripts(cls, scratch):\n        \"\"\"Tag each script with attribute reachable.\n\n        The reachable attribute will be set false for any script that does not\n        begin with a hat block. Additionally, any script that begins with a\n        'when I receive' block whose event-name doesn't appear in a\n        corresponding broadcast block is marked as unreachable.\n\n        \"\"\"\n        if getattr(scratch, 'hairball_prepared', False):  # Only process once\n            return\n\n        reachable = set()\n        untriggered_events = {}\n        # Initial pass to find reachable and potentially reachable scripts\n        for script in cls.iter_scripts(scratch):\n            if not isinstance(script, kurt.Comment):\n                starting_type = cls.script_start_type(script)\n                if starting_type == cls.NO_HAT:\n                    script.reachable = False\n                elif starting_type == cls.HAT_WHEN_I_RECEIVE:\n                    # Value will be updated if reachable\n                    script.reachable = False\n                    message = script[0].args[0].lower()\n                    untriggered_events.setdefault(message, set()).add(script)\n                else:\n                    script.reachable = True\n                    reachable.add(script)\n        # Expand reachable states based on broadcast events\n        while reachable:\n            for event in cls.get_broadcast_events(reachable.pop()):\n                if event in untriggered_events:\n                    for script in untriggered_events.pop(event):\n                        script.reachable = True\n                        reachable.add(script)\n        scratch.hairball_prepared = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattribute that returns the plugin description from its docstring.", "response": "def description(self):\n        \"\"\"Attribute that returns the plugin description from its docstring.\"\"\"\n        lines = []\n        for line in self.__doc__.split('\\n')[2:]:\n            line = line.strip()\n            if line:\n                lines.append(line)\n        return ' '.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfinalize the compressed version of the spreadsheet.", "response": "def close(self):\n        \"\"\"\n        Finalises the compressed version of the spreadsheet. If you aren't using the context manager ('with' statement,\n        you must call this manually, it is not triggered automatically like on a file object.\n        :return: Nothing.\n        \"\"\"\n        self.zipf.writestr(\"content.xml\", self.dom.toxml().encode(\"utf-8\"))\n        self.zipf.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a row of cells into the default sheet of the spreadsheet.", "response": "def writerow(self, cells):\n        \"\"\"\n        Write a row of cells into the default sheet of the spreadsheet.\n        :param cells: A list of cells (most basic Python types supported).\n        :return: Nothing.\n        \"\"\"\n        if self.default_sheet is None:\n            self.default_sheet = self.new_sheet()\n        self.default_sheet.writerow(cells)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_sheet(self, name=None, cols=None):\n        sheet = Sheet(self.dom, name, cols)\n        self.sheets.append(sheet)\n        return sheet", "response": "Create a new sheet in the spreadsheet and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_limit(entries, **kwargs):\n    limit = kwargs.pop('limit', 5)\n    if limit <= 0:\n        return show_menu(entries, **kwargs)\n    istart = 0 # Index of group start.\n    iend = limit # Index of group end.\n    dft = kwargs.pop('dft', None)\n    if type(dft) == int:\n        dft = str(dft)\n    while True:\n        if iend > len(entries):\n            iend = len(entries)\n            istart = iend - limit\n        if istart < 0:\n            istart = 0\n            iend = limit\n        unext = len(entries) - iend # Number of next entries.\n        uprev = istart # Number of previous entries.\n        nnext = \"\" # Name of 'next' menu entry.\n        nprev = \"\" # Name of 'prev' menu entry.\n        dnext = \"\" # Description of 'next' menu entry.\n        dprev = \"\" # Description of 'prev' menu entry.\n        group = copy.deepcopy(entries[istart:iend])\n        names = [i.name for i in group]\n        if unext > 0:\n            for i in [\"n\", \"N\", \"next\", \"NEXT\", \"->\", \">>\", \">>>\"]:\n                if i not in names:\n                    nnext = i\n                    dnext = \"Next %u of %u entries\" % (unext, len(entries))\n                    group.append(MenuEntry(nnext, dnext, None, None, None))\n                    names.append(\"n\")\n                    break\n        if uprev > 0:\n            for i in [\"p\", \"P\", \"prev\", \"PREV\", \"<-\", \"<<\", \"<<<\"]:\n                if i not in names:\n                    nprev = i\n                    dprev = \"Previous %u of %u entries\" % (uprev, len(entries))\n                    group.append(MenuEntry(nprev, dprev, None, None, None))\n                    names.append(\"p\")\n                    break\n        tmpdft = None\n        if dft != None:\n            if dft not in names:\n                if \"n\" in names:\n                    tmpdft = \"n\"\n            else:\n                tmpdft = dft\n        result = show_menu(group, dft=tmpdft, **kwargs)\n        if result == nnext or result == dnext:\n            istart += limit\n            iend += limit\n        elif result == nprev or result == dprev:\n            istart -= limit\n            iend -= limit\n        else:\n            return result", "response": "Shows a menu but limits the number of entries shown at a time."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows a menu with the given list of MenuEntry objects.", "response": "def show_menu(entries, **kwargs):\n    \"\"\"Shows a menu with the given list of `MenuEntry` items.\n\n    **Params**:\n      - header (str) - String to show above menu.\n      - note (str) - String to show as a note below menu.\n      - msg (str) - String to show below menu.\n      - dft (str) - Default value if input is left blank.\n      - compact (bool) - If true, the menu items will not be displayed\n        [default: False].\n      - returns (str) - Controls what part of the menu entry is returned,\n        'func' returns function result [default: name].\n      - limit (int) - If set, limits the number of menu entries show at a time\n        [default: None].\n      - fzf (bool) - If true, can enter FCHR at the menu prompt to search menu.\n    \"\"\"\n    global _AUTO\n    hdr = kwargs.get('hdr', \"\")\n    note = kwargs.get('note', \"\")\n    dft = kwargs.get('dft', \"\")\n    fzf = kwargs.pop('fzf', True)\n    compact = kwargs.get('compact', False)\n    returns = kwargs.get('returns', \"name\")\n    limit = kwargs.get('limit', None)\n    dft = kwargs.get('dft', None)\n    msg = []\n    if limit:\n        return show_limit(entries, **kwargs)\n    def show_banner():\n        banner = \"-- MENU\"\n        if hdr:\n            banner += \": \" + hdr\n        banner += \" --\"\n        msg.append(banner)\n        if _AUTO:\n            return\n        for i in entries:\n            msg.append(\"  (%s) %s\" % (i.name, i.desc))\n    valid = [i.name for i in entries]\n    if type(dft) == int:\n        dft = str(dft)\n    if dft not in valid:\n        dft = None\n    if not compact:\n        show_banner()\n    if note and not _AUTO:\n        msg.append(\"[!] \" + note)\n    if fzf:\n        valid.append(FCHR)\n    msg.append(QSTR + kwargs.get('msg', \"Enter menu selection\"))\n    msg = os.linesep.join(msg)\n    entry = None\n    while entry not in entries:\n        choice = ask(msg, vld=valid, dft=dft, qstr=False)\n        if choice == FCHR and fzf:\n            try:\n                from iterfzf import iterfzf\n                choice = iterfzf(reversed([\"%s\\t%s\" % (i.name, i.desc) for i in entries])).strip(\"\\0\").split(\"\\t\", 1)[0]\n            except:\n                warn(\"Issue encountered during fzf search.\")\n        match = [i for i in entries if i.name == choice]\n        if match:\n            entry = match[0]\n    if entry.func:\n        fresult = run_func(entry)\n        if \"func\" == returns:\n            return fresult\n    try:\n        return getattr(entry, returns)\n    except:\n        return getattr(entry, \"name\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_func(entry):\n    if entry.func:\n        if entry.args and entry.krgs:\n            return entry.func(*entry.args, **entry.krgs)\n        if entry.args:\n            return entry.func(*entry.args)\n        if entry.krgs:\n            return entry.func(**entry.krgs)\n        return entry.func()", "response": "Runs the function associated with the given MenuEntry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enum_menu(strs, menu=None, *args, **kwargs):\n    if not menu:\n        menu = Menu(*args, **kwargs)\n    for s in strs:\n        menu.enum(s)\n    return menu", "response": "Enumerates the given list of strings into a menu."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprompting the user for input and returns the answer. Optionally returns the given answer.", "response": "def ask(msg=\"Enter input\", fmt=None, dft=None, vld=None, shw=True, blk=False, hlp=None, qstr=True):\n    \"\"\"Prompts the user for input and returns the given answer. Optionally\n    checks if answer is valid.\n\n    **Params**:\n      - msg (str) - Message to prompt the user with.\n      - fmt (func) - Function used to format user input.\n      - dft (int|float|str) - Default value if input is left blank.\n      - vld ([int|float|str|func]) - Valid input entries.\n      - shw (bool) - If true, show the user's input as typed.\n      - blk (bool) - If true, accept a blank string as valid input. Note that\n        supplying a default value will disable accepting blank input.\n    \"\"\"\n    global _AUTO\n    def print_help():\n        lst = [v for v in vld if not callable(v)]\n        if blk:\n            lst.remove(\"\")\n        for v in vld:\n            if not callable(v):\n                continue\n            if int == v:\n                lst.append(\"<int>\")\n            elif float == v:\n                lst.append(\"<float>\")\n            elif str == v:\n                lst.append(\"<str>\")\n            else:\n                lst.append(\"(\" + v.__name__ + \")\")\n        if lst:\n            echo(\"[HELP] Valid input: %s\" % (\" | \".join([str(l) for l in lst])))\n        if hlp:\n            echo(\"[HELP] Extra notes: \" + hlp)\n        if blk:\n            echo(\"[HELP] Input may be blank.\")\n    vld = vld or []\n    hlp = hlp or \"\"\n    if not hasattr(vld, \"__iter__\"):\n        vld = [vld]\n    if not hasattr(fmt, \"__call__\"):\n        fmt = lambda x: x  # NOTE: Defaults to function that does nothing.\n    msg = \"%s%s\" % (QSTR if qstr else \"\", msg)\n    dft = fmt(dft) if dft != None else None # Prevents showing [None] default.\n    if dft != None:\n        msg += \" [%s]\" % (dft if type(dft) is str else repr(dft))\n        vld.append(dft)\n        blk = False\n    if vld:\n        # Sanitize valid inputs.\n        vld = list(set([fmt(v) if fmt(v) else v for v in vld]))\n        if blk and \"\" not in vld:\n            vld.append(\"\")\n        # NOTE: The following fixes a Py3 related bug found in `0.8.1`.\n        try: vld = sorted(vld)\n        except: pass\n    msg += ISTR\n    ans = None\n    while ans is None:\n        get_input = _input if shw else getpass\n        ans = get_input(msg)\n        if _AUTO:\n            echo(ans)\n        if \"?\" == ans:\n            print_help()\n            ans = None\n            continue\n        if \"\" == ans:\n            if dft != None:\n                ans = dft if not fmt else fmt(dft)\n                break\n            if \"\" not in vld:\n                ans = None\n                continue\n        try:\n            ans = ans if not fmt else fmt(ans)\n        except:\n            ans = None\n        if vld:\n            for v in vld:\n                if type(v) is type and cast(ans, v) is not None:\n                    ans = cast(ans, v)\n                    break\n                elif hasattr(v, \"__call__\"):\n                    try:\n                        if v(ans):\n                            break\n                    except:\n                        pass\n                elif ans in vld:\n                    break\n            else:\n                ans = None\n    return ans"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprompts the user for a yes or no answer. Returns True for yes False for no.", "response": "def ask_yesno(msg=\"Proceed?\", dft=None):\n    \"\"\"Prompts the user for a yes or no answer. Returns True for yes, False\n    for no.\"\"\"\n    yes = [\"y\", \"yes\", \"Y\", \"YES\"]\n    no = [\"n\", \"no\", \"N\", \"NO\"]\n    if dft != None:\n        dft = yes[0] if (dft in yes or dft == True) else no[0]\n    return ask(msg, dft=dft, vld=yes+no) in yes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ask_int(msg=\"Enter an integer\", dft=None, vld=None, hlp=None):\n    vld = vld or [int]\n    return ask(msg, dft=dft, vld=vld, fmt=partial(cast, typ=int), hlp=hlp)", "response": "Prompts the user for an integer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ask_float(msg=\"Enter a float\", dft=None, vld=None, hlp=None):\n    vld = vld or [float]\n    return ask(msg, dft=dft, vld=vld, fmt=partial(cast, typ=float), hlp=hlp)", "response": "Prompts the user for a float."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ask_str(msg=\"Enter a string\", dft=None, vld=None, shw=True, blk=True, hlp=None):\n    vld = vld or [str]\n    return ask(msg, dft=dft, vld=vld, shw=shw, blk=blk, hlp=hlp)", "response": "Prompts the user for a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ask_captcha(length=4):\n    captcha = \"\".join(random.choice(string.ascii_lowercase) for _ in range(length))\n    ask_str('Enter the following letters, \"%s\"' % (captcha), vld=[captcha, captcha.upper()], blk=False)", "response": "Prompts the user for a random string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a status message at the start and finish of an associated function.", "response": "def status(*args, **kwargs):\n    \"\"\"Prints a status message at the start and finish of an associated\n    function. Can be used as a function decorator or as a function that accepts\n    another function as the first parameter.\n\n    **Params**:\n\n    The following parameters are available when used as a decorator:\n\n      - msg (str) [args] - Message to print at start of `func`.\n\n    The following parameters are available when used as a function:\n\n      - msg (str) [args] - Message to print at start of `func`.\n      - func (func) - Function to call. First `args` if using `status()` as a\n        function. Automatically provided if using `status()` as a decorator.\n      - fargs (list) - List of `args` passed to `func`.\n      - fkrgs (dict) - Dictionary of `kwargs` passed to `func`.\n      - fin (str) [kwargs] - Message to print when `func` finishes.\n\n    **Examples**:\n    ::\n        @qprompt.status(\"Something is happening...\")\n        def do_something(a):\n            time.sleep(a)\n\n        do_something()\n        # [!] Something is happening... DONE.\n\n        qprompt.status(\"Doing a thing...\", myfunc, [arg1], {krgk: krgv})\n        # [!] Doing a thing... DONE.\n    \"\"\"\n    def decor(func):\n        @wraps(func)\n        def wrapper(*args, **krgs):\n            echo(\"[!] \" + msg, end=\" \", flush=True)\n            result = func(*args, **krgs)\n            echo(fin, flush=True)\n            return result\n        return wrapper\n    fin = kwargs.pop('fin', \"DONE.\")\n    args = list(args)\n    if len(args) > 1 and callable(args[1]):\n        msg = args.pop(0)\n        func = args.pop(0)\n        try: fargs = args.pop(0)\n        except: fargs = []\n        try: fkrgs = args.pop(0)\n        except: fkrgs = {}\n        return decor(func)(*fargs, **fkrgs)\n    msg = args.pop(0)\n    return decor"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a message then exits the program.", "response": "def fatal(msg, exitcode=1, **kwargs):\n    \"\"\"Prints a message then exits the program. Optionally pause before exit\n    with `pause=True` kwarg.\"\"\"\n    # NOTE: Can't use normal arg named `pause` since function has same name.\n    pause_before_exit = kwargs.pop(\"pause\") if \"pause\" in kwargs.keys() else False\n    echo(\"[FATAL] \" + msg, **kwargs)\n    if pause_before_exit:\n        pause()\n    sys.exit(exitcode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noutputting or returns a horizontal line of the given character and width.", "response": "def hrule(width=None, char=None):\n    \"\"\"Outputs or returns a horizontal line of the given character and width.\n    Returns printed string.\"\"\"\n    width = width or HRWIDTH\n    char = char or HRCHAR\n    return echo(getline(char, width))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the title of the console window.", "response": "def title(msg):\n    \"\"\"Sets the title of the console window.\"\"\"\n    if sys.platform.startswith(\"win\"):\n        ctypes.windll.kernel32.SetConsoleTitleW(tounicode(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap(item, args=None, krgs=None, **kwargs):\n    with Wrap(**kwargs):\n        if callable(item):\n            args = args or []\n            krgs = krgs or {}\n            item(*args, **krgs)\n        else:\n            echo(item)", "response": "Wraps the given item content between horizontal lines."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _guess_name(desc, taken=None):\n    taken = taken or []\n    name = \"\"\n    # Try to find the shortest name based on the given description.\n    for word in desc.split():\n        c = word[0].lower()\n        if not c.isalnum():\n            continue\n        name += c\n        if name not in taken:\n            break\n    # If name is still taken, add a number postfix.\n    count = 2\n    while name in taken:\n        name = name + str(count)\n        count += 1\n    return name", "response": "Attempts to guess the menu entry name from the function name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, name, desc, func=None, args=None, krgs=None):\n        self.entries.append(MenuEntry(name, desc, func, args or [], krgs or {}))", "response": "Add a menu entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a menu entry whose name will be an auto indexed number.", "response": "def enum(self, desc, func=None, args=None, krgs=None):\n        \"\"\"Add a menu entry whose name will be an auto indexed number.\"\"\"\n        name = str(len(self.entries)+1)\n        self.entries.append(MenuEntry(name, desc, func, args or [], krgs or {}))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show(self, **kwargs):\n        show_kwargs = copy.deepcopy(self._show_kwargs)\n        show_kwargs.update(kwargs)\n        return show_menu(self.entries, **show_kwargs)", "response": "Shows the menu. Any keyword arguments passed will be passed to show_menu."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, name):\n        for entry in self.entries:\n            if entry.name == name:\n                run_func(entry)\n                break", "response": "Runs the function associated with the given entry name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the standard menu main logic. Any `kwargs` supplied will be pass to `Menu.show()`. If `argv` is provided to the script, it will be used as the `auto` parameter. **Params**: - auto ([str]) - If provided, the list of strings with be used as input for the menu prompts. - loop (bool) - If true, the menu will loop until quit. - quit ((str,str)) - If provided, adds a quit option to the menu.", "response": "def main(self, auto=None, loop=False, quit=(\"q\", \"Quit\"), **kwargs):\n        \"\"\"Runs the standard menu main logic. Any `kwargs` supplied will be\n        pass to `Menu.show()`. If `argv` is provided to the script, it will be\n        used as the `auto` parameter.\n\n        **Params**:\n          - auto ([str]) - If provided, the list of strings with be used as\n            input for the menu prompts.\n          - loop (bool) - If true, the menu will loop until quit.\n          - quit ((str,str)) - If provided, adds a quit option to the menu.\n        \"\"\"\n        def _main():\n            global _AUTO\n            if quit:\n                if self.entries[-1][:2] != quit:\n                    self.add(*quit, func=lambda: quit[0])\n            if stdin_auto.auto:\n                _AUTO = True\n            result = None\n            if loop:\n                note = \"Menu loops until quit.\"\n                try:\n                    while True:\n                        mresult = self.show(note=note, **kwargs)\n                        if mresult in quit:\n                            break\n                        result = mresult\n                except EOFError:\n                    pass\n                return result\n            else:\n                note = \"Menu does not loop, single entry.\"\n                result = self.show(note=note, **kwargs)\n            return result\n        global _AUTO\n        if _AUTO:\n            return _main()\n        else:\n            with stdin_auto:\n                return _main()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partition_scripts(scripts, start_type1, start_type2):\n    match, other = [], []\n    for script in scripts:\n        if (HairballPlugin.script_start_type(script) == start_type1 or \n            HairballPlugin.script_start_type(script) == start_type2):\n            match.append(script)\n        else:\n            other.append(script)\n    return match, other", "response": "Partition a list of scripts into two lists of scripts that begin with start_type1 or start_type2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attribute_result(cls, sprites):\n        retval = dict((x, True) for x in cls.ATTRIBUTES)\n        for properties in sprites.values():\n            for attribute, state in properties.items():\n                retval[attribute] &= state != cls.STATE_MODIFIED\n        return retval", "response": "Return mapping of attributes to if they were initialized or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attribute_state(cls, scripts, attribute):\n        green_flag, other = partition_scripts(scripts, cls.HAT_GREEN_FLAG, cls.HAT_CLONE)\n        block_set = cls.BLOCKMAPPING[attribute]\n        state = cls.STATE_NOT_MODIFIED\n        # TODO: Any regular broadcast blocks encountered in the initialization\n        # zone should be added to this loop for conflict checking.\n        for script in green_flag:\n            in_zone = True\n            for name, level, _ in cls.iter_blocks(script.blocks):\n                if name == 'broadcast %s and wait':\n                    # TODO: Follow the broadcast and wait scripts that occur in\n                    # the initialization zone\n                    in_zone = False\n                if (name, 'absolute') in block_set:\n                    if in_zone and level == 0:  # Success!\n                        if state == cls.STATE_NOT_MODIFIED:\n                            state = cls.STATE_INITIALIZED\n                        else:  # Multiple when green flag clicked conflict\n                            state = cls.STATE_MODIFIED\n                    elif in_zone:\n                        continue  # Conservative ignore for nested absolutes\n                    else:\n                        state = cls.STATE_MODIFIED\n                    break  # The state of the script has been determined\n                elif (name, 'relative') in block_set:\n                    state = cls.STATE_MODIFIED\n                    break\n        if state != cls.STATE_NOT_MODIFIED:\n            return state\n        # Check the other scripts to see if the attribute was ever modified\n        for script in other:\n            for name, _, _ in cls.iter_blocks(script.blocks):\n                if name in [x[0] for x in block_set]:\n                    return cls.STATE_MODIFIED\n        return cls.STATE_NOT_MODIFIED", "response": "Return the state of the scripts for the given attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting whether or not each attribute was correctly initialized.", "response": "def output_results(cls, sprites):\n        \"\"\"Output whether or not each attribute was correctly initialized.\n\n        Attributes that were not modified at all are considered to be properly\n        initialized.\n\n        \"\"\"\n        print(' '.join(cls.ATTRIBUTES))\n        format_strs = ['{{{}!s:^{}}}'.format(x, len(x)) for x in\n                       cls.ATTRIBUTES]\n        print(' '.join(format_strs).format(**cls.attribute_result(sprites)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sprite_changes(cls, sprite):\n        retval = dict((x, cls.attribute_state(sprite.scripts, x)) for x in\n                      (x for x in cls.ATTRIBUTES if x != 'background'))\n        return retval", "response": "Return a mapping of attributes to their initilization state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning and return the results of the AttributeInitialization plugin.", "response": "def analyze(self, scratch, **kwargs):\n        \"\"\"Run and return the results of the AttributeInitialization plugin.\"\"\"\n        changes = dict((x.name, self.sprite_changes(x)) for x in\n                       scratch.sprites)\n        changes['stage'] = {\n            'background': self.attribute_state(scratch.stage.scripts,\n                                               'costume')}\n        # self.output_results(changes)\n        return {'initialized': changes}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef variable_state(cls, scripts, variables):\n        def conditionally_set_not_modified():\n            \"\"\"Set the variable to modified if it hasn't been altered.\"\"\"\n            state = variables.get(block.args[0], None)\n            if state == cls.STATE_NOT_MODIFIED:\n                variables[block.args[0]] = cls.STATE_MODIFIED\n\n        green_flag, other = partition_scripts(scripts, cls.HAT_GREEN_FLAG)\n        variables = dict((x, cls.STATE_NOT_MODIFIED) for x in variables)\n        for script in green_flag:\n            in_zone = True\n            for name, level, block in cls.iter_blocks(script.blocks):\n                if name == 'broadcast %s and wait':\n                    in_zone = False\n                if name == 'set %s effect to %s':\n                    state = variables.get(block.args[0], None)\n                    if state is None:\n                        continue  # Not a variable we care about\n                    if in_zone and level == 0:  # Success!\n                        if state == cls.STATE_NOT_MODIFIED:\n                            state = cls.STATE_INITIALIZED\n                        else:  # Multiple when green flag clicked conflict\n                            # TODO: Need to allow multiple sets of a variable\n                            # within the same script\n                            # print 'CONFLICT', script\n                            state = cls.STATE_MODIFIED\n                    elif in_zone:\n                        continue  # Conservative ignore for nested absolutes\n                    elif state == cls.STATE_NOT_MODIFIED:\n                        state = cls.STATE_MODIFIED\n                    variables[block.args[0]] = state\n                elif name == 'change %s effect by %s':\n                    conditionally_set_not_modified()\n        for script in other:\n            for name, _, block in cls.iter_blocks(script.blocks):\n                if name in ('change %s effect by %s', 'set %s effect to %s'):\n                    conditionally_set_not_modified()\n        return variables", "response": "Return the initialization state for each variable in variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef analyze(self, scratch, **kwargs):\n        variables = dict((x, self.variable_state(x.scripts, x.variables))\n                         for x in scratch.sprites)\n        variables['global'] = self.variable_state(self.iter_scripts(scratch),\n                                                  scratch.stage.variables)\n        # Output for now\n        import pprint\n        pprint.pprint(variables)\n        return {'variables': variables}", "response": "Run and return the results of the VariableInitialization plugin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noutputting the default sprite names found in the project.", "response": "def finalize(self):\n        \"\"\"Output the default sprite names found in the project.\"\"\"\n        print('{} default sprite names found:'.format(self.total_default))\n        for name in self.list_default:\n            print(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning and return the results from the SpriteNaming plugin.", "response": "def analyze(self, scratch, **kwargs):\n        \"\"\"Run and return the results from the SpriteNaming plugin.\"\"\"\n        for sprite in self.iter_sprites(scratch):\n            for default in self.default_names:\n                if default in sprite.name:\n                    self.total_default += 1\n                    self.list_default.append(sprite.name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tunneling(handler, registry):\n    log.info('get_tunneling enabled')\n\n    def get_tunneling(request):\n        if request.method == 'GET':\n            method = request.GET.pop('_m', 'GET')\n            request.method = method\n\n            if method in ['POST', 'PUT', 'PATCH']:\n                get_params = request.GET.mixed()\n                valid_params = drop_reserved_params(get_params)\n                request.body = six.b(json.dumps(valid_params))\n                request.content_type = 'application/json'\n                request._tunneled_get = True\n\n        return handler(request)\n\n    return get_tunneling", "response": "Returns a function that will tunnel the request to the next resource in the list of available resources."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_selfalias(config, id_name):\n\n    def context_found_subscriber(event):\n        request = event.request\n        user = getattr(request, 'user', None)\n        if (request.matchdict and\n                request.matchdict.get(id_name, None) == 'self' and\n                user):\n            request.matchdict[id_name] = user.username\n\n    config.add_subscriber(context_found_subscriber, ContextFound)", "response": "Enable self alias for the given id_name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert dotted keys in a nested dictset to a nested dictset.", "response": "def convert_dotted(params):\n        \"\"\" Convert dotted keys in :params: dictset to a nested dictset.\n\n        E.g. {'settings.foo': 'bar'} -> {'settings': {'foo': 'bar'}}\n        \"\"\"\n        if not isinstance(params, dictset):\n            params = dictset(params)\n\n        dotted_items = {k: v for k, v in params.items() if '.' in k}\n\n        if dotted_items:\n            dicts = [str2dict(key, val) for key, val in dotted_items.items()]\n            dotted = six.functools.reduce(merge_dicts, dicts)\n            params = params.subset(['-' + k for k in dotted_items.keys()])\n            params.update(dict(dotted))\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_request_params(self, _query_params, _json_params):\n        self._query_params = dictset(\n            _query_params or self.request.params.mixed())\n        self._json_params = dictset(_json_params)\n\n        ctype = self.request.content_type\n        if self.request.method in ['POST', 'PUT', 'PATCH']:\n            if ctype == 'application/json':\n                try:\n                    self._json_params.update(self.request.json)\n                except simplejson.JSONDecodeError:\n                    log.error(\n                        \"Expecting JSON. Received: '{}'. \"\n                        \"Request: {} {}\".format(\n                            self.request.body, self.request.method,\n                            self.request.url))\n\n            self._json_params = BaseView.convert_dotted(self._json_params)\n            self._query_params = BaseView.convert_dotted(self._query_params)\n\n        self._params = self._query_params.copy()\n        self._params.update(self._json_params)", "response": "Prepare query and update params."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_override_rendered(self):\n        if '' in self.request.accept:\n            self.request.override_renderer = self._default_renderer\n        elif 'application/json' in self.request.accept:\n            self.request.override_renderer = 'nefertari_json'\n        elif 'text/plain' in self.request.accept:\n            self.request.override_renderer = 'string'", "response": "Set self. request. override_renderer if needed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping self. index method with ESAggregator.", "response": "def _setup_aggregation(self, aggregator=None):\n        \"\"\" Wrap `self.index` method with ESAggregator.\n\n        This makes `self.index` to first try to run aggregation and only\n        on fail original method is run. Method is wrapped only if it is\n        defined and `elasticsearch.enable_aggregations` setting is true.\n        \"\"\"\n        from nefertari.elasticsearch import ES\n        if aggregator is None:\n            aggregator = ESAggregator\n        aggregations_enabled = (\n            ES.settings and ES.settings.asbool('enable_aggregations'))\n        if not aggregations_enabled:\n            log.debug('Elasticsearch aggregations are not enabled')\n            return\n\n        index = getattr(self, 'index', None)\n        index_defined = index and index != self.not_allowed_action\n        if index_defined:\n            self.index = aggregator(self).wrap(self.index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying ES collection and return results.", "response": "def get_collection_es(self):\n        \"\"\" Query ES collection and return results.\n\n        This is default implementation of querying ES collection with\n        `self._query_params`. It must return found ES collection\n        results for default response renderers to work properly.\n        \"\"\"\n        from nefertari.elasticsearch import ES\n        return ES(self.Model.__name__).get_collection(**self._query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_null_values(self):\n        if not self.Model:\n            log.info(\"%s has no model defined\" % self.__class__.__name__)\n            return\n\n        empty_values = self.Model.get_null_values()\n        for field, value in empty_values.items():\n            if field not in self._json_params:\n                self._json_params[field] = value", "response": "Fill missing model fields in JSON with null values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset public limits if auth is enabled and user is not authenticated.", "response": "def set_public_limits(self):\n        \"\"\" Set public limits if auth is enabled and user is not\n        authenticated.\n\n        Also sets default limit for GET, HEAD requests.\n        \"\"\"\n        if self.request.method.upper() in ['GET', 'HEAD']:\n            self._query_params.process_int_param('_limit', 20)\n        if self._auth_enabled and not getattr(self.request, 'user', None):\n            wrappers.set_public_limits(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts object IDs from self. _json_params to objects if needed.", "response": "def convert_ids2objects(self):\n        \"\"\" Convert object IDs from `self._json_params` to objects if needed.\n\n        Only IDs that belong to relationship field of `self.Model`\n        are converted.\n        \"\"\"\n        if not self.Model:\n            log.info(\"%s has no model defined\" % self.__class__.__name__)\n            return\n\n        for field in self._json_params.keys():\n            if not engine.is_relationship_field(field, self.Model):\n                continue\n            rel_model_cls = engine.get_relationship_cls(field, self.Model)\n            self.id2obj(field, rel_model_cls)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_default_wrappers(self):\n        # Index\n        self._after_calls['index'] = [\n            wrappers.wrap_in_dict(self.request),\n            wrappers.add_meta(self.request),\n            wrappers.add_object_url(self.request),\n        ]\n\n        # Show\n        self._after_calls['show'] = [\n            wrappers.wrap_in_dict(self.request),\n            wrappers.add_meta(self.request),\n            wrappers.add_object_url(self.request),\n        ]\n\n        # Create\n        self._after_calls['create'] = [\n            wrappers.wrap_in_dict(self.request),\n            wrappers.add_meta(self.request),\n            wrappers.add_object_url(self.request),\n        ]\n\n        # Update\n        self._after_calls['update'] = [\n            wrappers.wrap_in_dict(self.request),\n            wrappers.add_meta(self.request),\n            wrappers.add_object_url(self.request),\n        ]\n\n        # Replace\n        self._after_calls['replace'] = [\n            wrappers.wrap_in_dict(self.request),\n            wrappers.add_meta(self.request),\n            wrappers.add_object_url(self.request),\n        ]\n\n        # Privacy wrappers\n        if self._auth_enabled:\n            for meth in ('index', 'show', 'create', 'update', 'replace'):\n                self._after_calls[meth] += [\n                    wrappers.apply_privacy(self.request),\n                ]\n            for meth in ('update', 'replace', 'update_many'):\n                self._before_calls[meth] += [\n                    wrappers.apply_request_privacy(\n                        self.Model, self._json_params),\n                ]", "response": "Setup defaulf wrappers.\n\n        Wrappers are applied when view method does not return instance\n        of Response. In this case nefertari renderers call wrappers and\n        handle response generation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef migrate_codec(config_old, config_new):\n    '''Migrate data from mongodict <= 0.2.1 to 0.3.0\n    `config_old` and `config_new` should be dictionaries with the keys\n    regarding to MongoDB server:\n        - `host`\n        - `port`\n        - `database`\n        - `collection`\n    '''\n    assert mongodict.__version__ in [(0, 3, 0), (0, 3, 1)]\n\n    connection = pymongo.Connection(host=config_old['host'],\n                                    port=config_old['port'])\n    database = connection[config_old['database']]\n    collection = database[config_old['collection']]\n    new_dict = mongodict.MongoDict(**config_new) # uses pickle codec by default\n    total_pairs = collection.count()\n    start_time = time.time()\n    for counter, pair in enumerate(collection.find(), start=1):\n        key, value = pair['_id'], pair['value']\n        new_dict[key] = value\n        if counter % REPORT_INTERVAL == 0:\n            print_report(counter, total_pairs, start_time)\n    print_report(counter, total_pairs, start_time)\n    print('')", "response": "Migrate data from mongodict < = 0. 2. 1 to 0. 3. 0\n    config_old and config_new should be dictionaries with the keys\n    and the values\n    should be dicts with the keys\n    regarding to MongoDB server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dict(cls, data, model):\n        model_provided = model is not None\n        result = {}\n        for name, new_value in data.items():\n            kwargs = {\n                'name': name,\n                'new_value': new_value,\n            }\n            if model_provided:\n                kwargs['params'] = model.get_field_params(name)\n            result[name] = cls(**kwargs)\n        return result", "response": "Generate a map of fieldName to clsInstance from dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self):\n        user, created = self.Model.create_account(\n            self._json_params)\n\n        if not created:\n            raise JHTTPConflict('Looks like you already have an account.')\n\n        self.request._user = user\n        pk_field = user.pk_field()\n        headers = remember(self.request, getattr(user, pk_field))\n        return JHTTPOk('Registered', headers=headers)", "response": "Register new user by POSTing all required data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self):\n        user, created = self.Model.create_account(self._json_params)\n        if user.api_key is None:\n            raise JHTTPBadRequest('Failed to generate ApiKey for user')\n\n        if not created:\n            raise JHTTPConflict('Looks like you already have an account.')\n\n        self.request._user = user\n        headers = remember(self.request, user.username)\n        return JHTTPOk('Registered', headers=headers)", "response": "Register a new user by POSTing all required data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef claim_token(self, **params):\n        self._json_params.update(params)\n        success, self.user = self.Model.authenticate_by_password(\n            self._json_params)\n\n        if success:\n            headers = remember(self.request, self.user.username)\n            return JHTTPOk('Token claimed', headers=headers)\n        if self.user:\n            raise JHTTPUnauthorized('Wrong login or password')\n        else:\n            raise JHTTPNotFound('User not found')", "response": "Claim current token by POSTing login and password."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset current token by POSTing login and password.", "response": "def reset_token(self, **params):\n        \"\"\" Reset current token by POSTing 'login' and 'password'.\n\n        User's `Authorization` header value is returned in `WWW-Authenticate`\n        header.\n        \"\"\"\n        response = self.claim_token(**params)\n        if not self.user:\n            return response\n\n        self.user.api_key.reset_token()\n        headers = remember(self.request, self.user.username)\n        return JHTTPOk('Registered', headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying privacy to nested documents.", "response": "def _apply_nested_privacy(self, data):\n        \"\"\" Apply privacy to nested documents.\n\n        :param data: Dict of data to which privacy is already applied.\n        \"\"\"\n        kw = {\n            'is_admin': self.is_admin,\n            'drop_hidden': self.drop_hidden,\n        }\n        for key, val in data.items():\n            if is_document(val):\n                data[key] = apply_privacy(self.request)(result=val, **kw)\n            elif isinstance(val, list) and val and is_document(val[0]):\n                data[key] = [apply_privacy(self.request)(result=doc, **kw)\n                             for doc in val]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_object_self(self, obj):\n        from nefertari.elasticsearch import ES\n        location = self.request.path_url\n        route_kwargs = {}\n\n        \"\"\" Check for parents \"\"\"\n        if self.request.matchdict:\n            route_kwargs.update(self.request.matchdict)\n        try:\n            type_, obj_pk = obj['_type'], obj['_pk']\n        except KeyError:\n            return\n        resource = (self.model_collections.get(type_) or\n                    self.model_collections.get(ES.src2type(type_)))\n        if resource is not None:\n            route_kwargs.update({resource.id_name: obj_pk})\n            location = self.request.route_url(\n                resource.uid, **route_kwargs)\n        obj.setdefault('_self', location)", "response": "Add _self key value to obj."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the root resource.", "response": "def get_root_resource(config):\n    \"\"\"Returns the root resource.\"\"\"\n    app_package_name = get_app_package_name(config)\n    return config.registry._root_resources.setdefault(\n        app_package_name, Resource(config))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_resource_routes(config, view, member_name, collection_name, **kwargs):\n\n    view = maybe_dotted(view)\n    path_prefix = kwargs.pop('path_prefix', '')\n    name_prefix = kwargs.pop('name_prefix', '')\n\n    if config.route_prefix:\n        name_prefix = \"%s_%s\" % (config.route_prefix, name_prefix)\n\n    if collection_name:\n        id_name = '/{%s}' % (kwargs.pop('id_name', None) or DEFAULT_ID_NAME)\n    else:\n        id_name = ''\n\n    path = path_prefix.strip('/') + '/' + (collection_name or member_name)\n\n    _factory = kwargs.pop('factory', None)\n    # If factory is not set, than auth should be False\n    _auth = kwargs.pop('auth', None) and _factory\n    _traverse = (kwargs.pop('traverse', None) or id_name) if _factory else None\n\n    action_route = {}\n    added_routes = {}\n\n    def add_route_and_view(config, action, route_name, path, request_method,\n                           **route_kwargs):\n        if route_name not in added_routes:\n            config.add_route(\n                route_name, path, factory=_factory,\n                request_method=['GET', 'POST', 'PUT', 'PATCH', 'DELETE',\n                                'OPTIONS'],\n                **route_kwargs)\n            added_routes[route_name] = path\n\n        action_route[action] = route_name\n\n        if _auth:\n            permission = PERMISSIONS[action]\n        else:\n            permission = None\n        config.add_view(view=view, attr=action, route_name=route_name,\n                        request_method=request_method,\n                        permission=permission,\n                        **kwargs)\n        config.commit()\n\n    if collection_name == member_name:\n        collection_name = collection_name + '_collection'\n\n    if collection_name:\n        add_route_and_view(\n            config, 'index', name_prefix + collection_name, path,\n            'GET')\n\n        add_route_and_view(\n            config, 'collection_options', name_prefix + collection_name, path,\n            'OPTIONS')\n\n    add_route_and_view(\n        config, 'show', name_prefix + member_name, path + id_name,\n        'GET', traverse=_traverse)\n\n    add_route_and_view(\n        config, 'item_options', name_prefix + member_name, path + id_name,\n        'OPTIONS', traverse=_traverse)\n\n    add_route_and_view(\n        config, 'replace', name_prefix + member_name, path + id_name,\n        'PUT', traverse=_traverse)\n\n    add_route_and_view(\n        config, 'update', name_prefix + member_name, path + id_name,\n        'PATCH', traverse=_traverse)\n\n    add_route_and_view(\n        config, 'create', name_prefix + (collection_name or member_name), path,\n        'POST')\n\n    add_route_and_view(\n        config, 'delete', name_prefix + member_name, path + id_name,\n        'DELETE', traverse=_traverse)\n\n    if collection_name:\n        add_route_and_view(\n            config, 'update_many',\n            name_prefix + (collection_name or member_name),\n            path, 'PUT', traverse=_traverse)\n\n        add_route_and_view(\n            config, 'update_many',\n            name_prefix + (collection_name or member_name),\n            path, 'PATCH', traverse=_traverse)\n\n        add_route_and_view(\n            config, 'delete_many',\n            name_prefix + (collection_name or member_name),\n            path, 'DELETE', traverse=_traverse)\n\n    return action_route", "response": "Add routes to the resource collection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_default_view_path(resource):\n    \"Returns the dotted path to the default view class.\"\n\n    parts = [a.member_name for a in resource.ancestors] +\\\n            [resource.collection_name or resource.member_name]\n\n    if resource.prefix:\n        parts.insert(-1, resource.prefix)\n\n    view_file = '%s' % '_'.join(parts)\n    view = '%s:%sView' % (view_file, snake2camel(view_file))\n\n    app_package_name = get_app_package_name(resource.config)\n    return '%s.views.%s' % (app_package_name, view)", "response": "Returns the dotted path to the default view class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ancestors(self):\n        \"Returns the list of ancestor resources.\"\n\n        if self._ancestors:\n            return self._ancestors\n\n        if not self.parent:\n            return []\n\n        obj = self.resource_map.get(self.parent.uid)\n\n        while obj and obj.member_name:\n            self._ancestors.append(obj)\n            obj = obj.parent\n\n        self._ancestors.reverse()\n        return self._ancestors", "response": "Returns the list of ancestor resources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new resource to the resource map.", "response": "def add(self, member_name, collection_name='', parent=None, uid='',\n            **kwargs):\n        \"\"\"\n        :param member_name: singular name of the resource. It should be the\n            appropriate singular version of the resource given your locale\n            and used with members of the collection.\n\n        :param collection_name: plural name of the resource. It will be used\n            to refer to the resource collection methods and should be a\n            plural version of the ``member_name`` argument.\n            Note: if collection_name is empty, it means resource is singular\n\n        :param parent: parent resource name or object.\n\n        :param uid: unique name for the resource\n\n        :param kwargs:\n            view: custom view to overwrite the default one.\n            the rest of the keyward arguments are passed to\n            add_resource_routes call.\n\n        :return: ResourceMap object\n        \"\"\"\n        # self is the parent resource on which this method is called.\n        parent = (self.resource_map.get(parent) if type(parent)\n                  is str else parent or self)\n\n        prefix = kwargs.pop('prefix', '')\n\n        uid = (uid or\n               ':'.join(filter(bool, [parent.uid, prefix, member_name])))\n\n        if uid in self.resource_map:\n            raise ValueError('%s already exists in resource map' % uid)\n\n        # Use id_name of parent for singular views to make url generation\n        # easier\n        id_name = kwargs.get('id_name', '')\n        if not id_name and parent:\n            id_name = parent.id_name\n\n        new_resource = Resource(self.config, member_name=member_name,\n                                collection_name=collection_name,\n                                parent=parent, uid=uid,\n                                id_name=id_name,\n                                prefix=prefix)\n\n        view = maybe_dotted(\n            kwargs.pop('view', None) or get_default_view_path(new_resource))\n\n        for name, val in kwargs.pop('view_args', {}).items():\n            setattr(view, name, val)\n\n        root_resource = self.config.get_root_resource()\n\n        view.root_resource = root_resource\n        new_resource.view = view\n        path_segs = []\n        kwargs['path_prefix'] = ''\n\n        for res in new_resource.ancestors:\n            if not res.is_singular:\n                if res.id_name:\n                    id_full = res.id_name\n                else:\n                    id_full = \"%s_%s\" % (res.member_name, DEFAULT_ID_NAME)\n\n                path_segs.append('%s/{%s}' % (res.collection_name, id_full))\n            else:\n                path_segs.append(res.member_name)\n\n        if path_segs:\n            kwargs['path_prefix'] = '/'.join(path_segs)\n\n        if prefix:\n            kwargs['path_prefix'] += '/' + prefix\n\n        name_segs = [a.member_name for a in new_resource.ancestors]\n        name_segs.insert(1, prefix)\n        name_segs = [seg for seg in name_segs if seg]\n        if name_segs:\n            kwargs['name_prefix'] = '_'.join(name_segs) + ':'\n\n        new_resource.renderer = kwargs.setdefault(\n            'renderer', view._default_renderer)\n\n        kwargs.setdefault('auth', root_resource.auth)\n        kwargs.setdefault('factory', root_resource.default_factory)\n        _factory = maybe_dotted(kwargs['factory'])\n\n        kwargs['auth'] = kwargs.get('auth', root_resource.auth)\n\n        kwargs['http_cache'] = kwargs.get(\n            'http_cache', root_resource.http_cache)\n\n        new_resource.action_route_map = add_resource_routes(\n            self.config, view, member_name, collection_name,\n            **kwargs)\n\n        self.resource_map[uid] = new_resource\n        # add all route names for this resource as keys in the dict,\n        # so its easy to find it in the view.\n        self.resource_map.update(dict.fromkeys(\n            list(new_resource.action_route_map.values()),\n            new_resource))\n\n        # Store resources in {modelName: resource} map if:\n        #   * Its view has Model defined\n        #   * It's not singular\n        #   * Its parent is root or it's not already stored\n        model = new_resource.view.Model\n        is_collection = model is not None and not new_resource.is_singular\n        if is_collection:\n            is_needed = (model.__name__ not in self.model_collections or\n                         new_resource.parent is root_resource)\n            if is_needed:\n                self.model_collections[model.__name__] = new_resource\n\n        parent.children.append(new_resource)\n        view._resource = new_resource\n        view._factory = _factory\n\n        return new_resource"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_from_child(self, resource, **kwargs):\n\n        new_resource = self.add(\n            resource.member_name, resource.collection_name, **kwargs)\n        for child in resource.children:\n            new_resource.add_from_child(child, **kwargs)", "response": "Add a resource with its all children resources to the current\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, path):\n        name_with_ext = os.path.split(path)[1]  # split directory and filename\n        name = name_with_ext.split('.')[0]  # remove extension\n        self.list.update({name: path})", "response": "Adds the path of a data set to the list of available sets\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nunpacks a data set to a Pandas DataFrame containing only the available datasets.", "response": "def unpack(self, name):\n        \"\"\"\n        Unpacks a data set to a Pandas DataFrame\n\n        Parameters\n        ----------\n        name : str\n            call `.list` to see all availble datasets\n\n        Returns\n        -------\n        pd.DataFrame\n        \"\"\"\n        path = self.list[name]\n        df = pd.read_pickle(path, compression='gzip')\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating each sequence into six reading frames", "response": "def six_frame(genome, table, minimum = 10):\n    \"\"\"\n    translate each sequence into six reading frames\n    \"\"\"\n    for seq in parse_fasta(genome):\n        dna = Seq(seq[1].upper().replace('U', 'T'), IUPAC.ambiguous_dna)\n        counter = 0\n        for sequence in ['f', dna], ['rc', dna.reverse_complement()]:\n            direction, sequence = sequence\n            for frame in range(0, 3):\n                for prot in \\\n                            sequence[frame:].\\\n                            translate(table = table, to_stop = False).split('*'):\n                    if len(prot) < minimum:\n                        continue\n                    counter += 1\n                    header = '%s_%s table=%s frame=%s-%s %s' % \\\n                                (seq[0].split()[0], counter, table, frame+1, \\\n                                direction, ' '.join(seq[0].split()[1:]))\n                    yield [header, prot]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef publish_processed_network_packets(\n        name=\"not-set\",\n        task_queue=None,\n        result_queue=None,\n        need_response=False,\n        shutdown_msg=\"SHUTDOWN\"):\n\n    \"\"\"\n    # Redis/RabbitMQ/SQS messaging endpoints for pub-sub\n    routing_key = ev(\"PUBLISH_EXCHANGE\",\n                     \"reporting.accounts\")\n    queue_name = ev(\"PUBLISH_QUEUE\",\n                    \"reporting.accounts\")\n    auth_url = ev(\"PUB_BROKER_URL\",\n                  \"redis://localhost:6379/15\")\n    serializer = \"json\"\n    \"\"\"\n\n    # these keys need to be cycled to prevent\n    # exploiting static keys\n    filter_key = ev(\"IGNORE_KEY\",\n                    INCLUDED_IGNORE_KEY)\n\n    forward_host = ev(\"FORWARD_HOST\", \"127.0.0.1\")\n    forward_port = int(ev(\"FORWARD_PORT\", \"80\"))\n    include_filter_key = ev(\"FILTER_KEY\", \"\")\n    if not include_filter_key and filter_key:\n        include_filter_key = filter_key\n\n    filter_keys = [filter_key]\n\n    log.info((\"START consumer={} \"\n              \"forward={}:{} with \"\n              \"key={} filters={}\")\n             .format(name,\n                     forward_host,\n                     forward_port,\n                     include_filter_key,\n                     filter_key))\n\n    forward_skt = None\n\n    not_done = True\n    while not_done:\n\n        if not forward_skt:\n            forward_skt = connect_forwarder(\n                            forward_host=forward_host,\n                            forward_port=forward_port)\n\n        next_task = task_queue.get()\n        if next_task:\n\n            if str(next_task) == shutdown_msg:\n                # Poison pill for shutting down\n                log.info((\"{}: DONE CALLBACK \"\n                          \"Exiting msg={}\")\n                         .format(name,\n                                 next_task))\n                task_queue.task_done()\n                break\n            # end of handling shutdown case\n\n            try:\n                log.debug((\"{} parsing\")\n                          .format(name))\n\n                source = next_task.source\n                packet = next_task.payload\n\n                if not packet:\n                    log.error((\"{} invalid task found \"\n                               \"{} missing payload\")\n                              .format(name,\n                                      next_task))\n                    break\n\n                log.debug((\"{} found msg from src={}\")\n                          .format(name,\n                                  source))\n\n                network_data = parse_network_data(\n                                  data_packet=packet,\n                                  include_filter_key=include_filter_key,\n                                  filter_keys=filter_keys)\n\n                if network_data[\"status\"] == VALID:\n                    if network_data[\"data_type\"] == TCP \\\n                        or network_data[\"data_type\"] == UDP \\\n                            or network_data[\"data_type\"] == ARP \\\n                            or network_data[\"data_type\"] == ICMP:\n\n                        log.info((\"{} valid={} packet={} \"\n                                  \"data={}\")\n                                 .format(name,\n                                         network_data[\"id\"],\n                                         network_data[\"data_type\"],\n                                         network_data[\"target_data\"]))\n\n                        if not forward_skt:\n                            forward_skt = connect_forwarder(\n                                            forward_host=forward_host,\n                                            forward_port=forward_port)\n\n                        if forward_skt:\n                            if network_data[\"stream\"]:\n\n                                sent = False\n                                while not sent:\n                                    try:\n                                        log.info(\"sending={}\".format(\n                                            network_data[\"stream\"]))\n                                        send_msg(\n                                            forward_skt,\n                                            network_data[\"stream\"]\n                                            .encode(\"utf-8\"))\n                                        sent = True\n                                    except Exception as e:\n                                        sent = False\n                                        time.sleep(0.5)\n                                        try:\n                                            forward_skt.close()\n                                            forward_skt = None\n                                        except Exception as w:\n                                            forward_skt = None\n                                        forward_skt = connect_forwarder(\n                                            forward_host=forward_host,\n                                            forward_port=forward_port)\n                                # end of reconnecting\n\n                                log.info(\"sent={}\".format(\n                                    network_data[\"stream\"]))\n\n                                if need_response:\n                                    log.info(\"receiving\")\n                                    cdr_res = forward_skt.recv(1024)\n                                    log.info((\"cdr - res{}\")\n                                             .format(cdr_res))\n                            else:\n                                log.info((\"{} EMPTY stream={} \"\n                                          \"error={} status={}\")\n                                         .format(\n                                            name,\n                                            network_data[\"stream\"],\n                                            network_data[\"err\"],\n                                            network_data[\"status\"]))\n                    else:\n                        log.info((\"{} not_supported valid={} \"\n                                  \"packet data_type={} status={}\")\n                                 .format(name,\n                                         network_data[\"id\"],\n                                         network_data[\"data_type\"],\n                                         network_data[\"status\"]))\n                elif network_data[\"status\"] == FILTERED:\n                    log.info((\"{} filtered={} status={}\")\n                             .format(name,\n                                     network_data[\"filtered\"],\n                                     network_data[\"status\"]))\n                else:\n                    if network_data[\"status\"] == INVALID:\n                        log.info((\"{} invalid={} packet={} \"\n                                  \"error={} status={}\")\n                                 .format(name,\n                                         network_data[\"id\"],\n                                         network_data[\"data_type\"],\n                                         network_data[\"error\"],\n                                         network_data[\"status\"]))\n                    else:\n                        log.info((\"{} unknown={} packet={} \"\n                                  \"error={} status={}\")\n                                 .format(name,\n                                         network_data[\"id\"],\n                                         network_data[\"data_type\"],\n                                         network_data[\"error\"],\n                                         network_data[\"status\"]))\n                # end of if valid or not data\n            except KeyboardInterrupt as k:\n                log.info((\"{} stopping\")\n                         .format(name))\n                break\n            except Exception as e:\n                log.error((\"{} failed packaging packet to forward \"\n                           \"with ex={}\")\n                          .format(name,\n                                  e))\n                break\n            # end of try/ex during payload processing\n        # end of if found a next_task\n\n        log.info((\"Consumer: {} {}\")\n                 .format(name, next_task))\n        task_queue.task_done()\n\n        if need_response:\n            answer = \"processed: {}\".format(next_task())\n            result_queue.put(answer)\n    # end of while\n\n    if forward_skt:\n        try:\n            forward_skt.close()\n            log.info(\"CLOSED connection\")\n            forward_skt = None\n        except Exception:\n            log.info(\"CLOSED connection\")\n    # end of cleaning up forwarding socket\n\n    log.info(\"{} Done\".format(name))\n\n    return", "response": "Publish all network packets and return a list of the messages that were processed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the packet processor and the packet consumers", "response": "def run_main(\n        need_response=False,\n        callback=None):\n    \"\"\"run_main\n\n    start the packet consumers and the packet processors\n\n    :param need_response: should send response back to publisher\n    :param callback: handler method\n    \"\"\"\n\n    stop_file = ev(\"STOP_FILE\",\n                   \"/opt/stop_recording\")\n\n    num_workers = int(ev(\"NUM_WORKERS\",\n                         \"1\"))\n    shutdown_msg = \"SHUTDOWN\"\n\n    log.info(\"Start - {}\".format(name))\n\n    log.info(\"Creating multiprocessing queue\")\n    tasks = multiprocessing.JoinableQueue()\n    queue_to_consume = multiprocessing.Queue()\n    host = \"localhost\"\n\n    # Start consumers\n    log.info(\"Starting Consumers to process queued tasks\")\n    consumers = start_consumers_for_queue(\n        num_workers=num_workers,\n        tasks=tasks,\n        queue_to_consume=queue_to_consume,\n        shutdown_msg=shutdown_msg,\n        consumer_class=WorkerToProcessPackets,\n        callback=callback)\n\n    log.info(\"creating socket\")\n    skt = create_layer_2_socket()\n    log.info(\"socket created\")\n\n    not_done = True\n    while not_done:\n\n        if not skt:\n            log.info(\"Failed to create layer 2 socket\")\n            log.info(\"Please make sure to run as root\")\n            not_done = False\n            break\n\n        try:\n            if os.path.exists(stop_file):\n                log.info((\"Detected stop_file={}\")\n                         .format(stop_file))\n                not_done = False\n                break\n            # stop if the file exists\n\n            # Only works on linux\n            packet = skt.recvfrom(65565)\n\n            if os.path.exists(stop_file):\n                log.info((\"Detected stop_file={}\")\n                         .format(stop_file))\n                not_done = False\n                break\n            # stop if the file was created during a wait loop\n\n            tasks.put(NetworkPacketTask(source=host,\n                                        payload=packet))\n\n        except KeyboardInterrupt as k:\n            log.info(\"Stopping\")\n            not_done = False\n            break\n        except Exception as e:\n            log.error((\"Failed reading socket with ex={}\")\n                      .format(e))\n            not_done = False\n            break\n        # end of try/ex during socket receving\n\n    # end of while processing network packets\n\n    log.info((\"Shutting down consumers={}\")\n             .format(len(consumers)))\n\n    shutdown_consumers(num_workers=num_workers,\n                       tasks=tasks)\n\n    # Wait for all of the tasks to finish\n    if need_response:\n        log.info(\"Waiting for tasks to finish\")\n        tasks.join()\n\n    log.info(\"Done waiting for tasks to finish\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef best_model(seq2hmm):\n    for seq in seq2hmm:\n        best = []\n        for model in seq2hmm[seq]:\n            best.append([model, sorted([i[-1] for i in seq2hmm[seq][model]], reverse = True)[0]])\n        best_model = sorted(best, key = itemgetter(1), reverse = True)[0][0]\n        seq2hmm[seq] = [best_model] + [seq2hmm[seq][best_model]]\n    return seq2hmm", "response": "determine the best model for each sequence in the sequence2hmm"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_gaps(matches, gap_threshold = 0):\n    gaps = []\n    prev = None\n    for match in sorted(matches, key = itemgetter(0)):\n        if prev is None:\n            prev = match\n            continue\n        if match[0] - prev[1] >= gap_threshold:\n            gaps.append([prev, match])\n            prev = match\n    return [[i[0][1], i[1][0]] for i in gaps]", "response": "check for large gaps between alignment windows\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if sequence has already hit the same part of the model", "response": "def check_overlap(current, hit, overlap = 200):\n    \"\"\"\n    determine if sequence has already hit the same part of the model,\n    indicating that this hit is for another 16S rRNA gene\n    \"\"\"\n    for prev in current:\n        p_coords = prev[2:4]\n        coords = hit[2:4]\n        if get_overlap(coords, p_coords) >= overlap:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the hits are in the order of the current sequence", "response": "def check_order(current, hit, overlap = 200):\n    \"\"\"\n    determine if hits are sequential on model and on the\n    same strand\n        * if not, they should be split into different groups\n    \"\"\"\n    prev_model = current[-1][2:4]\n    prev_strand = current[-1][-2]\n    hit_model = hit[2:4]\n    hit_strand = hit[-2]\n    # make sure they are on the same strand\n    if prev_strand != hit_strand:\n        return False\n    # check for sequential hits on + strand\n    if prev_strand == '+' and (prev_model[1] - hit_model[0] >= overlap):\n        return False\n    # check for sequential hits on - strand\n    if prev_strand == '-' and (hit_model[1] - prev_model[0] >= overlap):\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hit_groups(hits):\n    groups = []\n    current = False\n    for hit in sorted(hits, key = itemgetter(0)):\n        if current is False:\n            current = [hit]\n        elif check_overlap(current, hit) is True or check_order(current, hit) is False:\n            groups.append(current)\n            current = [hit]\n        else:\n            current.append(hit)\n    groups.append(current)\n    return groups", "response": "Returns a list of groups that are hit by each sequence"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget info from ssu - cmsearch output", "response": "def get_info(line, bit_thresh):\n    \"\"\"\n    get info from either ssu-cmsearch or cmsearch output\n    \"\"\"\n    if len(line) >= 18: # output is from cmsearch\n        id, model, bit, inc = line[0].split()[0], line[2], float(line[14]), line[16]\n        sstart, send, strand = int(line[7]), int(line[8]), line[9]\n        mstart, mend = int(line[5]), int(line[6])\n    elif len(line) == 9: # output is from ssu-cmsearch\n        if bit_thresh == 0:\n            print('# ssu-cmsearch does not include a model-specific inclusion threshold, ', file=sys.stderr)\n            print('# please specify a bit score threshold', file=sys.stderr)\n            exit()\n        id, model, bit = line[1].split()[0], line[0], float(line[6])\n        inc = '!' # this is not a feature of ssu-cmsearch\n        sstart, send = int(line[2]), int(line[3])\n        mstart, mend = int(4), int(5)\n        if send >= sstart:\n            strand = '+'\n        else:\n            strand = '-'\n    else:\n        print('# unsupported hmm format:', file=sys.stderr)\n        print('# provide tabular output from ssu-cmsearch and cmsearch supported', file=sys.stderr)\n        exit()\n    coords = [sstart, send]\n    sstart, send = min(coords), max(coords)\n    mcoords = [mstart, mend]\n    mstart, mend = min(mcoords), max(mcoords)\n    return id, model, bit, sstart, send, mstart, mend, strand, inc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_buffer(coords, length, buffer):\n    s = min(coords[0], buffer)\n    e = min(length - coords[1], buffer)\n    return [s, e]", "response": "check to see how much of the buffer is being used"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a parser to a new type.", "response": "def convert_parser_to(parser, parser_or_type, metadata_props=None):\n    \"\"\"\n    :return: a parser of type parser_or_type, initialized with the properties of parser. If parser_or_type\n    is a type, an instance of it must contain a update method. The update method must also process\n    the set of properties supported by MetadataParser for the conversion to have any affect.\n    :param parser: the parser (or content or parser type) to convert to new_type\n    :param parser_or_type: a parser (or content) or type of parser to return\n    :see: get_metadata_parser(metadata_container) for more on how parser_or_type is treated\n    \"\"\"\n\n    old_parser = parser if isinstance(parser, MetadataParser) else get_metadata_parser(parser)\n    new_parser = get_metadata_parser(parser_or_type)\n\n    for prop in (metadata_props or _supported_props):\n        setattr(new_parser, prop, deepcopy(getattr(old_parser, prop, u'')))\n\n    new_parser.update()\n\n    return new_parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_metadata_parser(metadata_container, **metadata_defaults):\n\n    parser_type = None\n\n    if isinstance(metadata_container, MetadataParser):\n        parser_type = type(metadata_container)\n\n    elif isinstance(metadata_container, type):\n        parser_type = metadata_container\n        metadata_container = metadata_container().update(**metadata_defaults)\n\n    xml_root, xml_tree = get_parsed_content(metadata_container)\n\n    # The get_parsed_content method ensures only these roots will be returned\n\n    parser = None\n\n    if parser_type is not None:\n        parser = parser_type(xml_tree, **metadata_defaults)\n    elif xml_root in ISO_ROOTS:\n        parser = IsoParser(xml_tree, **metadata_defaults)\n    else:\n        has_arcgis_data = any(element_exists(xml_tree, e) for e in ARCGIS_NODES)\n\n        if xml_root == FGDC_ROOT and not has_arcgis_data:\n            parser = FgdcParser(xml_tree, **metadata_defaults)\n        elif xml_root in ARCGIS_ROOTS:\n            parser = ArcGISParser(xml_tree, **metadata_defaults)\n\n    return parser", "response": "Returns a new instance of a MetadataParser class corresponding to the standard represented by the given metadata_container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing any of the types of content and returns the XML root and XML Tree parsed by and compatible with element_utils.", "response": "def get_parsed_content(metadata_content):\n    \"\"\"\n    Parses any of the following types of content:\n    1. XML string or file object: parses XML content\n    2. MetadataParser instance: deep copies xml_tree\n    3. Dictionary with nested objects containing:\n        - name (required): the name of the element tag\n        - text: the text contained by element\n        - tail: text immediately following the element\n        - attributes: a Dictionary containing element attributes\n        - children: a List of converted child elements\n\n    :raises InvalidContent: if the XML is invalid or does not conform to a supported metadata standard\n    :raises NoContent: If the content passed in is null or otherwise empty\n\n    :return: the XML root along with an XML Tree parsed by and compatible with element_utils\n    \"\"\"\n\n    _import_parsers()  # Prevents circular dependencies between modules\n\n    xml_tree = None\n\n    if metadata_content is None:\n        raise NoContent('Metadata has no data')\n    else:\n        if isinstance(metadata_content, MetadataParser):\n            xml_tree = deepcopy(metadata_content._xml_tree)\n        elif isinstance(metadata_content, dict):\n            xml_tree = get_element_tree(metadata_content)\n        else:\n            try:\n                # Strip name spaces from file or XML content\n                xml_tree = get_element_tree(metadata_content)\n            except Exception:\n                xml_tree = None  # Several exceptions possible, outcome is the same\n\n    if xml_tree is None:\n        raise InvalidContent(\n            'Cannot instantiate a {parser_type} parser with invalid content to parse',\n            parser_type=type(metadata_content).__name__\n        )\n\n    xml_root = get_element_name(xml_tree)\n\n    if xml_root is None:\n        raise NoContent('Metadata contains no data')\n    elif xml_root not in VALID_ROOTS:\n        content = type(metadata_content).__name__\n        raise InvalidContent('Invalid root element for {content}: {xml_root}', content=content, xml_root=xml_root)\n\n    return xml_root, xml_tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _import_parsers():\n\n    global ARCGIS_NODES\n    global ARCGIS_ROOTS\n    global ArcGISParser\n\n    global FGDC_ROOT\n    global FgdcParser\n\n    global ISO_ROOTS\n    global IsoParser\n\n    global VALID_ROOTS\n\n    if ARCGIS_NODES is None or ARCGIS_ROOTS is None or ArcGISParser is None:\n        from gis_metadata.arcgis_metadata_parser import ARCGIS_NODES\n        from gis_metadata.arcgis_metadata_parser import ARCGIS_ROOTS\n        from gis_metadata.arcgis_metadata_parser import ArcGISParser\n\n    if FGDC_ROOT is None or FgdcParser is None:\n        from gis_metadata.fgdc_metadata_parser import FGDC_ROOT\n        from gis_metadata.fgdc_metadata_parser import FgdcParser\n\n    if ISO_ROOTS is None or IsoParser is None:\n        from gis_metadata.iso_metadata_parser import ISO_ROOTS\n        from gis_metadata.iso_metadata_parser import IsoParser\n\n    if VALID_ROOTS is None:\n        VALID_ROOTS = {FGDC_ROOT}.union(ARCGIS_ROOTS + ISO_ROOTS)", "response": "Lazy imports to prevent circular dependencies between this module and utils"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the data map for this object.", "response": "def _init_data_map(self):\n        \"\"\" Default data map initialization: MUST be overridden in children \"\"\"\n\n        if self._data_map is None:\n            self._data_map = {'_root': None}\n            self._data_map.update({}.fromkeys(self._metadata_props))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the xml tree for the template.", "response": "def _get_template(self, root=None, **metadata_defaults):\n        \"\"\" Iterate over items metadata_defaults {prop: val, ...} to populate template \"\"\"\n\n        if root is None:\n            if self._data_map is None:\n                self._init_data_map()\n\n            root = self._xml_root = self._data_map['_root']\n\n        template_tree = self._xml_tree = create_element_tree(root)\n\n        for prop, val in iteritems(metadata_defaults):\n            path = self._data_map.get(prop)\n            if path and val:\n                setattr(self, prop, val)\n                update_property(template_tree, None, path, prop, val)\n\n        return template_tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the xpath for a given property", "response": "def _get_xpath_for(self, prop):\n        \"\"\" :return: the configured xpath for a given property \"\"\"\n\n        xpath = self._data_map.get(prop)\n        return getattr(xpath, 'xpath', xpath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_complex(self, prop):\n\n        xpath_root = None\n        xpath_map = self._data_structures[prop]\n\n        return parse_complex(self._xml_tree, xpath_root, xpath_map, prop)", "response": "Default parsing operation for a complex struct"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefaulting parsing operation for lists of complex structs", "response": "def _parse_complex_list(self, prop):\n        \"\"\" Default parsing operation for lists of complex structs \"\"\"\n\n        xpath_root = self._get_xroot_for(prop)\n        xpath_map = self._data_structures[prop]\n\n        return parse_complex_list(self._xml_tree, xpath_root, xpath_map, prop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and returns a Date Types data structure parsed from the metadata", "response": "def _parse_dates(self, prop=DATES):\n        \"\"\" Creates and returns a Date Types data structure parsed from the metadata \"\"\"\n\n        return parse_dates(self._xml_tree, self._data_structures[prop])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefaults update operation for a complex struct", "response": "def _update_complex(self, **update_props):\n        \"\"\" Default update operation for a complex struct \"\"\"\n\n        prop = update_props['prop']\n        xpath_root = self._get_xroot_for(prop)\n        xpath_map = self._data_structures[prop]\n\n        return update_complex(xpath_root=xpath_root, xpath_map=xpath_map, **update_props)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_complex_list(self, **update_props):\n\n        prop = update_props['prop']\n        xpath_root = self._get_xroot_for(prop)\n        xpath_map = self._data_structures[prop]\n\n        return update_complex_list(xpath_root=xpath_root, xpath_map=xpath_map, **update_props)", "response": "Default update operation for lists of complex structs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_dates(self, xpath_root=None, **update_props):\n\n        tree_to_update = update_props['tree_to_update']\n        prop = update_props['prop']\n        values = (update_props['values'] or {}).get(DATE_VALUES) or u''\n        xpaths = self._data_structures[prop]\n\n        if not self.dates:\n            date_xpaths = xpath_root\n        elif self.dates[DATE_TYPE] != DATE_TYPE_RANGE:\n            date_xpaths = xpaths.get(self.dates[DATE_TYPE], u'')\n        else:\n            date_xpaths = [\n                xpaths[DATE_TYPE_RANGE_BEGIN],\n                xpaths[DATE_TYPE_RANGE_END]\n            ]\n\n        if xpath_root:\n            remove_element(tree_to_update, xpath_root)\n\n        return update_property(tree_to_update, xpath_root, date_xpaths, prop, values)", "response": "Update the dates property of the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, use_template=False, out_file_or_path=None, encoding=DEFAULT_ENCODING):\n\n        if not out_file_or_path:\n            out_file_or_path = self.out_file_or_path\n\n        if not out_file_or_path:\n            # FileNotFoundError doesn't exist in Python 2\n            raise IOError('Output file path has not been provided')\n\n        write_element(self.update(use_template), out_file_or_path, encoding)", "response": "Updates an XML tree with the instance properties and writes the content to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefaults validation for updated properties", "response": "def validate(self):\n        \"\"\" Default validation for updated properties: MAY be overridden in children \"\"\"\n\n        validate_properties(self._data_map, self._metadata_props)\n\n        for prop in self._data_map:\n            validate_any(prop, getattr(self, prop), self._data_structures.get(prop))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch order of the given regexps", "response": "def _search_regex(ops: dict, regex_pat: str):\n    \"\"\"\n    Search order:\n      * specified regexps\n      * operators sorted from longer to shorter\n    \"\"\"\n    custom_regexps = list(filter(None, [dic['regex'] for op, dic in ops.items() if 'regex' in dic]))\n    op_names = [op for op, dic in ops.items() if 'regex' not in dic]\n    regex = [regex_pat.format(_ops_regex(op_names))] if len(op_names) > 0 else []\n    return re.compile('|'.join(custom_regexps + regex))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spec(self, postf_un_ops: str) -> list:\n        spec = [(l + op, {'pat': self.pat(pat),\n                          'postf': self.postf(r, postf_un_ops),\n                          'regex': None})\n                for op, pat in self.styles.items()\n                for l, r in self.brackets]\n        spec[0][1]['regex'] = self.regex_pat.format(\n            _ops_regex(l for l, r in self.brackets),\n            _ops_regex(self.styles.keys())\n        )\n        return spec", "response": "Return prefix unary operators list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning prefix unary operators list. Sets only one regex for all items in the dict.", "response": "def spec(self) -> list:\n        \"\"\"Returns prefix unary operators list.\n        Sets only one regex for all items in the dict.\"\"\"\n        spec = [item\n                for op, pat in self.ops.items()\n                for item in [('{' + op, {'pat': pat, 'postf': self.postf, 'regex': None}),\n                             ('\u02f1' + op, {'pat': pat, 'postf': self.postf, 'regex': None})]\n                ]\n        spec[0][1]['regex'] = self.regex_pat.format(_ops_regex(self.ops.keys()))\n        return spec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfilling the internal state of the internal state with the postf_un_ops.", "response": "def fill(self, postf_un_ops: str):\n        \"\"\"\n        Insert:\n          * math styles\n          * other styles\n          * unary prefix operators without brackets\n          * defaults\n        \"\"\"\n        for op, dic in self.ops.items():\n            if 'postf' not in dic:\n                dic['postf'] = self.postf\n        self.ops = OrderedDict(\n            self.styles.spec(postf_un_ops) +\n            self.other_styles.spec(postf_un_ops) +\n            self.pref_un_greedy.spec() +\n            list(self.ops.items())\n        )\n        for op, dic in self.ops.items():\n            dic['postf'] = re.compile(dic['postf'])\n        self.regex = _search_regex(self.ops, self.regex_pat)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns compiled regex and function for su_scripts.", "response": "def _su_scripts_regex(self):\n        \"\"\"\n        :return:\n            [compiled regex, function]\n        \"\"\"\n        sups = re.escape(''.join([k for k in self.superscripts.keys()]))\n        subs = re.escape(''.join([k for k in self.subscripts.keys()]))  # language=PythonRegExp\n        su_regex = (r'\\\\([{su_}])|([{sub}]+|\u2039[{sub}]+\u203a|\u02f9[{sub}]+\u02fa)' +\n                    r'|([{sup}]+)(?=\u221a)|([{sup}]+(?!\u221a)|\u2039[{sup}]+\u203a|\u02f9[{sup}]+\u02fa)').format(\n            su_=subs + sups, sub=subs, sup=sups)\n        su_regex = re.compile(su_regex)\n\n        def su_replace(m):\n            esc, sub, root_sup, sup = m.groups()\n            if esc is not None:\n                return esc\n            elif sub is not None:\n                return '_{' + ''.join([c if (c in ['\u2039', '\u203a', '\u02f9', '\u02fa']) else self.subscripts[c] for c in sub]) + '}'\n            elif root_sup is not None:\n                return ''.join([self.superscripts[c] for c in root_sup])\n            elif sup is not None:\n                return '^{' + ''.join([c if (c in ['\u2039', '\u203a', '\u02f9', '\u02fa']) else self.superscripts[c] for c in sup]) + '}'\n            else:\n                raise TypeError(\"Regex bug: this should never be reached\")\n\n        return [su_regex, su_replace]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _local_map(match, loc: str = 'lr') -> list:\n        s = match.string\n        map_ = [None] * (len(s) + 2)\n        if loc == 'l' or loc == 'lr':\n            balance = 0\n            for i in reversed(range(0, match.start())):\n                map_[i] = balance\n                c, prev = s[i], (s[i - 1] if i > 0 else '')\n                if (c == '}' or c == '\u02f2') and prev != '\\\\':\n                    balance += 1\n                elif (c == '{' or c == '\u02f1') and prev != '\\\\':\n                    balance -= 1\n                if balance < 0:\n                    break\n            map_[-1] = balance\n        if loc == 'r' or loc == 'lr':\n            balance = 0\n            for i in range(match.end(), len(s)):\n                map_[i] = balance\n                c, prev = s[i], s[i - 1]\n                if (c == '{' or c == '\u02f1') and prev != '\\\\':\n                    balance += 1\n                elif (c == '}' or c == '\u02f2') and prev != '\\\\':\n                    balance -= 1\n                if balance < 0:\n                    break\n            map_[len(s)] = balance\n        return map_", "response": "Returns a list of local map entries for loc."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing the operators in the string.", "response": "def _operators_replace(self, string: str) -> str:\n        \"\"\"\n        Searches for first unary or binary operator (via self.op_regex\n        that has only one group that contain operator)\n        then replaces it (or escapes it if brackets do not match).\n        Everything until:\n          * space ' '\n          * begin/end of the string\n          * bracket from outer scope (like '{a/b}': term1=a term2=b)\n        is considered a term (contents of matching brackets '{}' are\n        ignored).\n\n        Attributes\n        ----------\n        string: str\n            string to replace\n        \"\"\"\n        # noinspection PyShadowingNames\n        def replace(string: str, start: int, end: int, substring: str) -> str:\n            return string[0:start] + substring + string[end:len(string)]\n\n        # noinspection PyShadowingNames\n        def sub_pat(pat: Callable[[list], str] or str, terms: list) -> str:\n            if isinstance(pat, str):\n                return pat.format(*terms)\n            else:\n                return pat(terms)\n\n        count = 0\n\n        def check():\n            nonlocal count\n            count += 1\n            if count > self.max_while:\n                raise RuntimeError('Presumably while loop is stuck')\n\n        # noinspection PyShadowingNames\n        def null_replace(match) -> str:\n            regex_terms = [gr for gr in match.groups() if gr is not None]\n            op = regex_terms[0]\n            terms = regex_terms[1:]\n            return sub_pat(self.null_ops.ops[op]['pat'], terms)\n\n        string = self.null_ops.regex.sub(null_replace, string)\n\n        for ops, loc in [(self.pref_un_ops, 'r'), (self.postf_un_ops, 'l'),\n                         (self.bin_centr_ops, 'lr')]:\n            count = 0\n            match = ops.regex.search(string)\n            while match:\n                check()\n                regex_terms = [gr for gr in match.groups() if gr is not None]\n                op = regex_terms[0]\n                loc_map = self._local_map(match, loc)\n                lmatch, rmatch = None, None\n                if loc == 'l' or loc == 'lr':\n                    for m in ops.ops[op]['pref'].finditer(string):\n                        if m.end() <= match.start() and loc_map[m.end() - 1] == 0:\n                            lmatch = m\n                    if lmatch is None:\n                        string = replace(string, match.start(), match.end(), match.group(0).replace(op, '\\\\' + op))\n                        match = ops.regex.search(string)\n                        continue\n                    else:\n                        term1 = string[lmatch.end():match.start()]\n                if loc == 'r' or loc == 'lr':\n                    for m in ops.ops[op]['postf'].finditer(string):\n                        if m.start() >= match.end() and loc_map[m.start()] == 0:\n                            rmatch = m\n                            break\n                    if rmatch is None:\n                        string = replace(string, match.start(), match.end(), match.group(0).replace(op, '\\\\' + op))\n                        match = ops.regex.search(string)\n                        continue\n                    else:\n                        term2 = string[match.end():rmatch.start()]\n                if loc == 'l':\n                    # noinspection PyUnboundLocalVariable\n                    terms = list(lmatch.groups()) + [term1] + regex_terms[1:]\n                    start, end = lmatch.start(), match.end()\n                elif loc == 'r':\n                    # noinspection PyUnboundLocalVariable\n                    terms = regex_terms[1:] + [term2] + list(rmatch.groups())\n                    start, end = match.start(), rmatch.end()\n                elif loc == 'lr':\n                    terms = list(lmatch.groups()) + [term1] + regex_terms[1:] + [term2] + list(rmatch.groups())\n                    start, end = lmatch.start(), rmatch.end()\n                else:  # this never happen\n                    terms = regex_terms[1:]\n                    start, end = match.start(), match.end()\n\n                string = replace(string, start, end, sub_pat(ops.ops[op]['pat'], terms))\n                match = ops.regex.search(string)\n\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces LaTeX characters in src with new LaTeX characters.", "response": "def replace(self, src: str) -> str:\n        \"\"\"\n        Extends LaTeX syntax via regex preprocess\n        :param src: str\n            LaTeX string\n        :return: str\n            New LaTeX string\n        \"\"\"\n        if not self.readied:\n            self.ready()\n\n        # Brackets + simple pre replacements:\n        src = self._dict_replace(self.simple_pre, src)\n\n        # Superscripts and subscripts + pre regexps:\n        for regex, replace in self.regex_pre:\n            src = regex.sub(replace, src)\n\n        # Unary and binary operators:\n        src = self._operators_replace(src)\n\n        # Loop regexps:\n        src_prev = src\n        for i in range(self.max_iter):\n            for regex, replace in self.loop_regexps:\n                src = regex.sub(replace, src)\n            if src_prev == src:\n                break\n            else:\n                src_prev = src\n\n        # Post regexps:\n        for regex, replace in self.regex_post:\n            src = regex.sub(replace, src)\n\n        # Simple post replacements:\n        src = self._dict_replace(self.simple_post, src)\n\n        # Escape characters:\n        src = self.escapes_regex.sub(r'\\1', src)\n\n        return src"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_gaps(plot, columns):\n\tfrom plot_window import window_plot_convolve as plot_window\n#\tplot_window([columns], len(columns)*.01, plot)\n\tplot_window([[100 - i for i in columns]], len(columns)*.01, plot)", "response": "plot % of gaps at each position"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample_group(sid, groups):\n    for name in groups:\n        if sid in groups[name].sids:\n            return name", "response": "Return the name of the first category that contains the given SampleID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncombine multiple sets into a single set.", "response": "def combine_sets(*sets):\n    \"\"\"\n    Combine multiple sets to create a single larger set.\n    \"\"\"\n    combined = set()\n    for s in sets:\n        combined.update(s)\n    return combined"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unique_otuids(groups):\n    uniques = {key: set() for key in groups}\n    for i, group in enumerate(groups):\n        to_combine = groups.values()[:i]+groups.values()[i+1:]\n        combined = combine_sets(*to_combine)\n        uniques[group] = groups[group].difference(combined)\n    return uniques", "response": "Get unique OTUIDs of each category."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all OTUIDs shared between all unique combinations of groups.", "response": "def shared_otuids(groups):\n    \"\"\"\n    Get shared OTUIDs between all unique combinations of groups.\n\n    :type groups: Dict\n    :param groups: {Category name: OTUIDs in category}\n\n    :return type: dict\n    :return: Dict keyed on group combination and their shared OTUIDs as values.\n    \"\"\"\n    for g in sorted(groups):\n        print(\"Number of OTUs in {0}: {1}\".format(g, len(groups[g].results[\"otuids\"])))\n    number_of_categories = len(groups)\n    shared = defaultdict()\n    for i in range(2, number_of_categories+1):\n        for j in combinations(sorted(groups), i):\n            combo_name = \" & \".join(list(j))\n            for grp in j:\n                # initialize combo values\n                shared[combo_name] = groups[j[0]].results[\"otuids\"].copy()\n                \"\"\"iterate through all groups and keep updating combo OTUIDs with set\n                intersection_update\"\"\"\n                for grp in j[1:]:\n                    shared[combo_name].intersection_update(groups[grp].results[\"otuids\"])\n    return shared"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a path, the method writes out one file for each group name in the uniques dictionary with the file name in the pattern PATH/prefix_group.txt with each file containing the unique OTUIDs found when comparing that group to all the other groups in uniques. :type path: str :param path: Output files will be saved in this PATH. :type prefix: str :param prefix: Prefix name added in front of output filename. :type uniques: dict :param uniques: Output from unique_otus() function.", "response": "def write_uniques(path, prefix, uniques):\n    \"\"\"\n    Given a path, the method writes out one file for each group name in the\n    uniques dictionary with the file name in the pattern\n\n        PATH/prefix_group.txt\n\n    with each file containing the unique OTUIDs found when comparing that group\n    to all the other groups in uniques.\n\n    :type path: str\n    :param path: Output files will be saved in this PATH.\n\n    :type prefix: str\n    :param prefix: Prefix name added in front of output filename.\n\n    :type uniques: dict\n    :param uniques: Output from unique_otus() function.\n    \"\"\"\n    for group in uniques:\n        fp = osp.join(path, \"{}_{}.txt\".format(prefix, group))\n        with open(fp, \"w\") as outf:\n            outf.write(\"\\n\".join(uniques[group]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the records in a FASTA - format file into a list of tuples.", "response": "def storeFASTA(fastaFNH):\n    \"\"\"\n    Parse the records in a FASTA-format file by first reading the entire file into memory.\n\n    :type source: path to FAST file or open file handle\n    :param source: The data source from which to parse the FASTA records. Expects the\n                   input to resolve to a collection that can be iterated through, such as\n                   an open file handle.\n\n    :rtype: tuple\n    :return: FASTA records containing entries for id, description and data.\n    \"\"\"\n    fasta = file_handle(fastaFNH).read()\n    return [FASTARecord(rec[0].split()[0], rec[0].split(None, 1)[1], \"\".join(rec[1:]))\n            for rec in (x.strip().split(\"\\n\") for x in fasta.split(\">\")[1:])]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the records in a FASTA - format file keeping the file open and reading through .", "response": "def parseFASTA(fastaFNH):\n    \"\"\"\n    Parse the records in a FASTA-format file keeping the file open, and reading through\n    one line at a time.\n\n    :type source: path to FAST file or open file handle\n    :param source: The data source from which to parse the FASTA records.\n                   Expects the input to resolve to a collection that can be iterated\n                   through, such as an open file handle.\n\n    :rtype: tuple\n    :return: FASTA records containing entries for id, description and data.\n    \"\"\"\n    recs = []\n    seq = []\n    seqID = \"\"\n    descr = \"\"\n\n    for line in file_handle(fastaFNH):\n        line = line.strip()\n        if line[0] == \";\":\n            continue\n        if line[0] == \">\":\n            # conclude previous record\n            if seq:\n                recs.append(FASTARecord(seqID, descr, \"\".join(seq)))\n                seq = []\n            # start new record\n            line = line[1:].split(None, 1)\n            seqID, descr = line[0], line[1]\n        else:\n            seq.append(line)\n\n    # catch last seq in file\n    if seq:\n        recs.append(FASTARecord(seqID, descr, \"\".join(seq)))\n    return recs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the contents of a QIIME mapping file and returns a dictionary keyed on SampleID BarcodeSequence LinkerPrimerSequence State Rat_Oral .", "response": "def parse_map_file(mapFNH):\n    \"\"\"\n    Opens a QIIME mapping file and stores the contents in a dictionary keyed on SampleID\n    (default) or a user-supplied one. The only required fields are SampleID,\n    BarcodeSequence, LinkerPrimerSequence (in that order), and Description\n    (which must be the final field).\n\n    :type mapFNH: str\n    :param mapFNH: Either the full path to the map file or an open file handle\n\n    :rtype: tuple, dict\n    :return: A tuple of header line for mapping file and a map associating each line of\n             the mapping file with the appropriate sample ID (each value of the map also\n             contains the sample ID). An OrderedDict is used for mapping so the returned\n             map is guaranteed to have the same order as the input file.\n\n    Example data:\n    #SampleID BarcodeSequence LinkerPrimerSequence State   Description\n    11.V13    ACGCTCGACA      GTTTGATCCTGGCTCAG    Disease Rat_Oral\n    \"\"\"\n    m = OrderedDict()\n    map_header = None\n\n    with file_handle(mapFNH) as mapF:\n        for line in mapF:\n            if line.startswith(\"#SampleID\"):\n                map_header = line.strip().split(\"\\t\")\n            if line.startswith(\"#\") or not line:\n                    continue\n            line = line.strip().split(\"\\t\")\n            m[line[0]] = line\n\n    return map_header, m"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_vid_from_url(url):\n        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n          parse_query_param(url, 'v') or \\\n          parse_query_param(parse_query_param(url, 'u'), 'v')", "response": "Extracts video ID from URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake Mimi from UIDs", "response": "def makeMimi(upid):\n    \"\"\"From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\n    L110\"\"\"\n    strSeed = \"gGddgPfeaf_gzyr\"\n    prehash = upid + \"_\" + strSeed\n    return md5(prehash.encode('utf-8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fc2video_download(url, output_dir = '.', merge = True, info_only = False, **kwargs):\n    #'http://video.fc2.com/en/content/20151021bTVKnbEw'\n    #'http://xiaojiadianvideo.asia/content/20151021bTVKnbEw'\n    #'http://video.fc2.com/ja/content/20151021bTVKnbEw'\n    #'http://video.fc2.com/tw/content/20151021bTVKnbEw'\n    hostname = urlparse(url).hostname\n    if not ('fc2.com' in hostname or 'xiaojiadianvideo.asia' in hostname):\n        return False\n    upid = match1(url, r'.+/content/(\\w+)')\n\n    fc2video_download_by_upid(upid, output_dir, merge, info_only)", "response": "Download a video from the FC2 server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload Dailymotion videos by URL.", "response": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a single UCAS page.", "response": "def ucas_download_single(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''video page'''\n    html = get_content(url)\n    # resourceID is UUID\n    resourceID = re.findall( r'resourceID\":\"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})', html)[0]\n    assert resourceID != '', 'Cannot find resourceID!'\n\n    title = match1(html, r'<div class=\"bc-h\">(.+)</div>')\n    url_lists = _ucas_get_url_lists_by_resourceID(resourceID)\n    assert url_lists, 'Cannot find any URL of such class!'\n    \n    for k, part in enumerate(url_lists):\n        part_title = title + '_' + str(k)\n        print_info(site_info, part_title, 'flv', 0)\n        if not info_only:\n            download_urls(part, part_title, 'flv', total_size=None, output_dir=output_dir, merge=merge)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a playlist from the UCS.", "response": "def ucas_download_playlist(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''course page'''\n    html = get_content(url)\n\n    parts = re.findall( r'(getplaytitle.do\\?.+)\"', html)\n    assert parts, 'No part found!'\n\n    for part_path in parts:\n        ucas_download('http://v.ucas.ac.cn/course/' + part_path, output_dir=output_dir, merge=merge, info_only=info_only)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading a Sina video by its unique vid.", "response": "def sina_download_by_vid(vid, title=None, output_dir='.', merge=True, info_only=False):\n    \"\"\"Downloads a Sina video by its unique vid.\n    http://video.sina.com.cn/\n    \"\"\"\n    xml = api_req(vid)\n    urls, name, size = video_info(xml)\n    if urls is None:\n        log.wtf(name)\n    title = name\n    print_info(site_info, title, 'flv', size)\n    if not info_only:\n        download_urls(urls, title, 'flv', size, output_dir = output_dir, merge = merge)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sina_download_by_vkey(vkey, title=None, output_dir='.', merge=True, info_only=False):\n\n    url = 'http://video.sina.com/v/flvideo/%s_0.flv' % vkey\n    type, ext, size = url_info(url)\n\n    print_info(site_info, title, 'flv', size)\n    if not info_only:\n        download_urls([url], title, 'flv', size, output_dir = output_dir, merge = merge)", "response": "Downloads a Sina video by its unique vkey."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading Sina videos by URL.", "response": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef veoh_download(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Get item_id'''\n    if re.match(r'http://www.veoh.com/watch/\\w+', url):\n        item_id = match1(url, r'http://www.veoh.com/watch/(\\w+)')\n    elif re.match(r'http://www.veoh.com/m/watch.php\\?v=\\.*', url):\n        item_id = match1(url, r'http://www.veoh.com/m/watch.php\\?v=(\\w+)')\n    else:\n        raise NotImplementedError('Cannot find item ID')\n    veoh_download_by_id(item_id, output_dir = '.', merge = False, info_only = info_only, **kwargs)", "response": "Download a VEOH archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef veoh_download_by_id(item_id, output_dir = '.', merge = False, info_only = False, **kwargs):\n    webpage_url = 'http://www.veoh.com/m/watch.php?v={item_id}&quality=1'.format(item_id = item_id)\n\n    #grab download URL\n    a = get_content(webpage_url, decoded=True)\n    url = match1(a, r'<source src=\"(.*?)\\\"\\W')\n\n    #grab title\n    title = match1(a, r'<meta property=\"og:title\" content=\"([^\"]*)\"')\n\n    type_, ext, size = url_info(url)\n    print_info(site_info, title, type_, size)\n    if not info_only:\n        download_urls([url], title, ext, total_size=None, output_dir=output_dir, merge=merge)", "response": "Download a single item from Veoh."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download_by_id(self, vid = '', title = None, output_dir='.', merge=True, info_only=False,**kwargs):\n\n        assert vid\n\n        self.prepare(vid = vid, title = title, **kwargs)\n\n        self.extract(**kwargs)\n\n        self.download(output_dir = output_dir, \n                    merge = merge, \n                    info_only = info_only, **kwargs)", "response": "This method will download the video with the specified ID from the BokeCC cloud and extract it into the specified directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting video ID from live. qq. com.", "response": "def get_vid_from_url(self, url):\n        \"\"\"Extracts video ID from live.qq.com.\n        \"\"\"\n        hit = re.search(r'live.qq.com/(\\d+)', url)\n        if hit is not None:\n            return hit.group(1)\n        hit = re.search(r'live.qq.com/directory/match/(\\d+)', url)\n        if hit is not None:\n            return self.get_room_id_from_url(hit.group(1))\n        html = get_content(url)\n        room_id = match1(html, r'room_id\\\":(\\d+)')\n        if room_id is None:\n            log.wtf('Unknown page {}'.format(url))\n        return room_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat text with color or other effects into ANSI escaped string.", "response": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_log(text, *colors):\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")", "response": "Print a log message to standard error."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints an error log message.", "response": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wtf(message, exit_code=1):\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)", "response": "What a Terrible Failure!"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a single file from the weibo. com.", "response": "def miaopai_download_by_fid(fid, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Source: Android mobile'''\n    page_url = 'http://video.weibo.com/show?fid=' + fid + '&type=mp4'\n\n    mobile_page = get_content(page_url, headers=fake_headers_mobile)\n    url = match1(mobile_page, r'<video id=.*?src=[\\'\"](.*?)[\\'\"]\\W')\n    if url is None:\n        wb_mp = re.search(r'<script src=([\\'\"])(.+?wb_mp\\.js)\\1>', mobile_page).group(2)\n        return miaopai_download_by_wbmp(wb_mp, fid, output_dir=output_dir, merge=merge,\n                                        info_only=info_only, total_size=None, **kwargs)\n    title = match1(mobile_page, r'<title>((.|\\n)+?)</title>')\n    if not title:\n        title = fid\n    title = title.replace('\\n', '_')\n    ext, size = 'mp4', url_info(url)[2]\n    print_info(site_info, title, ext, size)\n    if not info_only:\n        download_urls([url], title, ext, total_size=None, output_dir=output_dir, merge=merge)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a vimeo file by channel.", "response": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vimeo_download_by_channel_id(channel_id, output_dir='.', merge=False, info_only=False, **kwargs):\n    html = get_content('https://api.vimeo.com/channels/{channel_id}/videos?access_token={access_token}'.format(channel_id=channel_id, access_token=access_token))\n    data = loads(html)\n    id_list = []\n\n    #print(data)\n    for i in data['data']:\n        id_list.append(match1(i['uri'], r'/videos/(\\w+)'))\n\n    for id in id_list:\n        try:\n            vimeo_download_by_id(id, None, output_dir, merge, info_only, **kwargs)\n        except urllib.error.URLError as e:\n            log.w('{} failed with {}'.format(id, e))", "response": "Download all vimeo videos from a channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload a Vimeo video by its id.", "response": "def vimeo_download_by_id(id, title=None, output_dir='.', merge=True, info_only=False, **kwargs):\n    '''\n    try:\n        # normal Vimeo video\n        html = get_content('https://vimeo.com/' + id)\n        cfg_patt = r'clip_page_config\\s*=\\s*(\\{.+?\\});'\n        cfg = json.loads(match1(html, cfg_patt))\n        video_page = get_content(cfg['player']['config_url'], headers=fake_headers)\n        title = cfg['clip']['title']\n        info = loads(video_page)\n    except:\n        # embedded player - referer may be required\n        if 'referer' in kwargs:\n            fake_headers['Referer'] = kwargs['referer']\n\n        video_page = get_content('http://player.vimeo.com/video/%s' % id, headers=fake_headers)\n        title = r1(r'<title>([^<]+)</title>', video_page)\n        info = loads(match1(video_page, r'var t=(\\{.+?\\});'))\n\n    streams = info['request']['files']['progressive']\n    streams = sorted(streams, key=lambda i: i['height'])\n    url = streams[-1]['url']\n\n    type, ext, size = url_info(url, faker=True)\n\n    print_info(site_info, title, type, size)\n    if not info_only:\n        download_urls([url], title, ext, size, output_dir, merge=merge, faker=True)\n    '''\n    site = VimeoExtractor()\n    site.download_by_vid(id, info_only=info_only, output_dir=output_dir, merge=merge, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ckplayer_get_info_by_xml(ckinfo):\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict", "response": "Get CKPlayer API content by XML."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets video URL from video ID", "response": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_vid_from_url(url):\n        vid = match1(url, 'https?://www.mgtv.com/(?:b|l)/\\d+/(\\d+).html')\n        if not vid:\n            vid = match1(url, 'https?://www.mgtv.com/hz/bdpz/\\d+/(\\d+).html')\n        return vid", "response": "Extracts video ID from URL."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mgtv_real_url(url):\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list", "response": "Get the REAL M3U url and size of the real files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets branch and commit from HEAD of a git repo.", "response": "def get_head(repo_path):\n    \"\"\"Get (branch, commit) from HEAD of a git repo.\"\"\"\n    try:\n        ref = open(os.path.join(repo_path, '.git', 'HEAD'), 'r').read().strip()[5:].split('/')\n        branch = ref[-1]\n        commit = open(os.path.join(repo_path, '.git', *ref), 'r').read().strip()[:7]\n        return branch, commit\n    except:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef legitimize(text, os=detect_os()):\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text", "response": "Converts a string to a valid filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_terminal_size():\n    try:\n        import fcntl, termios, struct # fcntl module only available on Unix\n        return struct.unpack('hh', fcntl.ioctl(1, termios.TIOCGWINSZ, '1234'))\n    except:\n        return (40, 80)", "response": "Get the width and height of the current terminal."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading CBS videos by URL.", "response": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(self, **kwargs):\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')", "response": "Download the one available one - language object from the DASH and return the ID of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading Acfun video by vid.", "response": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload a set of files with FFMPEG and return the path to the output file.", "response": "def ffmpeg_download_stream(files, title, ext, params={}, output_dir='.', stream=True):\n    \"\"\"str, str->True\n    WARNING: NOT THE SAME PARMS AS OTHER FUNCTIONS!!!!!!\n    You can basicly download anything with this function\n    but better leave it alone with\n    \"\"\"\n    output = title + '.' + ext\n\n    if not (output_dir == '.'):\n        output = output_dir + '/' + output\n\n    print('Downloading streaming content with FFmpeg, press q to stop recording...')\n    if stream:\n        ffmpeg_params = [FFMPEG] + ['-y', '-re', '-i']\n    else:\n        ffmpeg_params = [FFMPEG] + ['-y', '-i']\n    ffmpeg_params.append(files)  #not the same here!!!!\n\n    if FFMPEG == 'avconv':  #who cares?\n        ffmpeg_params += ['-c', 'copy', output]\n    else:\n        ffmpeg_params += ['-c', 'copy', '-bsf:a', 'aac_adtstoasc']\n\n    if params is not None:\n        if len(params) > 0:\n            for k, v in params:\n                ffmpeg_params.append(k)\n                ffmpeg_params.append(v)\n\n    ffmpeg_params.append(output)\n\n    print(' '.join(ffmpeg_params))\n\n    try:\n        a = subprocess.Popen(ffmpeg_params, stdin= subprocess.PIPE)\n        a.communicate()\n    except KeyboardInterrupt:\n        try:\n            a.stdin.write('q'.encode('utf-8'))\n        except:\n            pass\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscanning through a string for substrings matched some patterns. Returns None if no match is found.", "response": "def match1(text, *patterns):\n    \"\"\"Scans through a string for substrings matched some patterns (first-subgroups only).\n\n    Args:\n        text: A string to be scanned.\n        patterns: Arbitrary number of regex patterns.\n\n    Returns:\n        When only one pattern is given, returns a string (None if no match found).\n        When more than one pattern are given, returns a list of strings ([] if no match found).\n    \"\"\"\n\n    if len(patterns) == 1:\n        pattern = patterns[0]\n        match = re.search(pattern, text)\n        if match:\n            return match.group(1)\n        else:\n            return None\n    else:\n        ret = []\n        for pattern in patterns:\n            match = re.search(pattern, text)\n            if match:\n                ret.append(match.group(1))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning through a string for substrings matched some patterns. Returns a list of the names of the substrings matched.", "response": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_query_param(url, param):\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None", "response": "Parses the query string of a URL and returns the value of a parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecompresses data for Content - Encoding gzip.", "response": "def ungzip(data):\n    \"\"\"Decompresses data for Content-Encoding: gzip.\n    \"\"\"\n    from io import BytesIO\n    import gzip\n    buffer = BytesIO(data)\n    f = gzip.GzipFile(fileobj=buffer)\n    return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecompressing data for Content - Encoding.", "response": "def undeflate(data):\n    \"\"\"Decompresses data for Content-Encoding: deflate.\n    (the zlib compression is used.)\n    \"\"\"\n    import zlib\n    decompressobj = zlib.decompressobj(-zlib.MAX_WBITS)\n    return decompressobj.decompress(data)+decompressobj.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the content of a URL.", "response": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data", "response": "Post the content of a URL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_host(host):\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)", "response": "Parses a host name and port number from a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint a new object to stdout.", "response": "def print_more_compatible(*args, **kwargs):\n    import builtins as __builtin__\n    \"\"\"Overload default print function as py (<3.3) does not support 'flush' keyword.\n    Although the function name can be same as print to get itself overloaded automatically,\n    I'd rather leave it with a different name and only overload it when importing to make less confusion.\n    \"\"\"\n    # nothing happens on py3.3 and later\n    if sys.version_info[:2] >= (3, 3):\n        return __builtin__.print(*args, **kwargs)\n\n    # in lower pyver (e.g. 3.2.x), remove 'flush' keyword and flush it as requested\n    doFlush = kwargs.pop('flush', False)\n    ret = __builtin__.print(*args, **kwargs)\n    if doFlush:\n        kwargs.get('file', sys.stdout).flush()\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets room id by room url key.", "response": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef showroom_download_by_room_id(room_id, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Source: Android mobile'''\n    while True:\n        timestamp = str(int(time() * 1000))\n        api_endpoint = 'https://www.showroom-live.com/api/live/streaming_url?room_id={room_id}&_={timestamp}'.format(room_id = room_id, timestamp = timestamp)\n        html = get_content(api_endpoint)\n        html = json.loads(html)\n        #{'streaming_url_list': [{'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 1, 'label': 'original spec(low latency)', 'is_default': True, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed/playlist.m3u8', 'is_default': True, 'id': 2, 'type': 'hls', 'label': 'original spec'}, {'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 3, 'label': 'low spec(low latency)', 'is_default': False, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low/playlist.m3u8', 'is_default': False, 'id': 4, 'type': 'hls', 'label': 'low spec'}]}\n        if len(html) >= 1:\n            break\n        log.w('The live show is currently offline.')\n        sleep(1)\n\n    #This is mainly for testing the M3U FFmpeg parser so I would ignore any non-m3u ones\n    stream_url = [i['url'] for i in html['streaming_url_list'] if i['is_default'] and i['type'] == 'hls'][0]\n\n    assert stream_url\n\n    #title\n    title = ''\n    profile_api = 'https://www.showroom-live.com/api/room/profile?room_id={room_id}'.format(room_id = room_id)\n    html = loads(get_content(profile_api))\n    try:\n        title = html['main_name']\n    except KeyError:\n        title = 'Showroom_{room_id}'.format(room_id = room_id)\n\n    type_, ext, size = url_info(stream_url)\n    print_info(site_info, title, type_, size)\n    if not info_only:\n        download_url_ffmpeg(url=stream_url, title=title, ext= 'mp4', output_dir=output_dir)", "response": "Download all the streams for a given room id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a proper title by topic and part index.", "response": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wanmen_download_by_course(json_api_content, output_dir='.', merge=True, info_only=False, **kwargs):\n\n    for tIndex in range(len(json_api_content[0]['Topics'])):\n        for pIndex in range(len(json_api_content[0]['Topics'][tIndex]['Parts'])):\n            wanmen_download_by_course_topic_part(json_api_content,\n                                                 tIndex,\n                                                 pIndex,\n                                                 output_dir=output_dir,\n                                                 merge=merge,\n                                                 info_only=info_only,\n                                                 **kwargs)", "response": "Download a WHOLE course."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wanmen_download_by_course_topic_part(json_api_content, tIndex, pIndex, output_dir='.', merge=True, info_only=False, **kwargs):\n\n    html = json_api_content\n\n    title = _wanmen_get_title_by_json_topic_part(html, \n                                                  tIndex, \n                                                  pIndex)\n\n    bokeccID = _wanmen_get_boke_id_by_json_topic_part(html,\n                                                      tIndex, \n                                                     pIndex)\n\n    bokecc_download_by_id(vid = bokeccID, title = title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)", "response": "Download one part of the course by topic part."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the streams of a video by its id.", "response": "def get_streams_by_id(account_number, video_id):\n        \"\"\"\n        int, int->list\n        \n        Get the height of the videos.\n        \n        Since brightcove is using 3 kinds of links: rtmp, http and https,\n        we will be using the HTTPS one to make it secure.\n        \n        If somehow akamaihd.net is blocked by the Great Fucking Wall,\n        change the \"startswith https\" to http.\n        \"\"\"\n        endpoint = 'https://edge.api.brightcove.com/playback/v1/accounts/{account_number}/videos/{video_id}'.format(account_number = account_number, video_id = video_id)\n        fake_header_id = fake_headers\n        #is this somehow related to the time? Magic....\n        fake_header_id['Accept'] ='application/json;pk=BCpkADawqM1cc6wmJQC2tvoXZt4mrB7bFfi6zGt9QnOzprPZcGLE9OMGJwspQwKfuFYuCjAAJ53JdjI8zGFx1ll4rxhYJ255AXH1BQ10rnm34weknpfG-sippyQ'\n\n        html = get_content(endpoint, headers= fake_header_id)\n        html_json = json.loads(html)\n\n        link_list = []\n\n        for i in html_json['sources']:\n            if 'src' in i:  #to avoid KeyError\n                if i['src'].startswith('https'):\n                    link_list.append((str(i['height']), i['src']))\n\n        return link_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_task(self, task_instance):\n        if task_instance.key in self.queued_tasks or task_instance.key in self.running:\n            return True", "response": "Checks if a task is either queued or running in this executor s cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_event_buffer(self, dag_ids=None):\n        cleared_events = dict()\n        if dag_ids is None:\n            cleared_events = self.event_buffer\n            self.event_buffer = dict()\n        else:\n            for key in list(self.event_buffer.keys()):\n                dag_id, _, _, _ = key\n                if dag_id in dag_ids:\n                    cleared_events[key] = self.event_buffer.pop(key)\n\n        return cleared_events", "response": "Returns and flushes the event buffer for the given dag_ids. If no dag_ids is specified the event buffer will be cleared."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_conn_params(self):\n        conn = self.get_connection(self.snowflake_conn_id)\n        account = conn.extra_dejson.get('account', None)\n        warehouse = conn.extra_dejson.get('warehouse', None)\n        database = conn.extra_dejson.get('database', None)\n        region = conn.extra_dejson.get(\"region\", None)\n        role = conn.extra_dejson.get('role', None)\n\n        conn_config = {\n            \"user\": conn.login,\n            \"password\": conn.password or '',\n            \"schema\": conn.schema or '',\n            \"database\": self.database or database or '',\n            \"account\": self.account or account or '',\n            \"warehouse\": self.warehouse or warehouse or '',\n            \"region\": self.region or region or '',\n            \"role\": self.role or role or '',\n        }\n\n        \"\"\"\n        If private_key_file is specified in the extra json, load the contents of the file as a private\n        key and specify that in the connection configuration. The connection password then becomes the\n        passphrase for the private key. If your private key file is not encrypted (not recommended), then\n        leave the password empty.\n        \"\"\"\n        private_key_file = conn.extra_dejson.get('private_key_file', None)\n        if private_key_file:\n            with open(private_key_file, \"rb\") as key:\n                passphrase = None\n                if conn.password:\n                    passphrase = conn.password.strip().encode()\n\n                p_key = serialization.load_pem_private_key(\n                    key.read(),\n                    password=passphrase,\n                    backend=default_backend()\n                )\n\n            pkb = p_key.private_bytes(encoding=serialization.Encoding.DER,\n                                      format=serialization.PrivateFormat.PKCS8,\n                                      encryption_algorithm=serialization.NoEncryption())\n\n            conn_config['private_key'] = pkb\n            conn_config.pop('password', None)\n\n        return conn_config", "response": "get connection params as a dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverriding DbApiHook get_uri method for get_sqlalchemy_engine", "response": "def get_uri(self):\n        \"\"\"\n        override DbApiHook get_uri method for get_sqlalchemy_engine()\n        \"\"\"\n        conn_config = self._get_conn_params()\n        uri = 'snowflake://{user}:{password}@{account}/{database}/'\n        uri += '{schema}?warehouse={warehouse}&role={role}'\n        return uri.format(**conn_config)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conn(self):\n        conn_config = self._get_conn_params()\n        conn = snowflake.connector.connect(**conn_config)\n        return conn", "response": "Returns a snowflake. connection object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_aws_credentials(self):\n        if self.snowflake_conn_id:\n            connection_object = self.get_connection(self.snowflake_conn_id)\n            if 'aws_secret_access_key' in connection_object.extra_dejson:\n                aws_access_key_id = connection_object.extra_dejson.get(\n                    'aws_access_key_id')\n                aws_secret_access_key = connection_object.extra_dejson.get(\n                    'aws_secret_access_key')\n        return aws_access_key_id, aws_secret_access_key", "response": "returns aws_access_key_id aws_secret_access_key from extra_dejson"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch a field from extras and returns it.", "response": "def _get_field(self, field_name, default=None):\n        \"\"\"\n        Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.\n        \"\"\"\n        full_field_name = 'extra__grpc__{}'.format(field_name)\n        if full_field_name in self.extras:\n            return self.extras[full_field_name]\n        else:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying an EXPERIMENTAL file into a file.", "response": "def copy_expert(self, sql, filename, open=open):\n        \"\"\"\n        Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.\n        \"\"\"\n        if not os.path.isfile(filename):\n            with open(filename, 'w'):\n                pass\n\n        with open(filename, 'r+') as f:\n            with closing(self.get_conn()) as conn:\n                with closing(conn.cursor()) as cur:\n                    cur.copy_expert(sql, f)\n                    f.truncate(f.tell())\n                    conn.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a tab - delimited file into a database table", "response": "def bulk_load(self, table, tmp_file):\n        \"\"\"\n        Loads a tab-delimited file into a database table\n        \"\"\"\n        self.copy_expert(\"COPY {table} FROM STDIN\".format(table=table), tmp_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bulk_dump(self, table, tmp_file):\n        self.copy_expert(\"COPY {table} TO STDOUT\".format(table=table), tmp_file)", "response": "Dumps a database table into a tab - delimited file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute(self, context):\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n\n        hook.upload(\n            bucket_name=self.bucket,\n            object_name=self.dst,\n            mime_type=self.mime_type,\n            filename=self.src,\n            gzip=self.gzip,\n        )", "response": "Executes the upload operation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef max_partition(\n        table, schema=\"default\", field=None, filter_map=None,\n        metastore_conn_id='metastore_default'):\n    \"\"\"\n    Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'\n    \"\"\"\n    from airflow.hooks.hive_hooks import HiveMetastoreHook\n    if '.' in table:\n        schema, table = table.split('.')\n    hh = HiveMetastoreHook(metastore_conn_id=metastore_conn_id)\n    return hh.max_partition(\n        schema=schema, table_name=table, field=field, filter_map=filter_map)", "response": "Get the max value for a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _closest_date(target_dt, date_list, before_target=None):\n    fb = lambda d: target_dt - d if d <= target_dt else datetime.timedelta.max\n    fa = lambda d: d - target_dt if d >= target_dt else datetime.timedelta.max\n    fnone = lambda d: target_dt - d if d < target_dt else d - target_dt\n    if before_target is None:\n        return min(date_list, key=fnone).date()\n    if before_target:\n        return min(date_list, key=fb).date()\n    else:\n        return min(date_list, key=fa).date()", "response": "This function finds the date in a list closest to the target date."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_conn(self):\n        conn = self.get_connection(self.mysql_conn_id)\n        conn_config = {\n            \"user\": conn.login,\n            \"passwd\": conn.password or '',\n            \"host\": conn.host or 'localhost',\n            \"db\": self.schema or conn.schema or ''\n        }\n\n        if not conn.port:\n            conn_config[\"port\"] = 3306\n        else:\n            conn_config[\"port\"] = int(conn.port)\n\n        if conn.extra_dejson.get('charset', False):\n            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]\n            if (conn_config[\"charset\"]).lower() == 'utf8' or\\\n                    (conn_config[\"charset\"]).lower() == 'utf-8':\n                conn_config[\"use_unicode\"] = True\n        if conn.extra_dejson.get('cursor', False):\n            if (conn.extra_dejson[\"cursor\"]).lower() == 'sscursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'dictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'ssdictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor\n        local_infile = conn.extra_dejson.get('local_infile', False)\n        if conn.extra_dejson.get('ssl', False):\n            # SSL parameter for MySQL has to be a dictionary and in case\n            # of extra/dejson we can get string if extra is passed via\n            # URL parameters\n            dejson_ssl = conn.extra_dejson['ssl']\n            if isinstance(dejson_ssl, six.string_types):\n                dejson_ssl = json.loads(dejson_ssl)\n            conn_config['ssl'] = dejson_ssl\n        if conn.extra_dejson.get('unix_socket'):\n            conn_config['unix_socket'] = conn.extra_dejson['unix_socket']\n        if local_infile:\n            conn_config[\"local_infile\"] = 1\n        conn = MySQLdb.connect(**conn_config)\n        return conn", "response": "Returns a MySQL connection object for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bulk_load(self, table, tmp_file):\n        conn = self.get_conn()\n        cur = conn.cursor()\n        cur.execute(\"\"\"\n            LOAD DATA LOCAL INFILE '{tmp_file}'\n            INTO TABLE {table}\n            \"\"\".format(tmp_file=tmp_file, table=table))\n        conn.commit()", "response": "Loads a tab - delimited file into a table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether new objects have been uploaded and the inactivity_period has passed and updates the state of the sensor accordingly.", "response": "def is_bucket_updated(self, current_num_objects):\n        \"\"\"\n        Checks whether new objects have been uploaded and the inactivity_period\n        has passed and updates the state of the sensor accordingly.\n\n        :param current_num_objects: number of objects in bucket during last poke.\n        :type current_num_objects: int\n        \"\"\"\n\n        if current_num_objects > self.previous_num_objects:\n            # When new objects arrived, reset the inactivity_seconds\n            # previous_num_objects for the next poke.\n            self.log.info(\n                '''\n                New objects found at {} resetting last_activity_time.\n                '''.format(os.path.join(self.bucket, self.prefix)))\n            self.last_activity_time = get_time()\n            self.inactivity_seconds = 0\n            self.previous_num_objects = current_num_objects\n        elif current_num_objects < self.previous_num_objects:\n            # During the last poke interval objects were deleted.\n            if self.allow_delete:\n                self.previous_num_objects = current_num_objects\n                self.last_activity_time = get_time()\n                self.log.warning(\n                    '''\n                    Objects were deleted during the last\n                    poke interval. Updating the file counter and\n                    resetting last_activity_time.\n                    '''\n                )\n            else:\n                raise RuntimeError(\n                    '''\n                    Illegal behavior: objects were deleted in {} between pokes.\n                    '''.format(os.path.join(self.bucket, self.prefix))\n                )\n        else:\n            if self.last_activity_time:\n                self.inactivity_seconds = (\n                    get_time() - self.last_activity_time).total_seconds()\n            else:\n                # Handles the first poke where last inactivity time is None.\n                self.last_activity_time = get_time()\n                self.inactivity_seconds = 0\n\n            if self.inactivity_seconds >= self.inactivity_period:\n                if current_num_objects >= self.min_objects:\n                    self.log.info(\n                        '''\n                        SUCCESS:\n                        Sensor found {} objects at {}.\n                        Waited at least {} seconds, with no new objects dropped.\n                        '''.format(\n                            current_num_objects,\n                            os.path.join(self.bucket, self.prefix),\n                            self.inactivity_period))\n                    return True\n\n                warn_msg = \\\n                    '''\n                    FAILURE:\n                    Inactivity Period passed,\n                    not enough objects found in {}\n                    '''.format(\n                        os.path.join(self.bucket, self.prefix))\n                self.log.warning(warn_msg)\n                return False\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting stack traces when this gets a SIGQUIT or CTRL + +", "response": "def sigquit_handler(sig, frame):\n    \"\"\"Helps debug deadlocks by printing stacktraces when this gets a SIGQUIT\n    e.g. kill -s QUIT <PID> or CTRL+\\\n    \"\"\"\n    print(\"Dumping stack traces for all threads in PID {}\".format(os.getpid()))\n    id_to_name = dict([(th.ident, th.name) for th in threading.enumerate()])\n    code = []\n    for thread_id, stack in sys._current_frames().items():\n        code.append(\"\\n# Thread: {}({})\"\n                    .format(id_to_name.get(thread_id, \"\"), thread_id))\n        for filename, line_number, name, line in traceback.extract_stack(stack):\n            code.append('File: \"{}\", line {}, in {}'\n                        .format(filename, line_number, name))\n            if line:\n                code.append(\"  {}\".format(line.strip()))\n    print(\"\\n\".join(code))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trigger_dag(args):\n    log = LoggingMixin().log\n    try:\n        message = api_client.trigger_dag(dag_id=args.dag_id,\n                                         run_id=args.run_id,\n                                         conf=args.conf,\n                                         execution_date=args.exec_date)\n    except IOError as err:\n        log.error(err)\n        raise AirflowException(err)\n    log.info(message)", "response": "Trigger a dag run for the specified dag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_dag(args):\n    log = LoggingMixin().log\n    if args.yes or input(\n            \"This will drop all existing records related to the specified DAG. \"\n            \"Proceed? (y/n)\").upper() == \"Y\":\n        try:\n            message = api_client.delete_dag(dag_id=args.dag_id)\n        except IOError as err:\n            log.error(err)\n            raise AirflowException(err)\n        log.info(message)\n    else:\n        print(\"Bail.\")", "response": "Delete all DB records related to the specified DAG."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the unmet dependencies for a task instance from the perspective of the scheduler (i.e. why a task instance doesn't get scheduled and then queued by the scheduler, and then run by an executor). >>> airflow task_failed_deps tutorial sleep 2015-01-01 Task instance dependencies not met: Dagrun Running: Task instance's dagrun did not exist: Unknown reason Trigger Rule: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es).", "response": "def task_failed_deps(args):\n    \"\"\"\n    Returns the unmet dependencies for a task instance from the perspective of the\n    scheduler (i.e. why a task instance doesn't get scheduled and then queued by the\n    scheduler, and then run by an executor).\n    >>> airflow task_failed_deps tutorial sleep 2015-01-01\n    Task instance dependencies not met:\n    Dagrun Running: Task instance's dagrun did not exist: Unknown reason\n    Trigger Rule: Task's trigger rule 'all_success' requires all upstream tasks\n    to have succeeded, but found 1 non-success(es).\n    \"\"\"\n    dag = get_dag(args)\n    task = dag.get_task(task_id=args.task_id)\n    ti = TaskInstance(task, args.execution_date)\n\n    dep_context = DepContext(deps=SCHEDULER_DEPS)\n    failed_deps = list(ti.get_failed_dep_statuses(dep_context=dep_context))\n    # TODO, Do we want to print or log this\n    if failed_deps:\n        print(\"Task instance dependencies not met:\")\n        for dep in failed_deps:\n            print(\"{}: {}\".format(dep.dep_name, dep.reason))\n    else:\n        print(\"Task instance dependencies are all met.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the state of a TaskInstance at the command line. >>> airflow task_state tutorial sleep 2015-01-01 success", "response": "def task_state(args):\n    \"\"\"\n    Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success\n    \"\"\"\n    dag = get_dag(args)\n    task = dag.get_task(task_id=args.task_id)\n    ti = TaskInstance(task, args.execution_date)\n    print(ti.current_state())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dag_state(args):\n    dag = get_dag(args)\n    dr = DagRun.find(dag.dag_id, execution_date=args.execution_date)\n    print(dr[0].state if len(dr) > 0 else None)", "response": "A simple dag_state command line tool"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the next execution datetime of a DAG at the command line. >>> airflow next_execution tutorial 2018-08-31 10:38:00", "response": "def next_execution(args):\n    \"\"\"\n    Returns the next execution datetime of a DAG at the command line.\n    >>> airflow next_execution tutorial\n    2018-08-31 10:38:00\n    \"\"\"\n    dag = get_dag(args)\n\n    if dag.is_paused:\n        print(\"[INFO] Please be reminded this DAG is PAUSED now.\")\n\n    if dag.latest_execution_date:\n        next_execution_dttm = dag.following_schedule(dag.latest_execution_date)\n\n        if next_execution_dttm is None:\n            print(\"[WARN] No following schedule can be found. \" +\n                  \"This DAG may have schedule interval '@once' or `None`.\")\n\n        print(next_execution_dttm)\n    else:\n        print(\"[WARN] Only applicable when there is execution record found for the DAG.\")\n        print(None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrestarts the workers in the cluster.", "response": "def restart_workers(gunicorn_master_proc, num_workers_expected, master_timeout):\n    \"\"\"\n    Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.\n    \"\"\"\n\n    def wait_until_true(fn, timeout=0):\n        \"\"\"\n        Sleeps until fn is true\n        \"\"\"\n        t = time.time()\n        while not fn():\n            if 0 < timeout <= time.time() - t:\n                raise AirflowWebServerTimeout(\n                    \"No response from gunicorn master within {0} seconds\"\n                    .format(timeout))\n            time.sleep(0.1)\n\n    def start_refresh(gunicorn_master_proc):\n        batch_size = conf.getint('webserver', 'worker_refresh_batch_size')\n        log.debug('%s doing a refresh of %s workers', state, batch_size)\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n        excess = 0\n        for _ in range(batch_size):\n            gunicorn_master_proc.send_signal(signal.SIGTTIN)\n            excess += 1\n            wait_until_true(lambda: num_workers_expected + excess ==\n                            get_num_workers_running(gunicorn_master_proc),\n                            master_timeout)\n\n    try:\n        wait_until_true(lambda: num_workers_expected ==\n                        get_num_workers_running(gunicorn_master_proc),\n                        master_timeout)\n        while True:\n            num_workers_running = get_num_workers_running(gunicorn_master_proc)\n            num_ready_workers_running = \\\n                get_num_ready_workers_running(gunicorn_master_proc)\n\n            state = '[{0} / {1}]'.format(num_ready_workers_running, num_workers_running)\n\n            # Whenever some workers are not ready, wait until all workers are ready\n            if num_ready_workers_running < num_workers_running:\n                log.debug('%s some workers are starting up, waiting...', state)\n                sys.stdout.flush()\n                time.sleep(1)\n\n            # Kill a worker gracefully by asking gunicorn to reduce number of workers\n            elif num_workers_running > num_workers_expected:\n                excess = num_workers_running - num_workers_expected\n                log.debug('%s killing %s workers', state, excess)\n\n                for _ in range(excess):\n                    gunicorn_master_proc.send_signal(signal.SIGTTOU)\n                    excess -= 1\n                    wait_until_true(lambda: num_workers_expected + excess ==\n                                    get_num_workers_running(gunicorn_master_proc),\n                                    master_timeout)\n\n            # Start a new worker by asking gunicorn to increase number of workers\n            elif num_workers_running == num_workers_expected:\n                refresh_interval = conf.getint('webserver', 'worker_refresh_interval')\n                log.debug(\n                    '%s sleeping for %ss starting doing a refresh...',\n                    state, refresh_interval\n                )\n                time.sleep(refresh_interval)\n                start_refresh(gunicorn_master_proc)\n\n            else:\n                # num_ready_workers_running == num_workers_running < num_workers_expected\n                log.error((\n                    \"%s some workers seem to have died and gunicorn\"\n                    \"did not restart them as expected\"\n                ), state)\n                time.sleep(10)\n                if len(\n                    psutil.Process(gunicorn_master_proc.pid).children()\n                ) < num_workers_expected:\n                    start_refresh(gunicorn_master_proc)\n    except (AirflowWebServerTimeout, OSError) as err:\n        log.error(err)\n        log.error(\"Shutting down webserver\")\n        try:\n            gunicorn_master_proc.terminate()\n            gunicorn_master_proc.wait()\n        finally:\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a connection to the Cloud Translate API.", "response": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client\n        \"\"\"\n        if not self._client:\n            self._client = Client(credentials=self._get_credentials())\n        return self._client"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef translate(\n        self, values, target_language, format_=None, source_language=None, model=None\n    ):\n        \"\"\"Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.\n        \"\"\"\n        client = self.get_conn()\n\n        return client.translate(\n            values=values,\n            target_language=target_language,\n            format_=format_,\n            source_language=source_language,\n            model=model,\n        )", "response": "Translate a string or list of strings into a target language."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, context):\n        self.log.info('Tmp dir root location: \\n %s', gettempdir())\n\n        # Prepare env for child process.\n        if self.env is None:\n            self.env = os.environ.copy()\n\n        airflow_context_vars = context_to_airflow_vars(context, in_env_var_format=True)\n        self.log.info('Exporting the following env vars:\\n%s',\n                      '\\n'.join([\"{}={}\".format(k, v)\n                                 for k, v in\n                                 airflow_context_vars.items()]))\n        self.env.update(airflow_context_vars)\n\n        self.lineage_data = self.bash_command\n\n        with TemporaryDirectory(prefix='airflowtmp') as tmp_dir:\n            with NamedTemporaryFile(dir=tmp_dir, prefix=self.task_id) as tmp_file:\n                tmp_file.write(bytes(self.bash_command, 'utf_8'))\n                tmp_file.flush()\n                script_location = os.path.abspath(tmp_file.name)\n                self.log.info('Temporary script location: %s', script_location)\n\n                def pre_exec():\n                    # Restore default signal disposition and invoke setsid\n                    for sig in ('SIGPIPE', 'SIGXFZ', 'SIGXFSZ'):\n                        if hasattr(signal, sig):\n                            signal.signal(getattr(signal, sig), signal.SIG_DFL)\n                    os.setsid()\n\n                self.log.info('Running command: %s', self.bash_command)\n                sub_process = Popen(\n                    ['bash', tmp_file.name],\n                    stdout=PIPE,\n                    stderr=STDOUT,\n                    cwd=tmp_dir,\n                    env=self.env,\n                    preexec_fn=pre_exec)\n\n                self.sub_process = sub_process\n\n                self.log.info('Output:')\n                line = ''\n                for raw_line in iter(sub_process.stdout.readline, b''):\n                    line = raw_line.decode(self.output_encoding).rstrip()\n                    self.log.info(line)\n\n                sub_process.wait()\n\n                self.log.info('Command exited with return code %s', sub_process.returncode)\n\n                if sub_process.returncode:\n                    raise AirflowException('Bash command failed')\n\n        return line", "response": "Execute the bash command in a temporary directory and return the result of the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_instance(self, instance, project_id=None):\n        return self.get_conn().instances().get(\n            project=project_id,\n            instance=instance\n        ).execute(num_retries=self.num_retries)", "response": "Retrieves a resource containing information about a Cloud SQL instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_instance(self, body, project_id=None):\n        response = self.get_conn().instances().insert(\n            project=project_id,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)", "response": "Creates a new Cloud SQL instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_instance(self, body, instance, project_id=None):\n        response = self.get_conn().instances().patch(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)", "response": "Updates the settings of a Cloud SQL instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_instance(self, instance, project_id=None):\n        response = self.get_conn().instances().delete(\n            project=project_id,\n            instance=instance,\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)", "response": "Deletes a Cloud SQL instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a Cloud SQL database resource from a Cloud SQL instance.", "response": "def get_database(self, instance, database, project_id=None):\n        \"\"\"\n        Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().databases().get(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new database inside a Cloud SQL instance.", "response": "def create_database(self, instance, body, project_id=None):\n        \"\"\"\n        Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().insert(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a database resource inside a Cloud SQL instance.", "response": "def patch_database(self, instance, database, body, project_id=None):\n        \"\"\"\n        Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().patch(\n            project=project_id,\n            instance=instance,\n            database=database,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a database from a Cloud SQL instance.", "response": "def delete_database(self, instance, database, project_id=None):\n        \"\"\"\n        Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().delete(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump or CSV file.", "response": "def export_instance(self, instance, body, project_id=None):\n        \"\"\"\n        Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        try:\n            response = self.get_conn().instances().export(\n                project=project_id,\n                instance=instance,\n                body=body\n            ).execute(num_retries=self.num_retries)\n            operation_name = response[\"name\"]\n            self._wait_for_operation_to_complete(project_id=project_id,\n                                                 operation_name=operation_name)\n        except HttpError as ex:\n            raise AirflowException(\n                'Exporting instance {} failed: {}'.format(instance, ex.content)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _wait_for_operation_to_complete(self, project_id, operation_name):\n        service = self.get_conn()\n        while True:\n            operation_response = service.operations().get(\n                project=project_id,\n                operation=operation_name,\n            ).execute(num_retries=self.num_retries)\n            if operation_response.get(\"status\") == CloudSqlOperationStatus.DONE:\n                error = operation_response.get(\"error\")\n                if error:\n                    # Extracting the errors list as string and trimming square braces\n                    error_msg = str(error.get(\"errors\"))[1:-1]\n                    raise AirflowException(error_msg)\n                # No meaningful info to return from the response in case of success\n                return\n            time.sleep(TIME_TO_SLEEP_IN_SECONDS)", "response": "Waits for the named operation to complete - checks status of the operation asynchronously call."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting the Cloud SQL Proxy.", "response": "def start_proxy(self):\n        \"\"\"\n        Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        if self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is already running: {}\".format(\n                self.sql_proxy_process))\n        else:\n            command_to_run = [self.sql_proxy_path]\n            command_to_run.extend(self.command_line_parameters)\n            try:\n                self.log.info(\"Creating directory %s\",\n                              self.cloud_sql_proxy_socket_directory)\n                os.makedirs(self.cloud_sql_proxy_socket_directory)\n            except OSError:\n                # Needed for python 2 compatibility (exists_ok missing)\n                pass\n            command_to_run.extend(self._get_credential_parameters())\n            self.log.info(\"Running the command: `%s`\", \" \".join(command_to_run))\n            self.sql_proxy_process = Popen(command_to_run,\n                                           stdin=PIPE, stdout=PIPE, stderr=PIPE)\n            self.log.info(\"The pid of cloud_sql_proxy: %s\", self.sql_proxy_process.pid)\n            while True:\n                line = self.sql_proxy_process.stderr.readline().decode('utf-8')\n                return_code = self.sql_proxy_process.poll()\n                if line == '' and return_code is not None:\n                    self.sql_proxy_process = None\n                    raise AirflowException(\n                        \"The cloud_sql_proxy finished early with return code {}!\".format(\n                            return_code))\n                if line != '':\n                    self.log.info(line)\n                if \"googleapi: Error\" in line or \"invalid instance name:\" in line:\n                    self.stop_proxy()\n                    raise AirflowException(\n                        \"Error when starting the cloud_sql_proxy {}!\".format(\n                            line))\n                if \"Ready for new connections\" in line:\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop_proxy(self):\n        if not self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is not started yet\")\n        else:\n            self.log.info(\"Stopping the cloud_sql_proxy pid: %s\",\n                          self.sql_proxy_process.pid)\n            self.sql_proxy_process.kill()\n            self.sql_proxy_process = None\n        # Cleanup!\n        self.log.info(\"Removing the socket directory: %s\",\n                      self.cloud_sql_proxy_socket_directory)\n        shutil.rmtree(self.cloud_sql_proxy_socket_directory, ignore_errors=True)\n        if self.sql_proxy_was_downloaded:\n            self.log.info(\"Removing downloaded proxy: %s\", self.sql_proxy_path)\n            # Silently ignore if the file has already been removed (concurrency)\n            try:\n                os.remove(self.sql_proxy_path)\n            except OSError as e:\n                if not e.errno == errno.ENOENT:\n                    raise\n        else:\n            self.log.info(\"Skipped removing proxy - it was not downloaded: %s\",\n                          self.sql_proxy_path)\n        if os.path.isfile(self.credentials_path):\n            self.log.info(\"Removing generated credentials file %s\",\n                          self.credentials_path)\n            # Here file cannot be delete by concurrent task (each task has its own copy)\n            os.remove(self.credentials_path)", "response": "Stops running the sql proxy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_proxy_version(self):\n        self._download_sql_proxy_if_needed()\n        command_to_run = [self.sql_proxy_path]\n        command_to_run.extend(['--version'])\n        command_to_run.extend(self._get_credential_parameters())\n        result = subprocess.check_output(command_to_run).decode('utf-8')\n        pattern = re.compile(\"^.*[V|v]ersion ([^;]*);.*$\")\n        m = pattern.match(result)\n        if m:\n            return m.group(1)\n        else:\n            return None", "response": "Returns the version of the Cloud SQL Proxy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_connection(self, session=None):\n        connection = Connection(conn_id=self.db_conn_id)\n        uri = self._generate_connection_uri()\n        self.log.info(\"Creating connection %s\", self.db_conn_id)\n        connection.parse_from_uri(uri)\n        session.add(connection)\n        session.commit()", "response": "Create a new connection in the Connection table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the dynamically created connection from the Connection table.", "response": "def retrieve_connection(self, session=None):\n        \"\"\"\n        Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Retrieving connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            return connections[0]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_connection(self, session=None):\n        self.log.info(\"Deleting connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            connection = connections[0]\n            session.delete(connection)\n            session.commit()\n        else:\n            self.log.info(\"Connection was already deleted!\")", "response": "Delete the dynamically created connection from the Connection table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sqlproxy_runner(self):\n        if not self.use_proxy:\n            raise AirflowException(\"Proxy runner can only be retrieved in case of use_proxy = True\")\n        return CloudSqlProxyRunner(\n            path_prefix=self.sql_proxy_unique_path,\n            instance_specification=self._get_sqlproxy_instance_specification(),\n            project_id=self.project_id,\n            sql_proxy_version=self.sql_proxy_version,\n            sql_proxy_binary_path=self.sql_proxy_binary_path\n        )", "response": "Retrieves the Cloud Sql Proxy runner."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_database_hook(self):\n        if self.database_type == 'postgres':\n            self.db_hook = PostgresHook(postgres_conn_id=self.db_conn_id,\n                                        schema=self.database)\n        else:\n            self.db_hook = MySqlHook(mysql_conn_id=self.db_conn_id,\n                                     schema=self.database)\n        return self.db_hook", "response": "Retrieve database hook. This is the actual Postgres or MySQL database hook that uses proxy or connects directly to the Google Cloud SQL database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclean up database hook after it was used.", "response": "def cleanup_database_hook(self):\n        \"\"\"\n        Clean up database hook after it was used.\n        \"\"\"\n        if self.database_type == 'postgres':\n            if hasattr(self.db_hook,\n                       'conn') and self.db_hook.conn and self.db_hook.conn.notices:\n                for output in self.db_hook.conn.notices:\n                    self.log.info(output)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreserving free TCP port for the SQL Proxy.", "response": "def reserve_free_tcp_port(self):\n        \"\"\"\n        Reserve free TCP port to be used by Cloud SQL Proxy\n        \"\"\"\n        self.reserved_tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.reserved_tcp_socket.bind(('127.0.0.1', 0))\n        self.sql_proxy_tcp_port = self.reserved_tcp_socket.getsockname()[1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _normalize_mlengine_job_id(job_id):\n\n    # Add a prefix when a job_id starts with a digit or a template\n    match = re.search(r'\\d|\\{{2}', job_id)\n    if match and match.start() == 0:\n        job = 'z_{}'.format(job_id)\n    else:\n        job = job_id\n\n    # Clean up 'bad' characters except templates\n    tracker = 0\n    cleansed_job_id = ''\n    for m in re.finditer(r'\\{{2}.+?\\}{2}', job):\n        cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_',\n                                  job[tracker:m.start()])\n        cleansed_job_id += job[m.start():m.end()]\n        tracker = m.end()\n\n    # Clean up last substring or the full string if no templates\n    cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_', job[tracker:])\n\n    return cleansed_job_id", "response": "Normalizes a MLEngine job_id string to be a valid MLEngine job_id string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_error_code(self, e):\n        try:\n            matches = self.error_code_pattern.match(str(e))\n            code = int(matches.group(0))\n            return code\n        except ValueError:\n            return e", "response": "Extract error code from ftp exception"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _integrate_plugins():\n    import sys\n    from airflow.plugins_manager import sensors_modules\n    for sensors_module in sensors_modules:\n        sys.modules[sensors_module.__name__] = sensors_module\n        globals()[sensors_module._name] = sensors_module", "response": "Integrate plugins to the context"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove any existing DAG runs for the perf test DAGs.", "response": "def clear_dag_runs():\n    \"\"\"\n    Remove any existing DAG runs for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    drs = session.query(DagRun).filter(\n        DagRun.dag_id.in_(DAG_IDS),\n    ).all()\n    for dr in drs:\n        logging.info('Deleting DagRun :: {}'.format(dr))\n        session.delete(dr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove any existing task instances for the perf test DAGs.", "response": "def clear_dag_task_instances():\n    \"\"\"\n    Remove any existing task instances for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    TI = TaskInstance\n    tis = (\n        session\n        .query(TI)\n        .filter(TI.dag_id.in_(DAG_IDS))\n        .all()\n    )\n    for ti in tis:\n        logging.info('Deleting TaskInstance :: {}'.format(ti))\n        session.delete(ti)\n    session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the pause state of the DAGs in the test.", "response": "def set_dags_paused_state(is_paused):\n    \"\"\"\n    Toggle the pause state of the DAGs in the test.\n    \"\"\"\n    session = settings.Session()\n    dms = session.query(DagModel).filter(\n        DagModel.dag_id.in_(DAG_IDS))\n    for dm in dms:\n        logging.info('Setting DAG :: {} is_paused={}'.format(dm, is_paused))\n        dm.is_paused = is_paused\n    session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_stats(self):\n        session = settings.Session()\n        TI = TaskInstance\n        tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .all()\n        )\n        successful_tis = [x for x in tis if x.state == State.SUCCESS]\n        ti_perf = [(ti.dag_id, ti.task_id, ti.execution_date,\n                    (ti.queued_dttm - self.start_date).total_seconds(),\n                    (ti.start_date - self.start_date).total_seconds(),\n                    (ti.end_date - self.start_date).total_seconds(),\n                    ti.duration) for ti in successful_tis]\n        ti_perf_df = pd.DataFrame(ti_perf, columns=['dag_id', 'task_id',\n                                                    'execution_date',\n                                                    'queue_delay',\n                                                    'start_delay', 'land_time',\n                                                    'duration'])\n\n        print('Performance Results')\n        print('###################')\n        for dag_id in DAG_IDS:\n            print('DAG {}'.format(dag_id))\n            print(ti_perf_df[ti_perf_df['dag_id'] == dag_id])\n        print('###################')\n        if len(tis) > len(successful_tis):\n            print(\"WARNING!! The following task instances haven't completed\")\n            print(pd.DataFrame([(ti.dag_id, ti.task_id, ti.execution_date, ti.state)\n                  for ti in filter(lambda x: x.state != State.SUCCESS, tis)],\n                  columns=['dag_id', 'task_id', 'execution_date', 'state']))\n\n        session.commit()", "response": "Print statistics for the scheduler test."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef heartbeat(self):\n        super(SchedulerMetricsJob, self).heartbeat()\n        session = settings.Session()\n        # Get all the relevant task instances\n        TI = TaskInstance\n        successful_tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .filter(TI.state.in_([State.SUCCESS]))\n            .all()\n        )\n        session.commit()\n\n        dagbag = DagBag(SUBDIR)\n        dags = [dagbag.dags[dag_id] for dag_id in DAG_IDS]\n        # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.\n        num_task_instances = sum([(timezone.utcnow() - task.start_date).days\n                                 for dag in dags for task in dag.tasks])\n\n        if (len(successful_tis) == num_task_instances or\n                (timezone.utcnow() - self.start_date).total_seconds() >\n                MAX_RUNTIME_SECS):\n            if len(successful_tis) == num_task_instances:\n                self.log.info(\"All tasks processed! Printing stats.\")\n            else:\n                self.log.info(\"Test timeout reached. Printing available stats.\")\n            self.print_stats()\n            set_dags_paused_state(True)\n            sys.exit()", "response": "Override the scheduler heartbeat to determine when the test is complete"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvoke the Lambda function.", "response": "def invoke_lambda(self, payload):\n        \"\"\"\n        Invoke Lambda Function\n        \"\"\"\n\n        awslambda_conn = self.get_conn()\n\n        response = awslambda_conn.invoke(\n            FunctionName=self.function_name,\n            InvocationType=self.invocation_type,\n            LogType=self.log_type,\n            Payload=payload,\n            Qualifier=self.qualifier\n        )\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dag_run_state(dag_id, execution_date):\n\n    dagbag = DagBag()\n\n    # Check DAG exists.\n    if dag_id not in dagbag.dags:\n        error_message = \"Dag id {} not found\".format(dag_id)\n        raise DagNotFound(error_message)\n\n    # Get DAG object and check Task Exists\n    dag = dagbag.get_dag(dag_id)\n\n    # Get DagRun object and check that it exists\n    dagrun = dag.get_dagrun(execution_date=execution_date)\n    if not dagrun:\n        error_message = ('Dag Run for date {} not found in dag {}'\n                         .format(execution_date, dag_id))\n        raise DagRunNotFound(error_message)\n\n    return {'state': dagrun.get_state()}", "response": "Return the task object identified by the given dag_id and task_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the list of operators needed to evaluate the task with the given task_prefix.", "response": "def create_evaluate_ops(task_prefix,\n                        data_format,\n                        input_paths,\n                        prediction_path,\n                        metric_fn_and_keys,\n                        validate_fn,\n                        batch_prediction_job_id=None,\n                        project_id=None,\n                        region=None,\n                        dataflow_options=None,\n                        model_uri=None,\n                        model_name=None,\n                        version_name=None,\n                        dag=None):\n    \"\"\"\n    Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)\n    \"\"\"\n\n    # Verify that task_prefix doesn't have any special characters except hyphen\n    # '-', which is the only allowed non-alphanumeric character by Dataflow.\n    if not re.match(r\"^[a-zA-Z][-A-Za-z0-9]*$\", task_prefix):\n        raise AirflowException(\n            \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"\n            \"and hyphens are allowed but got: \" + task_prefix)\n\n    metric_fn, metric_keys = metric_fn_and_keys\n    if not callable(metric_fn):\n        raise AirflowException(\"`metric_fn` param must be callable.\")\n    if not callable(validate_fn):\n        raise AirflowException(\"`validate_fn` param must be callable.\")\n\n    if dag is not None and dag.default_args is not None:\n        default_args = dag.default_args\n        project_id = project_id or default_args.get('project_id')\n        region = region or default_args.get('region')\n        model_name = model_name or default_args.get('model_name')\n        version_name = version_name or default_args.get('version_name')\n        dataflow_options = dataflow_options or \\\n            default_args.get('dataflow_default_options')\n\n    evaluate_prediction = MLEngineBatchPredictionOperator(\n        task_id=(task_prefix + \"-prediction\"),\n        project_id=project_id,\n        job_id=batch_prediction_job_id,\n        region=region,\n        data_format=data_format,\n        input_paths=input_paths,\n        output_path=prediction_path,\n        uri=model_uri,\n        model_name=model_name,\n        version_name=version_name,\n        dag=dag)\n\n    metric_fn_encoded = base64.b64encode(dill.dumps(metric_fn, recurse=True))\n    evaluate_summary = DataFlowPythonOperator(\n        task_id=(task_prefix + \"-summary\"),\n        py_options=[\"-m\"],\n        py_file=\"airflow.contrib.utils.mlengine_prediction_summary\",\n        dataflow_default_options=dataflow_options,\n        options={\n            \"prediction_path\": prediction_path,\n            \"metric_fn_encoded\": metric_fn_encoded,\n            \"metric_keys\": ','.join(metric_keys)\n        },\n        dag=dag)\n    evaluate_summary.set_upstream(evaluate_prediction)\n\n    def apply_validate_fn(*args, **kwargs):\n        prediction_path = kwargs[\"templates_dict\"][\"prediction_path\"]\n        scheme, bucket, obj, _, _ = urlsplit(prediction_path)\n        if scheme != \"gs\" or not bucket or not obj:\n            raise ValueError(\"Wrong format prediction_path: %s\",\n                             prediction_path)\n        summary = os.path.join(obj.strip(\"/\"),\n                               \"prediction.summary.json\")\n        gcs_hook = GoogleCloudStorageHook()\n        summary = json.loads(gcs_hook.download(bucket, summary))\n        return validate_fn(summary)\n\n    evaluate_validation = PythonOperator(\n        task_id=(task_prefix + \"-validation\"),\n        python_callable=apply_validate_fn,\n        provide_context=True,\n        templates_dict={\"prediction_path\": prediction_path},\n        dag=dag)\n    evaluate_validation.set_upstream(evaluate_summary)\n\n    return evaluate_prediction, evaluate_summary, evaluate_validation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the directory specified by path and optionally sets the umask to 0o755.", "response": "def mkdirs(path, mode):\n    \"\"\"\n    Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int\n    \"\"\"\n    try:\n        o_umask = os.umask(0)\n        os.makedirs(path, mode)\n    except OSError:\n        if not os.path.isdir(path):\n            raise\n    finally:\n        os.umask(o_umask)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _convert_to_float_if_possible(s):\n    try:\n        ret = float(s)\n    except (ValueError, TypeError):\n        ret = s\n    return ret", "response": "A small helper function to convert a string to a numeric value if appropriate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the current date and time in UTC", "response": "def utcnow():\n    \"\"\"\n    Get the current date and time in UTC\n    :return:\n    \"\"\"\n\n    # pendulum utcnow() is not used as that sets a TimezoneInfo object\n    # instead of a Timezone. This is not pickable and also creates issues\n    # when using replace()\n    d = dt.datetime.utcnow()\n    d = d.replace(tzinfo=utc)\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the epoch in the users timezone", "response": "def utc_epoch():\n    \"\"\"\n    Gets the epoch in the users timezone\n    :return:\n    \"\"\"\n\n    # pendulum utcnow() is not used as that sets a TimezoneInfo object\n    # instead of a Timezone. This is not pickable and also creates issues\n    # when using replace()\n    d = dt.datetime(1970, 1, 1)\n    d = d.replace(tzinfo=utc)\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_to_utc(value):\n    if not value:\n        return value\n\n    if not is_localized(value):\n        value = pendulum.instance(value, TIMEZONE)\n\n    return value.astimezone(utc)", "response": "Converts the value to UTC"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a naive datetime. datetime in a given time zone aware.", "response": "def make_aware(value, timezone=None):\n    \"\"\"\n    Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone\n\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Check that we won't overwrite the timezone of an aware datetime.\n    if is_localized(value):\n        raise ValueError(\n            \"make_aware expects a naive datetime, got %s\" % value)\n    if hasattr(value, 'fold'):\n        # In case of python 3.6 we want to do the same that pendulum does for python3.5\n        # i.e in case we move clock back we want to schedule the run at the time of the second\n        # instance of the same clock time rather than the first one.\n        # Fold parameter has no impact in other cases so we can safely set it to 1 here\n        value = value.replace(fold=1)\n    if hasattr(timezone, 'localize'):\n        # This method is available for pytz time zones.\n        return timezone.localize(value)\n    elif hasattr(timezone, 'convert'):\n        # For pendulum\n        return timezone.convert(value)\n    else:\n        # This may be wrong around DST changes!\n        return value.replace(tzinfo=timezone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_naive(value, timezone=None):\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Emulate the behavior of astimezone() on Python < 3.6.\n    if is_naive(value):\n        raise ValueError(\"make_naive() cannot be applied to a naive datetime\")\n\n    o = value.astimezone(timezone)\n\n    # cross library compatibility\n    naive = dt.datetime(o.year,\n                        o.month,\n                        o.day,\n                        o.hour,\n                        o.minute,\n                        o.second,\n                        o.microsecond)\n\n    return naive", "response": "Make an aware datetime. datetime naive in a given time zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef datetime(*args, **kwargs):\n    if 'tzinfo' not in kwargs:\n        kwargs['tzinfo'] = TIMEZONE\n\n    return dt.datetime(*args, **kwargs)", "response": "Wrapper around datetime. datetime that adds settings. TIMEZONE to the first argument of the datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the environment variable GOOGLE_APPLICATION_CREDENTIALS with either the path to the keyfile from the specified connection id or the JSON of the connection id.", "response": "def _set_env_from_extras(self, extras):\n        \"\"\"\n        Sets the environment variable `GOOGLE_APPLICATION_CREDENTIALS` with either:\n\n        - The path to the keyfile from the specified connection id\n        - A generated file's path if the user specified JSON in the connection id. The\n            file is assumed to be deleted after the process dies due to how mkstemp()\n            works.\n\n        The environment variable is used inside the gcloud command to determine correct\n        service account to use.\n        \"\"\"\n        key_path = self._get_field(extras, 'key_path', False)\n        keyfile_json_str = self._get_field(extras, 'keyfile_dict', False)\n\n        if not key_path and not keyfile_json_str:\n            self.log.info('Using gcloud with application default credentials.')\n        elif key_path:\n            os.environ[G_APP_CRED] = key_path\n        else:\n            # Write service account JSON to secure file for gcloud to reference\n            service_key = tempfile.NamedTemporaryFile(delete=False)\n            service_key.write(keyfile_json_str)\n            os.environ[G_APP_CRED] = service_key.name\n            # Return file object to have a pointer to close after use,\n            # thus deleting from file system.\n            return service_key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a field from extras and returns it.", "response": "def _get_field(self, extras, field, default=None):\n        \"\"\"\n        Fetches a field from extras, and returns it. This is some Airflow\n        magic. The google_cloud_platform hook type adds custom UI elements\n        to the hook page, which allow admins to specify service_account,\n        key_path, etc. They get formatted as shown below.\n        \"\"\"\n        long_f = 'extra__google_cloud_platform__{}'.format(field)\n        if long_f in extras:\n            return extras[long_f]\n        else:\n            self.log.info('Field %s not found in extras.', field)\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_conn(self):\n        conn = self.get_connection(self.druid_broker_conn_id)\n        druid_broker_conn = connect(\n            host=conn.host,\n            port=conn.port,\n            path=conn.extra_dejson.get('endpoint', '/druid/v2/sql'),\n            scheme=conn.extra_dejson.get('schema', 'http')\n        )\n        self.log.info('Get the connection to druid broker on %s', conn.host)\n        return druid_broker_conn", "response": "Establish a connection to druid broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a requests. Session object for use with requests. Session.", "response": "def get_conn(self, headers=None):\n        \"\"\"\n        Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        \"\"\"\n        session = requests.Session()\n        if self.http_conn_id:\n            conn = self.get_connection(self.http_conn_id)\n\n            if \"://\" in conn.host:\n                self.base_url = conn.host\n            else:\n                # schema defaults to HTTP\n                schema = conn.schema if conn.schema else \"http\"\n                self.base_url = schema + \"://\" + conn.host\n\n            if conn.port:\n                self.base_url = self.base_url + \":\" + str(conn.port)\n            if conn.login:\n                session.auth = (conn.login, conn.password)\n            if conn.extra:\n                try:\n                    session.headers.update(conn.extra_dejson)\n                except TypeError:\n                    self.log.warn('Connection to %s has invalid extra field.', conn.host)\n        if headers:\n            session.headers.update(headers)\n\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the request on the specified endpoint and returns the response.", "response": "def run(self, endpoint, data=None, headers=None, extra_options=None):\n        \"\"\"\n        Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        session = self.get_conn(headers)\n\n        if self.base_url and not self.base_url.endswith('/') and \\\n           endpoint and not endpoint.startswith('/'):\n            url = self.base_url + '/' + endpoint\n        else:\n            url = (self.base_url or '') + (endpoint or '')\n\n        req = None\n        if self.method == 'GET':\n            # GET uses params\n            req = requests.Request(self.method,\n                                   url,\n                                   params=data,\n                                   headers=headers)\n        elif self.method == 'HEAD':\n            # HEAD doesn't use params\n            req = requests.Request(self.method,\n                                   url,\n                                   headers=headers)\n        else:\n            # Others use data\n            req = requests.Request(self.method,\n                                   url,\n                                   data=data,\n                                   headers=headers)\n\n        prepped_request = session.prepare_request(req)\n        self.log.info(\"Sending '%s' to url: %s\", self.method, url)\n        return self.run_and_check(session, prepped_request, extra_options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the status code and raises an exception on non 2XX or 3XX status codes", "response": "def check_response(self, response):\n        \"\"\"\n        Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response\n        \"\"\"\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError:\n            self.log.error(\"HTTP error: %s\", response.reason)\n            if self.method not in ['GET', 'HEAD']:\n                self.log.error(response.text)\n            raise AirflowException(str(response.status_code) + \":\" + response.reason)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the request and checks the response.", "response": "def run_and_check(self, session, prepped_request, extra_options):\n        \"\"\"\n        Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        try:\n            response = session.send(\n                prepped_request,\n                stream=extra_options.get(\"stream\", False),\n                verify=extra_options.get(\"verify\", True),\n                proxies=extra_options.get(\"proxies\", {}),\n                cert=extra_options.get(\"cert\"),\n                timeout=extra_options.get(\"timeout\"),\n                allow_redirects=extra_options.get(\"allow_redirects\", True))\n\n            if extra_options.get('check_response', True):\n                self.check_response(response)\n            return response\n\n        except requests.exceptions.ConnectionError as ex:\n            self.log.warn(str(ex) + ' Tenacity will retry to execute the operation')\n            raise ex"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a Tenacity hook and retries the request.", "response": "def run_with_advanced_retry(self, _retry_args, *args, **kwargs):\n        \"\"\"\n        Runs Hook.run() with a Tenacity decorator attached to it. This is useful for\n        connectors which might be disturbed by intermittent issues and should not\n        instantly fail.\n\n        :param _retry_args: Arguments which define the retry behaviour.\n            See Tenacity documentation at https://github.com/jd/tenacity\n        :type _retry_args: dict\n\n\n        :Example::\n\n            hook = HttpHook(http_conn_id='my_conn',method='GET')\n            retry_args = dict(\n                 wait=tenacity.wait_exponential(),\n                 stop=tenacity.stop_after_attempt(10),\n                 retry=requests.exceptions.ConnectionError\n             )\n             hook.run_with_advanced_retry(\n                     endpoint='v1/test',\n                     _retry_args=retry_args\n                 )\n        \"\"\"\n        self._retry_obj = tenacity.Retrying(\n            **_retry_args\n        )\n\n        self._retry_obj(self.run, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef provide_session(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        arg_session = 'session'\n\n        func_params = func.__code__.co_varnames\n        session_in_args = arg_session in func_params and \\\n            func_params.index(arg_session) < len(args)\n        session_in_kwargs = arg_session in kwargs\n\n        if session_in_kwargs or session_in_args:\n            return func(*args, **kwargs)\n        else:\n            with create_session() as session:\n                kwargs[arg_session] = session\n                return func(*args, **kwargs)\n\n    return wrapper", "response": "A function decorator that provides a session if it isn t provided."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear out the database for the current Alembic version", "response": "def resetdb():\n    \"\"\"\n    Clear out the database\n    \"\"\"\n    from airflow import models\n\n    # alembic adds significant import time, so we import it lazily\n    from alembic.migration import MigrationContext\n\n    log.info(\"Dropping tables that exist\")\n\n    models.base.Base.metadata.drop_all(settings.engine)\n    mc = MigrationContext.configure(settings.engine)\n    if mc._version.exists(settings.engine):\n        mc._version.drop(settings.engine)\n\n    from flask_appbuilder.models.sqla import Base\n    Base.metadata.drop_all(settings.engine)\n\n    initdb()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, context):\n        hook = WasbHook(wasb_conn_id=self.wasb_conn_id)\n        self.log.info(\n            'Uploading %s to wasb://%s '\n            'as %s'.format(self.file_path, self.container_name, self.blob_name)\n        )\n        hook.load_file(self.file_path, self.container_name,\n                       self.blob_name, **self.load_options)", "response": "Execute the File Upload Method"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conn(self):\n        db = self.get_connection(self.presto_conn_id)\n        reqkwargs = None\n        if db.password is not None:\n            reqkwargs = {'auth': HTTPBasicAuth(db.login, db.password)}\n        return presto.connect(\n            host=db.host,\n            port=db.port,\n            username=db.login,\n            source=db.extra_dejson.get('source', 'airflow'),\n            protocol=db.extra_dejson.get('protocol', 'http'),\n            catalog=db.extra_dejson.get('catalog', 'hive'),\n            requests_kwargs=reqkwargs,\n            schema=db.schema)", "response": "Returns a connection object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a pretty error message for an exception.", "response": "def _get_pretty_exception_message(e):\n        \"\"\"\n        Parses some DatabaseError to provide a better error message\n        \"\"\"\n        if (hasattr(e, 'message') and\n            'errorName' in e.message and\n                'message' in e.message):\n            return ('{name}: {message}'.format(\n                    name=e.message['errorName'],\n                    message=e.message['message']))\n        else:\n            return str(e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_records(self, hql, parameters=None):\n        try:\n            return super().get_records(\n                self._strip_sql(hql), parameters)\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))", "response": "Get a set of records from the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a pandas dataframe from a sql query.", "response": "def get_pandas_df(self, hql, parameters=None):\n        \"\"\"\n        Get a pandas dataframe from a sql query.\n        \"\"\"\n        import pandas\n        cursor = self.get_cursor()\n        try:\n            cursor.execute(self._strip_sql(hql), parameters)\n            data = cursor.fetchall()\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))\n        column_descriptions = cursor.description\n        if data:\n            df = pandas.DataFrame(data)\n            df.columns = [c[0] for c in column_descriptions]\n        else:\n            df = pandas.DataFrame()\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute the given SQL statement against Presto.", "response": "def run(self, hql, parameters=None):\n        \"\"\"\n        Execute the statement against Presto. Can be used to create views.\n        \"\"\"\n        return super().run(self._strip_sql(hql), parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_rows(self, table, rows, target_fields=None):\n        super().insert_rows(table, rows, target_fields, 0)", "response": "A generic way to insert a set of tuples into a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a cosmos db client.", "response": "def get_conn(self):\n        \"\"\"\n        Return a cosmos db client.\n        \"\"\"\n        if self.cosmos_client is not None:\n            return self.cosmos_client\n\n        # Initialize the Python Azure Cosmos DB client\n        self.cosmos_client = cosmos_client.CosmosClient(self.endpoint_uri, {'masterKey': self.master_key})\n\n        return self.cosmos_client"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a collection exists in CosmosDB.", "response": "def does_collection_exist(self, collection_name, database_name=None):\n        \"\"\"\n        Checks if a collection exists in CosmosDB.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n        if len(existing_container) == 0:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_collection(self, collection_name, database_name=None):\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        # We need to check to see if this container already exists so we don't try\n        # to create it twice\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n\n        # Only create if we did not find it already existing\n        if len(existing_container) == 0:\n            self.get_conn().CreateContainer(\n                get_database_link(self.__get_database_name(database_name)),\n                {\"id\": collection_name})", "response": "Creates a new collection in the CosmosDB database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef does_database_exist(self, database_name):\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n        if len(existing_database) == 0:\n            return False\n\n        return True", "response": "Checks if a database exists in CosmosDB."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new database in CosmosDB.", "response": "def create_database(self, database_name):\n        \"\"\"\n        Creates a new database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        # We need to check to see if this database already exists so we don't try\n        # to create it twice\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n\n        # Only create if we did not find it already existing\n        if len(existing_database) == 0:\n            self.get_conn().CreateDatabase({\"id\": database_name})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_database(self, database_name):\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        self.get_conn().DeleteDatabase(get_database_link(database_name))", "response": "Deletes an existing database in CosmosDB."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_collection(self, collection_name, database_name=None):\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        self.get_conn().DeleteContainer(\n            get_collection_link(self.__get_database_name(database_name), collection_name))", "response": "Deletes an existing collection in the Cosmos DB database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert a new document into an existing document in the CosmosDB database.", "response": "def upsert_document(self, document, database_name=None, collection_name=None, document_id=None):\n        \"\"\"\n        Inserts a new document (or updates an existing one) into an existing\n        collection in the CosmosDB database.\n        \"\"\"\n        # Assign unique ID if one isn't provided\n        if document_id is None:\n            document_id = str(uuid.uuid4())\n\n        if document is None:\n            raise AirflowBadRequest(\"You cannot insert a None document\")\n\n        # Add document id if isn't found\n        if 'id' in document:\n            if document['id'] is None:\n                document['id'] = document_id\n        else:\n            document['id'] = document_id\n\n        created_document = self.get_conn().CreateItem(\n            get_collection_link(\n                self.__get_database_name(database_name),\n                self.__get_collection_name(collection_name)),\n            document)\n\n        return created_document"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert a list of new documents into an existing collection.", "response": "def insert_documents(self, documents, database_name=None, collection_name=None):\n        \"\"\"\n        Insert a list of new documents into an existing collection in the CosmosDB database.\n        \"\"\"\n        if documents is None:\n            raise AirflowBadRequest(\"You cannot insert empty documents\")\n\n        created_documents = []\n        for single_document in documents:\n            created_documents.append(\n                self.get_conn().CreateItem(\n                    get_collection_link(\n                        self.__get_database_name(database_name),\n                        self.__get_collection_name(collection_name)),\n                    single_document))\n\n        return created_documents"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes an existing document out of a collection.", "response": "def delete_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Delete an existing document out of a collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot delete a document without an id\")\n\n        self.get_conn().DeleteItem(\n            get_document_link(\n                self.__get_database_name(database_name),\n                self.__get_collection_name(collection_name),\n                document_id))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_document(self, document_id, database_name=None, collection_name=None):\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot get a document without an id\")\n\n        try:\n            return self.get_conn().ReadItem(\n                get_document_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name),\n                    document_id))\n        except HTTPFailure:\n            return None", "response": "Get a document from an existing collection in the CosmosDB database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_documents(self, sql_string, database_name=None, collection_name=None, partition_key=None):\n        if sql_string is None:\n            raise AirflowBadRequest(\"SQL query string cannot be None\")\n\n        # Query them in SQL\n        query = {'query': sql_string}\n\n        try:\n            result_iterable = self.get_conn().QueryItems(\n                get_collection_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name)),\n                query,\n                partition_key)\n\n            return list(result_iterable)\n        except HTTPFailure:\n            return None", "response": "Get a list of documents from an existing collection in the CosmosDB database via SQL query."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns python code of a given dag_id.", "response": "def get_code(dag_id):\n    \"\"\"Return python code of a given dag_id.\"\"\"\n    session = settings.Session()\n    DM = models.DagModel\n    dag = session.query(DM).filter(DM.dag_id == dag_id).first()\n    session.close()\n    # Check DAG exists.\n    if dag is None:\n        error_message = \"Dag id {} not found\".format(dag_id)\n        raise DagNotFound(error_message)\n\n    try:\n        with wwwutils.open_maybe_zipped(dag.fileloc, 'r') as f:\n            code = f.read()\n            return code\n    except IOError as e:\n        error_message = \"Error {} while reading Dag id {} Code\".format(str(e), dag_id)\n        raise AirflowException(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_function(self, name):\n        return self.get_conn().projects().locations().functions().get(\n            name=name).execute(num_retries=self.num_retries)", "response": "Returns the Cloud Function with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new function in the specified location in the body.", "response": "def create_new_function(self, location, body, project_id=None):\n        \"\"\"\n        Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().create(\n            location=self._full_location(project_id, location),\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_function(self, name, body, update_mask):\n        response = self.get_conn().projects().locations().functions().patch(\n            updateMask=\",\".join(update_mask),\n            name=name,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)", "response": "Updates the cloud function with the specified name and body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading a zip file with sources to the function.", "response": "def upload_function_zip(self, location, zip_path, project_id=None):\n        \"\"\"\n        Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().generateUploadUrl(\n            parent=self._full_location(project_id, location)\n        ).execute(num_retries=self.num_retries)\n        upload_url = response.get('uploadUrl')\n        with open(zip_path, 'rb') as fp:\n            requests.put(\n                url=upload_url,\n                data=fp,\n                # Those two headers needs to be specified according to:\n                # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl\n                # nopep8\n                headers={\n                    'Content-type': 'application/zip',\n                    'x-goog-content-length-range': '0,104857600',\n                }\n            )\n        return upload_url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the specified Cloud Function.", "response": "def delete_function(self, name):\n        \"\"\"\n        Deletes the specified Cloud Function.\n\n        :param name: The name of the function.\n        :type name: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().delete(\n            name=name).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwaits for the named operation to complete - checks status of the Airflow API call.", "response": "def _wait_for_operation_to_complete(self, operation_name):\n        \"\"\"\n        Waits for the named operation to complete - checks status of the\n        asynchronous call.\n\n        :param operation_name: The name of the operation.\n        :type operation_name: str\n        :return: The response returned by the operation.\n        :rtype: dict\n        :exception: AirflowException in case error is returned.\n        \"\"\"\n        service = self.get_conn()\n        while True:\n            operation_response = service.operations().get(\n                name=operation_name,\n            ).execute(num_retries=self.num_retries)\n            if operation_response.get(\"done\"):\n                response = operation_response.get(\"response\")\n                error = operation_response.get(\"error\")\n                # Note, according to documentation always either response or error is\n                # set when \"done\" == True\n                if error:\n                    raise AirflowException(str(error))\n                return response\n            time.sleep(TIME_TO_SLEEP_IN_SECONDS)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef publish(self, project, topic, messages):\n        body = {'messages': messages}\n        full_topic = _format_topic(project, topic)\n        request = self.get_conn().projects().topics().publish(\n            topic=full_topic, body=body)\n        try:\n            request.execute(num_retries=self.num_retries)\n        except HttpError as e:\n            raise PubSubException(\n                'Error publishing to topic {}'.format(full_topic), e)", "response": "Publishes messages to a Pub / Sub topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_topic(self, project, topic, fail_if_exists=False):\n        service = self.get_conn()\n        full_topic = _format_topic(project, topic)\n        try:\n            service.projects().topics().create(\n                name=full_topic, body={}).execute(num_retries=self.num_retries)\n        except HttpError as e:\n            # Status code 409 indicates that the topic already exists.\n            if str(e.resp['status']) == '409':\n                message = 'Topic already exists: {}'.format(full_topic)\n                self.log.warning(message)\n                if fail_if_exists:\n                    raise PubSubException(message)\n            else:\n                raise PubSubException(\n                    'Error creating topic {}'.format(full_topic), e)", "response": "Creates a Pub / Sub topic."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_topic(self, project, topic, fail_if_not_exists=False):\n        service = self.get_conn()\n        full_topic = _format_topic(project, topic)\n        try:\n            service.projects().topics().delete(topic=full_topic).execute(num_retries=self.num_retries)\n        except HttpError as e:\n            # Status code 409 indicates that the topic was not found\n            if str(e.resp['status']) == '404':\n                message = 'Topic does not exist: {}'.format(full_topic)\n                self.log.warning(message)\n                if fail_if_not_exists:\n                    raise PubSubException(message)\n            else:\n                raise PubSubException(\n                    'Error deleting topic {}'.format(full_topic), e)", "response": "Deletes a Pub / Sub topic if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Pub / Sub subscription.", "response": "def create_subscription(self, topic_project, topic, subscription=None,\n                            subscription_project=None, ack_deadline_secs=10,\n                            fail_if_exists=False):\n        \"\"\"Creates a Pub/Sub subscription, if it does not already exist.\n\n        :param topic_project: the GCP project ID of the topic that the\n            subscription will be bound to.\n        :type topic_project: str\n        :param topic: the Pub/Sub topic name that the subscription will be bound\n            to create; do not include the ``projects/{project}/subscriptions/``\n            prefix.\n        :type topic: str\n        :param subscription: the Pub/Sub subscription name. If empty, a random\n            name will be generated using the uuid module\n        :type subscription: str\n        :param subscription_project: the GCP project ID where the subscription\n            will be created. If unspecified, ``topic_project`` will be used.\n        :type subscription_project: str\n        :param ack_deadline_secs: Number of seconds that a subscriber has to\n            acknowledge each message pulled from the subscription\n        :type ack_deadline_secs: int\n        :param fail_if_exists: if set, raise an exception if the topic\n            already exists\n        :type fail_if_exists: bool\n        :return: subscription name which will be the system-generated value if\n            the ``subscription`` parameter is not supplied\n        :rtype: str\n        \"\"\"\n        service = self.get_conn()\n        full_topic = _format_topic(topic_project, topic)\n        if not subscription:\n            subscription = 'sub-{}'.format(uuid4())\n        if not subscription_project:\n            subscription_project = topic_project\n        full_subscription = _format_subscription(subscription_project,\n                                                 subscription)\n        body = {\n            'topic': full_topic,\n            'ackDeadlineSeconds': ack_deadline_secs\n        }\n        try:\n            service.projects().subscriptions().create(\n                name=full_subscription, body=body).execute(num_retries=self.num_retries)\n        except HttpError as e:\n            # Status code 409 indicates that the subscription already exists.\n            if str(e.resp['status']) == '409':\n                message = 'Subscription already exists: {}'.format(\n                    full_subscription)\n                self.log.warning(message)\n                if fail_if_exists:\n                    raise PubSubException(message)\n            else:\n                raise PubSubException(\n                    'Error creating subscription {}'.format(full_subscription),\n                    e)\n        return subscription"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_subscription(self, project, subscription,\n                            fail_if_not_exists=False):\n        \"\"\"Deletes a Pub/Sub subscription, if it exists.\n\n        :param project: the GCP project ID where the subscription exists\n        :type project: str\n        :param subscription: the Pub/Sub subscription name to delete; do not\n            include the ``projects/{project}/subscriptions/`` prefix.\n        :type subscription: str\n        :param fail_if_not_exists: if set, raise an exception if the topic\n            does not exist\n        :type fail_if_not_exists: bool\n        \"\"\"\n        service = self.get_conn()\n        full_subscription = _format_subscription(project, subscription)\n        try:\n            service.projects().subscriptions().delete(\n                subscription=full_subscription).execute(num_retries=self.num_retries)\n        except HttpError as e:\n            # Status code 404 indicates that the subscription was not found\n            if str(e.resp['status']) == '404':\n                message = 'Subscription does not exist: {}'.format(\n                    full_subscription)\n                self.log.warning(message)\n                if fail_if_not_exists:\n                    raise PubSubException(message)\n            else:\n                raise PubSubException(\n                    'Error deleting subscription {}'.format(full_subscription),\n                    e)", "response": "Deletes a Pub / Sub subscription."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npull up to max_messages messages from the specified subscription.", "response": "def pull(self, project, subscription, max_messages,\n             return_immediately=False):\n        \"\"\"Pulls up to ``max_messages`` messages from Pub/Sub subscription.\n\n        :param project: the GCP project ID where the subscription exists\n        :type project: str\n        :param subscription: the Pub/Sub subscription name to pull from; do not\n            include the 'projects/{project}/topics/' prefix.\n        :type subscription: str\n        :param max_messages: The maximum number of messages to return from\n            the Pub/Sub API.\n        :type max_messages: int\n        :param return_immediately: If set, the Pub/Sub API will immediately\n            return if no messages are available. Otherwise, the request will\n            block for an undisclosed, but bounded period of time\n        :type return_immediately: bool\n        :return: A list of Pub/Sub ReceivedMessage objects each containing\n            an ``ackId`` property and a ``message`` property, which includes\n            the base64-encoded message content. See\n            https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions/pull#ReceivedMessage\n        \"\"\"\n        service = self.get_conn()\n        full_subscription = _format_subscription(project, subscription)\n        body = {\n            'maxMessages': max_messages,\n            'returnImmediately': return_immediately\n        }\n        try:\n            response = service.projects().subscriptions().pull(\n                subscription=full_subscription, body=body).execute(num_retries=self.num_retries)\n            return response.get('receivedMessages', [])\n        except HttpError as e:\n            raise PubSubException(\n                'Error pulling messages from subscription {}'.format(\n                    full_subscription), e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef acknowledge(self, project, subscription, ack_ids):\n        service = self.get_conn()\n        full_subscription = _format_subscription(project, subscription)\n        try:\n            service.projects().subscriptions().acknowledge(\n                subscription=full_subscription, body={'ackIds': ack_ids}\n            ).execute(num_retries=self.num_retries)\n        except HttpError as e:\n            raise PubSubException(\n                'Error acknowledging {} messages pulled from subscription {}'\n                .format(len(ack_ids), full_subscription), e)", "response": "Acknowledge the specified messages from the specified topic."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap around the private _get_dep_statuses method that contains some global checks for all dependencies. :param ti: the task instance to get the dependency status for :type ti: airflow.models.TaskInstance :param session: database session :type session: sqlalchemy.orm.session.Session :param dep_context: the context for which this dependency should be evaluated for :type dep_context: DepContext", "response": "def get_dep_statuses(self, ti, session, dep_context=None):\n        \"\"\"\n        Wrapper around the private _get_dep_statuses method that contains some global\n        checks for all dependencies.\n\n        :param ti: the task instance to get the dependency status for\n        :type ti: airflow.models.TaskInstance\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        :param dep_context: the context for which this dependency should be evaluated for\n        :type dep_context: DepContext\n        \"\"\"\n        # this avoids a circular dependency\n        from airflow.ti_deps.dep_context import DepContext\n\n        if dep_context is None:\n            dep_context = DepContext()\n\n        if self.IGNOREABLE and dep_context.ignore_all_deps:\n            yield self._passing_status(\n                reason=\"Context specified all dependencies should be ignored.\")\n            return\n\n        if self.IS_TASK_DEP and dep_context.ignore_task_deps:\n            yield self._passing_status(\n                reason=\"Context specified all task dependencies should be ignored.\")\n            return\n\n        for dep_status in self._get_dep_statuses(ti, session, dep_context):\n            yield dep_status"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_met(self, ti, session, dep_context=None):\n        return all(status.passed for status in\n                   self.get_dep_statuses(ti, session, dep_context))", "response": "Returns whether or not this dependency is met for a given task instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterable of strings that explain why this dependency was met.", "response": "def get_failure_reasons(self, ti, session, dep_context=None):\n        \"\"\"\n        Returns an iterable of strings that explain why this dependency wasn't met.\n\n        :param ti: the task instance to see if this dependency is met for\n        :type ti: airflow.models.TaskInstance\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        :param dep_context: The context this dependency is being checked under that stores\n            state that can be used by this dependency.\n        :type dep_context: BaseDepContext\n        \"\"\"\n        for dep_status in self.get_dep_statuses(ti, session, dep_context):\n            if not dep_status.passed:\n                yield dep_status.reason"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a config file for s3 credentials.", "response": "def _parse_s3_config(config_file_name, config_format='boto', profile=None):\n    \"\"\"\n    Parses a config file for s3 credentials. Can currently\n    parse boto, s3cmd.conf and AWS SDK config formats\n\n    :param config_file_name: path to the config file\n    :type config_file_name: str\n    :param config_format: config type. One of \"boto\", \"s3cmd\" or \"aws\".\n        Defaults to \"boto\"\n    :type config_format: str\n    :param profile: profile name in AWS type config file\n    :type profile: str\n    \"\"\"\n    config = configparser.ConfigParser()\n    if config.read(config_file_name):  # pragma: no cover\n        sections = config.sections()\n    else:\n        raise AirflowException(\"Couldn't read {0}\".format(config_file_name))\n    # Setting option names depending on file format\n    if config_format is None:\n        config_format = 'boto'\n    conf_format = config_format.lower()\n    if conf_format == 'boto':  # pragma: no cover\n        if profile is not None and 'profile ' + profile in sections:\n            cred_section = 'profile ' + profile\n        else:\n            cred_section = 'Credentials'\n    elif conf_format == 'aws' and profile is not None:\n        cred_section = profile\n    else:\n        cred_section = 'default'\n    # Option names\n    if conf_format in ('boto', 'aws'):  # pragma: no cover\n        key_id_option = 'aws_access_key_id'\n        secret_key_option = 'aws_secret_access_key'\n        # security_token_option = 'aws_security_token'\n    else:\n        key_id_option = 'access_key'\n        secret_key_option = 'secret_key'\n    # Actual Parsing\n    if cred_section not in sections:\n        raise AirflowException(\"This config file format is not recognized\")\n    else:\n        try:\n            access_key = config.get(cred_section, key_id_option)\n            secret_key = config.get(cred_section, secret_key_option)\n        except Exception:\n            logging.warning(\"Option Error in parsing s3 config file\")\n            raise\n        return access_key, secret_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_credentials(self, region_name=None):\n        session, _ = self._get_credentials(region_name)\n        # Credentials are refreshable, so accessing your access key and\n        # secret key separately can lead to a race condition.\n        # See https://stackoverflow.com/a/36291428/8283373\n        return session.get_credentials().get_frozen_credentials()", "response": "Get the underlying botocore. Credentials object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expand_role(self, role):\n        if '/' in role:\n            return role\n        else:\n            return self.get_client_type('iam').get_role(RoleName=role)['Role']['Arn']", "response": "Expand the role name to a resource name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_conn(self):\n        conn = self.get_connection(self.vertica_conn_id)\n        conn_config = {\n            \"user\": conn.login,\n            \"password\": conn.password or '',\n            \"database\": conn.schema,\n            \"host\": conn.host or 'localhost'\n        }\n\n        if not conn.port:\n            conn_config[\"port\"] = 5433\n        else:\n            conn_config[\"port\"] = int(conn.port)\n\n        conn = connect(**conn_config)\n        return conn", "response": "Returns a connection object for the current verticaql version of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the context of the given logger.", "response": "def set_context(logger, value):\n    \"\"\"\n    Walks the tree of loggers and tries to set the context for each handler\n    :param logger: logger\n    :param value: value to set\n    \"\"\"\n    _logger = logger\n    while _logger:\n        for handler in _logger.handlers:\n            try:\n                handler.set_context(value)\n            except AttributeError:\n                # Not all handlers need to have context passed in so we ignore\n                # the error when handlers do not have set_context defined.\n                pass\n        if _logger.propagate is True:\n            _logger = _logger.parent\n        else:\n            _logger = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write(self, message):\n        if not message.endswith(\"\\n\"):\n            self._buffer += message\n        else:\n            self._buffer += message\n            self.logger.log(self.level, self._buffer.rstrip())\n            self._buffer = str()", "response": "Write a message to the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flush(self):\n        if len(self._buffer) > 0:\n            self.logger.log(self.level, self._buffer)\n            self._buffer = str()", "response": "Flushes all logging output to the logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef correct_maybe_zipped(fileloc):\n\n    _, archive, filename = re.search(\n        r'((.*\\.zip){})?(.*)'.format(re.escape(os.sep)), fileloc).groups()\n    if archive and zipfile.is_zipfile(archive):\n        return archive\n    else:\n        return fileloc", "response": "Check if the file is a zipped folder. If it is a file then it is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_py_file_paths(directory, safe_mode=True,\n                       include_examples=None):\n    \"\"\"\n    Traverse a directory and look for Python files.\n\n    :param directory: the directory to traverse\n    :type directory: unicode\n    :param safe_mode: whether to use a heuristic to determine whether a file\n        contains Airflow DAG definitions\n    :return: a list of paths to Python files in the specified directory\n    :rtype: list[unicode]\n    \"\"\"\n    if include_examples is None:\n        include_examples = conf.getboolean('core', 'LOAD_EXAMPLES')\n    file_paths = []\n    if directory is None:\n        return []\n    elif os.path.isfile(directory):\n        return [directory]\n    elif os.path.isdir(directory):\n        patterns_by_dir = {}\n        for root, dirs, files in os.walk(directory, followlinks=True):\n            patterns = patterns_by_dir.get(root, [])\n            ignore_file = os.path.join(root, '.airflowignore')\n            if os.path.isfile(ignore_file):\n                with open(ignore_file, 'r') as f:\n                    # If we have new patterns create a copy so we don't change\n                    # the previous list (which would affect other subdirs)\n                    patterns += [re.compile(p) for p in f.read().split('\\n') if p]\n\n            # If we can ignore any subdirs entirely we should - fewer paths\n            # to walk is better. We have to modify the ``dirs`` array in\n            # place for this to affect os.walk\n            dirs[:] = [\n                d\n                for d in dirs\n                if not any(p.search(os.path.join(root, d)) for p in patterns)\n            ]\n\n            # We want patterns defined in a parent folder's .airflowignore to\n            # apply to subdirs too\n            for d in dirs:\n                patterns_by_dir[os.path.join(root, d)] = patterns\n\n            for f in files:\n                try:\n                    file_path = os.path.join(root, f)\n                    if not os.path.isfile(file_path):\n                        continue\n                    mod_name, file_ext = os.path.splitext(\n                        os.path.split(file_path)[-1])\n                    if file_ext != '.py' and not zipfile.is_zipfile(file_path):\n                        continue\n                    if any([re.findall(p, file_path) for p in patterns]):\n                        continue\n\n                    # Heuristic that guesses whether a Python file contains an\n                    # Airflow DAG definition.\n                    might_contain_dag = True\n                    if safe_mode and not zipfile.is_zipfile(file_path):\n                        with open(file_path, 'rb') as fp:\n                            content = fp.read()\n                            might_contain_dag = all(\n                                [s in content for s in (b'DAG', b'airflow')])\n\n                    if not might_contain_dag:\n                        continue\n\n                    file_paths.append(file_path)\n                except Exception:\n                    log = LoggingMixin().log\n                    log.exception(\"Error while examining %s\", f)\n    if include_examples:\n        import airflow.example_dags\n        example_dag_folder = airflow.example_dags.__path__[0]\n        file_paths.extend(list_py_file_paths(example_dag_folder, safe_mode, False))\n    return file_paths", "response": "Walk a directory and look for Python files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_task_instance(self, session=None, lock_for_update=False):\n        TI = airflow.models.TaskInstance\n\n        qry = session.query(TI).filter(\n            TI.dag_id == self._dag_id,\n            TI.task_id == self._task_id,\n            TI.execution_date == self._execution_date)\n\n        if lock_for_update:\n            ti = qry.with_for_update().first()\n        else:\n            ti = qry.first()\n        return ti", "response": "Constructs a TaskInstance from the database based on the primary key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the base class for the given DAG ID.", "response": "def get_dag(self, dag_id):\n        \"\"\"\n        :param dag_id: DAG ID\n        :type dag_id: unicode\n        :return: if the given DAG ID exists in the bag, return the BaseDag\n        corresponding to that ID. Otherwise, throw an Exception\n        :rtype: airflow.utils.dag_processing.SimpleDag\n        \"\"\"\n        if dag_id not in self.dag_id_to_simple_dag:\n            raise AirflowException(\"Unknown DAG ID {}\".format(dag_id))\n        return self.dag_id_to_simple_dag[dag_id]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlaunching DagFileProcessorManager processor and start parsing loop in manager.", "response": "def start(self):\n        \"\"\"\n        Launch DagFileProcessorManager processor and start DAG parsing loop in manager.\n        \"\"\"\n        self._process = self._launch_process(self._dag_directory,\n                                             self._file_paths,\n                                             self._max_runs,\n                                             self._processor_factory,\n                                             self._child_signal_conn,\n                                             self._stat_queue,\n                                             self._result_queue,\n                                             self._async_mode)\n        self.log.info(\"Launched DagFileProcessorManager with pid: %s\", self._process.pid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nharvest simple dags from result queue and sync metadata from stat queue and return list of parsing result in SimpleDag format.", "response": "def harvest_simple_dags(self):\n        \"\"\"\n        Harvest DAG parsing results from result queue and sync metadata from stat queue.\n        :return: List of parsing result in SimpleDag format.\n        \"\"\"\n        # Metadata and results to be harvested can be inconsistent,\n        # but it should not be a big problem.\n        self._sync_metadata()\n        # Heartbeating after syncing metadata so we do not restart manager\n        # if it processed all files for max_run times and exit normally.\n        self._heartbeat_manager()\n        simple_dags = []\n        # multiprocessing.Queue().qsize will not work on MacOS.\n        if sys.platform == \"darwin\":\n            qsize = self._result_count\n        else:\n            qsize = self._result_queue.qsize()\n        for _ in range(qsize):\n            simple_dags.append(self._result_queue.get())\n\n        self._result_count = 0\n\n        return simple_dags"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _heartbeat_manager(self):\n        if self._process and not self._process.is_alive() and not self.done:\n            self.start()", "response": "Start the Heartbeat DAG file processor if it is not alive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sync_metadata(self):\n        while not self._stat_queue.empty():\n            stat = self._stat_queue.get()\n            self._file_paths = stat.file_paths\n            self._all_pids = stat.all_pids\n            self._done = stat.done\n            self._all_files_processed = stat.all_files_processed\n            self._result_count += stat.result_count", "response": "Sync metadata from stat queue and only keep the latest stat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef terminate(self):\n        self.log.info(\"Sending termination message to manager.\")\n        self._child_signal_conn.send(DagParsingSignal.TERMINATE_MANAGER)", "response": "Send a termination signal to the manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef end(self):\n        if not self._process:\n            self.log.warn('Ending without manager process.')\n            return\n        this_process = psutil.Process(os.getpid())\n        try:\n            manager_process = psutil.Process(self._process.pid)\n        except psutil.NoSuchProcess:\n            self.log.info(\"Manager process not running.\")\n            return\n\n        # First try SIGTERM\n        if manager_process.is_running() \\\n                and manager_process.pid in [x.pid for x in this_process.children()]:\n            self.log.info(\"Terminating manager process: %s\", manager_process.pid)\n            manager_process.terminate()\n            # TODO: Remove magic number\n            timeout = 5\n            self.log.info(\"Waiting up to %ss for manager process to exit...\", timeout)\n            try:\n                psutil.wait_procs({manager_process}, timeout)\n            except psutil.TimeoutExpired:\n                self.log.debug(\"Ran out of time while waiting for \"\n                               \"processes to exit\")\n\n        # Then SIGKILL\n        if manager_process.is_running() \\\n                and manager_process.pid in [x.pid for x in this_process.children()]:\n            self.log.info(\"Killing manager process: %s\", manager_process.pid)\n            manager_process.kill()\n            manager_process.wait()", "response": "Terminate the manager process and then kill the manager process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _exit_gracefully(self, signum, frame):\n        self.log.info(\"Exiting gracefully upon receiving signal %s\", signum)\n        self.terminate()\n        self.end()\n        self.log.debug(\"Finished terminating DAG processors.\")\n        sys.exit(os.EX_OK)", "response": "Helper method to clean up DAG file processors to avoid leaving orphan processes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing multiple processes to parse and generate tasks for the DAGs in parallel. By processing them in separate processes, we can get parallelism and isolation from potentially harmful user code.", "response": "def start(self):\n        \"\"\"\n        Use multiple processes to parse and generate tasks for the\n        DAGs in parallel. By processing them in separate processes,\n        we can get parallelism and isolation from potentially harmful\n        user code.\n        \"\"\"\n\n        self.log.info(\"Processing files using up to %s processes at a time \", self._parallelism)\n        self.log.info(\"Process each file at most once every %s seconds\", self._file_process_interval)\n        self.log.info(\n            \"Checking for new files in %s every %s seconds\", self._dag_directory, self.dag_dir_list_interval\n        )\n\n        if self._async_mode:\n            self.log.debug(\"Starting DagFileProcessorManager in async mode\")\n            self.start_in_async()\n        else:\n            self.log.debug(\"Starting DagFileProcessorManager in sync mode\")\n            self.start_in_sync()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_in_async(self):\n        while True:\n            loop_start_time = time.time()\n\n            if self._signal_conn.poll():\n                agent_signal = self._signal_conn.recv()\n                if agent_signal == DagParsingSignal.TERMINATE_MANAGER:\n                    self.terminate()\n                    break\n                elif agent_signal == DagParsingSignal.END_MANAGER:\n                    self.end()\n                    sys.exit(os.EX_OK)\n\n            self._refresh_dag_dir()\n\n            simple_dags = self.heartbeat()\n            for simple_dag in simple_dags:\n                self._result_queue.put(simple_dag)\n\n            self._print_stat()\n\n            all_files_processed = all(self.get_last_finish_time(x) is not None\n                                      for x in self.file_paths)\n            max_runs_reached = self.max_runs_reached()\n\n            dag_parsing_stat = DagParsingStat(self._file_paths,\n                                              self.get_all_pids(),\n                                              max_runs_reached,\n                                              all_files_processed,\n                                              len(simple_dags))\n            self._stat_queue.put(dag_parsing_stat)\n\n            if max_runs_reached:\n                self.log.info(\"Exiting dag parsing loop as all files \"\n                              \"have been processed %s times\", self._max_runs)\n                break\n\n            loop_duration = time.time() - loop_start_time\n            if loop_duration < 1:\n                sleep_length = 1 - loop_duration\n                self.log.debug(\"Sleeping for %.2f seconds to prevent excessive logging\", sleep_length)\n                time.sleep(sleep_length)", "response": "This method is used to start the dag parsing loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses DAG files in a loop controlled by DagParsingSignal. Actual DAG parsing loop will run once upon receiving one agent heartbeat message and will report done when finished the loop.", "response": "def start_in_sync(self):\n        \"\"\"\n        Parse DAG files in a loop controlled by DagParsingSignal.\n        Actual DAG parsing loop will run once upon receiving one\n        agent heartbeat message and will report done when finished the loop.\n        \"\"\"\n        while True:\n            agent_signal = self._signal_conn.recv()\n            if agent_signal == DagParsingSignal.TERMINATE_MANAGER:\n                self.terminate()\n                break\n            elif agent_signal == DagParsingSignal.END_MANAGER:\n                self.end()\n                sys.exit(os.EX_OK)\n            elif agent_signal == DagParsingSignal.AGENT_HEARTBEAT:\n\n                self._refresh_dag_dir()\n\n                simple_dags = self.heartbeat()\n                for simple_dag in simple_dags:\n                    self._result_queue.put(simple_dag)\n\n                self._print_stat()\n\n                all_files_processed = all(self.get_last_finish_time(x) is not None\n                                          for x in self.file_paths)\n                max_runs_reached = self.max_runs_reached()\n\n                dag_parsing_stat = DagParsingStat(self._file_paths,\n                                                  self.get_all_pids(),\n                                                  self.max_runs_reached(),\n                                                  all_files_processed,\n                                                  len(simple_dags))\n                self._stat_queue.put(dag_parsing_stat)\n\n                self.wait_until_finished()\n                self._signal_conn.send(DagParsingSignal.MANAGER_DONE)\n\n                if max_runs_reached:\n                    self.log.info(\"Exiting dag parsing loop as all files \"\n                                  \"have been processed %s times\", self._max_runs)\n                    self._signal_conn.send(DagParsingSignal.MANAGER_DONE)\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefresh the file paths from the dag dir.", "response": "def _refresh_dag_dir(self):\n        \"\"\"\n        Refresh file paths from dag dir if we haven't done it for too long.\n        \"\"\"\n        elapsed_time_since_refresh = (timezone.utcnow() -\n                                      self.last_dag_dir_refresh_time).total_seconds()\n        if elapsed_time_since_refresh > self.dag_dir_list_interval:\n            # Build up a list of Python files that could contain DAGs\n            self.log.info(\"Searching for files in %s\", self._dag_directory)\n            self._file_paths = list_py_file_paths(self._dag_directory)\n            self.last_dag_dir_refresh_time = timezone.utcnow()\n            self.log.info(\"There are %s files in %s\", len(self._file_paths), self._dag_directory)\n            self.set_file_paths(self._file_paths)\n\n            try:\n                self.log.debug(\"Removing old import errors\")\n                self.clear_nonexistent_import_errors()\n            except Exception:\n                self.log.exception(\"Error removing old import errors\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _print_stat(self):\n        if ((timezone.utcnow() - self.last_stat_print_time).total_seconds() >\n                self.print_stats_interval):\n            if len(self._file_paths) > 0:\n                self._log_file_processing_stats(self._file_paths)\n            self.last_stat_print_time = timezone.utcnow()", "response": "Print out stats about how fast the files are getting processed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_nonexistent_import_errors(self, session):\n        query = session.query(errors.ImportError)\n        if self._file_paths:\n            query = query.filter(\n                ~errors.ImportError.filename.in_(self._file_paths)\n            )\n        query.delete(synchronize_session='fetch')\n        session.commit()", "response": "Clears the import errors for files that no longer exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint out stats about how files are being processed.", "response": "def _log_file_processing_stats(self, known_file_paths):\n        \"\"\"\n        Print out stats about how files are getting processed.\n\n        :param known_file_paths: a list of file paths that may contain Airflow\n            DAG definitions\n        :type known_file_paths: list[unicode]\n        :return: None\n        \"\"\"\n\n        # File Path: Path to the file containing the DAG definition\n        # PID: PID associated with the process that's processing the file. May\n        # be empty.\n        # Runtime: If the process is currently running, how long it's been\n        # running for in seconds.\n        # Last Runtime: If the process ran before, how long did it take to\n        # finish in seconds\n        # Last Run: When the file finished processing in the previous run.\n        headers = [\"File Path\",\n                   \"PID\",\n                   \"Runtime\",\n                   \"Last Runtime\",\n                   \"Last Run\"]\n\n        rows = []\n        for file_path in known_file_paths:\n            last_runtime = self.get_last_runtime(file_path)\n            file_name = os.path.basename(file_path)\n            file_name = os.path.splitext(file_name)[0].replace(os.sep, '.')\n            if last_runtime:\n                Stats.gauge(\n                    'dag_processing.last_runtime.{}'.format(file_name),\n                    last_runtime\n                )\n\n            processor_pid = self.get_pid(file_path)\n            processor_start_time = self.get_start_time(file_path)\n            runtime = ((timezone.utcnow() - processor_start_time).total_seconds()\n                       if processor_start_time else None)\n            last_run = self.get_last_finish_time(file_path)\n            if last_run:\n                seconds_ago = (timezone.utcnow() - last_run).total_seconds()\n                Stats.gauge(\n                    'dag_processing.last_run.seconds_ago.{}'.format(file_name),\n                    seconds_ago\n                )\n\n            rows.append((file_path,\n                         processor_pid,\n                         runtime,\n                         last_runtime,\n                         last_run))\n\n        # Sort by longest last runtime. (Can't sort None values in python3)\n        rows = sorted(rows, key=lambda x: x[3] or 0.0)\n\n        formatted_rows = []\n        for file_path, pid, runtime, last_runtime, last_run in rows:\n            formatted_rows.append((file_path,\n                                   pid,\n                                   \"{:.2f}s\".format(runtime)\n                                   if runtime else None,\n                                   \"{:.2f}s\".format(last_runtime)\n                                   if last_runtime else None,\n                                   last_run.strftime(\"%Y-%m-%dT%H:%M:%S\")\n                                   if last_run else None))\n        log_str = (\"\\n\" +\n                   \"=\" * 80 +\n                   \"\\n\" +\n                   \"DAG File Processing Stats\\n\\n\" +\n                   tabulate(formatted_rows, headers=headers) +\n                   \"\\n\" +\n                   \"=\" * 80)\n\n        self.log.info(log_str)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the process ID of the process processing the given file", "response": "def get_pid(self, file_path):\n        \"\"\"\n        :param file_path: the path to the file that's being processed\n        :type file_path: unicode\n        :return: the PID of the process processing the given file or None if\n            the specified file is not being processed\n        :rtype: int\n        \"\"\"\n        if file_path in self._processors:\n            return self._processors[file_path].pid\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the current runtime of the process that s currently processing the specified file", "response": "def get_runtime(self, file_path):\n        \"\"\"\n        :param file_path: the path to the file that's being processed\n        :type file_path: unicode\n        :return: the current runtime (in seconds) of the process that's\n            processing the specified file or None if the file is not currently\n            being processed\n        \"\"\"\n        if file_path in self._processors:\n            return (timezone.utcnow() - self._processors[file_path].start_time)\\\n                .total_seconds()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_start_time(self, file_path):\n        if file_path in self._processors:\n            return self._processors[file_path].start_time\n        return None", "response": "returns the start time of the process that s processing the\n            specified file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the internal list of file paths to new set of paths to DAG definition files.", "response": "def set_file_paths(self, new_file_paths):\n        \"\"\"\n        Update this with a new set of paths to DAG definition files.\n\n        :param new_file_paths: list of paths to DAG definition files\n        :type new_file_paths: list[unicode]\n        :return: None\n        \"\"\"\n        self._file_paths = new_file_paths\n        self._file_path_queue = [x for x in self._file_path_queue\n                                 if x in new_file_paths]\n        # Stop processors that are working on deleted files\n        filtered_processors = {}\n        for file_path, processor in self._processors.items():\n            if file_path in new_file_paths:\n                filtered_processors[file_path] = processor\n            else:\n                self.log.warning(\"Stopping processor for %s\", file_path)\n                processor.terminate()\n        self._processors = filtered_processors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait until all the processors are done.", "response": "def wait_until_finished(self):\n        \"\"\"\n        Sleeps until all the processors are done.\n        \"\"\"\n        for file_path, processor in self._processors.items():\n            while not processor.done:\n                time.sleep(0.1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef heartbeat(self):\n        finished_processors = {}\n        \"\"\":type : dict[unicode, AbstractDagFileProcessor]\"\"\"\n        running_processors = {}\n        \"\"\":type : dict[unicode, AbstractDagFileProcessor]\"\"\"\n\n        for file_path, processor in self._processors.items():\n            if processor.done:\n                self.log.debug(\"Processor for %s finished\", file_path)\n                now = timezone.utcnow()\n                finished_processors[file_path] = processor\n                self._last_runtime[file_path] = (now -\n                                                 processor.start_time).total_seconds()\n                self._last_finish_time[file_path] = now\n                self._run_count[file_path] += 1\n            else:\n                running_processors[file_path] = processor\n        self._processors = running_processors\n\n        self.log.debug(\"%s/%s DAG parsing processes running\",\n                       len(self._processors), self._parallelism)\n\n        self.log.debug(\"%s file paths queued for processing\",\n                       len(self._file_path_queue))\n\n        # Collect all the DAGs that were found in the processed files\n        simple_dags = []\n        for file_path, processor in finished_processors.items():\n            if processor.result is None:\n                self.log.warning(\n                    \"Processor for %s exited with return code %s.\",\n                    processor.file_path, processor.exit_code\n                )\n            else:\n                for simple_dag in processor.result:\n                    simple_dags.append(simple_dag)\n\n        # Generate more file paths to process if we processed all the files\n        # already.\n        if len(self._file_path_queue) == 0:\n            # If the file path is already being processed, or if a file was\n            # processed recently, wait until the next batch\n            file_paths_in_progress = self._processors.keys()\n            now = timezone.utcnow()\n            file_paths_recently_processed = []\n            for file_path in self._file_paths:\n                last_finish_time = self.get_last_finish_time(file_path)\n                if (last_finish_time is not None and\n                    (now - last_finish_time).total_seconds() <\n                        self._file_process_interval):\n                    file_paths_recently_processed.append(file_path)\n\n            files_paths_at_run_limit = [file_path\n                                        for file_path, num_runs in self._run_count.items()\n                                        if num_runs == self._max_runs]\n\n            files_paths_to_queue = list(set(self._file_paths) -\n                                        set(file_paths_in_progress) -\n                                        set(file_paths_recently_processed) -\n                                        set(files_paths_at_run_limit))\n\n            for file_path, processor in self._processors.items():\n                self.log.debug(\n                    \"File path %s is still being processed (started: %s)\",\n                    processor.file_path, processor.start_time.isoformat()\n                )\n\n            self.log.debug(\n                \"Queuing the following files for processing:\\n\\t%s\",\n                \"\\n\\t\".join(files_paths_to_queue)\n            )\n\n            self._file_path_queue.extend(files_paths_to_queue)\n\n        zombies = self._find_zombies()\n\n        # Start more processors if we have enough slots and files to process\n        while (self._parallelism - len(self._processors) > 0 and\n               len(self._file_path_queue) > 0):\n            file_path = self._file_path_queue.pop(0)\n            processor = self._processor_factory(file_path, zombies)\n\n            processor.start()\n            self.log.debug(\n                \"Started a process (PID: %s) to generate tasks for %s\",\n                processor.pid, file_path\n            )\n            self._processors[file_path] = processor\n\n        # Update heartbeat count.\n        self._run_count[self._heart_beat_key] += 1\n\n        return simple_dags", "response": "This method is called by the manager loop to process all the DAGs that have finished processing and return the list of SimpleDags that were produced by the processors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding zombie task instances which are tasks haven t heartbeated for too long.", "response": "def _find_zombies(self, session):\n        \"\"\"\n        Find zombie task instances, which are tasks haven't heartbeated for too long.\n        :return: Zombie task instances in SimpleTaskInstance format.\n        \"\"\"\n        now = timezone.utcnow()\n        zombies = []\n        if (now - self._last_zombie_query_time).total_seconds() \\\n                > self._zombie_query_interval:\n            # to avoid circular imports\n            from airflow.jobs import LocalTaskJob as LJ\n            self.log.info(\"Finding 'running' jobs without a recent heartbeat\")\n            TI = airflow.models.TaskInstance\n            limit_dttm = timezone.utcnow() - timedelta(\n                seconds=self._zombie_threshold_secs)\n            self.log.info(\"Failing jobs without heartbeat after %s\", limit_dttm)\n\n            tis = (\n                session.query(TI)\n                .join(LJ, TI.job_id == LJ.id)\n                .filter(TI.state == State.RUNNING)\n                .filter(\n                    or_(\n                        LJ.state != State.RUNNING,\n                        LJ.latest_heartbeat < limit_dttm,\n                    )\n                ).all()\n            )\n            self._last_zombie_query_time = timezone.utcnow()\n            for ti in tis:\n                zombies.append(SimpleTaskInstance(ti))\n\n        return zombies"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef max_runs_reached(self):\n        if self._max_runs == -1:  # Unlimited runs.\n            return False\n        for file_path in self._file_paths:\n            if self._run_count[file_path] < self._max_runs:\n                return False\n        if self._run_count[self._heart_beat_key] < self._max_runs:\n            return False\n        return True", "response": "Returns True if all file paths have been processed max_runs times\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nterminate all child processes on exit.", "response": "def end(self):\n        \"\"\"\n        Kill all child processes on exit since we don't want to leave\n        them as orphaned.\n        \"\"\"\n        pids_to_kill = self.get_all_pids()\n        if len(pids_to_kill) > 0:\n            # First try SIGTERM\n            this_process = psutil.Process(os.getpid())\n            # Only check child processes to ensure that we don't have a case\n            # where we kill the wrong process because a child process died\n            # but the PID got reused.\n            child_processes = [x for x in this_process.children(recursive=True)\n                               if x.is_running() and x.pid in pids_to_kill]\n            for child in child_processes:\n                self.log.info(\"Terminating child PID: %s\", child.pid)\n                child.terminate()\n            # TODO: Remove magic number\n            timeout = 5\n            self.log.info(\"Waiting up to %s seconds for processes to exit...\", timeout)\n            try:\n                psutil.wait_procs(\n                    child_processes, timeout=timeout,\n                    callback=lambda x: self.log.info('Terminated PID %s', x.pid))\n            except psutil.TimeoutExpired:\n                self.log.debug(\"Ran out of time while waiting for processes to exit\")\n\n            # Then SIGKILL\n            child_processes = [x for x in this_process.children(recursive=True)\n                               if x.is_running() and x.pid in pids_to_kill]\n            if len(child_processes) > 0:\n                self.log.info(\"SIGKILL processes that did not terminate gracefully\")\n                for child in child_processes:\n                    self.log.info(\"Killing child PID: %s\", child.pid)\n                    child.kill()\n                    child.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a SSH connection to the remote host.", "response": "def get_conn(self):\n        \"\"\"\n        Opens a ssh connection to the remote host.\n\n        :rtype: paramiko.client.SSHClient\n        \"\"\"\n\n        self.log.debug('Creating SSH client for conn_id: %s', self.ssh_conn_id)\n        client = paramiko.SSHClient()\n        if not self.allow_host_key_change:\n            self.log.warning('Remote Identification Change is not verified. '\n                             'This wont protect against Man-In-The-Middle attacks')\n            client.load_system_host_keys()\n        if self.no_host_key_check:\n            self.log.warning('No Host Key Verification. This wont protect '\n                             'against Man-In-The-Middle attacks')\n            # Default is RejectPolicy\n            client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\n        if self.password and self.password.strip():\n            client.connect(hostname=self.remote_host,\n                           username=self.username,\n                           password=self.password,\n                           key_filename=self.key_file,\n                           timeout=self.timeout,\n                           compress=self.compress,\n                           port=self.port,\n                           sock=self.host_proxy)\n        else:\n            client.connect(hostname=self.remote_host,\n                           username=self.username,\n                           key_filename=self.key_file,\n                           timeout=self.timeout,\n                           compress=self.compress,\n                           port=self.port,\n                           sock=self.host_proxy)\n\n        if self.keepalive_interval:\n            client.get_transport().set_keepalive(self.keepalive_interval)\n\n        self.client = client\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a tunnel between two hosts. Like ssh - L <LOCAL_PORT > host:<REMOTE_PORT >.", "response": "def get_tunnel(self, remote_port, remote_host=\"localhost\", local_port=None):\n        \"\"\"\n        Creates a tunnel between two hosts. Like ssh -L <LOCAL_PORT>:host:<REMOTE_PORT>.\n\n        :param remote_port: The remote port to create a tunnel to\n        :type remote_port: int\n        :param remote_host: The remote host to create a tunnel to (default localhost)\n        :type remote_host: str\n        :param local_port:  The local port to attach the tunnel to\n        :type local_port: int\n\n        :return: sshtunnel.SSHTunnelForwarder object\n        \"\"\"\n\n        if local_port:\n            local_bind_address = ('localhost', local_port)\n        else:\n            local_bind_address = ('localhost',)\n\n        if self.password and self.password.strip():\n            client = SSHTunnelForwarder(self.remote_host,\n                                        ssh_port=self.port,\n                                        ssh_username=self.username,\n                                        ssh_password=self.password,\n                                        ssh_pkey=self.key_file,\n                                        ssh_proxy=self.host_proxy,\n                                        local_bind_address=local_bind_address,\n                                        remote_bind_address=(remote_host, remote_port),\n                                        logger=self.log)\n        else:\n            client = SSHTunnelForwarder(self.remote_host,\n                                        ssh_port=self.port,\n                                        ssh_username=self.username,\n                                        ssh_pkey=self.key_file,\n                                        ssh_proxy=self.host_proxy,\n                                        local_bind_address=local_bind_address,\n                                        remote_bind_address=(remote_host, remote_port),\n                                        host_pkey_directories=[],\n                                        logger=self.log)\n\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a transfer job that runs periodically.", "response": "def create_transfer_job(self, body):\n        \"\"\"\n        Creates a transfer job that runs periodically.\n\n        :param body: (Required) A request body, as described in\n            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/patch#request-body\n        :type body: dict\n        :return: transfer job.\n            See:\n            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs#TransferJob\n        :rtype: dict\n        \"\"\"\n        body = self._inject_project_id(body, BODY, PROJECT_ID)\n        return self.get_conn().transferJobs().create(body=body).execute(num_retries=self.num_retries)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_transfer_job(self, job_name, project_id=None):\n        return (\n            self.get_conn()\n            .transferJobs()\n            .get(jobName=job_name, projectId=project_id)\n            .execute(num_retries=self.num_retries)\n        )", "response": "Gets the latest state of a long - running operation in Google Storage\n            Transfer Service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_transfer_job(self, filter):\n        conn = self.get_conn()\n        filter = self._inject_project_id(filter, FILTER, FILTER_PROJECT_ID)\n        request = conn.transferJobs().list(filter=json.dumps(filter))\n        jobs = []\n\n        while request is not None:\n            response = request.execute(num_retries=self.num_retries)\n            jobs.extend(response[TRANSFER_JOBS])\n\n            request = conn.transferJobs().list_next(previous_request=request, previous_response=response)\n\n        return jobs", "response": "Lists long - running operations in Google Storage Transfer Jobs Service that match the specified filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a transfer job that runs periodically.", "response": "def update_transfer_job(self, job_name, body):\n        \"\"\"\n        Updates a transfer job that runs periodically.\n\n        :param job_name: (Required) Name of the job to be updated\n        :type job_name: str\n        :param body: A request body, as described in\n            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/patch#request-body\n        :type body: dict\n        :return: If successful, TransferJob.\n        :rtype: dict\n        \"\"\"\n        body = self._inject_project_id(body, BODY, PROJECT_ID)\n        return (\n            self.get_conn()\n            .transferJobs()\n            .patch(jobName=job_name, body=body)\n            .execute(num_retries=self.num_retries)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a Transfer Job.", "response": "def delete_transfer_job(self, job_name, project_id):\n        \"\"\"\n        Deletes a transfer job. This is a soft delete. After a transfer job is\n        deleted, the job and all the transfer executions are subject to garbage\n        collection. Transfer jobs become eligible for garbage collection\n        30 days after soft delete.\n\n        :param job_name: (Required) Name of the job to be deleted\n        :type job_name: str\n        :param project_id: (Optional) the ID of the project that owns the Transfer\n            Job. If set to None or missing, the default project_id from the GCP\n            connection is used.\n        :type project_id: str\n        :rtype: None\n        \"\"\"\n\n        return (\n            self.get_conn()\n            .transferJobs()\n            .patch(\n                jobName=job_name,\n                body={\n                    PROJECT_ID: project_id,\n                    TRANSFER_JOB: {STATUS1: GcpTransferJobsStatus.DELETED},\n                    TRANSFER_JOB_FIELD_MASK: STATUS1,\n                },\n            )\n            .execute(num_retries=self.num_retries)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cancel_transfer_operation(self, operation_name):\n        self.get_conn().transferOperations().cancel(name=operation_name).execute(num_retries=self.num_retries)", "response": "Cancels an operation in Google Storage Transfer Service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_transfer_operation(self, operation_name):\n        return (\n            self.get_conn()\n            .transferOperations()\n            .get(name=operation_name)\n            .execute(num_retries=self.num_retries)\n        )", "response": "Gets an operation in Google Storage Transfer Service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an operation in Google Storage Transfer Service.", "response": "def list_transfer_operations(self, filter):\n        \"\"\"\n        Gets an transfer operation in Google Storage Transfer Service.\n\n        :param filter: (Required) A request filter, as described in\n            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/list#body.QUERY_PARAMETERS.filter\n            With one additional improvement:\n\n            * project_id is optional if you have a project id defined\n              in the connection\n              See: :ref:`howto/connection:gcp`\n\n        :type filter: dict\n        :return: transfer operation\n        :rtype: list[dict]\n        \"\"\"\n        conn = self.get_conn()\n\n        filter = self._inject_project_id(filter, FILTER, FILTER_PROJECT_ID)\n\n        operations = []\n\n        request = conn.transferOperations().list(name=TRANSFER_OPERATIONS, filter=json.dumps(filter))\n\n        while request is not None:\n            response = request.execute(num_retries=self.num_retries)\n            if OPERATIONS in response:\n                operations.extend(response[OPERATIONS])\n\n            request = conn.transferOperations().list_next(\n                previous_request=request, previous_response=response\n            )\n\n        return operations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pause_transfer_operation(self, operation_name):\n        self.get_conn().transferOperations().pause(name=operation_name).execute(num_retries=self.num_retries)", "response": "Pauses an operation in Google Storage Transfer Service."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresume an operation in Google Storage Transfer Service.", "response": "def resume_transfer_operation(self, operation_name):\n        \"\"\"\n        Resumes an transfer operation in Google Storage Transfer Service.\n\n        :param operation_name: (Required) Name of the transfer operation.\n        :type operation_name: str\n        :rtype: None\n        \"\"\"\n        self.get_conn().transferOperations().resume(name=operation_name).execute(num_retries=self.num_retries)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_transfer_job(self, job, expected_statuses=(GcpTransferOperationStatus.SUCCESS,), timeout=60):\n        while timeout > 0:\n            operations = self.list_transfer_operations(\n                filter={FILTER_PROJECT_ID: job[PROJECT_ID], FILTER_JOB_NAMES: [job[NAME]]}\n            )\n\n            if GCPTransferServiceHook.operations_contain_expected_statuses(operations, expected_statuses):\n                return\n            time.sleep(TIME_TO_SLEEP_IN_SECONDS)\n            timeout -= TIME_TO_SLEEP_IN_SECONDS\n        raise AirflowException(\"Timeout. The operation could not be completed within the allotted time.\")", "response": "Waits until the job reaches the expected state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether the list of operations contains the expected statuses.", "response": "def operations_contain_expected_statuses(operations, expected_statuses):\n        \"\"\"\n        Checks whether the operation list has an operation with the\n        expected status, then returns true\n        If it encounters operations in FAILED or ABORTED state\n        throw :class:`airflow.exceptions.AirflowException`.\n\n        :param operations: (Required) List of transfer operations to check.\n        :type operations: list[dict]\n        :param expected_statuses: (Required) status that is expected\n            See:\n            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferOperations#Status\n        :type expected_statuses: set[str]\n        :return: If there is an operation with the expected state\n            in the operation list, returns true,\n        :raises: airflow.exceptions.AirflowException If it encounters operations\n            with a state in the list,\n        :rtype: bool\n        \"\"\"\n        expected_statuses = (\n            {expected_statuses} if isinstance(expected_statuses, six.string_types) else set(expected_statuses)\n        )\n        if len(operations) == 0:\n            return False\n\n        current_statuses = {operation[METADATA][STATUS] for operation in operations}\n\n        if len(current_statuses - set(expected_statuses)) != len(current_statuses):\n            return True\n\n        if len(NEGATIVE_STATUSES - current_statuses) != len(NEGATIVE_STATUSES):\n            raise AirflowException(\n                'An unexpected operation status was encountered. Expected: {}'.format(\n                    \", \".join(expected_statuses)\n                )\n            )\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all task reschedules for the task instance and try number.", "response": "def find_for_task_instance(task_instance, session):\n        \"\"\"\n        Returns all task reschedules for the task instance and try number,\n        in ascending order.\n\n        :param task_instance: the task instance to find task reschedules for\n        :type task_instance: airflow.models.TaskInstance\n        \"\"\"\n        TR = TaskReschedule\n        return (\n            session\n            .query(TR)\n            .filter(TR.dag_id == task_instance.dag_id,\n                    TR.task_id == task_instance.task_id,\n                    TR.execution_date == task_instance.execution_date,\n                    TR.try_number == task_instance.try_number)\n            .order_by(asc(TR.id))\n            .all()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstrip any unsafe Kubernetes special characters from the Pod name.", "response": "def _strip_unsafe_kubernetes_special_chars(string):\n        \"\"\"\n        Kubernetes only supports lowercase alphanumeric characters and \"-\" and \".\" in\n        the pod name\n        However, there are special rules about how \"-\" and \".\" can be used so let's\n        only keep\n        alphanumeric chars  see here for detail:\n        https://kubernetes.io/docs/concepts/overview/working-with-objects/names/\n\n        :param string: The requested Pod name\n        :return: ``str`` Pod name stripped of any unsafe characters\n        \"\"\"\n        return ''.join(ch.lower() for ind, ch in enumerate(string) if ch.isalnum())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a safe pod name based on the given values.", "response": "def _make_safe_pod_id(safe_dag_id, safe_task_id, safe_uuid):\n        \"\"\"\n        Kubernetes pod names must be <= 253 chars and must pass the following regex for\n        validation\n        \"^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$\"\n\n        :param safe_dag_id: a dag_id with only alphanumeric characters\n        :param safe_task_id: a task_id with only alphanumeric characters\n        :param random_uuid: a uuid\n        :return: ``str`` valid Pod name of appropriate length\n        \"\"\"\n        MAX_POD_ID_LEN = 253\n\n        safe_key = safe_dag_id + safe_task_id\n\n        safe_pod_id = safe_key[:MAX_POD_ID_LEN - len(safe_uuid) - 1] + \"-\" + safe_uuid\n\n        return safe_pod_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_safe_label_value(string):\n        MAX_LABEL_LEN = 63\n\n        safe_label = re.sub(r'^[^a-z0-9A-Z]*|[^a-zA-Z0-9_\\-\\.]|[^a-z0-9A-Z]*$', '', string)\n\n        if len(safe_label) > MAX_LABEL_LEN or string != safe_label:\n            safe_hash = hashlib.md5(string.encode()).hexdigest()[:9]\n            safe_label = safe_label[:MAX_LABEL_LEN - len(safe_hash) - 1] + \"-\" + safe_hash\n\n        return safe_label", "response": "Make a safe label value from a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_not_launched_queued_tasks(self, session=None):\n        queued_tasks = session\\\n            .query(TaskInstance)\\\n            .filter(TaskInstance.state == State.QUEUED).all()\n        self.log.info(\n            'When executor started up, found %s queued task instances',\n            len(queued_tasks)\n        )\n\n        for task in queued_tasks:\n            dict_string = (\n                \"dag_id={},task_id={},execution_date={},airflow-worker={}\".format(\n                    AirflowKubernetesScheduler._make_safe_label_value(task.dag_id),\n                    AirflowKubernetesScheduler._make_safe_label_value(task.task_id),\n                    AirflowKubernetesScheduler._datetime_to_label_safe_datestring(\n                        task.execution_date\n                    ),\n                    self.worker_uuid\n                )\n            )\n            kwargs = dict(label_selector=dict_string)\n            pod_list = self.kube_client.list_namespaced_pod(\n                self.kube_config.kube_namespace, **kwargs)\n            if len(pod_list.items) == 0:\n                self.log.info(\n                    'TaskInstance: %s found in queued state but was not launched, '\n                    'rescheduling', task\n                )\n                session.query(TaskInstance).filter(\n                    TaskInstance.dag_id == task.dag_id,\n                    TaskInstance.task_id == task.task_id,\n                    TaskInstance.execution_date == task.execution_date\n                ).update({TaskInstance.state: State.NONE})", "response": "Clear the not launched queued tasks from the given session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the number of slots open at the moment", "response": "def open_slots(self, session):\n        \"\"\"\n        Returns the number of slots open at the moment\n        \"\"\"\n        from airflow.models.taskinstance import \\\n            TaskInstance as TI  # Avoid circular import\n\n        used_slots = session.query(func.count()).filter(TI.pool == self.pool).filter(\n            TI.state.in_([State.RUNNING, State.QUEUED])).scalar()\n        return self.slots - used_slots"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expand_env_var(env_var):\n    if not env_var:\n        return env_var\n    while True:\n        interpolated = os.path.expanduser(os.path.expandvars(str(env_var)))\n        if interpolated == env_var:\n            return interpolated\n        else:\n            env_var = interpolated", "response": "Expands a single environment variable by repeatedly applying expandvars and expanduser until interpolation stops having\n    any effect."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns command and returns stdout SARL", "response": "def run_command(command):\n    \"\"\"\n    Runs command and returns stdout\n    \"\"\"\n    process = subprocess.Popen(\n        shlex.split(command),\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        close_fds=True)\n    output, stderr = [stream.decode(sys.getdefaultencoding(), 'ignore')\n                      for stream in process.communicate()]\n\n    if process.returncode != 0:\n        raise AirflowConfigException(\n            \"Cannot execute {}. Error code is: {}. Output: {}, Stderr: {}\"\n            .format(command, process.returncode, output, stderr)\n        )\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parameterized_config(template):\n    all_vars = {k: v for d in [globals(), locals()] for k, v in d.items()}\n    return template.format(**all_vars)", "response": "Generates a config content from the provided template + variables defined in\n    current scope"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_option(self, section, option, remove_default=True):\n        if super().has_option(section, option):\n            super().remove_option(section, option)\n\n        if self.airflow_defaults.has_option(section, option) and remove_default:\n            self.airflow_defaults.remove_option(section, option)", "response": "Removes an option from a section of the config file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the section as a dict. Values are converted to int float bool as required.", "response": "def getsection(self, section):\n        \"\"\"\n        Returns the section as a dict. Values are converted to int, float, bool\n        as required.\n\n        :param section: section from the config\n        :rtype: dict\n        \"\"\"\n        if (section not in self._sections and\n                section not in self.airflow_defaults._sections):\n            return None\n\n        _section = copy.deepcopy(self.airflow_defaults._sections[section])\n\n        if section in self._sections:\n            _section.update(copy.deepcopy(self._sections[section]))\n\n        section_prefix = 'AIRFLOW__{S}__'.format(S=section.upper())\n        for env_var in sorted(os.environ.keys()):\n            if env_var.startswith(section_prefix):\n                key = env_var.replace(section_prefix, '').lower()\n                _section[key] = self._get_env_var_option(section, key)\n\n        for key, val in iteritems(_section):\n            try:\n                val = int(val)\n            except ValueError:\n                try:\n                    val = float(val)\n                except ValueError:\n                    if val.lower() in ('t', 'true'):\n                        val = True\n                    elif val.lower() in ('f', 'false'):\n                        val = False\n            _section[key] = val\n        return _section"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_dict(\n            self, display_source=False, display_sensitive=False, raw=False):\n        \"\"\"\n        Returns the current configuration as an OrderedDict of OrderedDicts.\n        :param display_source: If False, the option value is returned. If True,\n            a tuple of (option_value, source) is returned. Source is either\n            'airflow.cfg', 'default', 'env var', or 'cmd'.\n        :type display_source: bool\n        :param display_sensitive: If True, the values of options set by env\n            vars and bash commands will be displayed. If False, those options\n            are shown as '< hidden >'\n        :type display_sensitive: bool\n        :param raw: Should the values be output as interpolated values, or the\n            \"raw\" form that can be fed back in to ConfigParser\n        :type raw: bool\n        \"\"\"\n        cfg = {}\n        configs = [\n            ('default', self.airflow_defaults),\n            ('airflow.cfg', self),\n        ]\n\n        for (source_name, config) in configs:\n            for section in config.sections():\n                sect = cfg.setdefault(section, OrderedDict())\n                for (k, val) in config.items(section=section, raw=raw):\n                    if display_source:\n                        val = (val, source_name)\n                    sect[k] = val\n\n        # add env vars and overwrite because they have priority\n        for ev in [ev for ev in os.environ if ev.startswith('AIRFLOW__')]:\n            try:\n                _, section, key = ev.split('__')\n                opt = self._get_env_var_option(section, key)\n            except ValueError:\n                continue\n            if not display_sensitive and ev != 'AIRFLOW__CORE__UNIT_TEST_MODE':\n                opt = '< hidden >'\n            elif raw:\n                opt = opt.replace('%', '%%')\n            if display_source:\n                opt = (opt, 'env var')\n            cfg.setdefault(section.lower(), OrderedDict()).update(\n                {key.lower(): opt})\n\n        # add bash commands\n        for (section, key) in self.as_command_stdout:\n            opt = self._get_cmd_option(section, key)\n            if opt:\n                if not display_sensitive:\n                    opt = '< hidden >'\n                if display_source:\n                    opt = (opt, 'cmd')\n                elif raw:\n                    opt = opt.replace('%', '%%')\n                cfg.setdefault(section, OrderedDict()).update({key: opt})\n                del cfg[section][key + '_cmd']\n\n        return cfg", "response": "Returns the current configuration as an OrderedDict of OrderedDicts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef allocate_ids(self, partial_keys):\n        conn = self.get_conn()\n\n        resp = (conn\n                .projects()\n                .allocateIds(projectId=self.project_id, body={'keys': partial_keys})\n                .execute(num_retries=self.num_retries))\n\n        return resp['keys']", "response": "Allocate IDs for incomplete keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbegin a new transaction.", "response": "def begin_transaction(self):\n        \"\"\"\n        Begins a new transaction.\n\n        .. seealso::\n            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/beginTransaction\n\n        :return: a transaction handle.\n        :rtype: str\n        \"\"\"\n        conn = self.get_conn()\n\n        resp = (conn\n                .projects()\n                .beginTransaction(projectId=self.project_id, body={})\n                .execute(num_retries=self.num_retries))\n\n        return resp['transaction']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncommit a transaction optionally creating or deleting some entities.", "response": "def commit(self, body):\n        \"\"\"\n        Commit a transaction, optionally creating, deleting or modifying some entities.\n\n        .. seealso::\n            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/commit\n\n        :param body: the body of the commit request.\n        :type body: dict\n        :return: the response body of the commit request.\n        :rtype: dict\n        \"\"\"\n        conn = self.get_conn()\n\n        resp = (conn\n                .projects()\n                .commit(projectId=self.project_id, body=body)\n                .execute(num_retries=self.num_retries))\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rollback(self, transaction):\n        conn = self.get_conn()\n\n        conn.projects().rollback(\n            projectId=self.project_id, body={'transaction': transaction}\n        ).execute(num_retries=self.num_retries)", "response": "Roll back a transaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_query(self, body):\n        conn = self.get_conn()\n\n        resp = (conn\n                .projects()\n                .runQuery(projectId=self.project_id, body=body)\n                .execute(num_retries=self.num_retries))\n\n        return resp['batch']", "response": "Run a query for entities."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the latest state of a long - running operation.", "response": "def get_operation(self, name):\n        \"\"\"\n        Gets the latest state of a long-running operation.\n\n        .. seealso::\n            https://cloud.google.com/datastore/docs/reference/data/rest/v1/projects.operations/get\n\n        :param name: the name of the operation resource.\n        :type name: str\n        :return: a resource operation instance.\n        :rtype: dict\n        \"\"\"\n        conn = self.get_conn()\n\n        resp = (conn\n                .projects()\n                .operations()\n                .get(name=name)\n                .execute(num_retries=self.num_retries))\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes the long - running operation.", "response": "def delete_operation(self, name):\n        \"\"\"\n        Deletes the long-running operation.\n\n        .. seealso::\n            https://cloud.google.com/datastore/docs/reference/data/rest/v1/projects.operations/delete\n\n        :param name: the name of the operation resource.\n        :type name: str\n        :return: none if successful.\n        :rtype: dict\n        \"\"\"\n        conn = self.get_conn()\n\n        resp = (conn\n                .projects()\n                .operations()\n                .delete(name=name)\n                .execute(num_retries=self.num_retries))\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npoll backup operation state until it s completed.", "response": "def poll_operation_until_done(self, name, polling_interval_in_seconds):\n        \"\"\"\n        Poll backup operation state until it's completed.\n\n        :param name: the name of the operation resource\n        :type name: str\n        :param polling_interval_in_seconds: The number of seconds to wait before calling another request.\n        :type polling_interval_in_seconds: int\n        :return: a resource operation instance.\n        :rtype: dict\n        \"\"\"\n        while True:\n            result = self.get_operation(name)\n\n            state = result['metadata']['common']['state']\n            if state == 'PROCESSING':\n                self.log.info('Operation is processing. Re-polling state in {} seconds'\n                              .format(polling_interval_in_seconds))\n                time.sleep(polling_interval_in_seconds)\n            else:\n                return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export_to_storage_bucket(self, bucket, namespace=None, entity_filter=None, labels=None):\n        admin_conn = self.get_conn()\n\n        output_uri_prefix = 'gs://' + '/'.join(filter(None, [bucket, namespace]))\n        if not entity_filter:\n            entity_filter = {}\n        if not labels:\n            labels = {}\n        body = {\n            'outputUrlPrefix': output_uri_prefix,\n            'entityFilter': entity_filter,\n            'labels': labels,\n        }\n        resp = (admin_conn\n                .projects()\n                .export(projectId=self.project_id, body=body)\n                .execute(num_retries=self.num_retries))\n\n        return resp", "response": "Export entities from Cloud Datastore to Cloud Storage for backup."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport a backup from Cloud Storage to Cloud Datastore.", "response": "def import_from_storage_bucket(self, bucket, file, namespace=None, entity_filter=None, labels=None):\n        \"\"\"\n        Import a backup from Cloud Storage to Cloud Datastore.\n\n        .. note::\n            Keep in mind that this requests the Admin API not the Data API.\n\n        .. seealso::\n            https://cloud.google.com/datastore/docs/reference/admin/rest/v1/projects/import\n\n        :param bucket: The name of the Cloud Storage bucket.\n        :type bucket: str\n        :param file: the metadata file written by the projects.export operation.\n        :type file: str\n        :param namespace: The Cloud Storage namespace path.\n        :type namespace: str\n        :param entity_filter: specify which kinds/namespaces are to be imported.\n        :type entity_filter: dict\n        :param labels: Client-assigned labels.\n        :type labels: dict of str\n        :return: a resource operation instance.\n        :rtype: dict\n        \"\"\"\n        admin_conn = self.get_conn()\n\n        input_url = 'gs://' + '/'.join(filter(None, [bucket, namespace, file]))\n        if not entity_filter:\n            entity_filter = {}\n        if not labels:\n            labels = {}\n        body = {\n            'inputUrl': input_url,\n            'entityFilter': entity_filter,\n            'labels': labels,\n        }\n        resp = (admin_conn\n                .projects()\n                .import_(projectId=self.project_id, body=body)\n                .execute(num_retries=self.num_retries))\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef publish_to_target(self, target_arn, message):\n\n        conn = self.get_conn()\n\n        messages = {\n            'default': message\n        }\n\n        return conn.publish(\n            TargetArn=target_arn,\n            Message=json.dumps(messages),\n            MessageStructure='json'\n        )", "response": "Publish a message to a topic or an endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_hostname():\n    # First we attempt to fetch the callable path from the config.\n    try:\n        callable_path = conf.get('core', 'hostname_callable')\n    except AirflowConfigException:\n        callable_path = None\n\n    # Then we handle the case when the config is missing or empty. This is the\n    # default behavior.\n    if not callable_path:\n        return socket.getfqdn()\n\n    # Since we have a callable path, we try to import and run it next.\n    module_path, attr_name = callable_path.split(':')\n    module = importlib.import_module(module_path)\n    callable = getattr(module, attr_name)\n    return callable()", "response": "Fetch the hostname using the callable from the config or socket. getfqdn as a fallback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a connection to the Cloud Natural Language service.", "response": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Natural Language service.\n\n        :return: Cloud Natural Language service object\n        :rtype: google.cloud.language_v1.LanguageServiceClient\n        \"\"\"\n        if not self._conn:\n            self._conn = LanguageServiceClient(credentials=self._get_credentials())\n        return self._conn"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze_entities(self, document, encoding_type=None, retry=None, timeout=None, metadata=None):\n        client = self.get_conn()\n\n        return client.analyze_entities(\n            document=document, encoding_type=encoding_type, retry=retry, timeout=timeout, metadata=metadata\n        )", "response": "Analyze named entities in the text along with entity types salience mentions for each entity and other properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef annotate_text(self, document, features, encoding_type=None, retry=None, timeout=None, metadata=None):\n        client = self.get_conn()\n\n        return client.annotate_text(\n            document=document,\n            features=features,\n            encoding_type=encoding_type,\n            retry=retry,\n            timeout=timeout,\n            metadata=metadata,\n        )", "response": "This method returns the annotations for the specified document."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclassifies a document into categories.", "response": "def classify_text(self, document, retry=None, timeout=None, metadata=None):\n        \"\"\"\n        Classifies a document into categories.\n\n        :param document: Input document.\n            If a dict is provided, it must be of the same form as the protobuf message Document\n        :type document: dict or class google.cloud.language_v1.types.Document\n        :param retry: A retry object used to retry requests. If None is specified, requests will not be\n            retried.\n        :type retry: google.api_core.retry.Retry\n        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if\n            retry is specified, the timeout applies to each individual attempt.\n        :type timeout: float\n        :param metadata: Additional metadata that is provided to the method.\n        :type metadata: sequence[tuple[str, str]]]\n        :rtype: google.cloud.language_v1.types.AnalyzeEntitiesResponse\n        \"\"\"\n        client = self.get_conn()\n\n        return client.classify_text(document=document, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the task object identified by the given dag_id and task_id.", "response": "def get_task(dag_id, task_id):\n    \"\"\"Return the task object identified by the given dag_id and task_id.\"\"\"\n    dagbag = DagBag()\n\n    # Check DAG exists.\n    if dag_id not in dagbag.dags:\n        error_message = \"Dag id {} not found\".format(dag_id)\n        raise DagNotFound(error_message)\n\n    # Get DAG object and check Task Exists\n    dag = dagbag.get_dag(dag_id)\n    if not dag.has_task(task_id):\n        error_message = 'Task {} not found in dag {}'.format(task_id, dag_id)\n        raise TaskNotFound(error_message)\n\n    # Return the task.\n    return dag.get_task(task_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the template field for a specific operator class.", "response": "def get_template_field(env, fullname):\n    \"\"\"\n    Gets template fields for specific operator class.\n\n    :param fullname: Full path to operator class.\n        For example: ``airflow.contrib.operators.gcp_vision_operator.CloudVisionProductSetCreateOperator``\n    :return: List of template field\n    :rtype: list[str]\n    \"\"\"\n    modname, classname = fullname.rsplit(\".\", 1)\n\n    try:\n        with mock(env.config.autodoc_mock_imports):\n            mod = import_module(modname)\n    except ImportError:\n        raise RoleException(\"Error loading %s module.\" % (modname, ))\n\n    clazz = getattr(mod, classname)\n    if not clazz:\n        raise RoleException(\"Error finding %s class in %s module.\" % (classname, modname))\n\n    template_fields = getattr(clazz, \"template_fields\")\n\n    if not template_fields:\n        raise RoleException(\n            \"Could not find the template fields for %s class in %s module.\" % (classname, modname)\n        )\n\n    return list(template_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef template_field_role(app, typ, rawtext, text, lineno, inliner, options={}, content=[]):\n    text = utils.unescape(text)\n\n    try:\n        template_fields = get_template_field(app.env, text)\n    except RoleException as e:\n        msg = inliner.reporter.error(\"invalid class name %s \\n%s\" % (text, e, ), line=lineno)\n        prb = inliner.problematic(rawtext, rawtext, msg)\n        return [prb], [msg]\n\n    node = nodes.inline(rawtext=rawtext)\n    for i, field in enumerate(template_fields):\n        if i != 0:\n            node += nodes.Text(\", \")\n        node += nodes.literal(field, \"\", nodes.Text(field))\n\n    return [node], []", "response": "This function creates a role that allows you to include a list of template fields in the middle of the text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dispose_orm():\n    log.debug(\"Disposing DB connection pool (PID %s)\", os.getpid())\n    global engine\n    global Session\n\n    if Session:\n        Session.remove()\n        Session = None\n    if engine:\n        engine.dispose()\n        engine = None", "response": "Disposes of pooled database connections"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares the classpath for the AIRFLOW_HOME.", "response": "def prepare_classpath():\n    \"\"\"\n    Ensures that certain subfolders of AIRFLOW_HOME are on the classpath\n    \"\"\"\n\n    if DAGS_FOLDER not in sys.path:\n        sys.path.append(DAGS_FOLDER)\n\n    # Add ./config/ for loading custom log parsers etc, or\n    # airflow_local_settings etc.\n    config_path = os.path.join(AIRFLOW_HOME, 'config')\n    if config_path not in sys.path:\n        sys.path.append(config_path)\n\n    if PLUGINS_FOLDER not in sys.path:\n        sys.path.append(PLUGINS_FOLDER)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_task_id(self, context):\n        ti = context['ti']\n        celery_result = ti.xcom_pull(task_ids=self.target_task_id)\n        return celery_result.ready()", "response": "Checks if the task has been executed and returns True if it has been finished execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if the ticket cache contains conf information as is found in ticket caches of Kerberos 1. 8. 1 or later.", "response": "def detect_conf_var():\n    \"\"\"Return true if the ticket cache contains \"conf\" information as is found\n    in ticket caches of Kerberos 1.8.1 or later. This is incompatible with the\n    Sun Java Krb5LoginModule in Java6, so we need to take an action to work\n    around it.\n    \"\"\"\n    ticket_cache = configuration.conf.get('kerberos', 'ccache')\n\n    with open(ticket_cache, 'rb') as f:\n        # Note: this file is binary, so we check against a bytearray.\n        return b'X-CACHECONF:' in f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alchemy_to_dict(obj):\n    if not obj:\n        return None\n    d = {}\n    for c in obj.__table__.columns:\n        value = getattr(obj, c.name)\n        if type(value) == datetime:\n            value = value.isoformat()\n        d[c.name] = value\n    return d", "response": "Transforms a SQLAlchemy model instance into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunks(items, chunk_size):\n    if chunk_size <= 0:\n        raise ValueError('Chunk size must be a positive integer')\n    for i in range(0, len(items), chunk_size):\n        yield items[i:i + chunk_size]", "response": "Yields a list of items from a given size"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreducing the given iterable by splitting it into chunks and passing each chunk through the initializer", "response": "def reduce_in_chunks(fn, iterable, initializer, chunk_size=0):\n    \"\"\"\n    Reduce the given list of items by splitting it into chunks\n    of the given size and passing each chunk through the reducer\n    \"\"\"\n    if len(iterable) == 0:\n        return initializer\n    if chunk_size == 0:\n        chunk_size = len(iterable)\n    return reduce(fn, chunks(iterable, chunk_size), initializer)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chain(*tasks):\n    for up_task, down_task in zip(tasks[:-1], tasks[1:]):\n        up_task.set_downstream(down_task)", "response": "Builds a dependency chain given a number of tasks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a pretty ascii table from tuples", "response": "def pprinttable(rows):\n    \"\"\"Returns a pretty ascii table from tuples\n\n    If namedtuple are used, the table will have headers\n    \"\"\"\n    if not rows:\n        return\n    if hasattr(rows[0], '_fields'):  # if namedtuple\n        headers = rows[0]._fields\n    else:\n        headers = [\"col{}\".format(i) for i in range(len(rows[0]))]\n    lens = [len(s) for s in headers]\n\n    for row in rows:\n        for i in range(len(rows[0])):\n            slenght = len(\"{}\".format(row[i]))\n            if slenght > lens[i]:\n                lens[i] = slenght\n    formats = []\n    hformats = []\n    for i in range(len(rows[0])):\n        if isinstance(rows[0][i], int):\n            formats.append(\"%%%dd\" % lens[i])\n        else:\n            formats.append(\"%%-%ds\" % lens[i])\n        hformats.append(\"%%-%ds\" % lens[i])\n    pattern = \" | \".join(formats)\n    hpattern = \" | \".join(hformats)\n    separator = \"-+-\".join(['-' * n for n in lens])\n    s = \"\"\n    s += separator + '\\n'\n    s += (hpattern % tuple(headers)) + '\\n'\n    s += separator + '\\n'\n\n    def f(t):\n        return \"{}\".format(t) if isinstance(t, basestring) else t\n\n    for line in rows:\n        s += pattern % tuple(f(t) for t in line) + '\\n'\n    s += separator + '\\n'\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reap_process_group(pid, log, sig=signal.SIGTERM,\n                       timeout=DEFAULT_TIME_TO_WAIT_AFTER_SIGTERM):\n    \"\"\"\n    Tries really hard to terminate all children (including grandchildren). Will send\n    sig (SIGTERM) to the process group of pid. If any process is alive after timeout\n    a SIGKILL will be send.\n\n    :param log: log handler\n    :param pid: pid to kill\n    :param sig: signal type\n    :param timeout: how much time a process has to terminate\n    \"\"\"\n\n    def on_terminate(p):\n        log.info(\"Process %s (%s) terminated with exit code %s\", p, p.pid, p.returncode)\n\n    if pid == os.getpid():\n        raise RuntimeError(\"I refuse to kill myself\")\n\n    parent = psutil.Process(pid)\n\n    children = parent.children(recursive=True)\n    children.append(parent)\n\n    try:\n        pg = os.getpgid(pid)\n    except OSError as err:\n        # Skip if not such process - we experience a race and it just terminated\n        if err.errno == errno.ESRCH:\n            return\n        raise\n\n    log.info(\"Sending %s to GPID %s\", sig, pg)\n    os.killpg(os.getpgid(pid), sig)\n\n    gone, alive = psutil.wait_procs(children, timeout=timeout, callback=on_terminate)\n\n    if alive:\n        for p in alive:\n            log.warn(\"process %s (%s) did not respond to SIGTERM. Trying SIGKILL\", p, pid)\n\n        os.killpg(os.getpgid(pid), signal.SIGKILL)\n\n        gone, alive = psutil.wait_procs(alive, timeout=timeout, callback=on_terminate)\n        if alive:\n            for p in alive:\n                log.error(\"Process %s (%s) could not be killed. Giving up.\", p, p.pid)", "response": "Send a SIGTERM to the process group of pid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a task instance try_number filename_template return the rendered log file name", "response": "def render_log_filename(ti, try_number, filename_template):\n    \"\"\"\n    Given task instance, try_number, filename_template, return the rendered log\n    filename\n\n    :param ti: task instance\n    :param try_number: try_number of the task\n    :param filename_template: filename template, which can be jinja template or\n        python string template\n    \"\"\"\n    filename_template, filename_jinja_template = parse_template_string(filename_template)\n    if filename_jinja_template:\n        jinja_context = ti.get_template_context()\n        jinja_context['try_number'] = try_number\n        return filename_jinja_template.render(**jinja_context)\n\n    return filename_template.format(dag_id=ti.dag_id,\n                                    task_id=ti.task_id,\n                                    execution_date=ti.execution_date.isoformat(),\n                                    try_number=try_number)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_task_instance(dag_id, task_id, execution_date):\n\n    dagbag = DagBag()\n\n    # Check DAG exists.\n    if dag_id not in dagbag.dags:\n        error_message = \"Dag id {} not found\".format(dag_id)\n        raise DagNotFound(error_message)\n\n    # Get DAG object and check Task Exists\n    dag = dagbag.get_dag(dag_id)\n    if not dag.has_task(task_id):\n        error_message = 'Task {} not found in dag {}'.format(task_id, dag_id)\n        raise TaskNotFound(error_message)\n\n    # Get DagRun object and check that it exists\n    dagrun = dag.get_dagrun(execution_date=execution_date)\n    if not dagrun:\n        error_message = ('Dag Run for date {} not found in dag {}'\n                         .format(execution_date, dag_id))\n        raise DagRunNotFound(error_message)\n\n    # Get task instance object and check that it exists\n    task_instance = dagrun.get_task_instance(task_id)\n    if not task_instance:\n        error_message = ('Task {} instance for date {} not found'\n                         .format(task_id, execution_date))\n        raise TaskInstanceNotFound(error_message)\n\n    return task_instance", "response": "Return the task object identified by the given dag_id and task_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nintegrate plugins to the context", "response": "def _integrate_plugins():\n    \"\"\"Integrate plugins to the context\"\"\"\n    import sys\n    from airflow.plugins_manager import operators_modules\n    for operators_module in operators_modules:\n        sys.modules[operators_module.__name__] = operators_module\n        globals()[operators_module._name] = operators_module"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Google Cloud Dataproc service object.", "response": "def get_conn(self):\n        \"\"\"Returns a Google Cloud Dataproc service object.\"\"\"\n        http_authorized = self._authorize()\n        return build(\n            'dataproc', self.api_version, http=http_authorized,\n            cache_discovery=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait(self, operation):\n        submitted = _DataProcOperation(self.get_conn(), operation,\n                                       self.num_retries)\n        submitted.wait_for_done()", "response": "Await for Google Cloud Dataproc Operation to complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncoerces content to a string if it is a dict or all values of content if it is a list or a dict.", "response": "def _deep_string_coerce(content, json_path='json'):\n    \"\"\"\n    Coerces content or all values of content if it is a dict to a string. The\n    function will throw if content contains non-string or non-numeric types.\n\n    The reason why we have this function is because the ``self.json`` field must be a\n    dict with only string values. This is because ``render_template`` will fail\n    for numerical values.\n    \"\"\"\n    c = _deep_string_coerce\n    if isinstance(content, six.string_types):\n        return content\n    elif isinstance(content, six.integer_types + (float,)):\n        # Databricks can tolerate either numeric or string types in the API backend.\n        return str(content)\n    elif isinstance(content, (list, tuple)):\n        return [c(e, '{0}[{1}]'.format(json_path, i)) for i, e in enumerate(content)]\n    elif isinstance(content, dict):\n        return {k: c(v, '{0}[{1}]'.format(json_path, k))\n                for k, v in list(content.items())}\n    else:\n        param_type = type(content)\n        msg = 'Type {0} used for parameter {1} is not a number or a string' \\\n            .format(param_type, json_path)\n        raise AirflowException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles the Databricks operator execution logic for a Databricks operator.", "response": "def _handle_databricks_operator_execution(operator, hook, log, context):\n    \"\"\"\n    Handles the Airflow + Databricks lifecycle logic for a Databricks operator\n\n    :param operator: Databricks operator being handled\n    :param context: Airflow context\n    \"\"\"\n    if operator.do_xcom_push:\n        context['ti'].xcom_push(key=XCOM_RUN_ID_KEY, value=operator.run_id)\n    log.info('Run submitted with run_id: %s', operator.run_id)\n    run_page_url = hook.get_run_page_url(operator.run_id)\n    if operator.do_xcom_push:\n        context['ti'].xcom_push(key=XCOM_RUN_PAGE_URL_KEY, value=run_page_url)\n\n    log.info('View run status, Spark UI, and logs at %s', run_page_url)\n    while True:\n        run_state = hook.get_run_state(operator.run_id)\n        if run_state.is_terminal:\n            if run_state.is_successful:\n                log.info('%s completed successfully.', operator.task_id)\n                log.info('View run status, Spark UI, and logs at %s', run_page_url)\n                return\n            else:\n                error_message = '{t} failed with terminal state: {s}'.format(\n                    t=operator.task_id,\n                    s=run_state)\n                raise AirflowException(error_message)\n        else:\n            log.info('%s in run state: %s', operator.task_id, run_state)\n            log.info('View run status, Spark UI, and logs at %s', run_page_url)\n            log.info('Sleeping for %s seconds.', operator.polling_period_seconds)\n            time.sleep(operator.polling_period_seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns an interactive pig script using the pig cli", "response": "def run_cli(self, pig, verbose=True):\n        \"\"\"\n        Run an pig script using the pig cli\n\n        >>> ph = PigCliHook()\n        >>> result = ph.run_cli(\"ls /;\")\n        >>> (\"hdfs://\" in result)\n        True\n        \"\"\"\n\n        with TemporaryDirectory(prefix='airflow_pigop_') as tmp_dir:\n            with NamedTemporaryFile(dir=tmp_dir) as f:\n                f.write(pig.encode('utf-8'))\n                f.flush()\n                fname = f.name\n                pig_bin = 'pig'\n                cmd_extra = []\n\n                pig_cmd = [pig_bin, '-f', fname] + cmd_extra\n\n                if self.pig_properties:\n                    pig_properties_list = self.pig_properties.split()\n                    pig_cmd.extend(pig_properties_list)\n                if verbose:\n                    self.log.info(\"%s\", \" \".join(pig_cmd))\n                sp = subprocess.Popen(\n                    pig_cmd,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.STDOUT,\n                    cwd=tmp_dir,\n                    close_fds=True)\n                self.sp = sp\n                stdout = ''\n                for line in iter(sp.stdout.readline, b''):\n                    stdout += line.decode('utf-8')\n                    if verbose:\n                        self.log.info(line.strip())\n                sp.wait()\n\n                if sp.returncode:\n                    raise AirflowException(stdout)\n\n                return stdout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching and return the state of the given celery task.", "response": "def fetch_celery_task_state(celery_task):\n    \"\"\"\n    Fetch and return the state of the given celery task. The scope of this function is\n    global so that it can be called by subprocesses in the pool.\n\n    :param celery_task: a tuple of the Celery task key and the async Celery object used\n        to fetch the task's state\n    :type celery_task: tuple(str, celery.result.AsyncResult)\n    :return: a tuple of the Celery task key and the Celery state of the task\n    :rtype: tuple[str, str]\n    \"\"\"\n\n    try:\n        with timeout(seconds=2):\n            # Accessing state property of celery task will make actual network request\n            # to get the current state of the task.\n            res = (celery_task[0], celery_task[1].state)\n    except Exception as e:\n        exception_traceback = \"Celery Task ID: {}\\n{}\".format(celery_task[0],\n                                                              traceback.format_exc())\n        res = ExceptionWithTraceback(e, exception_traceback)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _num_tasks_per_send_process(self, to_send_count):\n        return max(1,\n                   int(math.ceil(1.0 * to_send_count / self._sync_parallelism)))", "response": "Returns the number of tasks that should be sent per worker process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _num_tasks_per_fetch_process(self):\n        return max(1,\n                   int(math.ceil(1.0 * len(self.tasks) / self._sync_parallelism)))", "response": "Returns the number of tasks that should be used per worker process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike a Python builtin dict object setdefault returns the current value for a key and stores the default value and returns it.", "response": "def setdefault(cls, key, default, deserialize_json=False):\n        \"\"\"\n        Like a Python builtin dict object, setdefault returns the current value\n        for a key, and if it isn't there, stores the default value and returns it.\n\n        :param key: Dict key for this Variable\n        :type key: str\n        :param default: Default value to set and return if the variable\n            isn't already in the DB\n        :type default: Mixed\n        :param deserialize_json: Store this as a JSON encoded value in the DB\n            and un-encode it when retrieving a value\n        :return: Mixed\n        \"\"\"\n        obj = Variable.get(key, default_var=None,\n                           deserialize_json=deserialize_json)\n        if obj is None:\n            if default is not None:\n                Variable.set(key, default, serialize_json=deserialize_json)\n                return default\n            else:\n                raise ValueError('Default Value must be set')\n        else:\n            return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conn(self):\n        authed_http = self._authorize()\n        return build('ml', 'v1', http=authed_http, cache_discovery=False)", "response": "Returns a Google MLEngine service object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_job(self, project_id, job, use_existing_job_fn=None):\n        request = self._mlengine.projects().jobs().create(\n            parent='projects/{}'.format(project_id),\n            body=job)\n        job_id = job['jobId']\n\n        try:\n            request.execute()\n        except HttpError as e:\n            # 409 means there is an existing job with the same job ID.\n            if e.resp.status == 409:\n                if use_existing_job_fn is not None:\n                    existing_job = self._get_job(project_id, job_id)\n                    if not use_existing_job_fn(existing_job):\n                        self.log.error(\n                            'Job with job_id %s already exist, but it does '\n                            'not match our expectation: %s',\n                            job_id, existing_job\n                        )\n                        raise\n                self.log.info(\n                    'Job with job_id %s already exist. Will waiting for it to finish',\n                    job_id\n                )\n            else:\n                self.log.error('Failed to create MLEngine job: {}'.format(e))\n                raise\n\n        return self._wait_for_job_done(project_id, job_id)", "response": "Creates a new job in the specified project and waits for it to reach a terminal state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_job(self, project_id, job_id):\n        job_name = 'projects/{}/jobs/{}'.format(project_id, job_id)\n        request = self._mlengine.projects().jobs().get(name=job_name)\n        while True:\n            try:\n                return request.execute()\n            except HttpError as e:\n                if e.resp.status == 429:\n                    # polling after 30 seconds when quota failure occurs\n                    time.sleep(30)\n                else:\n                    self.log.error('Failed to get MLEngine job: {}'.format(e))\n                    raise", "response": "Gets a job based on the job name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _wait_for_job_done(self, project_id, job_id, interval=30):\n        if interval <= 0:\n            raise ValueError(\"Interval must be > 0\")\n        while True:\n            job = self._get_job(project_id, job_id)\n            if job['state'] in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n                return job\n            time.sleep(interval)", "response": "Waits for the job to be done."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_version(self, project_id, model_name, version_spec):\n        parent_name = 'projects/{}/models/{}'.format(project_id, model_name)\n        create_request = self._mlengine.projects().models().versions().create(\n            parent=parent_name, body=version_spec)\n        response = create_request.execute()\n        get_request = self._mlengine.projects().operations().get(\n            name=response['name'])\n\n        return _poll_with_exponential_delay(\n            request=get_request,\n            max_n=9,\n            is_done_func=lambda resp: resp.get('done', False),\n            is_error_func=lambda resp: resp.get('error', None) is not None)", "response": "Creates a version on Google Cloud ML Engine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_default_version(self, project_id, model_name, version_name):\n        full_version_name = 'projects/{}/models/{}/versions/{}'.format(\n            project_id, model_name, version_name)\n        request = self._mlengine.projects().models().versions().setDefault(\n            name=full_version_name, body={})\n\n        try:\n            response = request.execute()\n            self.log.info('Successfully set version: %s to default', response)\n            return response\n        except HttpError as e:\n            self.log.error('Something went wrong: %s', e)\n            raise", "response": "Sets a version to be the default. Blocks until finished."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist all available versions of a model. Blocks until finished.", "response": "def list_versions(self, project_id, model_name):\n        \"\"\"\n        Lists all available versions of a model. Blocks until finished.\n        \"\"\"\n        result = []\n        full_parent_name = 'projects/{}/models/{}'.format(\n            project_id, model_name)\n        request = self._mlengine.projects().models().versions().list(\n            parent=full_parent_name, pageSize=100)\n\n        response = request.execute()\n        next_page_token = response.get('nextPageToken', None)\n        result.extend(response.get('versions', []))\n        while next_page_token is not None:\n            next_request = self._mlengine.projects().models().versions().list(\n                parent=full_parent_name,\n                pageToken=next_page_token,\n                pageSize=100)\n            response = next_request.execute()\n            next_page_token = response.get('nextPageToken', None)\n            result.extend(response.get('versions', []))\n            time.sleep(5)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the given version of a model. Blocks until done.", "response": "def delete_version(self, project_id, model_name, version_name):\n        \"\"\"\n        Deletes the given version of a model. Blocks until finished.\n        \"\"\"\n        full_name = 'projects/{}/models/{}/versions/{}'.format(\n            project_id, model_name, version_name)\n        delete_request = self._mlengine.projects().models().versions().delete(\n            name=full_name)\n        response = delete_request.execute()\n        get_request = self._mlengine.projects().operations().get(\n            name=response['name'])\n\n        return _poll_with_exponential_delay(\n            request=get_request,\n            max_n=9,\n            is_done_func=lambda resp: resp.get('done', False),\n            is_error_func=lambda resp: resp.get('error', None) is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new model in the specified project. Blocks until finished.", "response": "def create_model(self, project_id, model):\n        \"\"\"\n        Create a Model. Blocks until finished.\n        \"\"\"\n        if not model['name']:\n            raise ValueError(\"Model name must be provided and \"\n                             \"could not be an empty string\")\n        project = 'projects/{}'.format(project_id)\n\n        request = self._mlengine.projects().models().create(\n            parent=project, body=model)\n        return request.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_model(self, project_id, model_name):\n        if not model_name:\n            raise ValueError(\"Model name must be provided and \"\n                             \"it could not be an empty string\")\n        full_model_name = 'projects/{}/models/{}'.format(\n            project_id, model_name)\n        request = self._mlengine.projects().models().get(name=full_model_name)\n        try:\n            return request.execute()\n        except HttpError as e:\n            if e.resp.status == 404:\n                self.log.error('Model was not found: %s', e)\n                return None\n            raise", "response": "Gets a specific model from the database. Blocks until finished."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_work(self, key, command):\n        if key is None:\n            return\n        self.log.info(\"%s running %s\", self.__class__.__name__, command)\n        try:\n            subprocess.check_call(command, close_fds=True)\n            state = State.SUCCESS\n        except subprocess.CalledProcessError as e:\n            state = State.FAILED\n            self.log.error(\"Failed to execute task %s.\", str(e))\n            # TODO: Why is this commented out?\n            # raise e\n        self.result_queue.put((key, state))", "response": "Executes a command received and stores the result in the result queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_batch_data(self, items):\n\n        dynamodb_conn = self.get_conn()\n\n        try:\n            table = dynamodb_conn.Table(self.table_name)\n\n            with table.batch_writer(overwrite_by_pkeys=self.table_keys) as batch:\n                for item in items:\n                    batch.put_item(Item=item)\n            return True\n        except Exception as general_error:\n            raise AirflowException(\n                'Failed to insert items in dynamodb, error: {error}'.format(\n                    error=str(general_error)\n                )\n            )", "response": "Write batch items to DynamoDB table with provisioned throughout capacity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _integrate_plugins():\n    from airflow.plugins_manager import executors_modules\n    for executors_module in executors_modules:\n        sys.modules[executors_module.__name__] = executors_module\n        globals()[executors_module._name] = executors_module", "response": "Integrate plugins to the context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of the configured executor if none exists and returns it", "response": "def get_default_executor():\n    \"\"\"Creates a new instance of the configured executor if none exists and returns it\"\"\"\n    global DEFAULT_EXECUTOR\n\n    if DEFAULT_EXECUTOR is not None:\n        return DEFAULT_EXECUTOR\n\n    executor_name = configuration.conf.get('core', 'EXECUTOR')\n\n    DEFAULT_EXECUTOR = _get_executor(executor_name)\n\n    log = LoggingMixin().log\n    log.info(\"Using executor %s\", executor_name)\n\n    return DEFAULT_EXECUTOR"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_executor(executor_name):\n    if executor_name == Executors.LocalExecutor:\n        return LocalExecutor()\n    elif executor_name == Executors.SequentialExecutor:\n        return SequentialExecutor()\n    elif executor_name == Executors.CeleryExecutor:\n        from airflow.executors.celery_executor import CeleryExecutor\n        return CeleryExecutor()\n    elif executor_name == Executors.DaskExecutor:\n        from airflow.executors.dask_executor import DaskExecutor\n        return DaskExecutor()\n    elif executor_name == Executors.KubernetesExecutor:\n        from airflow.contrib.executors.kubernetes_executor import KubernetesExecutor\n        return KubernetesExecutor()\n    else:\n        # Loading plugins\n        _integrate_plugins()\n        executor_path = executor_name.split('.')\n        if len(executor_path) != 2:\n            raise AirflowException(\n                \"Executor {0} not supported: \"\n                \"please specify in format plugin_module.executor\".format(executor_name))\n\n        if executor_path[0] in globals():\n            return globals()[executor_path[0]].__dict__[executor_path[1]]()\n        else:\n            raise AirflowException(\"Executor {0} not supported.\".format(executor_name))", "response": "Returns an executor instance based on the name of the executor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_error(self, error, items):\n        self.log.error('Encountered Segment error: {segment_error} with '\n                       'items: {with_items}'.format(segment_error=error,\n                                                    with_items=items))\n        raise AirflowException('Segment error: {}'.format(error))", "response": "Handles error callbacks when using Segment with segment_debug_mode set to True\n                      "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_pod(self, pod, startup_timeout=120, get_logs=True):\n        # type: (Pod, int, bool) -> Tuple[State, Optional[str]]\n        \"\"\"\n        Launches the pod synchronously and waits for completion.\n        Args:\n            pod (Pod):\n            startup_timeout (int): Timeout for startup of the pod (if pod is pending for\n             too long, considers task a failure\n        \"\"\"\n        resp = self.run_pod_async(pod)\n        curr_time = dt.now()\n        if resp.status.start_time is None:\n            while self.pod_not_started(pod):\n                delta = dt.now() - curr_time\n                if delta.seconds >= startup_timeout:\n                    raise AirflowException(\"Pod took too long to start\")\n                time.sleep(1)\n            self.log.debug('Pod not yet started')\n\n        return self._monitor_pod(pod, get_logs)", "response": "Launches the pod synchronously and waits for completion."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a mssql connection object", "response": "def get_conn(self):\n        \"\"\"\n        Returns a mssql connection object\n        \"\"\"\n        conn = self.get_connection(self.mssql_conn_id)\n        conn = pymssql.connect(\n            server=conn.host,\n            user=conn.login,\n            password=conn.password,\n            database=self.schema or conn.schema,\n            port=conn.port)\n        return conn"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall the SparkSubmitHook to run the provided spark job", "response": "def execute(self, context):\n        \"\"\"\n        Call the SparkSubmitHook to run the provided spark job\n        \"\"\"\n        self._hook = SparkSubmitHook(\n            conf=self._conf,\n            conn_id=self._conn_id,\n            files=self._files,\n            py_files=self._py_files,\n            archives=self._archives,\n            driver_class_path=self._driver_class_path,\n            jars=self._jars,\n            java_class=self._java_class,\n            packages=self._packages,\n            exclude_packages=self._exclude_packages,\n            repositories=self._repositories,\n            total_executor_cores=self._total_executor_cores,\n            executor_cores=self._executor_cores,\n            executor_memory=self._executor_memory,\n            driver_memory=self._driver_memory,\n            keytab=self._keytab,\n            principal=self._principal,\n            name=self._name,\n            num_executors=self._num_executors,\n            application_args=self._application_args,\n            env_vars=self._env_vars,\n            verbose=self._verbose,\n            spark_binary=self._spark_binary\n        )\n        self._hook.submit(self._application)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntriggering a new dag run for a Dag with an execution date of now unless the data is provided in the request.", "response": "def trigger_dag(dag_id):\n    \"\"\"\n    Trigger a new dag run for a Dag with an execution date of now unless\n    specified in the data.\n    \"\"\"\n    data = request.get_json(force=True)\n\n    run_id = None\n    if 'run_id' in data:\n        run_id = data['run_id']\n\n    conf = None\n    if 'conf' in data:\n        conf = data['conf']\n\n    execution_date = None\n    if 'execution_date' in data and data['execution_date'] is not None:\n        execution_date = data['execution_date']\n\n        # Convert string datetime into actual datetime\n        try:\n            execution_date = timezone.parse(execution_date)\n        except ValueError:\n            error_message = (\n                'Given execution date, {}, could not be identified '\n                'as a date. Example date format: 2015-11-16T14:34:15+00:00'\n                .format(execution_date))\n            _log.info(error_message)\n            response = jsonify({'error': error_message})\n            response.status_code = 400\n\n            return response\n\n    try:\n        dr = trigger.trigger_dag(dag_id, run_id, conf, execution_date)\n    except AirflowException as err:\n        _log.error(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = err.status_code\n        return response\n\n    if getattr(g, 'user', None):\n        _log.info(\"User %s created %s\", g.user, dr)\n\n    response = jsonify(message=\"Created {}\".format(dr))\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes all DB records related to the specified Dag.", "response": "def delete_dag(dag_id):\n    \"\"\"\n    Delete all DB records related to the specified Dag.\n    \"\"\"\n    try:\n        count = delete.delete_dag(dag_id)\n    except AirflowException as err:\n        _log.error(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = err.status_code\n        return response\n    return jsonify(message=\"Removed {} record(s)\".format(count), count=count)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of Dag Runs for a specific DAG ID.", "response": "def dag_runs(dag_id):\n    \"\"\"\n    Returns a list of Dag Runs for a specific DAG ID.\n    :query param state: a query string parameter '?state=queued|running|success...'\n    :param dag_id: String identifier of a DAG\n    :return: List of DAG runs of a DAG with requested state,\n    or all runs if the state is not specified\n    \"\"\"\n    try:\n        state = request.args.get('state')\n        dagruns = get_dag_runs(dag_id, state)\n    except AirflowException as err:\n        _log.info(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = 400\n        return response\n\n    return jsonify(dagruns)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dag_code(dag_id):\n    try:\n        return get_code(dag_id)\n    except AirflowException as err:\n        _log.info(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = err.status_code\n        return response", "response": "Return python code of a given dag_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a JSON with a task s public instance variables.", "response": "def task_info(dag_id, task_id):\n    \"\"\"Returns a JSON with a task's public instance variables. \"\"\"\n    try:\n        info = get_task(dag_id, task_id)\n    except AirflowException as err:\n        _log.info(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = err.status_code\n        return response\n\n    # JSONify and return.\n    fields = {k: str(v)\n              for k, v in vars(info).items()\n              if not k.startswith('_')}\n    return jsonify(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dag_paused(dag_id, paused):\n\n    DagModel = models.DagModel\n    with create_session() as session:\n        orm_dag = (\n            session.query(DagModel)\n                   .filter(DagModel.dag_id == dag_id).first()\n        )\n        if paused == 'true':\n            orm_dag.is_paused = True\n        else:\n            orm_dag.is_paused = False\n        session.merge(orm_dag)\n        session.commit()\n\n    return jsonify({'response': 'ok'})", "response": "Un ) pauses a dag"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON with a task instance s public instance variables.", "response": "def task_instance_info(dag_id, execution_date, task_id):\n    \"\"\"\n    Returns a JSON with a task instance's public instance variables.\n    The format for the exec_date is expected to be\n    \"YYYY-mm-DDTHH:MM:SS\", for example: \"2016-11-16T11:34:15\". This will\n    of course need to have been encoded for URL in the request.\n    \"\"\"\n\n    # Convert string datetime into actual datetime\n    try:\n        execution_date = timezone.parse(execution_date)\n    except ValueError:\n        error_message = (\n            'Given execution date, {}, could not be identified '\n            'as a date. Example date format: 2015-11-16T14:34:15+00:00'\n            .format(execution_date))\n        _log.info(error_message)\n        response = jsonify({'error': error_message})\n        response.status_code = 400\n\n        return response\n\n    try:\n        info = get_task_instance(dag_id, task_id, execution_date)\n    except AirflowException as err:\n        _log.info(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = err.status_code\n        return response\n\n    # JSONify and return.\n    fields = {k: str(v)\n              for k, v in vars(info).items()\n              if not k.startswith('_')}\n    return jsonify(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a JSON with a dag_run s public instance variables.", "response": "def dag_run_status(dag_id, execution_date):\n    \"\"\"\n    Returns a JSON with a dag_run's public instance variables.\n    The format for the exec_date is expected to be\n    \"YYYY-mm-DDTHH:MM:SS\", for example: \"2016-11-16T11:34:15\". This will\n    of course need to have been encoded for URL in the request.\n    \"\"\"\n\n    # Convert string datetime into actual datetime\n    try:\n        execution_date = timezone.parse(execution_date)\n    except ValueError:\n        error_message = (\n            'Given execution date, {}, could not be identified '\n            'as a date. Example date format: 2015-11-16T14:34:15+00:00'.format(\n                execution_date))\n        _log.info(error_message)\n        response = jsonify({'error': error_message})\n        response.status_code = 400\n\n        return response\n\n    try:\n        info = get_dag_run_state(dag_id, execution_date)\n    except AirflowException as err:\n        _log.info(err)\n        response = jsonify(error=\"{}\".format(err))\n        response.status_code = err.status_code\n        return response\n\n    return jsonify(info)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new container group and update it", "response": "def create_or_update(self, resource_group, name, container_group):\n        \"\"\"\n        Create a new container group\n\n        :param resource_group: the name of the resource group\n        :type resource_group: str\n        :param name: the name of the container group\n        :type name: str\n        :param container_group: the properties of the container group\n        :type container_group: azure.mgmt.containerinstance.models.ContainerGroup\n        \"\"\"\n        self.connection.container_groups.create_or_update(resource_group,\n                                                          name,\n                                                          container_group)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_state_exitcode_details(self, resource_group, name):\n        current_state = self._get_instance_view(resource_group, name).current_state\n        return (current_state.state,\n                current_state.exit_code,\n                current_state.detail_status)", "response": "Get the state exitcode and detail status of a container group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_messages(self, resource_group, name):\n        instance_view = self._get_instance_view(resource_group, name)\n\n        return [event.message for event in instance_view.events]", "response": "Get the messages of a container group"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_logs(self, resource_group, name, tail=1000):\n        logs = self.connection.container.list_logs(resource_group, name, name, tail=tail)\n        return logs.content.splitlines(True)", "response": "Get the tail from logs of a container group"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a container group", "response": "def delete(self, resource_group, name):\n        \"\"\"\n        Delete a container group\n\n        :param resource_group: the name of the resource group\n        :type resource_group: str\n        :param name: the name of the container group\n        :type name: str\n        \"\"\"\n        self.connection.container_groups.delete(resource_group, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exists(self, resource_group, name):\n        for container in self.connection.container_groups.list_by_resource_group(resource_group):\n            if container.name == name:\n                return True\n        return False", "response": "Test if a container group exists"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_defaults(func):\n\n    # Cache inspect.signature for the wrapper closure to avoid calling it\n    # at every decorated invocation. This is separate sig_cache created\n    # per decoration, i.e. each function decorated using apply_defaults will\n    # have a different sig_cache.\n    sig_cache = signature(func)\n    non_optional_args = {\n        name for (name, param) in sig_cache.parameters.items()\n        if param.default == param.empty and\n        param.name != 'self' and\n        param.kind not in (param.VAR_POSITIONAL, param.VAR_KEYWORD)}\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if len(args) > 1:\n            raise AirflowException(\n                \"Use keyword arguments when initializing operators\")\n        dag_args = {}\n        dag_params = {}\n\n        dag = kwargs.get('dag', None) or settings.CONTEXT_MANAGER_DAG\n        if dag:\n            dag_args = copy(dag.default_args) or {}\n            dag_params = copy(dag.params) or {}\n\n        params = {}\n        if 'params' in kwargs:\n            params = kwargs['params']\n        dag_params.update(params)\n\n        default_args = {}\n        if 'default_args' in kwargs:\n            default_args = kwargs['default_args']\n            if 'params' in default_args:\n                dag_params.update(default_args['params'])\n                del default_args['params']\n\n        dag_args.update(default_args)\n        default_args = dag_args\n\n        for arg in sig_cache.parameters:\n            if arg not in kwargs and arg in default_args:\n                kwargs[arg] = default_args[arg]\n        missing_args = list(non_optional_args - set(kwargs))\n        if missing_args:\n            msg = \"Argument {0} is required\".format(missing_args)\n            raise AirflowException(msg)\n\n        kwargs['params'] = dag_params\n\n        result = func(*args, **kwargs)\n        return result\n    return wrapper", "response": "Decorator that applies default values to the arguments of the context manager."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef construct_ingest_query(self, static_path, columns):\n\n        # backward compatibility for num_shards,\n        # but target_partition_size is the default setting\n        # and overwrites the num_shards\n        num_shards = self.num_shards\n        target_partition_size = self.target_partition_size\n        if self.target_partition_size == -1:\n            if self.num_shards == -1:\n                target_partition_size = DEFAULT_TARGET_PARTITION_SIZE\n        else:\n            num_shards = -1\n\n        metric_names = [m['fieldName'] for m in self.metric_spec if m['type'] != 'count']\n\n        # Take all the columns, which are not the time dimension\n        # or a metric, as the dimension columns\n        dimensions = [c for c in columns if c not in metric_names and c != self.ts_dim]\n\n        ingest_query_dict = {\n            \"type\": \"index_hadoop\",\n            \"spec\": {\n                \"dataSchema\": {\n                    \"metricsSpec\": self.metric_spec,\n                    \"granularitySpec\": {\n                        \"queryGranularity\": self.query_granularity,\n                        \"intervals\": self.intervals,\n                        \"type\": \"uniform\",\n                        \"segmentGranularity\": self.segment_granularity,\n                    },\n                    \"parser\": {\n                        \"type\": \"string\",\n                        \"parseSpec\": {\n                            \"columns\": columns,\n                            \"dimensionsSpec\": {\n                                \"dimensionExclusions\": [],\n                                \"dimensions\": dimensions,  # list of names\n                                \"spatialDimensions\": []\n                            },\n                            \"timestampSpec\": {\n                                \"column\": self.ts_dim,\n                                \"format\": \"auto\"\n                            },\n                            \"format\": \"tsv\"\n                        }\n                    },\n                    \"dataSource\": self.druid_datasource\n                },\n                \"tuningConfig\": {\n                    \"type\": \"hadoop\",\n                    \"jobProperties\": {\n                        \"mapreduce.job.user.classpath.first\": \"false\",\n                        \"mapreduce.map.output.compress\": \"false\",\n                        \"mapreduce.output.fileoutputformat.compress\": \"false\",\n                    },\n                    \"partitionsSpec\": {\n                        \"type\": \"hashed\",\n                        \"targetPartitionSize\": target_partition_size,\n                        \"numShards\": num_shards,\n                    },\n                },\n                \"ioConfig\": {\n                    \"inputSpec\": {\n                        \"paths\": static_path,\n                        \"type\": \"static\"\n                    },\n                    \"type\": \"hadoop\"\n                }\n            }\n        }\n\n        if self.job_properties:\n            ingest_query_dict['spec']['tuningConfig']['jobProperties'] \\\n                .update(self.job_properties)\n\n        if self.hadoop_dependency_coordinates:\n            ingest_query_dict['hadoopDependencyCoordinates'] \\\n                = self.hadoop_dependency_coordinates\n\n        return ingest_query_dict", "response": "Builds an ingest query for an HDFS TSV load."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking for message on subscribed channels and write to xcom the message with key message", "response": "def poke(self, context):\n        \"\"\"\n        Check for message on subscribed channels and write to xcom the message with key ``message``\n\n        An example of message ``{'type': 'message', 'pattern': None, 'channel': b'test', 'data': b'hello'}``\n\n        :param context: the context object\n        :type context: dict\n        :return: ``True`` if message (with type 'message') is available or ``False`` if not\n        \"\"\"\n        self.log.info('RedisPubSubSensor checking for message on channels: %s', self.channels)\n\n        message = self.pubsub.get_message()\n        self.log.info('Message %s from channel %s', message, self.channels)\n\n        # Process only message types\n        if message and message['type'] == 'message':\n\n            context['ti'].xcom_push(key='message', value=message)\n            self.pubsub.unsubscribe(self.channels)\n\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreload the current dagrun from the database.", "response": "def refresh_from_db(self, session=None):\n        \"\"\"\n        Reloads the current dagrun from the database\n        :param session: database session\n        \"\"\"\n        DR = DagRun\n\n        exec_date = func.cast(self.execution_date, DateTime)\n\n        dr = session.query(DR).filter(\n            DR.dag_id == self.dag_id,\n            func.cast(DR.execution_date, DateTime) == exec_date,\n            DR.run_id == self.run_id\n        ).one()\n\n        self.id = dr.id\n        self.state = dr.state"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find(dag_id=None, run_id=None, execution_date=None,\n             state=None, external_trigger=None, no_backfills=False,\n             session=None):\n        \"\"\"\n        Returns a set of dag runs for the given search criteria.\n\n        :param dag_id: the dag_id to find dag runs for\n        :type dag_id: int, list\n        :param run_id: defines the the run id for this dag run\n        :type run_id: str\n        :param execution_date: the execution date\n        :type execution_date: datetime.datetime\n        :param state: the state of the dag run\n        :type state: airflow.utils.state.State\n        :param external_trigger: whether this dag run is externally triggered\n        :type external_trigger: bool\n        :param no_backfills: return no backfills (True), return all (False).\n            Defaults to False\n        :type no_backfills: bool\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        \"\"\"\n        DR = DagRun\n\n        qry = session.query(DR)\n        if dag_id:\n            qry = qry.filter(DR.dag_id == dag_id)\n        if run_id:\n            qry = qry.filter(DR.run_id == run_id)\n        if execution_date:\n            if isinstance(execution_date, list):\n                qry = qry.filter(DR.execution_date.in_(execution_date))\n            else:\n                qry = qry.filter(DR.execution_date == execution_date)\n        if state:\n            qry = qry.filter(DR.state == state)\n        if external_trigger is not None:\n            qry = qry.filter(DR.external_trigger == external_trigger)\n        if no_backfills:\n            # in order to prevent a circular dependency\n            from airflow.jobs import BackfillJob\n            qry = qry.filter(DR.run_id.notlike(BackfillJob.ID_PREFIX + '%'))\n\n        dr = qry.order_by(DR.execution_date).all()\n\n        return dr", "response": "Returns a list of dag runs for the given search criteria."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_task_instances(self, state=None, session=None):\n        from airflow.models.taskinstance import TaskInstance  # Avoid circular import\n        tis = session.query(TaskInstance).filter(\n            TaskInstance.dag_id == self.dag_id,\n            TaskInstance.execution_date == self.execution_date,\n        )\n        if state:\n            if isinstance(state, six.string_types):\n                tis = tis.filter(TaskInstance.state == state)\n            else:\n                # this is required to deal with NULL values\n                if None in state:\n                    tis = tis.filter(\n                        or_(TaskInstance.state.in_(state),\n                            TaskInstance.state.is_(None))\n                    )\n                else:\n                    tis = tis.filter(TaskInstance.state.in_(state))\n\n        if self.dag and self.dag.partial:\n            tis = tis.filter(TaskInstance.task_id.in_(self.dag.task_ids))\n\n        return tis.all()", "response": "Returns the task instances for this dag run"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_task_instance(self, task_id, session=None):\n\n        from airflow.models.taskinstance import TaskInstance  # Avoid circular import\n        TI = TaskInstance\n        ti = session.query(TI).filter(\n            TI.dag_id == self.dag_id,\n            TI.execution_date == self.execution_date,\n            TI.task_id == task_id\n        ).first()\n\n        return ti", "response": "Returns the task instance specified by task_id for this dag run\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the previous DagRun in the database.", "response": "def get_previous_dagrun(self, session=None):\n        \"\"\"The previous DagRun, if there is one\"\"\"\n\n        return session.query(DagRun).filter(\n            DagRun.dag_id == self.dag_id,\n            DagRun.execution_date < self.execution_date\n        ).order_by(\n            DagRun.execution_date.desc()\n        ).first()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_state(self, session=None):\n\n        dag = self.get_dag()\n\n        tis = self.get_task_instances(session=session)\n        self.log.debug(\"Updating state for %s considering %s task(s)\", self, len(tis))\n\n        for ti in list(tis):\n            # skip in db?\n            if ti.state == State.REMOVED:\n                tis.remove(ti)\n            else:\n                ti.task = dag.get_task(ti.task_id)\n\n        # pre-calculate\n        # db is faster\n        start_dttm = timezone.utcnow()\n        unfinished_tasks = self.get_task_instances(\n            state=State.unfinished(),\n            session=session\n        )\n        none_depends_on_past = all(not t.task.depends_on_past for t in unfinished_tasks)\n        none_task_concurrency = all(t.task.task_concurrency is None\n                                    for t in unfinished_tasks)\n        # small speed up\n        if unfinished_tasks and none_depends_on_past and none_task_concurrency:\n            # todo: this can actually get pretty slow: one task costs between 0.01-015s\n            no_dependencies_met = True\n            for ut in unfinished_tasks:\n                # We need to flag upstream and check for changes because upstream\n                # failures/re-schedules can result in deadlock false positives\n                old_state = ut.state\n                deps_met = ut.are_dependencies_met(\n                    dep_context=DepContext(\n                        flag_upstream_failed=True,\n                        ignore_in_retry_period=True,\n                        ignore_in_reschedule_period=True),\n                    session=session)\n                if deps_met or old_state != ut.current_state(session=session):\n                    no_dependencies_met = False\n                    break\n\n        duration = (timezone.utcnow() - start_dttm).total_seconds() * 1000\n        Stats.timing(\"dagrun.dependency-check.{}\".format(self.dag_id), duration)\n\n        root_ids = [t.task_id for t in dag.roots]\n        roots = [t for t in tis if t.task_id in root_ids]\n\n        # if all roots finished and at least one failed, the run failed\n        if (not unfinished_tasks and\n                any(r.state in (State.FAILED, State.UPSTREAM_FAILED) for r in roots)):\n            self.log.info('Marking run %s failed', self)\n            self.set_state(State.FAILED)\n            dag.handle_callback(self, success=False, reason='task_failure',\n                                session=session)\n\n        # if all roots succeeded and no unfinished tasks, the run succeeded\n        elif not unfinished_tasks and all(r.state in (State.SUCCESS, State.SKIPPED)\n                                          for r in roots):\n            self.log.info('Marking run %s successful', self)\n            self.set_state(State.SUCCESS)\n            dag.handle_callback(self, success=True, reason='success', session=session)\n\n        # if *all tasks* are deadlocked, the run failed\n        elif (unfinished_tasks and none_depends_on_past and\n              none_task_concurrency and no_dependencies_met):\n            self.log.info('Deadlock; marking run %s failed', self)\n            self.set_state(State.FAILED)\n            dag.handle_callback(self, success=False, reason='all_tasks_deadlocked',\n                                session=session)\n\n        # finally, if the roots aren't done, the dag is still running\n        else:\n            self.set_state(State.RUNNING)\n\n        self._emit_duration_stats_for_finished_state()\n\n        # todo: determine we want to use with_for_update to make sure to lock the run\n        session.merge(self)\n        session.commit()\n\n        return self.state", "response": "Updates the overall state of the DagRun based on the state of its TaskInstances."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify_integrity(self, session=None):\n        from airflow.models.taskinstance import TaskInstance  # Avoid circular import\n\n        dag = self.get_dag()\n        tis = self.get_task_instances(session=session)\n\n        # check for removed or restored tasks\n        task_ids = []\n        for ti in tis:\n            task_ids.append(ti.task_id)\n            task = None\n            try:\n                task = dag.get_task(ti.task_id)\n            except AirflowException:\n                if ti.state == State.REMOVED:\n                    pass  # ti has already been removed, just ignore it\n                elif self.state is not State.RUNNING and not dag.partial:\n                    self.log.warning(\"Failed to get task '{}' for dag '{}'. \"\n                                     \"Marking it as removed.\".format(ti, dag))\n                    Stats.incr(\n                        \"task_removed_from_dag.{}\".format(dag.dag_id), 1, 1)\n                    ti.state = State.REMOVED\n\n            is_task_in_dag = task is not None\n            should_restore_task = is_task_in_dag and ti.state == State.REMOVED\n            if should_restore_task:\n                self.log.info(\"Restoring task '{}' which was previously \"\n                              \"removed from DAG '{}'\".format(ti, dag))\n                Stats.incr(\"task_restored_to_dag.{}\".format(dag.dag_id), 1, 1)\n                ti.state = State.NONE\n\n        # check for missing tasks\n        for task in six.itervalues(dag.task_dict):\n            if task.start_date > self.execution_date and not self.is_backfill:\n                continue\n\n            if task.task_id not in task_ids:\n                Stats.incr(\n                    \"task_instance_created-{}\".format(task.__class__.__name__),\n                    1, 1)\n                ti = TaskInstance(task, self.execution_date)\n                session.add(ti)\n\n        session.commit()", "response": "Verifies that the DagRun has the correct integrity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_run(session, dag_id, execution_date):\n        qry = session.query(DagRun).filter(\n            DagRun.dag_id == dag_id,\n            DagRun.external_trigger == False, # noqa\n            DagRun.execution_date == execution_date,\n        )\n        return qry.first()", "response": "Get the DagRun object corresponding to the given dag_id and execution_date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef poll_job_in_queue(self, location, jenkins_server):\n        try_count = 0\n        location = location + '/api/json'\n        # TODO Use get_queue_info instead\n        # once it will be available in python-jenkins (v > 0.4.15)\n        self.log.info('Polling jenkins queue at the url %s', location)\n        while try_count < self.max_try_before_job_appears:\n            location_answer = jenkins_request_with_headers(jenkins_server,\n                                                           Request(location))\n            if location_answer is not None:\n                json_response = json.loads(location_answer['body'])\n                if 'executable' in json_response:\n                    build_number = json_response['executable']['number']\n                    self.log.info('Job executed on Jenkins side with the build number %s',\n                                  build_number)\n                    return build_number\n            try_count += 1\n            time.sleep(self.sleep_time)\n        raise AirflowException(\"The job hasn't been executed\"\n                               \" after polling the queue %d times\",\n                               self.max_try_before_job_appears)", "response": "This method polls the jenkins queue until the job is executed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef context_to_airflow_vars(context, in_env_var_format=False):\n    params = dict()\n    if in_env_var_format:\n        name_format = 'env_var_format'\n    else:\n        name_format = 'default'\n    task_instance = context.get('task_instance')\n    if task_instance and task_instance.dag_id:\n        params[AIRFLOW_VAR_NAME_FORMAT_MAPPING['AIRFLOW_CONTEXT_DAG_ID'][\n            name_format]] = task_instance.dag_id\n    if task_instance and task_instance.task_id:\n        params[AIRFLOW_VAR_NAME_FORMAT_MAPPING['AIRFLOW_CONTEXT_TASK_ID'][\n            name_format]] = task_instance.task_id\n    if task_instance and task_instance.execution_date:\n        params[\n            AIRFLOW_VAR_NAME_FORMAT_MAPPING['AIRFLOW_CONTEXT_EXECUTION_DATE'][\n                name_format]] = task_instance.execution_date.isoformat()\n    dag_run = context.get('dag_run')\n    if dag_run and dag_run.run_id:\n        params[AIRFLOW_VAR_NAME_FORMAT_MAPPING['AIRFLOW_CONTEXT_DAG_RUN_ID'][\n            name_format]] = dag_run.run_id\n    return params", "response": "Given a context this function returns a dictionary of values that can be used to reconstruct relations between dags dag_runs and tasks and task_instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls callbacks before execution.", "response": "def on_pre_execution(**kwargs):\n    \"\"\"\n    Calls callbacks before execution.\n    Note that any exception from callback will be logged but won't be propagated.\n    :param kwargs:\n    :return: None\n    \"\"\"\n    logging.debug(\"Calling callbacks: %s\", __pre_exec_callbacks)\n    for cb in __pre_exec_callbacks:\n        try:\n            cb(**kwargs)\n        except Exception:\n            logging.exception('Failed on pre-execution callback using %s', cb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_post_execution(**kwargs):\n    logging.debug(\"Calling callbacks: %s\", __post_exec_callbacks)\n    for cb in __post_exec_callbacks:\n        try:\n            cb(**kwargs)\n        except Exception:\n            logging.exception('Failed on post-execution callback using %s', cb)", "response": "Calls callbacks after execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conditionally_trigger(context, dag_run_obj):\n    c_p = context['params']['condition_param']\n    print(\"Controller DAG : conditionally_trigger = {}\".format(c_p))\n    if context['params']['condition_param']:\n        dag_run_obj.payload = {'message': context['params']['message']}\n        pp.pprint(dag_run_obj.payload)\n        return dag_run_obj", "response": "This function decides whether or not to Trigger the remote DAG"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_metric(self, metric_name, datapoint, tags=None, type_=None, interval=None):\n        response = api.Metric.send(\n            metric=metric_name,\n            points=datapoint,\n            host=self.host,\n            tags=tags,\n            type=type_,\n            interval=interval)\n\n        self.validate_response(response)\n        return response", "response": "Send a single datapoint metric to DataDog\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_metric(self,\n                     query,\n                     from_seconds_ago,\n                     to_seconds_ago):\n        \"\"\"\n        Queries datadog for a specific metric, potentially with some\n        function applied to it and returns the results.\n\n        :param query: The datadog query to execute (see datadog docs)\n        :type query: str\n        :param from_seconds_ago: How many seconds ago to start querying for.\n        :type from_seconds_ago: int\n        :param to_seconds_ago: Up to how many seconds ago to query for.\n        :type to_seconds_ago: int\n        \"\"\"\n        now = int(time.time())\n\n        response = api.Metric.query(\n            start=now - from_seconds_ago,\n            end=now - to_seconds_ago,\n            query=query)\n\n        self.validate_response(response)\n        return response", "response": "Queries datadog for a specific metric potentially with some other function applied to it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_event(self, title, text, aggregation_key=None, alert_type=None, date_happened=None,\n                   handle=None, priority=None, related_event_id=None, tags=None, device_name=None):\n        \"\"\"\n        Posts an event to datadog (processing finished, potentially alerts, other issues)\n        Think about this as a means to maintain persistence of alerts, rather than\n        alerting itself.\n\n        :param title: The title of the event\n        :type title: str\n        :param text: The body of the event (more information)\n        :type text: str\n        :param aggregation_key: Key that can be used to aggregate this event in a stream\n        :type aggregation_key: str\n        :param alert_type: The alert type for the event, one of\n            [\"error\", \"warning\", \"info\", \"success\"]\n        :type alert_type: str\n        :param date_happened: POSIX timestamp of the event; defaults to now\n        :type date_happened: int\n        :handle: User to post the event as; defaults to owner of the application key used\n            to submit.\n        :param handle: str\n        :param priority: Priority to post the event as. (\"normal\" or \"low\", defaults to \"normal\")\n        :type priority: str\n        :param related_event_id: Post event as a child of the given event\n        :type related_event_id: id\n        :param tags: List of tags to apply to the event\n        :type tags: list[str]\n        :param device_name: device_name to post the event with\n        :type device_name: list\n        \"\"\"\n        response = api.Event.create(\n            title=title,\n            text=text,\n            aggregation_key=aggregation_key,\n            alert_type=alert_type,\n            date_happened=date_happened,\n            handle=handle,\n            priority=priority,\n            related_event_id=related_event_id,\n            tags=tags,\n            host=self.host,\n            device_name=device_name,\n            source_type_name=self.source_type_name)\n\n        self.validate_response(response)\n        return response", "response": "Post an event to the datadog."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_token(self, token, http_conn_id):\n        if token:\n            return token\n        elif http_conn_id:\n            conn = self.get_connection(http_conn_id)\n            extra = conn.extra_dejson\n            return extra.get('webhook_token', '')\n        else:\n            raise AirflowException('Cannot get token: No valid Slack '\n                                   'webhook token nor conn_id supplied')", "response": "Given either a manually set token or a conn_id return the webhook_token to use\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_slack_message(self):\n        cmd = {}\n\n        if self.channel:\n            cmd['channel'] = self.channel\n        if self.username:\n            cmd['username'] = self.username\n        if self.icon_emoji:\n            cmd['icon_emoji'] = self.icon_emoji\n        if self.link_names:\n            cmd['link_names'] = 1\n        if self.attachments:\n            cmd['attachments'] = self.attachments\n\n        cmd['text'] = self.message\n        return json.dumps(cmd)", "response": "Builds the Slack message from the current object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the slack webhook call", "response": "def execute(self):\n        \"\"\"\n        Remote Popen (actually execute the slack webhook call)\n        \"\"\"\n        proxies = {}\n        if self.proxy:\n            # we only need https proxy for Slack, as the endpoint is https\n            proxies = {'https': self.proxy}\n\n        slack_message = self._build_slack_message()\n        self.run(endpoint=self.webhook_token,\n                 data=slack_message,\n                 headers={'Content-type': 'application/json'},\n                 extra_options={'proxies': proxies})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dag(self, dag_id):\n        from airflow.models.dag import DagModel  # Avoid circular import\n\n        # If asking for a known subdag, we want to refresh the parent\n        root_dag_id = dag_id\n        if dag_id in self.dags:\n            dag = self.dags[dag_id]\n            if dag.is_subdag:\n                root_dag_id = dag.parent_dag.dag_id\n\n        # If the dag corresponding to root_dag_id is absent or expired\n        orm_dag = DagModel.get_current(root_dag_id)\n        if orm_dag and (\n                root_dag_id not in self.dags or\n                (\n                    orm_dag.last_expired and\n                    dag.last_loaded < orm_dag.last_expired\n                )\n        ):\n            # Reprocess source file\n            found_dags = self.process_file(\n                filepath=orm_dag.fileloc, only_if_updated=False)\n\n            # If the source file no longer exports `dag_id`, delete it from self.dags\n            if found_dags and dag_id in [found_dag.dag_id for found_dag in found_dags]:\n                return self.dags[dag_id]\n            elif dag_id in self.dags:\n                del self.dags[dag_id]\n        return self.dags.get(dag_id)", "response": "Gets the DAG from the dictionary and refreshes it if expired"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a path to a python module or zip file, this method imports the module and look for dag objects within it.", "response": "def process_file(self, filepath, only_if_updated=True, safe_mode=True):\n        \"\"\"\n        Given a path to a python module or zip file, this method imports\n        the module and look for dag objects within it.\n        \"\"\"\n        from airflow.models.dag import DAG  # Avoid circular import\n\n        found_dags = []\n\n        # if the source file no longer exists in the DB or in the filesystem,\n        # return an empty list\n        # todo: raise exception?\n        if filepath is None or not os.path.isfile(filepath):\n            return found_dags\n\n        try:\n            # This failed before in what may have been a git sync\n            # race condition\n            file_last_changed_on_disk = datetime.fromtimestamp(os.path.getmtime(filepath))\n            if only_if_updated \\\n                    and filepath in self.file_last_changed \\\n                    and file_last_changed_on_disk == self.file_last_changed[filepath]:\n                return found_dags\n\n        except Exception as e:\n            self.log.exception(e)\n            return found_dags\n\n        mods = []\n        is_zipfile = zipfile.is_zipfile(filepath)\n        if not is_zipfile:\n            if safe_mode:\n                with open(filepath, 'rb') as f:\n                    content = f.read()\n                    if not all([s in content for s in (b'DAG', b'airflow')]):\n                        self.file_last_changed[filepath] = file_last_changed_on_disk\n                        # Don't want to spam user with skip messages\n                        if not self.has_logged:\n                            self.has_logged = True\n                            self.log.info(\n                                \"File %s assumed to contain no DAGs. Skipping.\",\n                                filepath)\n                        return found_dags\n\n            self.log.debug(\"Importing %s\", filepath)\n            org_mod_name, _ = os.path.splitext(os.path.split(filepath)[-1])\n            mod_name = ('unusual_prefix_' +\n                        hashlib.sha1(filepath.encode('utf-8')).hexdigest() +\n                        '_' + org_mod_name)\n\n            if mod_name in sys.modules:\n                del sys.modules[mod_name]\n\n            with timeout(configuration.conf.getint('core', \"DAGBAG_IMPORT_TIMEOUT\")):\n                try:\n                    m = imp.load_source(mod_name, filepath)\n                    mods.append(m)\n                except Exception as e:\n                    self.log.exception(\"Failed to import: %s\", filepath)\n                    self.import_errors[filepath] = str(e)\n                    self.file_last_changed[filepath] = file_last_changed_on_disk\n\n        else:\n            zip_file = zipfile.ZipFile(filepath)\n            for mod in zip_file.infolist():\n                head, _ = os.path.split(mod.filename)\n                mod_name, ext = os.path.splitext(mod.filename)\n                if not head and (ext == '.py' or ext == '.pyc'):\n                    if mod_name == '__init__':\n                        self.log.warning(\"Found __init__.%s at root of %s\", ext, filepath)\n                    if safe_mode:\n                        with zip_file.open(mod.filename) as zf:\n                            self.log.debug(\"Reading %s from %s\", mod.filename, filepath)\n                            content = zf.read()\n                            if not all([s in content for s in (b'DAG', b'airflow')]):\n                                self.file_last_changed[filepath] = (\n                                    file_last_changed_on_disk)\n                                # todo: create ignore list\n                                # Don't want to spam user with skip messages\n                                if not self.has_logged:\n                                    self.has_logged = True\n                                    self.log.info(\n                                        \"File %s assumed to contain no DAGs. Skipping.\",\n                                        filepath)\n\n                    if mod_name in sys.modules:\n                        del sys.modules[mod_name]\n\n                    try:\n                        sys.path.insert(0, filepath)\n                        m = importlib.import_module(mod_name)\n                        mods.append(m)\n                    except Exception as e:\n                        self.log.exception(\"Failed to import: %s\", filepath)\n                        self.import_errors[filepath] = str(e)\n                        self.file_last_changed[filepath] = file_last_changed_on_disk\n\n        for m in mods:\n            for dag in list(m.__dict__.values()):\n                if isinstance(dag, DAG):\n                    if not dag.full_filepath:\n                        dag.full_filepath = filepath\n                        if dag.fileloc != filepath and not is_zipfile:\n                            dag.fileloc = filepath\n                    try:\n                        dag.is_subdag = False\n                        self.bag_dag(dag, parent_dag=dag, root_dag=dag)\n                        if isinstance(dag._schedule_interval, six.string_types):\n                            croniter(dag._schedule_interval)\n                        found_dags.append(dag)\n                        found_dags += dag.subdags\n                    except (CroniterBadCronError,\n                            CroniterBadDateError,\n                            CroniterNotAlphaError) as cron_e:\n                        self.log.exception(\"Failed to bag_dag: %s\", dag.full_filepath)\n                        self.import_errors[dag.full_filepath] = \\\n                            \"Invalid Cron expression: \" + str(cron_e)\n                        self.file_last_changed[dag.full_filepath] = \\\n                            file_last_changed_on_disk\n                    except AirflowDagCycleException as cycle_exception:\n                        self.log.exception(\"Failed to bag_dag: %s\", dag.full_filepath)\n                        self.import_errors[dag.full_filepath] = str(cycle_exception)\n                        self.file_last_changed[dag.full_filepath] = \\\n                            file_last_changed_on_disk\n\n        self.file_last_changed[filepath] = file_last_changed_on_disk\n        return found_dags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef kill_zombies(self, zombies, session=None):\n        from airflow.models.taskinstance import TaskInstance  # Avoid circular import\n\n        for zombie in zombies:\n            if zombie.dag_id in self.dags:\n                dag = self.dags[zombie.dag_id]\n                if zombie.task_id in dag.task_ids:\n                    task = dag.get_task(zombie.task_id)\n                    ti = TaskInstance(task, zombie.execution_date)\n                    # Get properties needed for failure handling from SimpleTaskInstance.\n                    ti.start_date = zombie.start_date\n                    ti.end_date = zombie.end_date\n                    ti.try_number = zombie.try_number\n                    ti.state = zombie.state\n                    ti.test_mode = configuration.getboolean('core', 'unit_test_mode')\n                    ti.handle_failure(\"{} detected as zombie\".format(ti),\n                                      ti.test_mode, ti.get_template_context())\n                    self.log.info(\n                        'Marked zombie job %s as %s', ti, ti.state)\n                    Stats.incr('zombies_killed')\n        session.commit()", "response": "Fail given zombies which are tasks that have not had a heartbeat for too long in the current DagBag."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bag_dag(self, dag, parent_dag, root_dag):\n\n        dag.test_cycle()  # throws if a task cycle is found\n\n        dag.resolve_template_files()\n        dag.last_loaded = timezone.utcnow()\n\n        for task in dag.tasks:\n            settings.policy(task)\n\n        subdags = dag.subdags\n\n        try:\n            for subdag in subdags:\n                subdag.full_filepath = dag.full_filepath\n                subdag.parent_dag = dag\n                subdag.is_subdag = True\n                self.bag_dag(subdag, parent_dag=dag, root_dag=root_dag)\n\n            self.dags[dag.dag_id] = dag\n            self.log.debug('Loaded DAG %s', dag)\n        except AirflowDagCycleException as cycle_exception:\n            # There was an error in bagging the dag. Remove it from the list of dags\n            self.log.exception('Exception bagging dag: %s', dag.dag_id)\n            # Only necessary at the root level since DAG.subdags automatically\n            # performs DFS to search through all subdags\n            if dag == root_dag:\n                for subdag in subdags:\n                    if subdag.dag_id in self.dags:\n                        del self.dags[subdag.dag_id]\n            raise cycle_exception", "response": "Adds the dag into the bag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a file path or a folder, this method looks for python modules, imports them and adds them to the dagbag collection. Note that if a ``.airflowignore`` file is found while processing the directory, it will behave much like a ``.gitignore``, ignoring files that match any of the regex patterns specified in the file. **Note**: The patterns in .airflowignore are treated as un-anchored regexes, not shell-like glob patterns.", "response": "def collect_dags(\n            self,\n            dag_folder=None,\n            only_if_updated=True,\n            include_examples=configuration.conf.getboolean('core', 'LOAD_EXAMPLES'),\n            safe_mode=configuration.conf.getboolean('core', 'DAG_DISCOVERY_SAFE_MODE')):\n        \"\"\"\n        Given a file path or a folder, this method looks for python modules,\n        imports them and adds them to the dagbag collection.\n\n        Note that if a ``.airflowignore`` file is found while processing\n        the directory, it will behave much like a ``.gitignore``,\n        ignoring files that match any of the regex patterns specified\n        in the file.\n\n        **Note**: The patterns in .airflowignore are treated as\n        un-anchored regexes, not shell-like glob patterns.\n        \"\"\"\n        start_dttm = timezone.utcnow()\n        dag_folder = dag_folder or self.dag_folder\n\n        # Used to store stats around DagBag processing\n        stats = []\n        FileLoadStat = namedtuple(\n            'FileLoadStat', \"file duration dag_num task_num dags\")\n\n        dag_folder = correct_maybe_zipped(dag_folder)\n\n        for filepath in list_py_file_paths(dag_folder, safe_mode=safe_mode,\n                                           include_examples=include_examples):\n            try:\n                ts = timezone.utcnow()\n                found_dags = self.process_file(\n                    filepath, only_if_updated=only_if_updated,\n                    safe_mode=safe_mode)\n\n                td = timezone.utcnow() - ts\n                td = td.total_seconds() + (\n                    float(td.microseconds) / 1000000)\n                stats.append(FileLoadStat(\n                    filepath.replace(dag_folder, ''),\n                    td,\n                    len(found_dags),\n                    sum([len(dag.tasks) for dag in found_dags]),\n                    str([dag.dag_id for dag in found_dags]),\n                ))\n            except Exception as e:\n                self.log.exception(e)\n        Stats.gauge(\n            'collect_dags', (timezone.utcnow() - start_dttm).total_seconds(), 1)\n        Stats.gauge(\n            'dagbag_size', len(self.dags), 1)\n        Stats.gauge(\n            'dagbag_import_errors', len(self.import_errors), 1)\n        self.dagbag_stats = sorted(\n            stats, key=lambda x: x.duration, reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a report around DagBag loading stats", "response": "def dagbag_report(self):\n        \"\"\"Prints a report around DagBag loading stats\"\"\"\n        report = textwrap.dedent(\"\"\"\\n\n        -------------------------------------------------------------------\n        DagBag loading stats for {dag_folder}\n        -------------------------------------------------------------------\n        Number of DAGs: {dag_num}\n        Total task number: {task_num}\n        DagBag parsing time: {duration}\n        {table}\n        \"\"\")\n        stats = self.dagbag_stats\n        return report.format(\n            dag_folder=self.dag_folder,\n            duration=sum([o.duration for o in stats]),\n            dag_num=sum([o.dag_num for o in stats]),\n            task_num=sum([o.task_num for o in stats]),\n            table=pprinttable(stats),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the Spark job.", "response": "def execute(self, context):\n        \"\"\"\n        Call the SparkSubmitHook to run the provided spark job\n        \"\"\"\n        self._hook = SparkJDBCHook(\n            spark_app_name=self._spark_app_name,\n            spark_conn_id=self._spark_conn_id,\n            spark_conf=self._spark_conf,\n            spark_py_files=self._spark_py_files,\n            spark_files=self._spark_files,\n            spark_jars=self._spark_jars,\n            num_executors=self._num_executors,\n            executor_cores=self._executor_cores,\n            executor_memory=self._executor_memory,\n            driver_memory=self._driver_memory,\n            verbose=self._verbose,\n            keytab=self._keytab,\n            principal=self._principal,\n            cmd_type=self._cmd_type,\n            jdbc_table=self._jdbc_table,\n            jdbc_conn_id=self._jdbc_conn_id,\n            jdbc_driver=self._jdbc_driver,\n            metastore_table=self._metastore_table,\n            jdbc_truncate=self._jdbc_truncate,\n            save_mode=self._save_mode,\n            save_format=self._save_format,\n            batch_size=self._batch_size,\n            fetch_size=self._fetch_size,\n            num_partitions=self._num_partitions,\n            partition_column=self._partition_column,\n            lower_bound=self._lower_bound,\n            upper_bound=self._upper_bound,\n            create_table_column_types=self._create_table_column_types\n        )\n        self._hook.submit_jdbc_job()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ds_add(ds, days):\n\n    ds = datetime.strptime(ds, '%Y-%m-%d')\n    if days:\n        ds = ds + timedelta(days)\n    return ds.isoformat()[:10]", "response": "Add or subtract days from a YYYY - MM - DD format"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake an input string and outputs another string which contains a date", "response": "def ds_format(ds, input_format, output_format):\n    \"\"\"\n    Takes an input string and outputs another string\n    as specified in the output format\n\n    :param ds: input string which contains a date\n    :type ds: str\n    :param input_format: input string format. E.g. %Y-%m-%d\n    :type input_format: str\n    :param output_format: output string format  E.g. %Y-%m-%d\n    :type output_format: str\n\n    >>> ds_format('2015-01-01', \"%Y-%m-%d\", \"%m-%d-%y\")\n    '01-01-15'\n    >>> ds_format('1/5/2015', \"%m/%d/%Y\",  \"%Y-%m-%d\")\n    '2015-01-05'\n    \"\"\"\n    return datetime.strptime(ds, input_format).strftime(output_format)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _integrate_plugins():\n    import sys\n    from airflow.plugins_manager import macros_modules\n    for macros_module in macros_modules:\n        sys.modules[macros_module.__name__] = macros_module\n        globals()[macros_module._name] = macros_module", "response": "Integrate plugins to the context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef poke(self, context):\n        sb = self.hook(self.hdfs_conn_id).get_conn()\n        self.log.info(\n            'Poking for %s to be a directory with files matching %s', self.filepath, self.regex.pattern\n        )\n        result = [f for f in sb.ls([self.filepath], include_toplevel=False) if\n                  f['file_type'] == 'f' and\n                  self.regex.match(f['path'].replace('%s/' % self.filepath, ''))]\n        result = self.filter_for_ignored_ext(result, self.ignored_ext,\n                                             self.ignore_copying)\n        result = self.filter_for_filesize(result, self.file_size)\n        return bool(result)", "response": "Pokes for files in a directory with self. regex\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef poke(self, context):\n        sb = self.hook(self.hdfs_conn_id).get_conn()\n        result = [f for f in sb.ls([self.filepath], include_toplevel=True)]\n        result = self.filter_for_ignored_ext(result, self.ignored_ext,\n                                             self.ignore_copying)\n        result = self.filter_for_filesize(result, self.file_size)\n        if self.be_empty:\n            self.log.info('Poking for filepath %s to a empty directory', self.filepath)\n            return len(result) == 1 and result[0]['path'] == self.filepath\n        else:\n            self.log.info('Poking for filepath %s to a non empty directory', self.filepath)\n            result.pop(0)\n            return bool(result) and result[0]['file_type'] == 'f'", "response": "Returns True if the filepath is in the non empty directory False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclearing the set of task instances from the database.", "response": "def clear_task_instances(tis,\n                         session,\n                         activate_dag_runs=True,\n                         dag=None,\n                         ):\n    \"\"\"\n    Clears a set of task instances, but makes sure the running ones\n    get killed.\n\n    :param tis: a list of task instances\n    :param session: current session\n    :param activate_dag_runs: flag to check for active dag run\n    :param dag: DAG object\n    \"\"\"\n    job_ids = []\n    for ti in tis:\n        if ti.state == State.RUNNING:\n            if ti.job_id:\n                ti.state = State.SHUTDOWN\n                job_ids.append(ti.job_id)\n        else:\n            task_id = ti.task_id\n            if dag and dag.has_task(task_id):\n                task = dag.get_task(task_id)\n                task_retries = task.retries\n                ti.max_tries = ti.try_number + task_retries - 1\n            else:\n                # Ignore errors when updating max_tries if dag is None or\n                # task not found in dag since database records could be\n                # outdated. We make max_tries the maximum value of its\n                # original max_tries or the current task try number.\n                ti.max_tries = max(ti.max_tries, ti.try_number - 1)\n            ti.state = State.NONE\n            session.merge(ti)\n\n    if job_ids:\n        from airflow.jobs import BaseJob as BJ\n        for job in session.query(BJ).filter(BJ.id.in_(job_ids)).all():\n            job.state = State.SHUTDOWN\n\n    if activate_dag_runs and tis:\n        from airflow.models.dagrun import DagRun  # Avoid circular import\n        drs = session.query(DagRun).filter(\n            DagRun.dag_id.in_({ti.dag_id for ti in tis}),\n            DagRun.execution_date.in_({ti.execution_date for ti in tis}),\n        ).all()\n        for dr in drs:\n            dr.state = State.RUNNING\n            dr.start_date = timezone.utcnow()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the try number that this TI will be actually running.", "response": "def try_number(self):\n        \"\"\"\n        Return the try number that this task number will be when it is actually\n        run.\n\n        If the TI is currently running, this will match the column in the\n        databse, in all othercases this will be incremenetd\n        \"\"\"\n        # This is designed so that task logs end up in the right file.\n        if self.state == State.RUNNING:\n            return self._try_number\n        return self._try_number + 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef command(\n            self,\n            mark_success=False,\n            ignore_all_deps=False,\n            ignore_depends_on_past=False,\n            ignore_task_deps=False,\n            ignore_ti_state=False,\n            local=False,\n            pickle_id=None,\n            raw=False,\n            job_id=None,\n            pool=None,\n            cfg_path=None):\n        \"\"\"\n        Returns a command that can be executed anywhere where airflow is\n        installed. This command is part of the message sent to executors by\n        the orchestrator.\n        \"\"\"\n        return \" \".join(self.command_as_list(\n            mark_success=mark_success,\n            ignore_all_deps=ignore_all_deps,\n            ignore_depends_on_past=ignore_depends_on_past,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state,\n            local=local,\n            pickle_id=pickle_id,\n            raw=raw,\n            job_id=job_id,\n            pool=pool,\n            cfg_path=cfg_path))", "response": "Returns a string that can be executed anywhere where airflow is a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a command that can be executed anywhere in airflow.", "response": "def command_as_list(\n            self,\n            mark_success=False,\n            ignore_all_deps=False,\n            ignore_task_deps=False,\n            ignore_depends_on_past=False,\n            ignore_ti_state=False,\n            local=False,\n            pickle_id=None,\n            raw=False,\n            job_id=None,\n            pool=None,\n            cfg_path=None):\n        \"\"\"\n        Returns a command that can be executed anywhere where airflow is\n        installed. This command is part of the message sent to executors by\n        the orchestrator.\n        \"\"\"\n        dag = self.task.dag\n\n        should_pass_filepath = not pickle_id and dag\n        if should_pass_filepath and dag.full_filepath != dag.filepath:\n            path = \"DAGS_FOLDER/{}\".format(dag.filepath)\n        elif should_pass_filepath and dag.full_filepath:\n            path = dag.full_filepath\n        else:\n            path = None\n\n        return TaskInstance.generate_command(\n            self.dag_id,\n            self.task_id,\n            self.execution_date,\n            mark_success=mark_success,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_depends_on_past=ignore_depends_on_past,\n            ignore_ti_state=ignore_ti_state,\n            local=local,\n            pickle_id=pickle_id,\n            file_path=path,\n            raw=raw,\n            job_id=job_id,\n            pool=pool,\n            cfg_path=cfg_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_command(dag_id,\n                         task_id,\n                         execution_date,\n                         mark_success=False,\n                         ignore_all_deps=False,\n                         ignore_depends_on_past=False,\n                         ignore_task_deps=False,\n                         ignore_ti_state=False,\n                         local=False,\n                         pickle_id=None,\n                         file_path=None,\n                         raw=False,\n                         job_id=None,\n                         pool=None,\n                         cfg_path=None\n                         ):\n        \"\"\"\n        Generates the shell command required to execute this task instance.\n\n        :param dag_id: DAG ID\n        :type dag_id: unicode\n        :param task_id: Task ID\n        :type task_id: unicode\n        :param execution_date: Execution date for the task\n        :type execution_date: datetime\n        :param mark_success: Whether to mark the task as successful\n        :type mark_success: bool\n        :param ignore_all_deps: Ignore all ignorable dependencies.\n            Overrides the other ignore_* parameters.\n        :type ignore_all_deps: bool\n        :param ignore_depends_on_past: Ignore depends_on_past parameter of DAGs\n            (e.g. for Backfills)\n        :type ignore_depends_on_past: bool\n        :param ignore_task_deps: Ignore task-specific dependencies such as depends_on_past\n            and trigger rule\n        :type ignore_task_deps: bool\n        :param ignore_ti_state: Ignore the task instance's previous failure/success\n        :type ignore_ti_state: bool\n        :param local: Whether to run the task locally\n        :type local: bool\n        :param pickle_id: If the DAG was serialized to the DB, the ID\n            associated with the pickled DAG\n        :type pickle_id: unicode\n        :param file_path: path to the file containing the DAG definition\n        :param raw: raw mode (needs more details)\n        :param job_id: job ID (needs more details)\n        :param pool: the Airflow pool that the task should run in\n        :type pool: unicode\n        :param cfg_path: the Path to the configuration file\n        :type cfg_path: basestring\n        :return: shell command that can be used to run the task instance\n        \"\"\"\n        iso = execution_date.isoformat()\n        cmd = [\"airflow\", \"run\", str(dag_id), str(task_id), str(iso)]\n        cmd.extend([\"--mark_success\"]) if mark_success else None\n        cmd.extend([\"--pickle\", str(pickle_id)]) if pickle_id else None\n        cmd.extend([\"--job_id\", str(job_id)]) if job_id else None\n        cmd.extend([\"-A\"]) if ignore_all_deps else None\n        cmd.extend([\"-i\"]) if ignore_task_deps else None\n        cmd.extend([\"-I\"]) if ignore_depends_on_past else None\n        cmd.extend([\"--force\"]) if ignore_ti_state else None\n        cmd.extend([\"--local\"]) if local else None\n        cmd.extend([\"--pool\", pool]) if pool else None\n        cmd.extend([\"--raw\"]) if raw else None\n        cmd.extend([\"-sd\", file_path]) if file_path else None\n        cmd.extend([\"--cfg_path\", cfg_path]) if cfg_path else None\n        return cmd", "response": "Generates the command required to execute a task instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef current_state(self, session=None):\n        TI = TaskInstance\n        ti = session.query(TI).filter(\n            TI.dag_id == self.dag_id,\n            TI.task_id == self.task_id,\n            TI.execution_date == self.execution_date,\n        ).all()\n        if ti:\n            state = ti[0].state\n        else:\n            state = None\n        return state", "response": "Get the current state of the task instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef error(self, session=None):\n        self.log.error(\"Recording the task instance as FAILED\")\n        self.state = State.FAILED\n        session.merge(self)\n        session.commit()", "response": "Mark the task instance as FAILED"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh_from_db(self, session=None, lock_for_update=False):\n        TI = TaskInstance\n\n        qry = session.query(TI).filter(\n            TI.dag_id == self.dag_id,\n            TI.task_id == self.task_id,\n            TI.execution_date == self.execution_date)\n\n        if lock_for_update:\n            ti = qry.with_for_update().first()\n        else:\n            ti = qry.first()\n        if ti:\n            self.state = ti.state\n            self.start_date = ti.start_date\n            self.end_date = ti.end_date\n            # Get the raw value of try_number column, don't read through the\n            # accessor here otherwise it will be incremeneted by one already.\n            self.try_number = ti._try_number\n            self.max_tries = ti.max_tries\n            self.hostname = ti.hostname\n            self.pid = ti.pid\n            self.executor_config = ti.executor_config\n        else:\n            self.state = None", "response": "Refreshes the TaskInstance from the database based on the primary key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear all XCom data for the task instance.", "response": "def clear_xcom_data(self, session=None):\n        \"\"\"\n        Clears all XCom data from the database for the task instance\n        \"\"\"\n        session.query(XCom).filter(\n            XCom.dag_id == self.dag_id,\n            XCom.task_id == self.task_id,\n            XCom.execution_date == self.execution_date\n        ).delete()\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef key(self):\n        return self.dag_id, self.task_id, self.execution_date, self.try_number", "response": "Returns a tuple that identifies the task instance uniquely identified by the task class instance and the try number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether the dependents of this task instance have all succeeded.", "response": "def are_dependents_done(self, session=None):\n        \"\"\"\n        Checks whether the dependents of this task instance have all succeeded.\n        This is meant to be used by wait_for_downstream.\n\n        This is useful when you do not want to start processing the next\n        schedule of a task until the dependents are done. For instance,\n        if the task DROPs and recreates a table.\n        \"\"\"\n        task = self.task\n\n        if not task.downstream_task_ids:\n            return True\n\n        ti = session.query(func.count(TaskInstance.task_id)).filter(\n            TaskInstance.dag_id == self.dag_id,\n            TaskInstance.task_id.in_(task.downstream_task_ids),\n            TaskInstance.execution_date == self.execution_date,\n            TaskInstance.state == State.SUCCESS,\n        )\n        count = ti[0][0]\n        return count == len(task.downstream_task_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef are_dependencies_met(\n            self,\n            dep_context=None,\n            session=None,\n            verbose=False):\n        \"\"\"\n        Returns whether or not all the conditions are met for this task instance to be run\n        given the context for the dependencies (e.g. a task instance being force run from\n        the UI will ignore some dependencies).\n\n        :param dep_context: The execution context that determines the dependencies that\n            should be evaluated.\n        :type dep_context: DepContext\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        :param verbose: whether log details on failed dependencies on\n            info or debug log level\n        :type verbose: bool\n        \"\"\"\n        dep_context = dep_context or DepContext()\n        failed = False\n        verbose_aware_logger = self.log.info if verbose else self.log.debug\n        for dep_status in self.get_failed_dep_statuses(\n                dep_context=dep_context,\n                session=session):\n            failed = True\n\n            verbose_aware_logger(\n                \"Dependencies not met for %s, dependency '%s' FAILED: %s\",\n                self, dep_status.dep_name, dep_status.reason\n            )\n\n        if failed:\n            return False\n\n        verbose_aware_logger(\"Dependencies all met for %s\", self)\n        return True", "response": "Returns whether or not all the conditions for this task instance are met."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets datetime of the next retry if the task instance fails.", "response": "def next_retry_datetime(self):\n        \"\"\"\n        Get datetime of the next retry if the task instance fails. For exponential\n        backoff, retry_delay is used as base and will be converted to seconds.\n        \"\"\"\n        delay = self.task.retry_delay\n        if self.task.retry_exponential_backoff:\n            min_backoff = int(delay.total_seconds() * (2 ** (self.try_number - 2)))\n            # deterministic per task instance\n            hash = int(hashlib.sha1(\"{}#{}#{}#{}\".format(self.dag_id,\n                                                         self.task_id,\n                                                         self.execution_date,\n                                                         self.try_number)\n                                    .encode('utf-8')).hexdigest(), 16)\n            # between 0.5 * delay * (2^retry_number) and 1.0 * delay * (2^retry_number)\n            modded_hash = min_backoff + hash % min_backoff\n            # timedelta has a maximum representable value. The exponentiation\n            # here means this value can be exceeded after a certain number\n            # of tries (around 50 if the initial delay is 1s, even fewer if\n            # the delay is larger). Cap the value here before creating a\n            # timedelta object so the operation doesn't fail.\n            delay_backoff_in_seconds = min(\n                modded_hash,\n                timedelta.max.total_seconds() - 1\n            )\n            delay = timedelta(seconds=delay_backoff_in_seconds)\n            if self.task.max_retry_delay:\n                delay = min(self.task.max_retry_delay, delay)\n        return self.end_date + delay"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ready_for_retry(self):\n        return (self.state == State.UP_FOR_RETRY and\n                self.next_retry_datetime() < timezone.utcnow())", "response": "Checks on whether the task instance is ready for retry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pool_full(self, session):\n        if not self.task.pool:\n            return False\n\n        pool = (\n            session\n            .query(Pool)\n            .filter(Pool.pool == self.task.pool)\n            .first()\n        )\n        if not pool:\n            return False\n        open_slots = pool.open_slots(session=session)\n\n        return open_slots <= 0", "response": "Returns a boolean as to whether the slot pool has room for this task to run."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the DagRun for this TaskInstance", "response": "def get_dagrun(self, session):\n        \"\"\"\n        Returns the DagRun for this TaskInstance\n\n        :param session:\n        :return: DagRun\n        \"\"\"\n        from airflow.models.dagrun import DagRun  # Avoid circular import\n        dr = session.query(DagRun).filter(\n            DagRun.dag_id == self.dag_id,\n            DagRun.execution_date == self.execution_date\n        ).first()\n\n        return dr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks dependencies and then sets state to RUNNING if they are met. Returns True if the state is changed to not True if the state is changed to running.", "response": "def _check_and_change_state_before_execution(\n            self,\n            verbose=True,\n            ignore_all_deps=False,\n            ignore_depends_on_past=False,\n            ignore_task_deps=False,\n            ignore_ti_state=False,\n            mark_success=False,\n            test_mode=False,\n            job_id=None,\n            pool=None,\n            session=None):\n        \"\"\"\n        Checks dependencies and then sets state to RUNNING if they are met. Returns\n        True if and only if state is set to RUNNING, which implies that task should be\n        executed, in preparation for _run_raw_task\n\n        :param verbose: whether to turn on more verbose logging\n        :type verbose: bool\n        :param ignore_all_deps: Ignore all of the non-critical dependencies, just runs\n        :type ignore_all_deps: bool\n        :param ignore_depends_on_past: Ignore depends_on_past DAG attribute\n        :type ignore_depends_on_past: bool\n        :param ignore_task_deps: Don't check the dependencies of this TI's task\n        :type ignore_task_deps: bool\n        :param ignore_ti_state: Disregards previous task instance state\n        :type ignore_ti_state: bool\n        :param mark_success: Don't run the task, mark its state as success\n        :type mark_success: bool\n        :param test_mode: Doesn't record success or failure in the DB\n        :type test_mode: bool\n        :param pool: specifies the pool to use to run the task instance\n        :type pool: str\n        :return: whether the state was changed to running or not\n        :rtype: bool\n        \"\"\"\n        task = self.task\n        self.pool = pool or task.pool\n        self.test_mode = test_mode\n        self.refresh_from_db(session=session, lock_for_update=True)\n        self.job_id = job_id\n        self.hostname = get_hostname()\n        self.operator = task.__class__.__name__\n\n        if not ignore_all_deps and not ignore_ti_state and self.state == State.SUCCESS:\n            Stats.incr('previously_succeeded', 1, 1)\n\n        queue_dep_context = DepContext(\n            deps=QUEUE_DEPS,\n            ignore_all_deps=ignore_all_deps,\n            ignore_ti_state=ignore_ti_state,\n            ignore_depends_on_past=ignore_depends_on_past,\n            ignore_task_deps=ignore_task_deps)\n        if not self.are_dependencies_met(\n                dep_context=queue_dep_context,\n                session=session,\n                verbose=True):\n            session.commit()\n            return False\n\n        # TODO: Logging needs cleanup, not clear what is being printed\n        hr = \"\\n\" + (\"-\" * 80)  # Line break\n\n        # For reporting purposes, we report based on 1-indexed,\n        # not 0-indexed lists (i.e. Attempt 1 instead of\n        # Attempt 0 for the first attempt).\n        # Set the task start date. In case it was re-scheduled use the initial\n        # start date that is recorded in task_reschedule table\n        self.start_date = timezone.utcnow()\n        task_reschedules = TaskReschedule.find_for_task_instance(self, session)\n        if task_reschedules:\n            self.start_date = task_reschedules[0].start_date\n\n        dep_context = DepContext(\n            deps=RUN_DEPS - QUEUE_DEPS,\n            ignore_all_deps=ignore_all_deps,\n            ignore_depends_on_past=ignore_depends_on_past,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        runnable = self.are_dependencies_met(\n            dep_context=dep_context,\n            session=session,\n            verbose=True)\n\n        if not runnable and not mark_success:\n            # FIXME: we might have hit concurrency limits, which means we probably\n            # have been running prematurely. This should be handled in the\n            # scheduling mechanism.\n            self.state = State.NONE\n            self.log.warning(hr)\n            self.log.warning(\n                \"FIXME: Rescheduling due to concurrency limits reached at task runtime. Attempt %s of \"\n                \"%s. State set to NONE.\", self.try_number, self.max_tries + 1\n            )\n            self.log.warning(hr)\n\n            self.queued_dttm = timezone.utcnow()\n            self.log.info(\"Queuing into pool %s\", self.pool)\n            session.merge(self)\n            session.commit()\n            return False\n\n        # Another worker might have started running this task instance while\n        # the current worker process was blocked on refresh_from_db\n        if self.state == State.RUNNING:\n            self.log.warning(\"Task Instance already running %s\", self)\n            session.commit()\n            return False\n\n        # print status message\n        self.log.info(hr)\n        self.log.info(\"Starting attempt %s of %s\", self.try_number, self.max_tries + 1)\n        self.log.info(hr)\n        self._try_number += 1\n\n        if not test_mode:\n            session.add(Log(State.RUNNING, self))\n        self.state = State.RUNNING\n        self.pid = os.getpid()\n        self.end_date = None\n        if not test_mode:\n            session.merge(self)\n        session.commit()\n\n        # Closing all pooled connections to prevent\n        # \"max number of connections reached\"\n        settings.engine.dispose()\n        if verbose:\n            if mark_success:\n                self.log.info(\"Marking success for %s on %s\", self.task, self.execution_date)\n            else:\n                self.log.info(\"Executing %s on %s\", self.task, self.execution_date)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the task and returns the result.", "response": "def _run_raw_task(\n            self,\n            mark_success=False,\n            test_mode=False,\n            job_id=None,\n            pool=None,\n            session=None):\n        \"\"\"\n        Immediately runs the task (without checking or changing db state\n        before execution) and then sets the appropriate final state after\n        completion and runs any post-execute callbacks. Meant to be called\n        only after another function changes the state to running.\n\n        :param mark_success: Don't run the task, mark its state as success\n        :type mark_success: bool\n        :param test_mode: Doesn't record success or failure in the DB\n        :type test_mode: bool\n        :param pool: specifies the pool to use to run the task instance\n        :type pool: str\n        \"\"\"\n        task = self.task\n        self.pool = pool or task.pool\n        self.test_mode = test_mode\n        self.refresh_from_db(session=session)\n        self.job_id = job_id\n        self.hostname = get_hostname()\n        self.operator = task.__class__.__name__\n\n        context = {}\n        actual_start_date = timezone.utcnow()\n        try:\n            if not mark_success:\n                context = self.get_template_context()\n\n                task_copy = copy.copy(task)\n                self.task = task_copy\n\n                def signal_handler(signum, frame):\n                    self.log.error(\"Received SIGTERM. Terminating subprocesses.\")\n                    task_copy.on_kill()\n                    raise AirflowException(\"Task received SIGTERM signal\")\n                signal.signal(signal.SIGTERM, signal_handler)\n\n                # Don't clear Xcom until the task is certain to execute\n                self.clear_xcom_data()\n\n                start_time = time.time()\n\n                self.render_templates()\n                task_copy.pre_execute(context=context)\n\n                # If a timeout is specified for the task, make it fail\n                # if it goes beyond\n                result = None\n                if task_copy.execution_timeout:\n                    try:\n                        with timeout(int(\n                                task_copy.execution_timeout.total_seconds())):\n                            result = task_copy.execute(context=context)\n                    except AirflowTaskTimeout:\n                        task_copy.on_kill()\n                        raise\n                else:\n                    result = task_copy.execute(context=context)\n\n                # If the task returns a result, push an XCom containing it\n                if task_copy.do_xcom_push and result is not None:\n                    self.xcom_push(key=XCOM_RETURN_KEY, value=result)\n\n                task_copy.post_execute(context=context, result=result)\n\n                end_time = time.time()\n                duration = end_time - start_time\n                Stats.timing(\n                    'dag.{dag_id}.{task_id}.duration'.format(\n                        dag_id=task_copy.dag_id,\n                        task_id=task_copy.task_id),\n                    duration)\n\n                Stats.incr('operator_successes_{}'.format(\n                    self.task.__class__.__name__), 1, 1)\n                Stats.incr('ti_successes')\n            self.refresh_from_db(lock_for_update=True)\n            self.state = State.SUCCESS\n        except AirflowSkipException:\n            self.refresh_from_db(lock_for_update=True)\n            self.state = State.SKIPPED\n        except AirflowRescheduleException as reschedule_exception:\n            self.refresh_from_db()\n            self._handle_reschedule(actual_start_date, reschedule_exception, test_mode, context)\n            return\n        except AirflowException as e:\n            self.refresh_from_db()\n            # for case when task is marked as success/failed externally\n            # current behavior doesn't hit the success callback\n            if self.state in {State.SUCCESS, State.FAILED}:\n                return\n            else:\n                self.handle_failure(e, test_mode, context)\n                raise\n        except (Exception, KeyboardInterrupt) as e:\n            self.handle_failure(e, test_mode, context)\n            raise\n\n        # Success callback\n        try:\n            if task.on_success_callback:\n                task.on_success_callback(context)\n        except Exception as e3:\n            self.log.error(\"Failed when executing success callback\")\n            self.log.exception(e3)\n\n        # Recording SUCCESS\n        self.end_date = timezone.utcnow()\n        self.set_duration()\n        if not test_mode:\n            session.add(Log(self.state, self))\n            session.merge(self)\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npushes a new entry into the XCom database.", "response": "def xcom_push(\n            self,\n            key,\n            value,\n            execution_date=None):\n        \"\"\"\n        Make an XCom available for tasks to pull.\n\n        :param key: A key for the XCom\n        :type key: str\n        :param value: A value for the XCom. The value is pickled and stored\n            in the database.\n        :type value: any pickleable object\n        :param execution_date: if provided, the XCom will not be visible until\n            this date. This can be used, for example, to send a message to a\n            task on a future date without it being immediately visible.\n        :type execution_date: datetime\n        \"\"\"\n\n        if execution_date and execution_date < self.execution_date:\n            raise ValueError(\n                'execution_date can not be in the past (current '\n                'execution_date is {}; received {})'.format(\n                    self.execution_date, execution_date))\n\n        XCom.set(\n            key=key,\n            value=value,\n            task_id=self.task_id,\n            dag_id=self.dag_id,\n            execution_date=execution_date or self.execution_date)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xcom_pull(\n            self,\n            task_ids=None,\n            dag_id=None,\n            key=XCOM_RETURN_KEY,\n            include_prior_dates=False):\n        \"\"\"\n        Pull XComs that optionally meet certain criteria.\n\n        The default value for `key` limits the search to XComs\n        that were returned by other tasks (as opposed to those that were pushed\n        manually). To remove this filter, pass key=None (or any desired value).\n\n        If a single task_id string is provided, the result is the value of the\n        most recent matching XCom from that task_id. If multiple task_ids are\n        provided, a tuple of matching values is returned. None is returned\n        whenever no matches are found.\n\n        :param key: A key for the XCom. If provided, only XComs with matching\n            keys will be returned. The default key is 'return_value', also\n            available as a constant XCOM_RETURN_KEY. This key is automatically\n            given to XComs returned by tasks (as opposed to being pushed\n            manually). To remove the filter, pass key=None.\n        :type key: str\n        :param task_ids: Only XComs from tasks with matching ids will be\n            pulled. Can pass None to remove the filter.\n        :type task_ids: str or iterable of strings (representing task_ids)\n        :param dag_id: If provided, only pulls XComs from this DAG.\n            If None (default), the DAG of the calling task is used.\n        :type dag_id: str\n        :param include_prior_dates: If False, only XComs from the current\n            execution_date are returned. If True, XComs from previous dates\n            are returned as well.\n        :type include_prior_dates: bool\n        \"\"\"\n\n        if dag_id is None:\n            dag_id = self.dag_id\n\n        pull_fn = functools.partial(\n            XCom.get_one,\n            execution_date=self.execution_date,\n            key=key,\n            dag_id=dag_id,\n            include_prior_dates=include_prior_dates)\n\n        if is_container(task_ids):\n            return tuple(pull_fn(task_id=t) for t in task_ids)\n        else:\n            return pull_fn(task_id=task_ids)", "response": "Pull XComs from a DAG or a single task_id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the log context.", "response": "def init_run_context(self, raw=False):\n        \"\"\"\n        Sets the log context.\n        \"\"\"\n        self.raw = raw\n        self._set_context(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose and upload local log file to remote storage Wasb.", "response": "def close(self):\n        \"\"\"\n        Close and upload local log file to remote storage Wasb.\n        \"\"\"\n        # When application exit, system shuts down all handlers by\n        # calling close method. Here we check if logger is already\n        # closed to prevent uploading the log to remote storage multiple\n        # times when `logging.shutdown` is called.\n        if self.closed:\n            return\n\n        super().close()\n\n        if not self.upload_on_close:\n            return\n\n        local_loc = os.path.join(self.local_base, self.log_relative_path)\n        remote_loc = os.path.join(self.remote_base, self.log_relative_path)\n        if os.path.exists(local_loc):\n            # read log and remove old logs to get just the latest additions\n            with open(local_loc, 'r') as logfile:\n                log = logfile.read()\n            self.wasb_write(log, remote_loc, append=True)\n\n            if self.delete_local_copy:\n                shutil.rmtree(os.path.dirname(local_loc))\n        # Mark closed so we don't double write if close is called twice\n        self.closed = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read(self, ti, try_number, metadata=None):\n        # Explicitly getting log relative path is necessary as the given\n        # task instance might be different than task instance passed in\n        # in set_context method.\n        log_relative_path = self._render_filename(ti, try_number)\n        remote_loc = os.path.join(self.remote_base, log_relative_path)\n\n        if self.wasb_log_exists(remote_loc):\n            # If Wasb remote file exists, we do not fetch logs from task instance\n            # local machine even if there are errors reading remote logs, as\n            # returned remote_log will contain error messages.\n            remote_log = self.wasb_read(remote_loc, return_error=True)\n            log = '*** Reading remote log from {}.\\n{}\\n'.format(\n                remote_loc, remote_log)\n            return log, {'end_of_log': True}\n        else:\n            return super()._read(ti, try_number)", "response": "Read the log from the given task instance and try_number from the remote storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the given log location exists in the wasb container.", "response": "def wasb_log_exists(self, remote_log_location):\n        \"\"\"\n        Check if remote_log_location exists in remote storage\n        :param remote_log_location: log's location in remote storage\n        :return: True if location exists else False\n        \"\"\"\n        try:\n            return self.hook.check_for_blob(self.wasb_container, remote_log_location)\n        except Exception:\n            pass\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wasb_read(self, remote_log_location, return_error=False):\n        try:\n            return self.hook.read_file(self.wasb_container, remote_log_location)\n        except AzureHttpError:\n            msg = 'Could not read logs from {}'.format(remote_log_location)\n            self.log.exception(msg)\n            # return error if needed\n            if return_error:\n                return msg", "response": "Reads the log at the remote_log_location and returns the log found at the remote_log_location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wasb_write(self, log, remote_log_location, append=True):\n        if append and self.wasb_log_exists(remote_log_location):\n            old_log = self.wasb_read(remote_log_location)\n            log = '\\n'.join([old_log, log]) if old_log else log\n\n        try:\n            self.hook.load_string(\n                log,\n                self.wasb_container,\n                remote_log_location,\n            )\n        except AzureHttpError:\n            self.log.exception('Could not write logs to %s',\n                               remote_log_location)", "response": "Writes the log to the remote_log_location. Fails silently if no hook was created."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a connection to Google Compute Engine services object.", "response": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Google Compute Engine.\n\n        :return: Google Compute Engine services object\n        :rtype: dict\n        \"\"\"\n        if not self._conn:\n            http_authorized = self._authorize()\n            self._conn = build('compute', self.api_version,\n                               http=http_authorized, cache_discovery=False)\n        return self._conn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart an existing compute engine instance defined by project_id zone and resource_id.", "response": "def start_instance(self, zone, resource_id, project_id=None):\n        \"\"\"\n        Starts an existing instance defined by project_id, zone and resource_id.\n        Must be called with keyword arguments rather than positional.\n\n        :param zone: Google Cloud Platform zone where the instance exists\n        :type zone: str\n        :param resource_id: Name of the Compute Engine instance resource\n        :type resource_id: str\n        :param project_id: Optional, Google Cloud Platform project ID where the\n            Compute Engine Instance exists. If set to None or missing,\n            the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().start(\n            project=project_id,\n            zone=zone,\n            instance=resource_id\n        ).execute(num_retries=self.num_retries)\n        try:\n            operation_name = response[\"name\"]\n        except KeyError:\n            raise AirflowException(\n                \"Wrong response '{}' returned - it should contain \"\n                \"'name' field\".format(response))\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name,\n                                             zone=zone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_machine_type(self, zone, resource_id, body, project_id=None):\n        response = self._execute_set_machine_type(zone, resource_id, body, project_id)\n        try:\n            operation_name = response[\"name\"]\n        except KeyError:\n            raise AirflowException(\n                \"Wrong response '{}' returned - it should contain \"\n                \"'name' field\".format(response))\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name,\n                                             zone=zone)", "response": "Sets the machine type of an instance defined by project_id zone and resource_id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_instance_template(self, resource_id, project_id=None):\n        response = self.get_conn().instanceTemplates().get(\n            project=project_id,\n            instanceTemplate=resource_id\n        ).execute(num_retries=self.num_retries)\n        return response", "response": "Retrieves the instance template by project_id and resource_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninserts an instance template into the database.", "response": "def insert_instance_template(self, body, request_id=None, project_id=None):\n        \"\"\"\n        Inserts instance template using body specified\n        Must be called with keyword arguments rather than positional.\n\n        :param body: Instance template representation as object according to\n            https://cloud.google.com/compute/docs/reference/rest/v1/instanceTemplates\n        :type body: dict\n        :param request_id: Optional, unique request_id that you might add to achieve\n            full idempotence (for example when client call times out repeating the request\n            with the same request id will not create a new instance template again)\n            It should be in UUID format as defined in RFC 4122\n        :type request_id: str\n        :param project_id: Optional, Google Cloud Platform project ID where the\n            Compute Engine Instance exists. If set to None or missing,\n            the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instanceTemplates().insert(\n            project=project_id,\n            body=body,\n            requestId=request_id\n        ).execute(num_retries=self.num_retries)\n        try:\n            operation_name = response[\"name\"]\n        except KeyError:\n            raise AirflowException(\n                \"Wrong response '{}' returned - it should contain \"\n                \"'name' field\".format(response))\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the instance group manager representation for a resource_id and zone.", "response": "def get_instance_group_manager(self, zone, resource_id, project_id=None):\n        \"\"\"\n        Retrieves Instance Group Manager by project_id, zone and resource_id.\n        Must be called with keyword arguments rather than positional.\n\n        :param zone: Google Cloud Platform zone where the Instance Group Manager exists\n        :type zone: str\n        :param resource_id: Name of the Instance Group Manager\n        :type resource_id: str\n        :param project_id: Optional, Google Cloud Platform project ID where the\n            Compute Engine Instance exists. If set to None or missing,\n            the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: Instance group manager representation as object according to\n            https://cloud.google.com/compute/docs/reference/rest/beta/instanceGroupManagers\n        :rtype: dict\n        \"\"\"\n        response = self.get_conn().instanceGroupManagers().get(\n            project=project_id,\n            zone=zone,\n            instanceGroupManager=resource_id\n        ).execute(num_retries=self.num_retries)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npatch an existing instance group manager.", "response": "def patch_instance_group_manager(self, zone, resource_id,\n                                     body, request_id=None, project_id=None):\n        \"\"\"\n        Patches Instance Group Manager with the specified body.\n        Must be called with keyword arguments rather than positional.\n\n        :param zone: Google Cloud Platform zone where the Instance Group Manager exists\n        :type zone: str\n        :param resource_id: Name of the Instance Group Manager\n        :type resource_id: str\n        :param body: Instance Group Manager representation as json-merge-patch object\n            according to\n            https://cloud.google.com/compute/docs/reference/rest/beta/instanceTemplates/patch\n        :type body: dict\n        :param request_id: Optional, unique request_id that you might add to achieve\n            full idempotence (for example when client call times out repeating the request\n            with the same request id will not create a new instance template again).\n            It should be in UUID format as defined in RFC 4122\n        :type request_id: str\n        :param project_id: Optional, Google Cloud Platform project ID where the\n            Compute Engine Instance exists. If set to None or missing,\n            the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instanceGroupManagers().patch(\n            project=project_id,\n            zone=zone,\n            instanceGroupManager=resource_id,\n            body=body,\n            requestId=request_id\n        ).execute(num_retries=self.num_retries)\n        try:\n            operation_name = response[\"name\"]\n        except KeyError:\n            raise AirflowException(\n                \"Wrong response '{}' returned - it should contain \"\n                \"'name' field\".format(response))\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name,\n                                             zone=zone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wait_for_operation_to_complete(self, project_id, operation_name, zone=None):\n        service = self.get_conn()\n        while True:\n            if zone is None:\n                # noinspection PyTypeChecker\n                operation_response = self._check_global_operation_status(\n                    service, operation_name, project_id)\n            else:\n                # noinspection PyTypeChecker\n                operation_response = self._check_zone_operation_status(\n                    service, operation_name, project_id, zone, self.num_retries)\n            if operation_response.get(\"status\") == GceOperationStatus.DONE:\n                error = operation_response.get(\"error\")\n                if error:\n                    code = operation_response.get(\"httpErrorStatusCode\")\n                    msg = operation_response.get(\"httpErrorMessage\")\n                    # Extracting the errors list as string and trimming square braces\n                    error_msg = str(error.get(\"errors\"))[1:-1]\n                    raise AirflowException(\"{} {}: \".format(code, msg) + error_msg)\n                # No meaningful info to return from the response in case of success\n                return\n            time.sleep(TIME_TO_SLEEP_IN_SECONDS)", "response": "Waits for the named operation to complete - checks status of the async call."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the specified bucket exists.", "response": "def check_for_bucket(self, bucket_name):\n        \"\"\"\n        Check if bucket_name exists.\n\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        \"\"\"\n        try:\n            self.get_conn().head_bucket(Bucket=bucket_name)\n            return True\n        except ClientError as e:\n            self.log.info(e.response[\"Error\"][\"Message\"])\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_bucket(self, bucket_name, region_name=None):\n        s3_conn = self.get_conn()\n        if not region_name:\n            region_name = s3_conn.meta.region_name\n        if region_name == 'us-east-1':\n            self.get_conn().create_bucket(Bucket=bucket_name)\n        else:\n            self.get_conn().create_bucket(Bucket=bucket_name,\n                                          CreateBucketConfiguration={\n                                              'LocationConstraint': region_name\n                                          })", "response": "Creates an Amazon S3 bucket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that a prefix exists in a bucket_name.", "response": "def check_for_prefix(self, bucket_name, prefix, delimiter):\n        \"\"\"\n        Checks that a prefix exists in a bucket\n\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        :param prefix: a key prefix\n        :type prefix: str\n        :param delimiter: the delimiter marks key hierarchy.\n        :type delimiter: str\n        \"\"\"\n        prefix = prefix + delimiter if prefix[-1] != delimiter else prefix\n        prefix_split = re.split(r'(\\w+[{d}])$'.format(d=delimiter), prefix, 1)\n        previous_level = prefix_split[0]\n        plist = self.list_prefixes(bucket_name, previous_level, delimiter)\n        return False if plist is None else prefix in plist"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists the prefixes in a bucket under a key prefix.", "response": "def list_prefixes(self, bucket_name, prefix='', delimiter='',\n                      page_size=None, max_items=None):\n        \"\"\"\n        Lists prefixes in a bucket under prefix\n\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        :param prefix: a key prefix\n        :type prefix: str\n        :param delimiter: the delimiter marks key hierarchy.\n        :type delimiter: str\n        :param page_size: pagination size\n        :type page_size: int\n        :param max_items: maximum items to return\n        :type max_items: int\n        \"\"\"\n        config = {\n            'PageSize': page_size,\n            'MaxItems': max_items,\n        }\n\n        paginator = self.get_conn().get_paginator('list_objects_v2')\n        response = paginator.paginate(Bucket=bucket_name,\n                                      Prefix=prefix,\n                                      Delimiter=delimiter,\n                                      PaginationConfig=config)\n\n        has_results = False\n        prefixes = []\n        for page in response:\n            if 'CommonPrefixes' in page:\n                has_results = True\n                for p in page['CommonPrefixes']:\n                    prefixes.append(p['Prefix'])\n\n        if has_results:\n            return prefixes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist the keys in a bucket under prefix and not containing delimiter", "response": "def list_keys(self, bucket_name, prefix='', delimiter='',\n                  page_size=None, max_items=None):\n        \"\"\"\n        Lists keys in a bucket under prefix and not containing delimiter\n\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        :param prefix: a key prefix\n        :type prefix: str\n        :param delimiter: the delimiter marks key hierarchy.\n        :type delimiter: str\n        :param page_size: pagination size\n        :type page_size: int\n        :param max_items: maximum items to return\n        :type max_items: int\n        \"\"\"\n        config = {\n            'PageSize': page_size,\n            'MaxItems': max_items,\n        }\n\n        paginator = self.get_conn().get_paginator('list_objects_v2')\n        response = paginator.paginate(Bucket=bucket_name,\n                                      Prefix=prefix,\n                                      Delimiter=delimiter,\n                                      PaginationConfig=config)\n\n        has_results = False\n        keys = []\n        for page in response:\n            if 'Contents' in page:\n                has_results = True\n                for k in page['Contents']:\n                    keys.append(k['Key'])\n\n        if has_results:\n            return keys"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_for_key(self, key, bucket_name=None):\n        if not bucket_name:\n            (bucket_name, key) = self.parse_s3_url(key)\n\n        try:\n            self.get_conn().head_object(Bucket=bucket_name, Key=key)\n            return True\n        except ClientError as e:\n            self.log.info(e.response[\"Error\"][\"Message\"])\n            return False", "response": "Checks if a key exists in a bucket"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a boto3. s3. Object object for the given key.", "response": "def get_key(self, key, bucket_name=None):\n        \"\"\"\n        Returns a boto3.s3.Object\n\n        :param key: the path to the key\n        :type key: str\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        \"\"\"\n        if not bucket_name:\n            (bucket_name, key) = self.parse_s3_url(key)\n\n        obj = self.get_resource_type('s3').Object(bucket_name, key)\n        obj.load()\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_key(self, key, bucket_name=None):\n\n        obj = self.get_key(key, bucket_name)\n        return obj.get()['Body'].read().decode('utf-8')", "response": "Reads a key from S3 and returns the contents as a unicode string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a key with S3 Select.", "response": "def select_key(self, key, bucket_name=None,\n                   expression='SELECT * FROM S3Object',\n                   expression_type='SQL',\n                   input_serialization=None,\n                   output_serialization=None):\n        \"\"\"\n        Reads a key with S3 Select.\n\n        :param key: S3 key that will point to the file\n        :type key: str\n        :param bucket_name: Name of the bucket in which the file is stored\n        :type bucket_name: str\n        :param expression: S3 Select expression\n        :type expression: str\n        :param expression_type: S3 Select expression type\n        :type expression_type: str\n        :param input_serialization: S3 Select input data serialization format\n        :type input_serialization: dict\n        :param output_serialization: S3 Select output data serialization format\n        :type output_serialization: dict\n        :return: retrieved subset of original data by S3 Select\n        :rtype: str\n\n        .. seealso::\n            For more details about S3 Select parameters:\n            http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.select_object_content\n        \"\"\"\n        if input_serialization is None:\n            input_serialization = {'CSV': {}}\n        if output_serialization is None:\n            output_serialization = {'CSV': {}}\n        if not bucket_name:\n            (bucket_name, key) = self.parse_s3_url(key)\n\n        response = self.get_conn().select_object_content(\n            Bucket=bucket_name,\n            Key=key,\n            Expression=expression,\n            ExpressionType=expression_type,\n            InputSerialization=input_serialization,\n            OutputSerialization=output_serialization)\n\n        return ''.join(event['Records']['Payload'].decode('utf-8')\n                       for event in response['Payload']\n                       if 'Records' in event)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that a key matching a wildcard expression exists in a key hierarchy.", "response": "def check_for_wildcard_key(self,\n                               wildcard_key, bucket_name=None, delimiter=''):\n        \"\"\"\n        Checks that a key matching a wildcard expression exists in a bucket\n\n        :param wildcard_key: the path to the key\n        :type wildcard_key: str\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        :param delimiter: the delimiter marks key hierarchy\n        :type delimiter: str\n        \"\"\"\n        return self.get_wildcard_key(wildcard_key=wildcard_key,\n                                     bucket_name=bucket_name,\n                                     delimiter=delimiter) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_wildcard_key(self, wildcard_key, bucket_name=None, delimiter=''):\n        if not bucket_name:\n            (bucket_name, wildcard_key) = self.parse_s3_url(wildcard_key)\n\n        prefix = re.split(r'[*]', wildcard_key, 1)[0]\n        klist = self.list_keys(bucket_name, prefix=prefix, delimiter=delimiter)\n        if klist:\n            key_matches = [k for k in klist if fnmatch.fnmatch(k, wildcard_key)]\n            if key_matches:\n                return self.get_key(key_matches[0], bucket_name)", "response": "Returns a boto3. s3. Object object matching the wildcard expression"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_file(self,\n                  filename,\n                  key,\n                  bucket_name=None,\n                  replace=False,\n                  encrypt=False):\n        \"\"\"\n        Loads a local file to S3\n\n        :param filename: name of the file to load.\n        :type filename: str\n        :param key: S3 key that will point to the file\n        :type key: str\n        :param bucket_name: Name of the bucket in which to store the file\n        :type bucket_name: str\n        :param replace: A flag to decide whether or not to overwrite the key\n            if it already exists. If replace is False and the key exists, an\n            error will be raised.\n        :type replace: bool\n        :param encrypt: If True, the file will be encrypted on the server-side\n            by S3 and will be stored in an encrypted form while at rest in S3.\n        :type encrypt: bool\n        \"\"\"\n        if not bucket_name:\n            (bucket_name, key) = self.parse_s3_url(key)\n\n        if not replace and self.check_for_key(key, bucket_name):\n            raise ValueError(\"The key {key} already exists.\".format(key=key))\n\n        extra_args = {}\n        if encrypt:\n            extra_args['ServerSideEncryption'] = \"AES256\"\n\n        client = self.get_conn()\n        client.upload_file(filename, bucket_name, key, ExtraArgs=extra_args)", "response": "Loads a local file to S3."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_string(self,\n                    string_data,\n                    key,\n                    bucket_name=None,\n                    replace=False,\n                    encrypt=False,\n                    encoding='utf-8'):\n        \"\"\"\n        Loads a string to S3\n\n        This is provided as a convenience to drop a string in S3. It uses the\n        boto infrastructure to ship a file to s3.\n\n        :param string_data: str to set as content for the key.\n        :type string_data: str\n        :param key: S3 key that will point to the file\n        :type key: str\n        :param bucket_name: Name of the bucket in which to store the file\n        :type bucket_name: str\n        :param replace: A flag to decide whether or not to overwrite the key\n            if it already exists\n        :type replace: bool\n        :param encrypt: If True, the file will be encrypted on the server-side\n            by S3 and will be stored in an encrypted form while at rest in S3.\n        :type encrypt: bool\n        \"\"\"\n        self.load_bytes(string_data.encode(encoding),\n                        key=key,\n                        bucket_name=bucket_name,\n                        replace=replace,\n                        encrypt=encrypt)", "response": "This method loads a string into the S3 object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_bytes(self,\n                   bytes_data,\n                   key,\n                   bucket_name=None,\n                   replace=False,\n                   encrypt=False):\n        \"\"\"\n        Loads bytes to S3\n\n        This is provided as a convenience to drop a string in S3. It uses the\n        boto infrastructure to ship a file to s3.\n\n        :param bytes_data: bytes to set as content for the key.\n        :type bytes_data: bytes\n        :param key: S3 key that will point to the file\n        :type key: str\n        :param bucket_name: Name of the bucket in which to store the file\n        :type bucket_name: str\n        :param replace: A flag to decide whether or not to overwrite the key\n            if it already exists\n        :type replace: bool\n        :param encrypt: If True, the file will be encrypted on the server-side\n            by S3 and will be stored in an encrypted form while at rest in S3.\n        :type encrypt: bool\n        \"\"\"\n        if not bucket_name:\n            (bucket_name, key) = self.parse_s3_url(key)\n\n        if not replace and self.check_for_key(key, bucket_name):\n            raise ValueError(\"The key {key} already exists.\".format(key=key))\n\n        extra_args = {}\n        if encrypt:\n            extra_args['ServerSideEncryption'] = \"AES256\"\n\n        filelike_buffer = BytesIO(bytes_data)\n\n        client = self.get_conn()\n        client.upload_fileobj(filelike_buffer, bucket_name, key, ExtraArgs=extra_args)", "response": "This method loads the bytes into the S3 object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_file_obj(self,\n                      file_obj,\n                      key,\n                      bucket_name=None,\n                      replace=False,\n                      encrypt=False):\n        \"\"\"\n        Loads a file object to S3\n\n        :param file_obj: The file-like object to set as the content for the S3 key.\n        :type file_obj: file-like object\n        :param key: S3 key that will point to the file\n        :type key: str\n        :param bucket_name: Name of the bucket in which to store the file\n        :type bucket_name: str\n        :param replace: A flag that indicates whether to overwrite the key\n            if it already exists.\n        :type replace: bool\n        :param encrypt: If True, S3 encrypts the file on the server,\n            and the file is stored in encrypted form at rest in S3.\n        :type encrypt: bool\n        \"\"\"\n        if not bucket_name:\n            (bucket_name, key) = self.parse_s3_url(key)\n\n        if not replace and self.check_for_key(key, bucket_name):\n            raise ValueError(\"The key {key} already exists.\".format(key=key))\n\n        extra_args = {}\n        if encrypt:\n            extra_args['ServerSideEncryption'] = \"AES256\"\n\n        client = self.get_conn()\n        client.upload_fileobj(file_obj, bucket_name, key, ExtraArgs=extra_args)", "response": "Loads a file - like object to the S3 bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_object(self,\n                    source_bucket_key,\n                    dest_bucket_key,\n                    source_bucket_name=None,\n                    dest_bucket_name=None,\n                    source_version_id=None):\n        \"\"\"\n        Creates a copy of an object that is already stored in S3.\n\n        Note: the S3 connection used here needs to have access to both\n        source and destination bucket/key.\n\n        :param source_bucket_key: The key of the source object.\n\n            It can be either full s3:// style url or relative path from root level.\n\n            When it's specified as a full s3:// url, please omit source_bucket_name.\n        :type source_bucket_key: str\n        :param dest_bucket_key: The key of the object to copy to.\n\n            The convention to specify `dest_bucket_key` is the same\n            as `source_bucket_key`.\n        :type dest_bucket_key: str\n        :param source_bucket_name: Name of the S3 bucket where the source object is in.\n\n            It should be omitted when `source_bucket_key` is provided as a full s3:// url.\n        :type source_bucket_name: str\n        :param dest_bucket_name: Name of the S3 bucket to where the object is copied.\n\n            It should be omitted when `dest_bucket_key` is provided as a full s3:// url.\n        :type dest_bucket_name: str\n        :param source_version_id: Version ID of the source object (OPTIONAL)\n        :type source_version_id: str\n        \"\"\"\n\n        if dest_bucket_name is None:\n            dest_bucket_name, dest_bucket_key = self.parse_s3_url(dest_bucket_key)\n        else:\n            parsed_url = urlparse(dest_bucket_key)\n            if parsed_url.scheme != '' or parsed_url.netloc != '':\n                raise AirflowException('If dest_bucket_name is provided, ' +\n                                       'dest_bucket_key should be relative path ' +\n                                       'from root level, rather than a full s3:// url')\n\n        if source_bucket_name is None:\n            source_bucket_name, source_bucket_key = self.parse_s3_url(source_bucket_key)\n        else:\n            parsed_url = urlparse(source_bucket_key)\n            if parsed_url.scheme != '' or parsed_url.netloc != '':\n                raise AirflowException('If source_bucket_name is provided, ' +\n                                       'source_bucket_key should be relative path ' +\n                                       'from root level, rather than a full s3:// url')\n\n        CopySource = {'Bucket': source_bucket_name,\n                      'Key': source_bucket_key,\n                      'VersionId': source_version_id}\n        response = self.get_conn().copy_object(Bucket=dest_bucket_name,\n                                               Key=dest_bucket_key,\n                                               CopySource=CopySource)\n        return response", "response": "Copy an object from one bucket to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_objects(self,\n                       bucket,\n                       keys):\n        \"\"\"\n        :param bucket: Name of the bucket in which you are going to delete object(s)\n        :type bucket: str\n        :param keys: The key(s) to delete from S3 bucket.\n\n            When ``keys`` is a string, it's supposed to be the key name of\n            the single object to delete.\n\n            When ``keys`` is a list, it's supposed to be the list of the\n            keys to delete.\n        :type keys: str or list\n        \"\"\"\n        if isinstance(keys, list):\n            keys = keys\n        else:\n            keys = [keys]\n\n        delete_dict = {\"Objects\": [{\"Key\": k} for k in keys]}\n        response = self.get_conn().delete_objects(Bucket=bucket,\n                                                  Delete=delete_dict)\n        return response", "response": "Delete objects from S3 bucket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery cassandra and returns a cursor to the results.", "response": "def _query_cassandra(self):\n        \"\"\"\n        Queries cassandra and returns a cursor to the results.\n        \"\"\"\n        self.hook = CassandraHook(cassandra_conn_id=self.cassandra_conn_id)\n        session = self.hook.get_conn()\n        cursor = session.execute(self.cql)\n        return cursor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a cursor and writes results to a local file.", "response": "def _write_local_data_files(self, cursor):\n        \"\"\"\n        Takes a cursor, and writes results to a local file.\n\n        :return: A dictionary where keys are filenames to be used as object\n            names in GCS, and values are file handles to local files that\n            contain the data for the GCS objects.\n        \"\"\"\n        file_no = 0\n        tmp_file_handle = NamedTemporaryFile(delete=True)\n        tmp_file_handles = {self.filename.format(file_no): tmp_file_handle}\n        for row in cursor:\n            row_dict = self.generate_data_dict(row._fields, row)\n            s = json.dumps(row_dict).encode('utf-8')\n            tmp_file_handle.write(s)\n\n            # Append newline to make dumps BigQuery compatible.\n            tmp_file_handle.write(b'\\n')\n\n            if tmp_file_handle.tell() >= self.approx_max_file_size_bytes:\n                file_no += 1\n                tmp_file_handle = NamedTemporaryFile(delete=True)\n                tmp_file_handles[self.filename.format(file_no)] = tmp_file_handle\n\n        return tmp_file_handles"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_local_schema_file(self, cursor):\n        schema = []\n        tmp_schema_file_handle = NamedTemporaryFile(delete=True)\n\n        for name, type in zip(cursor.column_names, cursor.column_types):\n            schema.append(self.generate_schema_dict(name, type))\n        json_serialized_schema = json.dumps(schema).encode('utf-8')\n\n        tmp_schema_file_handle.write(json_serialized_schema)\n        return {self.schema_filename: tmp_schema_file_handle}", "response": "Takes a cursor and writes the BigQuery schema for the results to the local file system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_user_type(cls, name, value):\n        names = value._fields\n        values = [cls.convert_value(name, getattr(value, name)) for name in names]\n        return cls.generate_data_dict(names, values)", "response": "Converts a user type to RECORD that contains n fields where n is the\n        number of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_tuple_type(cls, name, value):\n        names = ['field_' + str(i) for i in range(len(value))]\n        values = [cls.convert_value(name, value) for name, value in zip(names, value)]\n        return cls.generate_data_dict(names, values)", "response": "Converts a tuple to RECORD that contains n fields each will be converted\n        to its corresponding data type in bq."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a map type to a repeated RECORD that contains two fields key and value.", "response": "def convert_map_type(cls, name, value):\n        \"\"\"\n        Converts a map to a repeated RECORD that contains two fields: 'key' and 'value',\n        each will be converted to its corresponding data type in BQ.\n        \"\"\"\n        converted_map = []\n        for k, v in zip(value.keys(), value.values()):\n            converted_map.append({\n                'key': cls.convert_value('key', k),\n                'value': cls.convert_value('value', v)\n            })\n        return converted_map"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_email(to, subject, html_content, files=None, dryrun=False, cc=None,\n               bcc=None, mime_subtype='mixed', sandbox_mode=False, **kwargs):\n    \"\"\"\n    Send an email with html content using sendgrid.\n\n    To use this plugin:\n    0. include sendgrid subpackage as part of your Airflow installation, e.g.,\n    pip install 'apache-airflow[sendgrid]'\n    1. update [email] backend in airflow.cfg, i.e.,\n    [email]\n    email_backend = airflow.contrib.utils.sendgrid.send_email\n    2. configure Sendgrid specific environment variables at all Airflow instances:\n    SENDGRID_MAIL_FROM={your-mail-from}\n    SENDGRID_API_KEY={your-sendgrid-api-key}.\n    \"\"\"\n    if files is None:\n        files = []\n\n    mail = Mail()\n    from_email = kwargs.get('from_email') or os.environ.get('SENDGRID_MAIL_FROM')\n    from_name = kwargs.get('from_name') or os.environ.get('SENDGRID_MAIL_SENDER')\n    mail.from_email = Email(from_email, from_name)\n    mail.subject = subject\n    mail.mail_settings = MailSettings()\n\n    if sandbox_mode:\n        mail.mail_settings.sandbox_mode = SandBoxMode(enable=True)\n\n    # Add the recipient list of to emails.\n    personalization = Personalization()\n    to = get_email_address_list(to)\n    for to_address in to:\n        personalization.add_to(Email(to_address))\n    if cc:\n        cc = get_email_address_list(cc)\n        for cc_address in cc:\n            personalization.add_cc(Email(cc_address))\n    if bcc:\n        bcc = get_email_address_list(bcc)\n        for bcc_address in bcc:\n            personalization.add_bcc(Email(bcc_address))\n\n    # Add custom_args to personalization if present\n    pers_custom_args = kwargs.get('personalization_custom_args', None)\n    if isinstance(pers_custom_args, dict):\n        for key in pers_custom_args.keys():\n            personalization.add_custom_arg(CustomArg(key, pers_custom_args[key]))\n\n    mail.add_personalization(personalization)\n    mail.add_content(Content('text/html', html_content))\n\n    categories = kwargs.get('categories', [])\n    for cat in categories:\n        mail.add_category(Category(cat))\n\n    # Add email attachment.\n    for fname in files:\n        basename = os.path.basename(fname)\n\n        attachment = Attachment()\n        attachment.type = mimetypes.guess_type(basename)[0]\n        attachment.filename = basename\n        attachment.disposition = \"attachment\"\n        attachment.content_id = '<{0}>'.format(basename)\n\n        with open(fname, \"rb\") as f:\n            attachment.content = base64.b64encode(f.read()).decode('utf-8')\n\n        mail.add_attachment(attachment)\n    _post_sendgrid_mail(mail.get())", "response": "Send an email using Sendgrid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a connection to the Cloud Speech API.", "response": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Speech.\n\n        :return: Google Cloud Speech client object.\n        :rtype: google.cloud.speech_v1.SpeechClient\n        \"\"\"\n        if not self._client:\n            self._client = SpeechClient(credentials=self._get_credentials())\n        return self._client"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recognize_speech(self, config, audio, retry=None, timeout=None):\n        client = self.get_conn()\n        response = client.recognize(config=config, audio=audio, retry=retry, timeout=timeout)\n        self.log.info(\"Recognised speech: %s\" % response)\n        return response", "response": "Recognizes audio data and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, context):\n        self._hook = SparkSqlHook(sql=self._sql,\n                                  conf=self._conf,\n                                  conn_id=self._conn_id,\n                                  total_executor_cores=self._total_executor_cores,\n                                  executor_cores=self._executor_cores,\n                                  executor_memory=self._executor_memory,\n                                  keytab=self._keytab,\n                                  principal=self._principal,\n                                  name=self._name,\n                                  num_executors=self._num_executors,\n                                  master=self._master,\n                                  yarn_queue=self._yarn_queue\n                                  )\n        self._hook.run_query()", "response": "Execute the sql query returning the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the airflow task context to the given task instance.", "response": "def set_context(self, ti):\n        \"\"\"\n        Provide task_instance context to airflow task handler.\n        :param ti: task instance object\n        \"\"\"\n        local_loc = self._init_file(ti)\n        self.handler = logging.FileHandler(local_loc)\n        self.handler.setFormatter(self.formatter)\n        self.handler.setLevel(self.level)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read(self, ti, try_number, metadata=None):\n        # Task instance here might be different from task instance when\n        # initializing the handler. Thus explicitly getting log location\n        # is needed to get correct log path.\n        log_relative_path = self._render_filename(ti, try_number)\n        location = os.path.join(self.local_base, log_relative_path)\n\n        log = \"\"\n\n        if os.path.exists(location):\n            try:\n                with open(location) as f:\n                    log += \"*** Reading local file: {}\\n\".format(location)\n                    log += \"\".join(f.readlines())\n            except Exception as e:\n                log = \"*** Failed to load local log file: {}\\n\".format(location)\n                log += \"*** {}\\n\".format(str(e))\n        else:\n            url = os.path.join(\n                \"http://{ti.hostname}:{worker_log_server_port}/log\", log_relative_path\n            ).format(\n                ti=ti,\n                worker_log_server_port=conf.get('celery', 'WORKER_LOG_SERVER_PORT')\n            )\n            log += \"*** Log file does not exist: {}\\n\".format(location)\n            log += \"*** Fetching from: {}\\n\".format(url)\n            try:\n                timeout = None  # No timeout\n                try:\n                    timeout = conf.getint('webserver', 'log_fetch_timeout_sec')\n                except (AirflowConfigException, ValueError):\n                    pass\n\n                response = requests.get(url, timeout=timeout)\n\n                # Check if the resource was properly fetched\n                response.raise_for_status()\n\n                log += '\\n' + response.text\n            except Exception as e:\n                log += \"*** Failed to fetch log file from worker. {}\\n\".format(str(e))\n\n        return log, {'end_of_log': True}", "response": "This method returns the log message from the log file at the specified try_number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread logs of given task instance from local machine.", "response": "def read(self, task_instance, try_number=None, metadata=None):\n        \"\"\"\n        Read logs of given task instance from local machine.\n        :param task_instance: task instance object\n        :param try_number: task instance try_number to read logs from. If None\n                           it returns all logs separated by try_number\n        :param metadata: log metadata,\n                         can be used for steaming log reading and auto-tailing.\n        :return: a list of logs\n        \"\"\"\n        # Task instance increments its try number when it starts to run.\n        # So the log for a particular task try will only show up when\n        # try number gets incremented in DB, i.e logs produced the time\n        # after cli run and before try_number + 1 in DB will not be displayed.\n\n        if try_number is None:\n            next_try = task_instance.next_try_number\n            try_numbers = list(range(1, next_try))\n        elif try_number < 1:\n            logs = [\n                'Error fetching the logs. Try number {} is invalid.'.format(try_number),\n            ]\n            return logs\n        else:\n            try_numbers = [try_number]\n\n        logs = [''] * len(try_numbers)\n        metadatas = [{}] * len(try_numbers)\n        for i, try_number in enumerate(try_numbers):\n            log, metadata = self._read(task_instance, try_number, metadata)\n            logs[i] += log\n            metadatas[i] = metadata\n\n        return logs, metadatas"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the log file and give it correct permissions.", "response": "def _init_file(self, ti):\n        \"\"\"\n        Create log directory and give it correct permissions.\n        :param ti: task instance object\n        :return: relative log path of the given task instance\n        \"\"\"\n        # To handle log writing when tasks are impersonated, the log files need to\n        # be writable by the user that runs the Airflow command and the user\n        # that is impersonated. This is mainly to handle corner cases with the\n        # SubDagOperator. When the SubDagOperator is run, all of the operators\n        # run under the impersonated user and create appropriate log files\n        # as the impersonated user. However, if the user manually runs tasks\n        # of the SubDagOperator through the UI, then the log files are created\n        # by the user that runs the Airflow command. For example, the Airflow\n        # run command may be run by the `airflow_sudoable` user, but the Airflow\n        # tasks may be run by the `airflow` user. If the log files are not\n        # writable by both users, then it's possible that re-running a task\n        # via the UI (or vice versa) results in a permission error as the task\n        # tries to write to a log file created by the other user.\n        relative_path = self._render_filename(ti, ti.try_number)\n        full_path = os.path.join(self.local_base, relative_path)\n        directory = os.path.dirname(full_path)\n        # Create the log file and give it group writable permissions\n        # TODO(aoen): Make log dirs and logs globally readable for now since the SubDag\n        # operator is not compatible with impersonation (e.g. if a Celery executor is used\n        # for a SubDag operator and the SubDag operator has a different owner than the\n        # parent DAG)\n        if not os.path.exists(directory):\n            # Create the directory as globally writable using custom mkdirs\n            # as os.makedirs doesn't set mode properly.\n            mkdirs(directory, 0o777)\n\n        if not os.path.exists(full_path):\n            open(full_path, \"a\").close()\n            # TODO: Investigate using 444 instead of 666.\n            os.chmod(full_path, 0o666)\n\n        return full_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading AirflowPlugin subclasses from the entry_points .", "response": "def load_entrypoint_plugins(entry_points, airflow_plugins):\n    \"\"\"\n    Load AirflowPlugin subclasses from the entrypoints\n    provided. The entry_point group should be 'airflow.plugins'.\n\n    :param entry_points: A collection of entrypoints to search for plugins\n    :type entry_points: Generator[setuptools.EntryPoint, None, None]\n    :param airflow_plugins: A collection of existing airflow plugins to\n        ensure we don't load duplicates\n    :type airflow_plugins: list[type[airflow.plugins_manager.AirflowPlugin]]\n    :rtype: list[airflow.plugins_manager.AirflowPlugin]\n    \"\"\"\n    for entry_point in entry_points:\n        log.debug('Importing entry_point plugin %s', entry_point.name)\n        plugin_obj = entry_point.load()\n        if is_valid_plugin(plugin_obj, airflow_plugins):\n            if callable(getattr(plugin_obj, 'on_load', None)):\n                plugin_obj.on_load()\n                airflow_plugins.append(plugin_obj)\n    return airflow_plugins"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether a potential object is a subclass of AirflowPlugin and if it is not in existing_plugins", "response": "def is_valid_plugin(plugin_obj, existing_plugins):\n    \"\"\"\n    Check whether a potential object is a subclass of\n    the AirflowPlugin class.\n\n    :param plugin_obj: potential subclass of AirflowPlugin\n    :param existing_plugins: Existing list of AirflowPlugin subclasses\n    :return: Whether or not the obj is a valid subclass of\n        AirflowPlugin\n    \"\"\"\n    if (\n        inspect.isclass(plugin_obj) and\n        issubclass(plugin_obj, AirflowPlugin) and\n        (plugin_obj is not AirflowPlugin)\n    ):\n        plugin_obj.validate()\n        return plugin_obj not in existing_plugins\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the tasks instances to skipped from the same dag run.", "response": "def skip(self, dag_run, execution_date, tasks, session=None):\n        \"\"\"\n        Sets tasks instances to skipped from the same dag run.\n\n        :param dag_run: the DagRun for which to set the tasks to skipped\n        :param execution_date: execution_date\n        :param tasks: tasks to skip (not task_ids)\n        :param session: db session to use\n        \"\"\"\n        if not tasks:\n            return\n\n        task_ids = [d.task_id for d in tasks]\n        now = timezone.utcnow()\n\n        if dag_run:\n            session.query(TaskInstance).filter(\n                TaskInstance.dag_id == dag_run.dag_id,\n                TaskInstance.execution_date == dag_run.execution_date,\n                TaskInstance.task_id.in_(task_ids)\n            ).update({TaskInstance.state: State.SKIPPED,\n                      TaskInstance.start_date: now,\n                      TaskInstance.end_date: now},\n                     synchronize_session=False)\n            session.commit()\n        else:\n            assert execution_date is not None, \"Execution date is None and no dag run\"\n\n            self.log.warning(\"No DAG RUN present this should not happen\")\n            # this is defensive against dag runs that are not complete\n            for task in tasks:\n                ti = TaskInstance(task, execution_date=execution_date)\n                ti.state = State.SKIPPED\n                ti.start_date = now\n                ti.end_date = now\n                session.merge(ti)\n\n            session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a AzureDLFileSystem object.", "response": "def get_conn(self):\n        \"\"\"Return a AzureDLFileSystem object.\"\"\"\n        conn = self.get_connection(self.conn_id)\n        service_options = conn.extra_dejson\n        self.account_name = service_options.get('account_name')\n\n        adlCreds = lib.auth(tenant_id=service_options.get('tenant'),\n                            client_secret=conn.password,\n                            client_id=conn.login)\n        adlsFileSystemClient = core.AzureDLFileSystem(adlCreds,\n                                                      store_name=self.account_name)\n        adlsFileSystemClient.connect()\n        return adlsFileSystemClient"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a file exists on Azure Data Lake.", "response": "def check_for_file(self, file_path):\n        \"\"\"\n        Check if a file exists on Azure Data Lake.\n\n        :param file_path: Path and name of the file.\n        :type file_path: str\n        :return: True if the file exists, False otherwise.\n        :rtype: bool\n        \"\"\"\n        try:\n            files = self.connection.glob(file_path, details=False, invalidate_cache=True)\n            return len(files) == 1\n        except FileNotFoundError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload a file to the Azure Data Lake API.", "response": "def upload_file(self, local_path, remote_path, nthreads=64, overwrite=True,\n                    buffersize=4194304, blocksize=4194304):\n        \"\"\"\n        Upload a file to Azure Data Lake.\n\n        :param local_path: local path. Can be single file, directory (in which case,\n            upload recursively) or glob pattern. Recursive glob patterns using `**`\n            are not supported.\n        :type local_path: str\n        :param remote_path: Remote path to upload to; if multiple files, this is the\n            directory root to write within.\n        :type remote_path: str\n        :param nthreads: Number of threads to use. If None, uses the number of cores.\n        :type nthreads: int\n        :param overwrite: Whether to forcibly overwrite existing files/directories.\n            If False and remote path is a directory, will quit regardless if any files\n            would be overwritten or not. If True, only matching filenames are actually\n            overwritten.\n        :type overwrite: bool\n        :param buffersize: int [2**22]\n            Number of bytes for internal buffer. This block cannot be bigger than\n            a chunk and cannot be smaller than a block.\n        :type buffersize: int\n        :param blocksize: int [2**22]\n            Number of bytes for a block. Within each chunk, we write a smaller\n            block for each API call. This block cannot be bigger than a chunk.\n        :type blocksize: int\n        \"\"\"\n        multithread.ADLUploader(self.connection,\n                                lpath=local_path,\n                                rpath=remote_path,\n                                nthreads=nthreads,\n                                overwrite=overwrite,\n                                buffersize=buffersize,\n                                blocksize=blocksize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading a file from Azure Blob Storage.", "response": "def download_file(self, local_path, remote_path, nthreads=64, overwrite=True,\n                      buffersize=4194304, blocksize=4194304):\n        \"\"\"\n        Download a file from Azure Blob Storage.\n\n        :param local_path: local path. If downloading a single file, will write to this\n            specific file, unless it is an existing directory, in which case a file is\n            created within it. If downloading multiple files, this is the root\n            directory to write within. Will create directories as required.\n        :type local_path: str\n        :param remote_path: remote path/globstring to use to find remote files.\n            Recursive glob patterns using `**` are not supported.\n        :type remote_path: str\n        :param nthreads: Number of threads to use. If None, uses the number of cores.\n        :type nthreads: int\n        :param overwrite: Whether to forcibly overwrite existing files/directories.\n            If False and remote path is a directory, will quit regardless if any files\n            would be overwritten or not. If True, only matching filenames are actually\n            overwritten.\n        :type overwrite: bool\n        :param buffersize: int [2**22]\n            Number of bytes for internal buffer. This block cannot be bigger than\n            a chunk and cannot be smaller than a block.\n        :type buffersize: int\n        :param blocksize: int [2**22]\n            Number of bytes for a block. Within each chunk, we write a smaller\n            block for each API call. This block cannot be bigger than a chunk.\n        :type blocksize: int\n        \"\"\"\n        multithread.ADLDownloader(self.connection,\n                                  lpath=local_path,\n                                  rpath=remote_path,\n                                  nthreads=nthreads,\n                                  overwrite=overwrite,\n                                  buffersize=buffersize,\n                                  blocksize=blocksize)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists files in Azure Data Lake Storage", "response": "def list(self, path):\n        \"\"\"\n        List files in Azure Data Lake Storage\n\n        :param path: full path/globstring to use to list files in ADLS\n        :type path: str\n        \"\"\"\n        if \"*\" in path:\n            return self.connection.glob(path)\n        else:\n            return self.connection.walk(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, context):\n        self.hook = self.get_hook()\n        self.hook.get_conn()\n\n        self.query_execution_context['Database'] = self.database\n        self.result_configuration['OutputLocation'] = self.output_location\n        self.query_execution_id = self.hook.run_query(self.query, self.query_execution_context,\n                                                      self.result_configuration, self.client_request_token)\n        query_status = self.hook.poll_query_status(self.query_execution_id, self.max_tries)\n\n        if query_status in AWSAthenaHook.FAILURE_STATES:\n            raise Exception(\n                'Final state of Athena job is {}, query_execution_id is {}.'\n                .format(query_status, self.query_execution_id))\n        elif not query_status or query_status in AWSAthenaHook.INTERMEDIATE_STATES:\n            raise Exception(\n                'Final state of Athena job is {}. '\n                'Max tries of poll status exceeded, query_execution_id is {}.'\n                .format(query_status, self.query_execution_id))", "response": "Execute the Athena query and return the result of the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_kill(self):\n        if self.query_execution_id:\n            self.log.info('\u26b0\ufe0f\u26b0\ufe0f\u26b0\ufe0f Received a kill Signal. Time to Die')\n            self.log.info(\n                'Stopping Query with executionId - %s', self.query_execution_id\n            )\n            response = self.hook.stop_query(self.query_execution_id)\n            http_status_code = None\n            try:\n                http_status_code = response['ResponseMetadata']['HTTPStatusCode']\n            except Exception as ex:\n                self.log.error('Exception while cancelling query', ex)\n            finally:\n                if http_status_code is None or http_status_code != 200:\n                    self.log.error('Unable to request query cancel on athena. Exiting')\n                else:\n                    self.log.info(\n                        'Polling Athena for query with id %s to reach final state', self.query_execution_id\n                    )\n                    self.hook.poll_query_status(self.query_execution_id)", "response": "Stop the submitted athena query and poll the status of the query."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uncompress_file(input_file_name, file_extension, dest_dir):\n    if file_extension.lower() not in ('.gz', '.bz2'):\n        raise NotImplementedError(\"Received {} format. Only gz and bz2 \"\n                                  \"files can currently be uncompressed.\"\n                                  .format(file_extension))\n    if file_extension.lower() == '.gz':\n        fmodule = gzip.GzipFile\n    elif file_extension.lower() == '.bz2':\n        fmodule = bz2.BZ2File\n    with fmodule(input_file_name, mode='rb') as f_compressed,\\\n        NamedTemporaryFile(dir=dest_dir,\n                           mode='wb',\n                           delete=False) as f_uncompressed:\n        shutil.copyfileobj(f_compressed, f_uncompressed)\n    return f_uncompressed.name", "response": "Uncompress a file and return its name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _query_mssql(self):\n        mssql = MsSqlHook(mssql_conn_id=self.mssql_conn_id)\n        conn = mssql.get_conn()\n        cursor = conn.cursor()\n        cursor.execute(self.sql)\n        return cursor", "response": "Queries MSSQL and returns a cursor of results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _write_local_data_files(self, cursor):\n        schema = list(map(lambda schema_tuple: schema_tuple[0].replace(' ', '_'), cursor.description))\n        file_no = 0\n        tmp_file_handle = NamedTemporaryFile(delete=True)\n        tmp_file_handles = {self.filename.format(file_no): tmp_file_handle}\n\n        for row in cursor:\n            # Convert if needed\n            row = map(self.convert_types, row)\n            row_dict = dict(zip(schema, row))\n\n            s = json.dumps(row_dict, sort_keys=True)\n            s = s.encode('utf-8')\n            tmp_file_handle.write(s)\n\n            # Append newline to make dumps BQ compatible\n            tmp_file_handle.write(b'\\n')\n\n            # Stop if the file exceeds the file size limit\n            if tmp_file_handle.tell() >= self.approx_max_file_size_bytes:\n                file_no += 1\n                tmp_file_handle = NamedTemporaryFile(delete=True)\n                tmp_file_handles[self.filename.format(file_no)] = tmp_file_handle\n\n        return tmp_file_handles", "response": "Takes a cursor and writes results to a local file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _upload_to_gcs(self, files_to_upload):\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n        for object_name, tmp_file_handle in files_to_upload.items():\n            hook.upload(self.bucket, object_name, tmp_file_handle.name, 'application/json',\n                        (self.gzip if object_name != self.schema_filename else False))", "response": "Upload all of the files to Google Cloud Storage."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a value from MSSQL and converts it to a value that s safe for Google Cloud Storage BigQuery.", "response": "def convert_types(cls, value):\n        \"\"\"\n        Takes a value from MSSQL, and converts it to a value that's safe for\n        JSON/Google Cloud Storage/BigQuery.\n        \"\"\"\n        if isinstance(value, decimal.Decimal):\n            return float(value)\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecorate function to execute function at the same time submitting action_logging but in CLI context. It will call action logger callbacks twice, one for pre-execution and the other one for post-execution. Action logger will be called with below keyword parameters: sub_command : name of sub-command start_datetime : start datetime instance by utc end_datetime : end datetime instance by utc full_command : full command line arguments user : current user log : airflow.models.log.Log ORM instance dag_id : dag id (optional) task_id : task_id (optional) execution_date : execution date (optional) error : exception instance if there's an exception :param f: function instance :return: wrapped function", "response": "def action_logging(f):\n    \"\"\"\n    Decorates function to execute function at the same time submitting action_logging\n    but in CLI context. It will call action logger callbacks twice,\n    one for pre-execution and the other one for post-execution.\n\n    Action logger will be called with below keyword parameters:\n        sub_command : name of sub-command\n        start_datetime : start datetime instance by utc\n        end_datetime : end datetime instance by utc\n        full_command : full command line arguments\n        user : current user\n        log : airflow.models.log.Log ORM instance\n        dag_id : dag id (optional)\n        task_id : task_id (optional)\n        execution_date : execution date (optional)\n        error : exception instance if there's an exception\n\n    :param f: function instance\n    :return: wrapped function\n    \"\"\"\n    @functools.wraps(f)\n    def wrapper(*args, **kwargs):\n        \"\"\"\n        An wrapper for cli functions. It assumes to have Namespace instance\n        at 1st positional argument\n        :param args: Positional argument. It assumes to have Namespace instance\n        at 1st positional argument\n        :param kwargs: A passthrough keyword argument\n        \"\"\"\n        assert args\n        assert isinstance(args[0], Namespace), \\\n            \"1st positional argument should be argparse.Namespace instance, \" \\\n            \"but {}\".format(args[0])\n        metrics = _build_metrics(f.__name__, args[0])\n        cli_action_loggers.on_pre_execution(**metrics)\n        try:\n            return f(*args, **kwargs)\n        except Exception as e:\n            metrics['error'] = e\n            raise\n        finally:\n            metrics['end_datetime'] = datetime.utcnow()\n            cli_action_loggers.on_post_execution(**metrics)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild metrics dict from function args", "response": "def _build_metrics(func_name, namespace):\n    \"\"\"\n    Builds metrics dict from function args\n    It assumes that function arguments is from airflow.bin.cli module's function\n    and has Namespace instance where it optionally contains \"dag_id\", \"task_id\",\n    and \"execution_date\".\n\n    :param func_name: name of function\n    :param namespace: Namespace instance from argparse\n    :return: dict with metrics\n    \"\"\"\n\n    metrics = {'sub_command': func_name, 'start_datetime': datetime.utcnow(),\n               'full_command': '{}'.format(list(sys.argv)), 'user': getpass.getuser()}\n\n    assert isinstance(namespace, Namespace)\n    tmp_dic = vars(namespace)\n    metrics['dag_id'] = tmp_dic.get('dag_id')\n    metrics['task_id'] = tmp_dic.get('task_id')\n    metrics['execution_date'] = tmp_dic.get('execution_date')\n    metrics['host_name'] = socket.gethostname()\n\n    extra = json.dumps(dict((k, metrics[k]) for k in ('host_name', 'full_command')))\n    log = Log(\n        event='cli_{}'.format(func_name),\n        task_instance=None,\n        owner=metrics['user'],\n        extra=extra,\n        task_id=metrics.get('task_id'),\n        dag_id=metrics.get('dag_id'),\n        execution_date=metrics.get('execution_date'))\n    metrics['log'] = log\n    return metrics"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _evaluate_trigger_rule(\n            self,\n            ti,\n            successes,\n            skipped,\n            failed,\n            upstream_failed,\n            done,\n            flag_upstream_failed,\n            session):\n        \"\"\"\n        Yields a dependency status that indicate whether the given task instance's trigger\n        rule was met.\n\n        :param ti: the task instance to evaluate the trigger rule of\n        :type ti: airflow.models.TaskInstance\n        :param successes: Number of successful upstream tasks\n        :type successes: bool\n        :param skipped: Number of skipped upstream tasks\n        :type skipped: bool\n        :param failed: Number of failed upstream tasks\n        :type failed: bool\n        :param upstream_failed: Number of upstream_failed upstream tasks\n        :type upstream_failed: bool\n        :param done: Number of completed upstream tasks\n        :type done: bool\n        :param flag_upstream_failed: This is a hack to generate\n            the upstream_failed state creation while checking to see\n            whether the task instance is runnable. It was the shortest\n            path to add the feature\n        :type flag_upstream_failed: bool\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        \"\"\"\n\n        TR = airflow.utils.trigger_rule.TriggerRule\n\n        task = ti.task\n        upstream = len(task.upstream_task_ids)\n        tr = task.trigger_rule\n        upstream_done = done >= upstream\n        upstream_tasks_state = {\n            \"total\": upstream, \"successes\": successes, \"skipped\": skipped,\n            \"failed\": failed, \"upstream_failed\": upstream_failed, \"done\": done\n        }\n        # TODO(aoen): Ideally each individual trigger rules would be its own class, but\n        # this isn't very feasible at the moment since the database queries need to be\n        # bundled together for efficiency.\n        # handling instant state assignment based on trigger rules\n        if flag_upstream_failed:\n            if tr == TR.ALL_SUCCESS:\n                if upstream_failed or failed:\n                    ti.set_state(State.UPSTREAM_FAILED, session)\n                elif skipped:\n                    ti.set_state(State.SKIPPED, session)\n            elif tr == TR.ALL_FAILED:\n                if successes or skipped:\n                    ti.set_state(State.SKIPPED, session)\n            elif tr == TR.ONE_SUCCESS:\n                if upstream_done and not successes:\n                    ti.set_state(State.SKIPPED, session)\n            elif tr == TR.ONE_FAILED:\n                if upstream_done and not (failed or upstream_failed):\n                    ti.set_state(State.SKIPPED, session)\n            elif tr == TR.NONE_FAILED:\n                if upstream_failed or failed:\n                    ti.set_state(State.UPSTREAM_FAILED, session)\n                elif skipped == upstream:\n                    ti.set_state(State.SKIPPED, session)\n            elif tr == TR.NONE_SKIPPED:\n                if skipped:\n                    ti.set_state(State.SKIPPED, session)\n\n        if tr == TR.ONE_SUCCESS:\n            if successes <= 0:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires one upstream \"\n                    \"task success, but none were found. \"\n                    \"upstream_tasks_state={1}, upstream_task_ids={2}\"\n                    .format(tr, upstream_tasks_state, task.upstream_task_ids))\n        elif tr == TR.ONE_FAILED:\n            if not failed and not upstream_failed:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires one upstream \"\n                    \"task failure, but none were found. \"\n                    \"upstream_tasks_state={1}, upstream_task_ids={2}\"\n                    .format(tr, upstream_tasks_state, task.upstream_task_ids))\n        elif tr == TR.ALL_SUCCESS:\n            num_failures = upstream - successes\n            if num_failures > 0:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires all upstream \"\n                    \"tasks to have succeeded, but found {1} non-success(es). \"\n                    \"upstream_tasks_state={2}, upstream_task_ids={3}\"\n                    .format(tr, num_failures, upstream_tasks_state,\n                            task.upstream_task_ids))\n        elif tr == TR.ALL_FAILED:\n            num_successes = upstream - failed - upstream_failed\n            if num_successes > 0:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires all upstream \"\n                    \"tasks to have failed, but found {1} non-failure(s). \"\n                    \"upstream_tasks_state={2}, upstream_task_ids={3}\"\n                    .format(tr, num_successes, upstream_tasks_state,\n                            task.upstream_task_ids))\n        elif tr == TR.ALL_DONE:\n            if not upstream_done:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires all upstream \"\n                    \"tasks to have completed, but found {1} task(s) that \"\n                    \"weren't done. upstream_tasks_state={2}, \"\n                    \"upstream_task_ids={3}\"\n                    .format(tr, upstream_done, upstream_tasks_state,\n                            task.upstream_task_ids))\n        elif tr == TR.NONE_FAILED:\n            num_failures = upstream - successes - skipped\n            if num_failures > 0:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires all upstream \"\n                    \"tasks to have succeeded or been skipped, but found {1} non-success(es). \"\n                    \"upstream_tasks_state={2}, upstream_task_ids={3}\"\n                    .format(tr, num_failures, upstream_tasks_state,\n                            task.upstream_task_ids))\n        elif tr == TR.NONE_SKIPPED:\n            if skipped > 0:\n                yield self._failing_status(\n                    reason=\"Task's trigger rule '{0}' requires all upstream \"\n                    \"tasks to not have been skipped, but found {1} task(s) skipped. \"\n                    \"upstream_tasks_state={2}, upstream_task_ids={3}\"\n                    .format(tr, skipped, upstream_tasks_state,\n                            task.upstream_task_ids))\n        else:\n            yield self._failing_status(\n                reason=\"No strategy to evaluate trigger rule '{0}'.\".format(tr))", "response": "Evaluate the trigger rule of the given task instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_cgroup(self, path):\n        node = trees.Tree().root\n        path_split = path.split(os.sep)\n        for path_element in path_split:\n            name_to_node = {x.name: x for x in node.children}\n            if path_element not in name_to_node:\n                self.log.debug(\"Creating cgroup %s in %s\", path_element, node.path)\n                node = node.create_cgroup(path_element)\n            else:\n                self.log.debug(\n                    \"Not creating cgroup %s in %s since it already exists\",\n                    path_element, node.path\n                )\n                node = name_to_node[path_element]\n        return node", "response": "Create the specified cgroup."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the specified cgroup.", "response": "def _delete_cgroup(self, path):\n        \"\"\"\n        Delete the specified cgroup.\n\n        :param path: The path of the cgroup to delete.\n        E.g. cpu/mygroup/mysubgroup\n        \"\"\"\n        node = trees.Tree().root\n        path_split = path.split(\"/\")\n        for path_element in path_split:\n            name_to_node = {x.name: x for x in node.children}\n            if path_element not in name_to_node:\n                self.log.warning(\"Cgroup does not exist: %s\", path)\n                return\n            else:\n                node = name_to_node[path_element]\n        # node is now the leaf node\n        parent = node.parent\n        self.log.debug(\"Deleting cgroup %s/%s\", parent, node.name)\n        parent.delete_cgroup(node.name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary mapping subsystem name to cgroup name", "response": "def _get_cgroup_names():\n        \"\"\"\n        :return: a mapping between the subsystem name to the cgroup name\n        :rtype: dict[str, str]\n        \"\"\"\n        with open(\"/proc/self/cgroup\") as f:\n            lines = f.readlines()\n            d = {}\n            for line in lines:\n                line_split = line.rstrip().split(\":\")\n                subsystem = line_split[1]\n                group_name = line_split[2]\n                d[subsystem] = group_name\n            return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the host field of a resource.", "response": "def _parse_host(host):\n        \"\"\"\n        The purpose of this function is to be robust to improper connections\n        settings provided by users, specifically in the host field.\n\n        For example -- when users supply ``https://xx.cloud.databricks.com`` as the\n        host, we must strip out the protocol to get the host.::\n\n            h = DatabricksHook()\n            assert h._parse_host('https://xx.cloud.databricks.com') == \\\n                'xx.cloud.databricks.com'\n\n        In the case where users supply the correct ``xx.cloud.databricks.com`` as the\n        host, this function is a no-op.::\n\n            assert h._parse_host('xx.cloud.databricks.com') == 'xx.cloud.databricks.com'\n\n        \"\"\"\n        urlparse_host = urlparse.urlparse(host).hostname\n        if urlparse_host:\n            # In this case, host = https://xx.cloud.databricks.com\n            return urlparse_host\n        else:\n            # In this case, host = xx.cloud.databricks.com\n            return host"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _do_api_call(self, endpoint_info, json):\n        method, endpoint = endpoint_info\n        url = 'https://{host}/{endpoint}'.format(\n            host=self._parse_host(self.databricks_conn.host),\n            endpoint=endpoint)\n        if 'token' in self.databricks_conn.extra_dejson:\n            self.log.info('Using token auth.')\n            auth = _TokenAuth(self.databricks_conn.extra_dejson['token'])\n        else:\n            self.log.info('Using basic auth.')\n            auth = (self.databricks_conn.login, self.databricks_conn.password)\n        if method == 'GET':\n            request_func = requests.get\n        elif method == 'POST':\n            request_func = requests.post\n        else:\n            raise AirflowException('Unexpected HTTP Method: ' + method)\n\n        attempt_num = 1\n        while True:\n            try:\n                response = request_func(\n                    url,\n                    json=json,\n                    auth=auth,\n                    headers=USER_AGENT_HEADER,\n                    timeout=self.timeout_seconds)\n                response.raise_for_status()\n                return response.json()\n            except requests_exceptions.RequestException as e:\n                if not _retryable_error(e):\n                    # In this case, the user probably made a mistake.\n                    # Don't retry.\n                    raise AirflowException('Response: {0}, Status Code: {1}'.format(\n                        e.response.content, e.response.status_code))\n\n                self._log_request_error(attempt_num, e)\n\n            if attempt_num == self.retry_limit:\n                raise AirflowException(('API requests to Databricks failed {} times. ' +\n                                        'Giving up.').format(self.retry_limit))\n\n            attempt_num += 1\n            sleep(self.retry_delay)", "response": "Utility function to perform an API call with retries"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_conn(self):\n        if not self.conn:\n            connection = self.get_connection(self.conn_id)\n            extras = connection.extra_dejson\n            self.conn = Salesforce(\n                username=connection.login,\n                password=connection.password,\n                security_token=extras['security_token'],\n                instance_url=connection.host,\n                sandbox=extras.get('sandbox', False)\n            )\n        return self.conn", "response": "Get the connection object for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_query(self, query):\n        conn = self.get_conn()\n\n        self.log.info(\"Querying for all objects\")\n        query_results = conn.query_all(query)\n\n        self.log.info(\"Received results: Total size: %s; Done: %s\",\n                      query_results['totalSize'], query_results['done'])\n\n        return query_results", "response": "Make a query to Salesforce."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef describe_object(self, obj):\n        conn = self.get_conn()\n\n        return conn.__getattr__(obj).describe()", "response": "Get the description of an object from Salesforce."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of all available fields for an object.", "response": "def get_available_fields(self, obj):\n        \"\"\"\n        Get a list of all available fields for an object.\n\n        :param obj: The name of the Salesforce object that we are getting a description of.\n        :type obj: str\n        :return: the names of the fields.\n        :rtype: list of str\n        \"\"\"\n        self.get_conn()\n\n        obj_description = self.describe_object(obj)\n\n        return [field['name'] for field in obj_description['fields']]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_object_from_salesforce(self, obj, fields):\n        query = \"SELECT {} FROM {}\".format(\",\".join(fields), obj)\n\n        self.log.info(\"Making query to Salesforce: %s\",\n                      query if len(query) < 30 else \" ... \".join([query[:15], query[-15:]]))\n\n        return self.make_query(query)", "response": "Get all instances of the object from Salesforce."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _to_timestamp(cls, column):\n        # try and convert the column to datetimes\n        # the column MUST have a four digit year somewhere in the string\n        # there should be a better way to do this,\n        # but just letting pandas try and convert every column without a format\n        # caused it to convert floats as well\n        # For example, a column of integers\n        # between 0 and 10 are turned into timestamps\n        # if the column cannot be converted,\n        # just return the original column untouched\n        try:\n            column = pd.to_datetime(column)\n        except ValueError:\n            log = LoggingMixin().log\n            log.warning(\"Could not convert field to timestamps: %s\", column.name)\n            return column\n\n        # now convert the newly created datetimes into timestamps\n        # we have to be careful here\n        # because NaT cannot be converted to a timestamp\n        # so we have to return NaN\n        converted = []\n        for value in column:\n            try:\n                converted.append(value.timestamp())\n            except (ValueError, AttributeError):\n                converted.append(pd.np.NaN)\n\n        return pd.Series(converted, index=column.index)", "response": "Convert a column of a dataframe to UNIX timestamps if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_object_to_file(self,\n                             query_results,\n                             filename,\n                             fmt=\"csv\",\n                             coerce_to_timestamp=False,\n                             record_time_added=False):\n        \"\"\"\n        Write query results to file.\n\n        Acceptable formats are:\n            - csv:\n                comma-separated-values file. This is the default format.\n            - json:\n                JSON array. Each element in the array is a different row.\n            - ndjson:\n                JSON array but each element is new-line delimited instead of comma delimited like in `json`\n\n        This requires a significant amount of cleanup.\n        Pandas doesn't handle output to CSV and json in a uniform way.\n        This is especially painful for datetime types.\n        Pandas wants to write them as strings in CSV, but as millisecond Unix timestamps.\n\n        By default, this function will try and leave all values as they are represented in Salesforce.\n        You use the `coerce_to_timestamp` flag to force all datetimes to become Unix timestamps (UTC).\n        This is can be greatly beneficial as it will make all of your datetime fields look the same,\n        and makes it easier to work with in other database environments\n\n        :param query_results: the results from a SQL query\n        :type query_results: list of dict\n        :param filename: the name of the file where the data should be dumped to\n        :type filename: str\n        :param fmt: the format you want the output in. Default:  'csv'\n        :type fmt: str\n        :param coerce_to_timestamp: True if you want all datetime fields to be converted into Unix timestamps.\n            False if you want them to be left in the same format as they were in Salesforce.\n            Leaving the value as False will result in datetimes being strings. Default: False\n        :type coerce_to_timestamp: bool\n        :param record_time_added: True if you want to add a Unix timestamp field\n            to the resulting data that marks when the data was fetched from Salesforce. Default: False\n        :type record_time_added: bool\n        :return: the dataframe that gets written to the file.\n        :rtype: pd.Dataframe\n        \"\"\"\n        fmt = fmt.lower()\n        if fmt not in ['csv', 'json', 'ndjson']:\n            raise ValueError(\"Format value is not recognized: {}\".format(fmt))\n\n        # this line right here will convert all integers to floats\n        # if there are any None/np.nan values in the column\n        # that's because None/np.nan cannot exist in an integer column\n        # we should write all of our timestamps as FLOATS in our final schema\n        df = pd.DataFrame.from_records(query_results, exclude=[\"attributes\"])\n\n        df.columns = [column.lower() for column in df.columns]\n\n        # convert columns with datetime strings to datetimes\n        # not all strings will be datetimes, so we ignore any errors that occur\n        # we get the object's definition at this point and only consider\n        # features that are DATE or DATETIME\n        if coerce_to_timestamp and df.shape[0] > 0:\n            # get the object name out of the query results\n            # it's stored in the \"attributes\" dictionary\n            # for each returned record\n            object_name = query_results[0]['attributes']['type']\n\n            self.log.info(\"Coercing timestamps for: %s\", object_name)\n\n            schema = self.describe_object(object_name)\n\n            # possible columns that can be converted to timestamps\n            # are the ones that are either date or datetime types\n            # strings are too general and we risk unintentional conversion\n            possible_timestamp_cols = [\n                field['name'].lower()\n                for field in schema['fields']\n                if field['type'] in [\"date\", \"datetime\"] and field['name'].lower() in df.columns\n            ]\n            df[possible_timestamp_cols] = df[possible_timestamp_cols].apply(self._to_timestamp)\n\n        if record_time_added:\n            fetched_time = time.time()\n            df[\"time_fetched_from_salesforce\"] = fetched_time\n\n        # write the CSV or JSON file depending on the option\n        # NOTE:\n        #   datetimes here are an issue.\n        #   There is no good way to manage the difference\n        #   for to_json, the options are an epoch or a ISO string\n        #   but for to_csv, it will be a string output by datetime\n        #   For JSON we decided to output the epoch timestamp in seconds\n        #   (as is fairly standard for JavaScript)\n        #   And for csv, we do a string\n        if fmt == \"csv\":\n            # there are also a ton of newline objects that mess up our ability to write to csv\n            # we remove these newlines so that the output is a valid CSV format\n            self.log.info(\"Cleaning data and writing to CSV\")\n            possible_strings = df.columns[df.dtypes == \"object\"]\n            df[possible_strings] = df[possible_strings].apply(\n                lambda x: x.str.replace(\"\\r\\n\", \"\").str.replace(\"\\n\", \"\")\n            )\n            # write the dataframe\n            df.to_csv(filename, index=False)\n        elif fmt == \"json\":\n            df.to_json(filename, \"records\", date_unit=\"s\")\n        elif fmt == \"ndjson\":\n            df.to_json(filename, \"records\", lines=True, date_unit=\"s\")\n\n        return df", "response": "Writes the results of a SQL query to a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read(self, ti, try_number, metadata=None):\n        # Explicitly getting log relative path is necessary as the given\n        # task instance might be different than task instance passed in\n        # in set_context method.\n        log_relative_path = self._render_filename(ti, try_number)\n        remote_loc = os.path.join(self.remote_base, log_relative_path)\n\n        try:\n            remote_log = self.gcs_read(remote_loc)\n            log = '*** Reading remote log from {}.\\n{}\\n'.format(\n                remote_loc, remote_log)\n            return log, {'end_of_log': True}\n        except Exception as e:\n            log = '*** Unable to read remote log from {}\\n*** {}\\n\\n'.format(\n                remote_loc, str(e))\n            self.log.error(log)\n            local_log, metadata = super()._read(ti, try_number)\n            log += local_log\n            return log, metadata", "response": "Read the log from GCS and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the log at the remote_log_location and returns the contents of the file.", "response": "def gcs_read(self, remote_log_location):\n        \"\"\"\n        Returns the log found at the remote_log_location.\n        :param remote_log_location: the log's location in remote storage\n        :type remote_log_location: str (path)\n        \"\"\"\n        bkt, blob = self.parse_gcs_url(remote_log_location)\n        return self.hook.download(bkt, blob).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gcs_write(self, log, remote_log_location, append=True):\n        if append:\n            try:\n                old_log = self.gcs_read(remote_log_location)\n                log = '\\n'.join([old_log, log]) if old_log else log\n            except Exception as e:\n                if not hasattr(e, 'resp') or e.resp.get('status') != '404':\n                    log = '*** Previous log discarded: {}\\n\\n'.format(str(e)) + log\n\n        try:\n            bkt, blob = self.parse_gcs_url(remote_log_location)\n            from tempfile import NamedTemporaryFile\n            with NamedTemporaryFile(mode='w+') as tmpfile:\n                tmpfile.write(log)\n                # Force the file to be flushed, since we're doing the\n                # upload from within the file context (it hasn't been\n                # closed).\n                tmpfile.flush()\n                self.hook.upload(bkt, blob, tmpfile.name)\n        except Exception as e:\n            self.log.error('Could not write logs to %s: %s', remote_log_location, e)", "response": "Writes the log to the remote storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a Google Cloud Storage URL returns a tuple containing the corresponding bucket and blob name.", "response": "def parse_gcs_url(gsurl):\n        \"\"\"\n        Given a Google Cloud Storage URL (gs://<bucket>/<blob>), returns a\n        tuple containing the corresponding bucket and blob.\n        \"\"\"\n        parsed_url = urlparse(gsurl)\n        if not parsed_url.netloc:\n            raise AirflowException('Please provide a bucket name')\n        else:\n            bucket = parsed_url.netloc\n            blob = parsed_url.path.strip('/')\n            return bucket, blob"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_collection(self, mongo_collection, mongo_db=None):\n        mongo_db = mongo_db if mongo_db is not None else self.connection.schema\n        mongo_conn = self.get_conn()\n\n        return mongo_conn.get_database(mongo_db).get_collection(mongo_collection)", "response": "Fetches a mongo collection object for querying."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aggregate(self, mongo_collection, aggregate_query, mongo_db=None, **kwargs):\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.aggregate(aggregate_query, **kwargs)", "response": "Runs an aggregation pipeline and returns the results\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a mongo find query and returns the results", "response": "def find(self, mongo_collection, query, find_one=False, mongo_db=None, **kwargs):\n        \"\"\"\n        Runs a mongo find query and returns the results\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.find\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        if find_one:\n            return collection.find_one(query, **kwargs)\n        else:\n            return collection.find(query, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert a single document into a mongo collection", "response": "def insert_one(self, mongo_collection, doc, mongo_db=None, **kwargs):\n        \"\"\"\n        Inserts a single document into a mongo collection\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.insert_one\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.insert_one(doc, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_many(self, mongo_collection, docs, mongo_db=None, **kwargs):\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.insert_many(docs, **kwargs)", "response": "Insert many docs into a mongo collection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_one(self, mongo_collection, filter_doc, update_doc,\n                   mongo_db=None, **kwargs):\n        \"\"\"\n        Updates a single document in a mongo collection.\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.update_one\n\n        :param mongo_collection: The name of the collection to update.\n        :type mongo_collection: str\n        :param filter_doc: A query that matches the documents to update.\n        :type filter_doc: dict\n        :param update_doc: The modifications to apply.\n        :type update_doc: dict\n        :param mongo_db: The name of the database to use.\n            Can be omitted; then the database from the connection string is used.\n        :type mongo_db: str\n\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.update_one(filter_doc, update_doc, **kwargs)", "response": "Updates a single document in a mongo collection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace a single document in a mongo collection.", "response": "def replace_one(self, mongo_collection, doc, filter_doc=None,\n                    mongo_db=None, **kwargs):\n        \"\"\"\n        Replaces a single document in a mongo collection.\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.replace_one\n\n        .. note::\n            If no ``filter_doc`` is given, it is assumed that the replacement\n            document contain the ``_id`` field which is then used as filters.\n\n        :param mongo_collection: The name of the collection to update.\n        :type mongo_collection: str\n        :param doc: The new document.\n        :type doc: dict\n        :param filter_doc: A query that matches the documents to replace.\n            Can be omitted; then the _id field from doc will be used.\n        :type filter_doc: dict\n        :param mongo_db: The name of the database to use.\n            Can be omitted; then the database from the connection string is used.\n        :type mongo_db: str\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        if not filter_doc:\n            filter_doc = {'_id': doc['_id']}\n\n        return collection.replace_one(filter_doc, doc, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing many documents in a collection.", "response": "def replace_many(self, mongo_collection, docs,\n                     filter_docs=None, mongo_db=None, upsert=False, collation=None,\n                     **kwargs):\n        \"\"\"\n        Replaces many documents in a mongo collection.\n\n        Uses bulk_write with multiple ReplaceOne operations\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.bulk_write\n\n        .. note::\n            If no ``filter_docs``are given, it is assumed that all\n            replacement documents contain the ``_id`` field which are then\n            used as filters.\n\n        :param mongo_collection: The name of the collection to update.\n        :type mongo_collection: str\n        :param docs: The new documents.\n        :type docs: list[dict]\n        :param filter_docs: A list of queries that match the documents to replace.\n            Can be omitted; then the _id fields from docs will be used.\n        :type filter_docs: list[dict]\n        :param mongo_db: The name of the database to use.\n            Can be omitted; then the database from the connection string is used.\n        :type mongo_db: str\n        :param upsert: If ``True``, perform an insert if no documents\n            match the filters for the replace operation.\n        :type upsert: bool\n        :param collation: An instance of\n            :class:`~pymongo.collation.Collation`. This option is only\n            supported on MongoDB 3.4 and above.\n        :type collation: pymongo.collation.Collation\n\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        if not filter_docs:\n            filter_docs = [{'_id': doc['_id']} for doc in docs]\n\n        requests = [\n            ReplaceOne(\n                filter_docs[i],\n                docs[i],\n                upsert=upsert,\n                collation=collation)\n            for i in range(len(docs))\n        ]\n\n        return collection.bulk_write(requests, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a single document in a mongo collection.", "response": "def delete_one(self, mongo_collection, filter_doc, mongo_db=None, **kwargs):\n        \"\"\"\n        Deletes a single document in a mongo collection.\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.delete_one\n\n        :param mongo_collection: The name of the collection to delete from.\n        :type mongo_collection: str\n        :param filter_doc: A query that matches the document to delete.\n        :type filter_doc: dict\n        :param mongo_db: The name of the database to use.\n            Can be omitted; then the database from the connection string is used.\n        :type mongo_db: str\n\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.delete_one(filter_doc, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete one or more documents in a mongo collection.", "response": "def delete_many(self, mongo_collection, filter_doc, mongo_db=None, **kwargs):\n        \"\"\"\n        Deletes one or more documents in a mongo collection.\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.delete_many\n\n        :param mongo_collection: The name of the collection to delete from.\n        :type mongo_collection: str\n        :param filter_doc: A query that matches the documents to delete.\n        :type filter_doc: dict\n        :param mongo_db: The name of the database to use.\n            Can be omitted; then the database from the connection string is used.\n        :type mongo_db: str\n\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.delete_many(filter_doc, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the mail folder for attachments with the given name.", "response": "def has_mail_attachment(self, name, mail_folder='INBOX', check_regex=False):\n        \"\"\"\n        Checks the mail folder for mails containing attachments with the given name.\n\n        :param name: The name of the attachment that will be searched for.\n        :type name: str\n        :param mail_folder: The mail folder where to look at.\n        :type mail_folder: str\n        :param check_regex: Checks the name for a regular expression.\n        :type check_regex: bool\n        :returns: True if there is an attachment with the given name and False if not.\n        :rtype: bool\n        \"\"\"\n        mail_attachments = self._retrieve_mails_attachments_by_name(name,\n                                                                    mail_folder,\n                                                                    check_regex,\n                                                                    latest_only=True)\n        return len(mail_attachments) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the mail s attachments in the mail folder by its name.", "response": "def retrieve_mail_attachments(self,\n                                  name,\n                                  mail_folder='INBOX',\n                                  check_regex=False,\n                                  latest_only=False,\n                                  not_found_mode='raise'):\n        \"\"\"\n        Retrieves mail's attachments in the mail folder by its name.\n\n        :param name: The name of the attachment that will be downloaded.\n        :type name: str\n        :param mail_folder: The mail folder where to look at.\n        :type mail_folder: str\n        :param check_regex: Checks the name for a regular expression.\n        :type check_regex: bool\n        :param latest_only: If set to True it will only retrieve\n                            the first matched attachment.\n        :type latest_only: bool\n        :param not_found_mode: Specify what should happen if no attachment has been found.\n                               Supported values are 'raise', 'warn' and 'ignore'.\n                               If it is set to 'raise' it will raise an exception,\n                               if set to 'warn' it will only print a warning and\n                               if set to 'ignore' it won't notify you at all.\n        :type not_found_mode: str\n        :returns: a list of tuple each containing the attachment filename and its payload.\n        :rtype: a list of tuple\n        \"\"\"\n        mail_attachments = self._retrieve_mails_attachments_by_name(name,\n                                                                    mail_folder,\n                                                                    check_regex,\n                                                                    latest_only)\n        if not mail_attachments:\n            self._handle_not_found_mode(not_found_mode)\n\n        return mail_attachments"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload the mail s attachments in the mail folder by its name.", "response": "def download_mail_attachments(self,\n                                  name,\n                                  local_output_directory,\n                                  mail_folder='INBOX',\n                                  check_regex=False,\n                                  latest_only=False,\n                                  not_found_mode='raise'):\n        \"\"\"\n        Downloads mail's attachments in the mail folder by its name to the local directory.\n\n        :param name: The name of the attachment that will be downloaded.\n        :type name: str\n        :param local_output_directory: The output directory on the local machine\n                                       where the files will be downloaded to.\n        :type local_output_directory: str\n        :param mail_folder: The mail folder where to look at.\n        :type mail_folder: str\n        :param check_regex: Checks the name for a regular expression.\n        :type check_regex: bool\n        :param latest_only: If set to True it will only download\n                            the first matched attachment.\n        :type latest_only: bool\n        :param not_found_mode: Specify what should happen if no attachment has been found.\n                               Supported values are 'raise', 'warn' and 'ignore'.\n                               If it is set to 'raise' it will raise an exception,\n                               if set to 'warn' it will only print a warning and\n                               if set to 'ignore' it won't notify you at all.\n        :type not_found_mode: str\n        \"\"\"\n        mail_attachments = self._retrieve_mails_attachments_by_name(name,\n                                                                    mail_folder,\n                                                                    check_regex,\n                                                                    latest_only)\n\n        if not mail_attachments:\n            self._handle_not_found_mode(not_found_mode)\n\n        self._create_files(mail_attachments, local_output_directory)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all attachments by name.", "response": "def get_attachments_by_name(self, name, check_regex, find_first=False):\n        \"\"\"\n        Gets all attachments by name for the mail.\n\n        :param name: The name of the attachment to look for.\n        :type name: str\n        :param check_regex: Checks the name for a regular expression.\n        :type check_regex: bool\n        :param find_first: If set to True it will only find the first match and then quit.\n        :type find_first: bool\n        :returns: a list of tuples each containing name and payload\n                  where the attachments name matches the given name.\n        :rtype: list of tuple\n        \"\"\"\n        attachments = []\n\n        for part in self.mail.walk():\n            mail_part = MailPart(part)\n            if mail_part.is_attachment():\n                found_attachment = mail_part.has_matching_name(name) if check_regex \\\n                    else mail_part.has_equal_name(name)\n                if found_attachment:\n                    file_name, file_payload = mail_part.get_file()\n                    self.log.info('Found attachment: {}'.format(file_name))\n                    attachments.append((file_name, file_payload))\n                    if find_first:\n                        break\n\n        return attachments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_file(self):\n        return self.part.get_filename(), self.part.get_payload(decode=True)", "response": "Gets the file including name and payload."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite batch records to Kinesis Firehose", "response": "def put_records(self, records):\n        \"\"\"\n        Write batch records to Kinesis Firehose\n        \"\"\"\n\n        firehose_conn = self.get_conn()\n\n        response = firehose_conn.put_record_batch(\n            DeliveryStreamName=self.delivery_stream,\n            Records=records\n        )\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a generator that yields the statuses of the dependencies that are in the reschedule period.", "response": "def _get_dep_statuses(self, ti, session, dep_context):\n        \"\"\"\n        Determines whether a task is ready to be rescheduled. Only tasks in\n        NONE state with at least one row in task_reschedule table are\n        handled by this dependency class, otherwise this dependency is\n        considered as passed. This dependency fails if the latest reschedule\n        request's reschedule date is still in future.\n        \"\"\"\n        if dep_context.ignore_in_reschedule_period:\n            yield self._passing_status(\n                reason=\"The context specified that being in a reschedule period was \"\n                       \"permitted.\")\n            return\n\n        if ti.state not in self.RESCHEDULEABLE_STATES:\n            yield self._passing_status(\n                reason=\"The task instance is not in State_UP_FOR_RESCHEDULE or NONE state.\")\n            return\n\n        task_reschedules = TaskReschedule.find_for_task_instance(task_instance=ti)\n        if not task_reschedules:\n            yield self._passing_status(\n                reason=\"There is no reschedule request for this task instance.\")\n            return\n\n        now = timezone.utcnow()\n        next_reschedule_date = task_reschedules[-1].reschedule_date\n        if now >= next_reschedule_date:\n            yield self._passing_status(\n                reason=\"Task instance id ready for reschedule.\")\n            return\n\n        yield self._failing_status(\n            reason=\"Task is not ready for reschedule yet but will be rescheduled \"\n                   \"automatically. Current date is {0} and task will be rescheduled \"\n                   \"at {1}.\".format(now.isoformat(), next_reschedule_date.isoformat()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends email using the default backend.", "response": "def send_email(to, subject, html_content,\n               files=None, dryrun=False, cc=None, bcc=None,\n               mime_subtype='mixed', mime_charset='utf-8', **kwargs):\n    \"\"\"\n    Send email using backend specified in EMAIL_BACKEND.\n    \"\"\"\n    path, attr = configuration.conf.get('email', 'EMAIL_BACKEND').rsplit('.', 1)\n    module = importlib.import_module(path)\n    backend = getattr(module, attr)\n    to = get_email_address_list(to)\n    to = \", \".join(to)\n\n    return backend(to, subject, html_content, files=files,\n                   dryrun=dryrun, cc=cc, bcc=bcc,\n                   mime_subtype=mime_subtype, mime_charset=mime_charset, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_email_smtp(to, subject, html_content, files=None,\n                    dryrun=False, cc=None, bcc=None,\n                    mime_subtype='mixed', mime_charset='utf-8',\n                    **kwargs):\n    \"\"\"\n    Send an email with html content\n\n    >>> send_email('test@example.com', 'foo', '<b>Foo</b> bar', ['/dev/null'], dryrun=True)\n    \"\"\"\n    smtp_mail_from = configuration.conf.get('smtp', 'SMTP_MAIL_FROM')\n\n    to = get_email_address_list(to)\n\n    msg = MIMEMultipart(mime_subtype)\n    msg['Subject'] = subject\n    msg['From'] = smtp_mail_from\n    msg['To'] = \", \".join(to)\n    recipients = to\n    if cc:\n        cc = get_email_address_list(cc)\n        msg['CC'] = \", \".join(cc)\n        recipients = recipients + cc\n\n    if bcc:\n        # don't add bcc in header\n        bcc = get_email_address_list(bcc)\n        recipients = recipients + bcc\n\n    msg['Date'] = formatdate(localtime=True)\n    mime_text = MIMEText(html_content, 'html', mime_charset)\n    msg.attach(mime_text)\n\n    for fname in files or []:\n        basename = os.path.basename(fname)\n        with open(fname, \"rb\") as f:\n            part = MIMEApplication(\n                f.read(),\n                Name=basename\n            )\n            part['Content-Disposition'] = 'attachment; filename=\"%s\"' % basename\n            part['Content-ID'] = '<%s>' % basename\n            msg.attach(part)\n\n    send_MIME_email(smtp_mail_from, recipients, msg, dryrun)", "response": "Send an email with html content"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the result value of a get_record_or_record_or_record_or_record call.", "response": "def process_result_value(self, value, dialect):\n        \"\"\"\n        Processes DateTimes from the DB making sure it is always\n        returning UTC. Not using timezone.convert_to_utc as that\n        converts to configured TIMEZONE while the DB might be\n        running with some other setting. We assume UTC datetimes\n        in the database.\n        \"\"\"\n        if value is not None:\n            if value.tzinfo is None:\n                value = value.replace(tzinfo=utc)\n            else:\n                value = value.astimezone(utc)\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_for_blob(self, container_name, blob_name, **kwargs):\n        return self.connection.exists(container_name, blob_name, **kwargs)", "response": "Check if a blob exists on Azure Blob Storage."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_for_prefix(self, container_name, prefix, **kwargs):\n        matches = self.connection.list_blobs(container_name, prefix,\n                                             num_results=1, **kwargs)\n        return len(list(matches)) > 0", "response": "Check if a prefix exists on Azure Blob storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nuploading a file to Azure Blob Storage.", "response": "def load_file(self, file_path, container_name, blob_name, **kwargs):\n        \"\"\"\n        Upload a file to Azure Blob Storage.\n\n        :param file_path: Path to the file to load.\n        :type file_path: str\n        :param container_name: Name of the container.\n        :type container_name: str\n        :param blob_name: Name of the blob.\n        :type blob_name: str\n        :param kwargs: Optional keyword arguments that\n            `BlockBlobService.create_blob_from_path()` takes.\n        :type kwargs: object\n        \"\"\"\n        # Reorder the argument order from airflow.hooks.S3_hook.load_file.\n        self.connection.create_blob_from_path(container_name, blob_name,\n                                              file_path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupload a string to Azure Blob Storage.", "response": "def load_string(self, string_data, container_name, blob_name, **kwargs):\n        \"\"\"\n        Upload a string to Azure Blob Storage.\n\n        :param string_data: String to load.\n        :type string_data: str\n        :param container_name: Name of the container.\n        :type container_name: str\n        :param blob_name: Name of the blob.\n        :type blob_name: str\n        :param kwargs: Optional keyword arguments that\n            `BlockBlobService.create_blob_from_text()` takes.\n        :type kwargs: object\n        \"\"\"\n        # Reorder the argument order from airflow.hooks.S3_hook.load_string.\n        self.connection.create_blob_from_text(container_name, blob_name,\n                                              string_data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_file(self, file_path, container_name, blob_name, **kwargs):\n        return self.connection.get_blob_to_path(container_name, blob_name,\n                                                file_path, **kwargs)", "response": "Download a file from Azure Blob Storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_file(self, container_name, blob_name, **kwargs):\n        return self.connection.get_blob_to_text(container_name,\n                                                blob_name,\n                                                **kwargs).content", "response": "Reads a file from Azure Blob Storage and returns as a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_file(self, container_name, blob_name, is_prefix=False,\n                    ignore_if_missing=False, **kwargs):\n        \"\"\"\n        Delete a file from Azure Blob Storage.\n\n        :param container_name: Name of the container.\n        :type container_name: str\n        :param blob_name: Name of the blob.\n        :type blob_name: str\n        :param is_prefix: If blob_name is a prefix, delete all matching files\n        :type is_prefix: bool\n        :param ignore_if_missing: if True, then return success even if the\n            blob does not exist.\n        :type ignore_if_missing: bool\n        :param kwargs: Optional keyword arguments that\n            `BlockBlobService.create_blob_from_path()` takes.\n        :type kwargs: object\n        \"\"\"\n\n        if is_prefix:\n            blobs_to_delete = [\n                blob.name for blob in self.connection.list_blobs(\n                    container_name, prefix=blob_name, **kwargs\n                )\n            ]\n        elif self.check_for_blob(container_name, blob_name):\n            blobs_to_delete = [blob_name]\n        else:\n            blobs_to_delete = []\n\n        if not ignore_if_missing and len(blobs_to_delete) == 0:\n            raise AirflowException('Blob(s) not found: {}'.format(blob_name))\n\n        for blob_uri in blobs_to_delete:\n            self.log.info(\"Deleting blob: \" + blob_uri)\n            self.connection.delete_blob(container_name,\n                                        blob_uri,\n                                        delete_snapshots='include',\n                                        **kwargs)", "response": "Delete a file from Azure Blob Storage."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_conn(self):\n        if self.conn is None:\n            params = self.get_connection(self.ftp_conn_id)\n            pasv = params.extra_dejson.get(\"passive\", True)\n            self.conn = ftplib.FTP(params.host, params.login, params.password)\n            self.conn.set_pasv(pasv)\n\n        return self.conn", "response": "Returns a FTP connection object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of all files in the remote directory", "response": "def describe_directory(self, path):\n        \"\"\"\n        Returns a dictionary of {filename: {attributes}} for all files\n        on the remote system (where the MLSD command is supported).\n\n        :param path: full path to the remote directory\n        :type path: str\n        \"\"\"\n        conn = self.get_conn()\n        conn.cwd(path)\n        try:\n            # only works in Python 3\n            files = dict(conn.mlsd())\n        except AttributeError:\n            files = dict(mlsd(conn))\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_directory(self, path, nlst=False):\n        conn = self.get_conn()\n        conn.cwd(path)\n\n        files = conn.nlst()\n        return files", "response": "Returns a list of files on the remote system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef retrieve_file(\n            self,\n            remote_full_path,\n            local_full_path_or_buffer,\n            callback=None):\n        \"\"\"\n        Transfers the remote file to a local location.\n\n        If local_full_path_or_buffer is a string path, the file will be put\n        at that location; if it is a file-like buffer, the file will\n        be written to the buffer but not closed.\n\n        :param remote_full_path: full path to the remote file\n        :type remote_full_path: str\n        :param local_full_path_or_buffer: full path to the local file or a\n            file-like buffer\n        :type local_full_path_or_buffer: str or file-like buffer\n        :param callback: callback which is called each time a block of data\n            is read. if you do not use a callback, these blocks will be written\n            to the file or buffer passed in. if you do pass in a callback, note\n            that writing to a file or buffer will need to be handled inside the\n            callback.\n            [default: output_handle.write()]\n        :type callback: callable\n\n        :Example::\n\n            hook = FTPHook(ftp_conn_id='my_conn')\n\n            remote_path = '/path/to/remote/file'\n            local_path = '/path/to/local/file'\n\n            # with a custom callback (in this case displaying progress on each read)\n            def print_progress(percent_progress):\n                self.log.info('Percent Downloaded: %s%%' % percent_progress)\n\n            total_downloaded = 0\n            total_file_size = hook.get_size(remote_path)\n            output_handle = open(local_path, 'wb')\n            def write_to_file_with_progress(data):\n                total_downloaded += len(data)\n                output_handle.write(data)\n                percent_progress = (total_downloaded / total_file_size) * 100\n                print_progress(percent_progress)\n            hook.retrieve_file(remote_path, None, callback=write_to_file_with_progress)\n\n            # without a custom callback data is written to the local_path\n            hook.retrieve_file(remote_path, local_path)\n        \"\"\"\n        conn = self.get_conn()\n\n        is_path = isinstance(local_full_path_or_buffer, basestring)\n\n        # without a callback, default to writing to a user-provided file or\n        # file-like buffer\n        if not callback:\n            if is_path:\n                output_handle = open(local_full_path_or_buffer, 'wb')\n            else:\n                output_handle = local_full_path_or_buffer\n            callback = output_handle.write\n        else:\n            output_handle = None\n\n        remote_path, remote_file_name = os.path.split(remote_full_path)\n        conn.cwd(remote_path)\n        self.log.info('Retrieving file from FTP: %s', remote_full_path)\n        conn.retrbinary('RETR %s' % remote_file_name, callback)\n        self.log.info('Finished retrieving file from FTP: %s', remote_full_path)\n\n        if is_path and output_handle:\n            output_handle.close()", "response": "This method will retrieve the remote file to a local location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores a local file to the remote location.", "response": "def store_file(self, remote_full_path, local_full_path_or_buffer):\n        \"\"\"\n        Transfers a local file to the remote location.\n\n        If local_full_path_or_buffer is a string path, the file will be read\n        from that location; if it is a file-like buffer, the file will\n        be read from the buffer but not closed.\n\n        :param remote_full_path: full path to the remote file\n        :type remote_full_path: str\n        :param local_full_path_or_buffer: full path to the local file or a\n            file-like buffer\n        :type local_full_path_or_buffer: str or file-like buffer\n        \"\"\"\n        conn = self.get_conn()\n\n        is_path = isinstance(local_full_path_or_buffer, basestring)\n\n        if is_path:\n            input_handle = open(local_full_path_or_buffer, 'rb')\n        else:\n            input_handle = local_full_path_or_buffer\n        remote_path, remote_file_name = os.path.split(remote_full_path)\n        conn.cwd(remote_path)\n        conn.storbinary('STOR %s' % remote_file_name, input_handle)\n\n        if is_path:\n            input_handle.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenames a file from name to name", "response": "def rename(self, from_name, to_name):\n        \"\"\"\n        Rename a file.\n\n        :param from_name: rename file from name\n        :param to_name: rename file to name\n        \"\"\"\n        conn = self.get_conn()\n        return conn.rename(from_name, to_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a datetime object representing the last time the file was modified.", "response": "def get_mod_time(self, path):\n        \"\"\"\n        Returns a datetime object representing the last time the file was modified\n\n        :param path: remote file path\n        :type path: string\n        \"\"\"\n        conn = self.get_conn()\n        ftp_mdtm = conn.sendcmd('MDTM ' + path)\n        time_val = ftp_mdtm[4:]\n        # time_val optionally has microseconds\n        try:\n            return datetime.datetime.strptime(time_val, \"%Y%m%d%H%M%S.%f\")\n        except ValueError:\n            return datetime.datetime.strptime(time_val, '%Y%m%d%H%M%S')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_dagruns(dag, execution_dates, state, run_id_template):\n    # find out if we need to create any dag runs\n    drs = DagRun.find(dag_id=dag.dag_id, execution_date=execution_dates)\n    dates_to_create = list(set(execution_dates) - set([dr.execution_date for dr in drs]))\n\n    for date in dates_to_create:\n        dr = dag.create_dagrun(\n            run_id=run_id_template.format(date.isoformat()),\n            execution_date=date,\n            start_date=timezone.utcnow(),\n            external_trigger=False,\n            state=state,\n        )\n        drs.append(dr)\n\n    return drs", "response": "Create all the dag runs for the given execution dates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the state of a task instance and if needed its relatives.", "response": "def set_state(task, execution_date, upstream=False, downstream=False,\n              future=False, past=False, state=State.SUCCESS, commit=False, session=None):\n    \"\"\"\n    Set the state of a task instance and if needed its relatives. Can set state\n    for future tasks (calculated from execution_date) and retroactively\n    for past tasks. Will verify integrity of past dag runs in order to create\n    tasks that did not exist. It will not create dag runs that are missing\n    on the schedule (but it will as for subdag dag runs if needed).\n    :param task: the task from which to work. task.task.dag needs to be set\n    :param execution_date: the execution date from which to start looking\n    :param upstream: Mark all parents (upstream tasks)\n    :param downstream: Mark all siblings (downstream tasks) of task_id, including SubDags\n    :param future: Mark all future tasks on the interval of the dag up until\n        last execution date.\n    :param past: Retroactively mark all tasks starting from start_date of the DAG\n    :param state: State to which the tasks need to be set\n    :param commit: Commit tasks to be altered to the database\n    :param session: database session\n    :return: list of tasks that have been created and updated\n    \"\"\"\n    assert timezone.is_localized(execution_date)\n\n    assert task.dag is not None\n    dag = task.dag\n\n    latest_execution_date = dag.latest_execution_date\n    assert latest_execution_date is not None\n\n    # determine date range of dag runs and tasks to consider\n    end_date = latest_execution_date if future else execution_date\n\n    if 'start_date' in dag.default_args:\n        start_date = dag.default_args['start_date']\n    elif dag.start_date:\n        start_date = dag.start_date\n    else:\n        start_date = execution_date\n\n    start_date = execution_date if not past else start_date\n\n    if dag.schedule_interval == '@once':\n        dates = [start_date]\n    else:\n        dates = dag.date_range(start_date=start_date, end_date=end_date)\n\n    # find relatives (siblings = downstream, parents = upstream) if needed\n    task_ids = [task.task_id]\n    if downstream:\n        relatives = task.get_flat_relatives(upstream=False)\n        task_ids += [t.task_id for t in relatives]\n    if upstream:\n        relatives = task.get_flat_relatives(upstream=True)\n        task_ids += [t.task_id for t in relatives]\n\n    # verify the integrity of the dag runs in case a task was added or removed\n    # set the confirmed execution dates as they might be different\n    # from what was provided\n    confirmed_dates = []\n    drs = DagRun.find(dag_id=dag.dag_id, execution_date=dates)\n    for dr in drs:\n        dr.dag = dag\n        dr.verify_integrity()\n        confirmed_dates.append(dr.execution_date)\n\n    # go through subdagoperators and create dag runs. We will only work\n    # within the scope of the subdag. We wont propagate to the parent dag,\n    # but we will propagate from parent to subdag.\n    dags = [dag]\n    sub_dag_ids = []\n    while len(dags) > 0:\n        current_dag = dags.pop()\n        for task_id in task_ids:\n            if not current_dag.has_task(task_id):\n                continue\n\n            current_task = current_dag.get_task(task_id)\n            if isinstance(current_task, SubDagOperator):\n                # this works as a kind of integrity check\n                # it creates missing dag runs for subdagoperators,\n                # maybe this should be moved to dagrun.verify_integrity\n                drs = _create_dagruns(current_task.subdag,\n                                      execution_dates=confirmed_dates,\n                                      state=State.RUNNING,\n                                      run_id_template=BackfillJob.ID_FORMAT_PREFIX)\n\n                for dr in drs:\n                    dr.dag = current_task.subdag\n                    dr.verify_integrity()\n                    if commit:\n                        dr.state = state\n                        session.merge(dr)\n\n                dags.append(current_task.subdag)\n                sub_dag_ids.append(current_task.subdag.dag_id)\n\n    # now look for the task instances that are affected\n    TI = TaskInstance\n\n    # get all tasks of the main dag that will be affected by a state change\n    qry_dag = session.query(TI).filter(\n        TI.dag_id == dag.dag_id,\n        TI.execution_date.in_(confirmed_dates),\n        TI.task_id.in_(task_ids)).filter(\n        or_(TI.state.is_(None),\n            TI.state != state)\n    )\n\n    # get *all* tasks of the sub dags\n    if len(sub_dag_ids) > 0:\n        qry_sub_dag = session.query(TI).filter(\n            TI.dag_id.in_(sub_dag_ids),\n            TI.execution_date.in_(confirmed_dates)).filter(\n            or_(TI.state.is_(None),\n                TI.state != state)\n        )\n\n    if commit:\n        tis_altered = qry_dag.with_for_update().all()\n        if len(sub_dag_ids) > 0:\n            tis_altered += qry_sub_dag.with_for_update().all()\n        for ti in tis_altered:\n            ti.state = state\n    else:\n        tis_altered = qry_dag.all()\n        if len(sub_dag_ids) > 0:\n            tis_altered += qry_sub_dag.all()\n\n    return tis_altered"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_dag_run_state(dag_id, execution_date, state, session=None):\n    DR = DagRun\n    dr = session.query(DR).filter(\n        DR.dag_id == dag_id,\n        DR.execution_date == execution_date\n    ).one()\n    dr.state = state\n    if state == State.RUNNING:\n        dr.start_date = timezone.utcnow()\n        dr.end_date = None\n    else:\n        dr.end_date = timezone.utcnow()\n    session.merge(dr)", "response": "Helper method that set the dag run state in the DB."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_dag_run_state_to_success(dag, execution_date, commit=False, session=None):\n    res = []\n\n    if not dag or not execution_date:\n        return res\n\n    # Mark the dag run to success.\n    if commit:\n        _set_dag_run_state(dag.dag_id, execution_date, State.SUCCESS, session)\n\n    # Mark all task instances of the dag run to success.\n    for task in dag.tasks:\n        task.dag = dag\n        new_state = set_state(task=task, execution_date=execution_date,\n                              state=State.SUCCESS, commit=commit)\n        res.extend(new_state)\n\n    return res", "response": "Set the dag run to success."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_dag_run_state_to_failed(dag, execution_date, commit=False, session=None):\n    res = []\n\n    if not dag or not execution_date:\n        return res\n\n    # Mark the dag run to failed.\n    if commit:\n        _set_dag_run_state(dag.dag_id, execution_date, State.FAILED, session)\n\n    # Mark only RUNNING task instances.\n    TI = TaskInstance\n    task_ids = [task.task_id for task in dag.tasks]\n    tis = session.query(TI).filter(\n        TI.dag_id == dag.dag_id,\n        TI.execution_date == execution_date,\n        TI.task_id.in_(task_ids)).filter(TI.state == State.RUNNING)\n    task_ids_of_running_tis = [ti.task_id for ti in tis]\n    for task in dag.tasks:\n        if task.task_id not in task_ids_of_running_tis:\n            continue\n        task.dag = dag\n        new_state = set_state(task=task, execution_date=execution_date,\n                              state=State.FAILED, commit=commit)\n        res.extend(new_state)\n\n    return res", "response": "Sets the dag run to failed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the dag run to running.", "response": "def set_dag_run_state_to_running(dag, execution_date, commit=False, session=None):\n    \"\"\"\n    Set the dag run for a specific execution date to running.\n    :param dag: the DAG of which to alter state\n    :param execution_date: the execution date from which to start looking\n    :param commit: commit DAG and tasks to be altered to the database\n    :param session: database session\n    :return: If commit is true, list of tasks that have been updated,\n             otherwise list of tasks that will be updated\n    \"\"\"\n    res = []\n    if not dag or not execution_date:\n        return res\n\n    # Mark the dag run to running.\n    if commit:\n        _set_dag_run_state(dag.dag_id, execution_date, State.RUNNING, session)\n\n    # To keep the return type consistent with the other similar functions.\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef git_version(version):\n    repo = None\n    try:\n        import git\n        repo = git.Repo('.git')\n    except ImportError:\n        logger.warning('gitpython not found: Cannot compute the git version.')\n        return ''\n    except Exception as e:\n        logger.warning('Cannot compute the git version. {}'.format(e))\n        return ''\n    if repo:\n        sha = repo.head.commit.hexsha\n        if repo.is_dirty():\n            return '.dev0+{sha}.dirty'.format(sha=sha)\n        # commit is clean\n        return '.release:{version}+{sha}'.format(version=version, sha=sha)\n    else:\n        return 'no_git_version'", "response": "Returns a version to identify the state of the git repo."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, context):\n        self.hook = DiscordWebhookHook(\n            self.http_conn_id,\n            self.webhook_endpoint,\n            self.message,\n            self.username,\n            self.avatar_url,\n            self.tts,\n            self.proxy\n        )\n        self.hook.execute()", "response": "Call the DiscordWebhookHook to post message"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the field is OK.", "response": "def _validate_field(self, validation_spec, dictionary_to_validate, parent=None,\n                        force_optional=False):\n        \"\"\"\n        Validates if field is OK.\n\n        :param validation_spec: specification of the field\n        :type validation_spec: dict\n        :param dictionary_to_validate: dictionary where the field should be present\n        :type dictionary_to_validate: dict\n        :param parent: full path of parent field\n        :type parent: str\n        :param force_optional: forces the field to be optional\n            (all union fields have force_optional set to True)\n        :type force_optional: bool\n        :return: True if the field is present\n        \"\"\"\n        field_name = validation_spec['name']\n        field_type = validation_spec.get('type')\n        optional = validation_spec.get('optional')\n        regexp = validation_spec.get('regexp')\n        allow_empty = validation_spec.get('allow_empty')\n        children_validation_specs = validation_spec.get('fields')\n        required_api_version = validation_spec.get('api_version')\n        custom_validation = validation_spec.get('custom_validation')\n\n        full_field_path = self._get_field_name_with_parent(field_name=field_name,\n                                                           parent=parent)\n        if required_api_version and required_api_version != self._api_version:\n            self.log.debug(\n                \"Skipping validation of the field '%s' for API version '%s' \"\n                \"as it is only valid for API version '%s'\",\n                field_name, self._api_version, required_api_version)\n            return False\n        value = dictionary_to_validate.get(field_name)\n\n        if (optional or force_optional) and value is None:\n            self.log.debug(\"The optional field '%s' is missing. That's perfectly OK.\", full_field_path)\n            return False\n\n        # Certainly down from here the field is present (value is not None)\n        # so we should only return True from now on\n\n        self._sanity_checks(children_validation_specs=children_validation_specs,\n                            field_type=field_type,\n                            full_field_path=full_field_path,\n                            regexp=regexp,\n                            allow_empty=allow_empty,\n                            custom_validation=custom_validation,\n                            value=value)\n\n        if allow_empty is False:\n            self._validate_is_empty(full_field_path, value)\n        if regexp:\n            self._validate_regexp(full_field_path, regexp, value)\n        elif field_type == 'dict':\n            if not isinstance(value, dict):\n                raise GcpFieldValidationException(\n                    \"The field '{}' should be of dictionary type according to the \"\n                    \"specification '{}' but it is '{}'\".\n                    format(full_field_path, validation_spec, value))\n            if children_validation_specs is None:\n                self.log.debug(\n                    \"The dict field '%s' has no nested fields defined in the \"\n                    \"specification '%s'. That's perfectly ok - it's content will \"\n                    \"not be validated.\", full_field_path, validation_spec)\n            else:\n                self._validate_dict(children_validation_specs, full_field_path, value)\n        elif field_type == 'union':\n            if not children_validation_specs:\n                raise GcpValidationSpecificationException(\n                    \"The union field '%s' has no nested fields \"\n                    \"defined in specification '%s'. Unions should have at least one \"\n                    \"nested field defined.\", full_field_path, validation_spec)\n            self._validate_union(children_validation_specs, full_field_path,\n                                 dictionary_to_validate)\n        elif field_type == 'list':\n            if not isinstance(value, list):\n                raise GcpFieldValidationException(\n                    \"The field '{}' should be of list type according to the \"\n                    \"specification '{}' but it is '{}'\".\n                    format(full_field_path, validation_spec, value))\n        elif custom_validation:\n            try:\n                custom_validation(value)\n            except Exception as e:\n                raise GcpFieldValidationException(\n                    \"Error while validating custom field '{}' specified by '{}': '{}'\".\n                    format(full_field_path, validation_spec, e))\n        elif field_type is None:\n            self.log.debug(\"The type of field '%s' is not specified in '%s'. \"\n                           \"Not validating its content.\", full_field_path, validation_spec)\n        else:\n            raise GcpValidationSpecificationException(\n                \"The field '{}' is of type '{}' in specification '{}'.\"\n                \"This type is unknown to validation!\".format(\n                    full_field_path, field_type, validation_spec))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, body_to_validate):\n        try:\n            for validation_spec in self._validation_specs:\n                self._validate_field(validation_spec=validation_spec,\n                                     dictionary_to_validate=body_to_validate)\n        except GcpFieldValidationException as e:\n            raise GcpFieldValidationException(\n                \"There was an error when validating: body '{}': '{}'\".\n                format(body_to_validate, e))\n        all_field_names = [spec['name'] for spec in self._validation_specs\n                           if spec.get('type') != 'union' and\n                           spec.get('api_version') != self._api_version]\n        all_union_fields = [spec for spec in self._validation_specs\n                            if spec.get('type') == 'union']\n        for union_field in all_union_fields:\n            all_field_names.extend(\n                [nested_union_spec['name'] for nested_union_spec in union_field['fields']\n                 if nested_union_spec.get('type') != 'union' and\n                 nested_union_spec.get('api_version') != self._api_version])\n        for field_name in body_to_validate.keys():\n            if field_name not in all_field_names:\n                self.log.warning(\n                    \"The field '%s' is in the body, but is not specified in the \"\n                    \"validation specification '%s'. \"\n                    \"This might be because you are using newer API version and \"\n                    \"new field names defined for that version. Then the warning \"\n                    \"can be safely ignored, or you might want to upgrade the operator\"\n                    \"to the version that supports the new API version.\",\n                    field_name, self._validation_specs)", "response": "Validates that the body of the object is well - formed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the FileService object.", "response": "def get_conn(self):\n        \"\"\"Return the FileService object.\"\"\"\n        conn = self.get_connection(self.conn_id)\n        service_options = conn.extra_dejson\n        return FileService(account_name=conn.login,\n                           account_key=conn.password, **service_options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a directory exists on Azure File Share.", "response": "def check_for_directory(self, share_name, directory_name, **kwargs):\n        \"\"\"\n        Check if a directory exists on Azure File Share.\n\n        :param share_name: Name of the share.\n        :type share_name: str\n        :param directory_name: Name of the directory.\n        :type directory_name: str\n        :param kwargs: Optional keyword arguments that\n            `FileService.exists()` takes.\n        :type kwargs: object\n        :return: True if the file exists, False otherwise.\n        :rtype: bool\n        \"\"\"\n        return self.connection.exists(share_name, directory_name,\n                                      **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a file exists on Azure File Share.", "response": "def check_for_file(self, share_name, directory_name, file_name, **kwargs):\n        \"\"\"\n        Check if a file exists on Azure File Share.\n\n        :param share_name: Name of the share.\n        :type share_name: str\n        :param directory_name: Name of the directory.\n        :type directory_name: str\n        :param file_name: Name of the file.\n        :type file_name: str\n        :param kwargs: Optional keyword arguments that\n            `FileService.exists()` takes.\n        :type kwargs: object\n        :return: True if the file exists, False otherwise.\n        :rtype: bool\n        \"\"\"\n        return self.connection.exists(share_name, directory_name,\n                                      file_name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of directories and files stored on a Azure File Share.", "response": "def list_directories_and_files(self, share_name, directory_name=None, **kwargs):\n        \"\"\"\n        Return the list of directories and files stored on a Azure File Share.\n\n        :param share_name: Name of the share.\n        :type share_name: str\n        :param directory_name: Name of the directory.\n        :type directory_name: str\n        :param kwargs: Optional keyword arguments that\n            `FileService.list_directories_and_files()` takes.\n        :type kwargs: object\n        :return: A list of files and directories\n        :rtype: list\n        \"\"\"\n        return self.connection.list_directories_and_files(share_name,\n                                                          directory_name,\n                                                          **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_directory(self, share_name, directory_name, **kwargs):\n        return self.connection.create_directory(share_name, directory_name, **kwargs)", "response": "Creates a new directory on a Azure File Share."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload a file from Azure File Share.", "response": "def get_file(self, file_path, share_name, directory_name, file_name, **kwargs):\n        \"\"\"\n        Download a file from Azure File Share.\n\n        :param file_path: Where to store the file.\n        :type file_path: str\n        :param share_name: Name of the share.\n        :type share_name: str\n        :param directory_name: Name of the directory.\n        :type directory_name: str\n        :param file_name: Name of the file.\n        :type file_name: str\n        :param kwargs: Optional keyword arguments that\n            `FileService.get_file_to_path()` takes.\n        :type kwargs: object\n        \"\"\"\n        self.connection.get_file_to_path(share_name, directory_name,\n                                         file_name, file_path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_file_to_stream(self, stream, share_name, directory_name, file_name, **kwargs):\n        self.connection.get_file_to_stream(share_name, directory_name,\n                                           file_name, stream, **kwargs)", "response": "Download a file from the given stream"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_file(self, file_path, share_name, directory_name, file_name, **kwargs):\n        self.connection.create_file_from_path(share_name, directory_name,\n                                              file_name, file_path, **kwargs)", "response": "Upload a file to an Azure File Share."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_string(self, string_data, share_name, directory_name, file_name, **kwargs):\n        self.connection.create_file_from_text(share_name, directory_name,\n                                              file_name, string_data, **kwargs)", "response": "This method uploads a string to the Azure File Share."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_stream(self, stream, share_name, directory_name, file_name, count, **kwargs):\n        self.connection.create_file_from_stream(share_name, directory_name,\n                                                file_name, stream, count, **kwargs)", "response": "Uploads a stream to the Azure File Share."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the file name and the logging handler to be used for airflow tasks.", "response": "def set_context(self, filename):\n        \"\"\"\n        Provide filename context to airflow task handler.\n        :param filename: filename in which the dag is located\n        \"\"\"\n        local_loc = self._init_file(filename)\n        self.handler = logging.FileHandler(local_loc)\n        self.handler.setFormatter(self.formatter)\n        self.handler.setLevel(self.level)\n\n        if self._cur_date < datetime.today():\n            self._symlink_latest_log_directory()\n            self._cur_date = datetime.today()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate log file and directory if required.", "response": "def _init_file(self, filename):\n        \"\"\"\n        Create log file and directory if required.\n        :param filename: task instance object\n        :return: relative log path of the given task instance\n        \"\"\"\n        relative_path = self._render_filename(filename)\n        full_path = os.path.join(self._get_log_directory(), relative_path)\n        directory = os.path.dirname(full_path)\n\n        if not os.path.exists(directory):\n            try:\n                os.makedirs(directory)\n            except OSError:\n                if not os.path.isdir(directory):\n                    raise\n\n        if not os.path.exists(full_path):\n            open(full_path, \"a\").close()\n\n        return full_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_gcs_url(gsurl):\n\n    parsed_url = urlparse(gsurl)\n    if not parsed_url.netloc:\n        raise AirflowException('Please provide a bucket name')\n    else:\n        bucket = parsed_url.netloc\n        # Remove leading '/' but NOT trailing one\n        blob = parsed_url.path.lstrip('/')\n        return bucket, blob", "response": "Given a Google Cloud Storage URL returns a tuple containing the corresponding bucket and blob name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_conn(self):\n        if not self._conn:\n            self._conn = storage.Client(credentials=self._get_credentials())\n\n        return self._conn", "response": "Returns a Google Cloud Storage service object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying an object from one bucket to another.", "response": "def copy(self, source_bucket, source_object, destination_bucket=None,\n             destination_object=None):\n        \"\"\"\n        Copies an object from a bucket to another, with renaming if requested.\n\n        destination_bucket or destination_object can be omitted, in which case\n        source bucket/object is used, but not both.\n\n        :param source_bucket: The bucket of the object to copy from.\n        :type source_bucket: str\n        :param source_object: The object to copy.\n        :type source_object: str\n        :param destination_bucket: The destination of the object to copied to.\n            Can be omitted; then the same bucket is used.\n        :type destination_bucket: str\n        :param destination_object: The (renamed) path of the object if given.\n            Can be omitted; then the same name is used.\n        :type destination_object: str\n        \"\"\"\n        destination_bucket = destination_bucket or source_bucket\n        destination_object = destination_object or source_object\n        if source_bucket == destination_bucket and \\\n                source_object == destination_object:\n\n            raise ValueError(\n                'Either source/destination bucket or source/destination object '\n                'must be different, not both the same: bucket=%s, object=%s' %\n                (source_bucket, source_object))\n        if not source_bucket or not source_object:\n            raise ValueError('source_bucket and source_object cannot be empty.')\n\n        client = self.get_conn()\n        source_bucket = client.get_bucket(source_bucket)\n        source_object = source_bucket.blob(source_object)\n        destination_bucket = client.get_bucket(destination_bucket)\n        destination_object = source_bucket.copy_blob(\n            blob=source_object,\n            destination_bucket=destination_bucket,\n            new_name=destination_object)\n\n        self.log.info('Object %s in bucket %s copied to object %s in bucket %s',\n                      source_object.name, source_bucket.name,\n                      destination_object.name, destination_bucket.name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhave the same functionality as copy, except that will work on files over 5 TB, as well as when copying between locations and/or storage classes. destination_object can be omitted, in which case source_object is used. :param source_bucket: The bucket of the object to copy from. :type source_bucket: str :param source_object: The object to copy. :type source_object: str :param destination_bucket: The destination of the object to copied to. :type destination_bucket: str :param destination_object: The (renamed) path of the object if given. Can be omitted; then the same name is used. :type destination_object: str", "response": "def rewrite(self, source_bucket, source_object, destination_bucket,\n                destination_object=None):\n        \"\"\"\n        Has the same functionality as copy, except that will work on files\n        over 5 TB, as well as when copying between locations and/or storage\n        classes.\n\n        destination_object can be omitted, in which case source_object is used.\n\n        :param source_bucket: The bucket of the object to copy from.\n        :type source_bucket: str\n        :param source_object: The object to copy.\n        :type source_object: str\n        :param destination_bucket: The destination of the object to copied to.\n        :type destination_bucket: str\n        :param destination_object: The (renamed) path of the object if given.\n            Can be omitted; then the same name is used.\n        :type destination_object: str\n        \"\"\"\n        destination_object = destination_object or source_object\n        if (source_bucket == destination_bucket and\n                source_object == destination_object):\n            raise ValueError(\n                'Either source/destination bucket or source/destination object '\n                'must be different, not both the same: bucket=%s, object=%s' %\n                (source_bucket, source_object))\n        if not source_bucket or not source_object:\n            raise ValueError('source_bucket and source_object cannot be empty.')\n\n        client = self.get_conn()\n        source_bucket = client.get_bucket(bucket_name=source_bucket)\n        source_object = source_bucket.blob(blob_name=source_object)\n        destination_bucket = client.get_bucket(bucket_name=destination_bucket)\n\n        token, bytes_rewritten, total_bytes = destination_bucket.blob(\n            blob_name=destination_object).rewrite(\n            source=source_object\n        )\n\n        self.log.info('Total Bytes: %s | Bytes Written: %s',\n                      total_bytes, bytes_rewritten)\n\n        while token is not None:\n            token, bytes_rewritten, total_bytes = destination_bucket.blob(\n                blob_name=destination_object).rewrite(\n                source=source_object, token=token\n            )\n\n            self.log.info('Total Bytes: %s | Bytes Written: %s',\n                          total_bytes, bytes_rewritten)\n        self.log.info('Object %s in bucket %s copied to object %s in bucket %s',\n                      source_object.name, source_bucket.name,\n                      destination_object, destination_bucket.name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download(self, bucket_name, object_name, filename=None):\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name)\n        blob = bucket.blob(blob_name=object_name)\n\n        if filename:\n            blob.download_to_filename(filename)\n            self.log.info('File downloaded to %s', filename)\n\n        return blob.download_as_string()", "response": "Download a file from Google Cloud Storage."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload(self, bucket_name, object_name, filename,\n               mime_type='application/octet-stream', gzip=False):\n        \"\"\"\n        Uploads a local file to Google Cloud Storage.\n\n        :param bucket_name: The bucket to upload to.\n        :type bucket_name: str\n        :param object_name: The object name to set when uploading the local file.\n        :type object_name: str\n        :param filename: The local file path to the file to be uploaded.\n        :type filename: str\n        :param mime_type: The MIME type to set when uploading the file.\n        :type mime_type: str\n        :param gzip: Option to compress file for upload\n        :type gzip: bool\n        \"\"\"\n\n        if gzip:\n            filename_gz = filename + '.gz'\n\n            with open(filename, 'rb') as f_in:\n                with gz.open(filename_gz, 'wb') as f_out:\n                    shutil.copyfileobj(f_in, f_out)\n                    filename = filename_gz\n\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n        blob = bucket.blob(blob_name=object_name)\n        blob.upload_from_filename(filename=filename,\n                                  content_type=mime_type)\n\n        if gzip:\n            os.remove(filename)\n        self.log.info('File %s uploaded to %s in %s bucket', filename, object_name, bucket_name)", "response": "Uploads a local file to Google Cloud Storage."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exists(self, bucket_name, object_name):\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n        blob = bucket.blob(blob_name=object_name)\n        return blob.exists()", "response": "Checks for the existence of a file in Google Cloud Storage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if an object is updated after a given timestamp.", "response": "def is_updated_after(self, bucket_name, object_name, ts):\n        \"\"\"\n        Checks if an blob_name is updated in Google Cloud Storage.\n\n        :param bucket_name: The Google cloud storage bucket where the object is.\n        :type bucket_name: str\n        :param object_name: The name of the object to check in the Google cloud\n            storage bucket.\n        :type object_name: str\n        :param ts: The timestamp to check against.\n        :type ts: datetime.datetime\n        \"\"\"\n        client = self.get_conn()\n        bucket = storage.Bucket(client=client, name=bucket_name)\n        blob = bucket.get_blob(blob_name=object_name)\n        blob.reload()\n\n        blob_update_time = blob.updated\n\n        if blob_update_time is not None:\n            import dateutil.tz\n\n            if not ts.tzinfo:\n                ts = ts.replace(tzinfo=dateutil.tz.tzutc())\n\n            self.log.info(\"Verify object date: %s > %s\", blob_update_time, ts)\n\n            if blob_update_time > ts:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting an object from the bucket.", "response": "def delete(self, bucket_name, object_name):\n        \"\"\"\n        Deletes an object from the bucket.\n\n        :param bucket_name: name of the bucket, where the object resides\n        :type bucket_name: str\n        :param object_name: name of the object to delete\n        :type object_name: str\n        \"\"\"\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n        blob = bucket.blob(blob_name=object_name)\n        blob.delete()\n\n        self.log.info('Blob %s deleted.', object_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all objects in a given bucket with the given string prefix in name", "response": "def list(self, bucket_name, versions=None, max_results=None, prefix=None, delimiter=None):\n        \"\"\"\n        List all objects from the bucket with the give string prefix in name\n\n        :param bucket_name: bucket name\n        :type bucket_name: str\n        :param versions: if true, list all versions of the objects\n        :type versions: bool\n        :param max_results: max count of items to return in a single page of responses\n        :type max_results: int\n        :param prefix: prefix string which filters objects whose name begin with\n            this prefix\n        :type prefix: str\n        :param delimiter: filters objects based on the delimiter (for e.g '.csv')\n        :type delimiter: str\n        :return: a stream of object names matching the filtering criteria\n        \"\"\"\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n\n        ids = []\n        pageToken = None\n        while True:\n            blobs = bucket.list_blobs(\n                max_results=max_results,\n                page_token=pageToken,\n                prefix=prefix,\n                delimiter=delimiter,\n                versions=versions\n            )\n\n            blob_names = []\n            for blob in blobs:\n                blob_names.append(blob.name)\n\n            prefixes = blobs.prefixes\n            if prefixes:\n                ids += list(prefixes)\n            else:\n                ids += blob_names\n\n            pageToken = blobs.next_page_token\n            if pageToken is None:\n                # empty next page token\n                break\n        return ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_size(self, bucket_name, object_name):\n        self.log.info('Checking the file size of object: %s in bucket_name: %s',\n                      object_name,\n                      bucket_name)\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n        blob = bucket.get_blob(blob_name=object_name)\n        blob.reload()\n        blob_size = blob.size\n        self.log.info('The file size of %s is %s bytes.', object_name, blob_size)\n        return blob_size", "response": "Gets the size of a file in Google Cloud Storage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the CRC32c checksum of an object in Google Cloud Storage bucket.", "response": "def get_crc32c(self, bucket_name, object_name):\n        \"\"\"\n        Gets the CRC32c checksum of an object in Google Cloud Storage.\n\n        :param bucket_name: The Google cloud storage bucket where the blob_name is.\n        :type bucket_name: str\n        :param object_name: The name of the object to check in the Google cloud\n            storage bucket_name.\n        :type object_name: str\n        \"\"\"\n        self.log.info('Retrieving the crc32c checksum of '\n                      'object_name: %s in bucket_name: %s', object_name, bucket_name)\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n        blob = bucket.get_blob(blob_name=object_name)\n        blob.reload()\n        blob_crc32c = blob.crc32c\n        self.log.info('The crc32c checksum of %s is %s', object_name, blob_crc32c)\n        return blob_crc32c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the MD5 hash of an object in Google Cloud Storage bucket.", "response": "def get_md5hash(self, bucket_name, object_name):\n        \"\"\"\n        Gets the MD5 hash of an object in Google Cloud Storage.\n\n        :param bucket_name: The Google cloud storage bucket where the blob_name is.\n        :type bucket_name: str\n        :param object_name: The name of the object to check in the Google cloud\n            storage bucket_name.\n        :type object_name: str\n        \"\"\"\n        self.log.info('Retrieving the MD5 hash of '\n                      'object: %s in bucket: %s', object_name, bucket_name)\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name=bucket_name)\n        blob = bucket.get_blob(blob_name=object_name)\n        blob.reload()\n        blob_md5hash = blob.md5_hash\n        self.log.info('The md5Hash of %s is %s', object_name, blob_md5hash)\n        return blob_md5hash"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_bucket(self,\n                      bucket_name,\n                      resource=None,\n                      storage_class='MULTI_REGIONAL',\n                      location='US',\n                      project_id=None,\n                      labels=None\n                      ):\n        \"\"\"\n        Creates a new bucket. Google Cloud Storage uses a flat namespace, so\n        you can't create a bucket with a name that is already in use.\n\n        .. seealso::\n            For more information, see Bucket Naming Guidelines:\n            https://cloud.google.com/storage/docs/bucketnaming.html#requirements\n\n        :param bucket_name: The name of the bucket.\n        :type bucket_name: str\n        :param resource: An optional dict with parameters for creating the bucket.\n            For information on available parameters, see Cloud Storage API doc:\n            https://cloud.google.com/storage/docs/json_api/v1/buckets/insert\n        :type resource: dict\n        :param storage_class: This defines how objects in the bucket are stored\n            and determines the SLA and the cost of storage. Values include\n\n            - ``MULTI_REGIONAL``\n            - ``REGIONAL``\n            - ``STANDARD``\n            - ``NEARLINE``\n            - ``COLDLINE``.\n\n            If this value is not specified when the bucket is\n            created, it will default to STANDARD.\n        :type storage_class: str\n        :param location: The location of the bucket.\n            Object data for objects in the bucket resides in physical storage\n            within this region. Defaults to US.\n\n            .. seealso::\n                https://developers.google.com/storage/docs/bucket-locations\n\n        :type location: str\n        :param project_id: The ID of the GCP Project.\n        :type project_id: str\n        :param labels: User-provided labels, in key/value pairs.\n        :type labels: dict\n        :return: If successful, it returns the ``id`` of the bucket.\n        \"\"\"\n\n        self.log.info('Creating Bucket: %s; Location: %s; Storage Class: %s',\n                      bucket_name, location, storage_class)\n\n        client = self.get_conn()\n        bucket = client.bucket(bucket_name=bucket_name)\n        bucket_resource = resource or {}\n\n        for item in bucket_resource:\n            if item != \"name\":\n                bucket._patch_property(name=item, value=resource[item])\n\n        bucket.storage_class = storage_class\n        bucket.labels = labels or {}\n        bucket.create(project=project_id, location=location)\n        return bucket.id", "response": "Creates a new bucket in Google Cloud Storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_bucket_acl(self, bucket_name, entity, role, user_project=None):\n        self.log.info('Creating a new ACL entry in bucket: %s', bucket_name)\n        client = self.get_conn()\n        bucket = client.bucket(bucket_name=bucket_name)\n        bucket.acl.reload()\n        bucket.acl.entity_from_dict(entity_dict={\"entity\": entity, \"role\": role})\n        if user_project:\n            bucket.acl.user_project = user_project\n        bucket.acl.save()\n\n        self.log.info('A new ACL entry created in bucket: %s', bucket_name)", "response": "Inserts a new ACL entry on the specified bucket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert an object acl entry on the specified object in the specified bucket.", "response": "def insert_object_acl(self, bucket_name, object_name, entity, role, user_project=None):\n        \"\"\"\n        Creates a new ACL entry on the specified object.\n        See: https://cloud.google.com/storage/docs/json_api/v1/objectAccessControls/insert\n\n        :param bucket_name: Name of a bucket_name.\n        :type bucket_name: str\n        :param object_name: Name of the object. For information about how to URL encode\n            object names to be path safe, see:\n            https://cloud.google.com/storage/docs/json_api/#encoding\n        :type object_name: str\n        :param entity: The entity holding the permission, in one of the following forms:\n            user-userId, user-email, group-groupId, group-email, domain-domain,\n            project-team-projectId, allUsers, allAuthenticatedUsers\n            See: https://cloud.google.com/storage/docs/access-control/lists#scopes\n        :type entity: str\n        :param role: The access permission for the entity.\n            Acceptable values are: \"OWNER\", \"READER\".\n        :type role: str\n        :param user_project: (Optional) The project to be billed for this request.\n            Required for Requester Pays buckets.\n        :type user_project: str\n        \"\"\"\n        self.log.info('Creating a new ACL entry for object: %s in bucket: %s',\n                      object_name, bucket_name)\n        client = self.get_conn()\n        bucket = client.bucket(bucket_name=bucket_name)\n        blob = bucket.blob(object_name)\n        # Reload fetches the current ACL from Cloud Storage.\n        blob.acl.reload()\n        blob.acl.entity_from_dict(entity_dict={\"entity\": entity, \"role\": role})\n        if user_project:\n            blob.acl.user_project = user_project\n        blob.acl.save()\n\n        self.log.info('A new ACL entry created for object: %s in bucket: %s',\n                      object_name, bucket_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compose(self, bucket_name, source_objects, destination_object):\n\n        if not source_objects or not len(source_objects):\n            raise ValueError('source_objects cannot be empty.')\n\n        if not bucket_name or not destination_object:\n            raise ValueError('bucket_name and destination_object cannot be empty.')\n\n        self.log.info(\"Composing %s to %s in the bucket %s\",\n                      source_objects, destination_object, bucket_name)\n        client = self.get_conn()\n        bucket = client.get_bucket(bucket_name)\n        destination_blob = bucket.blob(destination_object)\n        destination_blob.compose(\n            sources=[\n                bucket.blob(blob_name=source_object) for source_object in source_objects\n            ])\n\n        self.log.info(\"Completed successfully.\")", "response": "This method is used to compose a list of existing object into a new object in the same storage bucket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef argmin(arr, f):\n    m = None\n    i = None\n    for idx, item in enumerate(arr):\n        if item is not None:\n            if m is None or f(item) < m:\n                m = f(item)\n                i = idx\n    return i", "response": "Return the index i in arr that minimizes f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the secondary status message of a training job has changed.", "response": "def secondary_training_status_changed(current_job_description, prev_job_description):\n    \"\"\"\n    Returns true if training job's secondary status message has changed.\n\n    :param current_job_description: Current job description, returned from DescribeTrainingJob call.\n    :type current_job_description: dict\n    :param prev_job_description: Previous job description, returned from DescribeTrainingJob call.\n    :type prev_job_description: dict\n\n    :return: Whether the secondary status message of a training job changed or not.\n    \"\"\"\n    current_secondary_status_transitions = current_job_description.get('SecondaryStatusTransitions')\n    if current_secondary_status_transitions is None or len(current_secondary_status_transitions) == 0:\n        return False\n\n    prev_job_secondary_status_transitions = prev_job_description.get('SecondaryStatusTransitions') \\\n        if prev_job_description is not None else None\n\n    last_message = prev_job_secondary_status_transitions[-1]['StatusMessage'] \\\n        if prev_job_secondary_status_transitions is not None \\\n        and len(prev_job_secondary_status_transitions) > 0 else ''\n\n    message = current_job_description['SecondaryStatusTransitions'][-1]['StatusMessage']\n\n    return message != last_message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string containing the start time and the secondary training job status message.", "response": "def secondary_training_status_message(job_description, prev_description):\n    \"\"\"\n    Returns a string contains start time and the secondary training job status message.\n\n    :param job_description: Returned response from DescribeTrainingJob call\n    :type job_description: dict\n    :param prev_description: Previous job description from DescribeTrainingJob call\n    :type prev_description: dict\n\n    :return: Job status string to be printed.\n    \"\"\"\n\n    if job_description is None or job_description.get('SecondaryStatusTransitions') is None\\\n            or len(job_description.get('SecondaryStatusTransitions')) == 0:\n        return ''\n\n    prev_description_secondary_transitions = prev_description.get('SecondaryStatusTransitions')\\\n        if prev_description is not None else None\n    prev_transitions_num = len(prev_description['SecondaryStatusTransitions'])\\\n        if prev_description_secondary_transitions is not None else 0\n    current_transitions = job_description['SecondaryStatusTransitions']\n\n    transitions_to_print = current_transitions[-1:] if len(current_transitions) == prev_transitions_num else \\\n        current_transitions[prev_transitions_num - len(current_transitions):]\n\n    status_strs = []\n    for transition in transitions_to_print:\n        message = transition['StatusMessage']\n        time_str = timezone.convert_to_utc(job_description['LastModifiedTime']).strftime('%Y-%m-%d %H:%M:%S')\n        status_strs.append('{} {} - {}'.format(time_str, transition['Status'], message))\n\n    return '\\n'.join(status_strs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tar_and_s3_upload(self, path, key, bucket):\n        with tempfile.TemporaryFile() as temp_file:\n            if os.path.isdir(path):\n                files = [os.path.join(path, name) for name in os.listdir(path)]\n            else:\n                files = [path]\n            with tarfile.open(mode='w:gz', fileobj=temp_file) as tar_file:\n                for f in files:\n                    tar_file.add(f, arcname=os.path.basename(f))\n            temp_file.seek(0)\n            self.s3_hook.load_file_obj(temp_file, key, bucket, replace=True)", "response": "Tar the local file or directory and upload to s3"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the SageMaker operation s S3 resources.", "response": "def configure_s3_resources(self, config):\n        \"\"\"\n        Extract the S3 operations from the configuration and execute them.\n\n        :param config: config of SageMaker operation\n        :type config: dict\n        :rtype: dict\n        \"\"\"\n        s3_operations = config.pop('S3Operations', None)\n\n        if s3_operations is not None:\n            create_bucket_ops = s3_operations.get('S3CreateBucket', [])\n            upload_ops = s3_operations.get('S3Upload', [])\n            for op in create_bucket_ops:\n                self.s3_hook.create_bucket(bucket_name=op['Bucket'])\n            for op in upload_ops:\n                if op['Tar']:\n                    self.tar_and_s3_upload(op['Path'], op['Key'],\n                                           op['Bucket'])\n                else:\n                    self.s3_hook.load_file(op['Path'], op['Key'],\n                                           op['Bucket'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if an S3 URL exists in the Airflow database.", "response": "def check_s3_url(self, s3url):\n        \"\"\"\n        Check if an S3 URL exists\n\n        :param s3url: S3 url\n        :type s3url: str\n        :rtype: bool\n        \"\"\"\n        bucket, key = S3Hook.parse_s3_url(s3url)\n        if not self.s3_hook.check_for_bucket(bucket_name=bucket):\n            raise AirflowException(\n                \"The input S3 Bucket {} does not exist \".format(bucket))\n        if key and not self.s3_hook.check_for_key(key=key, bucket_name=bucket)\\\n           and not self.s3_hook.check_for_prefix(\n                prefix=key, bucket_name=bucket, delimiter='/'):\n            # check if s3 key exists in the case user provides a single file\n            # or if s3 prefix exists in the case user provides multiple files in\n            # a prefix\n            raise AirflowException(\"The input S3 Key \"\n                                   \"or Prefix {} does not exist in the Bucket {}\"\n                                   .format(s3url, bucket))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_log_conn(self):\n        config = botocore.config.Config(retries={'max_attempts': 15})\n        return self.get_client_type('logs', config=config)", "response": "Establish an AWS connection to retrieve logs during training\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_training_job(self, config, wait_for_completion=True, print_log=True,\n                            check_interval=30, max_ingestion_time=None):\n        \"\"\"\n        Create a training job\n\n        :param config: the config for training\n        :type config: dict\n        :param wait_for_completion: if the program should keep running until job finishes\n        :type wait_for_completion: bool\n        :param check_interval: the time interval in seconds which the operator\n            will check the status of any SageMaker job\n        :type check_interval: int\n        :param max_ingestion_time: the maximum ingestion time in seconds. Any\n            SageMaker jobs that run longer than this will fail. Setting this to\n            None implies no timeout for any SageMaker job.\n        :type max_ingestion_time: int\n        :return: A response to training job creation\n        \"\"\"\n\n        self.check_training_config(config)\n\n        response = self.get_conn().create_training_job(**config)\n        if print_log:\n            self.check_training_status_with_log(config['TrainingJobName'],\n                                                self.non_terminal_states,\n                                                self.failed_states,\n                                                wait_for_completion,\n                                                check_interval, max_ingestion_time\n                                                )\n        elif wait_for_completion:\n            describe_response = self.check_status(config['TrainingJobName'],\n                                                  'TrainingJobStatus',\n                                                  self.describe_training_job,\n                                                  check_interval, max_ingestion_time\n                                                  )\n\n            billable_time = \\\n                (describe_response['TrainingEndTime'] - describe_response['TrainingStartTime']) * \\\n                describe_response['ResourceConfig']['InstanceCount']\n            self.log.info('Billable seconds:{}'.format(int(billable_time.total_seconds()) + 1))\n\n        return response", "response": "Create a training job and return the response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_tuning_job(self, config, wait_for_completion=True,\n                          check_interval=30, max_ingestion_time=None):\n        \"\"\"\n        Create a tuning job\n\n        :param config: the config for tuning\n        :type config: dict\n        :param wait_for_completion: if the program should keep running until job finishes\n        :type wait_for_completion: bool\n        :param check_interval: the time interval in seconds which the operator\n            will check the status of any SageMaker job\n        :type check_interval: int\n        :param max_ingestion_time: the maximum ingestion time in seconds. Any\n            SageMaker jobs that run longer than this will fail. Setting this to\n            None implies no timeout for any SageMaker job.\n        :type max_ingestion_time: int\n        :return: A response to tuning job creation\n        \"\"\"\n\n        self.check_tuning_config(config)\n\n        response = self.get_conn().create_hyper_parameter_tuning_job(**config)\n        if wait_for_completion:\n            self.check_status(config['HyperParameterTuningJobName'],\n                              'HyperParameterTuningJobStatus',\n                              self.describe_tuning_job,\n                              check_interval, max_ingestion_time\n                              )\n        return response", "response": "Create a tuning job in SageMaker"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_transform_job(self, config, wait_for_completion=True,\n                             check_interval=30, max_ingestion_time=None):\n        \"\"\"\n        Create a transform job\n\n        :param config: the config for transform job\n        :type config: dict\n        :param wait_for_completion: if the program should keep running until job finishes\n        :type wait_for_completion: bool\n        :param check_interval: the time interval in seconds which the operator\n            will check the status of any SageMaker job\n        :type check_interval: int\n        :param max_ingestion_time: the maximum ingestion time in seconds. Any\n            SageMaker jobs that run longer than this will fail. Setting this to\n            None implies no timeout for any SageMaker job.\n        :type max_ingestion_time: int\n        :return: A response to transform job creation\n        \"\"\"\n\n        self.check_s3_url(config['TransformInput']['DataSource']['S3DataSource']['S3Uri'])\n\n        response = self.get_conn().create_transform_job(**config)\n        if wait_for_completion:\n            self.check_status(config['TransformJobName'],\n                              'TransformJobStatus',\n                              self.describe_transform_job,\n                              check_interval, max_ingestion_time\n                              )\n        return response", "response": "Create a transform job"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an endpoint in SageMaker", "response": "def create_endpoint(self, config, wait_for_completion=True,\n                        check_interval=30, max_ingestion_time=None):\n        \"\"\"\n        Create an endpoint\n\n        :param config: the config for endpoint\n        :type config: dict\n        :param wait_for_completion: if the program should keep running until job finishes\n        :type wait_for_completion: bool\n        :param check_interval: the time interval in seconds which the operator\n            will check the status of any SageMaker job\n        :type check_interval: int\n        :param max_ingestion_time: the maximum ingestion time in seconds. Any\n            SageMaker jobs that run longer than this will fail. Setting this to\n            None implies no timeout for any SageMaker job.\n        :type max_ingestion_time: int\n        :return: A response to endpoint creation\n        \"\"\"\n\n        response = self.get_conn().create_endpoint(**config)\n        if wait_for_completion:\n            self.check_status(config['EndpointName'],\n                              'EndpointStatus',\n                              self.describe_endpoint,\n                              check_interval, max_ingestion_time,\n                              non_terminal_states=self.endpoint_non_terminal_states\n                              )\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the training job info associated with job_name and print CloudWatch logs.", "response": "def describe_training_job_with_log(self, job_name, positions, stream_names,\n                                       instance_count, state, last_description,\n                                       last_describe_job_call):\n        \"\"\"\n        Return the training job info associated with job_name and print CloudWatch logs\n        \"\"\"\n        log_group = '/aws/sagemaker/TrainingJobs'\n\n        if len(stream_names) < instance_count:\n            # Log streams are created whenever a container starts writing to stdout/err, so this list\n            # may be dynamic until we have a stream for every instance.\n            logs_conn = self.get_log_conn()\n            try:\n                streams = logs_conn.describe_log_streams(\n                    logGroupName=log_group,\n                    logStreamNamePrefix=job_name + '/',\n                    orderBy='LogStreamName',\n                    limit=instance_count\n                )\n                stream_names = [s['logStreamName'] for s in streams['logStreams']]\n                positions.update([(s, Position(timestamp=0, skip=0))\n                                  for s in stream_names if s not in positions])\n            except logs_conn.exceptions.ResourceNotFoundException:\n                # On the very first training job run on an account, there's no log group until\n                # the container starts logging, so ignore any errors thrown about that\n                pass\n\n        if len(stream_names) > 0:\n            for idx, event in self.multi_stream_iter(log_group, stream_names, positions):\n                self.log.info(event['message'])\n                ts, count = positions[stream_names[idx]]\n                if event['timestamp'] == ts:\n                    positions[stream_names[idx]] = Position(timestamp=ts, skip=count + 1)\n                else:\n                    positions[stream_names[idx]] = Position(timestamp=event['timestamp'], skip=1)\n\n        if state == LogState.COMPLETE:\n            return state, last_description, last_describe_job_call\n\n        if state == LogState.JOB_COMPLETE:\n            state = LogState.COMPLETE\n        elif time.time() - last_describe_job_call >= 30:\n            description = self.describe_training_job(job_name)\n            last_describe_job_call = time.time()\n\n            if secondary_training_status_changed(description, last_description):\n                self.log.info(secondary_training_status_message(description, last_description))\n                last_description = description\n\n            status = description['TrainingJobStatus']\n\n            if status not in self.non_terminal_states:\n                state = LogState.JOB_COMPLETE\n        return state, last_description, last_describe_job_call"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the status of a SageMaker job", "response": "def check_status(self, job_name, key,\n                     describe_function, check_interval,\n                     max_ingestion_time,\n                     non_terminal_states=None):\n        \"\"\"\n        Check status of a SageMaker job\n\n        :param job_name: name of the job to check status\n        :type job_name: str\n        :param key: the key of the response dict\n            that points to the state\n        :type key: str\n        :param describe_function: the function used to retrieve the status\n        :type describe_function: python callable\n        :param args: the arguments for the function\n        :param check_interval: the time interval in seconds which the operator\n            will check the status of any SageMaker job\n        :type check_interval: int\n        :param max_ingestion_time: the maximum ingestion time in seconds. Any\n            SageMaker jobs that run longer than this will fail. Setting this to\n            None implies no timeout for any SageMaker job.\n        :type max_ingestion_time: int\n        :param non_terminal_states: the set of nonterminal states\n        :type non_terminal_states: set\n        :return: response of describe call after job is done\n        \"\"\"\n        if not non_terminal_states:\n            non_terminal_states = self.non_terminal_states\n\n        sec = 0\n        running = True\n\n        while running:\n            time.sleep(check_interval)\n            sec = sec + check_interval\n\n            try:\n                response = describe_function(job_name)\n                status = response[key]\n                self.log.info('Job still running for %s seconds... '\n                              'current status is %s' % (sec, status))\n            except KeyError:\n                raise AirflowException('Could not get status of the SageMaker job')\n            except ClientError:\n                raise AirflowException('AWS request failed, check logs for more info')\n\n            if status in non_terminal_states:\n                running = True\n            elif status in self.failed_states:\n                raise AirflowException('SageMaker job failed because %s' % response['FailureReason'])\n            else:\n                running = False\n\n            if max_ingestion_time and sec > max_ingestion_time:\n                # ensure that the job gets killed if the max ingestion time is exceeded\n                raise AirflowException('SageMaker job took more than %s seconds', max_ingestion_time)\n\n        self.log.info('SageMaker Job Compeleted')\n        response = describe_function(job_name)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the training status of a given job and display the logs for the training job.", "response": "def check_training_status_with_log(self, job_name, non_terminal_states, failed_states,\n                                       wait_for_completion, check_interval, max_ingestion_time):\n        \"\"\"\n        Display the logs for a given training job, optionally tailing them until the\n        job is complete.\n\n        :param job_name: name of the training job to check status and display logs for\n        :type job_name: str\n        :param non_terminal_states: the set of non_terminal states\n        :type non_terminal_states: set\n        :param failed_states: the set of failed states\n        :type failed_states: set\n        :param wait_for_completion: Whether to keep looking for new log entries\n            until the job completes\n        :type wait_for_completion: bool\n        :param check_interval: The interval in seconds between polling for new log entries and job completion\n        :type check_interval: int\n        :param max_ingestion_time: the maximum ingestion time in seconds. Any\n            SageMaker jobs that run longer than this will fail. Setting this to\n            None implies no timeout for any SageMaker job.\n        :type max_ingestion_time: int\n        :return: None\n        \"\"\"\n\n        sec = 0\n        description = self.describe_training_job(job_name)\n        self.log.info(secondary_training_status_message(description, None))\n        instance_count = description['ResourceConfig']['InstanceCount']\n        status = description['TrainingJobStatus']\n\n        stream_names = []  # The list of log streams\n        positions = {}     # The current position in each stream, map of stream name -> position\n\n        job_already_completed = status not in non_terminal_states\n\n        state = LogState.TAILING if wait_for_completion and not job_already_completed else LogState.COMPLETE\n\n        # The loop below implements a state machine that alternates between checking the job status and\n        # reading whatever is available in the logs at this point. Note, that if we were called with\n        # wait_for_completion == False, we never check the job status.\n        #\n        # If wait_for_completion == TRUE and job is not completed, the initial state is TAILING\n        # If wait_for_completion == FALSE, the initial state is COMPLETE\n        # (doesn't matter if the job really is complete).\n        #\n        # The state table:\n        #\n        # STATE               ACTIONS                        CONDITION             NEW STATE\n        # ----------------    ----------------               -----------------     ----------------\n        # TAILING             Read logs, Pause, Get status   Job complete          JOB_COMPLETE\n        #                                                    Else                  TAILING\n        # JOB_COMPLETE        Read logs, Pause               Any                   COMPLETE\n        # COMPLETE            Read logs, Exit                                      N/A\n        #\n        # Notes:\n        # - The JOB_COMPLETE state forces us to do an extra pause and read any items that\n        # got to Cloudwatch after the job was marked complete.\n        last_describe_job_call = time.time()\n        last_description = description\n\n        while True:\n            time.sleep(check_interval)\n            sec = sec + check_interval\n\n            state, last_description, last_describe_job_call = \\\n                self.describe_training_job_with_log(job_name, positions, stream_names,\n                                                    instance_count, state, last_description,\n                                                    last_describe_job_call)\n            if state == LogState.COMPLETE:\n                break\n\n            if max_ingestion_time and sec > max_ingestion_time:\n                # ensure that the job gets killed if the max ingestion time is exceeded\n                raise AirflowException('SageMaker job took more than %s seconds', max_ingestion_time)\n\n        if wait_for_completion:\n            status = last_description['TrainingJobStatus']\n            if status in failed_states:\n                reason = last_description.get('FailureReason', '(No reason provided)')\n                raise AirflowException('Error training {}: {} Reason: {}'.format(job_name, status, reason))\n            billable_time = (last_description['TrainingEndTime'] - last_description['TrainingStartTime']) \\\n                * instance_count\n            self.log.info('Billable seconds:{}'.format(int(billable_time.total_seconds()) + 1))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the python dataflow job.", "response": "def execute(self, context):\n        \"\"\"Execute the python dataflow job.\"\"\"\n        bucket_helper = GoogleCloudBucketHelper(\n            self.gcp_conn_id, self.delegate_to)\n        self.py_file = bucket_helper.google_cloud_to_local(self.py_file)\n        hook = DataFlowHook(gcp_conn_id=self.gcp_conn_id,\n                            delegate_to=self.delegate_to,\n                            poll_sleep=self.poll_sleep)\n        dataflow_options = self.dataflow_default_options.copy()\n        dataflow_options.update(self.options)\n        # Convert argument names from lowerCamelCase to snake case.\n        camel_to_snake = lambda name: re.sub(\n            r'[A-Z]', lambda x: '_' + x.group(0).lower(), name)\n        formatted_options = {camel_to_snake(key): dataflow_options[key]\n                             for key in dataflow_options}\n        hook.start_python_dataflow(\n            self.job_name, formatted_options,\n            self.py_file, self.py_options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads the file specified by file_name and saves it locally.", "response": "def google_cloud_to_local(self, file_name):\n        \"\"\"\n        Checks whether the file specified by file_name is stored in Google Cloud\n        Storage (GCS), if so, downloads the file and saves it locally. The full\n        path of the saved file will be returned. Otherwise the local file_name\n        will be returned immediately.\n\n        :param file_name: The full path of input file.\n        :type file_name: str\n        :return: The full path of local file.\n        :rtype: str\n        \"\"\"\n        if not file_name.startswith('gs://'):\n            return file_name\n\n        # Extracts bucket_id and object_id by first removing 'gs://' prefix and\n        # then split the remaining by path delimiter '/'.\n        path_components = file_name[self.GCS_PREFIX_LENGTH:].split('/')\n        if len(path_components) < 2:\n            raise Exception(\n                'Invalid Google Cloud Storage (GCS) object path: {}'\n                .format(file_name))\n\n        bucket_id = path_components[0]\n        object_id = '/'.join(path_components[1:])\n        local_file = '/tmp/dataflow{}-{}'.format(str(uuid.uuid4())[:8],\n                                                 path_components[-1])\n        self._gcs_hook.download(bucket_id, object_id, local_file)\n\n        if os.stat(local_file).st_size > 0:\n            return local_file\n        raise Exception(\n            'Failed to download Google Cloud Storage (GCS) object: {}'\n            .format(file_name))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_migrations_offline():\n    context.configure(\n        url=settings.SQL_ALCHEMY_CONN, target_metadata=target_metadata,\n        literal_binds=True, compare_type=COMPARE_TYPE)\n\n    with context.begin_transaction():\n        context.run_migrations()", "response": "Run migrations in offline mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_migrations_online():\n    connectable = settings.engine\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            transaction_per_migration=True,\n            target_metadata=target_metadata,\n            compare_type=COMPARE_TYPE,\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()", "response": "Run migrations in online mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes the specified instance from the Cloud Bigtable.", "response": "def delete_instance(self, instance_id, project_id=None):\n        \"\"\"\n        Deletes the specified Cloud Bigtable instance.\n        Raises google.api_core.exceptions.NotFound if the Cloud Bigtable instance does\n        not exist.\n\n        :param project_id: Optional, Google Cloud Platform project ID where the\n            BigTable exists. If set to None or missing,\n            the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance_id: The ID of the Cloud Bigtable instance.\n        :type instance_id: str\n        \"\"\"\n        instance = self.get_instance(instance_id=instance_id, project_id=project_id)\n        if instance:\n            instance.delete()\n        else:\n            self.log.info(\"The instance '%s' does not exist in project '%s'. Exiting\", instance_id,\n                          project_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_instance(self,\n                        instance_id,\n                        main_cluster_id,\n                        main_cluster_zone,\n                        project_id=None,\n                        replica_cluster_id=None,\n                        replica_cluster_zone=None,\n                        instance_display_name=None,\n                        instance_type=enums.Instance.Type.TYPE_UNSPECIFIED,\n                        instance_labels=None,\n                        cluster_nodes=None,\n                        cluster_storage_type=enums.StorageType.STORAGE_TYPE_UNSPECIFIED,\n                        timeout=None):\n        \"\"\"\n        Creates new instance.\n\n        :type instance_id: str\n        :param instance_id: The ID for the new instance.\n        :type main_cluster_id: str\n        :param main_cluster_id: The ID for main cluster for the new instance.\n        :type main_cluster_zone: str\n        :param main_cluster_zone: The zone for main cluster.\n            See https://cloud.google.com/bigtable/docs/locations for more details.\n        :type project_id: str\n        :param project_id: Optional, Google Cloud Platform project ID where the\n            BigTable exists. If set to None or missing,\n            the default project_id from the GCP connection is used.\n        :type replica_cluster_id: str\n        :param replica_cluster_id: (optional) The ID for replica cluster for the new\n            instance.\n        :type replica_cluster_zone: str\n        :param replica_cluster_zone: (optional)  The zone for replica cluster.\n        :type instance_type: enums.Instance.Type\n        :param instance_type: (optional) The type of the instance.\n        :type instance_display_name: str\n        :param instance_display_name: (optional) Human-readable name of the instance.\n                Defaults to ``instance_id``.\n        :type instance_labels: dict\n        :param instance_labels: (optional) Dictionary of labels to associate with the\n            instance.\n        :type cluster_nodes: int\n        :param cluster_nodes: (optional) Number of nodes for cluster.\n        :type cluster_storage_type: enums.StorageType\n        :param cluster_storage_type: (optional) The type of storage.\n        :type timeout: int\n        :param timeout: (optional) timeout (in seconds) for instance creation.\n                        If None is not specified, Operator will wait indefinitely.\n        \"\"\"\n        cluster_storage_type = enums.StorageType(cluster_storage_type)\n        instance_type = enums.Instance.Type(instance_type)\n\n        instance = Instance(\n            instance_id,\n            self._get_client(project_id=project_id),\n            instance_display_name,\n            instance_type,\n            instance_labels,\n        )\n\n        clusters = [\n            instance.cluster(\n                main_cluster_id,\n                main_cluster_zone,\n                cluster_nodes,\n                cluster_storage_type\n            )\n        ]\n        if replica_cluster_id and replica_cluster_zone:\n            clusters.append(instance.cluster(\n                replica_cluster_id,\n                replica_cluster_zone,\n                cluster_nodes,\n                cluster_storage_type\n            ))\n        operation = instance.create(\n            clusters=clusters\n        )\n        operation.result(timeout)\n        return instance", "response": "Creates a new instance of the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_table(instance,\n                     table_id,\n                     initial_split_keys=None,\n                     column_families=None):\n        \"\"\"\n        Creates the specified Cloud Bigtable table.\n        Raises ``google.api_core.exceptions.AlreadyExists`` if the table exists.\n\n        :type instance: Instance\n        :param instance: The Cloud Bigtable instance that owns the table.\n        :type table_id: str\n        :param table_id: The ID of the table to create in Cloud Bigtable.\n        :type initial_split_keys: list\n        :param initial_split_keys: (Optional) A list of row keys in bytes to use to\n            initially split the table.\n        :type column_families: dict\n        :param column_families: (Optional) A map of columns to create. The key is the\n            column_id str, and the value is a\n            :class:`google.cloud.bigtable.column_family.GarbageCollectionRule`.\n        \"\"\"\n        if column_families is None:\n            column_families = {}\n        if initial_split_keys is None:\n            initial_split_keys = []\n        table = Table(table_id, instance)\n        table.create(initial_split_keys, column_families)", "response": "Creates a new table in the specified Cloud Bigtable instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_table(self, instance_id, table_id, project_id=None):\n        table = self.get_instance(instance_id=instance_id, project_id=project_id).table(table_id=table_id)\n        table.delete()", "response": "Deletes the specified table in Cloud Bigtable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the number of nodes in the specified Cloud Bigtable cluster.", "response": "def update_cluster(instance, cluster_id, nodes):\n        \"\"\"\n        Updates number of nodes in the specified Cloud Bigtable cluster.\n        Raises google.api_core.exceptions.NotFound if the cluster does not exist.\n\n        :type instance: Instance\n        :param instance: The Cloud Bigtable instance that owns the cluster.\n        :type cluster_id: str\n        :param cluster_id: The ID of the cluster.\n        :type nodes: int\n        :param nodes: The desired number of nodes.\n        \"\"\"\n        cluster = Cluster(cluster_id, instance)\n        cluster.serve_nodes = nodes\n        cluster.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _prepare_hiveconf(d):\n        if not d:\n            return []\n        return as_flattened_list(\n            zip([\"-hiveconf\"] * len(d),\n                [\"{}={}\".format(k, v) for k, v in d.items()])\n        )", "response": "This function prepares a list of hiveconf params\n        from a dictionary of key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_cli(self, hql, schema=None, verbose=True, hive_conf=None):\n        conn = self.conn\n        schema = schema or conn.schema\n        if schema:\n            hql = \"USE {schema};\\n{hql}\".format(schema=schema, hql=hql)\n\n        with TemporaryDirectory(prefix='airflow_hiveop_') as tmp_dir:\n            with NamedTemporaryFile(dir=tmp_dir) as f:\n                hql = hql + '\\n'\n                f.write(hql.encode('UTF-8'))\n                f.flush()\n                hive_cmd = self._prepare_cli_cmd()\n                env_context = get_context_from_env_var()\n                # Only extend the hive_conf if it is defined.\n                if hive_conf:\n                    env_context.update(hive_conf)\n                hive_conf_params = self._prepare_hiveconf(env_context)\n                if self.mapred_queue:\n                    hive_conf_params.extend(\n                        ['-hiveconf',\n                         'mapreduce.job.queuename={}'\n                         .format(self.mapred_queue),\n                         '-hiveconf',\n                         'mapred.job.queue.name={}'\n                         .format(self.mapred_queue),\n                         '-hiveconf',\n                         'tez.job.queue.name={}'\n                         .format(self.mapred_queue)\n                         ])\n\n                if self.mapred_queue_priority:\n                    hive_conf_params.extend(\n                        ['-hiveconf',\n                         'mapreduce.job.priority={}'\n                         .format(self.mapred_queue_priority)])\n\n                if self.mapred_job_name:\n                    hive_conf_params.extend(\n                        ['-hiveconf',\n                         'mapred.job.name={}'\n                         .format(self.mapred_job_name)])\n\n                hive_cmd.extend(hive_conf_params)\n                hive_cmd.extend(['-f', f.name])\n\n                if verbose:\n                    self.log.info(\"%s\", \" \".join(hive_cmd))\n                sp = subprocess.Popen(\n                    hive_cmd,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.STDOUT,\n                    cwd=tmp_dir,\n                    close_fds=True)\n                self.sp = sp\n                stdout = ''\n                while True:\n                    line = sp.stdout.readline()\n                    if not line:\n                        break\n                    stdout += line.decode('UTF-8')\n                    if verbose:\n                        self.log.info(line.decode('UTF-8').strip())\n                sp.wait()\n\n                if sp.returncode:\n                    raise AirflowException(stdout)\n\n                return stdout", "response": "Run an airflow - specific command using the hive cli."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_df(\n            self,\n            df,\n            table,\n            field_dict=None,\n            delimiter=',',\n            encoding='utf8',\n            pandas_kwargs=None, **kwargs):\n        \"\"\"\n        Loads a pandas DataFrame into hive.\n\n        Hive data types will be inferred if not passed but column names will\n        not be sanitized.\n\n        :param df: DataFrame to load into a Hive table\n        :type df: pandas.DataFrame\n        :param table: target Hive table, use dot notation to target a\n            specific database\n        :type table: str\n        :param field_dict: mapping from column name to hive data type.\n            Note that it must be OrderedDict so as to keep columns' order.\n        :type field_dict: collections.OrderedDict\n        :param delimiter: field delimiter in the file\n        :type delimiter: str\n        :param encoding: str encoding to use when writing DataFrame to file\n        :type encoding: str\n        :param pandas_kwargs: passed to DataFrame.to_csv\n        :type pandas_kwargs: dict\n        :param kwargs: passed to self.load_file\n        \"\"\"\n\n        def _infer_field_types_from_df(df):\n            DTYPE_KIND_HIVE_TYPE = {\n                'b': 'BOOLEAN',    # boolean\n                'i': 'BIGINT',     # signed integer\n                'u': 'BIGINT',     # unsigned integer\n                'f': 'DOUBLE',     # floating-point\n                'c': 'STRING',     # complex floating-point\n                'M': 'TIMESTAMP',  # datetime\n                'O': 'STRING',     # object\n                'S': 'STRING',     # (byte-)string\n                'U': 'STRING',     # Unicode\n                'V': 'STRING'      # void\n            }\n\n            d = OrderedDict()\n            for col, dtype in df.dtypes.iteritems():\n                d[col] = DTYPE_KIND_HIVE_TYPE[dtype.kind]\n            return d\n\n        if pandas_kwargs is None:\n            pandas_kwargs = {}\n\n        with TemporaryDirectory(prefix='airflow_hiveop_') as tmp_dir:\n            with NamedTemporaryFile(dir=tmp_dir, mode=\"w\") as f:\n\n                if field_dict is None:\n                    field_dict = _infer_field_types_from_df(df)\n\n                df.to_csv(path_or_buf=f,\n                          sep=delimiter,\n                          header=False,\n                          index=False,\n                          encoding=encoding,\n                          date_format=\"%Y-%m-%d %H:%M:%S\",\n                          **pandas_kwargs)\n                f.flush()\n\n                return self.load_file(filepath=f.name,\n                                      table=table,\n                                      delimiter=delimiter,\n                                      field_dict=field_dict,\n                                      **kwargs)", "response": "Loads a pandas DataFrame into a hive table and returns a dict of the data types."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a local file into the specified table.", "response": "def load_file(\n            self,\n            filepath,\n            table,\n            delimiter=\",\",\n            field_dict=None,\n            create=True,\n            overwrite=True,\n            partition=None,\n            recreate=False,\n            tblproperties=None):\n        \"\"\"\n        Loads a local file into Hive\n\n        Note that the table generated in Hive uses ``STORED AS textfile``\n        which isn't the most efficient serialization format. If a\n        large amount of data is loaded and/or if the tables gets\n        queried considerably, you may want to use this operator only to\n        stage the data into a temporary table before loading it into its\n        final destination using a ``HiveOperator``.\n\n        :param filepath: local filepath of the file to load\n        :type filepath: str\n        :param table: target Hive table, use dot notation to target a\n            specific database\n        :type table: str\n        :param delimiter: field delimiter in the file\n        :type delimiter: str\n        :param field_dict: A dictionary of the fields name in the file\n            as keys and their Hive types as values.\n            Note that it must be OrderedDict so as to keep columns' order.\n        :type field_dict: collections.OrderedDict\n        :param create: whether to create the table if it doesn't exist\n        :type create: bool\n        :param overwrite: whether to overwrite the data in table or partition\n        :type overwrite: bool\n        :param partition: target partition as a dict of partition columns\n            and values\n        :type partition: dict\n        :param recreate: whether to drop and recreate the table at every\n            execution\n        :type recreate: bool\n        :param tblproperties: TBLPROPERTIES of the hive table being created\n        :type tblproperties: dict\n        \"\"\"\n        hql = ''\n        if recreate:\n            hql += \"DROP TABLE IF EXISTS {table};\\n\".format(table=table)\n        if create or recreate:\n            if field_dict is None:\n                raise ValueError(\"Must provide a field dict when creating a table\")\n            fields = \",\\n    \".join(\n                [k + ' ' + v for k, v in field_dict.items()])\n            hql += \"CREATE TABLE IF NOT EXISTS {table} (\\n{fields})\\n\".format(\n                table=table, fields=fields)\n            if partition:\n                pfields = \",\\n    \".join(\n                    [p + \" STRING\" for p in partition])\n                hql += \"PARTITIONED BY ({pfields})\\n\".format(pfields=pfields)\n            hql += \"ROW FORMAT DELIMITED\\n\"\n            hql += \"FIELDS TERMINATED BY '{delimiter}'\\n\".format(delimiter=delimiter)\n            hql += \"STORED AS textfile\\n\"\n            if tblproperties is not None:\n                tprops = \", \".join(\n                    [\"'{0}'='{1}'\".format(k, v) for k, v in tblproperties.items()])\n                hql += \"TBLPROPERTIES({tprops})\\n\".format(tprops=tprops)\n        hql += \";\"\n        self.log.info(hql)\n        self.run_cli(hql)\n        hql = \"LOAD DATA LOCAL INPATH '{filepath}' \".format(filepath=filepath)\n        if overwrite:\n            hql += \"OVERWRITE \"\n        hql += \"INTO TABLE {table} \".format(table=table)\n        if partition:\n            pvals = \", \".join(\n                [\"{0}='{1}'\".format(k, v) for k, v in partition.items()])\n            hql += \"PARTITION ({pvals})\".format(pvals=pvals)\n\n        # As a workaround for HIVE-10541, add a newline character\n        # at the end of hql (AIRFLOW-2412).\n        hql += ';\\n'\n\n        self.log.info(hql)\n        self.run_cli(hql)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Hive thrift client.", "response": "def get_metastore_client(self):\n        \"\"\"\n        Returns a Hive thrift client.\n        \"\"\"\n        import hmsclient\n        from thrift.transport import TSocket, TTransport\n        from thrift.protocol import TBinaryProtocol\n        ms = self.metastore_conn\n        auth_mechanism = ms.extra_dejson.get('authMechanism', 'NOSASL')\n        if configuration.conf.get('core', 'security') == 'kerberos':\n            auth_mechanism = ms.extra_dejson.get('authMechanism', 'GSSAPI')\n            kerberos_service_name = ms.extra_dejson.get('kerberos_service_name', 'hive')\n\n        socket = TSocket.TSocket(ms.host, ms.port)\n        if configuration.conf.get('core', 'security') == 'kerberos' \\\n                and auth_mechanism == 'GSSAPI':\n            try:\n                import saslwrapper as sasl\n            except ImportError:\n                import sasl\n\n            def sasl_factory():\n                sasl_client = sasl.Client()\n                sasl_client.setAttr(\"host\", ms.host)\n                sasl_client.setAttr(\"service\", kerberos_service_name)\n                sasl_client.init()\n                return sasl_client\n\n            from thrift_sasl import TSaslClientTransport\n            transport = TSaslClientTransport(sasl_factory, \"GSSAPI\", socket)\n        else:\n            transport = TTransport.TBufferedTransport(socket)\n\n        protocol = TBinaryProtocol.TBinaryProtocol(transport)\n\n        return hmsclient.HMSClient(iprot=protocol)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks whether a partition exists in the metastore", "response": "def check_for_partition(self, schema, table, partition):\n        \"\"\"\n        Checks whether a partition exists\n\n        :param schema: Name of hive schema (database) @table belongs to\n        :type schema: str\n        :param table: Name of hive table @partition belongs to\n        :type schema: str\n        :partition: Expression that matches the partitions to check for\n            (eg `a = 'b' AND c = 'd'`)\n        :type schema: str\n        :rtype: bool\n\n        >>> hh = HiveMetastoreHook()\n        >>> t = 'static_babynames_partitioned'\n        >>> hh.check_for_partition('airflow', t, \"ds='2015-01-01'\")\n        True\n        \"\"\"\n        with self.metastore as client:\n            partitions = client.get_partitions_by_filter(\n                schema, table, partition, 1)\n\n        if partitions:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether a partition with a given name exists in the given schema.", "response": "def check_for_named_partition(self, schema, table, partition_name):\n        \"\"\"\n        Checks whether a partition with a given name exists\n\n        :param schema: Name of hive schema (database) @table belongs to\n        :type schema: str\n        :param table: Name of hive table @partition belongs to\n        :type schema: str\n        :partition: Name of the partitions to check for (eg `a=b/c=d`)\n        :type schema: str\n        :rtype: bool\n\n        >>> hh = HiveMetastoreHook()\n        >>> t = 'static_babynames_partitioned'\n        >>> hh.check_for_named_partition('airflow', t, \"ds=2015-01-01\")\n        True\n        >>> hh.check_for_named_partition('airflow', t, \"ds=xxx\")\n        False\n        \"\"\"\n        with self.metastore as client:\n            return client.check_for_named_partition(schema, table, partition_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_table(self, table_name, db='default'):\n        if db == 'default' and '.' in table_name:\n            db, table_name = table_name.split('.')[:2]\n        with self.metastore as client:\n            return client.get_table(dbname=db, tbl_name=table_name)", "response": "Get a metastore table object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of tables in a specific database.", "response": "def get_tables(self, db, pattern='*'):\n        \"\"\"\n        Get a metastore table object\n        \"\"\"\n        with self.metastore as client:\n            tables = client.get_tables(db_name=db, pattern=pattern)\n            return client.get_table_objects_by_name(db, tables)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all partitions in a table. Works only for tables with less than 32767", "response": "def get_partitions(\n            self, schema, table_name, filter=None):\n        \"\"\"\n        Returns a list of all partitions in a table. Works only\n        for tables with less than 32767 (java short max val).\n        For subpartitioned table, the number might easily exceed this.\n\n        >>> hh = HiveMetastoreHook()\n        >>> t = 'static_babynames_partitioned'\n        >>> parts = hh.get_partitions(schema='airflow', table_name=t)\n        >>> len(parts)\n        1\n        >>> parts\n        [{'ds': '2015-01-01'}]\n        \"\"\"\n        with self.metastore as client:\n            table = client.get_table(dbname=schema, tbl_name=table_name)\n            if len(table.partitionKeys) == 0:\n                raise AirflowException(\"The table isn't partitioned\")\n            else:\n                if filter:\n                    parts = client.get_partitions_by_filter(\n                        db_name=schema, tbl_name=table_name,\n                        filter=filter, max_parts=HiveMetastoreHook.MAX_PART_COUNT)\n                else:\n                    parts = client.get_partitions(\n                        db_name=schema, tbl_name=table_name,\n                        max_parts=HiveMetastoreHook.MAX_PART_COUNT)\n\n                pnames = [p.name for p in table.partitionKeys]\n                return [dict(zip(pnames, p.values)) for p in parts]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef max_partition(self, schema, table_name, field=None, filter_map=None):\n        with self.metastore as client:\n            table = client.get_table(dbname=schema, tbl_name=table_name)\n            key_name_set = set(key.name for key in table.partitionKeys)\n            if len(table.partitionKeys) == 1:\n                field = table.partitionKeys[0].name\n            elif not field:\n                raise AirflowException(\"Please specify the field you want the max \"\n                                       \"value for.\")\n            elif field not in key_name_set:\n                raise AirflowException(\"Provided field is not a partition key.\")\n\n            if filter_map and not set(filter_map.keys()).issubset(key_name_set):\n                raise AirflowException(\"Provided filter_map contains keys \"\n                                       \"that are not partition key.\")\n\n            part_names = \\\n                client.get_partition_names(schema,\n                                           table_name,\n                                           max_parts=HiveMetastoreHook.MAX_PART_COUNT)\n            part_specs = [client.partition_name_to_spec(part_name)\n                          for part_name in part_names]\n\n        return HiveMetastoreHook._get_max_partition_from_part_specs(part_specs,\n                                                                    field,\n                                                                    filter_map)", "response": "Returns the maximum value for all partitions with given field in a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef table_exists(self, table_name, db='default'):\n        try:\n            self.get_table(table_name, db)\n            return True\n        except Exception:\n            return False", "response": "Check if table exists in HiveMetastore"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a connection object.", "response": "def get_conn(self, schema=None):\n        \"\"\"\n        Returns a Hive connection object.\n        \"\"\"\n        db = self.get_connection(self.hiveserver2_conn_id)\n        auth_mechanism = db.extra_dejson.get('authMechanism', 'NONE')\n        if auth_mechanism == 'NONE' and db.login is None:\n            # we need to give a username\n            username = 'airflow'\n        kerberos_service_name = None\n        if configuration.conf.get('core', 'security') == 'kerberos':\n            auth_mechanism = db.extra_dejson.get('authMechanism', 'KERBEROS')\n            kerberos_service_name = db.extra_dejson.get('kerberos_service_name', 'hive')\n\n        # pyhive uses GSSAPI instead of KERBEROS as a auth_mechanism identifier\n        if auth_mechanism == 'GSSAPI':\n            self.log.warning(\n                \"Detected deprecated 'GSSAPI' for authMechanism \"\n                \"for %s. Please use 'KERBEROS' instead\",\n                self.hiveserver2_conn_id\n            )\n            auth_mechanism = 'KERBEROS'\n\n        from pyhive.hive import connect\n        return connect(\n            host=db.host,\n            port=db.port,\n            auth=auth_mechanism,\n            kerberos_service_name=kerberos_service_name,\n            username=db.login or username,\n            password=db.password,\n            database=schema or db.schema or 'default')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting results of the provided hql in target schema.", "response": "def get_results(self, hql, schema='default', fetch_size=None, hive_conf=None):\n        \"\"\"\n        Get results of the provided hql in target schema.\n\n        :param hql: hql to be executed.\n        :type hql: str or list\n        :param schema: target schema, default to 'default'.\n        :type schema: str\n        :param fetch_size: max size of result to fetch.\n        :type fetch_size: int\n        :param hive_conf: hive_conf to execute alone with the hql.\n        :type hive_conf: dict\n        :return: results of hql execution, dict with data (list of results) and header\n        :rtype: dict\n        \"\"\"\n        results_iter = self._get_results(hql, schema,\n                                         fetch_size=fetch_size, hive_conf=hive_conf)\n        header = next(results_iter)\n        results = {\n            'data': list(results_iter),\n            'header': header\n        }\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a single SQL query and write the results to a CSV file.", "response": "def to_csv(\n            self,\n            hql,\n            csv_filepath,\n            schema='default',\n            delimiter=',',\n            lineterminator='\\r\\n',\n            output_header=True,\n            fetch_size=1000,\n            hive_conf=None):\n        \"\"\"\n        Execute hql in target schema and write results to a csv file.\n\n        :param hql: hql to be executed.\n        :type hql: str or list\n        :param csv_filepath: filepath of csv to write results into.\n        :type csv_filepath: str\n        :param schema: target schema, default to 'default'.\n        :type schema: str\n        :param delimiter: delimiter of the csv file, default to ','.\n        :type delimiter: str\n        :param lineterminator: lineterminator of the csv file.\n        :type lineterminator: str\n        :param output_header: header of the csv file, default to True.\n        :type output_header: bool\n        :param fetch_size: number of result rows to write into the csv file, default to 1000.\n        :type fetch_size: int\n        :param hive_conf: hive_conf to execute alone with the hql.\n        :type hive_conf: dict\n\n        \"\"\"\n\n        results_iter = self._get_results(hql, schema,\n                                         fetch_size=fetch_size, hive_conf=hive_conf)\n        header = next(results_iter)\n        message = None\n\n        i = 0\n        with open(csv_filepath, 'wb') as f:\n            writer = csv.writer(f,\n                                delimiter=delimiter,\n                                lineterminator=lineterminator,\n                                encoding='utf-8')\n            try:\n                if output_header:\n                    self.log.debug('Cursor description is %s', header)\n                    writer.writerow([c[0] for c in header])\n\n                for i, row in enumerate(results_iter, 1):\n                    writer.writerow(row)\n                    if i % fetch_size == 0:\n                        self.log.info(\"Written %s rows so far.\", i)\n            except ValueError as exception:\n                message = str(exception)\n\n        if message:\n            # need to clean up the file first\n            os.remove(csv_filepath)\n            raise ValueError(message)\n\n        self.log.info(\"Done. Loaded a total of %s rows.\", i)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a set of records from a Hive query.", "response": "def get_records(self, hql, schema='default', hive_conf=None):\n        \"\"\"\n        Get a set of records from a Hive query.\n\n        :param hql: hql to be executed.\n        :type hql: str or list\n        :param schema: target schema, default to 'default'.\n        :type schema: str\n        :param hive_conf: hive_conf to execute alone with the hql.\n        :type hive_conf: dict\n        :return: result of hive execution\n        :rtype: list\n\n        >>> hh = HiveServer2Hook()\n        >>> sql = \"SELECT * FROM airflow.static_babynames LIMIT 100\"\n        >>> len(hh.get_records(sql))\n        100\n        \"\"\"\n        return self.get_results(hql, schema=schema, hive_conf=hive_conf)['data']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pandas_df(self, hql, schema='default'):\n        import pandas as pd\n        res = self.get_results(hql, schema=schema)\n        df = pd.DataFrame(res['data'])\n        df.columns = [c[0] for c in res['header']]\n        return df", "response": "Get a pandas dataframe from a Hive query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_conn(self):\n        if not self._client:\n            self._client = ProductSearchClient(credentials=self._get_credentials())\n        return self._client", "response": "Returns a connection to the Cloud Vision API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_product_set(\n        self,\n        location,\n        product_set,\n        project_id=None,\n        product_set_id=None,\n        retry=None,\n        timeout=None,\n        metadata=None,\n    ):\n        \"\"\"\n        For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductSetCreateOperator`\n        \"\"\"\n        client = self.get_conn()\n        parent = ProductSearchClient.location_path(project_id, location)\n        self.log.info('Creating a new ProductSet under the parent: %s', parent)\n        response = client.create_product_set(\n            parent=parent,\n            product_set=product_set,\n            product_set_id=product_set_id,\n            retry=retry,\n            timeout=timeout,\n            metadata=metadata,\n        )\n        self.log.info('ProductSet created: %s', response.name if response else '')\n        self.log.debug('ProductSet created:\\n%s', response)\n\n        if not product_set_id:\n            # Product set id was generated by the API\n            product_set_id = self._get_autogenerated_id(response)\n            self.log.info('Extracted autogenerated ProductSet ID from the response: %s', product_set_id)\n\n        return product_set_id", "response": "Creates a new ProductSet under the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a specific product set.", "response": "def get_product_set(\n        self, location, product_set_id, project_id=None, retry=None, timeout=None, metadata=None\n    ):\n        \"\"\"\n        For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductSetGetOperator`\n        \"\"\"\n        client = self.get_conn()\n        name = ProductSearchClient.product_set_path(project_id, location, product_set_id)\n        self.log.info('Retrieving ProductSet: %s', name)\n        response = client.get_product_set(name=name, retry=retry, timeout=timeout, metadata=metadata)\n        self.log.info('ProductSet retrieved.')\n        self.log.debug('ProductSet retrieved:\\n%s', response)\n        return MessageToDict(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_product_set(\n        self, location, product_set_id, project_id=None, retry=None, timeout=None, metadata=None\n    ):\n        \"\"\"\n        For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductSetDeleteOperator`\n        \"\"\"\n        client = self.get_conn()\n        name = ProductSearchClient.product_set_path(project_id, location, product_set_id)\n        self.log.info('Deleting ProductSet: %s', name)\n        client.delete_product_set(name=name, retry=retry, timeout=timeout, metadata=metadata)\n        self.log.info('ProductSet with the name [%s] deleted.', name)", "response": "For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductSetDeleteOperator`"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_product(\n        self, location, product, project_id=None, product_id=None, retry=None, timeout=None, metadata=None\n    ):\n        \"\"\"\n        For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductCreateOperator`\n        \"\"\"\n        client = self.get_conn()\n        parent = ProductSearchClient.location_path(project_id, location)\n        self.log.info('Creating a new Product under the parent: %s', parent)\n        response = client.create_product(\n            parent=parent,\n            product=product,\n            product_id=product_id,\n            retry=retry,\n            timeout=timeout,\n            metadata=metadata,\n        )\n        self.log.info('Product created: %s', response.name if response else '')\n        self.log.debug('Product created:\\n%s', response)\n\n        if not product_id:\n            # Product id was generated by the API\n            product_id = self._get_autogenerated_id(response)\n            self.log.info('Extracted autogenerated Product ID from the response: %s', product_id)\n\n        return product_id", "response": "Creates a new product under the specified location."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a single product from the Cloud Vision server.", "response": "def get_product(self, location, product_id, project_id=None, retry=None, timeout=None, metadata=None):\n        \"\"\"\n        For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductGetOperator`\n        \"\"\"\n        client = self.get_conn()\n        name = ProductSearchClient.product_path(project_id, location, product_id)\n        self.log.info('Retrieving Product: %s', name)\n        response = client.get_product(name=name, retry=retry, timeout=timeout, metadata=metadata)\n        self.log.info('Product retrieved.')\n        self.log.debug('Product retrieved:\\n%s', response)\n        return MessageToDict(response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_product(\n        self,\n        product,\n        location=None,\n        product_id=None,\n        update_mask=None,\n        project_id=None,\n        retry=None,\n        timeout=None,\n        metadata=None,\n    ):\n        \"\"\"\n        For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductUpdateOperator`\n        \"\"\"\n        client = self.get_conn()\n        product = self.product_name_determiner.get_entity_with_name(product, product_id, location, project_id)\n        self.log.info('Updating ProductSet: %s', product.name)\n        response = client.update_product(\n            product=product, update_mask=update_mask, retry=retry, timeout=timeout, metadata=metadata\n        )\n        self.log.info('Product updated: %s', response.name if response else '')\n        self.log.debug('Product updated:\\n%s', response)\n        return MessageToDict(response)", "response": "For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductUpdateOperator`"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_product(self, location, product_id, project_id=None, retry=None, timeout=None, metadata=None):\n        client = self.get_conn()\n        name = ProductSearchClient.product_path(project_id, location, product_id)\n        self.log.info('Deleting ProductSet: %s', name)\n        client.delete_product(name=name, retry=retry, timeout=timeout, metadata=metadata)\n        self.log.info('Product with the name [%s] deleted:', name)", "response": "For the documentation see:\n        :class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionProductDeleteOperator`"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new reference image for the specified resource.", "response": "def create_reference_image(\n        self,\n        location,\n        product_id,\n        reference_image,\n        reference_image_id=None,\n        project_id=None,\n        retry=None,\n        timeout=None,\n        metadata=None,\n    ):\n        \"\"\"\n        For the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionReferenceImageCreateOperator`\n        \"\"\"\n        client = self.get_conn()\n        self.log.info('Creating ReferenceImage')\n        parent = ProductSearchClient.product_path(project=project_id, location=location, product=product_id)\n\n        response = client.create_reference_image(\n            parent=parent,\n            reference_image=reference_image,\n            reference_image_id=reference_image_id,\n            retry=retry,\n            timeout=timeout,\n            metadata=metadata,\n        )\n\n        self.log.info('ReferenceImage created: %s', response.name if response else '')\n        self.log.debug('ReferenceImage created:\\n%s', response)\n\n        if not reference_image_id:\n            # Refernece image  id was generated by the API\n            reference_image_id = self._get_autogenerated_id(response)\n            self.log.info(\n                'Extracted autogenerated ReferenceImage ID from the response: %s', reference_image_id\n            )\n\n        return reference_image_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a reference image.", "response": "def delete_reference_image(\n        self,\n        location,\n        product_id,\n        reference_image_id,\n        project_id=None,\n        retry=None,\n        timeout=None,\n        metadata=None,\n    ):\n        \"\"\"\n        For the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionReferenceImageCreateOperator`\n        \"\"\"\n        client = self.get_conn()\n        self.log.info('Deleting ReferenceImage')\n        name = ProductSearchClient.reference_image_path(\n            project=project_id, location=location, product=product_id, reference_image=reference_image_id\n        )\n        response = client.delete_reference_image(name=name, retry=retry, timeout=timeout, metadata=metadata)\n        self.log.info('ReferenceImage with the name [%s] deleted.', name)\n\n        return MessageToDict(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a product to a Product Set", "response": "def add_product_to_product_set(\n        self,\n        product_set_id,\n        product_id,\n        location=None,\n        project_id=None,\n        retry=None,\n        timeout=None,\n        metadata=None,\n    ):\n        \"\"\"\n        For the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionAddProductToProductSetOperator`\n        \"\"\"\n        client = self.get_conn()\n\n        product_name = ProductSearchClient.product_path(project_id, location, product_id)\n        product_set_name = ProductSearchClient.product_set_path(project_id, location, product_set_id)\n\n        self.log.info('Add Product[name=%s] to Product Set[name=%s]', product_name, product_set_name)\n\n        client.add_product_to_product_set(\n            name=product_set_name, product=product_name, retry=retry, timeout=timeout, metadata=metadata\n        )\n\n        self.log.info('Product added to Product Set')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef annotate_image(self, request, retry=None, timeout=None):\n        client = self.annotator_client\n\n        self.log.info('Annotating image')\n\n        response = client.annotate_image(request=request, retry=retry, timeout=timeout)\n\n        self.log.info('Image annotated')\n\n        return MessageToDict(response)", "response": "Annotate an image with the specified request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef safe_search_detection(\n        self, image, max_results=None, retry=None, timeout=None, additional_properties=None\n    ):\n        \"\"\"\n        For the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionDetectImageSafeSearchOperator`\n        \"\"\"\n        client = self.annotator_client\n\n        self.log.info(\"Detecting safe search\")\n\n        if additional_properties is None:\n            additional_properties = {}\n\n        response = client.safe_search_detection(\n            image=image, max_results=max_results, retry=retry, timeout=timeout, **additional_properties\n        )\n        response = MessageToDict(response)\n        self._check_for_error(response)\n\n        self.log.info(\"Safe search detection finished\")\n        return response", "response": "This method performs a safe search on the cloud vision image and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_endpoint(self):\n        conn = self.get_connection(self.http_conn_id)\n        token = conn.password\n        if not token:\n            raise AirflowException('Dingding token is requests but get nothing, '\n                                   'check you conn_id configuration.')\n        return 'robot/send?access_token={}'.format(token)", "response": "Get Dingding endpoint for sending message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild the message for the current object", "response": "def _build_message(self):\n        \"\"\"\n        Build different type of Dingding message\n        As most commonly used type, text message just need post message content\n        rather than a dict like ``{'content': 'message'}``\n        \"\"\"\n        if self.message_type in ['text', 'markdown']:\n            data = {\n                'msgtype': self.message_type,\n                self.message_type: {\n                    'content': self.message\n                } if self.message_type == 'text' else self.message,\n                'at': {\n                    'atMobiles': self.at_mobiles,\n                    'isAtAll': self.at_all\n                }\n            }\n        else:\n            data = {\n                'msgtype': self.message_type,\n                self.message_type: self.message\n            }\n        return json.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self):\n        support_type = ['text', 'link', 'markdown', 'actionCard', 'feedCard']\n        if self.message_type not in support_type:\n            raise ValueError('DingdingWebhookHook only support {} '\n                             'so far, but receive {}'.format(support_type, self.message_type))\n\n        data = self._build_message()\n        self.log.info('Sending Dingding type %s message %s', self.message_type, data)\n        resp = self.run(endpoint=self._get_endpoint(),\n                        data=data,\n                        headers={'Content-Type': 'application/json'})\n\n        # Dingding success send message will with errcode equal to 0\n        if int(resp.json().get('errcode')) != 0:\n            raise AirflowException('Send Dingding message failed, receive error '\n                                   'message %s', resp.text)\n        self.log.info('Success Send Dingding message')", "response": "Send a Dingding message to the Airflow server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the log from Elasticsearch and returns the message and metadata.", "response": "def _read(self, ti, try_number, metadata=None):\n        \"\"\"\n        Endpoint for streaming log.\n        :param ti: task instance object\n        :param try_number: try_number of the task instance\n        :param metadata: log metadata,\n                         can be used for steaming log reading and auto-tailing.\n        :return: a list of log documents and metadata.\n        \"\"\"\n        if not metadata:\n            metadata = {'offset': 0}\n        if 'offset' not in metadata:\n            metadata['offset'] = 0\n\n        offset = metadata['offset']\n        log_id = self._render_log_id(ti, try_number)\n\n        logs = self.es_read(log_id, offset)\n\n        next_offset = offset if not logs else logs[-1].offset\n\n        metadata['offset'] = next_offset\n        # end_of_log_mark may contain characters like '\\n' which is needed to\n        # have the log uploaded but will not be stored in elasticsearch.\n        metadata['end_of_log'] = False if not logs \\\n            else logs[-1].message == self.end_of_log_mark.strip()\n\n        cur_ts = pendulum.now()\n        # Assume end of log after not receiving new log for 5 min,\n        # as executor heartbeat is 1 min and there might be some\n        # delay before Elasticsearch makes the log available.\n        if 'last_log_timestamp' in metadata:\n            last_log_ts = timezone.parse(metadata['last_log_timestamp'])\n            if cur_ts.diff(last_log_ts).in_minutes() >= 5:\n                metadata['end_of_log'] = True\n\n        if offset != next_offset or 'last_log_timestamp' not in metadata:\n            metadata['last_log_timestamp'] = str(cur_ts)\n\n        message = '\\n'.join([log.message for log in logs])\n\n        return message, metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef es_read(self, log_id, offset):\n\n        # Offset is the unique key for sorting logs given log_id.\n        s = Search(using=self.client) \\\n            .query('match_phrase', log_id=log_id) \\\n            .sort('offset')\n\n        s = s.filter('range', offset={'gt': offset})\n\n        logs = []\n        if s.count() != 0:\n            try:\n\n                logs = s[self.MAX_LINE_PER_PAGE * self.PAGE:self.MAX_LINE_PER_PAGE] \\\n                    .execute()\n            except Exception as e:\n                self.log.exception('Could not read log with log_id: %s, error: %s', log_id, str(e))\n\n        return logs", "response": "Reads the log with the given log_id and offset in Elasticsearch and returns the logs that match the given log_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _bind_parameters(operation, parameters):\n    # inspired by MySQL Python Connector (conversion.py)\n    string_parameters = {}\n    for (name, value) in iteritems(parameters):\n        if value is None:\n            string_parameters[name] = 'NULL'\n        elif isinstance(value, basestring):\n            string_parameters[name] = \"'\" + _escape(value) + \"'\"\n        else:\n            string_parameters[name] = str(value)\n    return operation % string_parameters", "response": "Helper method that binds parameters to a SQL query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _escape(s):\n    e = s\n    e = e.replace('\\\\', '\\\\\\\\')\n    e = e.replace('\\n', '\\\\n')\n    e = e.replace('\\r', '\\\\r')\n    e = e.replace(\"'\", \"\\\\'\")\n    e = e.replace('\"', '\\\\\"')\n    return e", "response": "Escape a string in a sequence of characters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to check that value is of expected type and raise TypeError if not", "response": "def _validate_value(key, value, expected_type):\n    \"\"\" function to check expected type and raise\n    error if type is not correct \"\"\"\n    if not isinstance(value, expected_type):\n        raise TypeError(\"{} argument must have a type {} not {}\".format(\n            key, expected_type, type(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_conn(self):\n        service = self.get_service()\n        project = self._get_field('project')\n        return BigQueryConnection(\n            service=service,\n            project_id=project,\n            use_legacy_sql=self.use_legacy_sql,\n            location=self.location,\n            num_retries=self.num_retries\n        )", "response": "Returns a BigQuery connection object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_service(self):\n        http_authorized = self._authorize()\n        return build(\n            'bigquery', 'v2', http=http_authorized, cache_discovery=False)", "response": "Returns a BigQuery service object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pandas_df(self, sql, parameters=None, dialect=None):\n        private_key = self._get_field('key_path', None) or self._get_field('keyfile_dict', None)\n\n        if dialect is None:\n            dialect = 'legacy' if self.use_legacy_sql else 'standard'\n\n        return read_gbq(sql,\n                        project_id=self._get_field('project'),\n                        dialect=dialect,\n                        verbose=False,\n                        private_key=private_key)", "response": "Returns a Pandas DataFrame for the results produced by a BigQuery SQL query."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks for the existence of a table in Google BigQuery.", "response": "def table_exists(self, project_id, dataset_id, table_id):\n        \"\"\"\n        Checks for the existence of a table in Google BigQuery.\n\n        :param project_id: The Google cloud project in which to look for the\n            table. The connection supplied to the hook must provide access to\n            the specified project.\n        :type project_id: str\n        :param dataset_id: The name of the dataset in which to look for the\n            table.\n        :type dataset_id: str\n        :param table_id: The name of the table to check the existence of.\n        :type table_id: str\n        \"\"\"\n        service = self.get_service()\n        try:\n            service.tables().get(\n                projectId=project_id, datasetId=dataset_id,\n                tableId=table_id).execute(num_retries=self.num_retries)\n            return True\n        except HttpError as e:\n            if e.resp['status'] == '404':\n                return False\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new empty table in the dataset.", "response": "def create_empty_table(self,\n                           project_id,\n                           dataset_id,\n                           table_id,\n                           schema_fields=None,\n                           time_partitioning=None,\n                           cluster_fields=None,\n                           labels=None,\n                           view=None,\n                           num_retries=None):\n        \"\"\"\n        Creates a new, empty table in the dataset.\n        To create a view, which is defined by a SQL query, parse a dictionary to 'view' kwarg\n\n        :param project_id: The project to create the table into.\n        :type project_id: str\n        :param dataset_id: The dataset to create the table into.\n        :type dataset_id: str\n        :param table_id: The Name of the table to be created.\n        :type table_id: str\n        :param schema_fields: If set, the schema field list as defined here:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schema\n        :type schema_fields: list\n        :param labels: a dictionary containing labels for the table, passed to BigQuery\n        :type labels: dict\n\n        **Example**: ::\n\n            schema_fields=[{\"name\": \"emp_name\", \"type\": \"STRING\", \"mode\": \"REQUIRED\"},\n                           {\"name\": \"salary\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"}]\n\n        :param time_partitioning: configure optional time partitioning fields i.e.\n            partition by field, type and expiration as per API specifications.\n\n            .. seealso::\n                https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#timePartitioning\n        :type time_partitioning: dict\n        :param cluster_fields: [Optional] The fields used for clustering.\n            Must be specified with time_partitioning, data in the table will be first\n            partitioned and subsequently clustered.\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#clustering.fields\n        :type cluster_fields: list\n        :param view: [Optional] A dictionary containing definition for the view.\n            If set, it will create a view instead of a table:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#view\n        :type view: dict\n\n        **Example**: ::\n\n            view = {\n                \"query\": \"SELECT * FROM `test-project-id.test_dataset_id.test_table_prefix*` LIMIT 1000\",\n                \"useLegacySql\": False\n            }\n\n        :return: None\n        \"\"\"\n\n        project_id = project_id if project_id is not None else self.project_id\n\n        table_resource = {\n            'tableReference': {\n                'tableId': table_id\n            }\n        }\n\n        if schema_fields:\n            table_resource['schema'] = {'fields': schema_fields}\n\n        if time_partitioning:\n            table_resource['timePartitioning'] = time_partitioning\n\n        if cluster_fields:\n            table_resource['clustering'] = {\n                'fields': cluster_fields\n            }\n\n        if labels:\n            table_resource['labels'] = labels\n\n        if view:\n            table_resource['view'] = view\n\n        num_retries = num_retries if num_retries else self.num_retries\n\n        self.log.info('Creating Table %s:%s.%s',\n                      project_id, dataset_id, table_id)\n\n        try:\n            self.service.tables().insert(\n                projectId=project_id,\n                datasetId=dataset_id,\n                body=table_resource).execute(num_retries=num_retries)\n\n            self.log.info('Table created successfully: %s:%s.%s',\n                          project_id, dataset_id, table_id)\n\n        except HttpError as err:\n            raise AirflowException(\n                'BigQuery job failed. Error was: {}'.format(err.content)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an external table in the Cloud Storage dataset.", "response": "def create_external_table(self,\n                              external_project_dataset_table,\n                              schema_fields,\n                              source_uris,\n                              source_format='CSV',\n                              autodetect=False,\n                              compression='NONE',\n                              ignore_unknown_values=False,\n                              max_bad_records=0,\n                              skip_leading_rows=0,\n                              field_delimiter=',',\n                              quote_character=None,\n                              allow_quoted_newlines=False,\n                              allow_jagged_rows=False,\n                              src_fmt_configs=None,\n                              labels=None\n                              ):\n        \"\"\"\n        Creates a new external table in the dataset with the data in Google\n        Cloud Storage. See here:\n\n        https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#resource\n\n        for more details about these parameters.\n\n        :param external_project_dataset_table:\n            The dotted ``(<project>.|<project>:)<dataset>.<table>($<partition>)`` BigQuery\n            table name to create external table.\n            If ``<project>`` is not included, project will be the\n            project defined in the connection json.\n        :type external_project_dataset_table: str\n        :param schema_fields: The schema field list as defined here:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#resource\n        :type schema_fields: list\n        :param source_uris: The source Google Cloud\n            Storage URI (e.g. gs://some-bucket/some-file.txt). A single wild\n            per-object name can be used.\n        :type source_uris: list\n        :param source_format: File format to export.\n        :type source_format: str\n        :param autodetect: Try to detect schema and format options automatically.\n            Any option specified explicitly will be honored.\n        :type autodetect: bool\n        :param compression: [Optional] The compression type of the data source.\n            Possible values include GZIP and NONE.\n            The default value is NONE.\n            This setting is ignored for Google Cloud Bigtable,\n            Google Cloud Datastore backups and Avro formats.\n        :type compression: str\n        :param ignore_unknown_values: [Optional] Indicates if BigQuery should allow\n            extra values that are not represented in the table schema.\n            If true, the extra values are ignored. If false, records with extra columns\n            are treated as bad records, and if there are too many bad records, an\n            invalid error is returned in the job result.\n        :type ignore_unknown_values: bool\n        :param max_bad_records: The maximum number of bad records that BigQuery can\n            ignore when running the job.\n        :type max_bad_records: int\n        :param skip_leading_rows: Number of rows to skip when loading from a CSV.\n        :type skip_leading_rows: int\n        :param field_delimiter: The delimiter to use when loading from a CSV.\n        :type field_delimiter: str\n        :param quote_character: The value that is used to quote data sections in a CSV\n            file.\n        :type quote_character: str\n        :param allow_quoted_newlines: Whether to allow quoted newlines (true) or not\n            (false).\n        :type allow_quoted_newlines: bool\n        :param allow_jagged_rows: Accept rows that are missing trailing optional columns.\n            The missing values are treated as nulls. If false, records with missing\n            trailing columns are treated as bad records, and if there are too many bad\n            records, an invalid error is returned in the job result. Only applicable when\n            soure_format is CSV.\n        :type allow_jagged_rows: bool\n        :param src_fmt_configs: configure optional fields specific to the source format\n        :type src_fmt_configs: dict\n        :param labels: a dictionary containing labels for the table, passed to BigQuery\n        :type labels: dict\n        \"\"\"\n\n        if src_fmt_configs is None:\n            src_fmt_configs = {}\n        project_id, dataset_id, external_table_id = \\\n            _split_tablename(table_input=external_project_dataset_table,\n                             default_project_id=self.project_id,\n                             var_name='external_project_dataset_table')\n\n        # bigquery only allows certain source formats\n        # we check to make sure the passed source format is valid\n        # if it's not, we raise a ValueError\n        # Refer to this link for more details:\n        #   https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#externalDataConfiguration.sourceFormat\n\n        source_format = source_format.upper()\n        allowed_formats = [\n            \"CSV\", \"NEWLINE_DELIMITED_JSON\", \"AVRO\", \"GOOGLE_SHEETS\",\n            \"DATASTORE_BACKUP\", \"PARQUET\"\n        ]\n        if source_format not in allowed_formats:\n            raise ValueError(\"{0} is not a valid source format. \"\n                             \"Please use one of the following types: {1}\"\n                             .format(source_format, allowed_formats))\n\n        compression = compression.upper()\n        allowed_compressions = ['NONE', 'GZIP']\n        if compression not in allowed_compressions:\n            raise ValueError(\"{0} is not a valid compression format. \"\n                             \"Please use one of the following types: {1}\"\n                             .format(compression, allowed_compressions))\n\n        table_resource = {\n            'externalDataConfiguration': {\n                'autodetect': autodetect,\n                'sourceFormat': source_format,\n                'sourceUris': source_uris,\n                'compression': compression,\n                'ignoreUnknownValues': ignore_unknown_values\n            },\n            'tableReference': {\n                'projectId': project_id,\n                'datasetId': dataset_id,\n                'tableId': external_table_id,\n            }\n        }\n\n        if schema_fields:\n            table_resource['externalDataConfiguration'].update({\n                'schema': {\n                    'fields': schema_fields\n                }\n            })\n\n        self.log.info('Creating external table: %s', external_project_dataset_table)\n\n        if max_bad_records:\n            table_resource['externalDataConfiguration']['maxBadRecords'] = max_bad_records\n\n        # if following fields are not specified in src_fmt_configs,\n        # honor the top-level params for backward-compatibility\n        if 'skipLeadingRows' not in src_fmt_configs:\n            src_fmt_configs['skipLeadingRows'] = skip_leading_rows\n        if 'fieldDelimiter' not in src_fmt_configs:\n            src_fmt_configs['fieldDelimiter'] = field_delimiter\n        if 'quote_character' not in src_fmt_configs:\n            src_fmt_configs['quote'] = quote_character\n        if 'allowQuotedNewlines' not in src_fmt_configs:\n            src_fmt_configs['allowQuotedNewlines'] = allow_quoted_newlines\n        if 'allowJaggedRows' not in src_fmt_configs:\n            src_fmt_configs['allowJaggedRows'] = allow_jagged_rows\n\n        src_fmt_to_param_mapping = {\n            'CSV': 'csvOptions',\n            'GOOGLE_SHEETS': 'googleSheetsOptions'\n        }\n\n        src_fmt_to_configs_mapping = {\n            'csvOptions': [\n                'allowJaggedRows', 'allowQuotedNewlines',\n                'fieldDelimiter', 'skipLeadingRows',\n                'quote'\n            ],\n            'googleSheetsOptions': ['skipLeadingRows']\n        }\n\n        if source_format in src_fmt_to_param_mapping.keys():\n\n            valid_configs = src_fmt_to_configs_mapping[\n                src_fmt_to_param_mapping[source_format]\n            ]\n\n            src_fmt_configs = {\n                k: v\n                for k, v in src_fmt_configs.items() if k in valid_configs\n            }\n\n            table_resource['externalDataConfiguration'][src_fmt_to_param_mapping[\n                source_format]] = src_fmt_configs\n\n        if labels:\n            table_resource['labels'] = labels\n\n        try:\n            self.service.tables().insert(\n                projectId=project_id,\n                datasetId=dataset_id,\n                body=table_resource\n            ).execute(num_retries=self.num_retries)\n\n            self.log.info('External table created successfully: %s',\n                          external_project_dataset_table)\n\n        except HttpError as err:\n            raise Exception(\n                'BigQuery job failed. Error was: {}'.format(err.content)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_table(self,\n                    dataset_id,\n                    table_id,\n                    project_id=None,\n                    description=None,\n                    expiration_time=None,\n                    external_data_configuration=None,\n                    friendly_name=None,\n                    labels=None,\n                    schema=None,\n                    time_partitioning=None,\n                    view=None,\n                    require_partition_filter=None):\n        \"\"\"\n        Patch information in an existing table.\n        It only updates fileds that are provided in the request object.\n\n        Reference: https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/patch\n\n        :param dataset_id: The dataset containing the table to be patched.\n        :type dataset_id: str\n        :param table_id: The Name of the table to be patched.\n        :type table_id: str\n        :param project_id: The project containing the table to be patched.\n        :type project_id: str\n        :param description: [Optional] A user-friendly description of this table.\n        :type description: str\n        :param expiration_time: [Optional] The time when this table expires,\n            in milliseconds since the epoch.\n        :type expiration_time: int\n        :param external_data_configuration: [Optional] A dictionary containing\n            properties of a table stored outside of BigQuery.\n        :type external_data_configuration: dict\n        :param friendly_name: [Optional] A descriptive name for this table.\n        :type friendly_name: str\n        :param labels: [Optional] A dictionary containing labels associated with this table.\n        :type labels: dict\n        :param schema: [Optional] If set, the schema field list as defined here:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schema\n            The supported schema modifications and unsupported schema modification are listed here:\n            https://cloud.google.com/bigquery/docs/managing-table-schemas\n            **Example**: ::\n\n                schema=[{\"name\": \"emp_name\", \"type\": \"STRING\", \"mode\": \"REQUIRED\"},\n                               {\"name\": \"salary\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"}]\n\n        :type schema: list\n        :param time_partitioning: [Optional] A dictionary containing time-based partitioning\n             definition for the table.\n        :type time_partitioning: dict\n        :param view: [Optional] A dictionary containing definition for the view.\n            If set, it will patch a view instead of a table:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#view\n            **Example**: ::\n\n                view = {\n                    \"query\": \"SELECT * FROM `test-project-id.test_dataset_id.test_table_prefix*` LIMIT 500\",\n                    \"useLegacySql\": False\n                }\n\n        :type view: dict\n        :param require_partition_filter: [Optional] If true, queries over the this table require a\n            partition filter. If false, queries over the table\n        :type require_partition_filter: bool\n\n        \"\"\"\n\n        project_id = project_id if project_id is not None else self.project_id\n\n        table_resource = {}\n\n        if description is not None:\n            table_resource['description'] = description\n        if expiration_time is not None:\n            table_resource['expirationTime'] = expiration_time\n        if external_data_configuration:\n            table_resource['externalDataConfiguration'] = external_data_configuration\n        if friendly_name is not None:\n            table_resource['friendlyName'] = friendly_name\n        if labels:\n            table_resource['labels'] = labels\n        if schema:\n            table_resource['schema'] = {'fields': schema}\n        if time_partitioning:\n            table_resource['timePartitioning'] = time_partitioning\n        if view:\n            table_resource['view'] = view\n        if require_partition_filter is not None:\n            table_resource['requirePartitionFilter'] = require_partition_filter\n\n        self.log.info('Patching Table %s:%s.%s',\n                      project_id, dataset_id, table_id)\n\n        try:\n            self.service.tables().patch(\n                projectId=project_id,\n                datasetId=dataset_id,\n                tableId=table_id,\n                body=table_resource).execute(num_retries=self.num_retries)\n\n            self.log.info('Table patched successfully: %s:%s.%s',\n                          project_id, dataset_id, table_id)\n\n        except HttpError as err:\n            raise AirflowException(\n                'BigQuery job failed. Error was: {}'.format(err.content)\n            )", "response": "This function patches the information in an existing table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a BigQuery SQL query and saves the results in a table.", "response": "def run_query(self,\n                  sql,\n                  destination_dataset_table=None,\n                  write_disposition='WRITE_EMPTY',\n                  allow_large_results=False,\n                  flatten_results=None,\n                  udf_config=None,\n                  use_legacy_sql=None,\n                  maximum_billing_tier=None,\n                  maximum_bytes_billed=None,\n                  create_disposition='CREATE_IF_NEEDED',\n                  query_params=None,\n                  labels=None,\n                  schema_update_options=(),\n                  priority='INTERACTIVE',\n                  time_partitioning=None,\n                  api_resource_configs=None,\n                  cluster_fields=None,\n                  location=None):\n        \"\"\"\n        Executes a BigQuery SQL query. Optionally persists results in a BigQuery\n        table. See here:\n\n        https://cloud.google.com/bigquery/docs/reference/v2/jobs\n\n        For more details about these parameters.\n\n        :param sql: The BigQuery SQL to execute.\n        :type sql: str\n        :param destination_dataset_table: The dotted ``<dataset>.<table>``\n            BigQuery table to save the query results.\n        :type destination_dataset_table: str\n        :param write_disposition: What to do if the table already exists in\n            BigQuery.\n        :type write_disposition: str\n        :param allow_large_results: Whether to allow large results.\n        :type allow_large_results: bool\n        :param flatten_results: If true and query uses legacy SQL dialect, flattens\n            all nested and repeated fields in the query results. ``allowLargeResults``\n            must be true if this is set to false. For standard SQL queries, this\n            flag is ignored and results are never flattened.\n        :type flatten_results: bool\n        :param udf_config: The User Defined Function configuration for the query.\n            See https://cloud.google.com/bigquery/user-defined-functions for details.\n        :type udf_config: list\n        :param use_legacy_sql: Whether to use legacy SQL (true) or standard SQL (false).\n            If `None`, defaults to `self.use_legacy_sql`.\n        :type use_legacy_sql: bool\n        :param api_resource_configs: a dictionary that contain params\n            'configuration' applied for Google BigQuery Jobs API:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs\n            for example, {'query': {'useQueryCache': False}}. You could use it\n            if you need to provide some params that are not supported by the\n            BigQueryHook like args.\n        :type api_resource_configs: dict\n        :param maximum_billing_tier: Positive integer that serves as a\n            multiplier of the basic price.\n        :type maximum_billing_tier: int\n        :param maximum_bytes_billed: Limits the bytes billed for this job.\n            Queries that will have bytes billed beyond this limit will fail\n            (without incurring a charge). If unspecified, this will be\n            set to your project default.\n        :type maximum_bytes_billed: float\n        :param create_disposition: Specifies whether the job is allowed to\n            create new tables.\n        :type create_disposition: str\n        :param query_params: a list of dictionary containing query parameter types and\n            values, passed to BigQuery\n        :type query_params: list\n        :param labels: a dictionary containing labels for the job/query,\n            passed to BigQuery\n        :type labels: dict\n        :param schema_update_options: Allows the schema of the destination\n            table to be updated as a side effect of the query job.\n        :type schema_update_options: tuple\n        :param priority: Specifies a priority for the query.\n            Possible values include INTERACTIVE and BATCH.\n            The default value is INTERACTIVE.\n        :type priority: str\n        :param time_partitioning: configure optional time partitioning fields i.e.\n            partition by field, type and expiration as per API specifications.\n        :type time_partitioning: dict\n        :param cluster_fields: Request that the result of this query be stored sorted\n            by one or more columns. This is only available in combination with\n            time_partitioning. The order of columns given determines the sort order.\n        :type cluster_fields: list[str]\n        :param location: The geographic location of the job. Required except for\n            US and EU. See details at\n            https://cloud.google.com/bigquery/docs/locations#specifying_your_location\n        :type location: str\n        \"\"\"\n\n        if time_partitioning is None:\n            time_partitioning = {}\n\n        if location:\n            self.location = location\n\n        if not api_resource_configs:\n            api_resource_configs = self.api_resource_configs\n        else:\n            _validate_value('api_resource_configs',\n                            api_resource_configs, dict)\n        configuration = deepcopy(api_resource_configs)\n        if 'query' not in configuration:\n            configuration['query'] = {}\n\n        else:\n            _validate_value(\"api_resource_configs['query']\",\n                            configuration['query'], dict)\n\n        if sql is None and not configuration['query'].get('query', None):\n            raise TypeError('`BigQueryBaseCursor.run_query` '\n                            'missing 1 required positional argument: `sql`')\n\n        # BigQuery also allows you to define how you want a table's schema to change\n        # as a side effect of a query job\n        # for more details:\n        #   https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.query.schemaUpdateOptions\n\n        allowed_schema_update_options = [\n            'ALLOW_FIELD_ADDITION', \"ALLOW_FIELD_RELAXATION\"\n        ]\n\n        if not set(allowed_schema_update_options\n                   ).issuperset(set(schema_update_options)):\n            raise ValueError(\"{0} contains invalid schema update options. \"\n                             \"Please only use one or more of the following \"\n                             \"options: {1}\"\n                             .format(schema_update_options,\n                                     allowed_schema_update_options))\n\n        if schema_update_options:\n            if write_disposition not in [\"WRITE_APPEND\", \"WRITE_TRUNCATE\"]:\n                raise ValueError(\"schema_update_options is only \"\n                                 \"allowed if write_disposition is \"\n                                 \"'WRITE_APPEND' or 'WRITE_TRUNCATE'.\")\n\n        if destination_dataset_table:\n            destination_project, destination_dataset, destination_table = \\\n                _split_tablename(table_input=destination_dataset_table,\n                                 default_project_id=self.project_id)\n\n            destination_dataset_table = {\n                'projectId': destination_project,\n                'datasetId': destination_dataset,\n                'tableId': destination_table,\n            }\n\n        if cluster_fields:\n            cluster_fields = {'fields': cluster_fields}\n\n        query_param_list = [\n            (sql, 'query', None, six.string_types),\n            (priority, 'priority', 'INTERACTIVE', six.string_types),\n            (use_legacy_sql, 'useLegacySql', self.use_legacy_sql, bool),\n            (query_params, 'queryParameters', None, list),\n            (udf_config, 'userDefinedFunctionResources', None, list),\n            (maximum_billing_tier, 'maximumBillingTier', None, int),\n            (maximum_bytes_billed, 'maximumBytesBilled', None, float),\n            (time_partitioning, 'timePartitioning', {}, dict),\n            (schema_update_options, 'schemaUpdateOptions', None, tuple),\n            (destination_dataset_table, 'destinationTable', None, dict),\n            (cluster_fields, 'clustering', None, dict),\n        ]\n\n        for param_tuple in query_param_list:\n\n            param, param_name, param_default, param_type = param_tuple\n\n            if param_name not in configuration['query'] and param in [None, {}, ()]:\n                if param_name == 'timePartitioning':\n                    param_default = _cleanse_time_partitioning(\n                        destination_dataset_table, time_partitioning)\n                param = param_default\n\n            if param not in [None, {}, ()]:\n                _api_resource_configs_duplication_check(\n                    param_name, param, configuration['query'])\n\n                configuration['query'][param_name] = param\n\n                # check valid type of provided param,\n                # it last step because we can get param from 2 sources,\n                # and first of all need to find it\n\n                _validate_value(param_name, configuration['query'][param_name],\n                                param_type)\n\n                if param_name == 'schemaUpdateOptions' and param:\n                    self.log.info(\"Adding experimental 'schemaUpdateOptions': \"\n                                  \"%s\", schema_update_options)\n\n                if param_name == 'destinationTable':\n                    for key in ['projectId', 'datasetId', 'tableId']:\n                        if key not in configuration['query']['destinationTable']:\n                            raise ValueError(\n                                \"Not correct 'destinationTable' in \"\n                                \"api_resource_configs. 'destinationTable' \"\n                                \"must be a dict with {'projectId':'', \"\n                                \"'datasetId':'', 'tableId':''}\")\n\n                    configuration['query'].update({\n                        'allowLargeResults': allow_large_results,\n                        'flattenResults': flatten_results,\n                        'writeDisposition': write_disposition,\n                        'createDisposition': create_disposition,\n                    })\n\n        if 'useLegacySql' in configuration['query'] and configuration['query']['useLegacySql'] and\\\n                'queryParameters' in configuration['query']:\n            raise ValueError(\"Query parameters are not allowed \"\n                             \"when using legacy SQL\")\n\n        if labels:\n            _api_resource_configs_duplication_check(\n                'labels', labels, configuration)\n            configuration['labels'] = labels\n\n        return self.run_with_configuration(configuration)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_extract(  # noqa\n            self,\n            source_project_dataset_table,\n            destination_cloud_storage_uris,\n            compression='NONE',\n            export_format='CSV',\n            field_delimiter=',',\n            print_header=True,\n            labels=None):\n        \"\"\"\n        Executes a BigQuery extract command to copy data from BigQuery to\n        Google Cloud Storage. See here:\n\n        https://cloud.google.com/bigquery/docs/reference/v2/jobs\n\n        For more details about these parameters.\n\n        :param source_project_dataset_table: The dotted ``<dataset>.<table>``\n            BigQuery table to use as the source data.\n        :type source_project_dataset_table: str\n        :param destination_cloud_storage_uris: The destination Google Cloud\n            Storage URI (e.g. gs://some-bucket/some-file.txt). Follows\n            convention defined here:\n            https://cloud.google.com/bigquery/exporting-data-from-bigquery#exportingmultiple\n        :type destination_cloud_storage_uris: list\n        :param compression: Type of compression to use.\n        :type compression: str\n        :param export_format: File format to export.\n        :type export_format: str\n        :param field_delimiter: The delimiter to use when extracting to a CSV.\n        :type field_delimiter: str\n        :param print_header: Whether to print a header for a CSV file extract.\n        :type print_header: bool\n        :param labels: a dictionary containing labels for the job/query,\n            passed to BigQuery\n        :type labels: dict\n        \"\"\"\n\n        source_project, source_dataset, source_table = \\\n            _split_tablename(table_input=source_project_dataset_table,\n                             default_project_id=self.project_id,\n                             var_name='source_project_dataset_table')\n\n        configuration = {\n            'extract': {\n                'sourceTable': {\n                    'projectId': source_project,\n                    'datasetId': source_dataset,\n                    'tableId': source_table,\n                },\n                'compression': compression,\n                'destinationUris': destination_cloud_storage_uris,\n                'destinationFormat': export_format,\n            }\n        }\n\n        if labels:\n            configuration['labels'] = labels\n\n        if export_format == 'CSV':\n            # Only set fieldDelimiter and printHeader fields if using CSV.\n            # Google does not like it if you set these fields for other export\n            # formats.\n            configuration['extract']['fieldDelimiter'] = field_delimiter\n            configuration['extract']['printHeader'] = print_header\n\n        return self.run_with_configuration(configuration)", "response": "Executes a BigQuery extract command to copy data from source_project_dataset_table to destination_project_dataset_table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a BigQuery copy command.", "response": "def run_copy(self,\n                 source_project_dataset_tables,\n                 destination_project_dataset_table,\n                 write_disposition='WRITE_EMPTY',\n                 create_disposition='CREATE_IF_NEEDED',\n                 labels=None):\n        \"\"\"\n        Executes a BigQuery copy command to copy data from one BigQuery table\n        to another. See here:\n\n        https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.copy\n\n        For more details about these parameters.\n\n        :param source_project_dataset_tables: One or more dotted\n            ``(project:|project.)<dataset>.<table>``\n            BigQuery tables to use as the source data. Use a list if there are\n            multiple source tables.\n            If ``<project>`` is not included, project will be the project defined\n            in the connection json.\n        :type source_project_dataset_tables: list|string\n        :param destination_project_dataset_table: The destination BigQuery\n            table. Format is: ``(project:|project.)<dataset>.<table>``\n        :type destination_project_dataset_table: str\n        :param write_disposition: The write disposition if the table already exists.\n        :type write_disposition: str\n        :param create_disposition: The create disposition if the table doesn't exist.\n        :type create_disposition: str\n        :param labels: a dictionary containing labels for the job/query,\n            passed to BigQuery\n        :type labels: dict\n        \"\"\"\n        source_project_dataset_tables = ([\n            source_project_dataset_tables\n        ] if not isinstance(source_project_dataset_tables, list) else\n            source_project_dataset_tables)\n\n        source_project_dataset_tables_fixup = []\n        for source_project_dataset_table in source_project_dataset_tables:\n            source_project, source_dataset, source_table = \\\n                _split_tablename(table_input=source_project_dataset_table,\n                                 default_project_id=self.project_id,\n                                 var_name='source_project_dataset_table')\n            source_project_dataset_tables_fixup.append({\n                'projectId':\n                source_project,\n                'datasetId':\n                source_dataset,\n                'tableId':\n                source_table\n            })\n\n        destination_project, destination_dataset, destination_table = \\\n            _split_tablename(table_input=destination_project_dataset_table,\n                             default_project_id=self.project_id)\n        configuration = {\n            'copy': {\n                'createDisposition': create_disposition,\n                'writeDisposition': write_disposition,\n                'sourceTables': source_project_dataset_tables_fixup,\n                'destinationTable': {\n                    'projectId': destination_project,\n                    'datasetId': destination_dataset,\n                    'tableId': destination_table\n                }\n            }\n        }\n\n        if labels:\n            configuration['labels'] = labels\n\n        return self.run_with_configuration(configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_load(self,\n                 destination_project_dataset_table,\n                 source_uris,\n                 schema_fields=None,\n                 source_format='CSV',\n                 create_disposition='CREATE_IF_NEEDED',\n                 skip_leading_rows=0,\n                 write_disposition='WRITE_EMPTY',\n                 field_delimiter=',',\n                 max_bad_records=0,\n                 quote_character=None,\n                 ignore_unknown_values=False,\n                 allow_quoted_newlines=False,\n                 allow_jagged_rows=False,\n                 schema_update_options=(),\n                 src_fmt_configs=None,\n                 time_partitioning=None,\n                 cluster_fields=None,\n                 autodetect=False):\n        \"\"\"\n        Executes a BigQuery load command to load data from Google Cloud Storage\n        to BigQuery. See here:\n\n        https://cloud.google.com/bigquery/docs/reference/v2/jobs\n\n        For more details about these parameters.\n\n        :param destination_project_dataset_table:\n            The dotted ``(<project>.|<project>:)<dataset>.<table>($<partition>)`` BigQuery\n            table to load data into. If ``<project>`` is not included, project will be the\n            project defined in the connection json. If a partition is specified the\n            operator will automatically append the data, create a new partition or create\n            a new DAY partitioned table.\n        :type destination_project_dataset_table: str\n        :param schema_fields: The schema field list as defined here:\n            https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.load\n            Required if autodetect=False; optional if autodetect=True.\n        :type schema_fields: list\n        :param autodetect: Attempt to autodetect the schema for CSV and JSON\n            source files.\n        :type autodetect: bool\n        :param source_uris: The source Google Cloud\n            Storage URI (e.g. gs://some-bucket/some-file.txt). A single wild\n            per-object name can be used.\n        :type source_uris: list\n        :param source_format: File format to export.\n        :type source_format: str\n        :param create_disposition: The create disposition if the table doesn't exist.\n        :type create_disposition: str\n        :param skip_leading_rows: Number of rows to skip when loading from a CSV.\n        :type skip_leading_rows: int\n        :param write_disposition: The write disposition if the table already exists.\n        :type write_disposition: str\n        :param field_delimiter: The delimiter to use when loading from a CSV.\n        :type field_delimiter: str\n        :param max_bad_records: The maximum number of bad records that BigQuery can\n            ignore when running the job.\n        :type max_bad_records: int\n        :param quote_character: The value that is used to quote data sections in a CSV\n            file.\n        :type quote_character: str\n        :param ignore_unknown_values: [Optional] Indicates if BigQuery should allow\n            extra values that are not represented in the table schema.\n            If true, the extra values are ignored. If false, records with extra columns\n            are treated as bad records, and if there are too many bad records, an\n            invalid error is returned in the job result.\n        :type ignore_unknown_values: bool\n        :param allow_quoted_newlines: Whether to allow quoted newlines (true) or not\n            (false).\n        :type allow_quoted_newlines: bool\n        :param allow_jagged_rows: Accept rows that are missing trailing optional columns.\n            The missing values are treated as nulls. If false, records with missing\n            trailing columns are treated as bad records, and if there are too many bad\n            records, an invalid error is returned in the job result. Only applicable when\n            soure_format is CSV.\n        :type allow_jagged_rows: bool\n        :param schema_update_options: Allows the schema of the destination\n            table to be updated as a side effect of the load job.\n        :type schema_update_options: tuple\n        :param src_fmt_configs: configure optional fields specific to the source format\n        :type src_fmt_configs: dict\n        :param time_partitioning: configure optional time partitioning fields i.e.\n            partition by field, type and  expiration as per API specifications.\n        :type time_partitioning: dict\n        :param cluster_fields: Request that the result of this load be stored sorted\n            by one or more columns. This is only available in combination with\n            time_partitioning. The order of columns given determines the sort order.\n        :type cluster_fields: list[str]\n        \"\"\"\n\n        # bigquery only allows certain source formats\n        # we check to make sure the passed source format is valid\n        # if it's not, we raise a ValueError\n        # Refer to this link for more details:\n        #   https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.query.tableDefinitions.(key).sourceFormat\n\n        if schema_fields is None and not autodetect:\n            raise ValueError(\n                'You must either pass a schema or autodetect=True.')\n\n        if src_fmt_configs is None:\n            src_fmt_configs = {}\n\n        source_format = source_format.upper()\n        allowed_formats = [\n            \"CSV\", \"NEWLINE_DELIMITED_JSON\", \"AVRO\", \"GOOGLE_SHEETS\",\n            \"DATASTORE_BACKUP\", \"PARQUET\"\n        ]\n        if source_format not in allowed_formats:\n            raise ValueError(\"{0} is not a valid source format. \"\n                             \"Please use one of the following types: {1}\"\n                             .format(source_format, allowed_formats))\n\n        # bigquery also allows you to define how you want a table's schema to change\n        # as a side effect of a load\n        # for more details:\n        # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.load.schemaUpdateOptions\n        allowed_schema_update_options = [\n            'ALLOW_FIELD_ADDITION', \"ALLOW_FIELD_RELAXATION\"\n        ]\n        if not set(allowed_schema_update_options).issuperset(\n                set(schema_update_options)):\n            raise ValueError(\n                \"{0} contains invalid schema update options.\"\n                \"Please only use one or more of the following options: {1}\"\n                .format(schema_update_options, allowed_schema_update_options))\n\n        destination_project, destination_dataset, destination_table = \\\n            _split_tablename(table_input=destination_project_dataset_table,\n                             default_project_id=self.project_id,\n                             var_name='destination_project_dataset_table')\n\n        configuration = {\n            'load': {\n                'autodetect': autodetect,\n                'createDisposition': create_disposition,\n                'destinationTable': {\n                    'projectId': destination_project,\n                    'datasetId': destination_dataset,\n                    'tableId': destination_table,\n                },\n                'sourceFormat': source_format,\n                'sourceUris': source_uris,\n                'writeDisposition': write_disposition,\n                'ignoreUnknownValues': ignore_unknown_values\n            }\n        }\n\n        time_partitioning = _cleanse_time_partitioning(\n            destination_project_dataset_table,\n            time_partitioning\n        )\n        if time_partitioning:\n            configuration['load'].update({\n                'timePartitioning': time_partitioning\n            })\n\n        if cluster_fields:\n            configuration['load'].update({'clustering': {'fields': cluster_fields}})\n\n        if schema_fields:\n            configuration['load']['schema'] = {'fields': schema_fields}\n\n        if schema_update_options:\n            if write_disposition not in [\"WRITE_APPEND\", \"WRITE_TRUNCATE\"]:\n                raise ValueError(\"schema_update_options is only \"\n                                 \"allowed if write_disposition is \"\n                                 \"'WRITE_APPEND' or 'WRITE_TRUNCATE'.\")\n            else:\n                self.log.info(\n                    \"Adding experimental 'schemaUpdateOptions': %s\",\n                    schema_update_options\n                )\n                configuration['load'][\n                    'schemaUpdateOptions'] = schema_update_options\n\n        if max_bad_records:\n            configuration['load']['maxBadRecords'] = max_bad_records\n\n        # if following fields are not specified in src_fmt_configs,\n        # honor the top-level params for backward-compatibility\n        if 'skipLeadingRows' not in src_fmt_configs:\n            src_fmt_configs['skipLeadingRows'] = skip_leading_rows\n        if 'fieldDelimiter' not in src_fmt_configs:\n            src_fmt_configs['fieldDelimiter'] = field_delimiter\n        if 'ignoreUnknownValues' not in src_fmt_configs:\n            src_fmt_configs['ignoreUnknownValues'] = ignore_unknown_values\n        if quote_character is not None:\n            src_fmt_configs['quote'] = quote_character\n        if allow_quoted_newlines:\n            src_fmt_configs['allowQuotedNewlines'] = allow_quoted_newlines\n\n        src_fmt_to_configs_mapping = {\n            'CSV': [\n                'allowJaggedRows', 'allowQuotedNewlines', 'autodetect',\n                'fieldDelimiter', 'skipLeadingRows', 'ignoreUnknownValues',\n                'nullMarker', 'quote'\n            ],\n            'DATASTORE_BACKUP': ['projectionFields'],\n            'NEWLINE_DELIMITED_JSON': ['autodetect', 'ignoreUnknownValues'],\n            'PARQUET': ['autodetect', 'ignoreUnknownValues'],\n            'AVRO': ['useAvroLogicalTypes'],\n        }\n        valid_configs = src_fmt_to_configs_mapping[source_format]\n        src_fmt_configs = {\n            k: v\n            for k, v in src_fmt_configs.items() if k in valid_configs\n        }\n        configuration['load'].update(src_fmt_configs)\n\n        if allow_jagged_rows:\n            configuration['load']['allowJaggedRows'] = allow_jagged_rows\n\n        return self.run_with_configuration(configuration)", "response": "Executes a BigQuery load command to load data from a Google Cloud Storage object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_with_configuration(self, configuration):\n        jobs = self.service.jobs()\n        job_data = {'configuration': configuration}\n\n        # Send query and wait for reply.\n        query_reply = jobs \\\n            .insert(projectId=self.project_id, body=job_data) \\\n            .execute(num_retries=self.num_retries)\n        self.running_job_id = query_reply['jobReference']['jobId']\n        if 'location' in query_reply['jobReference']:\n            location = query_reply['jobReference']['location']\n        else:\n            location = self.location\n\n        # Wait for query to finish.\n        keep_polling_job = True\n        while keep_polling_job:\n            try:\n                if location:\n                    job = jobs.get(\n                        projectId=self.project_id,\n                        jobId=self.running_job_id,\n                        location=location).execute(num_retries=self.num_retries)\n                else:\n                    job = jobs.get(\n                        projectId=self.project_id,\n                        jobId=self.running_job_id).execute(num_retries=self.num_retries)\n                if job['status']['state'] == 'DONE':\n                    keep_polling_job = False\n                    # Check if job had errors.\n                    if 'errorResult' in job['status']:\n                        raise Exception(\n                            'BigQuery job failed. Final error was: {}. The job was: {}'.\n                            format(job['status']['errorResult'], job))\n                else:\n                    self.log.info('Waiting for job to complete : %s, %s',\n                                  self.project_id, self.running_job_id)\n                    time.sleep(5)\n\n            except HttpError as err:\n                if err.resp.status in [500, 503]:\n                    self.log.info(\n                        '%s: Retryable error, waiting for job to complete: %s',\n                        err.resp.status, self.running_job_id)\n                    time.sleep(5)\n                else:\n                    raise Exception(\n                        'BigQuery job status check failed. Final error was: {}'.\n                        format(err.resp.status))\n\n        return self.running_job_id", "response": "Executes a BigQuery SQL query and waits for the job to complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cancel_query(self):\n        jobs = self.service.jobs()\n        if (self.running_job_id and\n                not self.poll_job_complete(self.running_job_id)):\n            self.log.info('Attempting to cancel job : %s, %s', self.project_id,\n                          self.running_job_id)\n            if self.location:\n                jobs.cancel(\n                    projectId=self.project_id,\n                    jobId=self.running_job_id,\n                    location=self.location).execute(num_retries=self.num_retries)\n            else:\n                jobs.cancel(\n                    projectId=self.project_id,\n                    jobId=self.running_job_id).execute(num_retries=self.num_retries)\n        else:\n            self.log.info('No running BigQuery jobs to cancel.')\n            return\n\n        # Wait for all the calls to cancel to finish\n        max_polling_attempts = 12\n        polling_attempts = 0\n\n        job_complete = False\n        while polling_attempts < max_polling_attempts and not job_complete:\n            polling_attempts = polling_attempts + 1\n            job_complete = self.poll_job_complete(self.running_job_id)\n            if job_complete:\n                self.log.info('Job successfully canceled: %s, %s',\n                              self.project_id, self.running_job_id)\n            elif polling_attempts == max_polling_attempts:\n                self.log.info(\n                    \"Stopping polling due to timeout. Job with id %s \"\n                    \"has not completed cancel and may or may not finish.\",\n                    self.running_job_id)\n            else:\n                self.log.info('Waiting for canceled job with id %s to finish.',\n                              self.running_job_id)\n                time.sleep(5)", "response": "Cancel all started queries that have not yet completed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the schema for a given dataset. table.", "response": "def get_schema(self, dataset_id, table_id):\n        \"\"\"\n        Get the schema for a given datset.table.\n        see https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\n\n        :param dataset_id: the dataset ID of the requested table\n        :param table_id: the table ID of the requested table\n        :return: a table schema\n        \"\"\"\n        tables_resource = self.service.tables() \\\n            .get(projectId=self.project_id, datasetId=dataset_id, tableId=table_id) \\\n            .execute(num_retries=self.num_retries)\n        return tables_resource['schema']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tabledata(self, dataset_id, table_id,\n                      max_results=None, selected_fields=None, page_token=None,\n                      start_index=None):\n        \"\"\"\n        Get the data of a given dataset.table and optionally with selected columns.\n        see https://cloud.google.com/bigquery/docs/reference/v2/tabledata/list\n\n        :param dataset_id: the dataset ID of the requested table.\n        :param table_id: the table ID of the requested table.\n        :param max_results: the maximum results to return.\n        :param selected_fields: List of fields to return (comma-separated). If\n            unspecified, all fields are returned.\n        :param page_token: page token, returned from a previous call,\n            identifying the result set.\n        :param start_index: zero based index of the starting row to read.\n        :return: map containing the requested rows.\n        \"\"\"\n        optional_params = {}\n        if max_results:\n            optional_params['maxResults'] = max_results\n        if selected_fields:\n            optional_params['selectedFields'] = selected_fields\n        if page_token:\n            optional_params['pageToken'] = page_token\n        if start_index:\n            optional_params['startIndex'] = start_index\n        return (self.service.tabledata().list(\n            projectId=self.project_id,\n            datasetId=dataset_id,\n            tableId=table_id,\n            **optional_params).execute(num_retries=self.num_retries))", "response": "Get the data of a given dataset. table and optionally with selected columns."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_table_delete(self, deletion_dataset_table,\n                         ignore_if_missing=False):\n        \"\"\"\n        Delete an existing table from the dataset;\n        If the table does not exist, return an error unless ignore_if_missing\n        is set to True.\n\n        :param deletion_dataset_table: A dotted\n            ``(<project>.|<project>:)<dataset>.<table>`` that indicates which table\n            will be deleted.\n        :type deletion_dataset_table: str\n        :param ignore_if_missing: if True, then return success even if the\n            requested table does not exist.\n        :type ignore_if_missing: bool\n        :return:\n        \"\"\"\n        deletion_project, deletion_dataset, deletion_table = \\\n            _split_tablename(table_input=deletion_dataset_table,\n                             default_project_id=self.project_id)\n\n        try:\n            self.service.tables() \\\n                .delete(projectId=deletion_project,\n                        datasetId=deletion_dataset,\n                        tableId=deletion_table) \\\n                .execute(num_retries=self.num_retries)\n            self.log.info('Deleted table %s:%s.%s.', deletion_project,\n                          deletion_dataset, deletion_table)\n        except HttpError:\n            if not ignore_if_missing:\n                raise Exception('Table deletion failed. Table does not exist.')\n            else:\n                self.log.info('Table does not exist. Skipping.')", "response": "Delete an existing table from the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun an upsert operation on the table resource.", "response": "def run_table_upsert(self, dataset_id, table_resource, project_id=None):\n        \"\"\"\n        creates a new, empty table in the dataset;\n        If the table already exists, update the existing table.\n        Since BigQuery does not natively allow table upserts, this is not an\n        atomic operation.\n\n        :param dataset_id: the dataset to upsert the table into.\n        :type dataset_id: str\n        :param table_resource: a table resource. see\n            https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\n        :type table_resource: dict\n        :param project_id: the project to upsert the table into.  If None,\n            project will be self.project_id.\n        :return:\n        \"\"\"\n        # check to see if the table exists\n        table_id = table_resource['tableReference']['tableId']\n        project_id = project_id if project_id is not None else self.project_id\n        tables_list_resp = self.service.tables().list(\n            projectId=project_id, datasetId=dataset_id).execute(num_retries=self.num_retries)\n        while True:\n            for table in tables_list_resp.get('tables', []):\n                if table['tableReference']['tableId'] == table_id:\n                    # found the table, do update\n                    self.log.info('Table %s:%s.%s exists, updating.',\n                                  project_id, dataset_id, table_id)\n                    return self.service.tables().update(\n                        projectId=project_id,\n                        datasetId=dataset_id,\n                        tableId=table_id,\n                        body=table_resource).execute(num_retries=self.num_retries)\n            # If there is a next page, we need to check the next page.\n            if 'nextPageToken' in tables_list_resp:\n                tables_list_resp = self.service.tables()\\\n                    .list(projectId=project_id,\n                          datasetId=dataset_id,\n                          pageToken=tables_list_resp['nextPageToken'])\\\n                    .execute(num_retries=self.num_retries)\n            # If there is no next page, then the table doesn't exist.\n            else:\n                # do insert\n                self.log.info('Table %s:%s.%s does not exist. creating.',\n                              project_id, dataset_id, table_id)\n                return self.service.tables().insert(\n                    projectId=project_id,\n                    datasetId=dataset_id,\n                    body=table_resource).execute(num_retries=self.num_retries)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_grant_dataset_view_access(self,\n                                      source_dataset,\n                                      view_dataset,\n                                      view_table,\n                                      source_project=None,\n                                      view_project=None):\n        \"\"\"\n        Grant authorized view access of a dataset to a view table.\n        If this view has already been granted access to the dataset, do nothing.\n        This method is not atomic.  Running it may clobber a simultaneous update.\n\n        :param source_dataset: the source dataset\n        :type source_dataset: str\n        :param view_dataset: the dataset that the view is in\n        :type view_dataset: str\n        :param view_table: the table of the view\n        :type view_table: str\n        :param source_project: the project of the source dataset. If None,\n            self.project_id will be used.\n        :type source_project: str\n        :param view_project: the project that the view is in. If None,\n            self.project_id will be used.\n        :type view_project: str\n        :return: the datasets resource of the source dataset.\n        \"\"\"\n\n        # Apply default values to projects\n        source_project = source_project if source_project else self.project_id\n        view_project = view_project if view_project else self.project_id\n\n        # we don't want to clobber any existing accesses, so we have to get\n        # info on the dataset before we can add view access\n        source_dataset_resource = self.service.datasets().get(\n            projectId=source_project, datasetId=source_dataset).execute(num_retries=self.num_retries)\n        access = source_dataset_resource[\n            'access'] if 'access' in source_dataset_resource else []\n        view_access = {\n            'view': {\n                'projectId': view_project,\n                'datasetId': view_dataset,\n                'tableId': view_table\n            }\n        }\n        # check to see if the view we want to add already exists.\n        if view_access not in access:\n            self.log.info(\n                'Granting table %s:%s.%s authorized view access to %s:%s dataset.',\n                view_project, view_dataset, view_table, source_project,\n                source_dataset)\n            access.append(view_access)\n            return self.service.datasets().patch(\n                projectId=source_project,\n                datasetId=source_dataset,\n                body={\n                    'access': access\n                }).execute(num_retries=self.num_retries)\n        else:\n            # if view is already in access, do nothing.\n            self.log.info(\n                'Table %s:%s.%s already has authorized view access to %s:%s dataset.',\n                view_project, view_dataset, view_table, source_project, source_dataset)\n            return source_dataset_resource", "response": "This method grants authorized view access of a dataset to a view table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an empty dataset.", "response": "def create_empty_dataset(self, dataset_id=\"\", project_id=\"\",\n                             dataset_reference=None):\n        \"\"\"\n        Create a new empty dataset:\n        https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert\n\n        :param project_id: The name of the project where we want to create\n            an empty a dataset. Don't need to provide, if projectId in dataset_reference.\n        :type project_id: str\n        :param dataset_id: The id of dataset. Don't need to provide,\n            if datasetId in dataset_reference.\n        :type dataset_id: str\n        :param dataset_reference: Dataset reference that could be provided\n            with request body. More info:\n            https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource\n        :type dataset_reference: dict\n        \"\"\"\n\n        if dataset_reference:\n            _validate_value('dataset_reference', dataset_reference, dict)\n        else:\n            dataset_reference = {}\n\n        if \"datasetReference\" not in dataset_reference:\n            dataset_reference[\"datasetReference\"] = {}\n\n        if not dataset_reference[\"datasetReference\"].get(\"datasetId\") and not dataset_id:\n            raise ValueError(\n                \"{} not provided datasetId. Impossible to create dataset\")\n\n        dataset_required_params = [(dataset_id, \"datasetId\", \"\"),\n                                   (project_id, \"projectId\", self.project_id)]\n        for param_tuple in dataset_required_params:\n            param, param_name, param_default = param_tuple\n            if param_name not in dataset_reference['datasetReference']:\n                if param_default and not param:\n                    self.log.info(\n                        \"%s was not specified. Will be used default value %s.\",\n                        param_name, param_default\n                    )\n                    param = param_default\n                dataset_reference['datasetReference'].update(\n                    {param_name: param})\n            elif param:\n                _api_resource_configs_duplication_check(\n                    param_name, param,\n                    dataset_reference['datasetReference'], 'dataset_reference')\n\n        dataset_id = dataset_reference.get(\"datasetReference\").get(\"datasetId\")\n        dataset_project_id = dataset_reference.get(\"datasetReference\").get(\n            \"projectId\")\n\n        self.log.info('Creating Dataset: %s in project: %s ', dataset_id,\n                      dataset_project_id)\n\n        try:\n            self.service.datasets().insert(\n                projectId=dataset_project_id,\n                body=dataset_reference).execute(num_retries=self.num_retries)\n            self.log.info('Dataset created successfully: In project %s '\n                          'Dataset %s', dataset_project_id, dataset_id)\n\n        except HttpError as err:\n            raise AirflowException(\n                'BigQuery job failed. Error was: {}'.format(err.content)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a dataset of Big query in your project.", "response": "def delete_dataset(self, project_id, dataset_id):\n        \"\"\"\n        Delete a dataset of Big query in your project.\n        :param project_id: The name of the project where we have the dataset .\n        :type project_id: str\n        :param dataset_id: The dataset to be delete.\n        :type dataset_id: str\n        :return:\n        \"\"\"\n        project_id = project_id if project_id is not None else self.project_id\n        self.log.info('Deleting from project: %s  Dataset:%s',\n                      project_id, dataset_id)\n\n        try:\n            self.service.datasets().delete(\n                projectId=project_id,\n                datasetId=dataset_id).execute(num_retries=self.num_retries)\n            self.log.info('Dataset deleted successfully: In project %s '\n                          'Dataset %s', project_id, dataset_id)\n\n        except HttpError as err:\n            raise AirflowException(\n                'BigQuery job failed. Error was: {}'.format(err.content)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dataset(self, dataset_id, project_id=None):\n\n        if not dataset_id or not isinstance(dataset_id, str):\n            raise ValueError(\"dataset_id argument must be provided and has \"\n                             \"a type 'str'. You provided: {}\".format(dataset_id))\n\n        dataset_project_id = project_id if project_id else self.project_id\n\n        try:\n            dataset_resource = self.service.datasets().get(\n                datasetId=dataset_id, projectId=dataset_project_id).execute(num_retries=self.num_retries)\n            self.log.info(\"Dataset Resource: %s\", dataset_resource)\n        except HttpError as err:\n            raise AirflowException(\n                'BigQuery job failed. Error was: {}'.format(err.content))\n\n        return dataset_resource", "response": "Method returns dataset_resource if dataset exists and raised 404 error if dataset does not exist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting a BigQuery query and returns the job ID.", "response": "def execute(self, operation, parameters=None):\n        \"\"\"\n        Executes a BigQuery query, and returns the job ID.\n\n        :param operation: The query to execute.\n        :type operation: str\n        :param parameters: Parameters to substitute into the query.\n        :type parameters: dict\n        \"\"\"\n        sql = _bind_parameters(operation,\n                               parameters) if parameters else operation\n        self.job_id = self.run_query(sql)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef executemany(self, operation, seq_of_parameters):\n        for parameters in seq_of_parameters:\n            self.execute(operation, parameters)", "response": "Execute a BigQuery query multiple times with different parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self):\n        if not self.job_id:\n            return None\n\n        if len(self.buffer) == 0:\n            if self.all_pages_loaded:\n                return None\n\n            query_results = (self.service.jobs().getQueryResults(\n                projectId=self.project_id,\n                jobId=self.job_id,\n                pageToken=self.page_token).execute(num_retries=self.num_retries))\n\n            if 'rows' in query_results and query_results['rows']:\n                self.page_token = query_results.get('pageToken')\n                fields = query_results['schema']['fields']\n                col_types = [field['type'] for field in fields]\n                rows = query_results['rows']\n\n                for dict_row in rows:\n                    typed_row = ([\n                        _bq_cast(vs['v'], col_types[idx])\n                        for idx, vs in enumerate(dict_row['f'])\n                    ])\n                    self.buffer.append(typed_row)\n\n                if not self.page_token:\n                    self.all_pages_loaded = True\n\n            else:\n                # Reset all state since we've exhausted the results.\n                self.page_token = None\n                self.job_id = None\n                self.page_token = None\n                return None\n\n        return self.buffer.pop(0)", "response": "Returns the next entry in the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the next set of rows of a query result returning a list of tuples.", "response": "def fetchmany(self, size=None):\n        \"\"\"\n        Fetch the next set of rows of a query result, returning a sequence of sequences\n        (e.g. a list of tuples). An empty sequence is returned when no more rows are\n        available. The number of rows to fetch per call is specified by the parameter.\n        If it is not given, the cursor's arraysize determines the number of rows to be\n        fetched. The method should try to fetch as many rows as indicated by the size\n        parameter. If this is not possible due to the specified number of rows not being\n        available, fewer rows may be returned. An :py:class:`~pyhive.exc.Error`\n        (or subclass) exception is raised if the previous call to\n        :py:meth:`execute` did not produce any result set or no call was issued yet.\n        \"\"\"\n        if size is None:\n            size = self.arraysize\n        result = []\n        for _ in range(size):\n            one = self.fetchone()\n            if one is None:\n                break\n            else:\n                result.append(one)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetchall(self):\n        result = []\n        while True:\n            one = self.fetchone()\n            if one is None:\n                break\n            else:\n                result.append(one)\n        return result", "response": "Fetch all rows of a query result returning them as a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the manifest file and registers the url_for_asset_ template tag.", "response": "def configure_manifest_files(app):\n    \"\"\"\n    Loads the manifest file and register the `url_for_asset_` template tag.\n    :param app:\n    :return:\n    \"\"\"\n\n    def parse_manifest_json():\n        # noinspection PyBroadException\n        try:\n            global manifest\n            manifest_file = os.path.join(os.path.dirname(__file__),\n                                         'static/dist/manifest.json')\n            with open(manifest_file, 'r') as f:\n                manifest.update(json.load(f))\n\n                for k in manifest.keys():\n                    manifest[k] = os.path.join(\"dist\", manifest[k])\n        except Exception:\n            print(\"Please make sure to build the frontend in \"\n                  \"static/ directory and restart the server\")\n            pass\n\n    def get_asset_url(filename):\n        if app.debug:\n            parse_manifest_json()\n        return url_for('static', filename=manifest.get(filename, ''))\n\n    parse_manifest_json()\n\n    @app.context_processor\n    def get_url_for_asset():\n        \"\"\"\n        Template tag to return the asset URL.\n        WebPack renders the assets after minification and modification\n        under the static/dist folder.\n        This template tag reads the asset name in manifest.json and returns\n        the appropriate file.\n        \"\"\"\n        return dict(url_for_asset=get_asset_url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery Postgres and returns a cursor to the results.", "response": "def _query_postgres(self):\n        \"\"\"\n        Queries Postgres and returns a cursor to the results.\n        \"\"\"\n        postgres = PostgresHook(postgres_conn_id=self.postgres_conn_id)\n        conn = postgres.get_conn()\n        cursor = conn.cursor()\n        cursor.execute(self.sql, self.parameters)\n        return cursor"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a cursor and writes results to a local file.", "response": "def _write_local_data_files(self, cursor):\n        \"\"\"\n        Takes a cursor, and writes results to a local file.\n\n        :return: A dictionary where keys are filenames to be used as object\n            names in GCS, and values are file handles to local files that\n            contain the data for the GCS objects.\n        \"\"\"\n        schema = list(map(lambda schema_tuple: schema_tuple[0], cursor.description))\n        tmp_file_handles = {}\n        row_no = 0\n\n        def _create_new_file():\n            handle = NamedTemporaryFile(delete=True)\n            filename = self.filename.format(len(tmp_file_handles))\n            tmp_file_handles[filename] = handle\n            return handle\n\n        # Don't create a file if there is nothing to write\n        if cursor.rowcount > 0:\n            tmp_file_handle = _create_new_file()\n\n            for row in cursor:\n                # Convert datetime objects to utc seconds, and decimals to floats\n                row = map(self.convert_types, row)\n                row_dict = dict(zip(schema, row))\n\n                s = json.dumps(row_dict, sort_keys=True).encode('utf-8')\n                tmp_file_handle.write(s)\n\n                # Append newline to make dumps BigQuery compatible.\n                tmp_file_handle.write(b'\\n')\n\n                # Stop if the file exceeds the file size limit.\n                if tmp_file_handle.tell() >= self.approx_max_file_size_bytes:\n                    tmp_file_handle = _create_new_file()\n                row_no += 1\n\n        self.log.info('Received %s rows over %s files', row_no, len(tmp_file_handles))\n\n        return tmp_file_handles"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the BigQuery schema for the results to the local file system.", "response": "def _write_local_schema_file(self, cursor):\n        \"\"\"\n        Takes a cursor, and writes the BigQuery schema for the results to a\n        local file system.\n\n        :return: A dictionary where key is a filename to be used as an object\n            name in GCS, and values are file handles to local files that\n            contains the BigQuery schema fields in .json format.\n        \"\"\"\n        schema = []\n        for field in cursor.description:\n            # See PEP 249 for details about the description tuple.\n            field_name = field[0]\n            field_type = self.type_map(field[1])\n            field_mode = 'REPEATED' if field[1] in (1009, 1005, 1007,\n                                                    1016) else 'NULLABLE'\n            schema.append({\n                'name': field_name,\n                'type': field_type,\n                'mode': field_mode,\n            })\n\n        self.log.info('Using schema for %s: %s', self.schema_filename, schema)\n        tmp_schema_file_handle = NamedTemporaryFile(delete=True)\n        s = json.dumps(schema, sort_keys=True).encode('utf-8')\n        tmp_schema_file_handle.write(s)\n        return {self.schema_filename: tmp_schema_file_handle}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_types(cls, value):\n        if type(value) in (datetime.datetime, datetime.date):\n            return time.mktime(value.timetuple())\n        elif type(value) == datetime.time:\n            formated_time = time.strptime(str(value), \"%H:%M:%S\")\n            return datetime.timedelta(\n                hours=formated_time.tm_hour,\n                minutes=formated_time.tm_min,\n                seconds=formated_time.tm_sec).seconds\n        elif isinstance(value, Decimal):\n            return float(value)\n        else:\n            return value", "response": "Takes a value from Postgres and converts it to a value that s safe for\n        JSON or Google Cloud Storage / BigQuery."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates all the intermediate directories in a remote host.", "response": "def _make_intermediate_dirs(sftp_client, remote_directory):\n    \"\"\"\n    Create all the intermediate directories in a remote host\n\n    :param sftp_client: A Paramiko SFTP client.\n    :param remote_directory: Absolute Path of the directory containing the file\n    :return:\n    \"\"\"\n    if remote_directory == '/':\n        sftp_client.chdir('/')\n        return\n    if remote_directory == '':\n        return\n    try:\n        sftp_client.chdir(remote_directory)\n    except IOError:\n        dirname, basename = os.path.split(remote_directory.rstrip('/'))\n        _make_intermediate_dirs(sftp_client, dirname)\n        sftp_client.mkdir(basename)\n        sftp_client.chdir(basename)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_queue(self, queue_name, attributes=None):\n        return self.get_conn().create_queue(QueueName=queue_name, Attributes=attributes or {})", "response": "Create a queue using the connection object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a message to the queue with optional delay", "response": "def send_message(self, queue_url, message_body, delay_seconds=0, message_attributes=None):\n        \"\"\"\n        Send message to the queue\n\n        :param queue_url: queue url\n        :type queue_url: str\n        :param message_body: the contents of the message\n        :type message_body: str\n        :param delay_seconds: seconds to delay the message\n        :type delay_seconds: int\n        :param message_attributes: additional attributes for the message (default: None)\n            For details of the attributes parameter see :py:meth:`botocore.client.SQS.send_message`\n        :type message_attributes: dict\n\n        :return: dict with the information about the message sent\n            For details of the returned value see :py:meth:`botocore.client.SQS.send_message`\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().send_message(QueueUrl=queue_url,\n                                            MessageBody=message_body,\n                                            DelaySeconds=delay_seconds,\n                                            MessageAttributes=message_attributes or {})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _integrate_plugins():\n    from airflow.plugins_manager import hooks_modules\n    for hooks_module in hooks_modules:\n        sys.modules[hooks_module.__name__] = hooks_module\n        globals()[hooks_module._name] = hooks_module", "response": "Integrate plugins to the context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_command(self, run_with=None, join_args=False):\n        run_with = run_with or []\n        cmd = [\" \".join(self._command)] if join_args else self._command\n        full_cmd = run_with + cmd\n\n        self.log.info('Running: %s', full_cmd)\n        proc = subprocess.Popen(\n            full_cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            universal_newlines=True,\n            close_fds=True,\n            env=os.environ.copy(),\n            preexec_fn=os.setsid\n        )\n\n        # Start daemon thread to read subprocess logging output\n        log_reader = threading.Thread(\n            target=self._read_task_logs,\n            args=(proc.stdout,),\n        )\n        log_reader.daemon = True\n        log_reader.start()\n        return proc", "response": "Runs the task command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_finish(self):\n        if self._cfg_path and os.path.isfile(self._cfg_path):\n            if self.run_as_user:\n                subprocess.call(['sudo', 'rm', self._cfg_path], close_fds=True)\n            else:\n                os.remove(self._cfg_path)", "response": "A callback that should be called when this is done running."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _main():\n    # Parse arguments\n    usage = \"usage: nvd3.py [options]\"\n    parser = OptionParser(usage=usage,\n                          version=(\"python-nvd3 - Charts generator with \"\n                                   \"nvd3.js and d3.js\"))\n    parser.add_option(\"-q\", \"--quiet\",\n                      action=\"store_false\", dest=\"verbose\", default=True,\n                      help=\"don't print messages to stdout\")\n\n    (options, args) = parser.parse_args()", "response": "Main function for the nvd3 - charts generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_serie(self, y, x, name=None, extra=None, **kwargs):\n        if not name:\n            name = \"Serie %d\" % (self.serie_no)\n\n        # For scatterChart shape & size fields are added in serie\n        if 'shape' in kwargs or 'size' in kwargs:\n            csize = kwargs.get('size', 1)\n            cshape = kwargs.get('shape', 'circle')\n\n            serie = [{\n                'x': x[i],\n                'y': j,\n                'shape': cshape,\n                'size': csize[i] if isinstance(csize, list) else csize\n            } for i, j in enumerate(y)]\n        else:\n            if self.model == 'pieChart':\n                serie = [{'label': x[i], 'value': y} for i, y in enumerate(y)]\n            else:\n                serie = [{'x': x[i], 'y': y} for i, y in enumerate(y)]\n\n        data_keyvalue = {'values': serie, 'key': name}\n\n        # multiChart\n        # Histogram type='bar' for the series\n        if 'type' in kwargs and kwargs['type']:\n            data_keyvalue['type'] = kwargs['type']\n\n        # Define on which Y axis the serie is related\n        # a chart can have 2 Y axis, left and right, by default only one Y Axis is used\n        if 'yaxis' in kwargs and kwargs['yaxis']:\n            data_keyvalue['yAxis'] = kwargs['yaxis']\n        else:\n            if self.model != 'pieChart':\n                data_keyvalue['yAxis'] = '1'\n\n        if 'bar' in kwargs and kwargs['bar']:\n            data_keyvalue['bar'] = 'true'\n\n        if 'disabled' in kwargs and kwargs['disabled']:\n            data_keyvalue['disabled'] = 'true'\n\n        if 'color' in kwargs and kwargs['color']:\n            data_keyvalue['color'] = kwargs['color']\n\n        if extra:\n            if self.model == 'pieChart':\n                if 'color_list' in extra and extra['color_list']:\n                    self.color_list = extra['color_list']\n\n            if extra.get('date_format'):\n                self.charttooltip_dateformat = extra['date_format']\n\n            if extra.get('tooltip'):\n                self.custom_tooltip_flag = True\n\n                if self.model != 'pieChart':\n                    _start = extra['tooltip']['y_start']\n                    _end = extra['tooltip']['y_end']\n                    _start = (\"'\" + str(_start) + \"' + \") if _start else ''\n                    _end = (\" + '\" + str(_end) + \"'\") if _end else ''\n\n                    if self.model == 'linePlusBarChart':\n                        if self.tooltip_condition_string:\n                            self.tooltip_condition_string += stab(5)\n                        self.tooltip_condition_string += stab(0) + \"if(key.indexOf('\" + name + \"') > -1 ){\\n\" +\\\n                            stab(6) + \"var y = \" + _start + \" String(graph.point.y) \" + _end + \";\\n\" +\\\n                            stab(5) + \"}\\n\"\n                    elif self.model == 'cumulativeLineChart':\n                        self.tooltip_condition_string += stab(0) + \"if(key == '\" + name + \"'){\\n\" +\\\n                            stab(6) + \"var y = \" + _start + \" String(e) \" + _end + \";\\n\" +\\\n                            stab(5) + \"}\\n\"\n                    else:\n                        self.tooltip_condition_string += stab(5) + \"if(key == '\" + name + \"'){\\n\" +\\\n                            stab(6) + \"var y = \" + _start + \" String(graph.point.y) \" + _end + \";\\n\" +\\\n                            stab(5) + \"}\\n\"\n\n                if self.model == 'pieChart':\n                    _start = extra['tooltip']['y_start']\n                    _end = extra['tooltip']['y_end']\n                    _start = (\"'\" + str(_start) + \"' + \") if _start else ''\n                    _end = (\" + '\" + str(_end) + \"'\") if _end else ''\n                    self.tooltip_condition_string += \"var y = \" + _start + \" String(y) \" + _end + \";\\n\"\n\n        # Increment series counter & append\n        self.serie_no += 1\n        self.series.append(data_keyvalue)", "response": "add serie to the log file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild HTML content only with no header or body tags.", "response": "def buildcontent(self):\n        \"\"\"Build HTML content only, no header or body tags. To be useful this\n        will usually require the attribute `juqery_on_ready` to be set which\n        will wrap the js in $(function(){<regular_js>};)\n        \"\"\"\n        self.buildcontainer()\n        # if the subclass has a method buildjs this method will be\n        # called instead of the method defined here\n        # when this subclass method is entered it does call\n        # the method buildjschart defined here\n        self.buildjschart()\n        self.htmlcontent = self.template_content_nvd3.render(chart=self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buildhtml(self):\n        self.buildcontent()\n        self.content = self.htmlcontent\n        self.htmlcontent = self.template_page_nvd3.render(chart=self)", "response": "Build the HTML page containing the HTML content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates HTML header content", "response": "def buildhtmlheader(self):\n        \"\"\"generate HTML header content\"\"\"\n        self.htmlheader = ''\n        # If the JavaScript assets have already been injected, don't bother re-sourcing them.\n        global _js_initialized\n        if '_js_initialized' not in globals() or not _js_initialized:\n            for css in self.header_css:\n                self.htmlheader += css\n            for js in self.header_js:\n                self.htmlheader += js"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates HTML div with style", "response": "def buildcontainer(self):\n        \"\"\"generate HTML div\"\"\"\n        if self.container:\n            return\n\n        # Create SVG div with style\n        if self.width:\n            if self.width[-1] != '%':\n                self.style += 'width:%spx;' % self.width\n            else:\n                self.style += 'width:%s;' % self.width\n        if self.height:\n            if self.height[-1] != '%':\n                self.style += 'height:%spx;' % self.height\n            else:\n                self.style += 'height:%s;' % self.height\n        if self.style:\n            self.style = 'style=\"%s\"' % self.style\n\n        self.container = self.containerheader + \\\n            '<div id=\"%s\"><svg %s></svg></div>\\n' % (self.name, self.style)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buildjschart(self):\n        self.jschart = ''\n\n        # add custom tooltip string in jschart\n        # default condition (if build_custom_tooltip is not called explicitly with date_flag=True)\n        if self.tooltip_condition_string == '':\n            self.tooltip_condition_string = 'var y = String(graph.point.y);\\n'\n\n        # Include data\n        self.series_js = json.dumps(self.series)", "response": "generate javascript code for the chart"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_x_axis(self, name, label=None, format=None, date=False, custom_format=False):\n        axis = {}\n        if custom_format and format:\n            axis['tickFormat'] = format\n        elif format:\n            if format == 'AM_PM':\n                axis['tickFormat'] = \"function(d) { return get_am_pm(parseInt(d)); }\"\n            else:\n                axis['tickFormat'] = \"d3.format(',%s')\" % format\n\n        if label:\n            axis['axisLabel'] = \"'\" + label + \"'\"\n\n        # date format : see https://github.com/mbostock/d3/wiki/Time-Formatting\n        if date:\n            self.dateformat = format\n            axis['tickFormat'] = (\"function(d) { return d3.time.format('%s')\"\n                                  \"(new Date(parseInt(d))) }\\n\"\n                                  \"\" % self.dateformat)\n            # flag is the x Axis is a date\n            if name[0] == 'x':\n                self.x_axis_date = True\n\n        # Add new axis to list of axis\n        self.axislist[name] = axis\n\n        # Create x2Axis if focus_enable\n        if name == \"xAxis\" and self.focus_enable:\n            self.axislist['x2Axis'] = axis", "response": "Create X - axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_y_axis(self, name, label=None, format=None, custom_format=False):\n        axis = {}\n\n        if custom_format and format:\n            axis['tickFormat'] = format\n        elif format:\n            axis['tickFormat'] = \"d3.format(',%s')\" % format\n\n        if label:\n            axis['axisLabel'] = \"'\" + label + \"'\"\n\n        # Add new axis to list of axis\n        self.axislist[name] = axis", "response": "Create Y - axis for the current key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding HTML content only with no header or body tags.", "response": "def buildcontent(self):\n        \"\"\"Build HTML content only, no header or body tags. To be useful this\n        will usually require the attribute `juqery_on_ready` to be set which\n        will wrap the js in $(function(){<regular_js>};)\n        \"\"\"\n        self.buildcontainer()\n        # if the subclass has a method buildjs this method will be\n        # called instead of the method defined here\n        # when this subclass method is entered it does call\n        # the method buildjschart defined here\n        self.buildjschart()\n        self.htmlcontent = self.template_chart_nvd3.render(chart=self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_conn(self):\n        conn = self.get_connection(self.sqlite_conn_id)\n        conn = sqlite3.connect(conn.host)\n        return conn", "response": "Returns a sqlite connection object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef action_logging(f):\n    @functools.wraps(f)\n    def wrapper(*args, **kwargs):\n\n        with create_session() as session:\n            if g.user.is_anonymous:\n                user = 'anonymous'\n            else:\n                user = g.user.username\n\n            log = Log(\n                event=f.__name__,\n                task_instance=None,\n                owner=user,\n                extra=str(list(request.args.items())),\n                task_id=request.args.get('task_id'),\n                dag_id=request.args.get('dag_id'))\n\n            if 'execution_date' in request.args:\n                log.execution_date = pendulum.parse(\n                    request.args.get('execution_date'))\n\n            session.add(log)\n\n        return f(*args, **kwargs)\n\n    return wrapper", "response": "Decorator to log user actions\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_dag_access(**dag_kwargs):\n    def decorator(f):\n        @functools.wraps(f)\n        def wrapper(self, *args, **kwargs):\n            has_access = self.appbuilder.sm.has_access\n            dag_id = request.args.get('dag_id')\n            # if it is false, we need to check whether user has write access on the dag\n            can_dag_edit = dag_kwargs.get('can_dag_edit', False)\n\n            # 1. check whether the user has can_dag_edit permissions on all_dags\n            # 2. if 1 false, check whether the user\n            #    has can_dag_edit permissions on the dag\n            # 3. if 2 false, check whether it is can_dag_read view,\n            #    and whether user has the permissions\n            if (\n                has_access('can_dag_edit', 'all_dags') or\n                has_access('can_dag_edit', dag_id) or (not can_dag_edit and\n                                                       (has_access('can_dag_read',\n                                                                   'all_dags') or\n                                                        has_access('can_dag_read',\n                                                                   dag_id)))):\n                return f(self, *args, **kwargs)\n            else:\n                flash(\"Access is Denied\", \"danger\")\n                return redirect(url_for(self.appbuilder.sm.auth_view.\n                                        __class__.__name__ + \".login\"))\n        return wrapper\n    return decorator", "response": "Decorator to check whether the user has read or write permission on the dag."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the last dag run for a dag.", "response": "def get_last_dagrun(dag_id, session, include_externally_triggered=False):\n    \"\"\"\n    Returns the last dag run for a dag, None if there was none.\n    Last dag run can be any type of run eg. scheduled or backfilled.\n    Overridden DagRuns are ignored.\n    \"\"\"\n    DR = DagRun\n    query = session.query(DR).filter(DR.dag_id == dag_id)\n    if not include_externally_triggered:\n        query = query.filter(DR.external_trigger == False)  # noqa\n    query = query.order_by(DR.execution_date.desc())\n    return query.first()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_dagrun(self,\n                      run_id,\n                      state,\n                      execution_date,\n                      start_date=None,\n                      external_trigger=False,\n                      conf=None,\n                      session=None):\n        \"\"\"\n        Creates a dag run from this dag including the tasks associated with this dag.\n        Returns the dag run.\n\n        :param run_id: defines the the run id for this dag run\n        :type run_id: str\n        :param execution_date: the execution date of this dag run\n        :type execution_date: datetime.datetime\n        :param state: the state of the dag run\n        :type state: airflow.utils.state.State\n        :param start_date: the date this dag run should be evaluated\n        :type start_date: datetime.datetime\n        :param external_trigger: whether this dag run is externally triggered\n        :type external_trigger: bool\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        \"\"\"\n\n        return self.get_dag().create_dagrun(run_id=run_id,\n                                            state=state,\n                                            execution_date=execution_date,\n                                            start_date=start_date,\n                                            external_trigger=external_trigger,\n                                            conf=conf,\n                                            session=session)", "response": "Creates a dag run from this dag including the tasks associated with this dag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends the message to SQS queue otos", "response": "def execute(self, context):\n        \"\"\"\n        Publish the message to SQS queue\n\n        :param context: the context object\n        :type context: dict\n        :return: dict with information about the message sent\n            For details of the returned dict see :py:meth:`botocore.client.SQS.send_message`\n        :rtype: dict\n        \"\"\"\n\n        hook = SQSHook(aws_conn_id=self.aws_conn_id)\n\n        result = hook.send_message(queue_url=self.sqs_queue,\n                                   message_body=self.message_content,\n                                   delay_seconds=self.delay_seconds,\n                                   message_attributes=self.message_attributes)\n\n        self.log.info('result is send_message is %s', result)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the HTML for a paging component.", "response": "def generate_pages(current_page, num_of_pages,\n                   search=None, showPaused=None, window=7):\n    \"\"\"\n    Generates the HTML for a paging component using a similar logic to the paging\n    auto-generated by Flask managed views. The paging component defines a number of\n    pages visible in the pager (window) and once the user goes to a page beyond the\n    largest visible, it would scroll to the right the page numbers and keeps the\n    current one in the middle of the pager component. When in the last pages,\n    the pages won't scroll and just keep moving until the last page. Pager also contains\n    <first, previous, ..., next, last> pages.\n    This component takes into account custom parameters such as search and showPaused,\n    which could be added to the pages link in order to maintain the state between\n    client and server. It also allows to make a bookmark on a specific paging state.\n    :param current_page:\n        the current page number, 0-indexed\n    :param num_of_pages:\n        the total number of pages\n    :param search:\n        the search query string, if any\n    :param showPaused:\n        false if paused dags will be hidden, otherwise true to show them\n    :param window:\n        the number of pages to be shown in the paging component (7 default)\n    :return:\n        the HTML string of the paging component\n    \"\"\"\n\n    void_link = 'javascript:void(0)'\n    first_node = Markup(\"\"\"<li class=\"paginate_button {disabled}\" id=\"dags_first\">\n    <a href=\"{href_link}\" aria-controls=\"dags\" data-dt-idx=\"0\" tabindex=\"0\">&laquo;</a>\n</li>\"\"\")\n\n    previous_node = Markup(\"\"\"<li class=\"paginate_button previous {disabled}\" id=\"dags_previous\">\n    <a href=\"{href_link}\" aria-controls=\"dags\" data-dt-idx=\"0\" tabindex=\"0\">&lt;</a>\n</li>\"\"\")\n\n    next_node = Markup(\"\"\"<li class=\"paginate_button next {disabled}\" id=\"dags_next\">\n    <a href=\"{href_link}\" aria-controls=\"dags\" data-dt-idx=\"3\" tabindex=\"0\">&gt;</a>\n</li>\"\"\")\n\n    last_node = Markup(\"\"\"<li class=\"paginate_button {disabled}\" id=\"dags_last\">\n    <a href=\"{href_link}\" aria-controls=\"dags\" data-dt-idx=\"3\" tabindex=\"0\">&raquo;</a>\n</li>\"\"\")\n\n    page_node = Markup(\"\"\"<li class=\"paginate_button {is_active}\">\n    <a href=\"{href_link}\" aria-controls=\"dags\" data-dt-idx=\"2\" tabindex=\"0\">{page_num}</a>\n</li>\"\"\")\n\n    output = [Markup('<ul class=\"pagination\" style=\"margin-top:0px;\">')]\n\n    is_disabled = 'disabled' if current_page <= 0 else ''\n    output.append(first_node.format(href_link=\"?{}\"\n                                    .format(get_params(page=0,\n                                                       search=search,\n                                                       showPaused=showPaused)),\n                                    disabled=is_disabled))\n\n    page_link = void_link\n    if current_page > 0:\n        page_link = '?{}'.format(get_params(page=(current_page - 1),\n                                            search=search,\n                                            showPaused=showPaused))\n\n    output.append(previous_node.format(href_link=page_link,\n                                       disabled=is_disabled))\n\n    mid = int(window / 2)\n    last_page = num_of_pages - 1\n\n    if current_page <= mid or num_of_pages < window:\n        pages = [i for i in range(0, min(num_of_pages, window))]\n    elif mid < current_page < last_page - mid:\n        pages = [i for i in range(current_page - mid, current_page + mid + 1)]\n    else:\n        pages = [i for i in range(num_of_pages - window, last_page + 1)]\n\n    def is_current(current, page):\n        return page == current\n\n    for page in pages:\n        vals = {\n            'is_active': 'active' if is_current(current_page, page) else '',\n            'href_link': void_link if is_current(current_page, page)\n                         else '?{}'.format(get_params(page=page,\n                                                      search=search,\n                                                      showPaused=showPaused)),\n            'page_num': page + 1\n        }\n        output.append(page_node.format(**vals))\n\n    is_disabled = 'disabled' if current_page >= num_of_pages - 1 else ''\n\n    page_link = (void_link if current_page >= num_of_pages - 1\n                 else '?{}'.format(get_params(page=current_page + 1,\n                                              search=search,\n                                              showPaused=showPaused)))\n\n    output.append(next_node.format(href_link=page_link, disabled=is_disabled))\n    output.append(last_node.format(href_link=\"?{}\"\n                                   .format(get_params(page=last_page,\n                                                      search=search,\n                                                      showPaused=showPaused)),\n                                   disabled=is_disabled))\n\n    output.append(Markup('</ul>'))\n\n    return Markup('\\n'.join(output))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a json response from a json serializable python object", "response": "def json_response(obj):\n    \"\"\"\n    returns a json response from a json serializable python object\n    \"\"\"\n    return Response(\n        response=json.dumps(\n            obj, indent=4, cls=AirflowJsonEncoder),\n        status=200,\n        mimetype=\"application/json\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_maybe_zipped(f, mode='r'):\n\n    _, archive, filename = ZIP_REGEX.search(f).groups()\n    if archive and zipfile.is_zipfile(archive):\n        return zipfile.ZipFile(archive, mode=mode).open(filename)\n    else:\n        return io.open(f, mode=mode)", "response": "Opens the given file if it is a zip file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses by cache to get a unique key per URL", "response": "def make_cache_key(*args, **kwargs):\n    \"\"\"\n    Used by cache to get a unique key per URL\n    \"\"\"\n    path = request.path\n    args = str(hash(frozenset(request.args.items())))\n    return (path + args).encode('ascii', 'ignore')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_conn(self):\n        if not self._conn:\n            self._conn = VideoIntelligenceServiceClient(credentials=self._get_credentials())\n        return self._conn", "response": "Returns Gcp Video Intelligence Service client"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform video annotation. :param input_uri: Input video location. Currently, only Google Cloud Storage URIs are supported, which must be specified in the following format: ``gs://bucket-id/object-id``. :type input_uri: str :param input_content: The video data bytes. If unset, the input video(s) should be specified via ``input_uri``. If set, ``input_uri`` should be unset. :type input_content: bytes :param features: Requested video annotation features. :type features: list[google.cloud.videointelligence_v1.VideoIntelligenceServiceClient.enums.Feature] :param output_uri: Optional, location where the output (in JSON format) should be stored. Currently, only Google Cloud Storage URIs are supported, which must be specified in the following format: ``gs://bucket-id/object-id``. :type output_uri: str :param video_context: Optional, Additional video context and/or feature-specific parameters. :type video_context: dict or google.cloud.videointelligence_v1.types.VideoContext :param location: Optional, cloud region where annotation should take place. Supported cloud regions: us-east1, us-west1, europe-west1, asia-east1. If no region is specified, a region will be determined based on video file location. :type location: str :param retry: Retry object used to determine when/if to retry requests. If None is specified, requests will not be retried. :type retry: google.api_core.retry.Retry :param timeout: Optional, The amount of time, in seconds, to wait for the request to complete. Note that if retry is specified, the timeout applies to each individual attempt. :type timeout: float :param metadata: Optional, Additional metadata that is provided to the method. :type metadata: seq[tuple[str, str]]", "response": "def annotate_video(\n        self,\n        input_uri=None,\n        input_content=None,\n        features=None,\n        video_context=None,\n        output_uri=None,\n        location=None,\n        retry=None,\n        timeout=None,\n        metadata=None,\n    ):\n        \"\"\"\n        Performs video annotation.\n\n        :param input_uri: Input video location. Currently, only Google Cloud Storage URIs are supported,\n            which must be specified in the following format: ``gs://bucket-id/object-id``.\n        :type input_uri: str\n        :param input_content: The video data bytes.\n            If unset, the input video(s) should be specified via ``input_uri``.\n            If set, ``input_uri`` should be unset.\n        :type input_content: bytes\n        :param features: Requested video annotation features.\n        :type features: list[google.cloud.videointelligence_v1.VideoIntelligenceServiceClient.enums.Feature]\n        :param output_uri: Optional, location where the output (in JSON format) should be stored. Currently,\n            only Google Cloud Storage URIs are supported, which must be specified in the following format:\n            ``gs://bucket-id/object-id``.\n        :type output_uri: str\n        :param video_context: Optional, Additional video context and/or feature-specific parameters.\n        :type video_context: dict or google.cloud.videointelligence_v1.types.VideoContext\n        :param location: Optional, cloud region where annotation should take place. Supported cloud regions:\n            us-east1, us-west1, europe-west1, asia-east1.\n            If no region is specified, a region will be determined based on video file location.\n        :type location: str\n        :param retry: Retry object used to determine when/if to retry requests.\n            If None is specified, requests will not be retried.\n        :type retry: google.api_core.retry.Retry\n        :param timeout: Optional, The amount of time, in seconds, to wait for the request to complete.\n            Note that if retry is specified, the timeout applies to each individual attempt.\n        :type timeout: float\n        :param metadata: Optional, Additional metadata that is provided to the method.\n        :type metadata: seq[tuple[str, str]]\n        \"\"\"\n        client = self.get_conn()\n        return client.annotate_video(\n            input_uri=input_uri,\n            input_content=input_content,\n            features=features,\n            video_context=video_context,\n            output_uri=output_uri,\n            location_id=location,\n            retry=retry,\n            timeout=timeout,\n            metadata=metadata,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_api_key(self):\n        conn = self.get_connection(self.http_conn_id)\n        api_key = conn.password\n        if not api_key:\n            raise AirflowException('Opsgenie API Key is required for this hook, '\n                                   'please check your conn_id configuration.')\n        return api_key", "response": "Get Opsgenie API Key for creating alert."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_conn(self, headers=None):\n        conn = self.get_connection(self.http_conn_id)\n        self.base_url = conn.host if conn.host else 'https://api.opsgenie.com'\n        session = requests.Session()\n        if headers:\n            session.headers.update(headers)\n        return session", "response": "Get a connection to the OPS NIE API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the Opsgenie Alert call TTS", "response": "def execute(self, payload={}):\n        \"\"\"\n        Execute the Opsgenie Alert call\n\n        :param payload: Opsgenie API Create Alert payload values\n            See https://docs.opsgenie.com/docs/alert-api#section-create-alert\n        :type payload: dict\n        \"\"\"\n        api_key = self._get_api_key()\n        return self.run(endpoint='v2/alerts',\n                        data=json.dumps(payload),\n                        headers={'Content-Type': 'application/json',\n                                 'Authorization': 'GenieKey %s' % api_key})"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the bash command in a temporary directory and return True if the command was successful False otherwise", "response": "def poke(self, context):\n        \"\"\"\n        Execute the bash command in a temporary directory\n        which will be cleaned afterwards\n        \"\"\"\n        bash_command = self.bash_command\n        self.log.info(\"Tmp dir root location: \\n %s\", gettempdir())\n        with TemporaryDirectory(prefix='airflowtmp') as tmp_dir:\n            with NamedTemporaryFile(dir=tmp_dir, prefix=self.task_id) as f:\n                f.write(bytes(bash_command, 'utf_8'))\n                f.flush()\n                fname = f.name\n                script_location = tmp_dir + \"/\" + fname\n                self.log.info(\"Temporary script location: %s\", script_location)\n                self.log.info(\"Running command: %s\", bash_command)\n                sp = Popen(\n                    ['bash', fname],\n                    stdout=PIPE, stderr=STDOUT,\n                    close_fds=True, cwd=tmp_dir,\n                    env=self.env, preexec_fn=os.setsid)\n\n                self.sp = sp\n\n                self.log.info(\"Output:\")\n                line = ''\n                for line in iter(sp.stdout.readline, b''):\n                    line = line.decode(self.output_encoding).strip()\n                    self.log.info(line)\n                sp.wait()\n                self.log.info(\"Command exited with return code %s\", sp.returncode)\n\n                return not sp.returncode"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the Opsgenie JSON payload.", "response": "def _build_opsgenie_payload(self):\n        \"\"\"\n        Construct the Opsgenie JSON payload. All relevant parameters are combined here\n        to a valid Opsgenie JSON payload.\n\n        :return: Opsgenie payload (dict) to send\n        \"\"\"\n        payload = {}\n\n        for key in [\n            \"message\", \"alias\", \"description\", \"responders\",\n            \"visibleTo\", \"actions\", \"tags\", \"details\", \"entity\",\n            \"source\", \"priority\", \"user\", \"note\"\n        ]:\n            val = getattr(self, key)\n            if val:\n                payload[key] = val\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, context):\n        self.hook = OpsgenieAlertHook(self.opsgenie_conn_id)\n        self.hook.execute(self._build_opsgenie_payload())", "response": "Call the OpsgenieAlertHook to post message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_conn(self):\n        if not self.conn:\n            self.conn = self.get_client_type('athena')\n        return self.conn", "response": "check if aws conn exists already or create one and return it\n\n        :return: boto3 session"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_query(self, query, query_context, result_configuration, client_request_token=None):\n        response = self.conn.start_query_execution(QueryString=query,\n                                                   ClientRequestToken=client_request_token,\n                                                   QueryExecutionContext=query_context,\n                                                   ResultConfiguration=result_configuration)\n        query_execution_id = response['QueryExecutionId']\n        return query_execution_id", "response": "Run a presto query on athena with provided config and return query_execution_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_query_status(self, query_execution_id):\n        response = self.conn.get_query_execution(QueryExecutionId=query_execution_id)\n        state = None\n        try:\n            state = response['QueryExecution']['Status']['State']\n        except Exception as ex:\n            self.log.error('Exception while getting query state', ex)\n        finally:\n            return state", "response": "Check the status of a query execution. Returns None or one of valid query states."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_query_results(self, query_execution_id):\n        query_state = self.check_query_status(query_execution_id)\n        if query_state is None:\n            self.log.error('Invalid Query state')\n            return None\n        elif query_state in self.INTERMEDIATE_STATES or query_state in self.FAILURE_STATES:\n            self.log.error('Query is in {state} state. Cannot fetch results'.format(state=query_state))\n            return None\n        return self.conn.get_query_results(QueryExecutionId=query_execution_id)", "response": "Fetch submitted athena query results. Returns None if query is in intermediate state or if query is in failure state or if query is in cancelled state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef poll_query_status(self, query_execution_id, max_tries=None):\n        try_number = 1\n        final_query_state = None  # Query state when query reaches final state or max_tries reached\n        while True:\n            query_state = self.check_query_status(query_execution_id)\n            if query_state is None:\n                self.log.info('Trial {try_number}: Invalid query state. Retrying again'.format(\n                    try_number=try_number))\n            elif query_state in self.INTERMEDIATE_STATES:\n                self.log.info('Trial {try_number}: Query is still in an intermediate state - {state}'\n                              .format(try_number=try_number, state=query_state))\n            else:\n                self.log.info('Trial {try_number}: Query execution completed. Final state is {state}'\n                              .format(try_number=try_number, state=query_state))\n                final_query_state = query_state\n                break\n            if max_tries and try_number >= max_tries:  # Break loop if max_tries reached\n                final_query_state = query_state\n                break\n            try_number += 1\n            sleep(self.sleep_time)\n        return final_query_state", "response": "Poll the status of the submitted athena query until the query reaches final state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_conn(self):\n        if self.conn is None:\n            cnopts = pysftp.CnOpts()\n            if self.no_host_key_check:\n                cnopts.hostkeys = None\n            cnopts.compression = self.compress\n            conn_params = {\n                'host': self.remote_host,\n                'port': self.port,\n                'username': self.username,\n                'cnopts': cnopts\n            }\n            if self.password and self.password.strip():\n                conn_params['password'] = self.password\n            if self.key_file:\n                conn_params['private_key'] = self.key_file\n            if self.private_key_pass:\n                conn_params['private_key_pass'] = self.private_key_pass\n\n            self.conn = pysftp.Connection(**conn_params)\n        return self.conn", "response": "Returns an SFTP connection object for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef describe_directory(self, path):\n        conn = self.get_conn()\n        flist = conn.listdir_attr(path)\n        files = {}\n        for f in flist:\n            modify = datetime.datetime.fromtimestamp(\n                f.st_mtime).strftime('%Y%m%d%H%M%S')\n            files[f.filename] = {\n                'size': f.st_size,\n                'type': 'dir' if stat.S_ISDIR(f.st_mode) else 'file',\n                'modify': modify}\n        return files", "response": "Returns a dictionary of all files\n            for all files in the remote directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of files on the remote system.", "response": "def list_directory(self, path):\n        \"\"\"\n        Returns a list of files on the remote system.\n        :param path: full path to the remote directory to list\n        :type path: str\n        \"\"\"\n        conn = self.get_conn()\n        files = conn.listdir(path)\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_directory(self, path, mode=777):\n        conn = self.get_conn()\n        conn.mkdir(path, mode)", "response": "Creates a directory on the remote system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransferring the remote file to a local location. If local_full_path is a string path, the file will be put at that location :param remote_full_path: full path to the remote file :type remote_full_path: str :param local_full_path: full path to the local file :type local_full_path: str", "response": "def retrieve_file(self, remote_full_path, local_full_path):\n        \"\"\"\n        Transfers the remote file to a local location.\n        If local_full_path is a string path, the file will be put\n        at that location\n        :param remote_full_path: full path to the remote file\n        :type remote_full_path: str\n        :param local_full_path: full path to the local file\n        :type local_full_path: str\n        \"\"\"\n        conn = self.get_conn()\n        self.log.info('Retrieving file from FTP: %s', remote_full_path)\n        conn.get(remote_full_path, local_full_path)\n        self.log.info('Finished retrieving file from FTP: %s', remote_full_path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef store_file(self, remote_full_path, local_full_path):\n        conn = self.get_conn()\n        conn.put(local_full_path, remote_full_path)", "response": "Stores a local file to the remote location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __handle_rate_limit_exception(self, rate_limit_exception):\n        retry_after = int(\n            rate_limit_exception.response.headers.get('Retry-After', 60))\n        self.log.info(\n            \"Hit Zendesk API rate limit. Pausing for %s seconds\",\n            retry_after\n        )\n        time.sleep(retry_after)", "response": "Handle a Zendesk API rate limit exception."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call(self, path, query=None, get_all_pages=True, side_loading=False):\n        zendesk = self.get_conn()\n        first_request_successful = False\n\n        while not first_request_successful:\n            try:\n                results = zendesk.call(path, query)\n                first_request_successful = True\n            except RateLimitError as rle:\n                self.__handle_rate_limit_exception(rle)\n\n        # Find the key with the results\n        keys = [path.split(\"/\")[-1].split(\".json\")[0]]\n        next_page = results['next_page']\n        if side_loading:\n            keys += query['include'].split(',')\n        results = {key: results[key] for key in keys}\n\n        if get_all_pages:\n            while next_page is not None:\n                try:\n                    # Need to split because the next page URL has\n                    # `github.zendesk...`\n                    # in it, but the call function needs it removed.\n                    next_url = next_page.split(self.__url)[1]\n                    self.log.info(\"Calling %s\", next_url)\n                    more_res = zendesk.call(next_url)\n                    for key in results:\n                        results[key].extend(more_res[key])\n                    if next_page == more_res['next_page']:\n                        # Unfortunately zdesk doesn't always throw ZendeskError\n                        # when we are done getting all the data. Sometimes the\n                        # next just refers to the current set of results.\n                        # Hence, need to deal with this special case\n                        break\n                    else:\n                        next_page = more_res['next_page']\n                except RateLimitError as rle:\n                    self.__handle_rate_limit_exception(rle)\n                except ZendeskError as ze:\n                    if b\"Use a start_time older than 5 minutes\" in ze.msg:\n                        # We have pretty up to date data\n                        break\n                    else:\n                        raise ze\n\n        return results", "response": "Call Zendesk API and return the results."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the partition values for a table.", "response": "def get_partitions(self,\n                       database_name,\n                       table_name,\n                       expression='',\n                       page_size=None,\n                       max_items=None):\n        \"\"\"\n        Retrieves the partition values for a table.\n\n        :param database_name: The name of the catalog database where the partitions reside.\n        :type database_name: str\n        :param table_name: The name of the partitions' table.\n        :type table_name: str\n        :param expression: An expression filtering the partitions to be returned.\n            Please see official AWS documentation for further information.\n            https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-partitions.html#aws-glue-api-catalog-partitions-GetPartitions\n        :type expression: str\n        :param page_size: pagination size\n        :type page_size: int\n        :param max_items: maximum items to return\n        :type max_items: int\n        :return: set of partition values where each value is a tuple since\n            a partition may be composed of multiple columns. For example:\n            ``{('2018-01-01','1'), ('2018-01-01','2')}``\n        \"\"\"\n        config = {\n            'PageSize': page_size,\n            'MaxItems': max_items,\n        }\n\n        paginator = self.get_conn().get_paginator('get_partitions')\n        response = paginator.paginate(\n            DatabaseName=database_name,\n            TableName=table_name,\n            Expression=expression,\n            PaginationConfig=config\n        )\n\n        partitions = set()\n        for page in response:\n            for p in page['Partitions']:\n                partitions.add(tuple(p['Values']))\n\n        return partitions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_for_partition(self, database_name, table_name, expression):\n        partitions = self.get_partitions(database_name, table_name, expression, max_items=1)\n\n        if partitions:\n            return True\n        else:\n            return False", "response": "Checks whether a partition exists with the given expression."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the information of the table in a hive database", "response": "def get_table(self, database_name, table_name):\n        \"\"\"\n        Get the information of the table\n\n        :param database_name: Name of hive database (schema) @table belongs to\n        :type database_name: str\n        :param table_name: Name of hive table\n        :type table_name: str\n        :rtype: dict\n\n        >>> hook = AwsGlueCatalogHook()\n        >>> r = hook.get_table('db', 'table_foo')\n        >>> r['Name'] = 'table_foo'\n        \"\"\"\n\n        result = self.get_conn().get_table(DatabaseName=database_name, Name=table_name)\n\n        return result['Table']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the physical location of the table in the specified database.", "response": "def get_table_location(self, database_name, table_name):\n        \"\"\"\n        Get the physical location of the table\n\n        :param database_name: Name of hive database (schema) @table belongs to\n        :type database_name: str\n        :param table_name: Name of hive table\n        :type table_name: str\n        :return: str\n        \"\"\"\n\n        table = self.get_table(database_name, table_name)\n\n        return table['StorageDescriptor']['Location']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cluster_status(self, cluster_identifier):\n        conn = self.get_conn()\n        try:\n            response = conn.describe_clusters(\n                ClusterIdentifier=cluster_identifier)['Clusters']\n            return response[0]['ClusterStatus'] if response else None\n        except conn.exceptions.ClusterNotFoundFault:\n            return 'cluster_not_found'", "response": "Return status of a cluster in the specified language"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a cluster and optionally create a snapshot", "response": "def delete_cluster(\n            self,\n            cluster_identifier,\n            skip_final_cluster_snapshot=True,\n            final_cluster_snapshot_identifier=''):\n        \"\"\"\n        Delete a cluster and optionally create a snapshot\n\n        :param cluster_identifier: unique identifier of a cluster\n        :type cluster_identifier: str\n        :param skip_final_cluster_snapshot: determines cluster snapshot creation\n        :type skip_final_cluster_snapshot: bool\n        :param final_cluster_snapshot_identifier: name of final cluster snapshot\n        :type final_cluster_snapshot_identifier: str\n        \"\"\"\n        response = self.get_conn().delete_cluster(\n            ClusterIdentifier=cluster_identifier,\n            SkipFinalClusterSnapshot=skip_final_cluster_snapshot,\n            FinalClusterSnapshotIdentifier=final_cluster_snapshot_identifier\n        )\n        return response['Cluster'] if response['Cluster'] else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of snapshots for a cluster", "response": "def describe_cluster_snapshots(self, cluster_identifier):\n        \"\"\"\n        Gets a list of snapshots for a cluster\n\n        :param cluster_identifier: unique identifier of a cluster\n        :type cluster_identifier: str\n        \"\"\"\n        response = self.get_conn().describe_cluster_snapshots(\n            ClusterIdentifier=cluster_identifier\n        )\n        if 'Snapshots' not in response:\n            return None\n        snapshots = response['Snapshots']\n        snapshots = filter(lambda x: x['Status'], snapshots)\n        snapshots.sort(key=lambda x: x['SnapshotCreateTime'], reverse=True)\n        return snapshots"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore_from_cluster_snapshot(self, cluster_identifier, snapshot_identifier):\n        response = self.get_conn().restore_from_cluster_snapshot(\n            ClusterIdentifier=cluster_identifier,\n            SnapshotIdentifier=snapshot_identifier\n        )\n        return response['Cluster'] if response['Cluster'] else None", "response": "Restores a cluster from its snapshot"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_cluster_snapshot(self, snapshot_identifier, cluster_identifier):\n        response = self.get_conn().create_cluster_snapshot(\n            SnapshotIdentifier=snapshot_identifier,\n            ClusterIdentifier=cluster_identifier,\n        )\n        return response['Snapshot'] if response['Snapshot'] else None", "response": "Creates a snapshot of a specific resource"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_volume(self, volume):\n\n        self._add_volume(name=volume.name, configs=volume.configs)", "response": "Adds a new volume to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a mount to the cache entry.", "response": "def add_mount(self,\n                  volume_mount):\n        \"\"\"\n        Args:\n            volume_mount (VolumeMount):\n        \"\"\"\n        self._add_mount(\n            name=volume_mount.name,\n            mount_path=volume_mount.mount_path,\n            sub_path=volume_mount.sub_path,\n            read_only=volume_mount.read_only\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a job flow using the config from the EMR connection.", "response": "def create_job_flow(self, job_flow_overrides):\n        \"\"\"\n        Creates a job flow using the config from the EMR connection.\n        Keys of the json extra hash may have the arguments of the boto3\n        run_job_flow method.\n        Overrides for this config may be passed as the job_flow_overrides.\n        \"\"\"\n\n        if not self.emr_conn_id:\n            raise AirflowException('emr_conn_id must be present to use create_job_flow')\n\n        emr_conn = self.get_connection(self.emr_conn_id)\n\n        config = emr_conn.extra_dejson.copy()\n        config.update(job_flow_overrides)\n\n        response = self.get_conn().run_job_flow(**config)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_for_filesize(result, size=None):\n        if size:\n            log = LoggingMixin().log\n            log.debug(\n                'Filtering for file size >= %s in files: %s',\n                size, map(lambda x: x['path'], result)\n            )\n            size *= settings.MEGABYTE\n            result = [x for x in result if x['length'] >= size]\n            log.debug('HdfsSensor.poke: after size filter result is %s', result)\n        return result", "response": "Filter the result list to only return the files with size > = size."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter out the result of Snakebite ls for ignored extensions.", "response": "def filter_for_ignored_ext(result, ignored_ext, ignore_copying):\n        \"\"\"\n        Will filter if instructed to do so the result to remove matching criteria\n\n        :param result: list of dicts returned by Snakebite ls\n        :type result: list[dict]\n        :param ignored_ext: list of ignored extensions\n        :type ignored_ext: list\n        :param ignore_copying: shall we ignore ?\n        :type ignore_copying: bool\n        :return: list of dicts which were not removed\n        :rtype: list[dict]\n        \"\"\"\n        if ignore_copying:\n            log = LoggingMixin().log\n            regex_builder = r\"^.*\\.(%s$)$\" % '$|'.join(ignored_ext)\n            ignored_extensions_regex = re.compile(regex_builder)\n            log.debug(\n                'Filtering result for ignored extensions: %s in files %s',\n                ignored_extensions_regex.pattern, map(lambda x: x['path'], result)\n            )\n            result = [x for x in result if not ignored_extensions_regex.match(x['path'])]\n            log.debug('HdfsSensor.poke: after ext filter result is %s', result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, context):\n        s3_conn = S3Hook(self.s3_conn_id)\n\n        # Grab collection and execute query according to whether or not it is a pipeline\n        if self.is_pipeline:\n            results = MongoHook(self.mongo_conn_id).aggregate(\n                mongo_collection=self.mongo_collection,\n                aggregate_query=self.mongo_query,\n                mongo_db=self.mongo_db\n            )\n\n        else:\n            results = MongoHook(self.mongo_conn_id).find(\n                mongo_collection=self.mongo_collection,\n                query=self.mongo_query,\n                mongo_db=self.mongo_db\n            )\n\n        # Performs transform then stringifies the docs results into json format\n        docs_str = self._stringify(self.transform(results))\n\n        # Load Into S3\n        s3_conn.load_string(\n            string_data=docs_str,\n            key=self.s3_key,\n            bucket_name=self.s3_bucket,\n            replace=self.replace\n        )\n\n        return True", "response": "Executes the task instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _stringify(iterable, joinable='\\n'):\n        return joinable.join(\n            [json.dumps(doc, default=json_util.default) for doc in iterable]\n        )", "response": "Takes an iterable containing dictionaries and\n            returns a stringified version using python join"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_pool(name, session=None):\n    if not (name and name.strip()):\n        raise AirflowBadRequest(\"Pool name shouldn't be empty\")\n\n    pool = session.query(Pool).filter_by(pool=name).first()\n    if pool is None:\n        raise PoolNotFound(\"Pool '%s' doesn't exist\" % name)\n\n    return pool", "response": "Get pool by a given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a pool with a given parameters.", "response": "def create_pool(name, slots, description, session=None):\n    \"\"\"Create a pool with a given parameters.\"\"\"\n    if not (name and name.strip()):\n        raise AirflowBadRequest(\"Pool name shouldn't be empty\")\n\n    try:\n        slots = int(slots)\n    except ValueError:\n        raise AirflowBadRequest(\"Bad value for `slots`: %s\" % slots)\n\n    session.expire_on_commit = False\n    pool = session.query(Pool).filter_by(pool=name).first()\n    if pool is None:\n        pool = Pool(pool=name, slots=slots, description=description)\n        session.add(pool)\n    else:\n        pool.slots = slots\n        pool.description = description\n\n    session.commit()\n\n    return pool"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes pool by a given name.", "response": "def delete_pool(name, session=None):\n    \"\"\"Delete pool by a given name.\"\"\"\n    if not (name and name.strip()):\n        raise AirflowBadRequest(\"Pool name shouldn't be empty\")\n\n    pool = session.query(Pool).filter_by(pool=name).first()\n    if pool is None:\n        raise PoolNotFound(\"Pool '%s' doesn't exist\" % name)\n\n    session.delete(pool)\n    session.commit()\n\n    return pool"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a python dictionary to the proto object", "response": "def _dict_to_proto(py_dict, proto):\n        \"\"\"\n        Converts a python dictionary to the proto supplied\n\n        :param py_dict: The dictionary to convert\n        :type py_dict: dict\n        :param proto: The proto object to merge with dictionary\n        :type proto: protobuf\n        :return: A parsed python dictionary in provided proto format\n        :raises:\n            ParseError: On JSON parsing problems.\n        \"\"\"\n        dict_json_str = json.dumps(py_dict)\n        return json_format.Parse(dict_json_str, proto)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_operation(self, operation, project_id=None):\n        self.log.info(\"Waiting for OPERATION_NAME %s\", operation.name)\n        time.sleep(OPERATIONAL_POLL_INTERVAL)\n        while operation.status != Operation.Status.DONE:\n            if operation.status == Operation.Status.RUNNING or operation.status == \\\n                    Operation.Status.PENDING:\n                time.sleep(OPERATIONAL_POLL_INTERVAL)\n            else:\n                raise exceptions.GoogleCloudError(\n                    \"Operation has failed with status: %s\" % operation.status)\n            # To update status of operation\n            operation = self.get_operation(operation.name, project_id=project_id or self.project_id)\n        return operation", "response": "Waits for an operation to complete and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the operation from Google Cloud", "response": "def get_operation(self, operation_name, project_id=None):\n        \"\"\"\n        Fetches the operation from Google Cloud\n\n        :param operation_name: Name of operation to fetch\n        :type operation_name: str\n        :param project_id: Google Cloud Platform project ID\n        :type project_id: str\n        :return: The new, updated operation from Google Cloud\n        \"\"\"\n        return self.get_client().get_operation(project_id=project_id or self.project_id,\n                                               zone=self.location,\n                                               operation_id=operation_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nappend labels to the provided Cluster Protobuf", "response": "def _append_label(cluster_proto, key, val):\n        \"\"\"\n        Append labels to provided Cluster Protobuf\n\n        Labels must fit the regex ``[a-z]([-a-z0-9]*[a-z0-9])?`` (current\n         airflow version string follows semantic versioning spec: x.y.z).\n\n        :param cluster_proto: The proto to append resource_label airflow\n            version to\n        :type cluster_proto: google.cloud.container_v1.types.Cluster\n        :param key: The key label\n        :type key: str\n        :param val:\n        :type val: str\n        :return: The cluster proto updated with new label\n        \"\"\"\n        val = val.replace('.', '-').replace('+', '-')\n        cluster_proto.resource_labels.update({key: val})\n        return cluster_proto"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the cluster with the specified name.", "response": "def delete_cluster(self, name, project_id=None, retry=DEFAULT, timeout=DEFAULT):\n        \"\"\"\n        Deletes the cluster, including the Kubernetes endpoint and all\n        worker nodes. Firewalls and routes that were configured during\n        cluster creation are also deleted. Other Google Compute Engine\n        resources that might be in use by the cluster (e.g. load balancer\n        resources) will not be deleted if they weren\u2019t present at the\n        initial create time.\n\n        :param name: The name of the cluster to delete\n        :type name: str\n        :param project_id: Google Cloud Platform project ID\n        :type project_id: str\n        :param retry: Retry object used to determine when/if to retry requests.\n            If None is specified, requests will not be retried.\n        :type retry: google.api_core.retry.Retry\n        :param timeout: The amount of time, in seconds, to wait for the request to\n            complete. Note that if retry is specified, the timeout applies to each\n            individual attempt.\n        :type timeout: float\n        :return: The full url to the delete operation if successful, else None\n        \"\"\"\n\n        self.log.info(\n            \"Deleting (project_id=%s, zone=%s, cluster_id=%s)\", self.project_id, self.location, name\n        )\n\n        try:\n            op = self.get_client().delete_cluster(project_id=project_id or self.project_id,\n                                                  zone=self.location,\n                                                  cluster_id=name,\n                                                  retry=retry,\n                                                  timeout=timeout)\n            op = self.wait_for_operation(op)\n            # Returns server-defined url for the resource\n            return op.self_link\n        except NotFound as error:\n            self.log.info('Assuming Success: %s', error.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_cluster(self, cluster, project_id=None, retry=DEFAULT, timeout=DEFAULT):\n\n        if isinstance(cluster, dict):\n            cluster_proto = Cluster()\n            cluster = self._dict_to_proto(py_dict=cluster, proto=cluster_proto)\n        elif not isinstance(cluster, Cluster):\n            raise AirflowException(\n                \"cluster is not instance of Cluster proto or python dict\")\n\n        self._append_label(cluster, 'airflow-version', 'v' + version.version)\n\n        self.log.info(\n            \"Creating (project_id=%s, zone=%s, cluster_name=%s)\",\n            self.project_id, self.location, cluster.name\n        )\n        try:\n            op = self.get_client().create_cluster(project_id=project_id or self.project_id,\n                                                  zone=self.location,\n                                                  cluster=cluster,\n                                                  retry=retry,\n                                                  timeout=timeout)\n            op = self.wait_for_operation(op)\n\n            return op.target_link\n        except AlreadyExists as error:\n            self.log.info('Assuming Success: %s', error.message)\n            return self.get_cluster(name=cluster.name).self_link", "response": "Creates a new cluster with the specified number and type of Engine instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves details of a cluster.", "response": "def get_cluster(self, name, project_id=None, retry=DEFAULT, timeout=DEFAULT):\n        \"\"\"\n        Gets details of specified cluster\n\n        :param name: The name of the cluster to retrieve\n        :type name: str\n        :param project_id: Google Cloud Platform project ID\n        :type project_id: str\n        :param retry: A retry object used to retry requests. If None is specified,\n            requests will not be retried.\n        :type retry: google.api_core.retry.Retry\n        :param timeout: The amount of time, in seconds, to wait for the request to\n            complete. Note that if retry is specified, the timeout applies to each\n            individual attempt.\n        :type timeout: float\n        :return: google.cloud.container_v1.types.Cluster\n        \"\"\"\n        self.log.info(\n            \"Fetching cluster (project_id=%s, zone=%s, cluster_name=%s)\",\n            project_id or self.project_id, self.location, name\n        )\n\n        return self.get_client().get_cluster(project_id=project_id or self.project_id,\n                                             zone=self.location,\n                                             cluster_id=name,\n                                             retry=retry,\n                                             timeout=timeout).self_link"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_webhook_endpoint(self, http_conn_id, webhook_endpoint):\n        if webhook_endpoint:\n            endpoint = webhook_endpoint\n        elif http_conn_id:\n            conn = self.get_connection(http_conn_id)\n            extra = conn.extra_dejson\n            endpoint = extra.get('webhook_endpoint', '')\n        else:\n            raise AirflowException('Cannot get webhook endpoint: No valid Discord '\n                                   'webhook endpoint or http_conn_id supplied.')\n\n        # make sure endpoint matches the expected Discord webhook format\n        if not re.match('^webhooks/[0-9]+/[a-zA-Z0-9_-]+$', endpoint):\n            raise AirflowException('Expected Discord webhook endpoint in the form '\n                                   'of \"webhooks/{webhook.id}/{webhook.token}\".')\n\n        return endpoint", "response": "Get the webhook endpoint from the Discord http_conn_id or the webhook endpoint if none is supplied."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the Discord JSON payload.", "response": "def _build_discord_payload(self):\n        \"\"\"\n        Construct the Discord JSON payload. All relevant parameters are combined here\n        to a valid Discord JSON payload.\n\n        :return: Discord payload (str) to send\n        \"\"\"\n        payload = {}\n\n        if self.username:\n            payload['username'] = self.username\n        if self.avatar_url:\n            payload['avatar_url'] = self.avatar_url\n\n        payload['tts'] = self.tts\n\n        if len(self.message) <= 2000:\n            payload['content'] = self.message\n        else:\n            raise AirflowException('Discord message length must be 2000 or fewer '\n                                   'characters.')\n\n        return json.dumps(payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self):\n        proxies = {}\n        if self.proxy:\n            # we only need https proxy for Discord\n            proxies = {'https': self.proxy}\n\n        discord_payload = self._build_discord_payload()\n\n        self.run(endpoint=self.webhook_endpoint,\n                 data=discord_payload,\n                 headers={'Content-type': 'application/json'},\n                 extra_options={'proxies': proxies})", "response": "Execute the Discord webhook call\n clf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt(self, key_name, plaintext, authenticated_data=None):\n        keys = self.get_conn().projects().locations().keyRings().cryptoKeys()\n        body = {'plaintext': _b64encode(plaintext)}\n        if authenticated_data:\n            body['additionalAuthenticatedData'] = _b64encode(authenticated_data)\n\n        request = keys.encrypt(name=key_name, body=body)\n        response = request.execute(num_retries=self.num_retries)\n\n        ciphertext = response['ciphertext']\n        return ciphertext", "response": "Encrypts a plaintext message using Google Cloud KMS."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a command and return a subprocess handle.", "response": "def Popen(self, cmd, **kwargs):\n        \"\"\"\n        Remote Popen\n\n        :param cmd: command to remotely execute\n        :param kwargs: extra arguments to Popen (see subprocess.Popen)\n        :return: handle to subprocess\n        \"\"\"\n        masked_cmd = ' '.join(self.cmd_mask_password(cmd))\n        self.log.info(\"Executing command: {}\".format(masked_cmd))\n        self.sp = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            **kwargs)\n\n        for line in iter(self.sp.stdout):\n            self.log.info(line.strip())\n\n        self.sp.wait()\n\n        self.log.info(\"Command exited with return code %s\", self.sp.returncode)\n\n        if self.sp.returncode:\n            raise AirflowException(\"Sqoop command failed: {}\".format(masked_cmd))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_table(self, table, target_dir=None, append=False, file_type=\"text\",\n                     columns=None, split_by=None, where=None, direct=False,\n                     driver=None, extra_import_options=None):\n        \"\"\"\n        Imports table from remote location to target dir. Arguments are\n        copies of direct sqoop command line arguments\n\n        :param table: Table to read\n        :param target_dir: HDFS destination dir\n        :param append: Append data to an existing dataset in HDFS\n        :param file_type: \"avro\", \"sequence\", \"text\" or \"parquet\".\n            Imports data to into the specified format. Defaults to text.\n        :param columns: <col,col,col\u2026> Columns to import from table\n        :param split_by: Column of the table used to split work units\n        :param where: WHERE clause to use during import\n        :param direct: Use direct connector if exists for the database\n        :param driver: Manually specify JDBC driver class to use\n        :param extra_import_options: Extra import options to pass as dict.\n            If a key doesn't have a value, just pass an empty string to it.\n            Don't include prefix of -- for sqoop options.\n        \"\"\"\n        cmd = self._import_cmd(target_dir, append, file_type, split_by, direct,\n                               driver, extra_import_options)\n\n        cmd += [\"--table\", table]\n\n        if columns:\n            cmd += [\"--columns\", columns]\n        if where:\n            cmd += [\"--where\", where]\n\n        self.Popen(cmd)", "response": "Imports data from a table into a target directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_query(self, query, target_dir, append=False, file_type=\"text\",\n                     split_by=None, direct=None, driver=None, extra_import_options=None):\n        \"\"\"\n        Imports a specific query from the rdbms to hdfs\n\n        :param query: Free format query to run\n        :param target_dir: HDFS destination dir\n        :param append: Append data to an existing dataset in HDFS\n        :param file_type: \"avro\", \"sequence\", \"text\" or \"parquet\"\n            Imports data to hdfs into the specified format. Defaults to text.\n        :param split_by: Column of the table used to split work units\n        :param direct: Use direct import fast path\n        :param driver: Manually specify JDBC driver class to use\n        :param extra_import_options: Extra import options to pass as dict.\n            If a key doesn't have a value, just pass an empty string to it.\n            Don't include prefix of -- for sqoop options.\n        \"\"\"\n        cmd = self._import_cmd(target_dir, append, file_type, split_by, direct,\n                               driver, extra_import_options)\n        cmd += [\"--query\", query]\n\n        self.Popen(cmd)", "response": "Imports a specific query from the rdbms to HDFS"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_table(self, table, export_dir, input_null_string,\n                     input_null_non_string, staging_table,\n                     clear_staging_table, enclosed_by,\n                     escaped_by, input_fields_terminated_by,\n                     input_lines_terminated_by,\n                     input_optionally_enclosed_by, batch,\n                     relaxed_isolation, extra_export_options=None):\n        \"\"\"\n        Exports Hive table to remote location. Arguments are copies of direct\n        sqoop command line Arguments\n\n        :param table: Table remote destination\n        :param export_dir: Hive table to export\n        :param input_null_string: The string to be interpreted as null for\n            string columns\n        :param input_null_non_string: The string to be interpreted as null\n            for non-string columns\n        :param staging_table: The table in which data will be staged before\n            being inserted into the destination table\n        :param clear_staging_table: Indicate that any data present in the\n            staging table can be deleted\n        :param enclosed_by: Sets a required field enclosing character\n        :param escaped_by: Sets the escape character\n        :param input_fields_terminated_by: Sets the field separator character\n        :param input_lines_terminated_by: Sets the end-of-line character\n        :param input_optionally_enclosed_by: Sets a field enclosing character\n        :param batch: Use batch mode for underlying statement execution\n        :param relaxed_isolation: Transaction isolation to read uncommitted\n            for the mappers\n        :param extra_export_options: Extra export options to pass as dict.\n            If a key doesn't have a value, just pass an empty string to it.\n            Don't include prefix of -- for sqoop options.\n        \"\"\"\n        cmd = self._export_cmd(table, export_dir, input_null_string,\n                               input_null_non_string, staging_table,\n                               clear_staging_table, enclosed_by, escaped_by,\n                               input_fields_terminated_by,\n                               input_lines_terminated_by,\n                               input_optionally_enclosed_by, batch,\n                               relaxed_isolation, extra_export_options)\n\n        self.Popen(cmd)", "response": "This function exports the given table to the given location."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves a connection to the Cloud Text to Speech API.", "response": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Text to Speech.\n\n        :return: Google Cloud Text to Speech client object.\n        :rtype: google.cloud.texttospeech_v1.TextToSpeechClient\n        \"\"\"\n        if not self._client:\n            self._client = TextToSpeechClient(credentials=self._get_credentials())\n        return self._client"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsynthesize a text input using the specified voice and audio configuration.", "response": "def synthesize_speech(self, input_data, voice, audio_config, retry=None, timeout=None):\n        \"\"\"\n        Synthesizes text input\n\n        :param input_data: text input to be synthesized. See more:\n            https://googleapis.github.io/google-cloud-python/latest/texttospeech/gapic/v1/types.html#google.cloud.texttospeech_v1.types.SynthesisInput\n        :type input_data: dict or google.cloud.texttospeech_v1.types.SynthesisInput\n        :param voice: configuration of voice to be used in synthesis. See more:\n            https://googleapis.github.io/google-cloud-python/latest/texttospeech/gapic/v1/types.html#google.cloud.texttospeech_v1.types.VoiceSelectionParams\n        :type voice: dict or google.cloud.texttospeech_v1.types.VoiceSelectionParams\n        :param audio_config: configuration of the synthesized audio. See more:\n            https://googleapis.github.io/google-cloud-python/latest/texttospeech/gapic/v1/types.html#google.cloud.texttospeech_v1.types.AudioConfig\n        :type audio_config: dict or google.cloud.texttospeech_v1.types.AudioConfig\n        :return: SynthesizeSpeechResponse See more:\n            https://googleapis.github.io/google-cloud-python/latest/texttospeech/gapic/v1/types.html#google.cloud.texttospeech_v1.types.SynthesizeSpeechResponse\n        :rtype: object\n        :param retry: (Optional) A retry object used to retry requests. If None is specified,\n                requests will not be retried.\n        :type retry: google.api_core.retry.Retry\n        :param timeout: (Optional) The amount of time, in seconds, to wait for the request to complete.\n            Note that if retry is specified, the timeout applies to each individual attempt.\n        :type timeout: float\n        \"\"\"\n        client = self.get_conn()\n        self.log.info(\"Synthesizing input: %s\" % input_data)\n        return client.synthesize_speech(\n            input_=input_data, voice=voice, audio_config=audio_config, retry=retry, timeout=timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        # When application exit, system shuts down all handlers by\n        # calling close method. Here we check if logger is already\n        # closed to prevent uploading the log to remote storage multiple\n        # times when `logging.shutdown` is called.\n        if self.closed:\n            return\n\n        super().close()\n\n        if not self.upload_on_close:\n            return\n\n        local_loc = os.path.join(self.local_base, self.log_relative_path)\n        remote_loc = os.path.join(self.remote_base, self.log_relative_path)\n        if os.path.exists(local_loc):\n            # read log and remove old logs to get just the latest additions\n            with open(local_loc, 'r') as logfile:\n                log = logfile.read()\n            self.s3_write(log, remote_loc)\n\n        # Mark closed so we don't double write if close is called twice\n        self.closed = True", "response": "Close and upload local log file to remote storage S3."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef s3_read(self, remote_log_location, return_error=False):\n        try:\n            return self.hook.read_key(remote_log_location)\n        except Exception:\n            msg = 'Could not read logs from {}'.format(remote_log_location)\n            self.log.exception(msg)\n            # return error if needed\n            if return_error:\n                return msg", "response": "Reads the log from the remote storage location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the log to the remote storage.", "response": "def s3_write(self, log, remote_log_location, append=True):\n        \"\"\"\n        Writes the log to the remote_log_location. Fails silently if no hook\n        was created.\n        :param log: the log to write to the remote_log_location\n        :type log: str\n        :param remote_log_location: the log's location in remote storage\n        :type remote_log_location: str (path)\n        :param append: if False, any existing log file is overwritten. If True,\n            the new log is appended to any existing logs.\n        :type append: bool\n        \"\"\"\n        if append and self.s3_log_exists(remote_log_location):\n            old_log = self.s3_read(remote_log_location)\n            log = '\\n'.join([old_log, log]) if old_log else log\n\n        try:\n            self.hook.load_string(\n                log,\n                key=remote_log_location,\n                replace=True,\n                encrypt=configuration.conf.getboolean('core', 'ENCRYPT_S3_LOGS'),\n            )\n        except Exception:\n            self.log.exception('Could not write logs to %s', remote_log_location)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_init_containers(self):\n        # If we're using volume claims to mount the dags, no init container is needed\n        if self.kube_config.dags_volume_claim or \\\n           self.kube_config.dags_volume_host or self.kube_config.dags_in_image:\n            return []\n\n        # Otherwise, define a git-sync init container\n        init_environment = [{\n            'name': 'GIT_SYNC_REPO',\n            'value': self.kube_config.git_repo\n        }, {\n            'name': 'GIT_SYNC_BRANCH',\n            'value': self.kube_config.git_branch\n        }, {\n            'name': 'GIT_SYNC_ROOT',\n            'value': self.kube_config.git_sync_root\n        }, {\n            'name': 'GIT_SYNC_DEST',\n            'value': self.kube_config.git_sync_dest\n        }, {\n            'name': 'GIT_SYNC_DEPTH',\n            'value': '1'\n        }, {\n            'name': 'GIT_SYNC_ONE_TIME',\n            'value': 'true'\n        }]\n        if self.kube_config.git_user:\n            init_environment.append({\n                'name': 'GIT_SYNC_USERNAME',\n                'value': self.kube_config.git_user\n            })\n        if self.kube_config.git_password:\n            init_environment.append({\n                'name': 'GIT_SYNC_PASSWORD',\n                'value': self.kube_config.git_password\n            })\n\n        volume_mounts = [{\n            'mountPath': self.kube_config.git_sync_root,\n            'name': self.dags_volume_name,\n            'readOnly': False\n        }]\n        if self.kube_config.git_ssh_key_secret_name:\n            volume_mounts.append({\n                'name': self.git_sync_ssh_secret_volume_name,\n                'mountPath': '/etc/git-secret/ssh',\n                'subPath': 'ssh'\n            })\n            init_environment.extend([\n                {\n                    'name': 'GIT_SSH_KEY_FILE',\n                    'value': '/etc/git-secret/ssh'\n                },\n                {\n                    'name': 'GIT_SYNC_SSH',\n                    'value': 'true'\n                }])\n        if self.kube_config.git_ssh_known_hosts_configmap_name:\n            volume_mounts.append({\n                'name': self.git_sync_ssh_known_hosts_volume_name,\n                'mountPath': '/etc/git-secret/known_hosts',\n                'subPath': 'known_hosts'\n            })\n            init_environment.extend([\n                {\n                    'name': 'GIT_KNOWN_HOSTS',\n                    'value': 'true'\n                },\n                {\n                    'name': 'GIT_SSH_KNOWN_HOSTS_FILE',\n                    'value': '/etc/git-secret/known_hosts'\n                }\n            ])\n        else:\n            init_environment.append({\n                'name': 'GIT_KNOWN_HOSTS',\n                'value': 'false'\n            })\n\n        return [{\n            'name': self.kube_config.git_sync_init_container_name,\n            'image': self.kube_config.git_sync_container,\n            'securityContext': {'runAsUser': 65533},  # git-sync user\n            'env': init_environment,\n            'volumeMounts': volume_mounts\n        }]", "response": "Returns a list of init containers that are needed for the current state of the dags."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_environment(self):\n        env = {}\n\n        for env_var_name, env_var_val in six.iteritems(self.kube_config.kube_env_vars):\n            env[env_var_name] = env_var_val\n\n        env[\"AIRFLOW__CORE__EXECUTOR\"] = \"LocalExecutor\"\n\n        if self.kube_config.airflow_configmap:\n            env['AIRFLOW_HOME'] = self.worker_airflow_home\n            env['AIRFLOW__CORE__DAGS_FOLDER'] = self.worker_airflow_dags\n        if (not self.kube_config.airflow_configmap and\n                'AIRFLOW__CORE__SQL_ALCHEMY_CONN' not in self.kube_config.kube_secrets):\n            env['AIRFLOW__CORE__SQL_ALCHEMY_CONN'] = conf.get(\"core\", \"SQL_ALCHEMY_CONN\")\n        if self.kube_config.git_dags_folder_mount_point:\n            # /root/airflow/dags/repo/dags\n            dag_volume_mount_path = os.path.join(\n                self.kube_config.git_dags_folder_mount_point,\n                self.kube_config.git_sync_dest,  # repo\n                self.kube_config.git_subpath     # dags\n            )\n            env['AIRFLOW__CORE__DAGS_FOLDER'] = dag_volume_mount_path\n        return env", "response": "Defines any necessary environment variables for the pod executor"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_secrets(self):\n        worker_secrets = []\n\n        for env_var_name, obj_key_pair in six.iteritems(self.kube_config.kube_secrets):\n            k8s_secret_obj, k8s_secret_key = obj_key_pair.split('=')\n            worker_secrets.append(\n                Secret('env', env_var_name, k8s_secret_obj, k8s_secret_key)\n            )\n\n        if self.kube_config.env_from_secret_ref:\n            for secret_ref in self.kube_config.env_from_secret_ref.split(','):\n                worker_secrets.append(\n                    Secret('env', None, secret_ref)\n                )\n\n        return worker_secrets", "response": "Defines any necessary secrets for the pod executor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_security_context(self):\n        security_context = {}\n\n        if self.kube_config.worker_run_as_user:\n            security_context['runAsUser'] = self.kube_config.worker_run_as_user\n\n        if self.kube_config.worker_fs_group:\n            security_context['fsGroup'] = self.kube_config.worker_fs_group\n\n        # set fs_group to 65533 if not explicitly specified and using git ssh keypair auth\n        if self.kube_config.git_ssh_key_secret_name and security_context.get('fsGroup') is None:\n            security_context['fsGroup'] = 65533\n\n        return security_context", "response": "Defines the security context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkilling a Qubole command", "response": "def kill(self, ti):\n        \"\"\"\n        Kill (cancel) a Qubole command\n        :param ti: Task Instance of the dag, used to determine the Quboles command id\n        :return: response from Qubole\n        \"\"\"\n        if self.cmd is None:\n            if not ti and not self.task_instance:\n                raise Exception(\"Unable to cancel Qubole Command, context is unavailable!\")\n            elif not ti:\n                ti = self.task_instance\n            cmd_id = ti.xcom_pull(key=\"qbol_cmd_id\", task_ids=ti.task_id)\n            self.cmd = self.cls.find(cmd_id)\n        if self.cls and self.cmd:\n            self.log.info('Sending KILL signal to Qubole Command Id: %s', self.cmd.id)\n            self.cmd.cancel()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the results of a command from Qubole and save it into a file.", "response": "def get_results(self, ti=None, fp=None, inline=True, delim=None, fetch=True):\n        \"\"\"\n        Get results (or just s3 locations) of a command from Qubole and save into a file\n        :param ti: Task Instance of the dag, used to determine the Quboles command id\n        :param fp: Optional file pointer, will create one and return if None passed\n        :param inline: True to download actual results, False to get s3 locations only\n        :param delim: Replaces the CTL-A chars with the given delim, defaults to ','\n        :param fetch: when inline is True, get results directly from s3 (if large)\n        :return: file location containing actual results or s3 locations of results\n        \"\"\"\n        if fp is None:\n            iso = datetime.datetime.utcnow().isoformat()\n            logpath = os.path.expanduser(\n                configuration.conf.get('core', 'BASE_LOG_FOLDER')\n            )\n            resultpath = logpath + '/' + self.dag_id + '/' + self.task_id + '/results'\n            configuration.mkdir_p(resultpath)\n            fp = open(resultpath + '/' + iso, 'wb')\n\n        if self.cmd is None:\n            cmd_id = ti.xcom_pull(key=\"qbol_cmd_id\", task_ids=self.task_id)\n            self.cmd = self.cls.find(cmd_id)\n\n        self.cmd.get_results(fp, inline, delim, fetch)\n        fp.flush()\n        fp.close()\n        return fp.name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the log of a command from Qubole", "response": "def get_log(self, ti):\n        \"\"\"\n        Get Logs of a command from Qubole\n        :param ti: Task Instance of the dag, used to determine the Quboles command id\n        :return: command log as text\n        \"\"\"\n        if self.cmd is None:\n            cmd_id = ti.xcom_pull(key=\"qbol_cmd_id\", task_ids=self.task_id)\n        Command.get_log_id(self.cls, cmd_id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_jobs_id(self, ti):\n        if self.cmd is None:\n            cmd_id = ti.xcom_pull(key=\"qbol_cmd_id\", task_ids=self.task_id)\n        Command.get_jobs_id(self.cls, cmd_id)", "response": "Get the jobs associated with a Qubole commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_extra_links(self, operator, dttm):\n        conn = BaseHook.get_connection(operator.kwargs['qubole_conn_id'])\n        if conn and conn.host:\n            host = re.sub(r'api$', 'v2/analyze?command_id=', conn.host)\n        else:\n            host = 'https://api.qubole.com/v2/analyze?command_id='\n\n        ti = TaskInstance(task=operator, execution_date=dttm)\n        qds_command_id = ti.xcom_pull(task_ids=operator.task_id, key='qbol_cmd_id')\n        url = host + str(qds_command_id) if qds_command_id else ''\n        return url", "response": "Get link to qubole command result page."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the job s entry in the database with a timestamp for the latest heartbeat.", "response": "def heartbeat(self):\n        \"\"\"\n        Heartbeats update the job's entry in the database with a timestamp\n        for the latest_heartbeat and allows for the job to be killed\n        externally. This allows at the system level to monitor what is\n        actually active.\n\n        For instance, an old heartbeat for SchedulerJob would mean something\n        is wrong.\n\n        This also allows for any job to be killed externally, regardless\n        of who is running it or on which machine it is running.\n\n        Note that if your heartbeat is set to 60 seconds and you call this\n        method after 10 seconds of processing since the last heartbeat, it\n        will sleep 50 seconds to complete the 60 seconds and keep a steady\n        heart rate. If you go over 60 seconds before calling it, it won't\n        sleep at all.\n        \"\"\"\n        try:\n            with create_session() as session:\n                job = session.query(BaseJob).filter_by(id=self.id).one()\n                make_transient(job)\n                session.commit()\n\n            if job.state == State.SHUTDOWN:\n                self.kill()\n\n            is_unit_test = conf.getboolean('core', 'unit_test_mode')\n            if not is_unit_test:\n                # Figure out how long to sleep for\n                sleep_for = 0\n                if job.latest_heartbeat:\n                    seconds_remaining = self.heartrate - \\\n                        (timezone.utcnow() - job.latest_heartbeat)\\\n                        .total_seconds()\n                    sleep_for = max(0, seconds_remaining)\n\n                sleep(sleep_for)\n\n            # Update last heartbeat time\n            with create_session() as session:\n                job = session.query(BaseJob).filter(BaseJob.id == self.id).first()\n                job.latest_heartbeat = timezone.utcnow()\n                session.merge(job)\n                session.commit()\n\n                self.heartbeat_callback(session=session)\n                self.log.debug('[heartbeat]')\n        except OperationalError as e:\n            self.log.error(\"Scheduler heartbeat got an exception: %s\", str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_state_for_orphaned_tasks(self, filter_by_dag_run=None, session=None):\n        queued_tis = self.executor.queued_tasks\n        # also consider running as the state might not have changed in the db yet\n        running_tis = self.executor.running\n\n        resettable_states = [State.SCHEDULED, State.QUEUED]\n        TI = models.TaskInstance\n        DR = models.DagRun\n        if filter_by_dag_run is None:\n            resettable_tis = (\n                session\n                .query(TI)\n                .join(\n                    DR,\n                    and_(\n                        TI.dag_id == DR.dag_id,\n                        TI.execution_date == DR.execution_date))\n                .filter(\n                    DR.state == State.RUNNING,\n                    DR.run_id.notlike(BackfillJob.ID_PREFIX + '%'),\n                    TI.state.in_(resettable_states))).all()\n        else:\n            resettable_tis = filter_by_dag_run.get_task_instances(state=resettable_states,\n                                                                  session=session)\n        tis_to_reset = []\n        # Can't use an update here since it doesn't support joins\n        for ti in resettable_tis:\n            if ti.key not in queued_tis and ti.key not in running_tis:\n                tis_to_reset.append(ti)\n\n        if len(tis_to_reset) == 0:\n            return []\n\n        def query(result, items):\n            filter_for_tis = ([and_(TI.dag_id == ti.dag_id,\n                                    TI.task_id == ti.task_id,\n                                    TI.execution_date == ti.execution_date)\n                               for ti in items])\n            reset_tis = (\n                session\n                .query(TI)\n                .filter(or_(*filter_for_tis), TI.state.in_(resettable_states))\n                .with_for_update()\n                .all())\n            for ti in reset_tis:\n                ti.state = State.NONE\n                session.merge(ti)\n            return result + reset_tis\n\n        reset_tis = helpers.reduce_in_chunks(query,\n                                             tis_to_reset,\n                                             [],\n                                             self.max_tis_per_query)\n\n        task_instance_str = '\\n\\t'.join(\n            [repr(x) for x in reset_tis])\n        session.commit()\n\n        self.log.info(\n            \"Reset the following %s TaskInstances:\\n\\t%s\",\n            len(reset_tis), task_instance_str\n        )\n        return reset_tis", "response": "This function resets the state of orphaned tasks in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlaunching a process to process the given file.", "response": "def _launch_process(result_queue,\n                        file_path,\n                        pickle_dags,\n                        dag_id_white_list,\n                        thread_name,\n                        zombies):\n        \"\"\"\n        Launch a process to process the given file.\n\n        :param result_queue: the queue to use for passing back the result\n        :type result_queue: multiprocessing.Queue\n        :param file_path: the file to process\n        :type file_path: unicode\n        :param pickle_dags: whether to pickle the DAGs found in the file and\n            save them to the DB\n        :type pickle_dags: bool\n        :param dag_id_white_list: if specified, only examine DAG ID's that are\n            in this list\n        :type dag_id_white_list: list[unicode]\n        :param thread_name: the name to use for the process that is launched\n        :type thread_name: unicode\n        :return: the process that was launched\n        :rtype: multiprocessing.Process\n        :param zombies: zombie task instances to kill\n        :type zombies: list[airflow.utils.dag_processing.SimpleTaskInstance]\n        \"\"\"\n        def helper():\n            # This helper runs in the newly created process\n            log = logging.getLogger(\"airflow.processor\")\n\n            stdout = StreamLogWriter(log, logging.INFO)\n            stderr = StreamLogWriter(log, logging.WARN)\n\n            set_context(log, file_path)\n\n            try:\n                # redirect stdout/stderr to log\n                sys.stdout = stdout\n                sys.stderr = stderr\n\n                # Re-configure the ORM engine as there are issues with multiple processes\n                settings.configure_orm()\n\n                # Change the thread name to differentiate log lines. This is\n                # really a separate process, but changing the name of the\n                # process doesn't work, so changing the thread name instead.\n                threading.current_thread().name = thread_name\n                start_time = time.time()\n\n                log.info(\"Started process (PID=%s) to work on %s\",\n                         os.getpid(), file_path)\n                scheduler_job = SchedulerJob(dag_ids=dag_id_white_list, log=log)\n                result = scheduler_job.process_file(file_path,\n                                                    zombies,\n                                                    pickle_dags)\n                result_queue.put(result)\n                end_time = time.time()\n                log.info(\n                    \"Processing %s took %.3f seconds\", file_path, end_time - start_time\n                )\n            except Exception:\n                # Log exceptions through the logging framework.\n                log.exception(\"Got an exception! Propagating...\")\n                raise\n            finally:\n                sys.stdout = sys.__stdout__\n                sys.stderr = sys.__stderr__\n                # We re-initialized the ORM within this Process above so we need to\n                # tear it down manually here\n                settings.dispose_orm()\n\n        p = multiprocessing.Process(target=helper,\n                                    args=(),\n                                    name=\"{}-Process\".format(thread_name))\n        p.start()\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting processing the DAG.", "response": "def start(self):\n        \"\"\"\n        Launch the process and start processing the DAG.\n        \"\"\"\n        self._process = DagFileProcessor._launch_process(\n            self._result_queue,\n            self.file_path,\n            self._pickle_dags,\n            self._dag_id_white_list,\n            \"DagFileProcessor{}\".format(self._instance_id),\n            self._zombies)\n        self._start_time = timezone.utcnow()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nterminating the process and then kill the process.", "response": "def terminate(self, sigkill=False):\n        \"\"\"\n        Terminate (and then kill) the process launched to process the file.\n\n        :param sigkill: whether to issue a SIGKILL if SIGTERM doesn't work.\n        :type sigkill: bool\n        \"\"\"\n        if self._process is None:\n            raise AirflowException(\"Tried to call stop before starting!\")\n        # The queue will likely get corrupted, so remove the reference\n        self._result_queue = None\n        self._process.terminate()\n        # Arbitrarily wait 5s for the process to die\n        self._process.join(5)\n        if sigkill and self._process.is_alive():\n            self.log.warning(\"Killing PID %s\", self._process.pid)\n            os.kill(self._process.pid, signal.SIGKILL)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the process launched to process this file is done.", "response": "def done(self):\n        \"\"\"\n        Check if the process launched to process this file is done.\n\n        :return: whether the process is finished running\n        :rtype: bool\n        \"\"\"\n        if self._process is None:\n            raise AirflowException(\"Tried to see if it's done before starting!\")\n\n        if self._done:\n            return True\n\n        # In case result queue is corrupted.\n        if self._result_queue and not self._result_queue.empty():\n            self._result = self._result_queue.get_nowait()\n            self._done = True\n            self.log.debug(\"Waiting for %s\", self._process)\n            self._process.join()\n            return True\n\n        # Potential error case when process dies\n        if self._result_queue and not self._process.is_alive():\n            self._done = True\n            # Get the object from the queue or else join() can hang.\n            if not self._result_queue.empty():\n                self._result = self._result_queue.get_nowait()\n            self.log.debug(\"Waiting for %s\", self._process)\n            self._process.join()\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexit gracefully upon receiving a signal.", "response": "def _exit_gracefully(self, signum, frame):\n        \"\"\"\n        Helper method to clean up processor_agent to avoid leaving orphan processes.\n        \"\"\"\n        self.log.info(\"Exiting gracefully upon receiving signal %s\", signum)\n        if self.processor_agent:\n            self.processor_agent.end()\n        sys.exit(os.EX_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmanaging all SLAs in a DAG and send alert emails for all the tasks that have succeeded in the past hour.", "response": "def manage_slas(self, dag, session=None):\n        \"\"\"\n        Finding all tasks that have SLAs defined, and sending alert emails\n        where needed. New SLA misses are also recorded in the database.\n\n        Where assuming that the scheduler runs often, so we only check for\n        tasks that should have succeeded in the past hour.\n        \"\"\"\n        if not any([isinstance(ti.sla, timedelta) for ti in dag.tasks]):\n            self.log.info(\"Skipping SLA check for %s because no tasks in DAG have SLAs\", dag)\n            return\n\n        TI = models.TaskInstance\n        sq = (\n            session\n            .query(\n                TI.task_id,\n                func.max(TI.execution_date).label('max_ti'))\n            .with_hint(TI, 'USE INDEX (PRIMARY)', dialect_name='mysql')\n            .filter(TI.dag_id == dag.dag_id)\n            .filter(or_(\n                TI.state == State.SUCCESS,\n                TI.state == State.SKIPPED))\n            .filter(TI.task_id.in_(dag.task_ids))\n            .group_by(TI.task_id).subquery('sq')\n        )\n\n        max_tis = session.query(TI).filter(\n            TI.dag_id == dag.dag_id,\n            TI.task_id == sq.c.task_id,\n            TI.execution_date == sq.c.max_ti,\n        ).all()\n\n        ts = timezone.utcnow()\n        for ti in max_tis:\n            task = dag.get_task(ti.task_id)\n            dttm = ti.execution_date\n            if isinstance(task.sla, timedelta):\n                dttm = dag.following_schedule(dttm)\n                while dttm < timezone.utcnow():\n                    following_schedule = dag.following_schedule(dttm)\n                    if following_schedule + task.sla < timezone.utcnow():\n                        session.merge(SlaMiss(\n                            task_id=ti.task_id,\n                            dag_id=ti.dag_id,\n                            execution_date=dttm,\n                            timestamp=ts))\n                    dttm = dag.following_schedule(dttm)\n        session.commit()\n\n        slas = (\n            session\n            .query(SlaMiss)\n            .filter(SlaMiss.notification_sent == False, SlaMiss.dag_id == dag.dag_id)  # noqa: E712\n            .all()\n        )\n\n        if slas:\n            sla_dates = [sla.execution_date for sla in slas]\n            qry = (\n                session\n                .query(TI)\n                .filter(\n                    TI.state != State.SUCCESS,\n                    TI.execution_date.in_(sla_dates),\n                    TI.dag_id == dag.dag_id\n                ).all()\n            )\n            blocking_tis = []\n            for ti in qry:\n                if ti.task_id in dag.task_ids:\n                    ti.task = dag.get_task(ti.task_id)\n                    blocking_tis.append(ti)\n                else:\n                    session.delete(ti)\n                    session.commit()\n\n            task_list = \"\\n\".join([\n                sla.task_id + ' on ' + sla.execution_date.isoformat()\n                for sla in slas])\n            blocking_task_list = \"\\n\".join([\n                ti.task_id + ' on ' + ti.execution_date.isoformat()\n                for ti in blocking_tis])\n            # Track whether email or any alert notification sent\n            # We consider email or the alert callback as notifications\n            email_sent = False\n            notification_sent = False\n            if dag.sla_miss_callback:\n                # Execute the alert callback\n                self.log.info(' --------------> ABOUT TO CALL SLA MISS CALL BACK ')\n                try:\n                    dag.sla_miss_callback(dag, task_list, blocking_task_list, slas,\n                                          blocking_tis)\n                    notification_sent = True\n                except Exception:\n                    self.log.exception(\"Could not call sla_miss_callback for DAG %s\",\n                                       dag.dag_id)\n            email_content = \"\"\"\\\n            Here's a list of tasks that missed their SLAs:\n            <pre><code>{task_list}\\n<code></pre>\n            Blocking tasks:\n            <pre><code>{blocking_task_list}\\n{bug}<code></pre>\n            \"\"\".format(task_list=task_list, blocking_task_list=blocking_task_list,\n                       bug=asciiart.bug)\n            emails = set()\n            for task in dag.tasks:\n                if task.email:\n                    if isinstance(task.email, basestring):\n                        emails |= set(get_email_address_list(task.email))\n                    elif isinstance(task.email, (list, tuple)):\n                        emails |= set(task.email)\n            if emails:\n                try:\n                    send_email(\n                        emails,\n                        \"[airflow] SLA miss on DAG=\" + dag.dag_id,\n                        email_content)\n                    email_sent = True\n                    notification_sent = True\n                except Exception:\n                    self.log.exception(\"Could not send SLA Miss email notification for\"\n                                       \" DAG %s\", dag.dag_id)\n            # If we sent any notification, update the sla_miss table\n            if notification_sent:\n                for sla in slas:\n                    if email_sent:\n                        sla.email_sent = True\n                    sla.notification_sent = True\n                    session.merge(sla)\n            session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the errors of the files that have not been imported by the DAGs in the given DagBag.", "response": "def update_import_errors(session, dagbag):\n        \"\"\"\n        For the DAGs in the given DagBag, record any associated import errors and clears\n        errors for files that no longer have them. These are usually displayed through the\n        Airflow UI so that users know that there are issues parsing DAGs.\n\n        :param session: session for ORM operations\n        :type session: sqlalchemy.orm.session.Session\n        :param dagbag: DagBag containing DAGs with import errors\n        :type dagbag: airflow.models.DagBag\n        \"\"\"\n        # Clear the errors of the processed files\n        for dagbag_file in dagbag.file_last_changed:\n            session.query(errors.ImportError).filter(\n                errors.ImportError.filename == dagbag_file\n            ).delete()\n\n        # Add the errors of the processed files\n        for filename, stacktrace in six.iteritems(dagbag.import_errors):\n            session.add(errors.ImportError(\n                filename=filename,\n                stacktrace=stacktrace))\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_dag_run(self, dag, session=None):\n        if dag.schedule_interval and conf.getboolean('scheduler', 'USE_JOB_SCHEDULE'):\n            active_runs = DagRun.find(\n                dag_id=dag.dag_id,\n                state=State.RUNNING,\n                external_trigger=False,\n                session=session\n            )\n            # return if already reached maximum active runs and no timeout setting\n            if len(active_runs) >= dag.max_active_runs and not dag.dagrun_timeout:\n                return\n            timedout_runs = 0\n            for dr in active_runs:\n                if (\n                        dr.start_date and dag.dagrun_timeout and\n                        dr.start_date < timezone.utcnow() - dag.dagrun_timeout):\n                    dr.state = State.FAILED\n                    dr.end_date = timezone.utcnow()\n                    dag.handle_callback(dr, success=False, reason='dagrun_timeout',\n                                        session=session)\n                    timedout_runs += 1\n            session.commit()\n            if len(active_runs) - timedout_runs >= dag.max_active_runs:\n                return\n\n            # this query should be replaced by find dagrun\n            qry = (\n                session.query(func.max(DagRun.execution_date))\n                .filter_by(dag_id=dag.dag_id)\n                .filter(or_(\n                    DagRun.external_trigger == False,  # noqa: E712\n                    # add % as a wildcard for the like query\n                    DagRun.run_id.like(DagRun.ID_PREFIX + '%')\n                ))\n            )\n            last_scheduled_run = qry.scalar()\n\n            # don't schedule @once again\n            if dag.schedule_interval == '@once' and last_scheduled_run:\n                return None\n\n            # don't do scheduler catchup for dag's that don't have dag.catchup = True\n            if not (dag.catchup or dag.schedule_interval == '@once'):\n                # The logic is that we move start_date up until\n                # one period before, so that timezone.utcnow() is AFTER\n                # the period end, and the job can be created...\n                now = timezone.utcnow()\n                next_start = dag.following_schedule(now)\n                last_start = dag.previous_schedule(now)\n                if next_start <= now:\n                    new_start = last_start\n                else:\n                    new_start = dag.previous_schedule(last_start)\n\n                if dag.start_date:\n                    if new_start >= dag.start_date:\n                        dag.start_date = new_start\n                else:\n                    dag.start_date = new_start\n\n            next_run_date = None\n            if not last_scheduled_run:\n                # First run\n                task_start_dates = [t.start_date for t in dag.tasks]\n                if task_start_dates:\n                    next_run_date = dag.normalize_schedule(min(task_start_dates))\n                    self.log.debug(\n                        \"Next run date based on tasks %s\",\n                        next_run_date\n                    )\n            else:\n                next_run_date = dag.following_schedule(last_scheduled_run)\n\n            # make sure backfills are also considered\n            last_run = dag.get_last_dagrun(session=session)\n            if last_run and next_run_date:\n                while next_run_date <= last_run.execution_date:\n                    next_run_date = dag.following_schedule(next_run_date)\n\n            # don't ever schedule prior to the dag's start_date\n            if dag.start_date:\n                next_run_date = (dag.start_date if not next_run_date\n                                 else max(next_run_date, dag.start_date))\n                if next_run_date == dag.start_date:\n                    next_run_date = dag.normalize_schedule(dag.start_date)\n\n                self.log.debug(\n                    \"Dag start date: %s. Next run date: %s\",\n                    dag.start_date, next_run_date\n                )\n\n            # don't ever schedule in the future or if next_run_date is None\n            if not next_run_date or next_run_date > timezone.utcnow():\n                return\n\n            # this structure is necessary to avoid a TypeError from concatenating\n            # NoneType\n            if dag.schedule_interval == '@once':\n                period_end = next_run_date\n            elif next_run_date:\n                period_end = dag.following_schedule(next_run_date)\n\n            # Don't schedule a dag beyond its end_date (as specified by the dag param)\n            if next_run_date and dag.end_date and next_run_date > dag.end_date:\n                return\n\n            # Don't schedule a dag beyond its end_date (as specified by the task params)\n            # Get the min task end date, which may come from the dag.default_args\n            min_task_end_date = []\n            task_end_dates = [t.end_date for t in dag.tasks if t.end_date]\n            if task_end_dates:\n                min_task_end_date = min(task_end_dates)\n            if next_run_date and min_task_end_date and next_run_date > min_task_end_date:\n                return\n\n            if next_run_date and period_end and period_end <= timezone.utcnow():\n                next_run = dag.create_dagrun(\n                    run_id=DagRun.ID_PREFIX + next_run_date.isoformat(),\n                    execution_date=next_run_date,\n                    start_date=timezone.utcnow(),\n                    state=State.RUNNING,\n                    external_trigger=False\n                )\n                return next_run", "response": "This method creates a new DagRun for a given DAG."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _change_state_for_tis_without_dagrun(self,\n                                             simple_dag_bag,\n                                             old_states,\n                                             new_state,\n                                             session=None):\n        \"\"\"\n        For all DAG IDs in the SimpleDagBag, look for task instances in the\n        old_states and set them to new_state if the corresponding DagRun\n        does not exist or exists but is not in the running state. This\n        normally should not happen, but it can if the state of DagRuns are\n        changed manually.\n\n        :param old_states: examine TaskInstances in this state\n        :type old_state: list[airflow.utils.state.State]\n        :param new_state: set TaskInstances to this state\n        :type new_state: airflow.utils.state.State\n        :param simple_dag_bag: TaskInstances associated with DAGs in the\n            simple_dag_bag and with states in the old_state will be examined\n        :type simple_dag_bag: airflow.utils.dag_processing.SimpleDagBag\n        \"\"\"\n        tis_changed = 0\n        query = session \\\n            .query(models.TaskInstance) \\\n            .outerjoin(models.DagRun, and_(\n                models.TaskInstance.dag_id == models.DagRun.dag_id,\n                models.TaskInstance.execution_date == models.DagRun.execution_date)) \\\n            .filter(models.TaskInstance.dag_id.in_(simple_dag_bag.dag_ids)) \\\n            .filter(models.TaskInstance.state.in_(old_states)) \\\n            .filter(or_(\n                models.DagRun.state != State.RUNNING,\n                models.DagRun.state.is_(None)))\n        if self.using_sqlite:\n            tis_to_change = query \\\n                .with_for_update() \\\n                .all()\n            for ti in tis_to_change:\n                ti.set_state(new_state, session=session)\n                tis_changed += 1\n        else:\n            subq = query.subquery()\n            tis_changed = session \\\n                .query(models.TaskInstance) \\\n                .filter(and_(\n                    models.TaskInstance.dag_id == subq.c.dag_id,\n                    models.TaskInstance.task_id == subq.c.task_id,\n                    models.TaskInstance.execution_date ==\n                    subq.c.execution_date)) \\\n                .update({models.TaskInstance.state: new_state},\n                        synchronize_session=False)\n            session.commit()\n\n        if tis_changed > 0:\n            self.log.warning(\n                \"Set %s task instances to state=%s as their associated DagRun was not in RUNNING state\",\n                tis_changed, new_state\n            )", "response": "Change the state of all TaskInstances in the SimpleDagBag with the given states."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __get_concurrency_maps(self, states, session=None):\n        TI = models.TaskInstance\n        ti_concurrency_query = (\n            session\n            .query(TI.task_id, TI.dag_id, func.count('*'))\n            .filter(TI.state.in_(states))\n            .group_by(TI.task_id, TI.dag_id)\n        ).all()\n        dag_map = defaultdict(int)\n        task_map = defaultdict(int)\n        for result in ti_concurrency_query:\n            task_id, dag_id, count = result\n            dag_map[dag_id] += count\n            task_map[(dag_id, task_id)] = count\n        return dag_map, task_map", "response": "Get the concurrency maps."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_executable_task_instances(self, simple_dag_bag, states, session=None):\n        executable_tis = []\n\n        # Get all task instances associated with scheduled\n        # DagRuns which are not backfilled, in the given states,\n        # and the dag is not paused\n        TI = models.TaskInstance\n        DR = models.DagRun\n        DM = models.DagModel\n        ti_query = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(simple_dag_bag.dag_ids))\n            .outerjoin(\n                DR,\n                and_(DR.dag_id == TI.dag_id, DR.execution_date == TI.execution_date)\n            )\n            .filter(or_(DR.run_id == None,  # noqa: E711\n                    not_(DR.run_id.like(BackfillJob.ID_PREFIX + '%'))))\n            .outerjoin(DM, DM.dag_id == TI.dag_id)\n            .filter(or_(DM.dag_id == None,  # noqa: E711\n                    not_(DM.is_paused)))\n        )\n\n        # Additional filters on task instance state\n        if None in states:\n            ti_query = ti_query.filter(\n                or_(TI.state == None, TI.state.in_(states))  # noqa: E711\n            )\n        else:\n            ti_query = ti_query.filter(TI.state.in_(states))\n\n        task_instances_to_examine = ti_query.all()\n\n        if len(task_instances_to_examine) == 0:\n            self.log.debug(\"No tasks to consider for execution.\")\n            return executable_tis\n\n        # Put one task instance on each line\n        task_instance_str = \"\\n\\t\".join(\n            [repr(x) for x in task_instances_to_examine])\n        self.log.info(\n            \"%s tasks up for execution:\\n\\t%s\", len(task_instances_to_examine),\n            task_instance_str\n        )\n\n        # Get the pool settings\n        pools = {p.pool: p for p in session.query(models.Pool).all()}\n\n        pool_to_task_instances = defaultdict(list)\n        for task_instance in task_instances_to_examine:\n            pool_to_task_instances[task_instance.pool].append(task_instance)\n\n        states_to_count_as_running = [State.RUNNING, State.QUEUED]\n        # dag_id to # of running tasks and (dag_id, task_id) to # of running tasks.\n        dag_concurrency_map, task_concurrency_map = self.__get_concurrency_maps(\n            states=states_to_count_as_running, session=session)\n\n        # Go through each pool, and queue up a task for execution if there are\n        # any open slots in the pool.\n        for pool, task_instances in pool_to_task_instances.items():\n            pool_name = pool\n            if not pool:\n                # Arbitrary:\n                # If queued outside of a pool, trigger no more than\n                # non_pooled_task_slot_count\n                open_slots = models.Pool.default_pool_open_slots()\n                pool_name = models.Pool.default_pool_name\n            else:\n                if pool not in pools:\n                    self.log.warning(\n                        \"Tasks using non-existent pool '%s' will not be scheduled\",\n                        pool\n                    )\n                    open_slots = 0\n                else:\n                    open_slots = pools[pool].open_slots(session=session)\n\n            num_ready = len(task_instances)\n            self.log.info(\n                \"Figuring out tasks to run in Pool(name=%s) with %s open slots \"\n                \"and %s task instances ready to be queued\",\n                pool, open_slots, num_ready\n            )\n\n            priority_sorted_task_instances = sorted(\n                task_instances, key=lambda ti: (-ti.priority_weight, ti.execution_date))\n\n            # Number of tasks that cannot be scheduled because of no open slot in pool\n            num_starving_tasks = 0\n            for current_index, task_instance in enumerate(priority_sorted_task_instances):\n                if open_slots <= 0:\n                    self.log.info(\n                        \"Not scheduling since there are %s open slots in pool %s\",\n                        open_slots, pool\n                    )\n                    # Can't schedule any more since there are no more open slots.\n                    num_starving_tasks = len(priority_sorted_task_instances) - current_index\n                    break\n\n                # Check to make sure that the task concurrency of the DAG hasn't been\n                # reached.\n                dag_id = task_instance.dag_id\n                simple_dag = simple_dag_bag.get_dag(dag_id)\n\n                current_dag_concurrency = dag_concurrency_map[dag_id]\n                dag_concurrency_limit = simple_dag_bag.get_dag(dag_id).concurrency\n                self.log.info(\n                    \"DAG %s has %s/%s running and queued tasks\",\n                    dag_id, current_dag_concurrency, dag_concurrency_limit\n                )\n                if current_dag_concurrency >= dag_concurrency_limit:\n                    self.log.info(\n                        \"Not executing %s since the number of tasks running or queued \"\n                        \"from DAG %s is >= to the DAG's task concurrency limit of %s\",\n                        task_instance, dag_id, dag_concurrency_limit\n                    )\n                    continue\n\n                task_concurrency_limit = simple_dag.get_task_special_arg(\n                    task_instance.task_id,\n                    'task_concurrency')\n                if task_concurrency_limit is not None:\n                    current_task_concurrency = task_concurrency_map[\n                        (task_instance.dag_id, task_instance.task_id)\n                    ]\n\n                    if current_task_concurrency >= task_concurrency_limit:\n                        self.log.info(\"Not executing %s since the task concurrency for\"\n                                      \" this task has been reached.\", task_instance)\n                        continue\n\n                if self.executor.has_task(task_instance):\n                    self.log.debug(\n                        \"Not handling task %s as the executor reports it is running\",\n                        task_instance.key\n                    )\n                    continue\n                executable_tis.append(task_instance)\n                open_slots -= 1\n                dag_concurrency_map[dag_id] += 1\n                task_concurrency_map[(task_instance.dag_id, task_instance.task_id)] += 1\n\n            Stats.gauge('pool.starving_tasks.{pool_name}'.format(pool_name=pool_name),\n                        num_starving_tasks)\n\n        task_instance_str = \"\\n\\t\".join(\n            [repr(x) for x in executable_tis])\n        self.log.info(\n            \"Setting the following tasks to queued state:\\n\\t%s\", task_instance_str)\n        # so these dont expire on commit\n        for ti in executable_tis:\n            copy_dag_id = ti.dag_id\n            copy_execution_date = ti.execution_date\n            copy_task_id = ti.task_id\n            make_transient(ti)\n            ti.dag_id = copy_dag_id\n            ti.execution_date = copy_execution_date\n            ti.task_id = copy_task_id\n        return executable_tis", "response": "Finds all the executable task instances in the given DAG bag and the given states."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the state of the tasks in the list with one of the given states to QUEUED atomically and returns the TIs changed in SimpleTaskInstance format.", "response": "def _change_state_for_executable_task_instances(self, task_instances,\n                                                    acceptable_states, session=None):\n        \"\"\"\n        Changes the state of task instances in the list with one of the given states\n        to QUEUED atomically, and returns the TIs changed in SimpleTaskInstance format.\n\n        :param task_instances: TaskInstances to change the state of\n        :type task_instances: list[airflow.models.TaskInstance]\n        :param acceptable_states: Filters the TaskInstances updated to be in these states\n        :type acceptable_states: Iterable[State]\n        :rtype: list[airflow.utils.dag_processing.SimpleTaskInstance]\n        \"\"\"\n        if len(task_instances) == 0:\n            session.commit()\n            return []\n\n        TI = models.TaskInstance\n        filter_for_ti_state_change = (\n            [and_(\n                TI.dag_id == ti.dag_id,\n                TI.task_id == ti.task_id,\n                TI.execution_date == ti.execution_date)\n                for ti in task_instances])\n        ti_query = (\n            session\n            .query(TI)\n            .filter(or_(*filter_for_ti_state_change)))\n\n        if None in acceptable_states:\n            ti_query = ti_query.filter(\n                or_(TI.state == None, TI.state.in_(acceptable_states))  # noqa: E711\n            )\n        else:\n            ti_query = ti_query.filter(TI.state.in_(acceptable_states))\n\n        tis_to_set_to_queued = (\n            ti_query\n            .with_for_update()\n            .all())\n        if len(tis_to_set_to_queued) == 0:\n            self.log.info(\"No tasks were able to have their state changed to queued.\")\n            session.commit()\n            return []\n\n        # set TIs to queued state\n        for task_instance in tis_to_set_to_queued:\n            task_instance.state = State.QUEUED\n            task_instance.queued_dttm = (timezone.utcnow()\n                                         if not task_instance.queued_dttm\n                                         else task_instance.queued_dttm)\n            session.merge(task_instance)\n\n        # Generate a list of SimpleTaskInstance for the use of queuing\n        # them in the executor.\n        simple_task_instances = [SimpleTaskInstance(ti) for ti in\n                                 tis_to_set_to_queued]\n\n        task_instance_str = \"\\n\\t\".join(\n            [repr(x) for x in tis_to_set_to_queued])\n\n        session.commit()\n        self.log.info(\"Setting the following %s tasks to queued state:\\n\\t%s\",\n                      len(tis_to_set_to_queued), task_instance_str)\n        return simple_task_instances"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking task_instances, which should have been set to queued, and enqueues them with the executor. :param simple_task_instances: TaskInstances to enqueue :type simple_task_instances: list[SimpleTaskInstance] :param simple_dag_bag: Should contains all of the task_instances' dags :type simple_dag_bag: airflow.utils.dag_processing.SimpleDagBag", "response": "def _enqueue_task_instances_with_queued_state(self, simple_dag_bag,\n                                                  simple_task_instances):\n        \"\"\"\n        Takes task_instances, which should have been set to queued, and enqueues them\n        with the executor.\n\n        :param simple_task_instances: TaskInstances to enqueue\n        :type simple_task_instances: list[SimpleTaskInstance]\n        :param simple_dag_bag: Should contains all of the task_instances' dags\n        :type simple_dag_bag: airflow.utils.dag_processing.SimpleDagBag\n        \"\"\"\n        TI = models.TaskInstance\n        # actually enqueue them\n        for simple_task_instance in simple_task_instances:\n            simple_dag = simple_dag_bag.get_dag(simple_task_instance.dag_id)\n            command = TI.generate_command(\n                simple_task_instance.dag_id,\n                simple_task_instance.task_id,\n                simple_task_instance.execution_date,\n                local=True,\n                mark_success=False,\n                ignore_all_deps=False,\n                ignore_depends_on_past=False,\n                ignore_task_deps=False,\n                ignore_ti_state=False,\n                pool=simple_task_instance.pool,\n                file_path=simple_dag.full_filepath,\n                pickle_id=simple_dag.pickle_id)\n\n            priority = simple_task_instance.priority_weight\n            queue = simple_task_instance.queue\n            self.log.info(\n                \"Sending %s to executor with priority %s and queue %s\",\n                simple_task_instance.key, priority, queue\n            )\n\n            self.executor.queue_command(\n                simple_task_instance,\n                command,\n                priority=priority,\n                queue=queue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the TaskInstances in the specified states.", "response": "def _execute_task_instances(self,\n                                simple_dag_bag,\n                                states,\n                                session=None):\n        \"\"\"\n        Attempts to execute TaskInstances that should be executed by the scheduler.\n\n        There are three steps:\n        1. Pick TIs by priority with the constraint that they are in the expected states\n        and that we do exceed max_active_runs or pool limits.\n        2. Change the state for the TIs above atomically.\n        3. Enqueue the TIs in the executor.\n\n        :param simple_dag_bag: TaskInstances associated with DAGs in the\n            simple_dag_bag will be fetched from the DB and executed\n        :type simple_dag_bag: airflow.utils.dag_processing.SimpleDagBag\n        :param states: Execute TaskInstances in these states\n        :type states: tuple[airflow.utils.state.State]\n        :return: Number of task instance with state changed.\n        \"\"\"\n        executable_tis = self._find_executable_task_instances(simple_dag_bag, states,\n                                                              session=session)\n\n        def query(result, items):\n            simple_tis_with_state_changed = \\\n                self._change_state_for_executable_task_instances(items,\n                                                                 states,\n                                                                 session=session)\n            self._enqueue_task_instances_with_queued_state(\n                simple_dag_bag,\n                simple_tis_with_state_changed)\n            session.commit()\n            return result + len(simple_tis_with_state_changed)\n\n        return helpers.reduce_in_chunks(query, executable_tis, 0, self.max_tis_per_query)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging the state of the tasks that failed to execute.", "response": "def _change_state_for_tasks_failed_to_execute(self, session):\n        \"\"\"\n        If there are tasks left over in the executor,\n        we set them back to SCHEDULED to avoid creating hanging tasks.\n\n        :param session: session for ORM operations\n        \"\"\"\n        if self.executor.queued_tasks:\n            TI = models.TaskInstance\n            filter_for_ti_state_change = (\n                [and_(\n                    TI.dag_id == dag_id,\n                    TI.task_id == task_id,\n                    TI.execution_date == execution_date,\n                    # The TI.try_number will return raw try_number+1 since the\n                    # ti is not running. And we need to -1 to match the DB record.\n                    TI._try_number == try_number - 1,\n                    TI.state == State.QUEUED)\n                    for dag_id, task_id, execution_date, try_number\n                    in self.executor.queued_tasks.keys()])\n            ti_query = (session.query(TI)\n                        .filter(or_(*filter_for_ti_state_change)))\n            tis_to_set_to_scheduled = (ti_query\n                                       .with_for_update()\n                                       .all())\n            if len(tis_to_set_to_scheduled) == 0:\n                session.commit()\n                return\n\n            # set TIs to queued state\n            for task_instance in tis_to_set_to_scheduled:\n                task_instance.state = State.SCHEDULED\n\n            task_instance_str = \"\\n\\t\".join(\n                [repr(x) for x in tis_to_set_to_scheduled])\n\n            session.commit()\n            self.log.info(\"Set the following tasks to scheduled state:\\n\\t%s\", task_instance_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_dags(self, dagbag, dags, tis_out):\n        for dag in dags:\n            dag = dagbag.get_dag(dag.dag_id)\n            if not dag:\n                self.log.error(\"DAG ID %s was not found in the DagBag\", dag.dag_id)\n                continue\n\n            if dag.is_paused:\n                self.log.info(\"Not processing DAG %s since it's paused\", dag.dag_id)\n                continue\n\n            self.log.info(\"Processing %s\", dag.dag_id)\n\n            dag_run = self.create_dag_run(dag)\n            if dag_run:\n                expected_start_date = dag.following_schedule(dag_run.execution_date)\n                if expected_start_date:\n                    schedule_delay = dag_run.start_date - expected_start_date\n                    Stats.timing(\n                        'dagrun.schedule_delay.{dag_id}'.format(dag_id=dag.dag_id),\n                        schedule_delay)\n                self.log.info(\"Created %s\", dag_run)\n            self._process_task_instances(dag, tis_out)\n            self.manage_slas(dag)", "response": "Processes the given DAGs and creates appropriate DagRuns and TaskInstances."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the executor events.", "response": "def _process_executor_events(self, simple_dag_bag, session=None):\n        \"\"\"\n        Respond to executor events.\n        \"\"\"\n        # TODO: this shares quite a lot of code with _manage_executor_state\n\n        TI = models.TaskInstance\n        for key, state in list(self.executor.get_event_buffer(simple_dag_bag.dag_ids)\n                                   .items()):\n            dag_id, task_id, execution_date, try_number = key\n            self.log.info(\n                \"Executor reports execution of %s.%s execution_date=%s \"\n                \"exited with status %s for try_number %s\",\n                dag_id, task_id, execution_date, state, try_number\n            )\n            if state == State.FAILED or state == State.SUCCESS:\n                qry = session.query(TI).filter(TI.dag_id == dag_id,\n                                               TI.task_id == task_id,\n                                               TI.execution_date == execution_date)\n                ti = qry.first()\n                if not ti:\n                    self.log.warning(\"TaskInstance %s went missing from the database\", ti)\n                    continue\n\n                # TODO: should we fail RUNNING as well, as we do in Backfills?\n                if ti.try_number == try_number and ti.state == State.QUEUED:\n                    msg = (\"Executor reports task instance {} finished ({}) \"\n                           \"although the task says its {}. Was the task \"\n                           \"killed externally?\".format(ti, state, ti.state))\n                    self.log.error(msg)\n                    try:\n                        simple_dag = simple_dag_bag.get_dag(dag_id)\n                        dagbag = models.DagBag(simple_dag.full_filepath)\n                        dag = dagbag.get_dag(dag_id)\n                        ti.task = dag.get_task(task_id)\n                        ti.handle_failure(msg)\n                    except Exception:\n                        self.log.error(\"Cannot load the dag bag to handle failure for %s\"\n                                       \". Setting task to FAILED without callbacks or \"\n                                       \"retries. Do you have enough resources?\", ti)\n                        ti.state = State.FAILED\n                        session.merge(ti)\n                        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _execute_helper(self):\n        self.executor.start()\n\n        self.log.info(\"Resetting orphaned tasks for active dag runs\")\n        self.reset_state_for_orphaned_tasks()\n\n        # Start after resetting orphaned tasks to avoid stressing out DB.\n        self.processor_agent.start()\n\n        execute_start_time = timezone.utcnow()\n\n        # Last time that self.heartbeat() was called.\n        last_self_heartbeat_time = timezone.utcnow()\n\n        # For the execute duration, parse and schedule DAGs\n        while True:\n            self.log.debug(\"Starting Loop...\")\n            loop_start_time = time.time()\n\n            if self.using_sqlite:\n                self.processor_agent.heartbeat()\n                # For the sqlite case w/ 1 thread, wait until the processor\n                # is finished to avoid concurrent access to the DB.\n                self.log.debug(\n                    \"Waiting for processors to finish since we're using sqlite\")\n                self.processor_agent.wait_until_finished()\n\n            self.log.debug(\"Harvesting DAG parsing results\")\n            simple_dags = self.processor_agent.harvest_simple_dags()\n            self.log.debug(\"Harvested {} SimpleDAGs\".format(len(simple_dags)))\n\n            # Send tasks for execution if available\n            simple_dag_bag = SimpleDagBag(simple_dags)\n            if len(simple_dags) > 0:\n                try:\n                    simple_dag_bag = SimpleDagBag(simple_dags)\n\n                    # Handle cases where a DAG run state is set (perhaps manually) to\n                    # a non-running state. Handle task instances that belong to\n                    # DAG runs in those states\n\n                    # If a task instance is up for retry but the corresponding DAG run\n                    # isn't running, mark the task instance as FAILED so we don't try\n                    # to re-run it.\n                    self._change_state_for_tis_without_dagrun(simple_dag_bag,\n                                                              [State.UP_FOR_RETRY],\n                                                              State.FAILED)\n                    # If a task instance is scheduled or queued or up for reschedule,\n                    # but the corresponding DAG run isn't running, set the state to\n                    # NONE so we don't try to re-run it.\n                    self._change_state_for_tis_without_dagrun(simple_dag_bag,\n                                                              [State.QUEUED,\n                                                               State.SCHEDULED,\n                                                               State.UP_FOR_RESCHEDULE],\n                                                              State.NONE)\n\n                    self._execute_task_instances(simple_dag_bag,\n                                                 (State.SCHEDULED,))\n                except Exception as e:\n                    self.log.error(\"Error queuing tasks\")\n                    self.log.exception(e)\n                    continue\n\n            # Call heartbeats\n            self.log.debug(\"Heartbeating the executor\")\n            self.executor.heartbeat()\n\n            self._change_state_for_tasks_failed_to_execute()\n\n            # Process events from the executor\n            self._process_executor_events(simple_dag_bag)\n\n            # Heartbeat the scheduler periodically\n            time_since_last_heartbeat = (timezone.utcnow() -\n                                         last_self_heartbeat_time).total_seconds()\n            if time_since_last_heartbeat > self.heartrate:\n                self.log.debug(\"Heartbeating the scheduler\")\n                self.heartbeat()\n                last_self_heartbeat_time = timezone.utcnow()\n\n            is_unit_test = conf.getboolean('core', 'unit_test_mode')\n            loop_end_time = time.time()\n            loop_duration = loop_end_time - loop_start_time\n            self.log.debug(\n                \"Ran scheduling loop in %.2f seconds\",\n                loop_duration)\n\n            if not is_unit_test:\n                self.log.debug(\"Sleeping for %.2f seconds\", self._processor_poll_interval)\n                time.sleep(self._processor_poll_interval)\n\n            # Exit early for a test mode, run one additional scheduler loop\n            # to reduce the possibility that parsed DAG was put into the queue\n            # by the DAG manager but not yet received by DAG agent.\n            if self.processor_agent.done:\n                self._last_loop = True\n\n            if self._last_loop:\n                self.log.info(\"Exiting scheduler loop as all files\"\n                              \" have been processed {} times\".format(self.num_runs))\n                break\n\n            if loop_duration < 1 and not is_unit_test:\n                sleep_length = 1 - loop_duration\n                self.log.debug(\n                    \"Sleeping for {0:.2f} seconds to prevent excessive logging\"\n                    .format(sleep_length))\n                sleep(sleep_length)\n\n        # Stop any processors\n        self.processor_agent.terminate()\n\n        # Verify that all files were processed, and if so, deactivate DAGs that\n        # haven't been touched by the scheduler as they likely have been\n        # deleted.\n        if self.processor_agent.all_files_processed:\n            self.log.info(\n                \"Deactivating DAGs that haven't been touched since %s\",\n                execute_start_time.isoformat()\n            )\n            models.DAG.deactivate_stale_dags(execute_start_time)\n\n        self.executor.end()\n\n        settings.Session.remove()", "response": "Execute the main loop of the scheduler."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a Python file containing Airflow DAGs and return a list of SimpleDags that represent the Dags.", "response": "def process_file(self, file_path, zombies, pickle_dags=False, session=None):\n        \"\"\"\n        Process a Python file containing Airflow DAGs.\n\n        This includes:\n\n        1. Execute the file and look for DAG objects in the namespace.\n        2. Pickle the DAG and save it to the DB (if necessary).\n        3. For each DAG, see what tasks should run and create appropriate task\n        instances in the DB.\n        4. Record any errors importing the file into ORM\n        5. Kill (in ORM) any task instances belonging to the DAGs that haven't\n        issued a heartbeat in a while.\n\n        Returns a list of SimpleDag objects that represent the DAGs found in\n        the file\n\n        :param file_path: the path to the Python file that should be executed\n        :type file_path: unicode\n        :param zombies: zombie task instances to kill.\n        :type zombies: list[airflow.utils.dag_processing.SimpleTaskInstance]\n        :param pickle_dags: whether serialize the DAGs found in the file and\n            save them to the db\n        :type pickle_dags: bool\n        :return: a list of SimpleDags made from the Dags found in the file\n        :rtype: list[airflow.utils.dag_processing.SimpleDagBag]\n        \"\"\"\n        self.log.info(\"Processing file %s for tasks to queue\", file_path)\n        # As DAGs are parsed from this file, they will be converted into SimpleDags\n        simple_dags = []\n\n        try:\n            dagbag = models.DagBag(file_path, include_examples=False)\n        except Exception:\n            self.log.exception(\"Failed at reloading the DAG file %s\", file_path)\n            Stats.incr('dag_file_refresh_error', 1, 1)\n            return []\n\n        if len(dagbag.dags) > 0:\n            self.log.info(\"DAG(s) %s retrieved from %s\", dagbag.dags.keys(), file_path)\n        else:\n            self.log.warning(\"No viable dags retrieved from %s\", file_path)\n            self.update_import_errors(session, dagbag)\n            return []\n\n        # Save individual DAGs in the ORM and update DagModel.last_scheduled_time\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n        paused_dag_ids = [dag.dag_id for dag in dagbag.dags.values()\n                          if dag.is_paused]\n\n        # Pickle the DAGs (if necessary) and put them into a SimpleDag\n        for dag_id in dagbag.dags:\n            # Only return DAGs that are not paused\n            if dag_id not in paused_dag_ids:\n                dag = dagbag.get_dag(dag_id)\n                pickle_id = None\n                if pickle_dags:\n                    pickle_id = dag.pickle(session).id\n                simple_dags.append(SimpleDag(dag, pickle_id=pickle_id))\n\n        if len(self.dag_ids) > 0:\n            dags = [dag for dag in dagbag.dags.values()\n                    if dag.dag_id in self.dag_ids and\n                    dag.dag_id not in paused_dag_ids]\n        else:\n            dags = [dag for dag in dagbag.dags.values()\n                    if not dag.parent_dag and\n                    dag.dag_id not in paused_dag_ids]\n\n        # Not using multiprocessing.Queue() since it's no longer a separate\n        # process and due to some unusual behavior. (empty() incorrectly\n        # returns true?)\n        ti_keys_to_schedule = []\n\n        self._process_dags(dagbag, dags, ti_keys_to_schedule)\n\n        for ti_key in ti_keys_to_schedule:\n            dag = dagbag.dags[ti_key[0]]\n            task = dag.get_task(ti_key[1])\n            ti = models.TaskInstance(task, ti_key[2])\n\n            ti.refresh_from_db(session=session, lock_for_update=True)\n            # We can defer checking the task dependency checks to the worker themselves\n            # since they can be expensive to run in the scheduler.\n            dep_context = DepContext(deps=QUEUE_DEPS, ignore_task_deps=True)\n\n            # Only schedule tasks that have their dependencies met, e.g. to avoid\n            # a task that recently got its state changed to RUNNING from somewhere\n            # other than the scheduler from getting its state overwritten.\n            # TODO(aoen): It's not great that we have to check all the task instance\n            # dependencies twice; once to get the task scheduled, and again to actually\n            # run the task. We should try to come up with a way to only check them once.\n            if ti.are_dependencies_met(\n                    dep_context=dep_context,\n                    session=session,\n                    verbose=True):\n                # Task starts out in the scheduled state. All tasks in the\n                # scheduled state will be sent to the executor\n                ti.state = State.SCHEDULED\n\n            # Also save this task instance to the DB.\n            self.log.info(\"Creating / updating %s in ORM\", ti)\n            session.merge(ti)\n        # commit batch\n        session.commit()\n\n        # Record import errors into the ORM\n        try:\n            self.update_import_errors(session, dagbag)\n        except Exception:\n            self.log.exception(\"Error logging import errors!\")\n        try:\n            dagbag.kill_zombies(zombies)\n        except Exception:\n            self.log.exception(\"Error killing zombies!\")\n\n        return simple_dags"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_counters(self, ti_status):\n        for key, ti in list(ti_status.running.items()):\n            ti.refresh_from_db()\n            if ti.state == State.SUCCESS:\n                ti_status.succeeded.add(key)\n                self.log.debug(\"Task instance %s succeeded. Don't rerun.\", ti)\n                ti_status.running.pop(key)\n                continue\n            elif ti.state == State.SKIPPED:\n                ti_status.skipped.add(key)\n                self.log.debug(\"Task instance %s skipped. Don't rerun.\", ti)\n                ti_status.running.pop(key)\n                continue\n            elif ti.state == State.FAILED:\n                self.log.error(\"Task instance %s failed\", ti)\n                ti_status.failed.add(key)\n                ti_status.running.pop(key)\n                continue\n            # special case: if the task needs to run again put it back\n            elif ti.state == State.UP_FOR_RETRY:\n                self.log.warning(\"Task instance %s is up for retry\", ti)\n                ti_status.running.pop(key)\n                ti_status.to_run[key] = ti\n            # special case: if the task needs to be rescheduled put it back\n            elif ti.state == State.UP_FOR_RESCHEDULE:\n                self.log.warning(\"Task instance %s is up for reschedule\", ti)\n                ti_status.running.pop(key)\n                ti_status.to_run[key] = ti\n            # special case: The state of the task can be set to NONE by the task itself\n            # when it reaches concurrency limits. It could also happen when the state\n            # is changed externally, e.g. by clearing tasks from the ui. We need to cover\n            # for that as otherwise those tasks would fall outside of the scope of\n            # the backfill suddenly.\n            elif ti.state == State.NONE:\n                self.log.warning(\n                    \"FIXME: task instance %s state was set to none externally or \"\n                    \"reaching concurrency limits. Re-adding task to queue.\",\n                    ti\n                )\n                ti.set_state(State.SCHEDULED)\n                ti_status.running.pop(key)\n                ti_status.to_run[key] = ti", "response": "Updates the counters for the tasks that were running."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the executor agrees with the state of task instances that are running", "response": "def _manage_executor_state(self, running):\n        \"\"\"\n        Checks if the executor agrees with the state of task instances\n        that are running\n\n        :param running: dict of key, task to verify\n        \"\"\"\n        executor = self.executor\n\n        for key, state in list(executor.get_event_buffer().items()):\n            if key not in running:\n                self.log.warning(\n                    \"%s state %s not in running=%s\",\n                    key, state, running.values()\n                )\n                continue\n\n            ti = running[key]\n            ti.refresh_from_db()\n\n            self.log.debug(\"Executor state: %s task %s\", state, ti)\n\n            if state == State.FAILED or state == State.SUCCESS:\n                if ti.state == State.RUNNING or ti.state == State.QUEUED:\n                    msg = (\"Executor reports task instance {} finished ({}) \"\n                           \"although the task says its {}. Was the task \"\n                           \"killed externally?\".format(ti, state, ti.state))\n                    self.log.error(msg)\n                    ti.handle_failure(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DagRun for the given run date or None if no dag run is available.", "response": "def _get_dag_run(self, run_date, session=None):\n        \"\"\"\n        Returns a dag run for the given run date, which will be matched to an existing\n        dag run if available or create a new dag run otherwise. If the max_active_runs\n        limit is reached, this function will return None.\n\n        :param run_date: the execution date for the dag run\n        :type run_date: datetime.datetime\n        :param session: the database session object\n        :type session: sqlalchemy.orm.session.Session\n        :return: a DagRun in state RUNNING or None\n        \"\"\"\n        run_id = BackfillJob.ID_FORMAT_PREFIX.format(run_date.isoformat())\n\n        # consider max_active_runs but ignore when running subdags\n        respect_dag_max_active_limit = (True\n                                        if (self.dag.schedule_interval and\n                                            not self.dag.is_subdag)\n                                        else False)\n\n        current_active_dag_count = self.dag.get_num_active_runs(external_trigger=False)\n\n        # check if we are scheduling on top of a already existing dag_run\n        # we could find a \"scheduled\" run instead of a \"backfill\"\n        run = DagRun.find(dag_id=self.dag.dag_id,\n                          execution_date=run_date,\n                          session=session)\n\n        if run is not None and len(run) > 0:\n            run = run[0]\n            if run.state == State.RUNNING:\n                respect_dag_max_active_limit = False\n        else:\n            run = None\n\n        # enforce max_active_runs limit for dag, special cases already\n        # handled by respect_dag_max_active_limit\n        if (respect_dag_max_active_limit and\n                current_active_dag_count >= self.dag.max_active_runs):\n            return None\n\n        run = run or self.dag.create_dagrun(\n            run_id=run_id,\n            execution_date=run_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING,\n            external_trigger=False,\n            session=session,\n            conf=self.conf,\n        )\n\n        # set required transient field\n        run.dag = self.dag\n\n        # explicitly mark as backfill and running\n        run.state = State.RUNNING\n        run.run_id = run_id\n        run.verify_integrity(session=session)\n        return run"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a map of task instance key to task instance object for the tasks to run in the given dag run.", "response": "def _task_instances_for_dag_run(self, dag_run, session=None):\n        \"\"\"\n        Returns a map of task instance key to task instance object for the tasks to\n        run in the given dag run.\n\n        :param dag_run: the dag run to get the tasks from\n        :type dag_run: airflow.models.DagRun\n        :param session: the database session object\n        :type session: sqlalchemy.orm.session.Session\n        \"\"\"\n        tasks_to_run = {}\n\n        if dag_run is None:\n            return tasks_to_run\n\n        # check if we have orphaned tasks\n        self.reset_state_for_orphaned_tasks(filter_by_dag_run=dag_run, session=session)\n\n        # for some reason if we don't refresh the reference to run is lost\n        dag_run.refresh_from_db()\n        make_transient(dag_run)\n\n        # TODO(edgarRd): AIRFLOW-1464 change to batch query to improve perf\n        for ti in dag_run.get_task_instances():\n            # all tasks part of the backfill are scheduled to run\n            if ti.state == State.NONE:\n                ti.set_state(State.SCHEDULED, session=session)\n            if ti.state != State.REMOVED:\n                tasks_to_run[ti.key] = ti\n\n        return tasks_to_run"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_backfill_task_instances(self,\n                                         ti_status,\n                                         executor,\n                                         pickle_id,\n                                         start_date=None, session=None):\n        \"\"\"\n        Process a set of task instances from a set of dag runs. Special handling is done\n        to account for different task instance states that could be present when running\n        them in a backfill process.\n\n        :param ti_status: the internal status of the job\n        :type ti_status: BackfillJob._DagRunTaskStatus\n        :param executor: the executor to run the task instances\n        :type executor: BaseExecutor\n        :param pickle_id: the pickle_id if dag is pickled, None otherwise\n        :type pickle_id: int\n        :param start_date: the start date of the backfill job\n        :type start_date: datetime.datetime\n        :param session: the current session object\n        :type session: sqlalchemy.orm.session.Session\n        :return: the list of execution_dates for the finished dag runs\n        :rtype: list\n        \"\"\"\n\n        executed_run_dates = []\n\n        while ((len(ti_status.to_run) > 0 or len(ti_status.running) > 0) and\n                len(ti_status.deadlocked) == 0):\n            self.log.debug(\"*** Clearing out not_ready list ***\")\n            ti_status.not_ready.clear()\n\n            # we need to execute the tasks bottom to top\n            # or leaf to root, as otherwise tasks might be\n            # determined deadlocked while they are actually\n            # waiting for their upstream to finish\n            @provide_session\n            def _per_task_process(task, key, ti, session=None):\n                ti.refresh_from_db()\n\n                task = self.dag.get_task(ti.task_id)\n                ti.task = task\n\n                ignore_depends_on_past = (\n                    self.ignore_first_depends_on_past and\n                    ti.execution_date == (start_date or ti.start_date))\n                self.log.debug(\n                    \"Task instance to run %s state %s\", ti, ti.state)\n\n                # The task was already marked successful or skipped by a\n                # different Job. Don't rerun it.\n                if ti.state == State.SUCCESS:\n                    ti_status.succeeded.add(key)\n                    self.log.debug(\"Task instance %s succeeded. Don't rerun.\", ti)\n                    ti_status.to_run.pop(key)\n                    if key in ti_status.running:\n                        ti_status.running.pop(key)\n                    return\n                elif ti.state == State.SKIPPED:\n                    ti_status.skipped.add(key)\n                    self.log.debug(\"Task instance %s skipped. Don't rerun.\", ti)\n                    ti_status.to_run.pop(key)\n                    if key in ti_status.running:\n                        ti_status.running.pop(key)\n                    return\n\n                # guard against externally modified tasks instances or\n                # in case max concurrency has been reached at task runtime\n                elif ti.state == State.NONE:\n                    self.log.warning(\n                        \"FIXME: task instance {} state was set to None \"\n                        \"externally. This should not happen\"\n                    )\n                    ti.set_state(State.SCHEDULED, session=session)\n                if self.rerun_failed_tasks:\n                    # Rerun failed tasks or upstreamed failed tasks\n                    if ti.state in (State.FAILED, State.UPSTREAM_FAILED):\n                        self.log.error(\"Task instance {ti} \"\n                                       \"with state {state}\".format(ti=ti,\n                                                                   state=ti.state))\n                        if key in ti_status.running:\n                            ti_status.running.pop(key)\n                        # Reset the failed task in backfill to scheduled state\n                        ti.set_state(State.SCHEDULED, session=session)\n                else:\n                    # Default behaviour which works for subdag.\n                    if ti.state in (State.FAILED, State.UPSTREAM_FAILED):\n                        self.log.error(\"Task instance {ti} \"\n                                       \"with {state} state\".format(ti=ti,\n                                                                   state=ti.state))\n                        ti_status.failed.add(key)\n                        ti_status.to_run.pop(key)\n                        if key in ti_status.running:\n                            ti_status.running.pop(key)\n                        return\n\n                backfill_context = DepContext(\n                    deps=RUN_DEPS,\n                    ignore_depends_on_past=ignore_depends_on_past,\n                    ignore_task_deps=self.ignore_task_deps,\n                    flag_upstream_failed=True)\n\n                # Is the task runnable? -- then run it\n                # the dependency checker can change states of tis\n                if ti.are_dependencies_met(\n                        dep_context=backfill_context,\n                        session=session,\n                        verbose=self.verbose):\n                    ti.refresh_from_db(lock_for_update=True, session=session)\n                    if ti.state in (State.SCHEDULED, State.UP_FOR_RETRY, State.UP_FOR_RESCHEDULE):\n                        if executor.has_task(ti):\n                            self.log.debug(\n                                \"Task Instance %s already in executor \"\n                                \"waiting for queue to clear\",\n                                ti\n                            )\n                        else:\n                            self.log.debug('Sending %s to executor', ti)\n                            # Skip scheduled state, we are executing immediately\n                            ti.state = State.QUEUED\n                            ti.queued_dttm = timezone.utcnow() if not ti.queued_dttm else ti.queued_dttm\n                            session.merge(ti)\n\n                            cfg_path = None\n                            if executor.__class__ in (executors.LocalExecutor,\n                                                      executors.SequentialExecutor):\n                                cfg_path = tmp_configuration_copy()\n\n                            executor.queue_task_instance(\n                                ti,\n                                mark_success=self.mark_success,\n                                pickle_id=pickle_id,\n                                ignore_task_deps=self.ignore_task_deps,\n                                ignore_depends_on_past=ignore_depends_on_past,\n                                pool=self.pool,\n                                cfg_path=cfg_path)\n                            ti_status.running[key] = ti\n                            ti_status.to_run.pop(key)\n                    session.commit()\n                    return\n\n                if ti.state == State.UPSTREAM_FAILED:\n                    self.log.error(\"Task instance %s upstream failed\", ti)\n                    ti_status.failed.add(key)\n                    ti_status.to_run.pop(key)\n                    if key in ti_status.running:\n                        ti_status.running.pop(key)\n                    return\n\n                # special case\n                if ti.state == State.UP_FOR_RETRY:\n                    self.log.debug(\n                        \"Task instance %s retry period not \"\n                        \"expired yet\", ti)\n                    if key in ti_status.running:\n                        ti_status.running.pop(key)\n                    ti_status.to_run[key] = ti\n                    return\n\n                # special case\n                if ti.state == State.UP_FOR_RESCHEDULE:\n                    self.log.debug(\n                        \"Task instance %s reschedule period not \"\n                        \"expired yet\", ti)\n                    if key in ti_status.running:\n                        ti_status.running.pop(key)\n                    ti_status.to_run[key] = ti\n                    return\n\n                # all remaining tasks\n                self.log.debug('Adding %s to not_ready', ti)\n                ti_status.not_ready.add(key)\n\n            non_pool_slots = conf.getint('core', 'non_pooled_backfill_task_slot_count')\n\n            try:\n                for task in self.dag.topological_sort():\n                    for key, ti in list(ti_status.to_run.items()):\n                        if task.task_id != ti.task_id:\n                            continue\n                        if task.pool:\n                            pool = session.query(models.Pool) \\\n                                .filter(models.Pool.pool == task.pool) \\\n                                .first()\n                            if not pool:\n                                raise PoolNotFound('Unknown pool: {}'.format(task.pool))\n\n                            open_slots = pool.open_slots(session=session)\n                            if open_slots <= 0:\n                                raise NoAvailablePoolSlot(\n                                    \"Not scheduling since there are \"\n                                    \"%s open slots in pool %s\".format(\n                                        open_slots, task.pool))\n                        else:\n                            if non_pool_slots <= 0:\n                                raise NoAvailablePoolSlot(\n                                    \"Not scheduling since there are no \"\n                                    \"non_pooled_backfill_task_slot_count.\")\n                            non_pool_slots -= 1\n\n                        num_running_tasks = DAG.get_num_task_instances(\n                            self.dag_id,\n                            states=(State.QUEUED, State.RUNNING))\n\n                        if num_running_tasks >= self.dag.concurrency:\n                            raise DagConcurrencyLimitReached(\n                                \"Not scheduling since concurrency limit \"\n                                \"is reached.\"\n                            )\n\n                        _per_task_process(task, key, ti)\n            except (NoAvailablePoolSlot, DagConcurrencyLimitReached) as e:\n                self.log.debug(e)\n\n            # execute the tasks in the queue\n            self.heartbeat()\n            executor.heartbeat()\n\n            # If the set of tasks that aren't ready ever equals the set of\n            # tasks to run and there are no running tasks then the backfill\n            # is deadlocked\n            if (ti_status.not_ready and\n                    ti_status.not_ready == set(ti_status.to_run) and\n                    len(ti_status.running) == 0):\n                self.log.warning(\n                    \"Deadlock discovered for ti_status.to_run=%s\",\n                    ti_status.to_run.values()\n                )\n                ti_status.deadlocked.update(ti_status.to_run.values())\n                ti_status.to_run.clear()\n\n            # check executor state\n            self._manage_executor_state(ti_status.running)\n\n            # update the task counters\n            self._update_counters(ti_status=ti_status)\n\n            # update dag run state\n            _dag_runs = ti_status.active_runs[:]\n            for run in _dag_runs:\n                run.update_state(session=session)\n                if run.state in State.finished():\n                    ti_status.finished_runs += 1\n                    ti_status.active_runs.remove(run)\n                    executed_run_dates.append(run.execution_date)\n\n            self._log_progress(ti_status)\n\n        # return updated status\n        return executed_run_dates", "response": "Process a set of task instances from a set of dag runs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _execute_for_run_dates(self, run_dates, ti_status, executor, pickle_id,\n                               start_date, session=None):\n        \"\"\"\n        Computes the dag runs and their respective task instances for\n        the given run dates and executes the task instances.\n        Returns a list of execution dates of the dag runs that were executed.\n\n        :param run_dates: Execution dates for dag runs\n        :type run_dates: list\n        :param ti_status: internal BackfillJob status structure to tis track progress\n        :type ti_status: BackfillJob._DagRunTaskStatus\n        :param executor: the executor to use, it must be previously started\n        :type executor: BaseExecutor\n        :param pickle_id: numeric id of the pickled dag, None if not pickled\n        :type pickle_id: int\n        :param start_date: backfill start date\n        :type start_date: datetime.datetime\n        :param session: the current session object\n        :type session: sqlalchemy.orm.session.Session\n        \"\"\"\n        for next_run_date in run_dates:\n            dag_run = self._get_dag_run(next_run_date, session=session)\n            tis_map = self._task_instances_for_dag_run(dag_run,\n                                                       session=session)\n            if dag_run is None:\n                continue\n\n            ti_status.active_runs.append(dag_run)\n            ti_status.to_run.update(tis_map or {})\n\n        processed_dag_run_dates = self._process_backfill_task_instances(\n            ti_status=ti_status,\n            executor=executor,\n            pickle_id=pickle_id,\n            start_date=start_date,\n            session=session)\n\n        ti_status.executed_dag_run_dates.update(processed_dag_run_dates)", "response": "Executes the tasks for the given run dates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state of all DAG runs that are not finished to failed.", "response": "def _set_unfinished_dag_runs_to_failed(self, dag_runs, session=None):\n        \"\"\"\n        Go through the dag_runs and update the state based on the task_instance state.\n        Then set DAG runs that are not finished to failed.\n\n        :param dag_runs: DAG runs\n        :param session: session\n        :return: None\n        \"\"\"\n        for dag_run in dag_runs:\n            dag_run.update_state()\n            if dag_run.state not in State.finished():\n                dag_run.set_state(State.FAILED)\n            session.merge(dag_run)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _execute(self, session=None):\n        ti_status = BackfillJob._DagRunTaskStatus()\n\n        start_date = self.bf_start_date\n\n        # Get intervals between the start/end dates, which will turn into dag runs\n        run_dates = self.dag.get_run_dates(start_date=start_date,\n                                           end_date=self.bf_end_date)\n        if self.run_backwards:\n            tasks_that_depend_on_past = [t.task_id for t in self.dag.task_dict.values() if t.depends_on_past]\n            if tasks_that_depend_on_past:\n                raise AirflowException(\n                    'You cannot backfill backwards because one or more tasks depend_on_past: {}'.format(\n                        \",\".join(tasks_that_depend_on_past)))\n            run_dates = run_dates[::-1]\n\n        if len(run_dates) == 0:\n            self.log.info(\"No run dates were found for the given dates and dag interval.\")\n            return\n\n        # picklin'\n        pickle_id = None\n        if not self.donot_pickle and self.executor.__class__ not in (\n                executors.LocalExecutor, executors.SequentialExecutor):\n            pickle = DagPickle(self.dag)\n            session.add(pickle)\n            session.commit()\n            pickle_id = pickle.id\n\n        executor = self.executor\n        executor.start()\n\n        ti_status.total_runs = len(run_dates)  # total dag runs in backfill\n\n        try:\n            remaining_dates = ti_status.total_runs\n            while remaining_dates > 0:\n                dates_to_process = [run_date for run_date in run_dates\n                                    if run_date not in ti_status.executed_dag_run_dates]\n\n                self._execute_for_run_dates(run_dates=dates_to_process,\n                                            ti_status=ti_status,\n                                            executor=executor,\n                                            pickle_id=pickle_id,\n                                            start_date=start_date,\n                                            session=session)\n\n                remaining_dates = (\n                    ti_status.total_runs - len(ti_status.executed_dag_run_dates)\n                )\n                err = self._collect_errors(ti_status=ti_status, session=session)\n                if err:\n                    raise AirflowException(err)\n\n                if remaining_dates > 0:\n                    self.log.info(\n                        \"max_active_runs limit for dag %s has been reached \"\n                        \" - waiting for other dag runs to finish\",\n                        self.dag_id\n                    )\n                    time.sleep(self.delay_on_limit_secs)\n        except (KeyboardInterrupt, SystemExit):\n            self.log.warning(\"Backfill terminated by user.\")\n\n            # TODO: we will need to terminate running task instances and set the\n            # state to failed.\n            self._set_unfinished_dag_runs_to_failed(ti_status.active_runs)\n        finally:\n            session.commit()\n            executor.end()\n\n        self.log.info(\"Backfill done. Exiting.\")", "response": "Executes the tasks in the current thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nself destruct task if state has been moved away from running externally", "response": "def heartbeat_callback(self, session=None):\n        \"\"\"Self destruct task if state has been moved away from running externally\"\"\"\n\n        if self.terminating:\n            # ensure termination if processes are created later\n            self.task_runner.terminate()\n            return\n\n        self.task_instance.refresh_from_db()\n        ti = self.task_instance\n\n        fqdn = get_hostname()\n        same_hostname = fqdn == ti.hostname\n        same_process = ti.pid == os.getpid()\n\n        if ti.state == State.RUNNING:\n            if not same_hostname:\n                self.log.warning(\"The recorded hostname %s \"\n                                 \"does not match this instance's hostname \"\n                                 \"%s\", ti.hostname, fqdn)\n                raise AirflowException(\"Hostname of job runner does not match\")\n            elif not same_process:\n                current_pid = os.getpid()\n                self.log.warning(\"Recorded pid %s does not match \"\n                                 \"the current pid %s\", ti.pid, current_pid)\n                raise AirflowException(\"PID of job runner does not match\")\n        elif (\n                self.task_runner.return_code() is None and\n                hasattr(self.task_runner, 'process')\n        ):\n            self.log.warning(\n                \"State of this instance has been externally set to %s. \"\n                \"Taking the poison pill.\",\n                ti.state\n            )\n            self.task_runner.terminate()\n            self.terminating = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_client(self, project_id):\n        if not self._client:\n            self._client = Client(project=project_id, credentials=self._get_credentials())\n        return self._client", "response": "Provides a client for interacting with the Cloud Spanner API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget information about a particular instance.", "response": "def get_instance(self, instance_id, project_id=None):\n        \"\"\"\n        Gets information about a particular instance.\n\n        :param project_id: Optional, The ID of the  GCP project that owns the Cloud Spanner\n            database.  If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :return: google.cloud.spanner_v1.instance.Instance\n        :rtype: object\n        \"\"\"\n        instance = self._get_client(project_id=project_id).instance(instance_id=instance_id)\n        if not instance.exists():\n            return None\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _apply_to_instance(self, project_id, instance_id, configuration_name, node_count,\n                           display_name, func):\n        \"\"\"\n        Invokes a method on a given instance by applying a specified Callable.\n\n        :param project_id: The ID of the  GCP project that owns the Cloud Spanner\n            database.\n        :type project_id: str\n        :param instance_id: The ID of the instance.\n        :type instance_id: str\n        :param configuration_name: Name of the instance configuration defining how the\n            instance will be created. Required for instances which do not yet exist.\n        :type configuration_name: str\n        :param node_count: (Optional) Number of nodes allocated to the instance.\n        :type node_count: int\n        :param display_name: (Optional) The display name for the instance in the Cloud\n            Console UI. (Must be between 4 and 30 characters.) If this value is not set\n            in the constructor, will fall back to the instance ID.\n        :type display_name: str\n        :param func: Method of the instance to be called.\n        :type func: Callable\n        \"\"\"\n        # noinspection PyUnresolvedReferences\n        instance = self._get_client(project_id=project_id).instance(\n            instance_id=instance_id, configuration_name=configuration_name,\n            node_count=node_count, display_name=display_name)\n        try:\n            operation = func(instance)  # type: Operation\n        except GoogleAPICallError as e:\n            self.log.error('An error occurred: %s. Exiting.', e.message)\n            raise e\n\n        if operation:\n            result = operation.result()\n            self.log.info(result)", "response": "Applies a method to the Cloud Spanner instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new Cloud Spanner instance.", "response": "def create_instance(self, instance_id, configuration_name, node_count,\n                        display_name, project_id=None):\n        \"\"\"\n        Creates a new Cloud Spanner instance.\n\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param configuration_name: The name of the instance configuration defining how the\n            instance will be created. Possible configuration values can be retrieved via\n            https://cloud.google.com/spanner/docs/reference/rest/v1/projects.instanceConfigs/list\n        :type configuration_name: str\n        :param node_count: (Optional) The number of nodes allocated to the Cloud Spanner\n            instance.\n        :type node_count: int\n        :param display_name: (Optional) The display name for the instance in the GCP\n            Console. Must be between 4 and 30 characters.  If this value is not set in\n            the constructor, the name falls back to the instance ID.\n        :type display_name: str\n        :param project_id: Optional, the ID of the  GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        self._apply_to_instance(project_id, instance_id, configuration_name,\n                                node_count, display_name, lambda x: x.create())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_instance(self, instance_id, configuration_name, node_count,\n                        display_name, project_id=None):\n        \"\"\"\n        Updates an existing Cloud Spanner instance.\n\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param configuration_name: The name of the instance configuration defining how the\n            instance will be created. Possible configuration values can be retrieved via\n            https://cloud.google.com/spanner/docs/reference/rest/v1/projects.instanceConfigs/list\n        :type configuration_name: str\n        :param node_count: (Optional) The number of nodes allocated to the Cloud Spanner\n            instance.\n        :type node_count: int\n        :param display_name: (Optional) The display name for the instance in the GCP\n            Console. Must be between 4 and 30 characters. If this value is not set in\n            the constructor, the name falls back to the instance ID.\n        :type display_name: str\n        :param project_id: Optional, the ID of the  GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        return self._apply_to_instance(project_id, instance_id, configuration_name,\n                                       node_count, display_name, lambda x: x.update())", "response": "Updates an existing Cloud Spanner instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete an existing Cloud Spanner instance.", "response": "def delete_instance(self, instance_id, project_id=None):\n        \"\"\"\n        Deletes an existing Cloud Spanner instance.\n\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param project_id: Optional, the ID of the GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n\n        instance = self._get_client(project_id=project_id).instance(instance_id)\n        try:\n            instance.delete()\n            return\n        except GoogleAPICallError as e:\n            self.log.error('An error occurred: %s. Exiting.', e.message)\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a database in Cloud Spanner.", "response": "def get_database(self, instance_id, database_id, project_id=None):\n        \"\"\"\n        Retrieves a database in Cloud Spanner. If the database does not exist\n        in the specified instance, it returns None.\n\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param database_id: The ID of the database in Cloud Spanner.\n        :type database_id: str\n        :param project_id: Optional, the ID of the  GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: Database object or None if database does not exist\n        :rtype: google.cloud.spanner_v1.database.Database or None\n        \"\"\"\n\n        instance = self._get_client(project_id=project_id).instance(\n            instance_id=instance_id)\n        if not instance.exists():\n            raise AirflowException(\"The instance {} does not exist in project {} !\".\n                                   format(instance_id, project_id))\n        database = instance.database(database_id=database_id)\n        if not database.exists():\n            return None\n        else:\n            return database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new database in Cloud Spanner.", "response": "def create_database(self, instance_id, database_id, ddl_statements, project_id=None):\n        \"\"\"\n        Creates a new database in Cloud Spanner.\n\n        :type project_id: str\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param database_id: The ID of the database to create in Cloud Spanner.\n        :type database_id: str\n        :param ddl_statements: The string list containing DDL for the new database.\n        :type ddl_statements: list[str]\n        :param project_id: Optional, the ID of the  GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :return: None\n        \"\"\"\n\n        instance = self._get_client(project_id=project_id).instance(\n            instance_id=instance_id)\n        if not instance.exists():\n            raise AirflowException(\"The instance {} does not exist in project {} !\".\n                                   format(instance_id, project_id))\n        database = instance.database(database_id=database_id,\n                                     ddl_statements=ddl_statements)\n        try:\n            operation = database.create()  # type: Operation\n        except GoogleAPICallError as e:\n            self.log.error('An error occurred: %s. Exiting.', e.message)\n            raise e\n\n        if operation:\n            result = operation.result()\n            self.log.info(result)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_database(self, instance_id, database_id, ddl_statements,\n                        project_id=None,\n                        operation_id=None):\n        \"\"\"\n        Updates DDL of a database in Cloud Spanner.\n\n        :type project_id: str\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param database_id: The ID of the database in Cloud Spanner.\n        :type database_id: str\n        :param ddl_statements: The string list containing DDL for the new database.\n        :type ddl_statements: list[str]\n        :param project_id: Optional, the ID of the GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :param operation_id: (Optional) The unique per database operation ID that can be\n            specified to implement idempotency check.\n        :type operation_id: str\n        :return: None\n        \"\"\"\n\n        instance = self._get_client(project_id=project_id).instance(\n            instance_id=instance_id)\n        if not instance.exists():\n            raise AirflowException(\"The instance {} does not exist in project {} !\".\n                                   format(instance_id, project_id))\n        database = instance.database(database_id=database_id)\n        try:\n            operation = database.update_ddl(\n                ddl_statements=ddl_statements, operation_id=operation_id)\n            if operation:\n                result = operation.result()\n                self.log.info(result)\n            return\n        except AlreadyExists as e:\n            if e.code == 409 and operation_id in e.message:\n                self.log.info(\"Replayed update_ddl message - the operation id %s \"\n                              \"was already done before.\", operation_id)\n                return\n        except GoogleAPICallError as e:\n            self.log.error('An error occurred: %s. Exiting.', e.message)\n            raise e", "response": "Updates DDL of a database in Cloud Spanner."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a database in Cloud Spanner.", "response": "def delete_database(self, instance_id, database_id, project_id=None):\n        \"\"\"\n        Drops a database in Cloud Spanner.\n\n        :type project_id: str\n        :param instance_id: The ID of the Cloud Spanner instance.\n        :type instance_id: str\n        :param database_id: The ID of the database in Cloud Spanner.\n        :type database_id: str\n        :param project_id: Optional, the ID of the  GCP project that owns the Cloud Spanner\n            database. If set to None or missing, the default project_id from the GCP connection is used.\n        :return: True if everything succeeded\n        :rtype: bool\n        \"\"\"\n\n        instance = self._get_client(project_id=project_id).\\\n            instance(instance_id=instance_id)\n        if not instance.exists():\n            raise AirflowException(\"The instance {} does not exist in project {} !\".\n                                   format(instance_id, project_id))\n        database = instance.database(database_id=database_id)\n        if not database.exists():\n            self.log.info(\"The database {} is already deleted from instance {}. \"\n                          \"Exiting.\".format(database_id, instance_id))\n            return\n        try:\n            operation = database.drop()  # type: Operation\n        except GoogleAPICallError as e:\n            self.log.error('An error occurred: %s. Exiting.', e.message)\n            raise e\n\n        if operation:\n            result = operation.result()\n            self.log.info(result)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_dml(self, instance_id, database_id, queries, project_id=None):\n        self._get_client(project_id=project_id).instance(instance_id=instance_id).\\\n            database(database_id=database_id).run_in_transaction(\n            lambda transaction: self._execute_sql_in_transaction(transaction, queries))", "response": "Executes an arbitrary DML query on the Cloud Spanner instance and database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef poke(self, context):\n        self.log.info('Poking for %s', self.attachment_name)\n\n        with ImapHook(imap_conn_id=self.conn_id) as imap_hook:\n            return imap_hook.has_mail_attachment(\n                name=self.attachment_name,\n                mail_folder=self.mail_folder,\n                check_regex=self.check_regex\n            )", "response": "Checks if a mail attachment with the given name is present on the mail server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_additional_parameters(additional_properties, language_hints, web_detection_params):\n    if language_hints is None and web_detection_params is None:\n        return additional_properties\n\n    if additional_properties is None:\n        return {}\n\n    merged_additional_parameters = deepcopy(additional_properties)\n\n    if 'image_context' not in merged_additional_parameters:\n        merged_additional_parameters['image_context'] = {}\n\n    merged_additional_parameters['image_context']['language_hints'] = merged_additional_parameters[\n        'image_context'\n    ].get('language_hints', language_hints)\n    merged_additional_parameters['image_context']['web_detection_params'] = merged_additional_parameters[\n        'image_context'\n    ].get('web_detection_params', web_detection_params)\n\n    return merged_additional_parameters", "response": "Prepares additional_properties parameter based on language_hints web_detection_params and additional_properties parameters specified by the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a cassandra Session object", "response": "def get_conn(self):\n        \"\"\"\n        Returns a cassandra Session object\n        \"\"\"\n        if self.session and not self.session.is_shutdown:\n            return self.session\n        self.session = self.cluster.connect(self.keyspace)\n        return self.session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef table_exists(self, table):\n        keyspace = self.keyspace\n        if '.' in table:\n            keyspace, table = table.split('.', 1)\n        cluster_metadata = self.get_conn().cluster.metadata\n        return (keyspace in cluster_metadata.keyspaces and\n                table in cluster_metadata.keyspaces[keyspace].tables)", "response": "Checks if a table exists in Cassandra"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a record exists in Cassandra", "response": "def record_exists(self, table, keys):\n        \"\"\"\n        Checks if a record exists in Cassandra\n\n        :param table: Target Cassandra table.\n                      Use dot notation to target a specific keyspace.\n        :type table: str\n        :param keys: The keys and their values to check the existence.\n        :type keys: dict\n        \"\"\"\n        keyspace = self.keyspace\n        if '.' in table:\n            keyspace, table = table.split('.', 1)\n        ks = \" AND \".join(\"{}=%({})s\".format(key, key) for key in keys.keys())\n        cql = \"SELECT * FROM {keyspace}.{table} WHERE {keys}\".format(\n            keyspace=keyspace, table=table, keys=ks)\n\n        try:\n            rs = self.get_conn().execute(cql, keys)\n            return rs.one() is not None\n        except Exception:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_spark_submit_command(self, application):\n        connection_cmd = self._get_spark_binary_path()\n\n        # The url ot the spark master\n        connection_cmd += [\"--master\", self._connection['master']]\n\n        if self._conf:\n            for key in self._conf:\n                connection_cmd += [\"--conf\", \"{}={}\".format(key, str(self._conf[key]))]\n        if self._env_vars and (self._is_kubernetes or self._is_yarn):\n            if self._is_yarn:\n                tmpl = \"spark.yarn.appMasterEnv.{}={}\"\n            else:\n                tmpl = \"spark.kubernetes.driverEnv.{}={}\"\n            for key in self._env_vars:\n                connection_cmd += [\n                    \"--conf\",\n                    tmpl.format(key, str(self._env_vars[key]))]\n        elif self._env_vars and self._connection['deploy_mode'] != \"cluster\":\n            self._env = self._env_vars  # Do it on Popen of the process\n        elif self._env_vars and self._connection['deploy_mode'] == \"cluster\":\n            raise AirflowException(\n                \"SparkSubmitHook env_vars is not supported in standalone-cluster mode.\")\n        if self._is_kubernetes:\n            connection_cmd += [\"--conf\", \"spark.kubernetes.namespace={}\".format(\n                self._connection['namespace'])]\n        if self._files:\n            connection_cmd += [\"--files\", self._files]\n        if self._py_files:\n            connection_cmd += [\"--py-files\", self._py_files]\n        if self._archives:\n            connection_cmd += [\"--archives\", self._archives]\n        if self._driver_class_path:\n            connection_cmd += [\"--driver-class-path\", self._driver_class_path]\n        if self._jars:\n            connection_cmd += [\"--jars\", self._jars]\n        if self._packages:\n            connection_cmd += [\"--packages\", self._packages]\n        if self._exclude_packages:\n            connection_cmd += [\"--exclude-packages\", self._exclude_packages]\n        if self._repositories:\n            connection_cmd += [\"--repositories\", self._repositories]\n        if self._num_executors:\n            connection_cmd += [\"--num-executors\", str(self._num_executors)]\n        if self._total_executor_cores:\n            connection_cmd += [\"--total-executor-cores\", str(self._total_executor_cores)]\n        if self._executor_cores:\n            connection_cmd += [\"--executor-cores\", str(self._executor_cores)]\n        if self._executor_memory:\n            connection_cmd += [\"--executor-memory\", self._executor_memory]\n        if self._driver_memory:\n            connection_cmd += [\"--driver-memory\", self._driver_memory]\n        if self._keytab:\n            connection_cmd += [\"--keytab\", self._keytab]\n        if self._principal:\n            connection_cmd += [\"--principal\", self._principal]\n        if self._name:\n            connection_cmd += [\"--name\", self._name]\n        if self._java_class:\n            connection_cmd += [\"--class\", self._java_class]\n        if self._verbose:\n            connection_cmd += [\"--verbose\"]\n        if self._connection['queue']:\n            connection_cmd += [\"--queue\", self._connection['queue']]\n        if self._connection['deploy_mode']:\n            connection_cmd += [\"--deploy-mode\", self._connection['deploy_mode']]\n\n        # The actual script to execute\n        connection_cmd += [application]\n\n        # Append any application arguments\n        if self._application_args:\n            connection_cmd += self._application_args\n\n        self.log.info(\"Spark-Submit cmd: %s\", connection_cmd)\n\n        return connection_cmd", "response": "Builds the spark - submit command to execute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_track_driver_status_command(self):\n        connection_cmd = self._get_spark_binary_path()\n\n        # The url ot the spark master\n        connection_cmd += [\"--master\", self._connection['master']]\n\n        # The driver id so we can poll for its status\n        if self._driver_id:\n            connection_cmd += [\"--status\", self._driver_id]\n        else:\n            raise AirflowException(\n                \"Invalid status: attempted to poll driver \" +\n                \"status but no driver id is known. Giving up.\")\n\n        self.log.debug(\"Poll driver status cmd: %s\", connection_cmd)\n\n        return connection_cmd", "response": "Builds the command to poll the driver status."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubmitting the application to Spark.", "response": "def submit(self, application=\"\", **kwargs):\n        \"\"\"\n        Remote Popen to execute the spark-submit job\n\n        :param application: Submitted application, jar or py file\n        :type application: str\n        :param kwargs: extra arguments to Popen (see subprocess.Popen)\n        \"\"\"\n        spark_submit_cmd = self._build_spark_submit_command(application)\n\n        if hasattr(self, '_env'):\n            env = os.environ.copy()\n            env.update(self._env)\n            kwargs[\"env\"] = env\n\n        self._submit_sp = subprocess.Popen(spark_submit_cmd,\n                                           stdout=subprocess.PIPE,\n                                           stderr=subprocess.STDOUT,\n                                           bufsize=-1,\n                                           universal_newlines=True,\n                                           **kwargs)\n\n        self._process_spark_submit_log(iter(self._submit_sp.stdout.readline, ''))\n        returncode = self._submit_sp.wait()\n\n        # Check spark-submit return code. In Kubernetes mode, also check the value\n        # of exit code in the log, as it may differ.\n        if returncode or (self._is_kubernetes and self._spark_exit_code != 0):\n            raise AirflowException(\n                \"Cannot execute: {}. Error code is: {}.\".format(\n                    spark_submit_cmd, returncode\n                )\n            )\n\n        self.log.debug(\"Should track driver: {}\".format(self._should_track_driver_status))\n\n        # We want the Airflow job to wait until the Spark driver is finished\n        if self._should_track_driver_status:\n            if self._driver_id is None:\n                raise AirflowException(\n                    \"No driver id is known: something went wrong when executing \" +\n                    \"the spark submit command\"\n                )\n\n            # We start with the SUBMITTED status as initial status\n            self._driver_status = \"SUBMITTED\"\n\n            # Start tracking the driver status (blocking function)\n            self._start_driver_status_tracking()\n\n            if self._driver_status != \"FINISHED\":\n                raise AirflowException(\n                    \"ERROR : Driver {} badly exited with status {}\"\n                    .format(self._driver_id, self._driver_status)\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_spark_submit_log(self, itr):\n        # Consume the iterator\n        for line in itr:\n            line = line.strip()\n            # If we run yarn cluster mode, we want to extract the application id from\n            # the logs so we can kill the application when we stop it unexpectedly\n            if self._is_yarn and self._connection['deploy_mode'] == 'cluster':\n                match = re.search('(application[0-9_]+)', line)\n                if match:\n                    self._yarn_application_id = match.groups()[0]\n                    self.log.info(\"Identified spark driver id: %s\",\n                                  self._yarn_application_id)\n\n            # If we run Kubernetes cluster mode, we want to extract the driver pod id\n            # from the logs so we can kill the application when we stop it unexpectedly\n            elif self._is_kubernetes:\n                match = re.search(r'\\s*pod name: ((.+?)-([a-z0-9]+)-driver)', line)\n                if match:\n                    self._kubernetes_driver_pod = match.groups()[0]\n                    self.log.info(\"Identified spark driver pod: %s\",\n                                  self._kubernetes_driver_pod)\n\n                # Store the Spark Exit code\n                match_exit_code = re.search(r'\\s*Exit code: (\\d+)', line)\n                if match_exit_code:\n                    self._spark_exit_code = int(match_exit_code.groups()[0])\n\n            # if we run in standalone cluster mode and we want to track the driver status\n            # we need to extract the driver id from the logs. This allows us to poll for\n            # the status using the driver id. Also, we can kill the driver when needed.\n            elif self._should_track_driver_status and not self._driver_id:\n                match_driver_id = re.search(r'(driver-[0-9\\-]+)', line)\n                if match_driver_id:\n                    self._driver_id = match_driver_id.groups()[0]\n                    self.log.info(\"identified spark driver id: {}\"\n                                  .format(self._driver_id))\n\n            else:\n                self.log.info(line)\n\n            self.log.debug(\"spark submit log: {}\".format(line))", "response": "Processes the spark submit log files and extracts useful information out of it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the spark driver status log and extracts the driver state", "response": "def _process_spark_status_log(self, itr):\n        \"\"\"\n        parses the logs of the spark driver status query process\n\n        :param itr: An iterator which iterates over the input of the subprocess\n        \"\"\"\n        # Consume the iterator\n        for line in itr:\n            line = line.strip()\n\n            # Check if the log line is about the driver status and extract the status.\n            if \"driverState\" in line:\n                self._driver_status = line.split(' : ')[1] \\\n                    .replace(',', '').replace('\\\"', '').strip()\n\n            self.log.debug(\"spark driver status log: {}\".format(line))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _start_driver_status_tracking(self):\n\n        # When your Spark Standalone cluster is not performing well\n        # due to misconfiguration or heavy loads.\n        # it is possible that the polling request will timeout.\n        # Therefore we use a simple retry mechanism.\n        missed_job_status_reports = 0\n        max_missed_job_status_reports = 10\n\n        # Keep polling as long as the driver is processing\n        while self._driver_status not in [\"FINISHED\", \"UNKNOWN\",\n                                          \"KILLED\", \"FAILED\", \"ERROR\"]:\n\n            # Sleep for 1 second as we do not want to spam the cluster\n            time.sleep(1)\n\n            self.log.debug(\"polling status of spark driver with id {}\"\n                           .format(self._driver_id))\n\n            poll_drive_status_cmd = self._build_track_driver_status_command()\n            status_process = subprocess.Popen(poll_drive_status_cmd,\n                                              stdout=subprocess.PIPE,\n                                              stderr=subprocess.STDOUT,\n                                              bufsize=-1,\n                                              universal_newlines=True)\n\n            self._process_spark_status_log(iter(status_process.stdout.readline, ''))\n            returncode = status_process.wait()\n\n            if returncode:\n                if missed_job_status_reports < max_missed_job_status_reports:\n                    missed_job_status_reports = missed_job_status_reports + 1\n                else:\n                    raise AirflowException(\n                        \"Failed to poll for the driver status {} times: returncode = {}\"\n                        .format(max_missed_job_status_reports, returncode)\n                    )", "response": "Start polling the status of the spark driver."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct the spark - kill command to kill a driver.", "response": "def _build_spark_driver_kill_command(self):\n        \"\"\"\n        Construct the spark-submit command to kill a driver.\n        :return: full command to kill a driver\n        \"\"\"\n\n        # If the spark_home is passed then build the spark-submit executable path using\n        # the spark_home; otherwise assume that spark-submit is present in the path to\n        # the executing user\n        if self._connection['spark_home']:\n            connection_cmd = [os.path.join(self._connection['spark_home'],\n                                           'bin',\n                                           self._connection['spark_binary'])]\n        else:\n            connection_cmd = [self._connection['spark_binary']]\n\n        # The url ot the spark master\n        connection_cmd += [\"--master\", self._connection['master']]\n\n        # The actual kill command\n        connection_cmd += [\"--kill\", self._driver_id]\n\n        self.log.debug(\"Spark-Kill cmd: %s\", connection_cmd)\n\n        return connection_cmd"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the task runner that can be used to run the given task.", "response": "def get_task_runner(local_task_job):\n    \"\"\"\n    Get the task runner that can be used to run the given job.\n\n    :param local_task_job: The LocalTaskJob associated with the TaskInstance\n        that needs to be executed.\n    :type local_task_job: airflow.jobs.LocalTaskJob\n    :return: The task runner to use to run the task.\n    :rtype: airflow.task.task_runner.base_task_runner.BaseTaskRunner\n    \"\"\"\n    if _TASK_RUNNER == \"StandardTaskRunner\":\n        return StandardTaskRunner(local_task_job)\n    elif _TASK_RUNNER == \"CgroupTaskRunner\":\n        from airflow.contrib.task_runner.cgroup_task_runner import CgroupTaskRunner\n        return CgroupTaskRunner(local_task_job)\n    else:\n        raise AirflowException(\"Unknown task runner type {}\".format(_TASK_RUNNER))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _wait_for_task_ended(self):\n        try:\n            waiter = self.client.get_waiter('job_execution_complete')\n            waiter.config.max_attempts = sys.maxsize  # timeout is managed by airflow\n            waiter.wait(jobs=[self.jobId])\n        except ValueError:\n            # If waiter not available use expo\n            retry = True\n            retries = 0\n\n            while retries < self.max_retries and retry:\n                self.log.info('AWS Batch retry in the next %s seconds', retries)\n                response = self.client.describe_jobs(\n                    jobs=[self.jobId]\n                )\n                if response['jobs'][-1]['status'] in ['SUCCEEDED', 'FAILED']:\n                    retry = False\n\n                sleep(1 + pow(retries * 0.1, 2))\n                retries += 1", "response": "Wait for the task to end."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries mysql and returns a cursor to the results.", "response": "def _query_mysql(self):\n        \"\"\"\n        Queries mysql and returns a cursor to the results.\n        \"\"\"\n        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)\n        conn = mysql.get_conn()\n        cursor = conn.cursor()\n        cursor.execute(self.sql)\n        return cursor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a cursor and writes results to a local file.", "response": "def _write_local_data_files(self, cursor):\n        \"\"\"\n        Takes a cursor, and writes results to a local file.\n\n        :return: A dictionary where keys are filenames to be used as object\n            names in GCS, and values are file handles to local files that\n            contain the data for the GCS objects.\n        \"\"\"\n        schema = list(map(lambda schema_tuple: schema_tuple[0], cursor.description))\n        col_type_dict = self._get_col_type_dict()\n        file_no = 0\n        tmp_file_handle = NamedTemporaryFile(delete=True)\n        if self.export_format == 'csv':\n            file_mime_type = 'text/csv'\n        else:\n            file_mime_type = 'application/json'\n        files_to_upload = [{\n            'file_name': self.filename.format(file_no),\n            'file_handle': tmp_file_handle,\n            'file_mime_type': file_mime_type\n        }]\n\n        if self.export_format == 'csv':\n            csv_writer = self._configure_csv_file(tmp_file_handle, schema)\n\n        for row in cursor:\n            # Convert datetime objects to utc seconds, and decimals to floats.\n            # Convert binary type object to string encoded with base64.\n            row = self._convert_types(schema, col_type_dict, row)\n\n            if self.export_format == 'csv':\n                csv_writer.writerow(row)\n            else:\n                row_dict = dict(zip(schema, row))\n\n                # TODO validate that row isn't > 2MB. BQ enforces a hard row size of 2MB.\n                s = json.dumps(row_dict, sort_keys=True).encode('utf-8')\n                tmp_file_handle.write(s)\n\n                # Append newline to make dumps BigQuery compatible.\n                tmp_file_handle.write(b'\\n')\n\n            # Stop if the file exceeds the file size limit.\n            if tmp_file_handle.tell() >= self.approx_max_file_size_bytes:\n                file_no += 1\n                tmp_file_handle = NamedTemporaryFile(delete=True)\n                files_to_upload.append({\n                    'file_name': self.filename.format(file_no),\n                    'file_handle': tmp_file_handle,\n                    'file_mime_type': file_mime_type\n                })\n\n                if self.export_format == 'csv':\n                    csv_writer = self._configure_csv_file(tmp_file_handle, schema)\n\n        return files_to_upload"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring a csv writer with the file_handle and write schema as headers for the new file.", "response": "def _configure_csv_file(self, file_handle, schema):\n        \"\"\"Configure a csv writer with the file_handle and write schema\n        as headers for the new file.\n        \"\"\"\n        csv_writer = csv.writer(file_handle, encoding='utf-8',\n                                delimiter=self.field_delimiter)\n        csv_writer.writerow(schema)\n        return csv_writer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_local_schema_file(self, cursor):\n        schema_str = None\n        schema_file_mime_type = 'application/json'\n        tmp_schema_file_handle = NamedTemporaryFile(delete=True)\n        if self.schema is not None and isinstance(self.schema, string_types):\n            schema_str = self.schema.encode('utf-8')\n        elif self.schema is not None and isinstance(self.schema, list):\n            schema_str = json.dumps(self.schema).encode('utf-8')\n        else:\n            schema = []\n            for field in cursor.description:\n                # See PEP 249 for details about the description tuple.\n                field_name = field[0]\n                field_type = self.type_map(field[1])\n                # Always allow TIMESTAMP to be nullable. MySQLdb returns None types\n                # for required fields because some MySQL timestamps can't be\n                # represented by Python's datetime (e.g. 0000-00-00 00:00:00).\n                if field[6] or field_type == 'TIMESTAMP':\n                    field_mode = 'NULLABLE'\n                else:\n                    field_mode = 'REQUIRED'\n                schema.append({\n                    'name': field_name,\n                    'type': field_type,\n                    'mode': field_mode,\n                })\n            schema_str = json.dumps(schema, sort_keys=True).encode('utf-8')\n        tmp_schema_file_handle.write(schema_str)\n\n        self.log.info('Using schema for %s: %s', self.schema_filename, schema_str)\n        schema_file_to_upload = {\n            'file_name': self.schema_filename,\n            'file_handle': tmp_schema_file_handle,\n            'file_mime_type': schema_file_mime_type\n        }\n        return schema_file_to_upload", "response": "Writes the BigQuery schema to a local file system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading all of the files to Google Cloud Storage.", "response": "def _upload_to_gcs(self, files_to_upload):\n        \"\"\"\n        Upload all of the file splits (and optionally the schema .json file) to\n        Google cloud storage.\n        \"\"\"\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n        for tmp_file in files_to_upload:\n            hook.upload(self.bucket, tmp_file.get('file_name'),\n                        tmp_file.get('file_handle').name,\n                        mime_type=tmp_file.get('file_mime_type'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert MySQLdb types to python types.", "response": "def _convert_types(schema, col_type_dict, row):\n        \"\"\"\n        Takes a value from MySQLdb, and converts it to a value that's safe for\n        JSON/Google cloud storage/BigQuery. Dates are converted to UTC seconds.\n        Decimals are converted to floats. Binary type fields are encoded with base64,\n        as imported BYTES data must be base64-encoded according to Bigquery SQL\n        date type documentation: https://cloud.google.com/bigquery/data-types\n        \"\"\"\n        converted_row = []\n        for col_name, col_val in zip(schema, row):\n            if type(col_val) in (datetime, date):\n                col_val = time.mktime(col_val.timetuple())\n            elif isinstance(col_val, Decimal):\n                col_val = float(col_val)\n            elif col_type_dict.get(col_name) == \"BYTES\":\n                col_val = base64.standard_b64encode(col_val).decode('ascii')\n            else:\n                col_val = col_val\n            converted_row.append(col_val)\n        return converted_row"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_col_type_dict(self):\n        schema = []\n        if isinstance(self.schema, string_types):\n            schema = json.loads(self.schema)\n        elif isinstance(self.schema, list):\n            schema = self.schema\n        elif self.schema is not None:\n            self.log.warn('Using default schema due to unexpected type.'\n                          'Should be a string or list.')\n\n        col_type_dict = {}\n        try:\n            col_type_dict = {col['name']: col['type'] for col in schema}\n        except KeyError:\n            self.log.warn('Using default schema due to missing name or type. Please '\n                          'refer to: https://cloud.google.com/bigquery/docs/schemas'\n                          '#specifying_a_json_schema_file')\n        return col_type_dict", "response": "Return a dict of column name and column type based on self. schema if not None."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthenticates a PasswordUser with the specified username and password.", "response": "def authenticate(session, username, password):\n    \"\"\"\n    Authenticate a PasswordUser with the specified\n    username/password.\n\n    :param session: An active SQLAlchemy session\n    :param username: The username\n    :param password: The password\n\n    :raise AuthenticationError: if an error occurred\n    :return: a PasswordUser\n    \"\"\"\n    if not username or not password:\n        raise AuthenticationError()\n\n    user = session.query(PasswordUser).filter(\n        PasswordUser.username == username).first()\n\n    if not user:\n        raise AuthenticationError()\n\n    if not user.authenticate(password):\n        raise AuthenticationError()\n\n    log.info(\"User %s successfully authenticated\", username)\n    return user"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the lineage to XCom and if configured to do so sends it to the backend.", "response": "def apply_lineage(func):\n    \"\"\"\n    Saves the lineage to XCom and if configured to do so sends it\n    to the backend.\n    \"\"\"\n    backend = _get_backend()\n\n    @wraps(func)\n    def wrapper(self, context, *args, **kwargs):\n        self.log.debug(\"Backend: %s, Lineage called with inlets: %s, outlets: %s\",\n                       backend, self.inlets, self.outlets)\n        ret_val = func(self, context, *args, **kwargs)\n\n        outlets = [x.as_dict() for x in self.outlets]\n        inlets = [x.as_dict() for x in self.inlets]\n\n        if len(self.outlets) > 0:\n            self.xcom_push(context,\n                           key=PIPELINE_OUTLETS,\n                           value=outlets,\n                           execution_date=context['ti'].execution_date)\n\n        if len(self.inlets) > 0:\n            self.xcom_push(context,\n                           key=PIPELINE_INLETS,\n                           value=inlets,\n                           execution_date=context['ti'].execution_date)\n\n        if backend:\n            backend.send_lineage(operator=self, inlets=self.inlets,\n                                 outlets=self.outlets, context=context)\n\n        return ret_val\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_lineage(func):\n    @wraps(func)\n    def wrapper(self, context, *args, **kwargs):\n        self.log.debug(\"Preparing lineage inlets and outlets\")\n\n        task_ids = set(self._inlets['task_ids']).intersection(\n            self.get_flat_relative_ids(upstream=True)\n        )\n        if task_ids:\n            inlets = self.xcom_pull(context,\n                                    task_ids=task_ids,\n                                    dag_id=self.dag_id,\n                                    key=PIPELINE_OUTLETS)\n            inlets = [item for sublist in inlets if sublist for item in sublist]\n            inlets = [DataSet.map_type(i['typeName'])(data=i['attributes'])\n                      for i in inlets]\n            self.inlets.extend(inlets)\n\n        if self._inlets['auto']:\n            # dont append twice\n            task_ids = set(self._inlets['task_ids']).symmetric_difference(\n                self.upstream_task_ids\n            )\n            inlets = self.xcom_pull(context,\n                                    task_ids=task_ids,\n                                    dag_id=self.dag_id,\n                                    key=PIPELINE_OUTLETS)\n            inlets = [item for sublist in inlets if sublist for item in sublist]\n            inlets = [DataSet.map_type(i['typeName'])(data=i['attributes'])\n                      for i in inlets]\n            self.inlets.extend(inlets)\n\n        if len(self._inlets['datasets']) > 0:\n            self.inlets.extend(self._inlets['datasets'])\n\n        # outlets\n        if len(self._outlets['datasets']) > 0:\n            self.outlets.extend(self._outlets['datasets'])\n\n        self.log.debug(\"inlets: %s, outlets: %s\", self.inlets, self.outlets)\n\n        for dataset in chain(self.inlets, self.outlets):\n            dataset.set_context(context)\n\n        return func(self, context, *args, **kwargs)\n\n    return wrapper", "response": "Decorator for lineage processing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extra_dejson(self):\n        obj = {}\n        if self.extra:\n            try:\n                obj = json.loads(self.extra)\n            except Exception as e:\n                self.log.exception(e)\n                self.log.error(\"Failed parsing the json for conn_id %s\", self.conn_id)\n\n        return obj", "response": "Returns the extra property by deserializing json."}
