{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites PUML from the system.", "response": "def write_puml(self, filename=''):\n        \"\"\"\n            Writes PUML from the system. If filename is given, stores result in the file.\n            Otherwise returns result as a string.\n        \"\"\"\n        def get_type(o):\n            type = 'program'\n            if isinstance(o, AbstractSensor):\n                type = 'sensor'\n            elif isinstance(o, AbstractActuator):\n                type = 'actuator'\n            return type\n\n        if filename:\n            s = open(filename, 'w')\n        else:\n            s = io.StringIO()\n        s.write('@startuml\\n')\n        s.write('skinparam state {\\n')\n        for k, v in list(self.background_colors.items()):\n            s.write('BackGroundColor<<%s>> %s\\n' % (k, v))\n        s.write('}\\n')\n\n        for o in self.system.objects:\n            if isinstance(o, DefaultProgram) or o.hide_in_uml:\n                continue\n\n            if isinstance(o, ProgrammableSystemObject):\n                s.write('state \"%s\" as %s <<%s>>\\n' % (o, o, get_type(o)))\n\n                s.write('%s: %s\\n' % (o, o.class_name))\n                if isinstance(o, AbstractActuator):\n                    for p in reversed(o.program_stack):\n                        s.write('%s: %s :: %s\\n' % (o, p, o.program_status.get(p, '-')))\n                elif hasattr(o, 'status'):\n                    s.write('%s: Status: %s\\n' % (o, o.status))\n                if getattr(o, 'is_program', False):\n                    s.write('%s: Priority: %s\\n' % (o, o.priority))\n\n                for t in o.actual_triggers:\n                    if isinstance(t, DefaultProgram) or t.hide_in_uml:\n                        continue\n                    s.write('%s -[%s]-> %s\\n' % (t, self.arrow_colors['trigger'], o))\n                for t in o.actual_targets:\n                    if t.hide_in_uml:\n                        continue\n                    if o.active:\n                        color = 'active_target'\n                    else:\n                        color = 'inactive_target'\n                    if getattr(t, 'program', None) == o:\n                        color = 'controlled_target'\n\n                    s.write('%s -[%s]-> %s\\n' % (o, self.arrow_colors[color], t))\n        s.write('@enduml\\n')\n        if filename:\n            s.close()\n        else:\n            return s.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_svg(self):\n        import plantuml\n        puml = self.write_puml()\n        server = plantuml.PlantUML(url=self.url)\n        svg = server.processes(puml)\n        return svg", "response": "Returns PUML from the system as a SVG image. Requires plantuml library."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the median kneighbor distance between a set of random datapoints and a set of random datapoints and a kth nearest neighbours.", "response": "def median_kneighbour_distance(X, k=5):\n    \"\"\"\n    Calculate the median kneighbor distance.\n\n    Find the distance between a set of random datapoints and\n    their kth nearest neighbours. This is a heuristic for setting the\n    kernel length scale.\n    \"\"\"\n    N_all = X.shape[0]\n    k = min(k, N_all)\n    N_subset = min(N_all, 2000)\n    sample_idx_train = np.random.permutation(N_all)[:N_subset]\n    nn = neighbors.NearestNeighbors(k)\n    nn.fit(X[sample_idx_train, :])\n    d, idx = nn.kneighbors(X[sample_idx_train, :])\n    return np.median(d[:, -1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pair_distance_centile(X, centile, max_pairs=5000):\n    N = X.shape[0]\n    n_pairs = min(max_pairs, N**2)\n    # randorder1 = np.random.permutation(N)\n    # randorder2 = np.random.permutation(N)\n\n    dists = np.zeros(n_pairs)\n\n    for i in range(n_pairs):\n        pair = np.random.randint(0, N, 2)\n        pairdiff = X[pair[0], :]-X[pair[1], :]\n        dists[i] = np.dot(pairdiff, pairdiff.T)\n    dists.sort()\n\n    out = dists[int(n_pairs*centile/100.)]\n    return np.sqrt(out)", "response": "Calculate centiles of distances between random pairs in a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfit the inlier model given training data.", "response": "def fit(self, X, y=None):\n        \"\"\"\n        Fit the inlier model given training data.\n\n        This function attempts to choose reasonable defaults for parameters\n        sigma and rho if none are specified, which could then be adjusted\n        to improve performance.\n\n        Parameters\n        ----------\n        X : array\n            Examples of inlier data, of dimension N times d (rows are\n            examples, columns are data dimensions)\n        y : array, optional\n            If the inliers have multiple classes, then y contains the class\n            assignments as a vector of length N. If this is specified then\n            the model will attempt to assign test data to one of the inlier\n            classes or to the outlier class.\n        \"\"\"\n        N = X.shape[0]\n\n        if y is None:\n            y = np.zeros(N)\n\n        self.classes = list(set(y))\n        self.classes.sort()\n        self.n_classes = len(self.classes)\n\n        # If no kernel parameters specified, try to choose some defaults\n        if not self.sigma:\n            self.sigma = median_kneighbour_distance(X)\n            self.gamma = self.sigma**-2\n\n        if not self.gamma:\n            self.gamma = self.sigma**-2\n\n        if not self.rho:\n            self.rho = 0.1\n\n        # choose kernel basis centres\n        if self.kernel_pos is None:\n            B = min(self.n_kernels_max, N)\n            kernel_idx = np.random.permutation(N)\n            self.kernel_pos = X[kernel_idx[:B]]\n        else:\n            B = self.kernel_pos.shape[0]\n\n        # fit coefficients\n        Phi = metrics.pairwise.rbf_kernel(X, self.kernel_pos, self.gamma)\n        theta = {}\n        Phi_PhiT = np.dot(Phi.T, Phi)\n        inverse_term = np.linalg.inv(Phi_PhiT + self.rho*np.eye(B))\n        for c in self.classes:\n            m = (y == c).astype(int)\n            theta[c] = np.dot(inverse_term, np.dot(Phi.T, m))\n\n        self.theta = theta"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npredicting the inlier and outlier inlier classes for the test data.", "response": "def predict(self, X):\n        \"\"\"\n        Assign classes to test data.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are examples, columns\n            are data dimensions)\n\n        Returns\n        -------\n        y_predicted : array\n            A vector of length N containing assigned classes. If no inlier\n            classes were specified during training, then 0 denotes an inlier\n            and 1 denotes an outlier. If multiple inlier classes were\n            specified, then each element of y_predicted is either on of\n            those inlier classes, or an outlier class (denoted by the\n            maximum inlier class ID plus 1).\n        \"\"\"\n        predictions_proba = self.predict_proba(X)\n        predictions = []\n        allclasses = copy.copy(self.classes)\n        allclasses.append('anomaly')\n        for i in range(X.shape[0]):\n            predictions.append(allclasses[predictions_proba[i, :].argmax()])\n        return predictions"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the probability of each class in the test data X.", "response": "def predict_proba(self, X):\n        \"\"\"\n        Calculate posterior probabilities of test data.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are examples, columns\n            are data dimensions)\n\n        Returns:\n        -------\n        y_prob : array\n            An array of dimension N times n_inlier_classes+1, containing\n            the probabilities of each row of X being one of the inlier\n            classes, or the outlier class (last column).\n        \"\"\"\n        Phi = metrics.pairwise.rbf_kernel(X, self.kernel_pos, self.gamma)\n        N = X.shape[0]\n        predictions = np.zeros((N, self.n_classes+1))\n        for i in range(N):\n            post = np.zeros(self.n_classes)\n            for c in range(self.n_classes):\n                post[c] = max(0,\n                              np.dot(self.theta[self.classes[c]].T, Phi[i, :]))\n                post[c] = min(post[c], 1.)\n            predictions[i, :-1] = post\n            predictions[i, -1] = max(0, 1-sum(post))\n\n        return predictions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating an inlier score for each test data example.", "response": "def decision_function(self, X):\n        \"\"\"\n        Generate an inlier score for each test data example.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are examples, columns\n            are data dimensions)\n\n        Returns:\n        -------\n        scores : array\n            A vector of length N, where each element contains an inlier\n            score in the range 0-1 (outliers have values close to zero,\n            inliers have values close to one).\n        \"\"\"\n        predictions = self.predict_proba(X)\n        out = np.zeros((predictions.shape[0], 1))\n        out[:, 0] = 1 - predictions[:, -1]\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef score(self, X, y):\n        predictions = self.predict(X)\n        true = 0.0\n        total = 0.0\n        for i in range(len(predictions)):\n            total += 1\n            if predictions[i] == y[i]:\n                true += 1\n        return true/total", "response": "Calculate accuracy score.\n\n        Needed because of bug in metrics.accuracy_score when comparing\n        list with numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npredict the class probabilities of a sequence of data.", "response": "def predict_sequence(self, X, A, pi, inference='smoothing'):\n        \"\"\"\n        Calculate class probabilities for a sequence of data.\n\n        Parameters\n        ----------\n        X : array\n            Test data, of dimension N times d (rows are time frames, columns\n            are data dimensions)\n        A : class transition matrix, where A[i,j] contains p(y_t=j|y_{t-1}=i)\n        pi : vector of initial class probabilities\n        inference : can be 'smoothing' or 'filtering'.\n\n        Returns:\n        -------\n        y_prob : array\n            An array of dimension N times n_inlier_classes+1, containing\n            the probabilities of each row of X being one of the inlier\n            classes, or the outlier class (last column).\n        \"\"\"\n        obsll = self.predict_proba(X)\n        T, S = obsll.shape\n        alpha = np.zeros((T, S))\n\n        alpha[0, :] = pi\n        for t in range(1, T):\n            alpha[t, :] = np.dot(alpha[t-1, :], A)\n            for s in range(S):\n                alpha[t, s] *= obsll[t, s]\n            alpha[t, :] = alpha[t, :]/sum(alpha[t, :])\n\n        if inference == 'filtering':\n            return alpha\n        else:\n            beta = np.zeros((T, S))\n            gamma = np.zeros((T, S))\n            beta[T-1, :] = np.ones(S)\n            for t in range(T-2, -1, -1):\n                for i in range(S):\n                    for j in range(S):\n                        beta[t, i] += A[i, j]*obsll[t+1, j]*beta[t+1, j]\n                beta[t, :] = beta[t, :]/sum(beta[t, :])\n\n            for t in range(T):\n                gamma[t, :] = alpha[t, :]*beta[t, :]\n                gamma[t, :] = gamma[t, :]/sum(gamma[t, :])\n\n            return gamma"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef toggle_sensor(request, sensorname):\n    if service.read_only:\n        service.logger.warning(\"Could not perform operation: read only mode enabled\")\n        raise Http404\n    source = request.GET.get('source', 'main')\n    sensor = service.system.namespace[sensorname]\n    sensor.status = not sensor.status\n    service.system.flush()\n    return HttpResponseRedirect(reverse(source))", "response": "Toggle a sensor in the system"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toggle_value(request, name):\n    obj = service.system.namespace.get(name, None)\n    if not obj or service.read_only:\n        raise Http404\n    new_status = obj.status = not obj.status\n    if service.redirect_from_setters:\n        return HttpResponseRedirect(reverse('set_ready', args=(name, new_status)))\n    else:\n        return set_ready(request, name, new_status)", "response": "Toggle the value of a node in the system namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_value(request, name, value):\n    obj = service.system.namespace.get(name, None)\n    if not obj or service.read_only:\n        raise Http404\n    obj.status = value\n    if service.redirect_from_setters:\n        return HttpResponseRedirect(reverse('set_ready', args=(name, value)))\n    else:\n        return set_ready(request, name, value)", "response": "Set the value of a node in the system namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets information about this object as a dictionary. Used by WebSocket interface to pass some relevant information to client applications.", "response": "def get_as_datadict(self):\n        \"\"\"\n            Get information about this object as a dictionary.  Used by WebSocket interface to pass some\n            relevant information to client applications.\n        \"\"\"\n        return dict(type=self.__class__.__name__, tags=list(self.tags))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting system attribute and do some initialization. Used by System.", "response": "def setup_system(self, system, name_from_system='', **kwargs):\n        \"\"\"\n            Set system attribute and do some initialization. Used by System.\n        \"\"\"\n\n        if not self.system:\n            self.system = system\n        name, traits = self._passed_arguments\n        new_name = self.system.get_unique_name(self, name, name_from_system)\n        if not self in self.system.reverse:\n            self.name = new_name\n        self.logger = self.system.logger.getChild('%s.%s' % (self.__class__.__name__, self.name))\n        self.logger.setLevel(self.log_level)\n        if name is None and 'name' in traits:  # Only __setstate__ sets name to None. Default is ''.\n            del traits['name']\n\n        for cname in self.callables:\n            if cname in traits:\n                c = self._postponed_callables[cname] = traits.pop(cname)\n                c.setup_callable_system(self.system)\n            getattr(self, cname).setup_callable_system(self.system)\n\n        if not self.traits_inited():\n            super().__init__(**traits)\n        self.name_changed_event = True\n        self.setup()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef grab_keyfile(cert_url):\n    key_cache = caches[getattr(settings, 'BOUNCY_KEY_CACHE', 'default')]\n\n    pemfile = key_cache.get(cert_url)\n    if not pemfile:\n        response = urlopen(cert_url)\n        pemfile = response.read()\n        # Extract the first certificate in the file and confirm it's a valid\n        # PEM certificate\n        certificates = pem.parse(smart_bytes(pemfile))\n\n        # A proper certificate file will contain 1 certificate\n        if len(certificates) != 1:\n            logger.error('Invalid Certificate File: URL %s', cert_url)\n            raise ValueError('Invalid Certificate File')\n\n        key_cache.set(cert_url, pemfile)\n    return pemfile", "response": "Function to grab the keyfile from the cache and return it"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_notification(data):\n    pemfile = grab_keyfile(data['SigningCertURL'])\n    cert = crypto.load_certificate(crypto.FILETYPE_PEM, pemfile)\n    signature = base64.decodestring(six.b(data['Signature']))\n\n    if data['Type'] == \"Notification\":\n        hash_format = NOTIFICATION_HASH_FORMAT\n    else:\n        hash_format = SUBSCRIPTION_HASH_FORMAT\n\n    try:\n        crypto.verify(\n            cert, signature, six.b(hash_format.format(**data)), 'sha1')\n    except crypto.Error:\n        return False\n    return True", "response": "Function to verify a notification came from a trusted source\n            Returns True if verified otherwise False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef approve_subscription(data):\n    url = data['SubscribeURL']\n\n    domain = urlparse(url).netloc\n    pattern = getattr(\n        settings,\n        'BOUNCY_SUBSCRIBE_DOMAIN_REGEX',\n        r\"sns.[a-z0-9\\-]+.amazonaws.com$\"\n    )\n    if not re.search(pattern, domain):\n        logger.error('Invalid Subscription Domain %s', url)\n        return HttpResponseBadRequest('Improper Subscription Domain')\n\n    try:\n        result = urlopen(url).read()\n        logger.info('Subscription Request Sent %s', url)\n    except urllib.HTTPError as error:\n        result = error.read()\n        logger.warning('HTTP Error Creating Subscription %s', str(result))\n\n    signals.subscription.send(\n        sender='bouncy_approve_subscription',\n        result=result,\n        notification=data\n    )\n\n    # Return a 200 Status Code\n    return HttpResponse(six.u(result))", "response": "This function is used to approve a SNS subscription with Amazon\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_time(time_string):\n    # Get a timezone-aware datetime object from the string\n    time = dateutil.parser.parse(time_string)\n    if not settings.USE_TZ:\n        # If timezone support is not active, convert the time to UTC and\n        # remove the timezone field\n        time = time.astimezone(timezone.utc).replace(tzinfo=None)\n    return time", "response": "Return a datetime from the Amazon - provided datetime string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_selectors(model, fields=None, exclude=None, key_map=None, **options):\n    fields = fields or DEFAULT_SELECTORS\n    exclude = exclude or ()\n    key_map = key_map or {}\n    validated = []\n\n    for alias in fields:\n        # Map the output key name to the actual field/accessor name for\n        # the model\n        actual = key_map.get(alias, alias)\n\n        # Validate the field exists\n        cleaned = resolver.get_field(model, actual)\n\n        if cleaned is None:\n            raise AttributeError('The \"{0}\" attribute could not be found '\n                                 'on the model \"{1}\"'.format(actual, model))\n\n        # Mapped value, so use the original name listed in `fields`\n        if type(cleaned) is list:\n            validated.extend(cleaned)\n        elif alias != actual:\n            validated.append(alias)\n        else:\n            validated.append(cleaned)\n\n    return tuple([x for x in validated if x not in exclude])", "response": "Validates fields are valid and maps pseudo - fields to actual fields\n    for a given model class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_local_fields(self, model):\n        \"Return the names of all locally defined fields on the model class.\"\n        local = [f for f in model._meta.fields]\n        m2m = [f for f in model._meta.many_to_many]\n        fields = local + m2m\n        names = tuple([x.name for x in fields])\n\n        return {\n            ':local': dict(list(zip(names, fields))),\n        }", "response": "Return the names of all locally defined fields on the model class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_related_fields(self, model):\n        \"Returns the names of all related fields for model class.\"\n        reverse_fk = self._get_all_related_objects(model)\n        reverse_m2m = self._get_all_related_many_to_many_objects(model)\n\n        fields = tuple(reverse_fk + reverse_m2m)\n        names = tuple([x.get_accessor_name() for x in fields])\n\n        return {\n            ':related': dict(list(zip(names, fields))),\n        }", "response": "Returns the names of all related fields for model class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_html(self, index=False, escape=False, header=True,\n            collapse_table=True, class_outer=\"table_outer\", **kargs):\n        \"\"\"Return HTML version of the table\n\n        This is a wrapper of the to_html method of the pandas dataframe.\n\n        :param bool index: do not include the index\n        :param bool escape: do not escape special characters\n        :param bool header: include header\n        :param bool collapse_table: long tables are shorten with a scroll bar\n        :param kargs: any parameter accepted by\n            :meth:`pandas.DataFrame.to_html`\n\n        \"\"\"\n        _buffer = {}\n        for k, v in self.pd_options.items():\n            # save the current option\n            _buffer[k] = pd.get_option(k)\n            # set with user value\n            pd.set_option(k, v)\n\n        # class sortable is to use the sorttable javascript\n        # note that the class has one t and the javascript library has 2\n        # as in the original version of sorttable.js\n        table = self.df.to_html(escape=escape, header=header, index=index,\n                classes='sortable', **kargs)\n\n        # get back to default options\n        for k, v in _buffer.items():\n            pd.set_option(k, v)\n\n        # We wrap the table in a dedicated class/div nammed table_scroller\n        # that users must define.\n        return '<div class=\"%s\">' % class_outer + table+\"</div>\"", "response": "Return HTML version of the table"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange column content into HTML paragraph with background color.", "response": "def add_bgcolor(self, colname, cmap='copper', mode='absmax',\n            threshold=2):\n        \"\"\"Change column content into HTML paragraph with background color\n\n        :param colname:\n        :param cmap: a colormap (matplotlib) or created using\n            colormap package (from pypi).\n        :param mode: type of normalisation in 'absmax', 'max', 'clip'\n            (see details below)\n        :param threshold: used if mode is set to 'clip'\n\n        Colormap have values between 0 and 1 so we need to normalised the data\n        between 0 and 1. There are 3 mode to normalise the data so far.\n\n        If mode is set to 'absmax', negatives and positives values are\n        expected to be found in a range from -inf to inf. Values are\n        scaled in between [0,1] X' = (X / M +1) /2. where m is the absolute\n        maximum. Ideally a colormap should be made of 3 colors, the first\n        color used for negative values, the second for zeros and third color\n        for positive values.\n\n        If mode is set to 'clip', values are clipped to a max value (parameter\n        *threshold* and values are normalised by that same threshold.\n\n        If mode is set to 'max', values are normalised by the max.\n\n        \"\"\"\n        try:\n            # if a cmap is provided, it may be just a known cmap name\n            cmap = cmap_builder(cmap)\n        except:\n            pass\n\n        data = self.df[colname].values\n\n        if len(data) == 0:\n            return\n\n        if mode == 'clip':\n            data = [min(x, threshold)/float(threshold) for x in data]\n        elif mode == 'absmax':\n            m = abs(data.min())\n            M = abs(data.max())\n            M = max([m, M])\n            if M != 0:\n                data = (data / M + 1)/2.\n        elif mode == 'max':\n            if data.max() != 0:\n                data = data / float(data.max())\n\n        # the expected RGB values for a given data point\n        rgbcolors = [cmap(x)[0:3] for x in data]\n        hexcolors = [rgb2hex(*x, normalised=True) for x in rgbcolors]\n\n        # need to read original data again\n        data = self.df[colname].values\n        # need to set precision since this is going to be a text not a number\n        # so pandas will not use the precision for those cases:\n\n        def prec(x):\n            try:\n                # this may fail if for instance x is nan or inf\n                x = easydev.precision(x, self.pd_options['precision'])\n                return x\n            except:\n                return x\n\n        data = [prec(x) for x in data]\n        html_formatter = '<p style=\"background-color:{0}\">{1}</p>'\n        self.df[colname] = [html_formatter.format(x, y)\n                for x, y in zip(hexcolors, data)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef changelist_view(self, request, extra_context=None):\n        extra_context = extra_context or {}\n        if 'object' in request.GET.keys():\n            value = request.GET['object'].split(':')\n            content_type = get_object_or_404(\n                ContentType,\n                id=value[0],\n            )\n            tracked_object = get_object_or_404(\n                content_type.model_class(),\n                id=value[1],\n            )\n            extra_context['tracked_object'] = tracked_object\n            extra_context['tracked_object_opts'] = tracked_object._meta\n        return super(TrackingEventAdmin, self).changelist_view(\n            request, extra_context)", "response": "Get object currently tracked and add a button to get back to it"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of configs.", "response": "def list(self, filter=None, type=None, sort=None, limit=None, page=None): # pylint: disable=redefined-builtin\n        \"\"\"Get a list of configs.\n\n        :param filter: (optional) Filters to apply as a string list.\n        :param type: (optional) `union` or `inter` as string.\n        :param sort: (optional) Sort fields to apply as string list.\n        :param limit: (optional) Limit returned list length.\n        :param page: (optional) Page to return.\n        :return: :class:`configs.Page <configs.Page>` object\n        \"\"\"\n        schema = self.LIST_SCHEMA\n        resp = self.service.list(self.base, filter, type, sort, limit, page)\n        cs, l = self.service.decode(schema, resp, many=True, links=True)\n        return Page(cs, l)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of configs. Whereas list fetches a single page of configs according to its limit and page arguments and iter_list returns all configs.", "response": "def iter_list(self, *args, **kwargs):\n        \"\"\"Get a list of configs.  Whereas ``list`` fetches a single page of\n        configs according to its ``limit`` and ``page`` arguments,\n        ``iter_list`` returns all configs by internally making\n        successive calls to ``list``.\n\n        :param args: Arguments that ``list`` takes.\n        :param kwargs: Optional arguments that ``list`` takes.\n        :return: :class:`configs.Config <configs.Config>` list\n\n        \"\"\"\n        return self.service.iter_list(self.list, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_plaintext(self, id): # pylint: disable=invalid-name,redefined-builtin\n        return self.service.get_id(self.base, id, params={'format': 'text'}).text", "response": "Get a config as plaintext."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new config. .", "response": "def create(self, resource):\n        \"\"\"Create a new config.\n\n        :param resource: :class:`configs.Config <configs.Config>` object\n        :return: :class:`configs.Config <configs.Config>` object\n        :rtype: configs.Config\n        \"\"\"\n        schema = self.CREATE_SCHEMA\n        json = self.service.encode(schema, resource)\n\n        schema = self.GET_SCHEMA\n        resp = self.service.create(self.base, json)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef edit(self, resource):\n        schema = self.EDIT_SCHEMA\n        json = self.service.encode(schema, resource)\n\n        schema = self.GET_SCHEMA\n        resp = self.service.edit(self.base, resource.id, json)\n        return self.service.decode(schema, resp)", "response": "Edit a config.\n       ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edit_shares(self, id, user_ids): # pylint: disable=invalid-name,redefined-builtin\n        return self.service.edit_shares(self.base, id, user_ids)", "response": "Edit shares for a config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess contents with cdrouter - cli - check - config.", "response": "def check_config(self, contents):\n        \"\"\"Process config contents with cdrouter-cli -check-config.\n\n        :param contents: Config contents as string.\n        :return: :class:`configs.CheckConfig <configs.CheckConfig>` object\n        :rtype: configs.CheckConfig\n        \"\"\"\n        schema = CheckConfigSchema()\n        resp = self.service.post(self.base,\n                                 params={'process': 'check'}, json={'contents': contents})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing config contents with cdrouter - cli - upgrade - config.", "response": "def upgrade_config(self, contents):\n        \"\"\"Process config contents with cdrouter-cli -upgrade-config.\n\n        :param contents: Config contents as string.\n        :return: :class:`configs.UpgradeConfig <configs.UpgradeConfig>` object\n        :rtype: configs.UpgradeConfig\n        \"\"\"\n        schema = UpgradeConfigSchema()\n        resp = self.service.post(self.base,\n                                 params={'process': 'upgrade'}, json={'contents': contents})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_networks(self, contents):\n        schema = NetworksSchema()\n        resp = self.service.post(self.base,\n                                 params={'process': 'networks'}, json={'contents': contents})\n        return self.service.decode(schema, resp)", "response": "Process config contents with cdrouter - cli - print - networks - json.\n        returns a dict containing the config contents as string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbulk copy a set of configs.", "response": "def bulk_copy(self, ids):\n        \"\"\"Bulk copy a set of configs.\n\n        :param ids: Int list of config IDs.\n        :return: :class:`configs.Config <configs.Config>` list\n        \"\"\"\n        schema = self.GET_SCHEMA\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbulks edit a set of configs.", "response": "def bulk_edit(self, _fields, ids=None, filter=None, type=None, all=False, testvars=None): # pylint: disable=redefined-builtin\n        \"\"\"Bulk edit a set of configs.\n\n        :param _fields: :class:`configs.Config <configs.Config>` object\n        :param ids: (optional) Int list of config IDs.\n        :param filter: (optional) String list of filters.\n        :param type: (optional) `union` or `inter` as string.\n        :param all: (optional) Apply to all if bool `True`.\n        :param testvars: (optional) :class:`configs.ConfigTestvars <configs.ConfigTestvars>` list\n        \"\"\"\n        schema = self.EDIT_SCHEMA\n        _fields = self.service.encode(schema, _fields, skip_none=True)\n        return self.service.bulk_edit(self.base, self.RESOURCE,\n                                      _fields, ids=ids, filter=filter, type=type, all=all, testvars=testvars)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bulk_delete(self, ids=None, filter=None, type=None, all=False): # pylint: disable=redefined-builtin\n        return self.service.bulk_delete(self.base, self.RESOURCE,\n                                        ids=ids, filter=filter, type=type, all=all)", "response": "Bulk delete a set of configs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting token from response and set it for the user.", "response": "def response_token_setter(remote, resp):\n    \"\"\"Extract token from response and set it for the user.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :raises invenio_oauthclient.errors.OAuthClientError: If authorization with\n        remote service failed.\n    :raises invenio_oauthclient.errors.OAuthResponseError: In case of bad\n        authorized request.\n    :returns: The token.\n    \"\"\"\n    if resp is None:\n        raise OAuthRejectedRequestError('User rejected request.', remote, resp)\n    else:\n        if 'access_token' in resp:\n            return oauth2_token_setter(remote, resp)\n        elif 'oauth_token' in resp and 'oauth_token_secret' in resp:\n            return oauth1_token_setter(remote, resp)\n        elif 'error' in resp:\n            # Only OAuth2 specifies how to send error messages\n            raise OAuthClientError(\n                'Authorization with remote service failed.', remote, resp,\n            )\n    raise OAuthResponseError('Bad OAuth authorized request', remote, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting an OAuth1 token.", "response": "def oauth1_token_setter(remote, resp, token_type='', extra_data=None):\n    \"\"\"Set an OAuth1 token.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :param token_type: The token type. (Default: ``''``)\n    :param extra_data: Extra information. (Default: ``None``)\n    :returns: A :class:`invenio_oauthclient.models.RemoteToken` instance.\n    \"\"\"\n    return token_setter(\n        remote,\n        resp['oauth_token'],\n        secret=resp['oauth_token_secret'],\n        extra_data=extra_data,\n        token_type=token_type,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef oauth2_token_setter(remote, resp, token_type='', extra_data=None):\n    return token_setter(\n        remote,\n        resp['access_token'],\n        secret='',\n        token_type=token_type,\n        extra_data=extra_data,\n    )", "response": "Set an OAuth2 token."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef token_setter(remote, token, secret='', token_type='', extra_data=None,\n                 user=None):\n    \"\"\"Set token for user.\n\n    :param remote: The remote application.\n    :param token: The token to set.\n    :param token_type: The token type. (Default: ``''``)\n    :param extra_data: Extra information. (Default: ``None``)\n    :param user: The user owner of the remote token. If it's not defined,\n        the current user is used automatically. (Default: ``None``)\n    :returns: A :class:`invenio_oauthclient.models.RemoteToken` instance or\n        ``None``.\n    \"\"\"\n    session[token_session_key(remote.name)] = (token, secret)\n    user = user or current_user\n\n    # Save token if user is not anonymous (user exists but can be not active at\n    # this moment)\n    if not user.is_anonymous:\n        uid = user.id\n        cid = remote.consumer_key\n\n        # Check for already existing token\n        t = RemoteToken.get(uid, cid, token_type=token_type)\n\n        if t:\n            t.update_token(token, secret)\n        else:\n            t = RemoteToken.create(\n                uid, cid, token, secret,\n                token_type=token_type, extra_data=extra_data\n            )\n        return t\n    return None", "response": "Set token for user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve OAuth access token.", "response": "def token_getter(remote, token=''):\n    \"\"\"Retrieve OAuth access token.\n\n    Used by flask-oauthlib to get the access token when making requests.\n\n    :param remote: The remote application.\n    :param token: Type of token to get. Data passed from ``oauth.request()`` to\n        identify which token to retrieve. (Default: ``''``)\n    :returns: The token.\n    \"\"\"\n    session_key = token_session_key(remote.name)\n\n    if session_key not in session and current_user.is_authenticated:\n        # Fetch key from token store if user is authenticated, and the key\n        # isn't already cached in the session.\n        remote_token = RemoteToken.get(\n            current_user.get_id(),\n            remote.consumer_key,\n            token_type=token,\n        )\n\n        if remote_token is None:\n            return None\n\n        # Store token and secret in session\n        session[session_key] = remote_token.token()\n\n    return session.get(session_key, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves OAuth access tokens from session.", "response": "def token_delete(remote, token=''):\n    \"\"\"Remove OAuth access tokens from session.\n\n    :param remote: The remote application.\n    :param token: Type of token to get. Data passed from ``oauth.request()`` to\n        identify which token to retrieve. (Default: ``''``)\n    :returns: The token.\n    \"\"\"\n    session_key = token_session_key(remote.name)\n    return session.pop(session_key, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authorized_default_handler(resp, remote, *args, **kwargs):\n    response_token_setter(remote, resp)\n    db.session.commit()\n    return redirect(url_for('invenio_oauthclient_settings.index'))", "response": "Store access token in session.\n\n    Default authorized handler.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :returns: Redirect response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef authorized_signup_handler(resp, remote, *args, **kwargs):\n    # Remove any previously stored auto register session key\n    session.pop(token_session_key(remote.name) + '_autoregister', None)\n\n    # Store token in session\n    # ----------------------\n    # Set token in session - token object only returned if\n    # current_user.is_autenticated().\n    token = response_token_setter(remote, resp)\n    handlers = current_oauthclient.signup_handlers[remote.name]\n\n    # Sign-in/up user\n    # ---------------\n    if not current_user.is_authenticated:\n        account_info = handlers['info'](resp)\n        account_info_received.send(\n            remote, token=token, response=resp, account_info=account_info\n        )\n\n        user = oauth_get_user(\n            remote.consumer_key,\n            account_info=account_info,\n            access_token=token_getter(remote)[0],\n        )\n\n        if user is None:\n            # Auto sign-up if user not found\n            form = create_csrf_disabled_registrationform()\n            form = fill_form(\n                form,\n                account_info['user']\n            )\n            user = oauth_register(form)\n\n            # if registration fails ...\n            if user is None:\n                # requires extra information\n                session[\n                    token_session_key(remote.name) + '_autoregister'] = True\n                session[token_session_key(remote.name) +\n                        '_account_info'] = account_info\n                session[token_session_key(remote.name) +\n                        '_response'] = resp\n                db.session.commit()\n                return redirect(url_for(\n                    '.signup',\n                    remote_app=remote.name,\n                ))\n\n        # Authenticate user\n        if not oauth_authenticate(remote.consumer_key, user,\n                                  require_existing_link=False):\n            return current_app.login_manager.unauthorized()\n\n        # Link account\n        # ------------\n        # Need to store token in database instead of only the session when\n        # called first time.\n        token = response_token_setter(remote, resp)\n\n    # Setup account\n    # -------------\n    if not token.remote_account.extra_data:\n        account_setup = handlers['setup'](token, resp)\n        account_setup_received.send(\n            remote, token=token, response=resp, account_setup=account_setup\n        )\n        db.session.commit()\n        account_setup_committed.send(remote, token=token)\n    else:\n        db.session.commit()\n\n    # Redirect to next\n    next_url = get_session_next_url(remote.name)\n    if next_url:\n        return redirect(next_url)\n    return redirect(url_for('invenio_oauthclient_settings.index'))", "response": "Handles the authorized sign - in and up functionality."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling unlinking of remote account. This default handler will just delete the remote account link. You may wish to extend this module to perform clean-up in the remote service before removing the link (e.g. removing install webhooks). :param remote: The remote application. :returns: Redirect response.", "response": "def disconnect_handler(remote, *args, **kwargs):\n    \"\"\"Handle unlinking of remote account.\n\n    This default handler will just delete the remote account link. You may\n    wish to extend this module to perform clean-up in the remote service\n    before removing the link (e.g. removing install webhooks).\n\n    :param remote: The remote application.\n    :returns: Redirect response.\n    \"\"\"\n    if not current_user.is_authenticated:\n        return current_app.login_manager.unauthorized()\n\n    with db.session.begin_nested():\n        account = RemoteAccount.get(\n            user_id=current_user.get_id(),\n            client_id=remote.consumer_key\n        )\n        if account:\n            account.delete()\n\n    db.session.commit()\n    return redirect(url_for('invenio_oauthclient_settings.index'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle extra signup information.", "response": "def signup_handler(remote, *args, **kwargs):\n    \"\"\"Handle extra signup information.\n\n    :param remote: The remote application.\n    :returns: Redirect response or the template rendered.\n    \"\"\"\n    # User already authenticated so move on\n    if current_user.is_authenticated:\n        return redirect('/')\n\n    # Retrieve token from session\n    oauth_token = token_getter(remote)\n    if not oauth_token:\n        return redirect('/')\n\n    session_prefix = token_session_key(remote.name)\n\n    # Test to see if this is coming from on authorized request\n    if not session.get(session_prefix + '_autoregister', False):\n        return redirect(url_for('.login', remote_app=remote.name))\n\n    form = create_registrationform(request.form)\n\n    if form.validate_on_submit():\n        account_info = session.get(session_prefix + '_account_info')\n        response = session.get(session_prefix + '_response')\n\n        # Register user\n        user = oauth_register(form)\n\n        if user is None:\n            raise OAuthError('Could not create user.', remote)\n\n        # Remove session key\n        session.pop(session_prefix + '_autoregister', None)\n\n        # Link account and set session data\n        token = token_setter(remote, oauth_token[0], secret=oauth_token[1],\n                             user=user)\n        handlers = current_oauthclient.signup_handlers[remote.name]\n\n        if token is None:\n            raise OAuthError('Could not create token for user.', remote)\n\n        if not token.remote_account.extra_data:\n            account_setup = handlers['setup'](token, response)\n            account_setup_received.send(\n                remote, token=token, response=response,\n                account_setup=account_setup\n            )\n            # Registration has been finished\n            db.session.commit()\n            account_setup_committed.send(remote, token=token)\n        else:\n            # Registration has been finished\n            db.session.commit()\n\n        # Authenticate the user\n        if not oauth_authenticate(remote.consumer_key, user,\n                                  require_existing_link=False):\n            # Redirect the user after registration (which doesn't include the\n            # activation), waiting for user to confirm his email.\n            return redirect(url_for('security.login'))\n\n        # Remove account info from session\n        session.pop(session_prefix + '_account_info', None)\n        session.pop(session_prefix + '_response', None)\n\n        # Redirect to next\n        next_url = get_session_next_url(remote.name)\n        if next_url:\n            return redirect(next_url)\n        else:\n            return redirect('/')\n\n    # Pre-fill form\n    account_info = session.get(session_prefix + '_account_info')\n    if not form.is_submitted():\n        form = fill_form(form, account_info['user'])\n\n    return render_template(\n        current_app.config['OAUTHCLIENT_SIGNUP_TEMPLATE'],\n        form=form,\n        remote=remote,\n        app_title=current_app.config['OAUTHCLIENT_REMOTE_APPS'][\n            remote.name].get('title', ''),\n        app_description=current_app.config['OAUTHCLIENT_REMOTE_APPS'][\n            remote.name].get('description', ''),\n        app_icon=current_app.config['OAUTHCLIENT_REMOTE_APPS'][\n            remote.name].get('icon', None),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef oauth_logout_handler(sender_app, user=None):\n    oauth = current_app.extensions['oauthlib.client']\n    for remote in oauth.remote_apps.values():\n        token_delete(remote)\n    db.session.commit()", "response": "Remove all access tokens from session on logout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_handler(f, remote, with_response=True):\n    if isinstance(f, six.string_types):\n        f = import_string(f)\n\n    @wraps(f)\n    def inner(*args, **kwargs):\n        if with_response:\n            return f(args[0], remote, *args[1:], **kwargs)\n        else:\n            return f(remote, *args, **kwargs)\n    return inner", "response": "Make a handler for authorized and disconnect callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _enable_cleanup(func):\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        self = args[0]\n        result = func(*args, **kwargs)\n        self.cleanup(self)\n        return result\n\n    return wrapper", "response": "Decorator to enable cleanup on the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _enable_thread_pool(func):\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        self = args[0]\n        if self.enable_thread_pool and hasattr(self, 'thread_pool'):\n            future = self.thread_pool.submit(func, *args, **kwargs)\n            is_async = kwargs.get('is_async')\n            if is_async is None or not is_async:\n                timeout = kwargs.get('timeout')\n                if timeout is None:\n                    timeout = 2\n                try:\n                    result = future.result(timeout=timeout)\n                except TimeoutError as e:\n                    self.logger.exception(e)\n                    result = None\n                return result\n            return future\n        else:\n            return func(*args, **kwargs)\n\n    return wrapper", "response": "Decorator for thread pooling."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear(self, only_read=False):\n        self.cache_items.clear()\n        self.total_access_count = 0\n        self.logger.debug('Cache clear operation is completed')", "response": ">>> cache = Cache(log_level=logging.WARNING)\n        >>> cache.put('a', 0)\n        >>> cache.put('b', 1)\n        >>> cache.size()\n        2\n        >>> cache.clear()\n        >>> cache.size()\n        0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace the evict function in the cache.", "response": "def replace_evict_func(self, func, only_read=False):\n        \"\"\"\n        >>> cache = Cache(log_level=logging.WARNING)\n        >>> def evict(dict, evict_number=10): pass\n        >>> cache.replace_evict_func(evict)\n        True\n        >>> def evict_b(dict): pass\n        >>> cache.replace_evict_func(evict_b)\n        False\n        >>> def evict_c(dict, a, b): pass\n        >>> cache.replace_evict_func(evict_c)\n        False\n        \"\"\"\n        self.logger.info('Replace the evict function %s ---> %s' % (\n            get_function_signature(self.evict_func), get_function_signature(func)))\n        self.evict_func = func\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_cleanup_func(self, func, only_read=False):\n        self.logger.info('Replace the cleanup function %s ---> %s' % (\n            get_function_signature(self.cleanup), get_function_signature(func)))\n        self.cleanup = func\n        return True", "response": "Replace the cleanup function in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_regularly_cleanup(self, only_read=False):\n        if hasattr(self, 'cleanup_supervisor') and self.cleanup_supervisor is not None:\n            self.cleanup_supervisor.stop()\n            self.logger.debug('Regularly cleanup thread %s is closed' % self.cleanup_supervisor.name)\n            self.cleanup_supervisor = None\n            return True\n        else:\n            self.logger.warning('Current not have a regularly cleanup thread is existent')\n            return False", "response": "Stop regularly cleanup of the current cache entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_regularly_cleanup(self, regularly_cleanup_interval=None, only_read=False):\n        if not hasattr(self, 'cleanup_supervisor') or self.cleanup_supervisor is None:\n            if regularly_cleanup_interval is None or not isinstance(regularly_cleanup_interval, int):\n                regularly_cleanup_interval = self.regularly_cleanup_interval\n\n            cleanup_supervisor = CleanupSupervisorThread(cache=self, logger=self.logger,\n                                                         interval=regularly_cleanup_interval)\n            cleanup_supervisor.start()\n            self.cleanup_supervisor = cleanup_supervisor\n            return True\n        else:\n            self.logger.warning('Already have a regularly cleanup thread - %s' % self.cleanup_supervisor.name)\n            return False", "response": "Start a regularly cleanup thread for the current cache entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a thread pool instance for this cache.", "response": "def with_thread_pool(self, init_func=None, only_read=False):\n        \"\"\"\n        >>> cache = Cache(enable_thread_pool=False, log_level=logging.ERROR)\n        >>> cache.with_thread_pool()\n        True\n        >>> cache.with_thread_pool()\n        False\n        \"\"\"\n        if not hasattr(self, 'thread_pool') or self.thread_pool is None:\n            if init_func is not None:\n                self.thread_pool = init_func()\n            else:\n                self.thread_pool = _init_thread_pool()\n            self.enable_thread_pool = True\n            self.logger.debug('Initialize thread pool completed %s' % self.thread_pool)\n            return True\n        else:\n            self.logger.warning('Already have a thread pool instance - %s' % self.thread_pool)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unable_thread_pool(self, only_read=False):\n        if self.enable_thread_pool and hasattr(self, 'thread_pool') and self.thread_pool is not None:\n            self.thread_pool.shutdown()\n            self.thread_pool = None\n            self.enable_thread_pool = False\n            self.logger.debug('Remove thread pool completed')\n            return True\n        else:\n            self.logger.warning('Current not have a thread pool is existent')\n            return False", "response": "Check if thread pool is not available."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshuts down thread pool.", "response": "def shutdown_thread_pool(self, only_read=False):\n        \"\"\"\n        >>> cache = Cache(log_level=logging.WARNING)\n        >>> cache.shutdown_thread_pool()\n        True\n        >>> cache.unable_thread_pool()\n        True\n        >>> cache.shutdown_thread_pool()\n        False\n        \"\"\"\n        if self.enable_thread_pool and hasattr(self, 'thread_pool') and self.thread_pool is not None:\n            self.thread_pool.shutdown()\n            return True\n        else:\n            self.logger.warning('Current not have a thread pool is existent')\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the capacity of the cache.", "response": "def set_capacity(self, new_capacity, only_read=False):\n        \"\"\"\n        >>> cache = Cache(log_level=logging.WARNING)\n        >>> cache.set_capacity(100)\n        >>> cache.capacity\n        100\n        >>> cache.set_capacity('haha')\n        >>> cache.capacity\n        100\n        \"\"\"\n        if not isinstance(new_capacity, int) or new_capacity <= 0:\n            self.logger.warning('Parameter new_capacity %s must be greater than 0 and is an integer' % new_capacity)\n            return\n        self.capacity = new_capacity"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the expiration time for the current object.", "response": "def set_expire(self, new_expire, only_read=False):\n        \"\"\"\n        >>> cache = Cache(log_level=logging.WARNING)\n        >>> cache.set_expire(40)\n        >>> cache.expire\n        40\n        >>> cache.set_expire('haha')\n        >>> cache.expire\n        40\n        \"\"\"\n        if not isinstance(new_expire, int) or new_expire < 0:\n            self.logger.warning('Parameter new_expire %s must be positive number' % new_expire)\n            return\n        self.expire = new_expire"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_evict_number(self, new_evict_number, only_read=False):\n        if not isinstance(new_evict_number, int) or new_evict_number <= 0:\n            self.logger.warning(\n                'Parameter new_evict_number %s must be greater than 0 and is an integer' % new_evict_number)\n            return\n        self.evict_number = new_evict_number", "response": "This method is used to set the number of entries that are evicted from the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef with_read_after_refresh_expire(self, flag, only_read=False):\n        if not isinstance(flag, bool):\n            self.logger.warning('Parameter flag %s must be boolean' % flag)\n            return\n        self.read_after_refresh_expire = flag", "response": "Set flag to True if the cache is read only after refresh expire"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef statistic_record(self, desc=True, timeout=3, is_async=False, only_read=True, *keys):\n        if len(keys) == 0:\n            records = self._generate_statistic_records()\n        else:\n            records = self._generate_statistic_records_by_keys(keys)\n        return sorted(records, key=lambda t: t['hit_counts'], reverse=desc)", "response": "Returns a list of dictionaries that each element is a dictionary of the statistic info of the cache item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef access_cache(self, key=None, key_location_on_param=0, expire=None, auto_update=True,\n                     cache_loader=None, cache_writer=None, timeout=1):\n        \"\"\"\n        The decorator for simplifying of use cache, it supports auto-update\n        cache(if parameter auto_update is True), load cache from other level cache\n        system or data source and writes back the update result to the\n        other level cache system or data source if cache miss.\n\n        The parameter key assigns a key for access cache or update cache and\n        if it is None so select a parameter as a key from the decorated function\n        by key_location_on_param, notice: key and key_location_on_param cannot all is None.\n\n        For function cache_loader() must is a one-parameter function and the parameter\n        represent a key of the cache, if this parameter is None so use self.cache_loader(),\n        if they all are None so not load cache from other caches system.\n\n        For function cache_writer() must is a two-parameter function and the first parameter\n        representing a key of the cache and the second parameter representing a value of the cache,\n        notice: if the parameter auto_update is False so it will not execute.\n\n        >>> import time\n        >>> cache = Cache(log_level=logging.WARNING)\n        >>> @cache.access_cache(key='a')\n        ... def a():\n        ...     return 'a from data source'\n        >>> a()\n        'a from data source'\n        >>> cache.get('a')\n        'a from data source'\n        >>> cache.put(key='b', value='b from cache')\n        >>> @cache.access_cache(key='b')\n        ... def b():\n        ...     return 'b from data source'\n        >>> b()\n        'b from cache'\n        >>> c_key = 'c'\n        >>> @cache.access_cache(key_location_on_param=0)\n        ... def c(key):\n        ...     return 'c from data source'\n        >>> c(c_key)\n        'c from data source'\n        >>> cache.get(c_key)\n        'c from data source'\n        >>> @cache.access_cache(key='d', auto_update=False)\n        ... def d():\n        ...     return 'd from data source'\n        >>> d()\n        'd from data source'\n        >>> cache.get('d') == None\n        True\n        >>> @cache.access_cache(key='e', cache_loader=lambda k: '%s from cache loader' % k)\n        ... def e():\n        ...     return 'e from data source'\n        >>> e()\n        'e from cache loader'\n        >>> out_dict = {}\n        >>> def writer(k, v):\n        ...     out_dict[k] = v\n        >>> @cache.access_cache(key='f', cache_writer=writer)\n        ... def f():\n        ...     return 'f from data source'\n        >>> f()\n        'f from data source'\n        >>> time.sleep(1) # wait to execute complete because it in the other thread\n        >>> out_dict\n        {'f': 'f from data source'}\n        >>> cache.with_cache_loader(lambda k: '%s from cache loader(global)' % k)\n        True\n        >>> @cache.access_cache(key='g')\n        ... def g():\n        ...     return 'g from data source'\n        >>> g()\n        'g from cache loader(global)'\n        \"\"\"\n\n        def decorate(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                k = None\n                if len(args) - 1 >= key_location_on_param:\n                    k = args[key_location_on_param]\n                if key is not None:\n                    k = key\n                cache_result = self.get(key=k, timeout=timeout)\n                # if the cache is miss and cache loader is the existent\n                # then query cache from cache loader\n                if cache_result is None:\n                    if cache_loader is not None:\n                        cache_result = cache_loader(k)\n                    elif self.cache_loader is not None:\n                        cache_result = self.cache_loader(k)\n                # if still miss then execute a function that is decorated\n                # then update cache on the basis of parameter auto_update\n                if cache_result is not None:\n                    return cache_result\n                else:\n                    result = func(*args, **kwargs)\n\n                if auto_update:\n                    self.put(key=k, value=result, expire=expire, timeout=timeout)\n                    if cache_writer is not None:\n                        self.thread_pool.submit(cache_writer, k, result)\n                    elif self.cache_writer is not None:\n                        self.thread_pool.submit(self.cache_writer, k, result)\n                return result\n\n            return wrapper\n\n        return decorate", "response": "This is a simple decorator for simplifying of use cache. It can be used to access a cache from other caches system or data source."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a key from the cache.", "response": "def get(self, key, timeout=1, is_async=False, only_read=True):\n        \"\"\"\n        Test:\n\n        >>> import time\n        >>> cache = Cache(expire=2)\n        >>> cache.put(key='a', value=0)\n        >>> cache.put(key='b', value=1)\n        >>> cache.put(key='c',value= 2)\n        >>> cache.get('a')\n        0\n        >>> cache.get('b')\n        1\n        >>> cache.get('c')\n        2\n        >>> cache.get('e') == None\n        True\n        >>> time.sleep(2)\n        >>> cache.put(key='e', value=4)\n        >>> cache.get('a') == None\n        True\n        >>> cache.get('b') == None\n        True\n        >>> cache.get('c') == None\n        True\n        \"\"\"\n        if key not in self.cache_items:\n            self.logger.debug('Cache item <%s> missing' % key)\n            return None\n\n        item = self.cache_items.pop(key)\n        item.update_hit_count()\n        if self.read_after_refresh_expire:\n            item.refresh_expire(self.expire)\n        value = item[key]\n        self.cache_items[key] = item\n        self.total_access_count += 1\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, key, value, expire=None, timeout=1, is_async=True, only_read=False):\n        if key in self.cache_items:\n            self.cache_items.pop(key)\n        if expire is None:\n            expire = self.expire\n        self.cache_items[key] = CacheItem(key=key, value=value, expire=expire)", "response": "Put a key - value pair in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npop an item from the cache.", "response": "def pop(self, key, timeout=1, is_async=False, only_read=False):\n        \"\"\"\n        Test:\n\n        >>> cache = Cache(log_level=logging.WARNING)\n        >>> cache.put('a', 0)\n        >>> cache.pop('a')\n        0\n        >>> cache.pop('b') == None\n        True\n        \"\"\"\n        if key not in self.cache_items:\n            return None\n        return self.cache_items.pop(key)[key]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef signature_unsafe(m, sk, pk, hash_func=H):\n    h = hash_func(sk)\n    a = 2 ** (b - 2) + sum(2 ** i * bit(h, i) for i in range(3, b - 2))\n    r = Hint(bytearray([h[j] for j in range(b // 8, b // 4)]) + m)\n    R = scalarmult_B(r)\n    S = (r + Hint(encodepoint(R) + pk + m) * a) % l\n    return bytes(encodepoint(R) + encodeint(S))", "response": "This function is used to use with secret keys or secret data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupgrade database to latest version.", "response": "def upgrade():\n    \"\"\"Upgrade database.\"\"\"\n    current_date = datetime.utcnow()\n\n    # Add 'created' and 'updated' columns to RemoteAccount\n    _add_created_updated_columns('oauthclient_remoteaccount', current_date)\n\n    # Add 'created' and 'updated' columns to RemoteToken\n    _add_created_updated_columns('oauthclient_remotetoken', current_date)\n\n    # Add 'created' and 'updated' columns to UserIdentity\n    _add_created_updated_columns('oauthclient_useridentity', current_date)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of symbols.", "response": "def symbols():\n    \"\"\"Return a list of symbols.\"\"\"\n    symbols = []\n    for line in symbols_stream():\n        symbols.append(line.decode('utf-8').strip())\n    return symbols"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _comp_task(inbox, args, kwargs):\n    # Note. this function uses a global variable which must be defined on the \n    # remote host.\n    for func, args, kwargs in itertools.izip(TASK, args, kwargs):\n        inbox = (func(inbox, *args, **kwargs),)\n    return inbox[0]", "response": "Internal function that compiles a task into a single task."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving a Piper instance or id of the Piper instance.", "response": "def resolve(self, piper, forgive=False):\n        \"\"\"\n        Given a ``Piper`` instance or the ``id`` of the ``Piper``. Returns the\n        ``Piper`` instance if it can be resolved else raises a ``DaggerError`` \n        or returns ``False`` depending on the \"forgive\" argument. \n        \n        Arguments:\n    \n        - piper(``Piper`` or id(``Piper``)) a ``Piper`` instance or its id to be\n          found in the ``Dagger``. \n        - forgive(``bool``) [default: ``False``] If \"forgive\" is ``False`` a \n          ``DaggerError`` is raised whenever a  ``Piper`` cannot be resolved in \n          the ``Dagger``. If \"forgive\" is ``True`` then ``False`` is returned.\n          \n        \"\"\"\n        try:\n            if piper in self:\n                resolved = piper\n            else:\n                resolved = [p for p in self if id(p) == piper][0]\n        except (TypeError, IndexError):\n            resolved = False\n        if resolved:\n            self.log.debug('%s resolved a piper from %s' % (repr(self), piper))\n        else:\n            self.log.debug('%s could not resolve a piper from %s' % \\\n                          (repr(self), repr(piper)))\n            if not forgive:\n                raise DaggerError('%s could not resolve a Piper from %s' % \\\n                                  (repr(self), repr(piper)))\n            resolved = False\n        return resolved"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting Pipers in the order input -> output.", "response": "def connect(self, datas=None):\n        \"\"\"\n        Connects ``Pipers`` in the order input -> output. See ``Piper.connect``.\n        According to the pipes (topology). If \"datas\" is given will connect the\n        input ``Pipers`` to the input data see: ``Dagger.connect_inputs``.\n        \n        Argumensts:\n        \n          - datas(sequence) [default: ``None``] valid sequence of input data.\n            see: ``Dagger.connect_inputs``.\n          \n        \"\"\"\n        # if data connect inputs\n        if datas:\n            self.connect_inputs(datas)\n        # connect the remaining pipers\n        postorder = self.postorder()\n        self.log.debug('%s trying to connect in the order %s' % \\\n                      (repr(self), repr(postorder)))\n        for piper in postorder:\n            if not piper.connected and self[piper].nodes():\n                # 1. sort inputs by index in postorder\n                inputs = [p for p in postorder if p in self[piper].nodes()]\n                # 2. sort postorder so that all parents come before children\n                # mind that the top of a pipeline is a child!\n                inputs.sort(cmp=self.children_after_parents)\n                # 2. branch age sorted inputs\n                piper.connect(inputs)\n        self.log.debug('%s succesfuly connected' % repr(self))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_inputs(self, datas):\n        start_pipers = self.get_inputs()\n        self.log.debug('%s trying to connect inputs in the order %s' % \\\n                      (repr(self), repr(start_pipers)))\n        for piper, data in izip(start_pipers, datas):\n            piper.connect([data])\n        self.log.debug('%s succesfuly connected inputs' % repr(self))", "response": "Connects all Pipers to datas in the correct order."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisconnecting Pipers from the pipeline in the order output - input.", "response": "def disconnect(self, forced=False):\n        \"\"\"\n        Given the pipeline topology disconnects ``Pipers`` in the order output \n        -> input. This also disconnects inputs. See ``Dagger.connect``,\n        ``Piper.connect`` and ``Piper.disconnect``. If \"forced\" is ``True``\n        ``NuMap`` instances will be emptied.\n        \n        Arguments:\n        \n          - forced(``bool``) [default: ``False``] If set ``True`` all tasks from\n            all ``NuMaps`` instances used in the ``Dagger`` will be removed even\n            if they did not belong to this ``Dagger``.\n        \n        \"\"\"\n        reversed_postorder = reversed(self.postorder())\n        self.log.debug('%s trying to disconnect in the order %s' % \\\n                      (repr(self), repr(reversed_postorder)))\n        for piper in reversed_postorder:\n            if piper.connected:\n                # we don't want to trigger an exception\n                piper.disconnect(forced)\n        self.log.debug('%s succesfuly disconnected' % repr(self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts Pipers in the order input - > output - > pipeline.", "response": "def start(self):\n        \"\"\"\n        Given the pipeline topology starts ``Pipers`` in the order input -> \n        output. See ``Piper.start``. ``Pipers`` instances are started in two \n        stages, which allows them to share ``NuMaps``.\n        \n        \"\"\"\n        # top - > bottom of pipeline\n        pipers = self.postorder()\n        # \n        for piper in pipers:\n            piper.start(stages=(0, 1))\n        for piper in pipers:\n            piper.start(stages=(2,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self):\n        self.log.debug('%s begins stopping routine' % repr(self))\n        self.log.debug('%s triggers stopping in input pipers' % repr(self))\n        inputs = self.get_inputs()\n        for piper in inputs:\n            piper.stop(forced=True)\n        self.log.debug('%s pulls output pipers until stop' % repr(self))\n        outputs = self.get_outputs()\n        while outputs:\n            for piper in outputs:\n                try:\n                    # for i in xrange(stride)?\n                    piper.next()\n                except StopIteration:\n                    outputs.remove(piper)\n                    self.log.debug(\"%s stopped output piper: %s\" % \\\n                                   (repr(self), repr(piper)))\n                    continue\n                except Exception, excp:\n                    self.log.debug(\"%s %s raised an exception: %s\" % \\\n                                   (repr(self), piper, excp))\n        self.log.debug(\"%s stops the remaining pipers\" % repr(self))\n        postorder = self.postorder()\n        for piper in postorder:\n            if piper not in inputs:\n                piper.stop(ends=[0])\n        self.log.debug(\"%s finishes stopping of input pipers\" % repr(self))\n        for piper in inputs:\n            if hasattr(piper.imap, 'stop'):\n                piper.imap.stop(ends=[0])\n        self.log.debug('%s finishes stopping routine' % repr(self))", "response": "Stops the Pipers according to pipeline topology."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_inputs(self):\n        start_p = [p for p in self.postorder() if not self.outgoing_edges(p)]\n        self.log.debug('%s got input pipers %s' % (repr(self), start_p))\n        return start_p", "response": "Returns a list of Piper instances which are inputs to the pipeline i. e. which are no incoming pipers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of Piper instances which are outputs to the pipeline i. e. which are outgoing pipes.", "response": "def get_outputs(self):\n        \"\"\"\n        Returns ``Piper`` instances, which are outputs to the pipeline i.e. have\n        no outgoing pipes (incoming dependency edges). \n        \n        \"\"\"\n        end_p = [p for p in self.postorder() if not self.incoming_edges(p)]\n        self.log.debug('%s got output pipers %s' % (repr(self), end_p))\n        return end_p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a Piper instance to this Dagger.", "response": "def add_piper(self, piper, xtra=None, create=True, branch=None):\n        \"\"\"\n        Adds a ``Piper`` instance to this ``Dagger``, but only if the ``Piper`` \n        is not already there. Optionally creates a new ``Piper`` if the \"piper\"\n        argument is valid for the ``Piper`` constructor. Returns a ``tuple``\n        (new_piper_created, piper_instance) indicating whether a new ``Piper`` \n        has been created and the instance of the added ``Piper``. Optionally \n        takes \"branch\" and \"xtra\" arguments for the topological node in the \n        graph.\n        \n        Arguments:\n        \n          - piper(``Piper``, ``Worker`` or id(``Piper``)) ``Piper`` instance or \n            object which will be converted to a ``Piper`` instance.\n          - create(``bool``) [default: ``True``] Should a new ``Piper`` be \n            created if \"piper\" cannot be resolved in this ``Dagger``?\n          - xtra(``dict``) [default: ``None``] Dictionary of  ``graph.Node``  \n            properties.\n        \n        \"\"\"\n        self.log.debug('%s trying to add piper %s' % (repr(self), piper))\n        piper = (self.resolve(piper, forgive=True) or piper)\n        if not isinstance(piper, Piper):\n            if create:\n                try:\n                    piper = Piper(piper)\n                except PiperError:\n                    self.log.error('%s cannot resolve or create a piper from %s' % \\\n                                   (repr(self), repr(piper)))\n                    raise DaggerError('%s cannot resolve or create a piper from %s' % \\\n                                      (repr(self), repr(piper)))\n            else:\n                self.log.error('%s cannot resolve a piper from %s' % \\\n                               (repr(self), repr(piper)))\n                raise DaggerError('%s cannot resolve a piper from %s' % \\\n                                  (repr(self), repr(piper)))\n        new_piper_created = self.add_node(piper, xtra, branch)\n        if new_piper_created:\n            self.log.debug('%s added piper %s' % (repr(self), piper))\n        return (new_piper_created, piper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef del_piper(self, piper, forced=False):\n        self.log.debug('%s trying to delete piper %s' % \\\n                      (repr(self), repr(piper)))\n        try:\n            piper = self.resolve(piper, forgive=False)\n        except DaggerError:\n            self.log.error('%s cannot resolve piper from %s' % \\\n                           (repr(self), repr(piper)))\n            raise DaggerError('%s cannot resolve piper from %s' % \\\n                              (repr(self), repr(piper)))\n        if self.incoming_edges(piper) and not forced:\n            self.log.error('%s piper %s has down-stream pipers (use forced =True to override)' % \\\n                           (repr(self), piper))\n            raise DaggerError('%s piper %s has down-stream pipers (use forced =True to override)' % \\\n                              (repr(self), piper))\n        self.del_node(piper)\n        self.log.debug('%s deleted piper %s' % (repr(self), piper))", "response": "Removes a Piper instance from the Dagger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_pipe(self, pipe, branch=None):\n        #TODO: Check if consume/spawn/produce is right!\n        self.log.debug('%s adding pipe: %s' % (repr(self), repr(pipe)))\n        for i in xrange(len(pipe) - 1):\n            edge = (pipe[i + 1], pipe[i])\n            edge = (self.add_piper(edge[0], create=True, branch=branch)[1], \\\n                    self.add_piper(edge[1], create=True, branch=branch)[1])\n            if edge[0] in self.dfs(edge[1], []):\n                self.log.error('%s cannot add the %s>>>%s edge (introduces a cycle)' % \\\n                                (repr(self), edge[0], edge[1]))\n                raise DaggerError('%s cannot add the %s>>>%s edge (introduces a cycle)' % \\\n                                (repr(self), edge[0], edge[1]))\n            self.add_edge(edge)\n            self.clear_nodes() #dfs\n            self.log.debug('%s added the %s>>>%s edge' % \\\n                          (repr(self), edge[0], edge[1]))", "response": "Adds a pipe to the Dagger."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef del_pipe(self, pipe, forced=False):\n        self.log.debug('%s removes pipe%s forced: %s' % \\\n                      (repr(self), repr(pipe), forced))\n        pipe = list(reversed(pipe))\n        for i in xrange(len(pipe) - 1):\n            edge = (self.resolve(pipe[i]), self.resolve(pipe[i + 1]))\n            self.del_edge(edge)\n            self.log.debug('%s removed the %s>>>%s edge' % \\\n                          (repr(self), edge[0], edge[1]))\n            try:\n                self.del_piper(edge[0], forced)\n                self.del_piper(edge[1], forced)\n            except DaggerError:\n                pass", "response": "Deletes a pipe from the DictGraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a sequence of Pipers instances to the Dagger in the left to right order.", "response": "def add_pipers(self, pipers, *args, **kwargs):\n        \"\"\"\n        Adds a sequence of ``Pipers`` instances to the ``Dagger`` in the \n        specified order. Takes optional arguments for ``Dagger.add_piper``.\n        \n        Arguments:\n        \n          - pipers(sequence of valid ``add_piper`` arguments) Sequence of \n            ``Pipers`` or valid ``Dagger.add_piper`` arguments to be added to \n            the ``Dagger`` in the left to right order.\n            \n        \"\"\"\n        for piper in pipers:\n            self.add_piper(piper, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a sequence of Pipers instances from the Dagger in the right to left order.", "response": "def del_pipers(self, pipers, *args, **kwargs):\n        \"\"\"\n        Deletes a sequence of ``Pipers`` instances from the ``Dagger`` in the\n        reverse of the specified order. Takes optional arguments for \n        ``Dagger.del_piper``.\n        \n        Arguments:\n        \n          - pipers (sequence of valid ``del_piper`` arguments) Sequence of \n            ``Pipers`` or valid ``Dagger.del_piper`` arguments to be removed \n            from the ``Dagger`` in the right to left order.\n\n        \"\"\"\n        pipers.reverse()\n        for piper in pipers:\n            self.del_piper(piper, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_pipes(self, pipes, *args, **kwargs):\n\n        for pipe in pipes:\n            self.add_pipe(pipe, *args, **kwargs)", "response": "Adds a sequence of pipes to the Dagger in the left to right order."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_pipes(self, pipes, *args, **kwargs):\n        for pipe in pipes:\n            self.del_pipe(pipe * args, **kwargs)", "response": "Deletes a sequence of pipes from the Dagger in the left to right order."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _finish(self, ispausing):\n        if ispausing:\n            self.log.debug('%s paused' % repr(self))\n        else:\n            self._finished.set()\n            self.log.debug('%s finished' % repr(self))", "response": "Internal method to set the flag that is set when the piper is finished."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _code(self):\n        icode, tcode = '', '' # imports, task code\n        icall, pcall = '', '' # imap calls, piper calls\n        tdone, idone = [], [] # task done, imap done\n\n        for piper in self:\n            p = piper\n            w = piper.worker\n            i = piper.imap\n            in_ = i.name if hasattr(i, 'name') else False\n            if in_ and in_ not in idone:\n                icall += I_SIG % (in_, i.worker_type, i.worker_num, i.stride, \\\n                                  i.buffer, i.ordered, i.skip, in_)\n                idone.append(in_)\n            ws = W_SIG % (\",\".join([t.__name__ for t in w.task]), w.args, w.kwargs)\n            pcall += P_SIG % (p.name, ws, in_, p.consume, p.produce, p.spawn, \\\n                              p.timeout, p.branch, p.debug, p.name, p.track)\n            for t in w.task:\n                if (t in tdone) or not t:\n                    continue\n                tm, tn = t.__module__, t.__name__\n                if (tm == '__builtin__') or hasattr(p, tn):\n                    continue\n                if tm == '__main__' or tm == self.filename:\n                    tcode += getsource(t)\n                else:\n                    icode += 'from %s import %s\\n' % (tm, tn)\n                tdone.append(t)\n\n        pipers = [p.name for p in self]\n        pipers = '[%s]' % \", \".join(pipers)\n        pipes = [L_SIG % (d.name, s.name) for s, d in self.edges()]\n        pipes = '[%s]' % \", \".join(pipes)                           # pipes\n        xtras = [str(self[p].xtra) for p in self]\n        xtras = '[%s]' % \",\".join(xtras)                            # node xtra\n        return (icode, tcode, icall, pcall, pipers, xtras, pipes)", "response": "Generates code for the internal pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, filename):\n        handle = open(filename, 'wb')\n        handle.write(P_LAY % self._code())\n        handle.close()", "response": "Saves the current pipeline source code as a Python source code file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, filename):\n        dir_name = os.path.dirname(filename)\n        mod_name = os.path.basename(filename).split('.')[0]\n        self.filename = mod_name\n        sys.path.insert(0, dir_name)\n        mod = __import__(mod_name)\n        sys.path.remove(dir_name) # do not pollute the path.\n        pipers, xtras, pipes = mod.pipeline()\n        self.add_pipers(pipers, xtras)\n        self.add_pipes(pipes)", "response": "Loads the instanciates pipeline from a source code file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self, datas):\n        if not self._started.isSet() and \\\n           not self._running.isSet() and \\\n           not self._pausing.isSet():\n            # Plumber statistics\n            self.stats = {}\n            self.stats['start_time'] = None\n            self.stats['run_time'] = None\n            # connects input pipers to external data\n            self.connect_inputs(datas)\n            # connects pipers within the pipeline\n            self.connect()\n            # make pointers to results collected for pipers by imaps\n            self.stats['pipers_tracked'] = {}\n            for piper in self.postorder():\n                if hasattr(piper.imap, '_tasks_tracked') and piper.track:\n                    self.stats['pipers_tracked'][piper] = \\\n                    [piper.imap._tasks_tracked[t.task] for t in piper.imap_tasks]\n\n            self.stats['start_time'] = time()\n            # starts the Dagger\n            # this starts Pipers and NuMaps\n            super(Plumber, self).start()\n            # transitioning to started state\n            self._started.set()\n            self._finished.clear()\n        else:\n            raise PlumberError", "response": "Starts the internal pipeline by connecting the input Pipers of the pipeline and starting the NuMaps of the internal pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        # remove non-block results for end tasks\n        if self._started.isSet() and \\\n           not self._running.isSet() and \\\n           not self._pausing.isSet() and \\\n           not self._finished.isSet():\n            stride = 1 # FIXME\n            tasks = self.get_outputs()\n            wtasks = _Weave(tasks, repeats=stride)\n            self._plunger = Thread(target=self._plunge, args=(wtasks, \\\n                            self._pausing.isSet, self._finish))\n            self._plunger.deamon = True\n            self._plunger.start()\n            self._running.set()\n        else:\n            raise PlumberError", "response": "Executes a started pipeline by pulling results from the pipeline s output \n        attribute and then processing the pipeline s output \n        attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait(self, timeout=None):\n        if self._started.isSet() and \\\n           self._running.isSet() and \\\n           not self._pausing.isSet():\n            self._finished.wait(timeout)\n        else:\n            raise PlumberError", "response": "Waits until the pipeline is finished."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npausing a running pipeline.", "response": "def pause(self):\n        \"\"\"\n        Pauses a running pipeline. This will stop retrieving results from the \n        pipeline. Parallel parts of the pipeline will stop after the ``NuMap`` \n        buffer is has been filled. A paused pipeline can be run or stopped. \n        \n        \"\"\"\n        # 1. stop the plumbing thread by raising a StopIteration on a stride \n        #    boundary\n        if self._started.isSet() and \\\n           self._running.isSet() and \\\n           not self._pausing.isSet():\n            self._pausing.set()\n            self._plunger.join()\n            del self._plunger\n            self._pausing.clear()\n            self._running.clear()\n        else:\n            raise PlumberError"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self):\n        if self._started.isSet() and \\\n           not self._running.isSet() and \\\n           not self._pausing.isSet():\n            # stops the dagger\n            super(Plumber, self).stop()\n            # disconnects all pipers\n            self.disconnect()\n            self.stats['run_time'] = time() - self.stats['start_time']\n            self._started.clear()\n        else:\n            raise PlumberError", "response": "Stops a paused pipeline and disconnects all pipers and nuMaps."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, stages=None):\n        # defaults differ linear vs. parallel\n        stages = stages or ((0,) if self.imap is imap else (0, 1, 2))\n        if not self.connected:\n            self.log.error('Piper %s is not connected.' % self)\n            raise PiperError('Piper %s is not connected.' % self)\n\n        if not self.started:\n            if 0 in stages:\n                self.tees.extend(tee(self, self.tee_num))\n\n        if hasattr(self.imap, 'start'):\n            # parallel piper\n            self.imap.start(stages)\n            if 2 in stages:\n                self.log.debug('Piper %s has been started using %s' % \\\n                              (self, self.imap))\n                self.started = True\n        else:\n            # linear piper\n            self.log.debug('Piper %s has been started using %s' % \\\n                          (self, self.imap))\n            self.started = True", "response": "Starts a new instance of a particular type of entry in the appropriate order."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(self, inbox):\n        if self.started:\n            self.log.error('Piper %s is started and cannot connect to %s.' % \\\n                           (self, inbox))\n            raise PiperError('Piper %s is started and cannot connect to %s.' % \\\n                             (self, inbox))\n        elif self.connected:\n            self.log.error('Piper %s is connected and cannot connect to %s.' % \\\n                           (self, inbox))\n            raise PiperError('Piper %s is connected and cannot connect to %s.' % \\\n                             (self, inbox))\n        elif hasattr(self.imap, '_started') and self.imap._started.isSet():\n            self.log.error('Piper %s cannot connect (NuMap is started).' % \\\n                           self)\n            raise PiperError('Piper %s cannot connect (NuMap is started).' % \\\n                           self)\n        else:\n            # not started and not connected and NuMap not started\n            self.log.debug('Piper %s connects to %s' % (self, inbox))\n            # determine the stride with which result will be consumed from the\n            # input.\n            stride = self.imap.stride if hasattr(self.imap, 'stride') else 1\n\n            # Tee input iterators. The idea is to create a promise object for a\n            # tee. The actual teed iterator will be created on start. Each tee\n            # is protected with a seperate lock the reasons for this are:\n            # - tee objects are as a collection not thread safe\n            # - tee objects might be next'ed from different threads, a single\n            #   lock will not guarantee that a thread might be allowed to finish\n            #   it's stride. (How it works that a thread releases the next \n            #   thread only if it finished a stride\n            teed = []\n            for piper in inbox:\n                if hasattr(piper, '_iter'): # isinstance Piper?\n                    piper.tee_num += 1\n                    tee_lock = Lock()\n                    tee_lock.acquire()\n                    piper.tee_locks.append(tee_lock)\n                    piper = _TeePiper(piper, piper.tee_num - 1, stride)\n                teed.append(_InputIterator(piper, self))\n\n            # set how much to consume from input iterators.\n            self.inbox = _Zip(*teed) if self.consume == 1 else\\\n                 _Consume(_Zip(*teed), n=self.consume, stride=stride)\n\n            # set how much to \n            for i in xrange(self.spawn):\n                self.imap_tasks.append(\\\n                    self.imap(self.worker, self.inbox) \\\n                        if self.imap is imap else \\\n                    self.imap(self.worker, self.inbox, timeout=self.timeout, \\\n                              track=self.track))\n            # chain the results together.\n            outbox = _Chain(self.imap_tasks, stride=stride)\n            # Make output\n            #prd = ProduceFromSequence if self.produce_from_sequence else Produce\n            if self.produce == 1:\n                self.outbox = outbox\n            elif self.repeat:\n                self.outbox = _Repeat(outbox, n=self.produce, stride=stride)\n            else:\n                self.outbox = _Produce(outbox, n=self.produce, stride=stride)\n            self.connected = True\n\n        return self", "response": "Connects the Piper instance to the upstream Pipers that should be given as a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the Piper instance and all its related NuMaps tasks.", "response": "def stop(self, forced=False, **kwargs):\n        \"\"\"\n        Attempts to cleanly stop the ``Piper`` instance. A ``Piper`` is \n        \"started\" if its  ``NuMap`` instance is \"started\". Non-parallel \n        ``Pipers`` do not have to be started or stopped. An ``NuMap`` instance\n        can be stopped by triggering its stopping procedure and retrieving \n        results from the ``NuMaps`` end tasks. Because neither the ``Piper`` nor\n        the ``NuMap`` \"knows\" which tasks i.e. ``Pipers`` are the end tasks \n        they have to be specified::\n        \n            end_task_ids = [0, 1]    # A list of NuMap task ids\n            piper_instance.stop(ends =end_task_ids)        \n        \n        results in::\n        \n            NuMap_instance.stop(ends =[0,1])\n            \n        If the ``Piper`` did not finish processing the data before the \n        stop method is called the \"forced\" argument has to be ``True``::\n        \n            piper_instance.stop(forced =True, ends =end_task_ids)\n            \n        If the ``Piper`` (and consequently ``NuMap``) is part of a ``Dagger`` \n        graph the ``Dagger.stop`` method should be called instead. See: \n        ``NuMap.stop`` and ``Dagger.stop``.\n        \n        # verify this:\n        # If \"forced\" is set ``True`` but the ends ``NuMap`` argument is not\n        # given. The ``NuMap`` instance will not try to retrieve any results and\n        # will not call the ``NuMap._stop`` method.\n        \n        Arguments:\n        \n          - forced(``bool``) [default: ``False``] The ``Piper`` will be forced \n            to stop the ``NuMap`` instance.\n            \n        Additional keyworded arguments are passed to the ``Piper.imap`` \n        instance.\n            \n        \"\"\"\n        # ends valid only if forced specified.\n        if not self.started:\n            self.log.error('Piper %s has not yet been started.' % self)\n            raise PiperError('Piper %s has not yet been started.' % self)\n        elif not self.finished and not forced:\n            msg = 'Piper %s has not finished. Use forced =True' % self\n            self.log.error(msg)\n            raise PiperError(msg)\n        else:\n            # started and (finished or forced)\n            if hasattr(self.imap, 'stop'):\n                self.imap.stop(forced=forced, **kwargs)\n            self.started = False\n            self.log.debug('Piper %s stops (finished: %s)' % \\\n                          (self, self.finished))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisconnecting the Piper instance from its upstream Pipers or input data.", "response": "def disconnect(self, forced=False):\n        \"\"\"\n        Disconnects the ``Piper`` instance from its upstream ``Pipers`` or \n        input data if the ``Piper`` is the input node of a pipeline.\n        \n        Arguments:\n        \n          - forced(``bool``) [default: ``False``] If ``True`` the ``Piper`` will\n            try to forcefully remove all tasks (including the spawned ones) from\n            the ``NuMap`` instance.\n             \n        \"\"\"\n        if not self.connected:\n            self.log.error('Piper %s is not connected and cannot be disconnected' % self)\n            raise PiperError('Piper %s is not connected and cannot be disconnected' % self)\n        elif self.started:\n            self.log.error('Piper %s is started and cannot be disconnected (stop first)' % self)\n            raise PiperError('Piper %s is started and cannot be disconnected (stop first)' % self)\n        elif hasattr(self.imap, '_started') and self.imap._started.isSet():\n            self.log.error('Piper %s cannot disconnect as its NuMap is started' % self)\n            raise PiperError('Piper %s cannot disconnect as its NuMap is started' % self)\n        else:\n            # connected and not started\n            if hasattr(self.imap, '_started'):\n                if self.imap._tasks == []:\n                    # fully stopped\n                    pass\n                elif self.imap_tasks[-1].task == len(self.imap._tasks) - 1:\n                    # the last task of this piper is the last task in the NuMap\n                    self.imap.pop_task(number=self.spawn)\n                elif forced:\n                    # removes all tasks from the NuMap can be called multiple \n                    # times.\n                    self.imap.pop_task(number=True)\n                else:\n                    msg = 'Piper %s is not the last Piper added to the NuMap' % \\\n                            self\n                    self.log.error(msg)\n                    raise PiperError(msg)\n            self.log.debug('Piper %s disconnected from %s' % (self, self.inbox))\n            self.imap_tasks = []\n            self.inbox = None\n            self.outbox = None\n            self.connected = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the next result from the internal queue.", "response": "def next(self):\n        \"\"\"\n        Returns the next result. If no result is availble within the specified \n        (during construction) \"timeout\" then a ``PiperError`` which wraps a  \n        ``TimeoutError`` is **returned**.\n\n        If the result is a ``WorkerError`` it is also wrapped in a \n        ``PiperError`` and is returned or raised if \"debug\" mode was specified \n        at initialization. If the result is a ``PiperError`` it is propagated.\n        \n        \"\"\"\n        try:\n            next = self.outbox.next()\n        except StopIteration, excp:\n            self.log.debug('Piper %s has processed all jobs (finished)' % self)\n            self.finished = True\n            # We re-raise StopIteration as part of the iterator protocol.\n            # And the outbox should do the same.\n            raise excp\n        except (AttributeError, RuntimeError), excp:\n            # probably self.outbox.next() is self.None.next()\n            self.log.error('Piper %s has not yet been started.' % self)\n            raise PiperError('Piper %s has not yet been started.' % self, excp)\n        except IndexError, excp:\n            # probably started before connected\n            self.log.error('Piper %s has been started before connect.' % self)\n            raise PiperError('Piper %s has been started before connect.' % self, excp)\n        except TimeoutError, excp:\n            self.log.error('Piper %s timed out waited %ss.' % \\\n                           (self, self.timeout))\n            next = PiperError(excp)\n            # we do not raise TimeoutErrors so they can be skipped.\n        if isinstance(next, WorkerError):\n            # return the WorkerError instance returned (not raised) by the\n            # worker Process.\n            self.log.error('Piper %s generated %s\"%s\" in func. %s on argument %s' % \\\n                     (self, type(next[0]), next[0], next[1], next[2]))\n            if self.debug:\n                # This makes only sense if you are debugging a piper as it will \n                # most probably crash papy and python NuMap worker processes \n                # threads will hang.\n                raise PiperError('Piper %s generated %s\"%s\" in func %s on argument %s' % \\\n                            (self, type(next[0]), next[0], next[1], next[2]))\n            next = PiperError(next)\n        elif isinstance(next, PiperError):\n            # Worker/PiperErrors are wrapped by workers\n            if self.debug:\n                raise next\n            self.log.debug('Piper %s propagates %s' % (self, next[0]))\n        return next"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _inject(self, conn):\n        # provide PAPY_DEFAULTS remotely\n        # provide PAPY_RUNTIME remotely\n        if not 'PAPY_INJECTED' in conn.namespace:\n            _inject_func(get_defaults, conn)\n            _inject_func(get_runtime, conn)\n            conn.execute('PAPY_DEFAULTS = get_defaults()')\n            conn.execute('PAPY_RUNTIME = get_runtime()')\n            conn.execute('PAPY_INJECTED = True')\n        # inject all functions\n        for func in self.task:\n            _inject_func(func, conn)\n        # create list of functions called TASK\n        # and inject a function comp_task which \n        _inject_func(_comp_task, conn)\n        conn.execute('TASK = %s' % \\\n                   str(tuple([i.__name__ for i in self.task])).replace(\"'\", \"\"))\n                    # ['func1', 'func2'] -> \"(func1, func2)\"\n        # inject compose function, will ...\n        self.task = [conn.namespace['_comp_task']]\n        self.args = [[self.args]]\n        self.kwargs = [{'kwargs':self.kwargs}]\n        # instead of multiple remote back and the combined functions is\n        # evaluated remotely.\n        return self", "response": "inject all functions into a rpyc connection object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the next sequence of results given stride and n.", "response": "def next(self):\n        \"\"\"\n        Returns the next sequence of results, given stride and n.\n        \n        \"\"\"\n        try:\n            results = self._stride_buffer.pop()\n        except (IndexError, AttributeError):\n            self._rebuffer()\n            results = self._stride_buffer.pop()\n        if not results:\n            raise StopIteration\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the next result from the chained iterables given stride.", "response": "def next(self):\n        \"\"\"\n        Returns the next result from the chained iterables given ``\"stride\"``.\n        \n        \"\"\"\n        if self.s:\n            self.s -= 1\n        else:\n            self.s = self.stride - 1\n            self.i = (self.i + 1) % self.l # new iterable\n        return self.iterables[self.i].next()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrefills the repeat buffer", "response": "def _rebuffer(self):\n        \"\"\"\n        (very internal) refill the repeat buffer\n        \"\"\"\n        results = []\n        exceptions = []\n        for i in xrange(self.stride):\n            try:\n                results.append(self.iterable.next())\n                exceptions.append(False)\n            except Exception, excp:\n                results.append(excp)\n                exceptions.append(True)\n        self._repeat_buffer = repeat((results, exceptions), self.n)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef next(self):\n        try:\n            res, excp = self._stride_buffer.next()\n        except (StopIteration, AttributeError):\n            try:\n                self._stride_buffer = izip(*self._repeat_buffer.next())\n            except (StopIteration, AttributeError):\n                self._rebuffer()\n                self._stride_buffer = izip(*self._repeat_buffer.next())\n            res, excp = self._stride_buffer.next()\n        if excp:\n            raise res\n        else:\n            return res", "response": "returns the next result given stride and n."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrefilling the repeat buffer", "response": "def _rebuffer(self):\n        \"\"\"\n        (internal) refill the repeat buffer\n        \n        \"\"\"\n        # collect a stride worth of results(result lists) or exceptions\n        results = []\n        exceptions = []\n        for i in xrange(self.stride):\n            try:\n                results.append(self.iterable.next())\n                exceptions.append(False)\n            except Exception, excp:\n                results.append(excp)\n                exceptions.append(True)\n        # un-roll the result lists\n        res_exc = []\n        for rep in xrange(self.n):\n            flat_results = []\n            for i in xrange(self.stride):\n                result_list, exception = results[i], exceptions[i]\n                if not exception:\n                    flat_results.append(result_list[rep])\n                else:\n                    flat_results.append(result_list)\n            res_exc.append((flat_results, exceptions))\n        # make an iterator (like repeat)\n        self._repeat_buffer = iter(res_exc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next(self):\n        if self.piper.imap is imap and \\\n           self.piper.started is False:\n            raise StopIteration\n        else:\n            return self.iterator.next()", "response": "returns the next result from the iterator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the next result from the wrappedPiper object for the wrappedPiper instance", "response": "def next(self):\n        \"\"\"\n        (internal) returns the next result from the ``itertools.tee`` object for\n        the wrapped ``Piper`` instance or re-raises an ``Exception``.\n        \n        \"\"\"\n        # do not acquire lock if NuMap is not finished.\n        if self.finished:\n            raise StopIteration\n        # get per-tee lock\n        self.piper.tee_locks[self.i].acquire()\n        # get result or exception\n        exception = True\n        try:\n            result = self.piper.tees[self.i].next()\n            exception = False\n        except StopIteration, result:\n            self.finished = True\n        except Exception, result:\n            pass\n        # release per-tee lock either self or next\n        if self.s == self.stride or self.finished:\n            self.s = 1\n            self.piper.tee_locks[(self.i + 1) % len(self.piper.tees)].release()\n\n        else:\n            self.s += 1\n            self.piper.tee_locks[self.i].release()\n        if exception:\n            raise result\n        else:\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_csv(self, filter=None, type=None, sort=None, limit=None, page=None): # pylint: disable=redefined-builtin\n        return self.service.list(self.base, filter, type, sort, limit, page, format='csv').text", "response": "Get a list of results as CSV."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef updates(self, id, update_id=None): # pylint: disable=invalid-name,redefined-builtin\n        if update_id is None:\n            update_id = -1\n        schema = UpdateSchema()\n        resp = self.service.get_id(self.base, id, params={'updates': update_id})\n        return self.service.decode(schema, resp)", "response": "Get updates of a running result."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pause(self, id, when=None): # pylint: disable=invalid-name,redefined-builtin\n        return self.service.post(self.base+str(id)+'/pause/', params={'when': when})", "response": "Pause a running result."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport a result. :param id: Result ID as an int. :param exclude_captures: If bool `True`, don't export capture files :rtype: tuple `(io.BytesIO, 'filename')`", "response": "def export(self, id, exclude_captures=False): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Export a result.\n\n        :param id: Result ID as an int.\n        :param exclude_captures: If bool `True`, don't export capture files\n        :rtype: tuple `(io.BytesIO, 'filename')`\n        \"\"\"\n        return self.service.export(self.base, id, params={'exclude_captures': exclude_captures})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bulk_export(self, ids, exclude_captures=False):\n        return self.service.bulk_export(self.base, ids, params={'exclude_captures': exclude_captures})", "response": "Bulk export a set of results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bulk_copy(self, ids):\n        schema = ResultSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)", "response": "Bulk copy a set of results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all_stats(self):\n        schema = AllStatsSchema()\n        resp = self.service.post(self.base, params={'stats': 'all'})\n        return self.service.decode(schema, resp)", "response": "Compute stats for all results."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes stats for a set of results.", "response": "def set_stats(self, ids):\n        \"\"\"Compute stats for a set of results.\n\n        :param id: Result IDs as int list.\n        :return: :class:`results.SetStats <results.SetStats>` object\n        :rtype: results.SetStats\n        \"\"\"\n        schema = SetStatsSchema()\n        resp = self.service.post(self.base, params={'stats': 'set'}, json=[{'id': str(x)} for x in ids])\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing diff stats for a set of results.", "response": "def diff_stats(self, ids):\n        \"\"\"Compute diff stats for a set of results.\n\n        :param id: Result IDs as int list.\n        :return: :class:`results.DiffStats <results.DiffStats>` object\n        :rtype: results.DiffStats\n        \"\"\"\n        schema = DiffStatsSchema()\n        resp = self.service.post(self.base, params={'stats': 'diff'}, json=[{'id': str(x)} for x in ids])\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef single_stats(self, id): # pylint: disable=invalid-name,redefined-builtin\n        schema = SingleStatsSchema()\n        resp = self.service.get(self.base+str(id)+'/', params={'stats': 'all'})\n        return self.service.decode(schema, resp)", "response": "Compute stats for a result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the progress stats for a result.", "response": "def progress_stats(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Compute progress stats for a result.\n\n        :param id: Result ID as an int.\n        :return: :class:`results.Progress <results.Progress>` object\n        :rtype: results.Progress\n        \"\"\"\n        schema = ProgressSchema()\n        resp = self.service.get(self.base+str(id)+'/', params={'stats': 'progress'})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summary_stats(self, id): # pylint: disable=invalid-name,redefined-builtin\n        schema = SummaryStatsSchema()\n        resp = self.service.get(self.base+str(id)+'/', params={'stats': 'summary'})\n        return self.service.decode(schema, resp)", "response": "Compute summary stats for a result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_logdir(self, id, filter=None, sort=None): # pylint: disable=invalid-name,redefined-builtin\n        schema = LogDirFileSchema()\n        resp = self.service.list(self.base+str(id)+'/logdir/', filter, sort)\n        return self.service.decode(schema, resp, many=True)", "response": "Get a list of logdir files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_logdir_file(self, id, filename): # pylint: disable=invalid-name,redefined-builtin\n        resp = self.service.get(self.base+str(id)+'/logdir/'+filename+'/', stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))", "response": "Download a logdir file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_logdir_archive(self, id, format='zip', exclude_captures=False): # pylint: disable=invalid-name,redefined-builtin\n        resp = self.service.get(self.base+str(id)+'/logdir/', params={'format': format, 'exclude_captures': exclude_captures}, stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))", "response": "Download logdir archive in tgz or zip format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_remote_by_client_id(client_id):\n    for remote in current_oauthclient.oauth.remote_apps.values():\n        if remote.name == 'cern' and remote.consumer_key == client_id:\n            return remote", "response": "Return a remote application based with given client ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare list of allowed group names.", "response": "def fetch_groups(groups):\n    \"\"\"Prepare list of allowed group names.\n\n    :param groups: The complete list of groups.\n    :returns: A filtered list of groups.\n    \"\"\"\n    hidden_groups = current_app.config.get(\n        'OAUTHCLIENT_CERN_HIDDEN_GROUPS', OAUTHCLIENT_CERN_HIDDEN_GROUPS)\n    hidden_groups_re = current_app.config.get(\n        'OAUTHCLIENT_CERN_HIDDEN_GROUPS_RE',\n        OAUTHCLIENT_CERN_HIDDEN_GROUPS_RE)\n    groups = [group for group in groups if group not in hidden_groups]\n    filter_groups = []\n    for regexp in hidden_groups_re:\n        for group in groups:\n            if regexp.match(group):\n                filter_groups.append(group)\n    groups = [group for group in groups if group not in filter_groups]\n\n    return groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_extra_data(resource):\n    person_id = resource.get('PersonID', [None])[0]\n    identity_class = resource.get('IdentityClass', [None])[0]\n    department = resource.get('Department', [None])[0]\n\n    return dict(\n        person_id=person_id,\n        identity_class=identity_class,\n        department=department\n    )", "response": "Return a dict with extra data retrieved from cern oauth."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch account groups and extra data from resource if necessary.", "response": "def account_groups_and_extra_data(account, resource,\n                                  refresh_timedelta=None):\n    \"\"\"Fetch account groups and extra data from resource if necessary.\"\"\"\n    updated = datetime.utcnow()\n    modified_since = updated\n    if refresh_timedelta is not None:\n        modified_since += refresh_timedelta\n    modified_since = modified_since.isoformat()\n    last_update = account.extra_data.get('updated', modified_since)\n\n    if last_update > modified_since:\n        return account.extra_data.get('groups', [])\n\n    groups = fetch_groups(resource['Group'])\n    extra_data = current_app.config.get(\n        'OAUTHCLIENT_CERN_EXTRA_DATA_SERIALIZER',\n        fetch_extra_data\n    )(resource)\n\n    account.extra_data.update(\n        groups=groups,\n        updated=updated.isoformat(),\n        **extra_data\n    )\n    return groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend_identity(identity, groups):\n    provides = set([UserNeed(current_user.email)] + [\n        RoleNeed('{0}@cern.ch'.format(name)) for name in groups\n    ])\n    identity.provides |= provides\n    session[OAUTHCLIENT_CERN_SESSION_KEY] = provides", "response": "Extend identity with roles based on CERN groups."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dict_from_response(response):\n    result = {}\n    if getattr(response, '_resp') and response._resp.code > 400:\n        return result\n\n    for i in response.data:\n        # strip the schema from the key\n        k = i['Type'].replace(REMOTE_APP_RESOURCE_SCHEMA, '')\n        result.setdefault(k, list())\n        result[k].append(i['Value'])\n    return result", "response": "Prepare new mapping with Value s groupped by Type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery CERN Resources to get user info and groups.", "response": "def get_resource(remote):\n    \"\"\"Query CERN Resources to get user info and groups.\"\"\"\n    cached_resource = session.pop('cern_resource', None)\n    if cached_resource:\n        return cached_resource\n\n    response = remote.get(REMOTE_APP_RESOURCE_API_URL)\n    dict_response = get_dict_from_response(response)\n    session['cern_resource'] = dict_response\n    return dict_response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef account_info(remote, resp):\n    resource = get_resource(remote)\n\n    valid_identities = current_app.config.get(\n        'OAUTHCLIENT_CERN_ALLOWED_IDENTITY_CLASSES',\n        OAUTHCLIENT_CERN_ALLOWED_IDENTITY_CLASSES\n    )\n    identity_class = resource.get('IdentityClass', [None])[0]\n    if identity_class is None or identity_class not in valid_identities:\n        raise OAuthCERNRejectedAccountError(\n            'Identity class {0} is not one of [{1}]'.format(\n                identity_class, ''.join(valid_identities)), remote, resp, )\n\n    email = resource['EmailAddress'][0]\n    person_id = resource.get('PersonID', [None])\n    external_id = resource.get('uidNumber', person_id)[0]\n    nice = resource['CommonName'][0]\n    name = resource['DisplayName'][0]\n\n    return dict(\n        user=dict(\n            email=email.lower(),\n            profile=dict(username=nice, full_name=name),\n        ),\n        external_id=external_id, external_method='cern',\n        active=True\n    )", "response": "Retrieve remote account information used to find local user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef disconnect_handler(remote, *args, **kwargs):\n    if not current_user.is_authenticated:\n        return current_app.login_manager.unauthorized()\n\n    account = RemoteAccount.get(user_id=current_user.get_id(),\n                                client_id=remote.consumer_key)\n    external_id = account.extra_data.get('external_id')\n\n    if external_id:\n        oauth_unlink_external_id(dict(id=external_id, method='cern'))\n    if account:\n        with db.session.begin_nested():\n            account.delete()\n\n    disconnect_identity(g.identity)\n\n    return redirect(url_for('invenio_oauthclient_settings.index'))", "response": "Handle unlinking of remote account."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming additional setup after user have been logged in.", "response": "def account_setup(remote, token, resp):\n    \"\"\"Perform additional setup after user have been logged in.\"\"\"\n    resource = get_resource(remote)\n\n    with db.session.begin_nested():\n        person_id = resource.get('PersonID', [None])\n        external_id = resource.get('uidNumber', person_id)[0]\n\n        # Set CERN person ID in extra_data.\n        token.remote_account.extra_data = {\n            'external_id': external_id,\n        }\n        groups = account_groups_and_extra_data(token.remote_account, resource)\n        assert not isinstance(g.identity, AnonymousIdentity)\n        extend_identity(g.identity, groups)\n\n        user = token.remote_account.user\n\n        # Create user <-> external id link.\n        oauth_link_external_id(user, dict(id=external_id, method='cern'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstore groups in session whenever identity changes.", "response": "def on_identity_changed(sender, identity):\n    \"\"\"Store groups in session whenever identity changes.\n\n    :param identity: The user identity where information are stored.\n    \"\"\"\n    if isinstance(identity, AnonymousIdentity):\n        return\n\n    client_id = current_app.config['CERN_APP_CREDENTIALS']['consumer_key']\n    account = RemoteAccount.get(\n        user_id=current_user.get_id(),\n        client_id=client_id,\n    )\n    groups = []\n    if account:\n        remote = find_remote_by_client_id(client_id)\n        resource = get_resource(remote)\n        refresh = current_app.config.get(\n            'OAUTHCLIENT_CERN_REFRESH_TIMEDELTA',\n            OAUTHCLIENT_CERN_REFRESH_TIMEDELTA\n        )\n\n        groups.extend(\n            account_groups_and_extra_data(account, resource,\n                                          refresh_timedelta=refresh)\n        )\n\n    extend_identity(identity, groups)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting RemoteAccount object for user.", "response": "def get(cls, user_id, client_id):\n        \"\"\"Get RemoteAccount object for user.\n\n        :param user_id: User id\n        :param client_id: Client id.\n        :returns: A :class:`invenio_oauthclient.models.RemoteAccount` instance.\n        \"\"\"\n        return cls.query.filter_by(\n            user_id=user_id,\n            client_id=client_id,\n        ).first()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new remote account for user.", "response": "def create(cls, user_id, client_id, extra_data):\n        \"\"\"Create new remote account for user.\n\n        :param user_id: User id.\n        :param client_id: Client id.\n        :param extra_data: JSON-serializable dictionary of any extra data that\n            needs to be save together with this link.\n        :returns: A :class:`invenio_oauthclient.models.RemoteAccount` instance.\n        \"\"\"\n        with db.session.begin_nested():\n            account = cls(\n                user_id=user_id,\n                client_id=client_id,\n                extra_data=extra_data or dict()\n            )\n            db.session.add(account)\n        return account"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_token(self, token, secret):\n        if self.access_token != token or self.secret != secret:\n            with db.session.begin_nested():\n                self.access_token = token\n                self.secret = secret\n                db.session.add(self)", "response": "Update the token with new values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(cls, user_id, client_id, token_type='', access_token=None):\n        args = [\n            RemoteAccount.id == RemoteToken.id_remote_account,\n            RemoteAccount.user_id == user_id,\n            RemoteAccount.client_id == client_id,\n            RemoteToken.token_type == token_type,\n        ]\n\n        if access_token:\n            args.append(RemoteToken.access_token == access_token)\n\n        return cls.query.options(\n            db.joinedload('remote_account')\n        ).filter(*args).first()", "response": "Get RemoteToken for user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_by_token(cls, client_id, access_token, token_type=''):\n        return cls.query.options(db.joinedload('remote_account')).filter(\n            RemoteAccount.id == RemoteToken.id_remote_account,\n            RemoteAccount.client_id == client_id,\n            RemoteToken.token_type == token_type,\n            RemoteToken.access_token == access_token,\n        ).first()", "response": "Get RemoteToken object for token."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new access token.", "response": "def create(cls, user_id, client_id, token, secret,\n               token_type='', extra_data=None):\n        \"\"\"Create a new access token.\n\n        .. note:: Creates RemoteAccount as well if it does not exists.\n\n        :param user_id: The user id.\n        :param client_id: The client id.\n        :param token: The token.\n        :param secret: The secret key.\n        :param token_type: The token type. (Default: ``''``)\n        :param extra_data: Extra data to set in the remote account if the\n            remote account doesn't exists. (Default: ``None``)\n        :returns: A :class:`invenio_oauthclient.models.RemoteToken` instance.\n\n        \"\"\"\n        account = RemoteAccount.get(user_id, client_id)\n\n        with db.session.begin_nested():\n            if account is None:\n                account = RemoteAccount(\n                    user_id=user_id,\n                    client_id=client_id,\n                    extra_data=extra_data or dict(),\n                )\n                db.session.add(account)\n\n            token = cls(\n                token_type=token_type,\n                remote_account=account,\n                access_token=token,\n                secret=secret,\n            )\n            db.session.add(token)\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbulking export a set of configs devices packages and results.", "response": "def bulk_export(self, config_ids=None, device_ids=None, package_ids=None, result_ids=None, exclude_captures=False):\n        \"\"\"Bulk export a set of configs, devices, packages and results.\n\n        :param config_ids: (optional) Int list of config IDs.\n        :param device_ids: (optional) Int list of device IDs.\n        :param package_ids: (optional) Int list of package IDs.\n        :param result_ids: (optional) Int list of result IDs.\n        :param exclude_captures: (optional) Exclude capture files if bool `True`.\n        :rtype: tuple `(io.BytesIO, 'filename')`\n        \"\"\"\n        if config_ids is None:\n            config_ids = []\n        if device_ids is None:\n            device_ids = []\n        if package_ids is None:\n            package_ids = []\n        if result_ids is None:\n            result_ids = []\n        json = {\n            'configs': map(int, config_ids),\n            'devices': map(int, device_ids),\n            'packages': map(int, package_ids),\n            'results': map(int, result_ids),\n            'options': {'exclude_captures': exclude_captures}\n        }\n        resp = self.service.post(self.base, json=json, stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_report(self):\n        self.sections = []\n        self.section_names = []\n\n\n        # if the directory already exists, print a warning\n        try:\n            if os.path.isdir(self.directory) is False:\n                if self.verbose:\n                    print(\"Created directory {}\".format(self.directory))\n                os.mkdir(self.directory)\n            # list of directories created in the constructor\n            for this in self._to_create:\n                try:\n                    os.mkdir(self.directory + os.sep + this)\n                except:\n                    pass # already created ?\n        except Exception:\n            pass\n        finally:\n            # Once the main directory is created, copy files required\n            temp_path = easydev.get_package_location(\"reports\")\n            temp_path += os.sep + \"reports\" + os.sep + \"resources\"\n\n            # Copy the CSS from reports/resources/css\n            filenames = glob.glob(os.sep.join([temp_path, \"css\", \"*.css\"]))\n\n            # If there are CSS in the directory with JINJA templates, use them\n            # as well\n            filenames += glob.glob(os.sep.join([self.searchpath, '*.css']))\n\n\n            # In addition, the user may also provide his own CSS as a list\n            filenames += self.extra_css_list\n            for filename in filenames:\n                target = os.sep.join([self.directory, 'css' ])\n                if os.path.isfile(target) is False:\n                    shutil.copy(filename, target)\n\n            # We copy all javascript from reports resources\n            for filename in ['sorttable.js', 'highlight.pack.js', \"jquery-1.12.3.min.js\"]:\n                target = os.sep.join([self.directory, 'js', filename ])\n                if os.path.isfile(target) is False:\n                    filename = os.sep.join([temp_path, \"javascript\", filename])\n                    shutil.copy(filename, target)\n            for filename in self.extra_js_list:\n                basename = os.path.basename(filename)\n                target = os.sep.join([self.directory, 'js', basename ])\n                if os.path.isfile(target) is False:\n                    shutil.copy(filename, target)", "response": "Create the report directory and return the directory name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a time stamp", "response": "def get_time_now(self):\n        \"\"\"Returns a time stamp\"\"\"\n        import datetime\n        import getpass\n        username = getpass.getuser()\n        # this is not working on some systems: os.environ[\"USERNAME\"]\n        timenow = str(datetime.datetime.now())\n        timenow = timenow.split('.')[0]\n        msg = '<div class=\"date\">Created on ' + timenow\n        msg += \" by \" + username +'</div>'\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_table_dependencies(self, package=\"reports\"):\n        dependencies = easydev.get_dependencies(package)\n        # TODO: Could re-use new method in HTMLTable for adding href\n        # but needs some extra work in the add_href method.\n        names = [x.project_name for x in dependencies]\n        versions = [x.version for x in dependencies]\n        links = [\"\"\"https://pypi.python.org/pypi/%s\"\"\" % p for p in names]\n        df = pd.DataFrame({\n            'package': [\"\"\"<a href=\"%s\">%s</a>\"\"\" % (links[i], p)\n                for i, p in enumerate(names)],\n            'version': versions})\n        table = HTMLTable(df, name=\"dependencies\", escape=False)\n        table.sort('package')\n        return table", "response": "Returns the dependencies of the pipeline as an HTML table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _track_class_related_field(cls, field):\n    # field = field on current model\n    # related_field = field on related model\n    (field, related_field) = field.split('__', 1)\n    field_obj = cls._meta.get_field(field)\n    related_cls = field_obj.remote_field.model\n    related_name = field_obj.remote_field.get_accessor_name()\n\n    if not hasattr(related_cls, '_tracked_related_fields'):\n        setattr(related_cls, '_tracked_related_fields', {})\n    if related_field not in related_cls._tracked_related_fields.keys():\n        related_cls._tracked_related_fields[related_field] = []\n\n    # There can be several field from different or same model\n    # related to a single model.\n    # Thus _tracked_related_fields will be of the form:\n    # {\n    #     'field name on related model': [\n    #         ('field name on current model', 'field name to current model'),\n    #         ('field name on another model', 'field name to another model'),\n    #         ...\n    #     ],\n    #     ...\n    # }\n\n    related_cls._tracked_related_fields[related_field].append(\n        (field, related_name)\n    )\n    _add_signals_to_cls(related_cls)\n    # Detect m2m fields changes\n    if isinstance(related_cls._meta.get_field(related_field), ManyToManyField):\n        m2m_changed.connect(\n            tracking_m2m,\n            sender=getattr(related_cls, related_field).through,\n            dispatch_uid=repr(related_cls),\n        )", "response": "Track a field on a related model"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _track_class_field(cls, field):\n    if '__' in field:\n        _track_class_related_field(cls, field)\n        return\n    # Will raise FieldDoesNotExist if there is an error\n    cls._meta.get_field(field)\n    # Detect m2m fields changes\n    if isinstance(cls._meta.get_field(field), ManyToManyField):\n        m2m_changed.connect(\n            tracking_m2m,\n            sender=getattr(cls, field).through,\n            dispatch_uid=repr(cls),\n        )", "response": "Track a field on the current model"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntracks fields on the specified model.", "response": "def _track_class(cls, fields):\n    \"\"\" Track fields on the specified model \"\"\"\n    # Small tests to ensure everything is all right\n    assert not getattr(cls, '_is_tracked', False)\n\n    for field in fields:\n        _track_class_field(cls, field)\n\n    _add_signals_to_cls(cls)\n\n    # Mark the class as tracked\n    cls._is_tracked = True\n    # Do not directly track related fields (tracked on related model)\n    # or m2m fields (tracked by another signal)\n    cls._tracked_fields = [\n        field for field in fields\n        if '__' not in field\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_get_tracking_url(cls):\n    def get_tracking_url(self):\n        \"\"\" return url to tracking view in admin panel \"\"\"\n        url = reverse('admin:tracking_fields_trackingevent_changelist')\n        object_id = '{0}%3A{1}'.format(\n            ContentType.objects.get_for_model(self).pk,\n            self.pk\n        )\n        return '{0}?object={1}'.format(url, object_id)\n    if not hasattr(cls, 'get_tracking_url'):\n        setattr(cls, 'get_tracking_url', get_tracking_url)", "response": "Add a method to get the tracking url of an object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef track(*fields):\n    def inner(cls):\n        _track_class(cls, fields)\n        _add_get_tracking_url(cls)\n        return cls\n    return inner", "response": "Decorator used to track changes on a specific field on a resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef indent(value, n=2, character=' '):\n\n    prefix = n * character\n    return '\\n'.join(prefix + line for line in value.splitlines())", "response": "Indent a string by n characters"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the documentation from the methods that have a __doc_meta__ attribute and saves the generated docs", "response": "def extract_docs():\n    \"\"\"\n    Parses the nano.rpc.Client for methods that have a __doc_meta__ attribute\n    and saves generated docs\n    \"\"\"\n\n    methods = []\n\n    def _key(entry):\n        return\n\n    sorted_entries = sorted(Client.__dict__.items(), key=lambda x: x[0])\n\n    tree = {}\n    meta_key = '__doc_meta__'\n\n    for attr_name, attr_value in sorted_entries:\n\n        if not hasattr(attr_value, meta_key):\n            continue\n\n        func = attr_value\n        meta = getattr(func, meta_key)\n\n        arg_spec = inspect.getargspec(func)\n        if arg_spec[0] and arg_spec[0][0] in ('cls', 'self'):\n            del arg_spec[0][0]\n\n        func_name = func.__name__\n        func_spec = func_name + inspect.formatargspec(*arg_spec)\n\n        doc = textwrap.dedent((func.__doc__ or ''))\n        doc = indent(doc, n=3)\n\n        func_desc_lines = []\n        for i, line in enumerate(func.__doc__.splitlines()):\n            if i == 0:\n                continue\n            func_desc_lines.append(line.strip())\n            if not line:\n                break\n        func_desc = ' '.join(func_desc_lines)\n\n        doc = textwrap.dedent(\n            \"\"\"\\\n            {func_name}\n            {func_name_line}\n\n            {func_desc}\n            :py:func:`nano.rpc.Client.{func_spec} <nano.rpc.Client.{func_name}>`\n\n            .. .. py:function:: nano.rpc.Client.{func_spec}\n\n            .. {doc}\n            \"\"\"\n        ).format(\n            func_spec=func_spec,\n            func_name_line='-' * len(func_name),\n            func_name=func_name,\n            func_desc=func_desc,\n            doc=doc,\n        )\n\n        categories = meta['categories']\n        for category in categories:\n            tree.setdefault(category, []).append(doc)\n\n    directory = 'rpc/methods'\n    for file in os.listdir(directory):\n        if file.endswith('.rst'):\n            os.unlink(os.path.join(directory, file))\n\n    for category, func_docs in sorted(tree.items(), key=lambda x: x[0]):\n        category = category or 'other'\n        file_path = os.path.join(directory, category) + '.rst'\n        with open(file_path, 'w') as docfile:\n            docfile.write('.. _%s-ref:\\n' % category + '\\n')\n            title = '{category}'.format(category=category.capitalize())\n            docfile.write('%s\\n' % title)\n            docfile.write('%s\\n' % (len(title) * '='))\n            docfile.write('\\n')\n\n            for func_doc in func_docs:\n                docfile.write(func_doc + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_instance(function):\n        def wrapper(self, *args, **kwargs):\n            func_trans = {\n                \"commit\": manager.Manager,\n                \"compare_config\": manager.Manager,\n                \"commit_check\": manager.Manager,\n                \"device_info\": manager.Manager,\n                \"diff_config\": manager.Manager,\n                \"health_check\": manager.Manager,\n                \"interface_errors\": manager.Manager,\n                \"op_cmd\": paramiko.client.SSHClient,\n                \"shell_cmd\": paramiko.client.SSHClient,\n                \"scp_pull\": paramiko.client.SSHClient,\n                \"scp_push\": paramiko.client.SSHClient\n            }\n            # when doing an operational command, logging in as root\n            # brings you to shell, so we need to enter the device as a shell\n            # connection, and move to cli to perform the command\n            # this is a one-off because the isinstance() check will be bypassed\n            if self.username == \"root\" and function.__name__ == \"op_cmd\":\n                if not self._session:\n                    self.conn_type = \"paramiko\"\n                    self.connect()\n                if not self._shell:\n                    self.conn_type = \"root\"\n                    self.connect()\n                self.shell_to_cli()  # check if we're in the cli\n            # Have to call shell command separately, since we are using _shell\n            # for comparison, not _session.\n            elif function.__name__ == 'shell_cmd':\n                if not self._shell:\n                    self.conn_type = \"shell\"\n                    self.connect()\n                self.cli_to_shell()  # check if we're in shell.\n            if isinstance(self._session, func_trans[function.__name__]):\n                # If they're doing SCP, we have to check for both _session and\n                # _scp\n                if function.__name__ in ['scp_pull', 'scp_push']:\n                    if not isinstance(self._scp, SCPClient):\n                        self.conn_type = \"scp\"\n                        self.connect()\n            else:\n                self.disconnect()\n                if function.__name__ == \"op_cmd\":\n                    self.conn_type = \"paramiko\"\n                elif function.__name__ in [\"scp_pull\", \"scp_push\"]:\n                    self.conn_type = \"scp\"\n                else:\n                    self.conn_type = \"ncclient\"\n                self.connect()\n            return function(self, *args, **kwargs)\n        return wrapper", "response": "Decorator that tests the type of _session and _shell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving _shell to the shell.", "response": "def cli_to_shell(self):\n        \"\"\" Move _shell to the shell from the command line interface (CLI). \"\"\"\n        if self._in_cli:\n            self._shell.send(\"start shell\\n\")\n            time.sleep(2)\n            self._shell.recv(9999)\n            self._in_cli = False\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef commit(self, commands=\"\", confirmed=None, comment=None,\n               at_time=None, synchronize=False, req_format='text'):\n        \"\"\" Perform a commit operation.\n\n        Purpose: Executes a commit operation. All parameters are optional.\n               | commit confirm and commit at are mutually exclusive. All\n               | the others can be used with each other and commit confirm/at.\n\n        @param commands: A string or list of multiple commands\n                       | that the device will compare with.\n                       | If a string, it can be a single command,\n                       | multiple commands separated by commas, or\n                       | a filepath location of a file with multiple\n                       | commands, each on its own line.\n        @type commands: str or list\n        @param confirmed: integer value of the number of **seconds** to\n                             | confirm the commit for, if requested.\n        @type confirmed: int\n        @param comment: string that the user wants to comment the commit\n                      | with. Will show up in the 'show system commit' log.\n        @type comment: str\n        @param at_time: string designating the time at which the commit\n                      | should happen. Can be in one of two Junos approved\n                      | formats.\n        @type comment: str\n        @param synchronize: boolean set to true if desiring a commit\n                          | synchronize operation.\n        @type synchronize: bool\n        @param req_format: string to specify the response format. Accepts\n                         | either 'text' or 'xml'\n        @type req_format: str\n\n        @returns: The reply from the device.\n        @rtype: str\n        \"\"\"\n        # ncclient doesn't support a truly blank commit, so if nothing is\n        # passed, use 'annotate system' to make a blank commit\n        if not commands:\n            commands = 'annotate system \"\"'\n        clean_cmds = []\n        for cmd in clean_lines(commands):\n            clean_cmds.append(cmd)\n        # try to lock the candidate config so we can make changes.\n        self.lock()\n        self._session.load_configuration(action='set', config=commands)\n        results = \"\"\n        # confirmed and commit at are mutually exclusive. commit confirm\n        # takes precedence.\n        if confirmed:\n            results = self._session.commit(confirmed=True,\n                                           timeout=str(confirmed),\n                                           comment=comment,\n                                           synchronize=synchronize)\n        else:\n            results = self._session.commit(comment=comment, at_time=at_time,\n                                           synchronize=synchronize)\n        self.unlock()\n        if results:\n            if req_format == 'xml':\n                return results\n            # commit() DOES NOT return a parse-able xml tree, so we\n            # convert it to an ElementTree xml tree.\n            results = ET.fromstring(results.tostring)\n            out = ''\n            for i in results.iter():\n                # the success message is just a tag, so we need to get it\n                # specifically.\n                if i.tag == 'commit-check-success':\n                    out += 'configuration check succeeds\\n'\n                elif i.tag == 'commit-success':\n                    out += 'commit complete\\n'\n                elif i.tag == 'ok':\n                    out += 'commit complete\\n'\n                # this is for normal output with a tag and inner text, it will\n                # strip the inner text and add it to the output.\n                elif i.text is not None:\n                    if i.text.strip() + '\\n' != '\\n':\n                        out += i.text.strip() + '\\n'\n                # this is for elements that don't have inner text,\n                # it will add the tag to the output.\n                elif i.text is None:\n                    if i.tag + '\\n' != '\\n':\n                        out += i.tag + '\\n'\n            return out\n        return False", "response": "Perform a commit operation on the ncclient device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a commit check operation on the device.", "response": "def commit_check(self, commands=\"\", req_format=\"text\"):\n        \"\"\" Execute a commit check operation.\n\n        Purpose: This method will take in string of multiple commands,\n               | and perform and 'commit check' on the device to ensure\n               | the commands are syntactically correct. The response can\n               | be formatted as text or as xml.\n\n        @param commands: A string, filepath, or list of multiple commands\n                       | that the device will compare with.\n        @type commands: str or list\n        @param req_format: The desired format of the response, defaults to\n                         | 'text', but also accepts 'xml'\n        @type req_format: str\n\n        @returns: The reply from the device.\n        @rtype: str\n        \"\"\"\n        if not commands:\n            raise InvalidCommandError('No commands specified')\n        clean_cmds = []\n        for cmd in clean_lines(commands):\n            clean_cmds.append(cmd)\n        self.lock()\n        self._session.load_configuration(action='set', config=clean_cmds)\n        # conn.validate() DOES NOT return a parse-able xml tree, so we\n        # convert it to an ElementTree xml tree.\n        results = ET.fromstring(self._session.validate(\n            source='candidate').tostring)\n        # release the candidate configuration\n        self.unlock()\n        if req_format == \"xml\":\n            return ET.tostring(results)\n        out = \"\"\n        # we have to parse the elementTree object, and get the text\n        # from the xml.\n        for i in results.iter():\n            # the success message is just a tag, so we need to get it\n            # specifically.\n            if i.tag == 'commit-check-success':\n                out += 'configuration check succeeds\\n'\n            # this is for normal output with a tag and inner text, it will\n            # strip the inner text and add it to the output.\n            elif i.text is not None:\n                if i.text.strip() + '\\n' != '\\n':\n                    out += i.text.strip() + '\\n'\n            # this is for elements that don't have inner text, it will add the\n            # tag to the output.\n            elif i.text is None:\n                if i.tag + '\\n' != '\\n':\n                    out += i.tag + '\\n'\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compare_config(self, commands=\"\", req_format=\"text\"):\n        if not commands:\n            raise InvalidCommandError('No commands specified')\n        clean_cmds = [cmd for cmd in clean_lines(commands)]\n        self.lock()\n        self._session.load_configuration(action='set', config=clean_cmds)\n        out = self._session.compare_configuration()\n        self.unlock()\n        if req_format.lower() == \"xml\":\n            return out\n        return out.xpath(\n            'configuration-information/configuration-output')[0].text", "response": "Execute a show | compare against the specified commands."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self):\n        if self.conn_type == 'paramiko':\n            self._session = paramiko.SSHClient()\n            # These two lines set the paramiko logging to Critical to\n            # remove extra messages from being sent to the user output.\n            logger = logging.Logger.manager.getLogger('paramiko.transport')\n            logger.setLevel(logging.CRITICAL)\n            self._session.set_missing_host_key_policy(\n                paramiko.AutoAddPolicy())\n            self._session.connect(hostname=self.host,\n                                  username=self.username,\n                                  password=self.password,\n                                  port=self.port,\n                                  timeout=self.connect_timeout)\n        if self.conn_type == 'scp':\n            self._scp_session = paramiko.SSHClient()\n            logger = logging.Logger.manager.getLogger('paramiko.transport')\n            logger.setLevel(logging.CRITICAL)\n            self._scp_session.set_missing_host_key_policy(\n                paramiko.AutoAddPolicy())\n            self._scp_session.connect(hostname=self.host,\n                                      username=self.username,\n                                      password=self.password,\n                                      port=self.port,\n                                      timeout=self.connect_timeout)\n            self._scp = SCPClient(self._scp_session.get_transport())\n        elif self.conn_type == \"ncclient\":\n            self._session = manager.connect(\n                host=self.host,\n                port=self.port,\n                username=self.username,\n                password=self.password,\n                timeout=self.connect_timeout,\n                device_params={'name': 'junos'},\n                hostkey_verify=False\n            )\n        elif self.conn_type == 'shell':\n            if not self._session:\n                self.conn_type = 'paramiko'\n                self.connect()\n                self.conn_type = 'shell'\n            if not self._shell:\n                self._shell = self._session.invoke_shell()\n                time.sleep(2)\n                if self.username != 'root' and not self._in_cli:\n                    self._in_cli = True\n            if not self.cli_to_shell():\n                self._shell.recv(9999)\n        elif self.conn_type == 'root':\n            # open the shell if necessary, and move into CLI\n            if not self._shell:\n                self._shell = self._session.invoke_shell()\n                time.sleep(2)\n            if not self.shell_to_cli():\n                self._shell.recv(9999)\n        self._update_timeout(self.session_timeout)", "response": "Establish a connection to the junos device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _copy_status(self, filename, size, sent):\n        output = \"Transferred %.0f%% of the file %s\" % (\n            (float(sent) / float(size) * 100), path.normpath(filename))\n        output += (' ' * (120 - len(output)))\n        if filename != self._filename:\n            if self._filename is not None:\n                print('')\n            self._filename = filename\n        print(output, end='\\r')", "response": "Echo the status of an actively running copy."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef device_info(self):\n        # get hostname, model, and version from 'show version'\n        resp = self._session.get_software_information(format='xml')\n\n        hostname = resp.xpath('//software-information/host-name')[0].text\n        model = resp.xpath('//software-information/product-model')[0].text\n\n        version = 'Unknown'\n        if resp.xpath('//junos-version'):\n            \"\"\" case:\n                <junos-version>15.1</junos-version>\n            \"\"\"\n            try:\n                version = resp.xpath('//junos-version')[0].text\n            except IndexError:\n                pass\n        elif resp.xpath(\"//package-information[name = 'junos-version']\"):\n            \"\"\" case:\n                <package-information>\n                    <name>junos-version</name>\n                    <comment>Junos: 14.2R4</comment>\n                </package-information>\n           \"\"\"\n            try:\n                version = (resp.xpath(\n                    \"//package-information[name = 'junos-version']/comment\"\n                    )[0].text).split()[1]\n            except IndexError:\n                pass\n        else:\n            \"\"\" case:\n                <package-information>\n                    <name>junos</name>\n                    <comment>JUNOS Base OS boot [12.3R5]</comment>\n                </package-information>\n            \"\"\"\n            try:\n                version = ((resp.xpath(\n                    '//software-information/package-information/comment'\n                    )[0].text.split('[')[1].split(']')[0]))\n            except IndexError:\n                pass\n\n        # try looking for 'junos-version' for >= 14.2\n#        for element in resp.xpath('//software-information'):\n#            version = element.findtext('junos-version')\n\n#        if not version:\n#            try:\n#                version = ((resp.xpath(\n#                    '//software-information/package-information/comment')\n#                    [0].text.split('[')[1].split(']')[0]))\n#            except IndexError:\n#                version = 'Unknown'\n\n        # get uptime from 'show system uptime'\n        resp = self._session.get_system_uptime_information(format='xml')\n        try:\n            current_time = resp.xpath('//current-time/date-time')[0].text\n        except IndexError:\n            current_time = 'Unknown'\n        try:\n            uptime = resp.xpath('//uptime-information/up-time')[0].text\n        except IndexError:\n            uptime = 'Unknown'\n        # get serial number from 'show chassis hardware'\n        show_hardware = self._session.get_chassis_inventory(format='xml')\n        # If we're hitting an EX, grab each Routing Engine Serial number\n        # to get all RE SNs in a VC\n        try:\n            chassis_module = show_hardware.xpath(\n                '//chassis-inventory/chassis/chassis-module/description'\n                )[0].text\n        except IndexError:\n            chassis_module = 'Unknown'\n\n        if ('EX' or 'ex' or 'Ex') in chassis_module:\n            serial_num = ''\n            for eng in show_hardware.xpath(\n                    '//chassis-inventory/chassis/chassis-module'):\n                if 'Routing Engine' in eng.xpath('name')[0].text:\n                    serial_num += (eng.xpath('name')[0].text + ' Serial #: ' +\n                                   eng.xpath('serial-number')[0].text)\n        else:  # Any other device type, just grab chassis SN\n            try:\n                serial_num = ('Chassis Serial Number: ' + show_hardware.xpath(\n                    '//chassis-inventory/chassis/serial-number')[0].text)\n            except IndexError:\n                serial_num = 'Chassis Serial Number: ' \\\n                    + 'Unknown (virtual machine?)'\n        return ('Hostname: %s\\nModel: %s\\nJunos Version: %s\\n%s\\nCurrent Time:'\n                ' %s\\nUptime: %s\\n' %\n                (hostname, model, version, serial_num, current_time, uptime))", "response": "Pull basic device information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef diff_config(self, second_host, mode='stanza'):\n        second_conn = manager.connect(\n            host=second_host,\n            port=self.port,\n            username=self.username,\n            password=self.password,\n            timeout=self.connect_timeout,\n            device_params={'name': 'junos'},\n            hostkey_verify=False\n        )\n\n        command = 'show configuration'\n        if mode == 'set':\n            command += ' | display set'\n\n        # get the raw xml config\n        config1 = self._session.command(command, format='text')\n        # for each /configuration-output snippet, turn it to text and join them\n        config1 = ''.join([snippet.text.lstrip('\\n') for snippet in\n                          config1.xpath('//configuration-output')])\n\n        config2 = second_conn.command(command, format='text')\n        config2 = ''.join([snippet.text.lstrip('\\n') for snippet in\n                          config2.xpath('//configuration-output')])\n\n        return difflib.unified_diff(config1.splitlines(), config2.splitlines(),\n                                    self.host, second_host)", "response": "Generate configuration differences with a second device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disconnect(self):\n        if self._shell:\n            self._shell.close()\n            self._shell = \"\"\n        if isinstance(self._session, manager.Manager):\n            self._session.close_session()\n        elif isinstance(self._session, paramiko.client.SSHClient):\n            self._session.close()\n            self._session = \"\"\n        elif isinstance(self._session, SCPClient):\n            self._session.close()\n            self._session = \"\"\n            self._scp = \"\"", "response": "Closes the current connection to the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _error_parse(self, interface, face):\n        try:\n            error_list = interface.xpath(face + '-error-list')[0].getchildren()\n        except IndexError:  # no error list on this interface\n            pass\n        else:\n            for x in range(len(error_list)):\n                if error_list[x].tag == \"carrier-transitions\":\n                    if int(error_list[x].text.strip()) > 50:\n                        yield \" has greater than 50 flaps.\"\n                elif int(error_list[x].text.strip()) > 0:\n                    yield \" has %s of %s.\" % (error_list[x].text.strip(),\n                                              error_list[x].tag.strip())", "response": "Parse the extensive xml output of an interface and yield the error types that have a significant number of errors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the health and alarm information from the device.", "response": "def health_check(self):\n        \"\"\" Pull health and alarm information from the device.\n\n        Purpose: Grab the cpu/mem usage, system/chassis alarms, top 5\n               | processes, and states if the primary/backup partitions are on\n               | different versions.\n\n        @returns: The output that should be shown to the user.\n        @rtype: str\n        \"\"\"\n        output = 'Chassis Alarms:\\n\\t'\n        # Grab chassis alarms, system alarms, show chassis routing-engine,\n        # 'show system processes extensive', and also xpath to the\n        # relevant nodes on each.\n        chassis_alarms = self._session.command(\"show chassis alarms\")\n        chassis_alarms = chassis_alarms.xpath('//alarm-detail')\n        system_alarms = self._session.command(\"show system alarms\")\n        system_alarms = system_alarms.xpath('//alarm-detail')\n        chass = self._session.command(command=\"show chassis routing-engine\",\n                                      format='text').xpath('//output')[0].text\n        proc = self._session.command(\"show system processes extensive\")\n        proc = proc.xpath('output')[0].text.split('\\n')\n        if chassis_alarms == []:  # Chassis Alarms\n            output += 'No chassis alarms active.\\n'\n        else:\n            for i in chassis_alarms:\n                output += (i.xpath('alarm-class')[0].text.strip() + ' Alarm \\t'\n                           '\\t' + i.xpath('alarm-time')[0].text.strip() +\n                           '\\n\\t' +\n                           i.xpath('alarm-description')[0].text.strip() + '\\n')\n        output += '\\nSystem Alarms: \\n\\t'\n        if system_alarms == []:  # System Alarms\n            output += 'No system alarms active.\\n'\n        else:\n            for i in system_alarms:\n                output += (i.xpath('alarm-class')[0].text.strip() + ' Alarm '\n                           '\\t\\t' + i.xpath('alarm-time')[0].text.strip() +\n                           '\\n\\t' +\n                           i.xpath('alarm-description')[0].text.strip() + '\\n')\n        # add the output of the show chassis routing-engine to the command.\n        output += '\\n' + chass\n        # Grabs the top 5 processes and the header line.\n        output += ('\\n\\nTop 5 busiest processes (high mgd values likely from '\n                   'script execution):\\n')\n        for line_number in range(8, 14):\n            output += proc[line_number] + '\\n'\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing show interfaces extensive and return interfaces with errors.", "response": "def interface_errors(self):\n        \"\"\" Parse 'show interfaces extensive' and return interfaces with errors.\n\n        Purpose: This function is called for the -e flag. It will let the user\n               | know if there are any interfaces with errors, and what those\n               | interfaces are.\n\n        @returns: The output that should be shown to the user.\n        @rtype: str\n        \"\"\"\n        output = []  # used to store the list of interfaces with errors.\n        # get a string of each physical and logical interface element\n        dev_response = self._session.command('sh interfaces extensive')\n        ints = dev_response.xpath('//physical-interface')\n        ints += dev_response.xpath('//logical-interface')\n        for i in ints:\n            # Grab the interface name for user output.\n            int_name = i.xpath('name')[0].text.strip()\n            # Only check certain interface types.\n            if (('ge' or 'fe' or 'ae' or 'xe' or 'so' or 'et' or 'vlan' or\n                 'lo0' or 'irb') in int_name):\n                try:\n                    status = (i.xpath('admin-status')[0].text.strip() +\n                              '/' + i.xpath('oper-status')[0].text.strip())\n                except IndexError:\n                    pass\n                else:\n                    for error in self._error_parse(i, \"input\"):\n                        output.append(\"%s (%s)%s\" % (int_name, status,\n                                                     error))\n                    for error in self._error_parse(i, \"output\"):\n                        output.append(\"%s (%s)%s\" % (int_name, status,\n                                                     error))\n        if output == []:\n            output.append('No interface errors were detected on this device.')\n        return '\\n'.join(output) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lock(self):\n        if isinstance(self._session, manager.Manager):\n            self._session.lock()", "response": "Lock the candidate config. Requires ncclient. manager. Manager"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes an operational mode command.", "response": "def op_cmd(self, command, req_format='text', xpath_expr=\"\"):\n        \"\"\" Execute an operational mode command.\n\n        Purpose: Used to send an operational mode command to the connected\n               | device. This requires and uses a paramiko.SSHClient() as\n               | the handler so that we can easily pass and allow all pipe\n               | commands to be used.\n               |\n               | We indiscriminately attach ' | no-more' on the end of\n               | every command so the device doesn't hold output. The\n               | req_format parameter can be set to 'xml' to force raw\n               | xml output in the reply.\n\n        @param command: The single command that to retrieve output from the\n                      | device. Any pipes will be taken into account.\n        @type command: str\n        @param req_format: The desired format of the response, defaults to\n                         | 'text', but also accepts 'xml'. **NOTE**: 'xml'\n                         | will still return a string, not a libxml ElementTree\n        @type req_format: str\n\n        @returns: The reply from the device.\n        @rtype: str\n        \"\"\"\n        if not command:\n            raise InvalidCommandError(\"Parameter 'command' cannot be empty\")\n        if req_format.lower() == 'xml' or xpath_expr:\n            command = command.strip() + ' | display xml'\n        command = command.strip() + ' | no-more\\n'\n        out = ''\n        # when logging in as root, we use _shell to get the response.\n        if self.username == 'root':\n            self._shell.send(command)\n            time.sleep(3)\n            while self._shell.recv_ready():\n                out += self._shell.recv(999999)\n                time.sleep(.75)\n            # take off the command being sent and the prompt at the end.\n            out = '\\n'.join(out.split('\\n')[1:-2])\n        # not logging in as root, and can grab the output as normal.\n        else:\n            stdin, stdout, stderr = self._session.exec_command(command=command,\n                                           timeout=float(self.session_timeout))\n            stdin.close()\n            # read normal output\n            while not stdout.channel.exit_status_ready():\n                out += stdout.read()\n            stdout.close()\n            # read errors\n            while not stderr.channel.exit_status_ready():\n                out += stderr.read()\n            stderr.close()\n        return out if not xpath_expr else xpath(out, xpath_expr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scp_pull(self, src, dest, progress=False, preserve_times=True):\n        # set up the progress callback if they want to see the process\n        if progress is True:\n            self._scp._progress = self._copy_status\n        # redirect to another function\n        elif hasattr(progress, '__call__'):\n            self._scp._progress = progress\n        else:  # no progress callback\n            self._scp._progress = None\n        # retrieve the file(s)\n        self._scp.get(src, dest, recursive=True, preserve_times=preserve_times)\n        self._filename = None\n        return False", "response": "This method is used to make an SCP pull request for the specified file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npush the contents of src to dest.", "response": "def scp_push(self, src, dest, progress=False, preserve_times=True):\n        \"\"\" Purpose: Makes an SCP push request for the specified file(s)/dir.\n\n        @param src: string containing the source file or directory\n        @type src: str\n        @param dest: destination string of where to put the file(s)/dir\n        @type dest: str\n        @param progress: set to `True` to have the progress callback be\n                       | printed as the operation is copying. Can also pass\n                       | a function pointer to handoff the progress callback\n                       | elsewhere.\n        @type progress: bool or function pointer\n        @param preserve_times: Set to false to have the times of the copied\n                             | files set at the time of copy.\n        @type preserve_times: bool\n\n        @returns: `True` if the copy succeeds.\n        @rtype: bool\n        \"\"\"\n        # set up the progress callback if they want to see the process\n        if progress is True:\n            self._scp._progress = self._copy_status\n        # redirect to another function\n        elif hasattr(progress, '__call__'):\n            self._scp._progress = progress\n        else:  # no progress callback\n            self._scp._progress = None\n        # push the file(s)\n        self._scp.put(src, dest, recursive=True, preserve_times=preserve_times)\n        self._filename = None\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shell_cmd(self, command=\"\"):\n        if not command:\n            raise InvalidCommandError(\"Parameter 'command' must not be empty.\")\n        command = command.strip() + '\\n'\n        self._shell.send(command)\n        time.sleep(2)\n        out = ''\n        while self._shell.recv_ready():\n            out += self._shell.recv(999999)\n            time.sleep(.75)\n        # take off the command being sent and the prompt at the end.\n        return '\\n'.join(out.split('\\n')[1:-1])", "response": "Execute a single command to the connected device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unlock(self):\n        if isinstance(self._session, manager.Manager):\n            self._session.unlock()", "response": "Unlocks the candidate configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef basic_cleanup(self):\n    next_expire = None\n    keys_to_delete = []\n    if self.expire is not None and self.expire > 0:\n        # cleanup invalid cache item until the meet valid cache item and record next expire time\n        for k, item in self.cache_items.items():\n            if item.is_dead():\n                keys_to_delete.append(k)\n            else:\n                next_expire = item.remaining_survival_time()\n                break\n\n    # if direct delete will to cause an error: OrderedDict mutated during iteration\n    # so use delay delete\n    for k in keys_to_delete:\n        self.cache_items.pop(k)\n\n    # if reach the upper limit of capacity then will execute evict by eviction strategy\n    while (len(self.cache_items) > self.capacity):\n        evicted_keys = self.evict_func(cache_dict=self.cache_items, evict_number=self.evict_number)\n        self.logger.debug('Evict operation is completed, count: %s, keys: %s' % (len(evicted_keys), evicted_keys))\n\n    return next_expire", "response": "This function is used to clean up the cache items and return the next expire time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nintercept an existing method on an object with the provided generator.", "response": "def intercept(obj, methodname, wrapper):\n    \"\"\"\n    Wraps an existing method on an object with the provided generator, which\n    will be \"sent\" the value when it yields control.\n\n    ::\n\n        >>> def ensure_primary_key_is_set():\n        ...     assert model.pk is None\n        ...     saved = yield\n        ...     aasert model is saved\n        ...     assert model.pk is not None\n        ...\n        >>> intercept(model, 'save', ensure_primary_key_is_set)\n        >>> model.save()\n\n    :param obj: the object that has the method to be wrapped\n    :type obj: :class:`object`\n    :param methodname: the name of the method that will be wrapped\n    :type methodname: :class:`str`\n    :param wrapper: the wrapper\n    :type wrapper: generator callable\n    \"\"\"\n    original = getattr(obj, methodname)\n\n    def replacement(*args, **kwargs):\n        wrapfn = wrapper(*args, **kwargs)\n        wrapfn.send(None)\n        result = original(*args, **kwargs)\n        try:\n            wrapfn.send(result)\n        except StopIteration:\n            return result\n        else:\n            raise AssertionError('Generator did not stop')\n\n    def unwrap():\n        \"\"\"\n        Restores the method to it's original (unwrapped) state.\n        \"\"\"\n        setattr(obj, methodname, original)\n\n    replacement.unwrap = unwrap\n\n    setattr(obj, methodname, replacement)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef imports(modules, forgive=False):\n    def wrap(f):\n        if modules:\n            # attach import to function\n            setattr(f, 'imports', modules)\n            for alternatives in modules:\n                # alternatives are comma seperated\n                alternatives = alternatives.split(',')\n                # we import the part of the import X.Y.Z -> Z\n                mod_name = alternatives[0].split('.')[-1]\n                for mod in alternatives:\n                    mod = mod.strip().split('.')\n\n                    try:\n                        if len(mod) == 1:\n                            module = __import__(mod[0])\n                        else:\n                            module = getattr(__import__('.'.join(mod[:-1]), \\\n                                            fromlist=[mod[-1]]), mod[-1])\n                        f.func_globals[mod_name] = module\n                        break # import only one\n                    except ImportError:\n                        pass\n                else:\n                    if forgive: # no break -> no import\n                        warnings.warn('Failed to import %s' % alternatives)\n                    else:\n                        raise ImportError('Failed to import %s' % alternatives)\n        return f\n    return wrap", "response": "A decorator that attaches imports to the function - level of \n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pool_get(get, results, next_available, task_next_lock, to_skip, \\\n                  task_num, pool_size, id_self):\n        \"\"\" \n        (internal) Intended to be run in a separate thread and take results from\n        the pool and put them into queues depending on the task of the result. \n        It finishes if it receives termination-sentinels from all pool workers.\n        \"\"\"\n        log.debug('NuMap(%s) started pool_getter' % id_self)\n        # should return when all workers have returned, each worker sends a \n        # sentinel before returning. Before returning it should send sentinels to\n        # all tasks but the next available queue should be released only if we \n        # know that no new results will arrive.\n        sentinels = 0\n        result_ids, last_result_id, very_last_result_id = {}, {}, {}\n        for i in xrange(task_num):\n            last_result_id[i] = -1\n            very_last_result_id[i] = -2\n            result_ids[i] = set()\n\n        while True:\n            try:\n                log.debug('NuMap(%s) pool_getter waits for a result.' % id_self)\n                #gc.disable()\n                result = get()\n                #gc.enable()\n            except (IOError, EOFError):\n                log.error('NuMap(%s) pool_getter has a pipe problem.' % id_self)\n                break\n\n            # got a sentinel?\n            if result is None:\n                sentinels += 1\n                log.debug('NuMap(%s) pool_getter got a sentinel.' % id_self)\n                if sentinels == pool_size:\n                    log.debug('NuMap(%s) pool_getter got all sentinels.' % \\\n                              id_self)\n                    # here we are escaping.\n                    break\n                else:\n                    # waiting for more sentinels or results to come.\n                    continue\n\n            # got a sentinel for a task?\n            # only one sentinel per task will be received\n            if result[1] is None:\n                task = result[0]\n                very_last_result_id[task] = result[2]\n                if last_result_id[task] == very_last_result_id[task]:\n                    results[task].put(('stop', False, 'stop'))\n                    next_available[task].put(True)\n                    log.debug('NuMap(%s) pool_getter sent sentinel for task %s.'\\\n                                                            % (id_self, task))\n                continue\n\n            # got some result for some task, which might be an exception\n            task, i, is_valid, real_result = result\n            # locked if next for this task is in \n            # the process of raising a TimeoutError\n            task_next_lock[task].acquire()\n            log.debug('NuMap(%s) pool_getter received result %s for task %s)' % \\\n                      (id_self, i, task))\n\n            if to_skip[task]:\n                log.debug('NuMap(%s) pool_getter skips results: %s' % (id_self, \\\n                range(last_result_id[task] + 1, last_result_id[task] + \\\n                      to_skip[task] + 1)))\n                last_result_id[task] += to_skip[task]\n                to_skip[task] = 0\n\n            if i > last_result_id[task]:\n                result_ids[task].add(i)\n                results[task].put((i, is_valid, real_result))\n                log.debug('NuMap(%s) pool_getter put result %s for task %s to queue' % \\\n                          (id_self, i, task))\n            else:\n                log.debug('NuMap(%s) pool_getter skips result %s for task %s' % \\\n                          (id_self, i, task))\n\n            # this releases the next method for each ordered result in the queue\n            # if the NuMap instance is ordered =False this information is \n            # ommitted.\n            while last_result_id[task] + 1 in result_ids[task]:\n                next_available[task].put(True)\n                last_result_id[task] += 1\n                log.debug('NuMap(%s) pool_getter released task: %s' % \\\n                          (id_self, task))\n            if last_result_id[task] == very_last_result_id[task]:\n                results[task].put(('stop', False, 'stop'))\n                next_available[task].put(True)\n            # release the next method\n            task_next_lock[task].release()\n        log.debug('NuMap(%s) pool_getter returns' % id_self)", "response": "This function is called by the worker threads to get the result of a task from the pool."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start_managers(self):\n        self._task_queue = _Weave(self._tasks, self.stride)\n        # here we determine the size of the maximum memory consumption\n        self._semaphore_value = (self.buffer or (len(self._tasks) * self.stride))\n        self._pool_semaphore = Semaphore(self._semaphore_value)\n\n\n        # start the pool getter thread\n        self._pool_getter = Thread(target=self._pool_get, args=(self._getout, \\\n                self._task_results, self._next_available, \\\n                self._task_next_lock, self._next_skipped, len(self._tasks), \\\n                len(self.pool), id(self)))\n        self._pool_getter.deamon = True\n        self._pool_getter.start()\n\n        # start the pool putter thread\n        self._pool_putter = Thread(target=self._pool_put, args=\\\n                (self._pool_semaphore, self._task_queue, self._putin, \\\n                len(self.pool), id(self), self._stopping.isSet))\n        self._pool_putter.deamon = True\n        self._pool_putter.start()", "response": "starts input and output pool queue manager threads."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _start_workers(self):\n        # creating the pool of worker process or threads\n        log.debug('%s starts a %s-pool of %s workers.' % \\\n                  (self, self.worker_type, self.worker_num))\n        self.pool = []\n        for host, worker_num in \\\n                           [(None, self.worker_num)] + list(self.worker_remote):\n            for _worker in range(worker_num):\n                __worker = Thread(target=_pool_worker, args=\\\n                                  (self._inqueue, self._outqueue, host)) \\\n                                  if self.worker_type == 'thread' else \\\n                           Process(target=_pool_worker, args=\\\n                                  (self._inqueue, self._outqueue, host))\n                self.pool.append(__worker)\n        for __worker in self.pool:\n            __worker.daemon = True\n            __worker.start()\n        log.debug('%s started the pool' % self)", "response": "starts the worker threads or processes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _stop(self):\n        if self._started.isSet():\n            # join threads\n            self._pool_getter.join()\n            self._pool_putter.join()\n            for worker in self.pool:\n                worker.join()\n            # remove threads  \n            del self._pool_putter\n            del self._pool_getter\n            del self.pool\n            # remove results\n            self._tasks = []\n            self._tasks_tracked = {}\n            # virgin variables\n            self._stopping.clear()\n            self._started.clear()", "response": "Stops input and output pool manager threads."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_task(self, func, iterable, args=None, kwargs=None, timeout=None, \\\n                block=True, track=False):\n        \"\"\" \n        Adds a **task** to evaluate. A **task** is jointly a function or \n        callable an iterable with optional arguments and keyworded arguments.\n        The iterable can be the result iterator of a previously added **task**\n        (to the same or to a different ``NuMap`` instance).\n\n        Arguments:\n        \n          - func (callable) this will be called on each element of the \n            \"iterable\" and supplied with arguments \"args\" and keyworded \n            arguments \"kwargs\"\n          - iterable (iterable) this must be a sequence of *picklable* objects \n            which will be the first arguments passed to the \"func\"\n          - args (``tuple``) [default: ``None``] A ``tuple`` of optional \n            constant arguments passed to the callable \"func\" after the first\n            argument from the \"iterable\"\n          - kwargs (``dict``) [default: ``None``] A dictionary of keyworded \n            arguments passed to \"func\" after the variable argument from the \n            \"iterable\" and the arguments from \"args\"\n          - timeout (``bool``) see: ``_NuMapTask``\n          - block (``bool``) see: ``_NuMapTask``\n          - track (``bool``) [default: ``False``] If ``True`` the results \n            (or exceptions) of a **task** are saved within:\n            ``self._tasks_tracked[%task_id%]`` as a ``{index:result}`` \n            dictionary. This is only useful if the callable \"func\" creates \n            persistant data. The dictionary can be used to restore the correct \n            order of the data\n            \n        \"\"\"\n        if not self._started.isSet():\n            task = izip(repeat(len(self._tasks)), repeat(func), \\\n                        repeat((args or ())), repeat((kwargs or {})), \\\n                        enumerate(iterable))\n            task_id = len(self._tasks)\n            self._tasks.append(task)\n            if track:\n                self._tasks_tracked[task_id] = {} # result:index\n            self._next_available[task_id] = Queue()\n            self._next_skipped[task_id] = 0\n            self._task_finished[task_id] = Event()\n            self._task_next_lock[task_id] = tLock()\n            # this locks threads not processes\n            self._task_results[task_id] = _PriorityQueue() if self.ordered \\\n                                                          else Queue()\n            return self.get_task(task=task_id, timeout=timeout, block=block)\n        else:\n            log.error('%s cannot add tasks (is started).' % self)\n            raise RuntimeError('%s cannot add tasks (is started).' % self)", "response": "Adds a task to evaluate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a previously added task from the NuMap instance.", "response": "def pop_task(self, number):\n        \"\"\"\n        Removes a previously added **task** from the ``NuMap`` instance.\n        \n        Arguments:\n        \n          - number (``int`` or ``True``) A positive integer specifying the \n            number of **tasks** to pop. If  number is set ``True`` all **tasks**\n            will be popped.\n        \n        \"\"\"\n        if not self._started.isSet():\n            if number is True:\n                self._tasks = []\n                self._tasks_tracked = {}\n            elif number > 0:\n                last_task_id = len(self._tasks) - 1\n                for i in xrange(number):\n                    self._tasks.pop()\n                    self._tasks_tracked.pop(last_task_id - i, None)\n        else:\n            log.error('%s cannot delete tasks (is started).' % self)\n            raise RuntimeError('%s cannot delete tasks (is started).' % self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_task(self, task=0, timeout=None, block=True):\n        return _NuMapTask(self, task=task, timeout=timeout, block=block)", "response": "Returns an iterator which returns one _NuMapTask instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the processes or threads in the internal pool and the threads in the internal pool and the input and output queues.", "response": "def start(self, stages=(1, 2)):\n        \"\"\"\n        Starts the processes or threads in the internal pool and the threads, \n        which manage the **worker pool** input and output queues. The \n        **starting mode** is split into **two stages**, which can be initiated \n        seperately. After the first stage the **worker pool** processes or \n        threads are  started and the ``NuMap._started`` event is set ``True``.\n        A call to the ``NuMap.next`` method **will** block. After the **second \n        stage** the ``NuMap._pool_putter`` and ``NuMap._pool_getter`` threads\n        will be running. The ``NuMap.next`` method should only be called **after** \n        this method returns.\n\n        Arguments:\n        \n          - stages (``tuple``) [default: ``(1, 2)``] Specifies which stages of \n            the start process to execute, by default both stages.\n\n        \"\"\"\n        if 1 in stages:\n            if not self._started.isSet():\n                self._start_workers()\n                self._started.set()\n        if 2 in stages:\n            if not hasattr(self, '_pool_getter'):\n                self._start_managers()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self, ends=None, forced=False):\n        if self._started.isSet():\n            if ends:\n                self._stopping.set()\n                # if _stopping is set the pool putter will notify the weave \n                # generator that no more new results are needed. The weave \n                # generator will stop _before_ getting the first result from \n                # task 0 in the next stride.\n                log.debug('%s begins stopping routine' % self)\n                to_do = ends[:] # if ends else ends\n                # We continue this loop until all end tasks\n                # have raised StopIteration this stops the pool\n                while to_do:\n                    for task in to_do:\n                        try:\n                            #for i in xrange(self.stride):\n                            self.next(task=task)\n                        except StopIteration:\n                            to_do.remove(task)\n                            log.debug('%s stopped task %s' % (self, task))\n                            continue\n                        except Exception, excp:\n                            log.debug('%s task %s raised exception %s' % \\\n                                      (self, task, excp))\n                # stop threads remove queues \n                self._stop()\n                log.debug('%s finished stopping routine' % self)\n            elif forced:\n                self._stopping.set()\n                log.debug('%s begins triggers stopping' % self)\n                # someone has to retrieve results and call the _stop_managers\n            else:\n                # this is the default\n                msg = '%s is started, but neither ends nor forced was set.' % \\\n                        self\n                log.error(msg)\n                raise RuntimeError(msg)", "response": "Stops the current instance and all of its pending results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self, timeout=None, task=0, block=True):\n        # check if any result is expected (started and not finished)\n        if not self._started.isSet():\n            log.debug('%s has not yet been started' % self)\n            raise RuntimeError('%s has not yet been started' % self)\n        elif self._task_finished[task].isSet():\n            log.debug('%s has finished task %s' % (self, task))\n            raise StopIteration\n\n        # try to get a result\n        try:\n            log.debug('%s waits for a result: ordered %s, task %s' % \\\n                      (self, self.ordered, task))\n            if self.ordered:\n                _got_next = \\\n                    self._next_available[task].get(timeout=timeout, block=block)\n                log.debug('%s has been released for task: %s' % (self, task))\n                result = self._task_results[task].get()\n            else:\n                result = \\\n                    self._task_results[task].get(timeout=timeout, block=block)\n        except Empty:\n            self._task_next_lock[task].acquire()\n            log.debug('%s timeout for result: ordered %s, task %s' % \\\n                      (self, self.ordered, task))\n            # the threads might have switched between the exception and the \n            # lock.acquire during this switch several items could have been \n            # submited to the queue if one of them is the one we are waiting \n            # for we get it here immediately, but lock the pool getter not to\n            # submit more results.\n            try:\n                if self.ordered:\n                    _got_next = self._next_available[task].get(block=False)\n                    log.debug('%s has been released for task: %s' % \\\n                              (self, task))\n                    result = self._task_results[task].get()\n                else:\n                    result = self._task_results[task].get(block=False)\n            except Empty:\n                if self.skip:\n                    self._next_skipped[task] += 1\n                    self._pool_semaphore.release()\n                self._task_next_lock[task].release()\n                raise TimeoutError('%s timeout for result: ordered %s, task %s' % \\\n                                   (self, self.ordered, task))\n        log.debug('%s got a result: ordered %s, task %s, %s' % \\\n                  (self, self.ordered, task, result))\n        # return or raise the result\n        index, is_valid, real_result = result\n        if index == 'stop':\n            # got the stop sentinel\n            self._task_finished[task].set()\n            log.debug('%s releases semaphore after StopIteration of task %s' % \\\n                      (self, task))\n            self._pool_semaphore.release()\n            log.debug('%s has finished task %s for the first time' % \\\n                      (self, task))\n            raise StopIteration\n        if task in self._tasks_tracked:\n            self._tasks_tracked[task][index] = real_result\n        if is_valid:\n            log.debug('%s returns %s for task %s' % (self, index, task))\n            self._pool_semaphore.release()\n            return real_result\n        else:\n            log.debug('%s raises %s for task %s' % (self, index, task))\n            self._pool_semaphore.release()\n            raise real_result", "response": "Returns the next result for the given task."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the next element or raises StopIteration if stopped.", "response": "def next(self):\n        \"\"\"\n        Returns the next element or raises ``StopIteration`` if stopped.\n        \"\"\"\n        # need new iterable?\n        if self.r == self.repeats:\n            self.i = (self.i + 1) % self.lenght\n            self.r = 0\n\n        self.r += 1\n        if self.stopping and self.i == 0 and self.r == 1:\n            self.stopped = True\n        if self.i == 0 and self.stopped:\n            raise StopIteration\n        else:\n            iterator = self.iterators[self.i]\n            return iterator.next()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a result if available within timeout else raises a", "response": "def next(self):\n        \"\"\"\n        Returns a result if availble within \"timeout\" else raises a \n        ``TimeoutError`` exception. See documentation for ``NuMap.next``.\n        \"\"\"\n        return self.iterator.next(task=self.task, timeout=self.timeout,\n                                                    block=self.block)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the language - specific script template to file.", "response": "def write_template(fn, lang=\"python\"):\n    \"\"\"\n    Write language-specific script template to file.\n\n    Arguments:\n\n      - fn(``string``) path to save the template to\n      - lang('python', 'bash') which programming language\n      \n    \"\"\"\n    with open(fn, \"wb\") as fh:\n        if lang == \"python\":\n            fh.write(PY_TEMPLATE)\n        elif lang == \"bash\":\n            fh.write(SH_TEMPLATE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes arbitrary scripts. Arguments: - cfg(``dict``) script configuartion dictionary", "response": "def script(inbox, cfg):\n    \"\"\"\n    Execute arbitrary scripts. \n\n    Arguments:\n    \n      - cfg(``dict``) script configuartion dictionary\n\n    \"\"\"\n    script_name = cfg[\"id\"]\n    script_id = str(abs(hash((cfg[\"id\"],) + tuple(inbox[0].values()))))[0:8]\n    # LOG.log(mp.DEFAULT, \"@papy;script %s:%s started\" % (script_name, script_id))\n    # LOG.log(mp.SUBDEFAULT, \"@papy;%s:%s received: %s\" % (script_name, script_id, inbox))\n    args = {}\n    args[\"params\"] = dict(cfg[\"params\"])\n    args[\"in\"] = {}\n    for in_port in cfg[\"in\"]:\n        for inin_ports in inbox:\n            in_path = inin_ports.get(in_port, None)\n            if (in_path is not None):\n                # first matching input-output (including type) port is linked remaining ignored\n                args[\"in\"][in_port] = in_path\n                break\n    # check that all input ports are connected\n    if len(args[\"in\"]) < len(cfg[\"in\"]):\n        raise Exception(\"not all in_ports connected, got: %s\" % (args[\"in\"],))\n    # create output file for out_ports\n    args[\"out\"] = {}\n    out = {}\n    for i, (out_port, out_ext) in enumerate(cfg[\"out\"]):\n        if cfg[\"in\"] == tuple(out_port_ for out_port_, _ in cfg[\"out\"]):\n            pfx = args[\"in\"][cfg[\"in\"][i]].split(\"/\")[-1].split(\".\")[0] + \"_\"\n            base = cfg[\"id\"]\n        else:\n            pfx = args[\"in\"][cfg[\"in\"][0]].split(\"/\")[-1].split(\".\")[0] + \"_\"\n            base = cfg[\"id\"] + \"-\" + out_port \n        if out_ext:\n            out_path = cfg[\"dir\"] + \"/\" + pfx + base + \".\" + out_ext\n        else:\n            out_path = cfg[\"dir\"] + \"/\" + pfx + base\n        args[\"out\"][out_port] = out_path\n        out[out_port] = out_path\n    # evaluate and check for errors\n    ret = _eval_script(cfg[\"evaluator\"], cfg[\"preamble\"], cfg[\"dir\"], cfg[\"executable\"], cfg[\"script\"], args)\n    if ret[0] != 0:\n        # LOG.error(\"@papy;%s:%s %s:%s:%s\" % (script_name, script_id, ret[0], \n        #                                                              ret[1].replace(\"\\n\", \"<br>\"), \n        #                                                              ret[2].replace(\"\\n\", \"<br>\")))\n        raise Exception(ret[0], cfg[\"script\"], ret[1], ret[2])\n    #LOG.log(mp.SUBDEFAULT, \"@papy;%s:%s produced:%s\" % (script_name, script_id, out))\n    #LOG.log(mp.DEFAULT, \"@papy;script %s:%s finished\" % (script_name, script_id))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nedit a job. :param resource: :class:`jobs.Job <jobs.Job>` object :return: :class:`jobs.Job <jobs.Job>` object :rtype: jobs.Job", "response": "def edit(self, resource):\n        \"\"\"Edit a job.\n\n        :param resource: :class:`jobs.Job <jobs.Job>` object\n        :return: :class:`jobs.Job <jobs.Job>` object\n        :rtype: jobs.Job\n        \"\"\"\n        schema = JobSchema(exclude=('id', 'status', 'options', 'package_name', 'config_name', 'device_name', 'result_id', 'user_id', 'created', 'updated', 'automatic', 'run_at'))\n        json = self.service.encode(schema, resource)\n\n        schema = JobSchema()\n        resp = self.service.edit(self.base, resource.name, json)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlaunch a new job.", "response": "def launch(self, resource):\n        \"\"\"Launch a new job.\n\n        :param resource: :class:`jobs.Job <jobs.Job>` object\n        :return: :class:`jobs.Job <jobs.Job>` object\n        :rtype: jobs.Job\n        \"\"\"\n        schema = JobSchema(exclude=('id', 'status', 'package_name', 'config_name', 'device_name', 'result_id', 'user_id', 'created', 'updated', 'automatic'))\n        json = self.service.encode(schema, resource)\n\n        schema = JobSchema()\n        resp = self.service.create(self.base, json)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bulk_launch(self, jobs=None, filter=None, all=False): # pylint: disable=redefined-builtin\n        json = None\n        if jobs is not None:\n            schema = JobSchema(exclude=('id', 'status', 'package_name', 'config_name', 'device_name', 'result_id', 'user_id', 'created', 'updated', 'automatic'))\n            jobs_json = self.service.encode(schema, jobs, many=True)\n            json = {self.RESOURCE: jobs_json}\n\n        schema = JobSchema()\n        resp = self.service.post(self.base,\n                                 params={'bulk': 'launch', 'filter': filter, 'all': all}, json=json)\n        return self.service.decode(schema, resp, many=True)", "response": "Bulk launch a set of jobs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a highlight. :param id: Result ID as an int. :param seq: TestResult sequence ID as an int. :param line: Line number in TestResult's logfile as an int. :return: :class:`highlights.Highlight <highlights.Highlight>` object", "response": "def get(self, id, seq, line): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param line: Line number in TestResult's logfile as an int.\n        :return: :class:`highlights.Highlight <highlights.Highlight>` object\n        \"\"\"\n        schema = HighlightSchema()\n        resp = self.service.get_id(self._base(id, seq), line)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_or_edit(self, id, seq, resource): # pylint: disable=invalid-name,redefined-builtin\n        schema = HighlightSchema(exclude=('id', 'seq'))\n        json = self.service.encode(schema, resource)\n\n        schema = HighlightSchema()\n        resp = self.service.edit(self._base(id, seq), resource.line, json)\n        return self.service.decode(schema, resp)", "response": "Create or edit a highlight."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a highlight. :param id: Result ID as an int. :param seq: TestResult sequence ID as an int. :param resource: :class:`highlights.Highlight <highlights.Highlight>` object :return: :class:`highlights.Highlight <highlights.Highlight>` object :rtype: highlights.Highlight", "response": "def create(self, id, seq, resource): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Create a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param resource: :class:`highlights.Highlight <highlights.Highlight>` object\n        :return: :class:`highlights.Highlight <highlights.Highlight>` object\n        :rtype: highlights.Highlight\n        \"\"\"\n        return self.create_or_edit(id, seq, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nedits a highlight. :param id: Result ID as an int. :param seq: TestResult sequence ID as an int. :param resource: :class:`highlights.Highlight <highlights.Highlight>` object :return: :class:`highlights.Highlight <highlights.Highlight>` object :rtype: highlights.Highlight", "response": "def edit(self, id, seq, resource): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Edit a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param resource: :class:`highlights.Highlight <highlights.Highlight>` object\n        :return: :class:`highlights.Highlight <highlights.Highlight>` object\n        :rtype: highlights.Highlight\n        \"\"\"\n        return self.create_or_edit(id, seq, resource)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a highlight. :param id: Result ID as an int. :param seq: TestResult sequence ID as an int. :param line: Line number in TestResult's logfile as an int.", "response": "def delete(self, id, seq, line): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Delete a highlight.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param line: Line number in TestResult's logfile as an int.\n        \"\"\"\n        return self.service.delete_id(self._base(id, seq), line)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend user to remote application for authentication.", "response": "def login(remote_app):\n    \"\"\"Send user to remote application for authentication.\"\"\"\n    oauth = current_app.extensions['oauthlib.client']\n\n    if remote_app not in oauth.remote_apps:\n        return abort(404)\n\n    # Get redirect target in safe manner.\n    next_param = get_safe_redirect_target(arg='next')\n\n    # Redirect URI - must be registered in the remote service.\n    callback_url = url_for(\n        '.authorized',\n        remote_app=remote_app,\n        _external=True,\n    )\n\n    # Create a JSON Web Token that expires after OAUTHCLIENT_STATE_EXPIRES\n    # seconds.\n    state_token = serializer.dumps({\n        'app': remote_app,\n        'next': next_param,\n        'sid': _create_identifier(),\n    })\n\n    return oauth.remote_apps[remote_app].authorize(\n        callback=callback_url,\n        state=state_token,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisconnects user from remote application.", "response": "def disconnect(remote_app):\n    \"\"\"Disconnect user from remote application.\n\n    Removes application as well as associated information.\n    \"\"\"\n    if remote_app not in current_oauthclient.disconnect_handlers:\n        return abort(404)\n\n    ret = current_oauthclient.disconnect_handlers[remote_app]()\n    db.session.commit()\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the checksum in bytes for an address in bytes", "response": "def address_checksum(address):\n    \"\"\"\n    Returns the checksum in bytes for an address in bytes\n    \"\"\"\n    address_bytes = address\n    h = blake2b(digest_size=5)\n    h.update(address_bytes)\n    checksum = bytearray(h.digest())\n    checksum.reverse()\n    return checksum"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keypair_from_seed(seed, index=0):\n\n    h = blake2b(digest_size=32)\n    h.update(seed + struct.pack(\">L\", index))\n    priv_key = h.digest()\n    pub_key = private_to_public_key(priv_key)\n    return {'private': priv_key, 'public': pub_key}", "response": "Generates a deterministic keypair from seed based on index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify that a message is signed with public_key.", "response": "def verify_signature(message, signature, public_key):\n    \"\"\"\n    Verifies `signature` is correct for a `message` signed with `public_key`\n\n    :param message: message to check\n    :type message: bytes\n\n    :param signature: signature to check\n    :type signature: bytes\n\n    :param public_key: public_key to check\n    :type public_key: bytes\n\n    :return: True if valid, False otherwise\n    :rtype: bool\n    \"\"\"\n\n    try:\n        ed25519_blake2.checkvalid(signature, message, public_key)\n    except ed25519_blake2.SignatureMismatch:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign_message(message, private_key, public_key=None):\n\n    if public_key is None:\n        public_key = private_to_public_key(private_key)\n\n    return ed25519_blake2.signature_unsafe(message, private_key, public_key)", "response": "Signs a message using private_key and public_key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_for_lounge_upgrade(self, email, password):\n        schema = ReleaseSchema()\n        resp = self.service.post(self.base+'lounge/check/',\n                                 json={'email': email, 'password': password})\n        return self.service.decode(schema, resp)", "response": "Check the CDRouter Support Lounge for eligible upgrades using your\n        Support Lounge email & password."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lounge_upgrade(self, email, password, release_id):\n        schema = UpgradeSchema()\n        resp = self.service.post(self.base+'lounge/upgrade/',\n                                 json={'email': email, 'password': password, 'release': {'id': int(release_id)}})\n        return self.service.decode(schema, resp)", "response": "Download & install an upgrade from the CDRouter Support Lounge email & password."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading & install a license for your CDRouter system from the CDRouter Support Lounge.", "response": "def lounge_update_license(self):\n        \"\"\"Download & install a license for your CDRouter system from the\n        CDRouter Support Lounge.\n\n        :return: :class:`system.Upgrade <system.Upgrade>` object\n        :rtype: system.Upgrade\n        \"\"\"\n        schema = UpgradeSchema()\n        resp = self.service.post(self.base+'license/')\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the license on your CDRouter system manually by uploading a. lic file.", "response": "def manual_update_license(self, fd, filename='cdrouter.lic'):\n        \"\"\"Update the license on your CDRouter system manually by uploading a\n        .lic license from the CDRouter Support Lounge.\n\n        :param fd: File-like object to upload.\n        :param filename: (optional) Filename to use for license as string.\n        :return: :class:`system.Upgrade <system.Upgrade>` object\n        :rtype: system.Upgrade\n        \"\"\"\n        schema = UpgradeSchema()\n        resp = self.service.post(self.base+'license/',\n                                 files={'file': (filename, fd)})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef space(self):\n        schema = SpaceSchema()\n        resp = self.service.get(self.base+'space/')\n        return self.service.decode(schema, resp)", "response": "Get system disk space usage."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef interfaces(self, addresses=False):\n        schema = InterfaceSchema()\n        resp = self.service.get(self.base+'interfaces/', params={'addresses': addresses})\n        return self.service.decode(schema, resp, many=True)", "response": "Get system interfaces.\n\n        :param addresses: (optional) If bool `True`, include interface addresses.\n        :return: :class:`system.Interface <system.Interface>` list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets preferences from / usr / cdrouter - data. yml.", "response": "def get_preferences(self):\n        \"\"\"Get preferences from /usr/cdrouter-data/etc/config.yml.\n\n        :return: :class:`system.Preferences <system.Preferences>` object\n        :rtype: system.Preferences\n        \"\"\"\n        schema = PreferencesSchema()\n        resp = self.service.get(self.base+'preferences/')\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nedit preferences in / usr / cdrouter - data / etc / config. yml.", "response": "def edit_preferences(self, resource):\n        \"\"\"Edit preferences in /usr/cdrouter-data/etc/config.yml.\n\n        :param resource: :class:`system.Preferences <system.Preferences>` object\n        :return: :class:`system.Preferences <system.Preferences>` object\n        :rtype: system.Preferences\n        \"\"\"\n        schema = PreferencesSchema()\n        json = self.service.encode(schema, resource)\n\n        schema = PreferencesSchema()\n        resp = self.service.patch(self.base+'preferences/', json=json)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave fields value only for non - m2m fields.", "response": "def _set_original_fields(instance):\n    \"\"\"\n    Save fields value, only for non-m2m fields.\n    \"\"\"\n    original_fields = {}\n\n    def _set_original_field(instance, field):\n        if instance.pk is None:\n            original_fields[field] = None\n        else:\n            if isinstance(instance._meta.get_field(field), ForeignKey):\n                # Only get the PK, we don't want to get the object\n                # (which would make an additional request)\n                original_fields[field] = getattr(instance,\n                                                 '{0}_id'.format(field))\n            else:\n                original_fields[field] = getattr(instance, field)\n\n    for field in getattr(instance, '_tracked_fields', []):\n        _set_original_field(instance, field)\n    for field in getattr(instance, '_tracked_related_fields', {}).keys():\n        _set_original_field(instance, field)\n\n    instance._original_fields = original_fields\n    # Include pk to detect the creation of an object\n    instance._original_fields['pk'] = instance.pk"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _has_changed(instance):\n    for field, value in instance._original_fields.items():\n        if field != 'pk' and \\\n           not isinstance(instance._meta.get_field(field), ManyToManyField):\n            try:\n                if field in getattr(instance, '_tracked_fields', []):\n                    if isinstance(instance._meta.get_field(field), ForeignKey):\n                        if getattr(instance, '{0}_id'.format(field)) != value:\n                            return True\n                    else:\n                        if getattr(instance, field) != value:\n                            return True\n            except TypeError:\n                # Can't compare old and new value, should be different.\n                return True\n    return False", "response": "Check if some tracked fields have changed"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if some related fields have changed", "response": "def _has_changed_related(instance):\n    \"\"\"\n    Check if some related tracked fields have changed\n    \"\"\"\n    tracked_related_fields = getattr(\n        instance,\n        '_tracked_related_fields',\n        {}\n    ).keys()\n    for field, value in instance._original_fields.items():\n        if field != 'pk' and \\\n           not isinstance(instance._meta.get_field(field), ManyToManyField):\n            if field in tracked_related_fields:\n                if isinstance(instance._meta.get_field(field), ForeignKey):\n                    if getattr(instance, '{0}_id'.format(field)) != value:\n                        return True\n                else:\n                    if getattr(instance, field) != value:\n                        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_event(instance, action):\n    user = None\n    user_repr = repr(user)\n    if CUSER:\n        user = CuserMiddleware.get_user()\n        user_repr = repr(user)\n        if user is not None and user.is_anonymous:\n            user = None\n    return TrackingEvent.objects.create(\n        action=action,\n        object=instance,\n        object_repr=repr(instance),\n        user=user,\n        user_repr=user_repr,\n    )", "response": "Create a new TrackingEvent object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a TrackedFieldModification for the instance.", "response": "def _create_tracked_field(event, instance, field, fieldname=None):\n    \"\"\"\n    Create a TrackedFieldModification for the instance.\n\n    :param event: The TrackingEvent on which to add TrackingField\n    :param instance: The instance on which the field is\n    :param field: The field name to track\n    :param fieldname: The displayed name for the field. Default to field.\n    \"\"\"\n    fieldname = fieldname or field\n    if isinstance(instance._meta.get_field(field), ForeignKey):\n        # We only have the pk, we need to get the actual object\n        model = instance._meta.get_field(field).remote_field.model\n        pk = instance._original_fields[field]\n        try:\n            old_value = model.objects.get(pk=pk)\n        except model.DoesNotExist:\n            old_value = None\n    else:\n        old_value = instance._original_fields[field]\n    return TrackedFieldModification.objects.create(\n        event=event,\n        field=fieldname,\n        old_value=_serialize_field(old_value),\n        new_value=_serialize_field(getattr(instance, field))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_create_tracking_event(instance):\n    event = _create_event(instance, CREATE)\n    for field in instance._tracked_fields:\n        if not isinstance(instance._meta.get_field(field), ManyToManyField):\n            _create_tracked_field(event, instance, field)", "response": "Create a TrackingEvent and TrackedFieldModification for a CREATE event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a TrackingEvent and TrackedFieldModification for an UPDATE event.", "response": "def _create_update_tracking_event(instance):\n    \"\"\"\n    Create a TrackingEvent and TrackedFieldModification for an UPDATE event.\n    \"\"\"\n    event = _create_event(instance, UPDATE)\n    for field in instance._tracked_fields:\n        if not isinstance(instance._meta.get_field(field), ManyToManyField):\n            try:\n                if isinstance(instance._meta.get_field(field), ForeignKey):\n                    # Compare pk\n                    value = getattr(instance, '{0}_id'.format(field))\n                else:\n                    value = getattr(instance, field)\n                if instance._original_fields[field] != value:\n                    _create_tracked_field(event, instance, field)\n            except TypeError:\n                # Can't compare old and new value, should be different.\n                _create_tracked_field(event, instance, field)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a TrackingEvent and TrackedFieldModification for an UPDATE event for each related model.", "response": "def _create_update_tracking_related_event(instance):\n    \"\"\"\n    Create a TrackingEvent and TrackedFieldModification for an UPDATE event\n    for each related model.\n    \"\"\"\n    events = {}\n    # Create a dict mapping related model field to modified fields\n    for field, related_fields in instance._tracked_related_fields.items():\n        if not isinstance(instance._meta.get_field(field), ManyToManyField):\n            if isinstance(instance._meta.get_field(field), ForeignKey):\n                # Compare pk\n                value = getattr(instance, '{0}_id'.format(field))\n            else:\n                value = getattr(instance, field)\n            if instance._original_fields[field] != value:\n                for related_field in related_fields:\n                    events.setdefault(related_field, []).append(field)\n\n    # Create the events from the events dict\n    for related_field, fields in events.items():\n        try:\n            related_instances = getattr(instance, related_field[1])\n        except ObjectDoesNotExist:\n            continue\n\n        # FIXME: isinstance(related_instances, RelatedManager ?)\n        if hasattr(related_instances, 'all'):\n            related_instances = related_instances.all()\n        else:\n            related_instances = [related_instances]\n        for related_instance in related_instances:\n            event = _create_event(related_instance, UPDATE)\n            for field in fields:\n                fieldname = '{0}__{1}'.format(related_field[0], field)\n                _create_tracked_field(\n                    event, instance, field, fieldname=fieldname\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the field name from a model and a sender from m2m_changed signal.", "response": "def _get_m2m_field(model, sender):\n    \"\"\"\n    Get the field name from a model and a sender from m2m_changed signal.\n    \"\"\"\n    for field in getattr(model, '_tracked_fields', []):\n        if isinstance(model._meta.get_field(field), ManyToManyField):\n            if getattr(model, field).through == sender:\n                return field\n    for field in getattr(model, '_tracked_related_fields', {}).keys():\n        if isinstance(model._meta.get_field(field), ManyToManyField):\n            if getattr(model, field).through == sender:\n                return field"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_tracked_event_m2m(model, instance, sender, objects, action):\n    field = _get_m2m_field(model, sender)\n    if field in getattr(model, '_tracked_related_fields', {}).keys():\n        # In case of a m2m tracked on a related model\n        related_fields = model._tracked_related_fields[field]\n        for related_field in related_fields:\n            try:\n                related_instances = getattr(instance, related_field[1])\n            except ObjectDoesNotExist:\n                continue\n            # FIXME: isinstance(related_instances, RelatedManager ?)\n            if hasattr(related_instances, 'all'):\n                related_instances = related_instances.all()\n            else:\n                related_instances = [related_instances]\n            for related_instance in related_instances:\n                event = _create_event(related_instance, action)\n                fieldname = '{0}__{1}'.format(related_field[0], field)\n                _create_tracked_field_m2m(\n                    event, instance, field, objects, action, fieldname\n                )\n    if field in getattr(model, '_tracked_fields', []):\n        event = _create_event(instance, action)\n        _create_tracked_field_m2m(event, instance, field, objects, action)", "response": "Create the TrackedEvent and the related TrackedFieldModification for a m2m modification."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when tracking_save is called.", "response": "def tracking_save(sender, instance, raw, using, update_fields, **kwargs):\n    \"\"\"\n    Post save, detect creation or changes and log them.\n    We need post_save to have the object for a create.\n    \"\"\"\n    if _has_changed(instance):\n        if instance._original_fields['pk'] is None:\n            # Create\n            _create_create_tracking_event(instance)\n        else:\n            # Update\n            _create_update_tracking_event(instance)\n    if _has_changed_related(instance):\n        # Because an object need to be saved before being related,\n        # it can only be an update\n        _create_update_tracking_related_event(instance)\n    if _has_changed(instance) or _has_changed_related(instance):\n        _set_original_fields(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform additional setup after user have been logged in.", "response": "def account_setup(remote, token, resp):\n    \"\"\"Perform additional setup after user have been logged in.\n\n    :param remote: The remote application.\n    :param token: The token value.\n    :param resp: The response.\n    \"\"\"\n    with db.session.begin_nested():\n        # Retrieve ORCID from response.\n        orcid = resp.get('orcid')\n        full_name = resp.get('name')\n\n        # Set ORCID in extra_data.\n        token.remote_account.extra_data = {\n            'orcid': orcid,\n            'full_name': full_name,\n        }\n\n        user = token.remote_account.user\n\n        # Create user <-> external id link.\n        oauth_link_external_id(user, {'id': orcid, 'method': 'orcid'})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_entry_generator(log_instance):\n    current_page_num = 0\n\n    while True:\n        has_results = False\n\n        for log_entry in log_instance.get_page(current_page_num):\n            has_results = True\n            yield log_entry\n\n        if not has_results:\n            break\n\n        current_page_num += 1", "response": "This is a generator function that returns LogEntry objects from the REST API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget log entries starting from start_id.", "response": "def get_by_start_id(self, start_id):\n        \"\"\"\n        :yield: Log entries starting from :start_id: and ending 200 entries\n                after. In most cases easier to call than the paginate one\n                because there is no need to keep track of the already read\n                entries in a specific page.\n        \"\"\"\n        url = '/scans/%s/log?id=%s' % (self.scan_id, start_id)\n        code, page = self.conn.send_request(url, method='GET')\n\n        if code != 200:\n            message = page.get('message', 'None')\n            args = (code, message)\n            raise APIException('Failed to retrieve scan log. Received HTTP'\n                               ' response code %s. Message: \"%s\"' % args)\n\n        entries = page.get('entries', None)\n\n        if entries is None:\n            raise APIException('Could not retrieve log entries attribute')\n\n        for entry_dict in entries:\n            yield LogEntry.from_entry_dict(entry_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(self, id, seq): # pylint: disable=invalid-name,redefined-builtin\n        schema = CaptureSchema(exclude=('id', 'seq'))\n        resp = self.service.list(self._base(id, seq))\n        return self.service.decode(schema, resp, many=True)", "response": "Get a list of captures."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a capture. :param id: Result ID as an int. :param seq: TestResult sequence ID as an int. :param intf: Interface name as string. :return: :class:`captures.Capture <captures.Capture>` object :rtype: captures.Capture", "response": "def get(self, id, seq, intf): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a capture.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param intf: Interface name as string.\n        :return: :class:`captures.Capture <captures.Capture>` object\n        :rtype: captures.Capture\n        \"\"\"\n        schema = CaptureSchema()\n        resp = self.service.get_id(self._base(id, seq), intf)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download(self, id, seq, intf, inline=False): # pylint: disable=invalid-name,redefined-builtin\n        resp = self.service.get_id(self._base(id, seq), intf, params={'format': 'cap', 'inline': inline}, stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))", "response": "Download a result set as a PCAP file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a capture s summary.", "response": "def summary(self, id, seq, intf, filter=None, inline=False): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a capture's summary.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param intf: Interface name as string.\n        :param filter: (optional) PCAP filter to apply as string.\n        :param inline: (optional) Use inline version of capture file.\n        :return: :class:`captures.Summary <captures.Summary>` object\n        :rtype: captures.Summary\n        \"\"\"\n        schema = SummarySchema()\n        resp = self.service.get(self._base(id, seq)+str(intf)+'/summary/',\n                                params={'filter': filter, 'inline': inline})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a capture s decode.", "response": "def decode(self, id, seq, intf, filter=None, frame=None, inline=False): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a capture's decode.\n\n        :param id: Result ID as an int.\n        :param seq: TestResult sequence ID as an int.\n        :param intf: Interface name as string.\n        :param filter: (optional) PCAP filter to apply as string.\n        :param frame: (optional) Frame number to decode.\n        :param inline: (optional) Use inline version of capture file.\n        :return: :class:`captures.Decode <captures.Decode>` object\n        :rtype: captures.Decode\n        \"\"\"\n        schema = DecodeSchema()\n        resp = self.service.get(self._base(id, seq)+str(intf)+'/decode/',\n                                params={'filter': filter, 'frame': frame, 'inline': inline})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_to_cloudshark(self, id, seq, intf, inline=False): # pylint: disable=invalid-name,redefined-builtin\n        schema = CloudSharkSchema()\n        resp = self.service.post(self._base(id, seq)+str(intf)+'/cloudshark/', params={'inline': inline})\n        return self.service.decode(schema, resp)", "response": "Send a capture to a CloudShark Appliance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_dict_from_response(response):\n    if getattr(response, '_resp') and response._resp.code > 400:\n        raise OAuthResponseError(\n                'Application mis-configuration in Globus', None, response\n            )\n\n    return response.data", "response": "Check for errors in the response and return the resulting JSON."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting user information from Globus.", "response": "def get_user_info(remote):\n    \"\"\"Get user information from Globus.\n\n    See the docs here for v2/oauth/userinfo:\n    https://docs.globus.org/api/auth/reference/\n    \"\"\"\n    response = remote.get(GLOBUS_USER_INFO_URL)\n    user_info = get_dict_from_response(response)\n    response.data['username'] = response.data['preferred_username']\n    if '@' in response.data['username']:\n        user_info['username'], _ = response.data['username'].split('@')\n    return user_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the Globus identity for a users given email.", "response": "def get_user_id(remote, email):\n    \"\"\"Get the Globus identity for a users given email.\n\n    A Globus ID is a UUID that can uniquely identify a Globus user. See the\n    docs here for v2/api/identities\n    https://docs.globus.org/api/auth/reference/\n    \"\"\"\n    try:\n        url = '{}?usernames={}'.format(GLOBUS_USER_ID_URL, email)\n        user_id = get_dict_from_response(remote.get(url))\n        return user_id['identities'][0]['id']\n    except KeyError:\n        # If we got here the response was successful but the data was invalid.\n        # It's likely the URL is wrong but possible the API has changed.\n        raise OAuthResponseError('Failed to fetch user id, likely server '\n                                 'mis-configuration', None, remote)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef account_info(remote, resp):\n    info = get_user_info(remote)\n\n    return {\n        'user': {\n            'email': info['email'],\n            'profile': {\n                'username': info['username'],\n                'full_name': info['name']\n            },\n        },\n        'external_id': get_user_id(remote, info['preferred_username']),\n        'external_method': GLOBUS_EXTERNAL_METHOD\n    }", "response": "Retrieve remote account information used to find local user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform additional setup after user have been logged in.", "response": "def account_setup(remote, token, resp):\n    \"\"\"Perform additional setup after user have been logged in.\n\n    :param remote: The remote application.\n    :param token: The token value.\n    :param resp: The response.\n    \"\"\"\n    info = get_user_info(remote)\n    user_id = get_user_id(remote, info['preferred_username'])\n    with db.session.begin_nested():\n\n        token.remote_account.extra_data = {\n            'login': info['username'],\n            'id': user_id}\n\n        # Create user <-> external id link.\n        oauth_link_external_id(\n            token.remote_account.user, dict(\n                id=user_id,\n                method=GLOBUS_EXTERNAL_METHOD)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling unlinking of remote account.", "response": "def disconnect_handler(remote, *args, **kwargs):\n    \"\"\"Handle unlinking of remote account.\n\n    :param remote: The remote application.\n    :returns: The HTML response.\n    \"\"\"\n    if not current_user.is_authenticated:\n        return current_app.login_manager.unauthorized()\n\n    remote_account = RemoteAccount.get(user_id=current_user.get_id(),\n                                       client_id=remote.consumer_key)\n    external_ids = [i.id for i in current_user.external_identifiers\n                    if i.method == GLOBUS_EXTERNAL_METHOD]\n\n    if external_ids:\n        oauth_unlink_external_id(dict(id=external_ids[0],\n                                      method=GLOBUS_EXTERNAL_METHOD))\n\n    if remote_account:\n        with db.session.begin_nested():\n            remote_account.delete()\n\n    return redirect(url_for('invenio_oauthclient_settings.index'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the signature string of the specified function.", "response": "def get_function_signature(func):\n    \"\"\"\n    Return the signature string of the specified function.\n\n    >>> def foo(name): pass\n    >>> get_function_signature(foo)\n    'foo(name)'\n    >>> something = 'Hello'\n    >>> get_function_signature(something)\n    Traceback (most recent call last):\n        ...\n    TypeError: The argument must be a function object: None type is <class 'str'>\n    \"\"\"\n    if func is None:\n        return 'Function is None'\n\n    try:\n        func_name = func.__name__\n    except AttributeError:\n        func_name = 'None'\n\n    if not inspect.isfunction(func):\n        raise TypeError('The argument must be a function object: %s type is %s' % (func_name, type(func)))\n\n    return func_name + str(inspect.signature(func))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nacquire a read lock.", "response": "def acquire_reader(self):\n        \"\"\"\n        Acquire a read lock, several threads can hold this type of lock.\n        \"\"\"\n        with self.mutex:\n            while self.rwlock < 0 or self.rwlock == self.max_reader_concurrency or self.writers_waiting:\n                self.readers_ok.wait()\n            self.rwlock += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef acquire_writer(self):\n        with self.mutex:\n            while self.rwlock != 0:\n                self._writer_wait()\n            self.rwlock = -1", "response": "Acquire a write lock."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef promote(self):\n        with self.mutex:\n            self.rwlock -= 1\n            while self.rwlock != 0:\n                self._writer_wait()\n            self.rwlock = -1", "response": "Promote an already acquired read lock to a write lock."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of packages.", "response": "def list(self, filter=None, type=None, sort=None, limit=None, page=None): # pylint: disable=redefined-builtin\n        \"\"\"Get a list of packages.\n\n        :param filter: (optional) Filters to apply as a string list.\n        :param type: (optional) `union` or `inter` as string.\n        :param sort: (optional) Sort fields to apply as string list.\n        :param limit: (optional) Limit returned list length.\n        :param page: (optional) Page to return.\n        :return: :class:`packages.Page <packages.Page>` object\n        \"\"\"\n        schema = PackageSchema(exclude=('testlist', 'extra_cli_args', 'agent_id', 'options', 'note'))\n        resp = self.service.list(self.base, filter, type, sort, limit, page)\n        ps, l = self.service.decode(schema, resp, many=True, links=True)\n        return Page(ps, l)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a package. :param id: Package ID as an int. :return: :class:`packages.Package <packages.Package>` object :rtype: packages.Package", "response": "def get(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a package.\n\n        :param id: Package ID as an int.\n        :return: :class:`packages.Package <packages.Package>` object\n        :rtype: packages.Package\n        \"\"\"\n        schema = PackageSchema()\n        resp = self.service.get_id(self.base, id)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, resource):\n        schema = PackageSchema(exclude=('id', 'created', 'updated', 'test_count', 'agent_id', 'result_id'))\n        json = self.service.encode(schema, resource)\n\n        schema = PackageSchema()\n        resp = self.service.create(self.base, json)\n        return self.service.decode(schema, resp)", "response": "Create a new package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of tests that will be skipped for a package.", "response": "def analyze(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a list of tests that will be skipped for a package.\n\n        :param id: Package ID as an int.\n        :return: :class:`packages.Analysis <packages.Analysis>` object\n        :rtype: packages.Analysis\n        \"\"\"\n        schema = AnalysisSchema()\n        resp = self.service.post(self.base+str(id)+'/', params={'process': 'analyze'})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bulk_copy(self, ids):\n        schema = PackageSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)", "response": "Bulk copy a set of packages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bulk_edit(self, _fields, ids=None, filter=None, type=None, all=False): # pylint: disable=redefined-builtin\n        schema = PackageSchema(exclude=('id', 'created', 'updated', 'test_count', 'agent_id', 'result_id'))\n        _fields = self.service.encode(schema, _fields, skip_none=True)\n        return self.service.bulk_edit(self.base, self.RESOURCE,\n                                      _fields, ids=ids, filter=filter, type=type, all=all)", "response": "Bulk edit a set of packages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a list of strings that are not comments or lines with only whitespace.", "response": "def clean_lines(commands):\n    \"\"\" Generate strings that are not comments or lines with only whitespace.\n\n    Purpose: This function is a generator that will read in either a\n           | plain text file of strings(IP list, command list, etc), a\n           | comma separated string of strings, or a list of strings. It\n           | will crop out any comments or blank lines, and yield\n           | individual strings.\n           |\n           | Only strings that do not start with a comment '#', or are not\n           | entirely whitespace will be yielded. This allows a file with\n           | comments and blank lines for formatting neatness to be used\n           | without a problem.\n\n    @param commands: This can be either a string that is a file\n                   | location, a comma separated string of strings\n                   | ('x,y,z,1,2,3'), or a python list of strings.\n    @type commands: str or list\n\n    @returns: Yields each command in order\n    @rtype: iterable of str\n    \"\"\"\n    if isinstance(commands, basestring):\n        # if the command argument is a filename, we need to open it.\n        if path.isfile(commands):\n            commands = open(commands, 'rb')\n        # if the command string is a comma separated list, break it up.\n        elif len(commands.split(',')) > 1:\n            commands = commands.split(',')\n        else:  # if a single command, need to just be returned.\n            try:\n                if commands.strip()[0] != \"#\":\n                    yield commands.strip() + '\\n'\n                    return\n            except IndexError:\n                pass\n    elif isinstance(commands, list):\n        pass\n    else:\n        raise TypeError('clean_lines() accepts a \\'str\\' or \\'list\\'')\n    for cmd in commands:\n        # exclude commented lines, and skip blank lines (index error)\n        try:\n            if cmd.strip()[0] != \"#\":\n                yield cmd.strip() + '\\n'\n        except IndexError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter xml based on an xpath expression.", "response": "def xpath(source_xml, xpath_expr, req_format='string'):\n    \"\"\" Filter xml based on an xpath expression.\n\n    Purpose: This function applies an Xpath expression to the XML\n           | supplied by source_xml. Returns a string subtree or\n           | subtrees that match the Xpath expression. It can also return\n           | an xml object if desired.\n\n    @param source_xml: Plain text XML that will be filtered\n    @type source_xml: str or lxml.etree.ElementTree.Element object\n    @param xpath_expr: Xpath expression that we will filter the XML by.\n    @type xpath_expr: str\n    @param req_format: the desired format of the response, accepts string or\n                     | xml.\n    @type req_format: str\n\n    @returns: The filtered XML if filtering was successful. Otherwise,\n            | an empty string.\n    @rtype: str or ElementTree\n    \"\"\"\n    tree = source_xml\n    if not isinstance(source_xml, ET.Element):\n        tree = objectify.fromstring(source_xml)\n    # clean up the namespace in the tags, as namespaces appear to confuse\n    # xpath method\n    for elem in tree.getiterator():\n        # beware of factory functions such as Comment\n        if isinstance(elem.tag, basestring):\n            i = elem.tag.find('}')\n            if i >= 0:\n                elem.tag = elem.tag[i+1:]\n\n    # remove unused namespaces\n    objectify.deannotate(tree, cleanup_namespaces=True)\n    filtered_list = tree.xpath(xpath_expr)\n    # Return string from the list of Elements or pure xml\n    if req_format == 'xml':\n        return filtered_list\n    matches = ''.join(etree.tostring(\n        element, pretty_print=True) for element in filtered_list)\n    return matches if matches else \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lowcase_str_boolean(obj):\n    \"\u0414\u0435\u043b\u0430\u0435\u0442 \u0438\u0437 obj \u0441\u0442\u0440\u043e\u043a\u0443 `true` \u0438\u043b\u0438 `false`\"\n    if isinstance(obj, str):\n        if obj not in [\"true\", \"false\"]:\n            raise RuntimeError(\n                'Expecting \"true\" or \"false\", got {}'.format(obj))\n        return obj\n    return str(bool(obj)).lower()", "response": "\u0414\u0435\u043b\u0430\u0435\u0442 \u0438\u0437 obj \u0441\u0442\u0440\u043e\u043a\u0443 true \u0438\u043b\u0438 false"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef status(self, timeout=None):\n        assembler = commons.StatusRequestAssembler(self._url)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        status = Status._parse(obj)\n\n        returnValue(status)", "response": "Get etcd cluster status."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, key, value, lease=None, return_previous=None, timeout=None):\n        assembler = commons.PutRequestAssembler(self._url, key, value, lease, return_previous)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        revision = Revision._parse(obj)\n\n        returnValue(revision)", "response": "Set the value for the key in the key - value store."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self,\n            key,\n            range_end=None,\n            count_only=None,\n            keys_only=None,\n            limit=None,\n            max_create_revision=None,\n            min_create_revision=None,\n            min_mod_revision=None,\n            revision=None,\n            serializable=None,\n            sort_order=None,\n            sort_target=None,\n            timeout=None):\n        \"\"\"\n        Range gets the keys in the range from the key-value store.\n\n        :param key: key is the first key for the range. If range_end is not given,\n            the request only looks up key.\n        :type key: bytes\n\n        :param range_end: range_end is the upper bound on the requested range\n            [key, range_end). If range_end is ``\\\\0``, the range is all keys ``\\u003e=`` key.\n            If the range_end is one bit larger than the given key, then the range requests\n            get the all keys with the prefix (the given key). If both key and range_end\n            are ``\\\\0``, then range requests returns all keys.\n        :type range_end: bytes\n\n        :param prefix: If set, and no range_end is given, compute range_end from key prefix.\n        :type prefix: bool\n\n        :param count_only: count_only when set returns only the count of the keys in the range.\n        :type count_only: bool\n\n        :param keys_only: keys_only when set returns only the keys and not the values.\n        :type keys_only: bool\n\n        :param limit: limit is a limit on the number of keys returned for the request.\n        :type limit: int\n\n        :param max_create_revision: max_create_revision is the upper bound for returned\n            key create revisions; all keys with greater create revisions will be filtered away.\n        :type max_create_revision: int\n\n        :param max_mod_revision: max_mod_revision is the upper bound for returned key\n            mod revisions; all keys with greater mod revisions will be filtered away.\n        :type max_mod_revision: int\n\n        :param min_create_revision: min_create_revision is the lower bound for returned\n            key create revisions; all keys with lesser create trevisions will be filtered away.\n        :type min_create_revision: int\n\n        :param min_mod_revision: min_mod_revision is the lower bound for returned key\n            mod revisions; all keys with lesser mod revisions will be filtered away.\n        :type min_min_revision: int\n\n        :param revision: revision is the point-in-time of the key-value store to use for the\n            range. If revision is less or equal to zero, the range is over the newest\n            key-value store. If the revision has been compacted, ErrCompacted is returned as\n            a response.\n        :type revision: int\n\n        :param serializable: serializable sets the range request to use serializable\n            member-local reads. Range requests are linearizable by default; linearizable\n            requests have higher latency and lower throughput than serializable requests\n            but reflect the current consensus of the cluster. For better performance, in\n            exchange for possible stale reads, a serializable range request is served\n            locally without needing to reach consensus with other nodes in the cluster.\n        :type serializable: bool\n\n        :param sort_order: Sort order for returned KVs,\n            one of :class:`txaioetcd.OpGet.SORT_ORDERS`.\n        :type sort_order: str\n\n        :param sort_target: Sort target for sorting returned KVs,\n            one of :class:`txaioetcd.OpGet.SORT_TARGETS`.\n        :type sort_taget: str or None\n\n        :param timeout: Request timeout in seconds.\n        :type timeout: int or None\n        \"\"\"\n        assembler = commons.GetRequestAssembler(self._url, key, range_end)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        result = Range._parse(obj)\n\n        returnValue(result)", "response": "Get the keys in the key - value store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, key, return_previous=None, timeout=None):\n        assembler = commons.DeleteRequestAssembler(self._url, key, return_previous)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        deleted = Deleted._parse(obj)\n\n        returnValue(deleted)", "response": "Delete the value for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef watch(self, keys, on_watch, filters=None, start_revision=None, return_previous=None):\n        d = self._start_watching(keys, on_watch, filters, start_revision, return_previous)\n\n        #\n        #   ODD: Trying to use a parameter instead of *args errors out as soon as the\n        #        parameter is accessed.\n        #\n        def on_err(*args):\n            if args[0].type not in [CancelledError, ResponseFailed]:\n                self.log.warn('etcd watch terminated with \"{error}\"', error=args[0].type)\n                return args[0]\n\n        d.addErrback(on_err)\n        return d", "response": "Watches one or more keys or key sets and invoke a callback."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubmit a transaction. Processes multiple requests in a single transaction. A transaction increments the revision of the key-value store and generates events with the same revision for every completed request. It is not allowed to modify the same key several times within one transaction. From google paxosdb paper: Our implementation hinges around a powerful primitive which we call MultiOp. All other database operations except for iteration are implemented as a single call to MultiOp. A MultiOp is applied atomically and consists of three components: 1. A list of tests called guard. Each test in guard checks a single entry in the database. It may check for the absence or presence of a value, or compare with a given value. Two different tests in the guard may apply to the same or different entries in the database. All tests in the guard are applied and MultiOp returns the results. If all tests are true, MultiOp executes t op (see item 2 below), otherwise it executes f op (see item 3 below). 2. A list of database operations called t op. Each operation in the list is either an insert, delete, or lookup operation, and applies to a single database entry. Two different operations in the list may apply to the same or different entries in the database. These operations are executed if guard evaluates to true. 3. A list of database operations called f op. Like t op, but executed if guard evaluates to false. :param txn: The transaction to submit. :type txn: instance of :class:`txaioetcd.Transaction` :param timeout: Request timeout in seconds. :type timeout: int :returns: An instance of :class:`txaioetcd.Success` or an exception of :class:`txioetcd.Failed` or :class:`txaioetcd.Error` :rtype: instance of :class:`txaioetcd.Success`, :class:`txaioetcd.Failed` or :class:`txaioetcd.Error`", "response": "def submit(self, txn, timeout=None):\n        \"\"\"\n        Submit a transaction.\n\n        Processes multiple requests in a single transaction.\n        A transaction increments the revision of the key-value store\n        and generates events with the same revision for every\n        completed request.\n\n        It is not allowed to modify the same key several times\n        within one transaction.\n\n        From google paxosdb paper:\n\n        Our implementation hinges around a powerful primitive which\n        we call MultiOp. All other database operations except for\n        iteration are implemented as a single call to MultiOp.\n        A MultiOp is applied atomically and consists of three components:\n\n        1. A list of tests called guard. Each test in guard checks\n           a single entry in the database. It may check for the absence\n           or presence of a value, or compare with a given value.\n           Two different tests in the guard may apply to the same or\n           different entries in the database. All tests in the guard\n           are applied and MultiOp returns the results. If all tests\n           are true, MultiOp executes t op (see item 2 below), otherwise\n           it executes f op (see item 3 below).\n\n        2. A list of database operations called t op. Each operation in\n           the list is either an insert, delete, or lookup operation, and\n           applies to a single database entry. Two different operations\n           in the list may apply to the same or different entries in\n           the database. These operations are executed if guard evaluates\n           to true.\n\n        3. A list of database operations called f op. Like t op, but\n           executed if guard evaluates to false.\n\n        :param txn: The transaction to submit.\n        :type txn: instance of :class:`txaioetcd.Transaction`\n\n        :param timeout: Request timeout in seconds.\n        :type timeout: int\n\n        :returns: An instance of :class:`txaioetcd.Success` or an exception\n            of :class:`txioetcd.Failed` or :class:`txaioetcd.Error`\n        :rtype: instance of :class:`txaioetcd.Success`,\n            :class:`txaioetcd.Failed` or :class:`txaioetcd.Error`\n        \"\"\"\n        url = ENDPOINT_SUBMIT.format(self._url).encode()\n        data = txn._marshal()\n\n        obj = yield self._post(url, data, timeout)\n\n        header, responses = validate_client_submit_response(obj)\n\n        if obj.get(u'succeeded', False):\n            returnValue(Success(header, responses))\n        else:\n            raise Failed(header, responses)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lease(self, time_to_live, lease_id=None, timeout=None):\n        assembler = commons.LeaseRequestAssembler(self._url, time_to_live, lease_id)\n\n        obj = yield self._post(assembler.url, assembler.data, timeout)\n\n        lease = Lease._parse(self, obj)\n\n        returnValue(lease)", "response": "Creates a new lease which expires if the server does not have a keep alive period."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self):\n        schema = ImportSchema()\n        resp = self.service.list(self.base)\n        return self.service.decode(schema, resp, many=True)", "response": "Get a list of staged ( in - progress ) imports."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stage_import_from_file(self, fd, filename='upload.gz'):\n        schema = ImportSchema()\n        resp = self.service.post(self.base,\n                                 files={'file': (filename, fd)})\n        return self.service.decode(schema, resp)", "response": "Stage an import from a file upload."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stage_import_from_filesystem(self, filepath):\n        schema = ImportSchema()\n        resp = self.service.post(self.base,\n                                 params={'path': filepath})\n        return self.service.decode(schema, resp)", "response": "Stage an import from a local filesystem path as string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstages an import from a URL to another CDRouter system.", "response": "def stage_import_from_url(self, url, token=None, username=None, password=None, insecure=False):\n        \"\"\"Stage an import from a URL to another CDRouter system.\n\n        :param url: URL to import as string.\n        :param token: (optional) API token to use as string (may be required if importing from a CDRouter 10+ system).\n        :param username: (optional) API username to use as string (may be required if importing from a CDRouter 10+ system).\n        :param password: (optional) API password to use as string (may be required if importing from a CDRouter 10+ system).\n        :param insecure: (optional) Allow insecure HTTPS connections if bool `True`.\n        :return: :class:`imports.Import <imports.Import>` object\n        \"\"\"\n        schema = ImportSchema()\n        resp = self.service.post(self.base,\n                                 params={'url': url, 'token': token, 'username': username, 'password': password, 'insecure': insecure})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_commit_request(self, id): # pylint: disable=invalid-name,redefined-builtin\n        schema = RequestSchema()\n        resp = self.service.get(self.base+str(id)+'/request/')\n        return self.service.decode(schema, resp)", "response": "Get a commit request for a staged import ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommitting a staged import.", "response": "def commit(self, id, impreq): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Commit a staged import.\n\n        :param id: Staged import ID as an int.\n        :param impreq: :class:`imports.Request <imports.Request>` object\n        :return: :class:`imports.Request <imports.Request>` object\n        :rtype: imports.Request\n        \"\"\"\n        schema = RequestSchema()\n        json = self.service.encode(schema, impreq)\n\n        schema = RequestSchema()\n        resp = self.service.post(self.base+str(id)+'/', json=json)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef model_to_dict(instance, **options):\n    \"Takes a model instance and converts it into a dict.\"\n\n    options = _defaults(options)\n    attrs = {}\n\n    if options['prehook']:\n        if isinstance(options['prehook'], collections.Callable):\n            instance = options['prehook'](instance)\n            if instance is None:\n                return attrs\n\n    # Items in the `fields` list are the output aliases, not the raw\n    # accessors (field, method, property names)\n    for alias in options['fields']:\n\n        # Get the accessor for the object\n        accessor = options['aliases'].get(alias, alias)\n\n        # Create the key that will be used in the output dict\n        key = options['prefix'] + alias\n\n        # Optionally camelcase the key\n        if options['camelcase']:\n            key = convert_to_camel(key)\n\n        # Get the field value. Use the mapped value to the actually property or\n        # method name. `value` may be a number of things, so the various types\n        # are checked below.\n        value = get_field_value(instance, accessor,\n                                allow_missing=options['allow_missing'])\n\n        # Related objects, perform some checks on their options\n        if isinstance(value, (models.Model, QuerySet)):\n            _options = _defaults(options['related'].get(accessor, {}))\n\n            # If the `prefix` follows the below template, generate the\n            # `prefix` for the related object\n            if '%(accessor)s' in _options['prefix']:\n                _options['prefix'] = _options['prefix'] % {'accessor': alias}\n\n            if isinstance(value, models.Model):\n                if len(_options['fields']) == 1 and _options['flat'] \\\n                        and not _options['merge']:\n                    value = list(serialize(value, **_options).values())[0]\n                else:\n                    # Recurse, get the dict representation\n                    _attrs = serialize(value, **_options)\n\n                    # Check if this object should be merged into the parent,\n                    # otherwise nest it under the accessor name\n                    if _options['merge']:\n                        attrs.update(_attrs)\n                        continue\n\n                    value = _attrs\n            else:\n                value = serialize(value, **_options)\n\n        attrs[key] = value\n\n    # Apply post-hook to serialized attributes\n    if options['posthook']:\n        attrs = options['posthook'](instance, attrs)\n\n    return attrs", "response": "Takes a model instance and converts it into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize(self, obj, fields=None, exclude=None, **options):\n        options = _merge({}, self.options, options)\n\n        # Handle model instances\n        if isinstance(obj, models.Model):\n            fields = parse_selectors(obj.__class__, fields, exclude, **options)\n            return model_to_dict(obj, fields=fields, **options)\n\n        # Handle querysets\n        if isinstance(obj, QuerySet):\n            fields = parse_selectors(obj.model, fields, exclude, **options)\n            return queryset_to_list(obj, fields=fields, **options)\n\n        # Handle dict instances\n        if isinstance(obj, dict):\n            exclude = exclude or []\n            if not fields:\n                fields = iter(obj.keys())\n            fields = [x for x in fields if x not in exclude]\n            return model_to_dict(obj, fields=fields, **options)\n\n        # Handle other iterables\n        if hasattr(obj, '__iter__'):\n            return [self.serialize(x, fields, exclude, **options) for x in obj]\n\n        return obj", "response": "Recursively attempts to find Model and QuerySet instances\n        to convert them into their representative datastructure per their\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_save_directory(base, source):\n    root = os.path.join(base, source)\n    if not os.path.isdir(root):\n        os.makedirs(root)\n\n    world.screenshot_root = root", "response": "Sets the root save directory for saving screenshots."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging a user s password.", "response": "def change_password(self, id, new, old=None, change_token=True): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Change a user's password.\n\n        :param id: User ID as an int.\n        :param new: New password as string.\n        :param old: (optional) Old password as string (required if performing action as non-admin).\n        :param change_token: (optional) If bool `True`, also generate a new API token for user.\n        :return: :class:`users.User <users.User>` object\n        :rtype: users.User\n        \"\"\"\n        schema = UserSchema(exclude=('password', 'password_confirm'))\n        resp = self.service.post(self.base+str(id)+'/password/',\n                                  params={'change_token': change_token},\n                                  json={'old': old, 'new': new, 'new_confirm': new})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange a user s token.", "response": "def change_token(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Change a user's token.\n\n        :param id: User ID as an int.\n        :return: :class:`users.User <users.User>` object\n        :rtype: users.User\n        \"\"\"\n        schema = UserSchema(exclude=('password', 'password_confirm'))\n        resp = self.service.post(self.base+str(id)+'/token/')\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bulk_copy(self, ids):\n        schema = UserSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)", "response": "Bulk copy a set of users."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fifo_for_evict(cache_dict, evict_number=1):\n    ordered_dict = sorted(cache_dict.items(), key=lambda t: t[1]['birthday'])\n    evicted_keys = []\n    if len(cache_dict) < evict_number:\n        evict_number = len(cache_dict)\n    for i in range(evict_number):\n        item = ordered_dict[i]\n        key = item[0]\n        cache_dict.pop(key)\n        evicted_keys.append(key)\n    return evicted_keys", "response": "This function will find the next set of items in the cache_dict and remove them from the cache_dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing LRU(Least Recently Used) strategy for evicting, the item that last used of time is the earliest will be removed. The parameter cache_dict must is an OrderedDict because its implementation based on the OrderedDict and reinsert key and value when every time to get the cache, this operation will make the cache of the often used is in the tail of OrderedDict and head of the OrderedDict is a cache of the least recently used. Test: >>> import collections >>> from common_cache import CacheItem >>> dict = {'a' : 0, 'b' : 1} >>> lru_for_evict(dict) Traceback (most recent call last): ... ValueError: Not supported type <class 'dict'> >>> cache = collections.OrderedDict() >>> cache['a'] = CacheItem(key='a', value=0, expire=3) >>> cache['b'] = CacheItem(key='b', value=1, expire=3) >>> cache['c'] = CacheItem(key='c', value=2, expire=3) >>> cache['d'] = CacheItem(key='d', value=3, expire=3) >>> lru_for_evict(cache) ['a'] >>> len(cache) 3 >>> lru_for_evict(cache, evict_number=2) ['b', 'c'] >>> len(cache) 1 >>> lru_for_evict(cache, evict_number=10) ['d'] >>> len(cache) 0", "response": "def lru_for_evict(cache_dict, evict_number=1):\n    \"\"\"\n    Use LRU(Least Recently Used) strategy for evicting, the item that last used of time is the earliest will be removed.\n    The parameter cache_dict must is an OrderedDict because its implementation based on the OrderedDict and reinsert key\n    and value when every time to get the cache, this operation will make the cache of the often used is in the\n    tail of OrderedDict and head of the OrderedDict is a cache of the least recently used.\n\n    Test:\n    >>> import collections\n    >>> from common_cache import CacheItem\n    >>> dict = {'a' : 0, 'b' : 1}\n    >>> lru_for_evict(dict)\n    Traceback (most recent call last):\n        ...\n    ValueError: Not supported type <class 'dict'>\n    >>> cache = collections.OrderedDict()\n    >>> cache['a'] = CacheItem(key='a', value=0, expire=3)\n    >>> cache['b'] = CacheItem(key='b', value=1, expire=3)\n    >>> cache['c'] = CacheItem(key='c', value=2, expire=3)\n    >>> cache['d'] = CacheItem(key='d', value=3, expire=3)\n    >>> lru_for_evict(cache)\n    ['a']\n    >>> len(cache)\n    3\n    >>> lru_for_evict(cache, evict_number=2)\n    ['b', 'c']\n    >>> len(cache)\n    1\n    >>> lru_for_evict(cache, evict_number=10)\n    ['d']\n    >>> len(cache)\n    0\n    \"\"\"\n    if not isinstance(cache_dict, collections.OrderedDict):\n        raise ValueError('Not supported type %s' % type(cache_dict))\n    evicted_keys = []\n    if len(cache_dict) < evict_number:\n        evict_number = len(cache_dict)\n    for i in range(evict_number):\n        item = cache_dict.popitem(last=False)\n        evicted_keys.append(item[0])\n    return evicted_keys"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(self, id, filter=None, type=None, sort=None, limit=None, page=None): # pylint: disable=invalid-name,redefined-builtin\n        schema = AttachmentSchema(exclude=('path'))\n        resp = self.service.list(self._base(id), filter, type, sort, limit, page)\n        at, l = self.service.decode(schema, resp, many=True, links=True)\n        return Page(at, l)", "response": "Get a list of a device s attachments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iter_list(self, id, *args, **kwargs):\n        l = partial(self.list, id)\n        return self.service.iter_list(l, *args, **kwargs)", "response": "Get a list of attachments by device ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a device s attachment.", "response": "def get(self, id, attid): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get a device's attachment.\n\n        :param id: Device ID as an int.\n        :param attid: Attachment ID as an int.\n        :return: :class:`attachments.Attachment <attachments.Attachment>` object\n        :rtype: attachments.Attachment\n        \"\"\"\n        schema = AttachmentSchema()\n        resp = self.service.get_id(self._base(id), attid)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an attachment to a device.", "response": "def create(self, id, fd, filename='attachment-name'): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Add an attachment to a device.\n\n        :param id: Device ID as an int.\n        :param fd: File-like object to upload.\n        :param filename: (optional) Name to use for new attachment as a string.\n        :return: :class:`attachments.Attachment <attachments.Attachment>` object\n        :rtype: attachments.Attachment\n        \"\"\"\n        schema = AttachmentSchema(exclude=('id', 'created', 'updated', 'size', 'path', 'device_id'))\n        resp = self.service.post(self._base(id),\n                                 files={'file': (filename, fd)})\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(self, id, attid): # pylint: disable=invalid-name,redefined-builtin\n        resp = self.service.get_id(self._base(id), attid, params={'format': 'download'}, stream=True)\n        b = io.BytesIO()\n        stream.stream_response_to_file(resp, path=b)\n        resp.close()\n        b.seek(0)\n        return (b, self.service.filename(resp))", "response": "Download a device s attachment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit(self, resource): # pylint: disable=invalid-name,redefined-builtin\n        schema = AttachmentSchema(exclude=('id', 'created', 'updated', 'size', 'path', 'device_id'))\n        json = self.service.encode(schema, resource)\n\n        schema = AttachmentSchema()\n        resp = self.service.edit(self._base(resource.device_id), resource.id, json)\n        return self.service.decode(schema, resp)", "response": "Edit a device s attachment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a device s attachment.", "response": "def delete(self, id, attid): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Delete a device's attachment.\n\n        :param id: Device ID as an int.\n        :param attid: Attachment ID as an int.\n        \"\"\"\n        return self.service.edit(self._base(id), attid)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_by_name(self, name): # pylint: disable=invalid-name,redefined-builtin\n        rs, _ = self.list(filter=field('name').eq(name), limit=1)\n        if len(rs) is 0:\n            raise CDRouterError('no such device')\n        return rs[0]", "response": "Get a device by name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edit(self, resource):\n        schema = DeviceSchema(exclude=('id', 'created', 'updated', 'result_id', 'attachments_dir'))\n        json = self.service.encode(schema, resource)\n\n        schema = DeviceSchema()\n        resp = self.service.edit(self.base, resource.id, json)\n        return self.service.decode(schema, resp)", "response": "Edit a device.\n\n        :param resource: :class:`devices.Device <devices.Device>` object\n        :return: :class:`devices.Device <devices.Device>` object\n        :rtype: devices.Device"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget information on proxy connection to a device s management interface.", "response": "def get_connection(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Get information on proxy connection to a device's management interface.\n\n        :param id: Device ID as an int.\n        :return: :class:`devices.Connection <devices.Connection>` object\n        :rtype: devices.Connection\n        \"\"\"\n        schema = ConnectionSchema()\n        resp = self.service.get(self.base+str(id)+'/connect/')\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening proxy connection to a device s management interface.", "response": "def connect(self, id): # pylint: disable=invalid-name,redefined-builtin\n        \"\"\"Open proxy connection to a device's management interface.\n\n        :param id: Device ID as an int.\n        :return: :class:`devices.Connection <devices.Connection>` object\n        :rtype: devices.Connection\n        \"\"\"\n        schema = ConnectionSchema()\n        resp = self.service.post(self.base+str(id)+'/connect/')\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disconnect(self, id): # pylint: disable=invalid-name,redefined-builtin\n        return self.service.post(self.base+str(id)+'/disconnect/')", "response": "Close proxy connection to a device s management interface."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef power_on(self, id): # pylint: disable=invalid-name,redefined-builtin\n        schema = PowerCmdSchema()\n        resp = self.service.post(self.base+str(id)+'/power/on/')\n        return self.service.decode(schema, resp)", "response": "Power on a device using it s power on command."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbulks copy a set of devices.", "response": "def bulk_copy(self, ids):\n        \"\"\"Bulk copy a set of devices.\n\n        :param ids: Int list of device IDs.\n        :return: :class:`devices.Device <devices.Device>` list\n        \"\"\"\n        schema = DeviceSchema()\n        return self.service.bulk_copy(self.base, self.RESOURCE, ids, schema)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps value in list if it is not one.", "response": "def ensure_list(value: Union[T, Sequence[T]]) -> Sequence[T]:\n    \"\"\"Wrap value in list if it is not one.\"\"\"\n    if value is None:\n        return []\n    return value if isinstance(value, list) else [value]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef color(out_string, color='grn'):\n    c = {\n        'blk': Fore.BLACK,\n        'blu': Fore.BLUE,\n        'cyn': Fore.CYAN,\n        'grn': Fore.GREEN,\n        'mag': Fore.MAGENTA,\n        'red': Fore.RED,\n        'wht': Fore.WHITE,\n        'yel': Fore.YELLOW,\n    }\n    try:\n        init()\n        return (c[color] + Style.BRIGHT + out_string + Fore.RESET + Style.NORMAL)\n    except AttributeError:\n        return out_string", "response": "Highlights a string in terminal color."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds ANSI codes for diff lines to output", "response": "def color_diffs(string):\n    \"\"\" Add color ANSI codes for diff lines.\n\n    Purpose: Adds the ANSI/win32 color coding for terminal output to output\n           | produced from difflib.\n\n    @param string: The string to be replacing\n    @type string: str\n\n    @returns: The new string with ANSI codes injected.\n    @rtype: str\n    \"\"\"\n    string = string.replace('--- ', color('--- ', 'red'))\n    string = string.replace('\\n+++ ', color('\\n+++ '))\n    string = string.replace('\\n-', color('\\n-', 'red'))\n    string = string.replace('\\n+', color('\\n+'))\n    string = string.replace('\\n@@ ', color('\\n@@ ', 'yel'))\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_script(browser, url):\n    if browser.current_url.startswith('file:'):\n        url = 'https:' + url\n    browser.execute_script(\"\"\"\n    var script_tag = document.createElement(\"script\");\n    script_tag.setAttribute(\"type\", \"text/javascript\");\n    script_tag.setAttribute(\"src\", arguments[0]);\n    document.getElementsByTagName(\"head\")[0].appendChild(script_tag);\n    \"\"\", url)\n\n    sleep(1)", "response": "Ensure that JavaScript at a given URL is available to the browser."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_elements_by_jquery(browser, selector):\n    try:\n        return browser.execute_script(\"\"\"return ($ || jQuery)(arguments[0]).get();\"\"\", selector)\n    except WebDriverException as e:\n        if e.msg.startswith(u'$ is not defined'):\n            load_script(browser, \"//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js\")\n            return browser.execute_script(\"\"\"return ($ || jQuery)(arguments[0]).get();\"\"\", selector)\n        else:\n            raise", "response": "Find HTML elements using jQuery - style selectors."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_element_by_jquery(step, browser, selector):\n    elements = find_elements_by_jquery(browser, selector)\n    assert_true(step, len(elements) > 0)\n    return elements[0]", "response": "Find a single HTML element using jQuery - style selectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True when we can access the REST API.", "response": "def can_access_api(self):\n        \"\"\"\n        :return: True when we can access the REST API\n        \"\"\"\n        try:\n            version_dict = self.get_version()\n        except Exception, e:\n            msg = 'An exception was raised when connecting to REST API: \"%s\"'\n            raise APIException(msg % e)\n        else:\n            \"\"\"\n            This is an example response from the REST API\n            {\n                \"branch\": \"develop\",\n                \"dirty\": \"Yes\",\n                \"revision\": \"f1cae98161 - 24 Jun 2015 16:29\",\n                \"version\": \"1.7.2\"\n            }\n            \"\"\"\n            if 'version' in version_dict:\n                # Yup, this looks like a w3af REST API\n                return True\n\n            msg = 'Unexpected HTTP response when connecting to REST API'\n            raise APIException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the Scan instances available in the remote API.", "response": "def get_scans(self):\n        \"\"\"\n        :return: A list with all the Scan instances available in the remote API\n        \"\"\"\n        code, data = self.send_request('/scans/', method='GET')\n\n        if code != 200:\n            msg = 'Failed to retrieve scans. Unexpected code %s'\n            raise APIException(msg % code)\n\n        scans = data.get('items', None)\n\n        if scans is None:\n            raise APIException('Failed to retrieve scans, no \"items\" in JSON.')\n\n        scan_instances = []\n        for scan_json in scans:\n            scan_id = scan_json['id']\n            scan_status = scan_json['status']\n            scan = Scan(self, scan_id=scan_id, status=scan_status)\n            scan_instances.append(scan)\n\n        return scan_instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the id of a label s for attribute", "response": "def element_id_by_label(browser, label):\n    \"\"\"Return the id of a label's for attribute\"\"\"\n    label = XPathSelector(browser,\n                          unicode('//label[contains(., \"%s\")]' % label))\n    if not label:\n        return False\n    return label.get_attribute('for')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_field(browser, field, value):\n    return find_field_by_id(browser, field, value) + \\\n        find_field_by_name(browser, field, value) + \\\n        find_field_by_label(browser, field, value)", "response": "Locate an input field of a given value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a field of any of the specified types.", "response": "def find_any_field(browser, field_types, field_name):\n    \"\"\"\n    Find a field of any of the specified types.\n    \"\"\"\n\n    return reduce(\n        operator.add,\n        (find_field(browser, field_type, field_name)\n         for field_type in field_types)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_field_by_label(browser, field, label):\n\n    return XPathSelector(browser,\n                         field_xpath(field, 'id', escape=False) %\n                         u'//label[contains(., \"{0}\")]/@for'.format(label))", "response": "Locate the control input that has a label pointing to it"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef option_in_select(browser, select_name, option):\n\n    select = find_field(browser, 'select', select_name)\n    assert select\n\n    try:\n        return select.find_element_by_xpath(unicode(\n            './/option[normalize-space(text()) = \"%s\"]' % option))\n    except NoSuchElementException:\n        return None", "response": "Returns the Element specified by option in the select2 widget."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _elements(self):\n        if not hasattr(self, '_elements_cached'):\n            setattr(self, '_elements_cached', list(self._select()))\n        return self._elements_cached", "response": "The cached list of elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of variables and their possibly os - dependent defaults.", "response": "def get_defaults():\n    \"\"\"\n    Returns a dictionary of variables and their possibly os-dependent defaults.\n    \n    \"\"\"\n    DEFAULTS = {}\n    # Determine the run-time pipe read/write buffer.\n    if 'PC_PIPE_BUF' in os.pathconf_names:\n        # unix\n        x, y = os.pipe()\n        DEFAULTS['PIPE_BUF'] = os.fpathconf(x, \"PC_PIPE_BUF\")\n    else:\n        # in Jython 16384\n        # on windows 512\n        # in jython in windows 512\n        DEFAULTS['PIPE_BUF'] = 512\n\n    # Determine the run-time socket buffers.\n    # Note that this number is determine on the papy server\n    # and inherited by the clients.\n    tcp_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    DEFAULTS['TCP_SNDBUF'] = tcp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_SNDBUF)\n    DEFAULTS['TCP_RCVBUF'] = tcp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_RCVBUF)\n    udp_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    DEFAULTS['UDP_SNDBUF'] = udp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_SNDBUF)\n    DEFAULTS['UDP_RCVBUF'] = udp_sock.getsockopt(socket.SOL_SOCKET, \\\n                                                 socket.SO_RCVBUF)\n\n    # check the ip visible from the world.\n    DEFAULTS['WHATS_MYIP_URL'] = \\\n    'http://www.whatismyip.com/automation/n09230945.asp'\n    return DEFAULTS"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a new logger.", "response": "def start_logger(log_to_file=False, \\\n                 log_to_stream=False, \\\n                 log_to_file_level=logging.INFO, \\\n                 log_to_stream_level=logging.INFO, \\\n                 log_filename=None, \\\n                 log_stream=None, \\\n                 log_rotate=True, \\\n                 log_size=524288, \\\n                 log_number=3):\n    \"\"\"\n    Configures and starts a logger to monitor the execution of a **PaPy** \n    pipeline.\n\n    Arguments:\n\n      - log_to_file(``bool``) [default: ``True``] Should we write logging \n        messages into a file?\n      - log_to_stream(``bool`` or ``object``) [default: ``False``] Should we \n        print logging messages to a stream? If ``True`` this defaults to \n        ``stderr``. \n      - log_to_file_level(``int``) [default: ``INFO``] The minimum logging \n        level of messages to be written to file. \n      - log_to_screen_level(``int``) [default: ``ERROR``] The minimum logging \n        level of messages to be printed to the stream.\n      - log_filename(``str``) [default: ``\"PaPy_log\"`` or ``\"PaPy_log_$TIME$\"``]\n        Name of the log file. Ignored if \"log_to_file\" is ``False``.\n      - log_rotate(``bool``) [default: ``True``] Should we limit the number of \n        logs? Ignored if \"log_to_file\" is ``False``.\n      - log_size(``int``) [default: ``524288``] Maximum number of ``bytes`` \n        saved in a single log file. Ignored if \"log_to_file\" is ``False``.\n      - log_number(``int``) [default: ``3``] Maximum number of rotated log files\n        Ignored if \"log_to_file\" is ``False``.\n        \n    \"\"\"\n    if log_rotate:\n        log_filename = log_filename or 'PaPy_log'\n    else:\n        run_time = \"_\".join(map(str, time.localtime()[0:5]))\n        log_filename = 'PaPy_log_%s' % run_time\n\n    root_log = logging.getLogger()\n    formatter = logging.Formatter(\n            \"%(levelname)s %(asctime)s,%(msecs).3d [%(name)s] - %(message)s\", \\\n            datefmt='%H:%M:%S')\n    root_log.setLevel(logging.DEBUG)\n    if log_to_file:\n        if log_rotate:\n            file_handler = logging.handlers.RotatingFileHandler(log_filename, \\\n                                    maxBytes=log_size, backupCount=log_number)\n        else:\n            file_handler = logging.FileHandler(log_filename, 'w')\n        file_handler.setLevel(log_to_file_level)\n        file_handler.setFormatter(formatter)\n        root_log.addHandler(file_handler)\n    if log_to_stream:\n        stream_handler = logging.StreamHandler(log_stream)\n        stream_handler.setLevel(log_to_stream_level)\n        stream_handler.setFormatter(formatter)\n        root_log.addHandler(stream_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the site URL.", "response": "def site_url(url):\n    \"\"\"\n    Determine the server URL.\n    \"\"\"\n    base_url = 'http://%s' % socket.gethostname()\n\n    if server.port is not 80:\n        base_url += ':%d' % server.port\n\n    return urlparse.urljoin(base_url, url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_external_id(account_info):\n    if all(k in account_info for k in ('external_id', 'external_method')):\n        return dict(id=account_info['external_id'],\n                    method=account_info['external_method'])\n    return None", "response": "Get external id from account info."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef oauth_get_user(client_id, account_info=None, access_token=None):\n    if access_token:\n        token = RemoteToken.get_by_token(client_id, access_token)\n        if token:\n            return token.remote_account.user\n\n    if account_info:\n        external_id = _get_external_id(account_info)\n        if external_id:\n            user_identity = UserIdentity.query.filter_by(\n                id=external_id['id'], method=external_id['method']).first()\n            if user_identity:\n                return user_identity.user\n        email = account_info.get('user', {}).get('email')\n        if email:\n            return User.query.filter_by(email=email).one_or_none()\n    return None", "response": "Retrieve the user object for the given client id and account info."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nauthenticates an oauth authorized callback.", "response": "def oauth_authenticate(client_id, user, require_existing_link=False):\n    \"\"\"Authenticate an oauth authorized callback.\n\n    :param client_id: The client id.\n    :param user: A user instance.\n    :param require_existing_link: If ``True``, check if remote account exists.\n        (Default: ``False``)\n    :returns: ``True`` if the user is successfully authenticated.\n    \"\"\"\n    # Authenticate via the access token (access token used to get user_id)\n    if not requires_confirmation(user):\n        after_this_request(_commit)\n        if login_user(user, remember=False):\n            if require_existing_link:\n                account = RemoteAccount.get(user.id, client_id)\n                if account is None:\n                    logout_user()\n                    return False\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef oauth_register(form):\n    if form.validate():\n        data = form.to_dict()\n        if not data.get('password'):\n            data['password'] = ''\n        user = register_user(**data)\n        if not data['password']:\n            user.password = None\n        _datastore.commit()\n        return user", "response": "Register user if possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef oauth_link_external_id(user, external_id=None):\n    try:\n        with db.session.begin_nested():\n            db.session.add(UserIdentity(\n                id=external_id['id'],\n                method=external_id['method'],\n                id_user=user.id\n            ))\n    except IntegrityError:\n        raise AlreadyLinkedError(user, external_id)", "response": "Link a user to an external id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting URL to redirect to and ensure that it is local.", "response": "def get_safe_redirect_target(arg='next'):\n    \"\"\"Get URL to redirect to and ensure that it is local.\n\n    :param arg: URL argument.\n    :returns: The redirect target or ``None``.\n    \"\"\"\n    for target in request.args.get(arg), request.referrer:\n        if target:\n            redirect_uri = urisplit(target)\n            allowed_hosts = current_app.config.get('APP_ALLOWED_HOSTS', [])\n            if redirect_uri.host in allowed_hosts:\n                return target\n            elif redirect_uri.path:\n                return uricompose(\n                    path=redirect_uri.path,\n                    query=redirect_uri.query,\n                    fragment=redirect_uri.fragment\n                )\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_registrationform(*args, **kwargs):\n    class RegistrationForm(_security.confirm_register_form):\n        password = None\n        recaptcha = None\n    return RegistrationForm(*args, **kwargs)", "response": "Create a registration form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfill the form with data.", "response": "def fill_form(form, data):\n    \"\"\"Prefill form with data.\n\n    :param form: The form to fill.\n    :param data: The data to insert in the form.\n    :returns: A pre-filled form.\n    \"\"\"\n    for (key, value) in data.items():\n        if hasattr(form, key):\n            if isinstance(value, dict):\n                fill_form(getattr(form, key), value)\n            else:\n                getattr(form, key).data = value\n    return form"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the right param to disable CSRF depending on WTF - Form version.", "response": "def _get_csrf_disabled_param():\n    \"\"\"Return the right param to disable CSRF depending on WTF-Form version.\n\n    From Flask-WTF 0.14.0, `csrf_enabled` param has been deprecated in favor of\n    `meta={csrf: True/False}`.\n    \"\"\"\n    import flask_wtf\n    from pkg_resources import parse_version\n    supports_meta = parse_version(flask_wtf.__version__) >= parse_version(\n        \"0.14.0\")\n    return dict(meta={'csrf': False}) if supports_meta else \\\n        dict(csrf_enabled=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind and load step definitions and load features under base_path specified on constructor", "response": "def run(self):\n        \"\"\" Find and load step definitions, and them find and load\n        features under `base_path` specified on constructor\n        \"\"\"\n        try:\n            self.loader.find_and_load_step_definitions()\n        except StepLoadingError, e:\n            print \"Error loading step definitions:\\n\", e\n            return\n\n        results = []\n        if self.explicit_features:\n            features_files = self.explicit_features\n        else:\n            features_files = self.loader.find_feature_files()\n        if self.random:\n            random.shuffle(features_files)\n\n        if not features_files:\n            self.output.print_no_features_found(self.loader.base_dir)\n            return\n\n        processes = Pool(processes=self.parallelization)\n        test_results_it = processes.imap_unordered(\n            worker_process, [(self, filename) for filename in features_files]\n        )\n        \n        all_total = ParallelTotalResult()\n        for result in test_results_it:\n            all_total += result['total']\n            sys.stdout.write(result['stdout'])\n            sys.stderr.write(result['stderr'])\n\n        return all_total"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deep_nodes(self, allnodes=None):\n        allnodes = (allnodes or [])\n        for (node, node_) in ((node, node_) for (node, node_) in\\\n            self.iteritems() if not node in allnodes):\n            allnodes.append(node)\n            node_.deep_nodes(allnodes)\n        return allnodes", "response": "A recursive method to return a list of all ** node objects ** \n       | connected from this toplogical node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmp_branch(self, node1, node2):\n        # note reverse\n        return cmp(getattr(self[node2], \"branch\", None), \\\n                   getattr(self[node1], \"branch\", None))", "response": "compare two nodes based on the branch attribute of \n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef postorder(self):\n        nodes_random = self.nodes()\n        # for debugging we could make it more random;)\n        # from random import shuffle\n        # shuffle(nodes_random)\n        # 1. sort branches\n        nodes_by_branch = sorted(nodes_random, cmp=self.cmp_branch)\n        # 1. topological sort\n        nodes_topological = []\n        for node in nodes_by_branch:\n            self.dfs(node, nodes_topological)\n        self.clear_nodes()\n        # 2. earthworm sort\n        nodes_consecutive = []\n        for node in nodes_topological:\n            Node = self[node]\n            outgoing_nodes = Node.nodes()\n            if outgoing_nodes:\n                last_index = max([nodes_consecutive.index(on) for on in \\\n                                   outgoing_nodes])\n                nodes_consecutive.insert(last_index + 1, node)\n            else:\n                nodes_consecutive.append(node)\n        return nodes_consecutive", "response": "Returns a valid postorder of the node objects in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef node_rank(self):\n        nodes = self.postorder()\n        node_rank = {}\n        for node in nodes:\n            max_rank = 0\n            for child in self[node].nodes():\n                some_rank = node_rank[child] + 1\n                max_rank = max(max_rank, some_rank)\n            node_rank[node] = max_rank\n        return node_rank", "response": "Returns the maximum rank for each topological node in theDictGraph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the width of each node in the graph.", "response": "def node_width(self):\n        \"\"\"\n        Returns the width of each node in the graph. #TODO\n        \n        \"\"\"\n        nodes = self.postorder()\n        node_width = {}\n        for node in nodes:\n            sum_width = 0\n            for child in self[node].nodes():\n                sum_width += node_width[child]\n            node_width[node] = (sum_width or 1)\n        return node_width"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rank_width(self):\n        rank_width = defaultdict(int)\n        node_rank = self.node_rank()\n        for rank in node_rank.values():\n            rank_width[rank] += 1\n        return dict(rank_width)", "response": "Returns the width of each rank in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a **node object ** to the dictGraph. Returns True if the object is already in the DictGraph False otherwise.", "response": "def add_node(self, node, xtra=None, branch=None):\n        \"\"\"\n        Adds a **node object** to the ``DictGraph``. Returns ``True`` if a \n        new **node object** has been added. If the **node object** is already in\n        the ``DictGraph`` returns ``False``.\n        \n        Arguments:\n        \n          - node(``object``) Node to be added. Any hashable Python ``object``.\n          - xtra(``dict``) [default: ``None``] The newly created topological \n            ``Node.xtra`` dictionary will be updated with the contents of this \n            dictionary. \n          - branch(``object``) [default: ``None``] an identificator used to \n            sort topologically equivalent branches.\n                \n        \"\"\"\n        if not node in self:\n            node_ = DictNode(node, xtra)\n            self.update(node_)\n            self[node].branch = (branch or getattr(node, \"branch\", None))\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef del_node(self, node):\n        for node_ in self.values():\n            if node in node_:\n                node_.pop(node)\n        return bool(self.pop(node))", "response": "Removes a **node object ** from the DictGraph. Returns True if the node object has been removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_edge(self, edge, double=False):\n        (left_entity, right_entity) = edge\n        self.add_node(left_entity)\n        self.add_node(right_entity)\n        self[left_entity].update({right_entity:self[right_entity]})\n        if double:\n            self.add_edge((edge[1], edge[0]))", "response": "Adds an edge to the DictGraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove an edge from the DictGraph.", "response": "def del_edge(self, edge, double=False):\n        \"\"\"\n        Removes an edge from the ``DictGraph``. An edge is a pair of **node \n        objects**. The **node objects** are not removed from the ``DictGraph``.\n        \n        Arguments:\n        \n          - edge(``tuple``) An ordered pair of **node objects**. The edge is \n            assumed to have a direction from the first to the second **node \n            object**.\n          - double(``bool``) [default: ``False```] If ``True`` the the reverse\n            edge is also removed.\n            \n        \"\"\"\n        (left_entity, right_entity) = edge\n        self[left_entity].pop(right_entity)\n        if double:\n            self.del_edge((edge[1], edge[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the nodes to the dictGraph.", "response": "def add_nodes(self, nodes, xtras=None):\n        \"\"\"\n        Adds **node objects** to the graph.\n        \n        Arguments:\n        \n          - nodes(iterable) Sequence of **node objects** to be added to the \n            ``DictGraph``\n                \n          - xtras(iterable) [default: ``None``] Sequence of ``Node.xtra`` \n            dictionaries corresponding to the **node objects** being added. \n            See: ``Graph.add_node``.\n            \n        \"\"\"\n        for node, xtra in izip(nodes, (xtras or repeat(None))):\n            self.add_node(node, xtra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_edges(self, edges, *args, **kwargs):\n        for edge in edges:\n            self.add_edge(edge, *args, **kwargs)", "response": "Adds edges to the dictionary graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves edges from the dictGraph.", "response": "def del_edges(self, edges, *args, **kwargs):\n        \"\"\"\n        Removes edges from the graph. Takes optional arguments for \n        ``DictGraph.del_edge``.\n        \n        Arguments:\n        \n          - edges(iterable) Sequence of edges to be removed from the \n            ``DictGraph``.\n            \n        \"\"\"\n        for edge in edges:\n            self.del_edge(edge, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edges(self, nodes=None):\n        # If a Node has been directly updated (__not__ recommended)\n        # then the Graph will not know the added nodes and therefore will\n        # miss half of their edges.\n        edges = set()\n        for node in (nodes or self.iterkeys()):\n            ends = self[node].nodes()\n            edges.update([(node, end) for end in ends])\n        return tuple(edges)", "response": "Returns a tuple of all edges in the DictGraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple of incoming edges for a node object.", "response": "def incoming_edges(self, node):\n        \"\"\"\n        Returns a ``tuple`` of incoming edges for a **node object**.\n        \n        Arguments:\n        \n          - node(``object``) **node object** present in the graph to be queried \n            for incoming edges.\n          \n        \"\"\"\n        edges = self.edges()\n        in_edges = []\n        for out_node, in_node in edges:\n            if node is in_node:\n                in_edges.append((out_node, in_node))\n        return tuple(in_edges)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a tuple of outgoing edges for a node object.", "response": "def outgoing_edges(self, node):\n        \"\"\"\n        Returns a ``tuple`` of outgoing edges for a **node object**.\n        \n        Arguments:\n        \n          - node(``object``) **node object** present in the graph to be queried \n            for outgoing edges.\n          \n        \"\"\"\n        #TODO: pls make outgoig_edges less insane\n        edges = self.edges()\n        out_edges = []\n        for out_node, in_node in edges:\n            if node is out_node:\n                out_edges.append((out_node, in_node))\n        return tuple(out_edges)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_connection(ip, username, password, function, args, write=False,\n                    conn_timeout=5, sess_timeout=300, port=22):\n    \"\"\" Open a Jaide session with the device.\n\n    To open a Jaide session to the device, and run the appropriate function\n    against the device. Arguments for the downstream function are passed\n    through.\n\n    @param ip: String of the IP or hostname of the device to connect to.\n    @type ip: str\n    @param username: The string username used to connect to the device.\n    @type useranme: str\n    @param password: The string password used to connect to the device.\n    @type password: str\n    @param function: The downstream jaide.wrap function we'll be handing\n                   | off the jaide.Jaide() object to execute the command\n                   | once we've established the connection.\n    @type function: function pointer.\n    @param args: The arguments that we will hand off to the downstream\n               | function.\n    @type args: list\n    @param write: If set, it would be a tuple that we pass back as part of\n                | our return statement, so that any callback function\n                | can know how and where to put the output from the device.\n    @type write: False or tuple.\n    @param conn_timeout: Sets the connection timeout value. This is how\n                       | we'll wait when connecting before classifying\n                       | the device unreachable.\n    @type conn_timeout: int\n    @param sess_timeout: Sets the session timeout value. A higher value may\n                       | be desired for long running commands, such as\n                       | 'request system snapshot slice alternate'\n    @type sess_timeout: int\n    @param port: The port to connect to the device on. Defaults to 22.\n    @type port: int\n\n    @returns: We could return either just a string of the output from the\n            | device, or a tuple containing the information needed to write\n            | to a file and the string output from the device.\n    @rtype: Tuple or str\n    \"\"\"\n    # start with the header line on the output.\n    output = color('=' * 50 + '\\nResults from device: %s\\n' % ip, 'yel')\n    try:\n        # create the Jaide session object for the device.\n        conn = Jaide(ip, username, password, connect_timeout=conn_timeout,\n                     session_timeout=sess_timeout, port=port)\n        if write is not False:\n            return write, output + function(conn, *args)\n        else:\n            return output + function(conn, *args)\n    except errors.SSHError:\n        output += color('Unable to connect to port %s on device: %s\\n' %\n                        (str(port), ip), 'red')\n    except errors.AuthenticationError:  # NCClient auth failure\n        output += color('Authentication failed for device: %s' % ip, 'red')\n    except AuthenticationException:  # Paramiko auth failure\n        output += color('Authentication failed for device: %s' % ip, 'red')\n    except SSHException as e:\n        output += color('Error connecting to device: %s\\nError: %s' %\n                        (ip, str(e)), 'red')\n    except socket.timeout:\n        output += color('Timeout exceeded connecting to device: %s' % ip, 'red')\n    except socket.gaierror:\n        output += color('No route to host, or invalid hostname: %s' % ip, 'red')\n    except socket.error:\n        output += color('The device refused the connection on port %s, or '\n                        'no route to host.' % port, 'red')\n    if write is not False:\n        return write, output\n    else:\n        return output", "response": "Open a connection to the specified device and run the appropriate function on it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command(jaide, commands, format=\"text\", xpath=False):\n    output = \"\"\n    for cmd in clean_lines(commands):\n        expression = \"\"\n        output += color('> ' + cmd + '\\n', 'yel')\n        # Get xpath expression from the command, if it is there.\n        # If there is an xpath expr, the output will be xml,\n        # overriding the req_format parameter\n        #\n        # Example command forcing xpath: show route % //rt-entry\n        if len(cmd.split('%')) == 2:\n            expression = cmd.split('%')[1].strip()\n            cmd = cmd.split('%')[0] + '\\n'\n        elif xpath is not False:\n            expression = xpath\n        if expression:\n            try:\n                output += jaide.op_cmd(command=cmd, req_format='xml',\n                                       xpath_expr=expression) + '\\n'\n            except lxml.etree.XMLSyntaxError:\n                output += color('Xpath expression resulted in no response.\\n',\n                                'red')\n        else:\n            output += jaide.op_cmd(cmd, req_format=format) + '\\n'\n    return output", "response": "Run an operational command on the specified object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef commit(jaide, commands, check, sync, comment, confirm, at_time, blank):\n    # set the commands to do nothing if the user wants a blank commit.\n    if blank:\n        commands = 'annotate system \"\"'\n    output = \"\"\n    # add show | compare output\n    if commands != \"\":\n        output += color(\"show | compare:\\n\", 'yel')\n        try:\n            output += color_diffs(jaide.compare_config(commands)) + '\\n'\n        except RPCError as e:\n            output += color(\"Could not get config comparison results before\"\n                            \" committing due to the following error:\\n%s\" %\n                            str(e))\n    # If they just want to validate the config, without committing\n    if check:\n        output += color(\"Commit check results from: %s\\n\" % jaide.host, 'yel')\n        try:\n            output += jaide.commit_check(commands) + '\\n'\n        except RPCError:\n            output += color(\"Uncommitted changes left on the device or someone\"\n                            \" else is in edit mode, couldn't lock the \"\n                            \"candidate configuration.\\n\", 'red')\n        except:\n            output += color(\"Failed to commit check on device %s for an \"\n                            \"unknown reason.\\n\" % jaide.host, 'red')\n    # Actually make a commit\n    else:\n        output += color(\"Attempting to commit on device: %s\\n\" % jaide.host,\n                        'yel')\n        try:\n            results = jaide.commit(confirmed=confirm, comment=comment,\n                                   at_time=at_time, synchronize=sync,\n                                   commands=commands)\n        except RPCError as e:\n            output += color('Commit could not be completed on this device, due'\n                            ' to the following error(s):\\n' + str(e), 'red')\n        # Jaide command succeeded, parse results\n        else:\n            if 'commit complete' in results:\n                output += results.split('commit complete')[0] + '\\n'\n                output += color('Commit complete on device: %s\\n' % jaide.host)\n                if confirm:\n                    output += color('Commit confirm will rollback in %s '\n                                    'minutes unless you commit again.\\n' %\n                                    str(confirm/60))\n            elif 'commit at' in results:\n                output += results.split('commit at will be executed at')[0]\n                output += color('Commit staged to happen at: %s\\n' % at_time)\n            else:\n                if 'failed' in results:\n                    output += (results.replace('failed', color('failed',\n                               'red')))\n                if 'red' in results:\n                    output += (results.replace('red', color('red',\n                               'red')))\n                output += color('Commit Failed on device: %s\\n' % jaide.host,\n                                'red')\n    return output", "response": "Execute a commit against a set of commands on a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a show | compare with some set commands.", "response": "def compare(jaide, commands):\n    \"\"\" Perform a show | compare with some set commands.\n\n    @param jaide: The jaide connection to the device.\n    @type jaide: jaide.Jaide object\n    @param commands: The set commands to send to the device to compare with.\n    @type commands: str or list\n\n    @returns: The output from the device.\n    @rtype str\n    \"\"\"\n    output = color(\"show | compare:\\n\", 'yel')\n    return output + color_diffs(jaide.compare_config(commands))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef diff_config(jaide, second_host, mode):\n    try:\n        # create a list of all the lines that differ, and merge it.\n        output = '\\n'.join([diff for diff in\n                            jaide.diff_config(second_host, mode.lower())])\n    except errors.SSHError:\n        output = color('Unable to connect to port %s on device: %s\\n' %\n                       (str(jaide.port), second_host), 'red')\n    except errors.AuthenticationError:  # NCClient auth failure\n        output = color('Authentication failed for device: %s' %\n                       second_host, 'red')\n    except AuthenticationException:  # Paramiko auth failure\n        output = color('Authentication failed for device: %s' %\n                       second_host, 'red')\n    except SSHException as e:\n        output = color('Error connecting to device: %s\\nError: %s' %\n                       (second_host, str(e)), 'red')\n    except socket.timeout:\n        output = color('Timeout exceeded connecting to device: %s' %\n                       second_host, 'red')\n    except socket.gaierror:\n        output = color('No route to host, or invalid hostname: %s' %\n                       second_host, 'red')\n    except socket.error:\n        output = color('The device refused the connection on port %s, or '\n                       'no route to host.' % jaide.port, 'red')\n    if output.strip() == '':\n        output = color(\"There were no config differences between %s and %s\\n\" %\n                       (jaide.host, second_host), 'yel')\n    else:\n        # color removals red, and additions green\n        return color_diffs(output)\n    return output", "response": "Perform a show compare with some set commands."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pull(jaide, source, destination, progress, multi):\n    output = color('Retrieving %s:%s, and putting it in %s\\n' %\n                   (jaide.host, source, path.normpath(destination)), 'yel')\n    # Check if the destination ends in a '/', if not, we need to add it.\n    destination = destination + '/' if destination[-1] != '/' else destination\n    # If the source ends in a slash, we need to remove it. For copying\n    # directories, this will ensure that the local directory gets created\n    # remotely, and not just the contents. Basically, this forces the behavior\n    # 'scp -r /var/log /dest/loc' instead of 'scp -r /var/log/* /dest/loc'\n    source = source[:-1] if source[-1] == '/' else source\n    source_file = path.basename(source) if not '' else path.basename(path.join(source, '..'))\n    dest_file = destination + jaide.host + '_' + source_file if multi else destination + source_file\n    try:\n        jaide.scp_pull(source, dest_file, progress)\n        if progress:  # move to the next line if we were printing the progress\n            click.echo('')\n    except SCPException as e:\n        output += color('!!! Error during copy from ' + jaide.host +\n                        '. Some files may have failed to transfer. SCP Module'\n                        ' error:\\n' + str(e) + ' !!!\\n', 'red')\n    except (IOError, OSError) as e:\n        output += color('!!! The local filepath was not found! Note that \\'~\\''\n                        ' cannot be used. Error:\\n' + str(e) + ' !!!\\n',\n                        'red')\n    else:\n        output += color('Received %s:%s and stored it in %s.\\n' %\n                        (jaide.host, source, path.normpath(dest_file)))\n    return output", "response": "Copy files from a device to a local machine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npushing a file from the local machine to the local machine.", "response": "def push(jaide, source, destination, progress, multi=False):\n    \"\"\" Copy file(s) from the local machine to a junos device.\n\n    @param jaide: The jaide connection to the device.\n    @type jaide: jaide.Jaide object\n    @param source: The source filepath on the junos device to pull.\n    @type source: str\n    @param destination: the destination filepath on the local device for\n                      | the files.\n    @type destination: str\n    @param progress: Flagged to True if the user desires to see the status\n                   | as the copy happens.\n    @type progress: bool\n    @param multi: Flagged to true if we're copying from multiple devices.\n                | Not needed in this function\n    @type multi: bool\n\n    @returns: The output of the copy.\n    @rtype str\n    \"\"\"\n    output = color('Pushing %s to %s:%s\\n' % (source, jaide.host, destination),\n                   'yel')\n    # Check if the destination ends in a '/', if not, we need to add it.\n    destination = destination + '/' if destination[-1] != '/' else destination\n    # If the source ends in a slash, we need to remove it. For copying\n    # directories, this will ensure that the local directory gets created\n    # remotely, and not just the contents. Basically, this forces the behavior\n    # 'scp -r /var/log /dest/loc' instead of 'scp -r /var/log/* /dest/loc'\n    source = source[:-1] if source[-1] == '/' else source\n    try:\n        jaide.scp_push(source, destination, progress)\n        if progress:\n            click.echo('')\n    except SCPException as e:\n        output += color('!!! Error during copy from ' + jaide.host +\n                        '. Some files may have failed to transfer. SCP Module'\n                        ' error:\\n' + str(e) + ' !!!\\n', 'red')\n    except (IOError, OSError) as e:\n        output += color('!!! The local filepath was not found! Note that \\'~\\''\n                        ' cannot be used. Error:\\n' + str(e) + ' !!!\\n',\n                        'red')\n    else:\n        output += color('Pushed %s to %s:%s\\n' % (source, jaide.host,\n                        destination))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends shell commands to a specific object.", "response": "def shell(jaide, commands):\n    \"\"\" Send shell commands to a device.\n\n    @param jaide: The jaide connection to the device.\n    @type jaide: jaide.Jaide object\n    @param commands: The shell commands to send to the device.\n    @type commands: str or list.\n\n    @returns: The output of the commands.\n    @rtype str\n    \"\"\"\n    out = \"\"\n    for cmd in clean_lines(commands):\n        out += color('> %s\\n' % cmd, 'yel')\n        out += jaide.shell_cmd(cmd) + '\\n'\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all keys from etcd.", "response": "def get_all_keys(reactor, key_type, value_type, etcd_address):\n    \"\"\"Returns all keys from etcd.\n\n    :param reactor: reference to Twisted' reactor.\n    :param etcd_address: Address with port number where etcd is\n        running.\n    :return: An instance of txaioetcd.Range containing all keys and\n        their values.\n    \"\"\"\n    etcd = Client(reactor, etcd_address)\n    result = yield etcd.get(b'\\x00', range_end=b'\\x00')\n\n    res = {}\n    for item in result.kvs:\n        if key_type == u'utf8':\n            key = item.key.decode('utf8')\n        elif key_type == u'binary':\n            key = binascii.b2a_base64(item.key).decode().strip()\n        else:\n            raise Exception('logic error')\n\n        if value_type == u'json':\n            value = json.loads(item.value.decode('utf8'))\n        elif value_type == u'binary':\n            value = binascii.b2a_base64(item.value).decode().strip()\n        elif value_type == u'utf8':\n            value = item.value.decode('utf8')\n        else:\n            raise Exception('logic error')\n\n        res[key] = value\n\n    returnValue(res)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self, timeout=None):\n        assert self.scan_id is not None, 'No scan_id has been set'\n\n        #\n        #   Simple stop\n        #\n        if timeout is None:\n            url = '/scans/%s/stop' % self.scan_id\n            self.conn.send_request(url, method='GET')\n            return\n\n        #\n        #   Stop with timeout\n        #\n        self.stop()\n\n        for _ in xrange(timeout):\n            time.sleep(1)\n\n            is_running = self.get_status()['is_running']\n            if not is_running:\n                return\n\n        msg = 'Failed to stop the scan in %s seconds'\n        raise ScanStopTimeoutException(msg % timeout)", "response": "Stop the scan and wait for the timeout"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef public_key_to_xrb_address(public_key):\n\n    if not len(public_key) == 32:\n        raise ValueError('public key must be 32 chars')\n\n    padded = b'000' + public_key\n    address = b32xrb_encode(padded)[4:]\n    checksum = b32xrb_encode(address_checksum(public_key))\n    return 'xrb_' + address.decode('ascii') + checksum.decode('ascii')", "response": "Convert public key to an xrb address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an xrb address to public key in bytes", "response": "def xrb_address_to_public_key(address):\n    \"\"\"\n    Convert an xrb address to public key in bytes\n\n    >>> xrb_address_to_public_key('xrb_1e3i81r51e3i81r51e3i81r51e3i'\\\n                                  '81r51e3i81r51e3i81r51e3imxssakuq')\n    b'00000000000000000000000000000000'\n\n    :param address: xrb address\n    :type address: bytes\n\n    :return: public key in bytes\n    :rtype: bytes\n\n    :raises ValueError:\n    \"\"\"\n\n    address = bytearray(address, 'ascii')\n\n    if not address.startswith(b'xrb_'):\n        raise ValueError('address does not start with xrb_: %s' % address)\n\n    if len(address) != 64:\n        raise ValueError('address must be 64 chars long: %s' % address)\n\n    address = bytes(address)\n    key_b32xrb = b'1111' + address[4:56]\n    key_bytes = b32xrb_decode(key_b32xrb)[3:]\n    checksum = address[56:]\n\n    if b32xrb_encode(address_checksum(key_bytes)) != checksum:\n        raise ValueError('invalid address, invalid checksum: %s' % address)\n\n    return key_bytes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_account(seed=None, index=0):\n\n    if not seed:\n        seed = unhexlify(''.join(random.choice('0123456789ABCDEF') for i in range(64)))\n\n    pair = keypair_from_seed(seed, index=index)\n    result = {\n        'address': public_key_to_xrb_address(pair['public']),\n        'private_key_bytes': pair['private'],\n        'public_key_bytes': pair['public'],\n    }\n    result['private_key_hex'] = hexlify(pair['private'])\n    result['public_key_hex'] = hexlify(pair['public'])\n\n    return result", "response": "Generate an account and keypair for the next random order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\"\"\"\n        self.init_config(app)\n        state = _OAuthClientState(app)\n        app.extensions['invenio-oauthclient'] = state\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the configuration of the application.", "response": "def init_config(self, app):\n        \"\"\"Initialize configuration.\"\"\"\n        for k in dir(config):\n            if k.startswith('OAUTHCLIENT_'):\n                app.config.setdefault(k, getattr(config, k))\n\n        @app.before_first_request\n        def override_template_configuration():\n            \"\"\"Override template configuration.\"\"\"\n            template_key = app.config.get(\n                'OAUTHCLIENT_TEMPLATE_KEY',\n                'SECURITY_LOGIN_USER_TEMPLATE'  # default template key\n            )\n            if template_key is not None:\n                template = app.config[template_key]  # keep the old value\n                app.config['OAUTHCLIENT_LOGIN_USER_TEMPLATE_PARENT'] = template\n                app.config[template_key] = app.config.get(\n                    'OAUTHCLIENT_LOGIN_USER_TEMPLATE',\n                    'invenio_oauthclient/login_user.html'\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spasser(inbox, s=None):\n    seq = (s or range(len(inbox)))\n    return [input_ for i, input_ in enumerate(inbox) if i in seq]", "response": "Returns a list of input_ objects that are spassered by the given inbox."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef szipper(inbox, s=None):\n    #TODO: test szipper\n    return zip(*[input_ for i, input_ in enumerate(inbox) if i in s])", "response": "Returns a generator that yields the inputs from inbox with indicies in s."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstrings joins input with indices in s.", "response": "def sjoiner(inbox, s=None, join=\"\"):\n    \"\"\" \n    String joins input with indices in s.\n\n    Arguments:\n\n      - s(sequence) [default: ``None``] ``tuple`` or ``list`` of indices of the\n        elements which will be joined.\n      - join(``str``) [default: ``\"\"``] String which will join the elements of \n        the inbox i.e. ``join.join()``.\n\n    \"\"\"\n    return join.join([input_ for i, input_ in enumerate(inbox) if i in s])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the first element of the input file to the provided stream.", "response": "def dump_stream(inbox, handle, delimiter=None):\n    \"\"\"\n    Writes the first element of the inbox to the provided stream (file handle) \n    delimiting the input by the optional delimiter string. Returns the name of\n    the file being written. \n    \n    Note that only a single process can have access to a file handle open for \n    writing. Therefore this function should only be used by a non-parallel \n    ``Piper``.\n\n    Arguments:\n\n      - handle(``file``) File handle open for writing.\n      - delimiter(``str``) [default: ``None``] A string which will seperate the\n        written items. e.g: ``\"END\"`` becomes ``\"\\\\nEND\\\\n\"`` in the output \n        stream. The default is an empty string which means that items will be \n        seperated by a blank line i.e.: ``\"\\\\n\\\\n\"`` (two new-line characters).\n        \n    \"\"\"\n    handle.write(inbox[0])\n    delimiter = '\\n%s\\n' % (delimiter or '')\n    handle.write(delimiter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator that yields the contents of a file in a sequence delimited by the delimiter string.", "response": "def load_stream(handle, delimiter=None):\n    \"\"\"\n    Creates a string generator from a stream (file handle) containing data \n    delimited by the delimiter strings. This is a stand-alone function and \n    should be used to feed external data into a pipeline.\n\n    Arguments:\n\n      - hande(``file``) A file handle open for reading.\n      - delimiter(``str``) [default: ``None``] The default means that items will\n        be separated by two new-line characters i.e.: ``\"\\\\n\\\\n\"``.\n    \n    \"\"\"\n    delimiter = (delimiter or \"\") + \"\\n\"\n    while True:\n        item = []\n        while True:\n            line = handle.readline()\n            if line == \"\":\n                raise StopIteration\n            elif line == delimiter:\n                if item:\n                    break\n            elif line != '\\n':\n                item.append(line)\n\n        yield \"\".join(item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump the first element of the given inbox as a file of a specified type.", "response": "def dump_item(inbox, type='file', prefix=None, suffix=None, dir=None, \\\n              timeout=320, buffer=None):\n    \"\"\"\n    Writes the first element of the inbox as a file of a specified type. The \n    type can be 'file', 'fifo' or 'socket' corresponding to typical  files, \n    named pipes (FIFOs). FIFOs and TCP sockets and are volatile i.e. exists only\n    as long as the Python process, which created them. FIFOs are local i.e.\n    allow to communicate processes only on the same computer.\n\n    This function returns a semi-random name of the file written. By default \n    creates files and fifos in the default temporary directory. To use named \n    pipes the operating system has to support both forks and fifos (not \n    Windows). Sockets should work on all operating systems.\n\n    This function is useful to efficently communicate parallel ``Pipers`` \n    without the overhead of using queues.\n\n    Arguments:\n\n      - type('file', 'fifo', 'socket') [default: 'file'] Type of the created \n        file-like object.\n      - prefix(``str``) [default: ``\"tmp_papy_%type%\"``] Prefix of the file to \n        be created. Should probably identify the ``Worker`` and ``Piper`` type. \n      - suffix(``str``) [default: ``''``] Suffix of the file to be created. \n        Should probably identify the format of the serialization protocol e.g. \n        ``\"pickle\"`` or deserialized data e.g. ``\"nubox\"``.\n      - dir(``str``) [default: ``tempfile.gettempdir()``] Directory to safe the\n        file to. (can be changed only for types ``\"file\"`` and ``\"fifo\"``)\n      - timeout(``int``) [default: ``320``] Number of seconds to keep the \n        process at the write-end of the ``\"socket\"`` or ``\"pipe\"`` alive.\n    \n    \"\"\"\n    # get a random filename generator\n    names = tempfile._get_candidate_names()\n    names.rng.seed() # re-seed rng after the fork\n    # try to own the file\n    if type in ('file', 'fifo'):\n        prefix = prefix or 'tmp_papy_%s' % type\n        suffix = suffix or ''\n        dir = dir or tempfile.gettempdir()\n        while True:\n            # create a random file name\n            file = prefix + names.next() + suffix#IGNORE:W0622\n            if type in ('file', 'fifo'):\n                file = os.path.join(dir, file)\n                try:\n                    if type == 'file':\n                        fd = os.open(file, tempfile._bin_openflags, 0600)\n                        tempfile._set_cloexec(fd) # ?, but still open\n                    elif type == 'fifo':\n                        os.mkfifo(file)\n                    file = os.path.abspath(file)\n                    break\n                except OSError, excp:\n                    # first try to close the fd\n                    try:\n                        os.close(fd)\n                    except OSError, excp_:\n                        if excp_.errno == errno.EBADF:\n                            pass\n                        # strange error better raise it\n                        raise excp_\n                    if excp.errno == errno.EEXIST:\n                        # file exists try another one\n                        continue\n                    # all other errors should be raise\n                    raise excp\n\n    # the os will create a random socket for us.\n    elif type in ('socket',):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        # try to bind to a port\n        try:\n            host = socket.gethostbyaddr(socket.gethostname())[0] # from /etc/hosts\n        except socket.gaierror:\n            host = urllib.urlopen(PAPY_DEFAULTS['WHATS_MYIP_URL']).read()\n        sock.bind(('', 0))           # os-chosen free port on all interfaces \n        port = sock.getsockname()[1] # port of the socket\n    else:\n        raise ValueError(\"type: %s not undertood\" % type)\n\n    if type == 'file':\n        # no forking\n        handle = open(file, 'wb')\n        os.close(fd) # no need to own a file twice!\n        handle.write(inbox[0])\n        handle.close() # close handle\n        file = (type, file, 0)\n    else:\n        # forking mode - forks should be waited\n        if type == 'fifo':\n            pid = os.fork()\n            if not pid:\n                # we set an alarm for 5min if nothing starts to read \n                # within this time the process gets killed.\n                signal.alarm(timeout)\n                fd = os.open(file, os.O_EXCL & os.O_CREAT | os.O_WRONLY)\n                signal.alarm(0)\n                os.write(fd, inbox[0])\n                os.close(fd)\n                os._exit(0)\n            file = (type, file, pid)\n        elif type == 'socket':\n            sock.listen(1)\n            pid = os.fork()\n            if not pid:\n                # sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                signal.alarm(timeout)\n                rsock, (rhost, rport) = sock.accept() # blocks until client connects\n                signal.alarm(0)\n                rsock.sendall(inbox[0])               # returns if all data was sent\n                # child closes all sockets and exits\n                rsock.close()\n                sock.close()\n                os._exit(0)\n            # parent closes server socket\n            sock.close()\n            file = (type, host, port)\n\n        # 0. get pid list and methods for atomic operations\n        # 1. add the child pid to the pid list\n        # 2. try to wait each pid in the list without blocking:\n        #    if success remove pid if not ready pass if OSError child not exists\n        #    another thread has waited this child.\n        # 0.\n        tid = threading._get_ident()\n        try:\n            pids = PAPY_RUNTIME[tid]\n        except KeyError:\n            PAPY_RUNTIME[tid] = []\n            pids = PAPY_RUNTIME[tid]\n        add_pid = pids.append   # list methods are atomic\n        del_pid = pids.remove\n        # 1.\n        add_pid(pid)\n        # 2. \n        for pid in pids:\n            try:\n                killed, status = os.waitpid(pid, os.WNOHANG)\n                if killed:\n                    del_pid(pid)\n            except OSError, excp:\n                if excp.errno == os.errno.ECHILD:\n                    continue\n                raise\n    # filename needs still to be unlinked\n    return file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_item(inbox, type=\"string\", remove=True, buffer=None):\n    is_file, is_fifo, is_socket = False, False, False\n\n    file = inbox[0]\n    try:\n        file_type = file[0]\n    except:\n        raise ValueError(\"invalid inbox item\")\n    if file_type == \"file\":\n        is_file = os.path.exists(file[1])\n    elif file_type == \"fifo\":\n        is_fifo = stat.S_ISFIFO(os.stat(file[1]).st_mode)\n    elif file_type == \"socket\":\n        # how to test is valid socket?\n        is_socket = True\n    else:\n        raise ValueError(\"type: %s not undertood\" % file_type)\n\n\n    if (is_fifo or is_socket) and (type == 'mmap'):\n        raise ValueError(\"mmap is not supported for FIFOs and sockets\")\n    if (is_fifo or is_socket) and not remove:\n        raise ValueError(\"FIFOs and sockets have to be removed\")\n\n    # get a fd and start/stop\n    start = 0\n    if is_fifo or is_file:\n        stop = os.stat(file[1]).st_size - 1\n        fd = os.open(file[1], os.O_RDONLY)\n        BUFFER = (buffer or PAPY_DEFAULTS['PIPE_BUF'])\n    elif is_socket:\n        host, port = socket.gethostbyname(file[1]), file[2]\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.connect((host, port))\n        stop = -1\n        fd = sock.fileno()\n        BUFFER = (buffer or PAPY_DEFAULTS['TCP_RCVBUF'])\n    else:\n        raise ValueError(\"got unknown inbox: %s\" % (repr(inbox)))\n\n    # get the data\n    if type == 'mmap':\n        offset = start - (start % (getattr(mmap, 'ALLOCATIONGRANULARITY', None)\\\n                                   or getattr(mmap, 'PAGESIZE')))\n        start = start - offset\n        stop = stop - offset + 1\n        try:\n            data = mmap.mmap(fd, stop, access=mmap.ACCESS_READ, offset=offset)\n        except TypeError:\n            # we're on Python 2.5\n            data = mmap.mmap(fd, stop, access=mmap.ACCESS_READ)\n        data.seek(start)\n\n    elif type == 'string':\n        data = []\n        if stop == -1:\n            while True:\n                buffer_ = os.read(fd, BUFFER)\n                if not buffer_:\n                    break\n                data.append(buffer_)\n            data = \"\".join(data)\n            # data = sock.recv(socket.MSG_WAITALL) \n            # this would read all the data from a socket\n        else:\n            os.lseek(fd, start, 0)\n            data = os.read(fd, stop - start + 1)\n    else:\n        raise ValueError('type: %s not understood.' % type)\n\n    # remove the file or close the socket\n    if remove:\n        if is_socket:\n            # closes client socket\n            sock.close()\n        else:\n            # pipes and files are just removed\n            os.close(fd)\n            os.unlink(file[1])\n    else:\n        os.close(fd)\n    # returns a string or mmap\n    return data", "response": "Loads a single item from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a generator that yields lines from a file handle.", "response": "def make_lines(handle, follow=False, wait=0.1):\n    \"\"\" \n    Creates a line generator from a stream (file handle) containing data in\n    lines.\n\n    Arguments:\n\n      - follow(``bool``) [default: ``False``] If ``True`` follows the file after\n        it finishes like 'tail -f'.\n      - wait(``float``) [default: ``0.1``] time to wait in seconds between file\n        polls.\n    \n    \"\"\"\n    while True:\n        line = handle.readline()\n        if line:\n            yield line\n        elif follow:\n            time.sleep(wait)\n        else:\n            raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pickle_dumps(inbox):\n    # http://bugs.python.org/issue4074\n    gc.disable()\n    str_ = cPickle.dumps(inbox[0], cPickle.HIGHEST_PROTOCOL)\n    gc.enable()\n    return str_", "response": "Serializes the first element of the input using the pickle protocol using\n    the fastes binary protocol."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef json_dumps(inbox):\n    gc.disable()\n    str_ = json.dumps(inbox[0])\n    gc.enable()\n    return str_", "response": "Serializes the first element of the input using the JSON protocol as \n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the at_time option for the current object.", "response": "def at_time_validate(ctx, param, value):\n    \"\"\" Callback validating the at_time commit option.\n\n    Purpose: Validates the `at time` option for the commit command. Only the\n           | the following two formats are supported: 'hh:mm[:ss]' or\n           | 'yyyy-mm-dd hh:mm[:ss]' (seconds are optional).\n\n    @param ctx: The click context paramter, for receiving the object dictionary\n              | being manipulated by other previous functions. Needed by any\n              | function with the @click.pass_context decorator. Callback\n              | functions such as this one receive this automatically.\n    @type ctx: click.Context\n    @param param: param is passed into a validation callback function by click.\n                | We do not use it.\n    @type param: None\n    @param value: The value that the user supplied for the at_time option.\n    @type value: str\n\n    @returns: The value that the user supplied, if it passed validation.\n            | Otherwise, raises click.BadParameter\n    @rtype: str\n    \"\"\"\n    # if they are doing commit_at, ensure the input is formatted correctly.\n    if value is not None:\n        if (re.search(r'([0-2]\\d)(:[0-5]\\d){1,2}', value) is None and\n            re.search(r'\\d{4}-[01]\\d-[0-3]\\d [0-2]\\d:[0-5]\\d(:[0-5]\\d)?',\n                      value) is None):\n            raise click.BadParameter(\"A commit at time must be in one of the \"\n                                     \"two formats: 'hh:mm[:ss]' or \"\n                                     \"'yyyy-mm-dd hh:mm[:ss]' (seconds are \"\n                                     \"optional).\")\n    ctx.obj['at_time'] = value\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_validate(ctx, param, value):\n    if value != (\"default\", \"default\"):\n        try:\n            mode, dest_file = (value[0], value[1])\n        except IndexError:\n            raise click.BadParameter('Expecting two arguments, one for how to '\n                                     'output (s, single, m, multiple), and '\n                                     'the second is a filepath where to put'\n                                     ' the output.')\n        if mode.lower() not in ['s', 'single', 'm', 'multiple']:\n            raise click.BadParameter('The first argument of the -w/--write '\n                                     'option must specifies whether to write'\n                                     ' to one file per device, or all device'\n                                     ' output to a single file. Valid options'\n                                     ' are \"s\", \"single\", \"m\", and \"multiple\"')\n        # we've passed the checks, so set the 'out' context variable to our\n        # tuple of the mode, and the destination file.\n        ctx.obj['out'] = (mode.lower(), dest_file)\n    else:  # they didn't use -w, so set the context variable accordingly.\n        ctx.obj['out'] = None", "response": "Validate the - w option."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmanipulate one or more Junos devices. Purpose: The main function is the entry point for the jaide tool. Click | handles arguments, commands and options. The parameters passed to | this function are all potential options (required or not) that | must come *before* the command from the group in the command line. @param ctx: The click context paramter, for receiving the object dictionary | being manipulated by other previous functions. Needed by any | function with the @click.pass_context decorator. @type ctx: click.Context @param host: The IP(s) or hostname(s) of the devices to connect to. @type host: str @param password: The string password used to connect to the device. @type password: str @param port: The numerical port to establish the connection to. Defauls | to 22. @type port: int @param quiet: An option that the user can set to suppress all output | from jaide. @type quiet: bool @param session_timeout: Sets the session timeout value. A higher value may | be desired for long running commands, such as | 'request system snapshot slice alternate' @type session_timeout: int @param connect_timeout: Sets the connection timeout value. This is how | we'll wait when connecting before classifying | the device unreachable. @type connect_timeout: int @param username: The string username used to connect to the device. @type useranme: str @returns: None. Functions part of click relating to the command group | 'main' do not return anything. Click handles passing context | between the functions and maintaing command order and chaining.", "response": "def main(ctx, host, password, port, quiet, session_timeout, connect_timeout,\n         username):\n    \"\"\" Manipulate one or more Junos devices.\n\n    Purpose: The main function is the entry point for the jaide tool. Click\n           | handles arguments, commands and options. The parameters passed to\n           | this function are all potential options (required or not) that\n           | must come *before* the command from the group in the command line.\n\n    @param ctx: The click context paramter, for receiving the object dictionary\n              | being manipulated by other previous functions. Needed by any\n              | function with the @click.pass_context decorator.\n    @type ctx: click.Context\n    @param host: The IP(s) or hostname(s) of the devices to connect to.\n    @type host: str\n    @param password: The string password used to connect to the device.\n    @type password: str\n    @param port: The numerical port to establish the connection to. Defauls\n               | to 22.\n    @type port: int\n    @param quiet: An option that the user can set to suppress all output\n                | from jaide.\n    @type quiet: bool\n    @param session_timeout: Sets the session timeout value. A higher value may\n                          | be desired for long running commands, such as\n                          | 'request system snapshot slice alternate'\n    @type session_timeout: int\n    @param connect_timeout: Sets the connection timeout value. This is how\n                          | we'll wait when connecting before classifying\n                          | the device unreachable.\n    @type connect_timeout: int\n    @param username: The string username used to connect to the device.\n    @type useranme: str\n\n    @returns: None. Functions part of click relating to the command group\n            | 'main' do not return anything. Click handles passing context\n            | between the functions and maintaing command order and chaining.\n    \"\"\"\n    # build the list of hosts\n    ctx.obj['hosts'] = [ip for ip in clean_lines(host)]\n    # set the connection parameters\n    ctx.obj['conn'] = {\n        \"username\": username,\n        \"password\": password,\n        \"port\": port,\n        \"session_timeout\": session_timeout,\n        \"connect_timeout\": connect_timeout\n    }\n    if quiet:\n        ctx.obj['out'] = \"quiet\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef commit(ctx, commands, blank, check, sync, comment, confirm, at_time):\n    if not blank and commands == 'annotate system \"\"':\n        raise click.BadParameter(\"--blank and the commands argument cannot\"\n                                 \" both be omitted.\")\n    mp_pool = multiprocessing.Pool(multiprocessing.cpu_count() * 2)\n    for ip in ctx.obj['hosts']:\n        mp_pool.apply_async(wrap.open_connection, args=(ip,\n                            ctx.obj['conn']['username'],\n                            ctx.obj['conn']['password'],\n                            wrap.commit,\n                            [commands, check, sync, comment, confirm,\n                             ctx.obj['at_time'], blank],\n                            ctx.obj['out'],\n                            ctx.obj['conn']['connect_timeout'],\n                            ctx.obj['conn']['session_timeout'],\n                            ctx.obj['conn']['port']), callback=write_out)\n    mp_pool.close()\n    mp_pool.join()", "response": "Execute a commit against the object dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare(ctx, commands):\n    mp_pool = multiprocessing.Pool(multiprocessing.cpu_count() * 2)\n    for ip in ctx.obj['hosts']:\n        mp_pool.apply_async(wrap.open_connection, args=(ip,\n                            ctx.obj['conn']['username'],\n                            ctx.obj['conn']['password'],\n                            wrap.compare, [commands],\n                            ctx.obj['out'],\n                            ctx.obj['conn']['connect_timeout'],\n                            ctx.obj['conn']['session_timeout'],\n                            ctx.obj['conn']['port']), callback=write_out)\n    mp_pool.close()\n    mp_pool.join()", "response": "Run the compare command for the specified commands."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy file from one device to another.", "response": "def pull(ctx, source, destination, progress):\n    \"\"\" Copy file(s) from device(s) -> local machine.\n\n    @param ctx: The click context paramter, for receiving the object dictionary\n              | being manipulated by other previous functions. Needed by any\n              | function with the @click.pass_context decorator.\n    @type ctx: click.Context\n    @param source: the source filepath or dirpath\n    @type source: str\n    @param destination: the destination filepath or dirpath\n    @type destination: str\n    @param progress: bool set to True if we should request a progress callback\n                   | from the Jaide object. Always set to False when\n                   | we're copying to/from multiple devices.\n    @type progress: bool\n\n    @returns: None. Functions part of click relating to the command group\n            | 'main' do not return anything. Click handles passing context\n            | between the functions and maintaing command order and chaining.\n    \"\"\"\n    mp_pool = multiprocessing.Pool(multiprocessing.cpu_count() * 2)\n    multi = True if len(ctx.obj['hosts']) > 1 else False\n    for ip in ctx.obj['hosts']:\n        mp_pool.apply_async(wrap.open_connection, args=(ip,\n                            ctx.obj['conn']['username'],\n                            ctx.obj['conn']['password'],\n                            wrap.pull, [source, destination, progress, multi],\n                            ctx.obj['out'],\n                            ctx.obj['conn']['connect_timeout'],\n                            ctx.obj['conn']['session_timeout'],\n                            ctx.obj['conn']['port']), callback=write_out)\n    mp_pool.close()\n    mp_pool.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push(ctx, source, destination, progress):\n    mp_pool = multiprocessing.Pool(multiprocessing.cpu_count() * 2)\n    for ip in ctx.obj['hosts']:\n        mp_pool.apply_async(wrap.open_connection, args=(ip,\n                            ctx.obj['conn']['username'],\n                            ctx.obj['conn']['password'],\n                            wrap.push, [source, destination, progress],\n                            ctx.obj['out'],\n                            ctx.obj['conn']['connect_timeout'],\n                            ctx.obj['conn']['session_timeout'],\n                            ctx.obj['conn']['port']), callback=write_out)\n    mp_pool.close()\n    mp_pool.join()", "response": "Pushes a file from one device to another."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef operational(ctx, commands, format, xpath):\n    mp_pool = multiprocessing.Pool(multiprocessing.cpu_count() * 2)\n    for ip in ctx.obj['hosts']:\n        mp_pool.apply_async(wrap.open_connection, args=(ip,\n                            ctx.obj['conn']['username'],\n                            ctx.obj['conn']['password'],\n                            wrap.command, [commands, format, xpath],\n                            ctx.obj['out'],\n                            ctx.obj['conn']['connect_timeout'],\n                            ctx.obj['conn']['session_timeout'],\n                            ctx.obj['conn']['port']), callback=write_out)\n    mp_pool.close()\n    mp_pool.join()", "response": "Execute a list of operational mode commands on the object dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallows for partial commands.", "response": "def get_command(self, ctx, cmd_name):\n        \"\"\" Allow for partial commands. \"\"\"\n        rv = click.Group.get_command(self, ctx, cmd_name)\n        if rv is not None:\n            return rv\n        matches = [x for x in self.list_commands(ctx)\n                   if x.startswith(cmd_name)]\n        if not matches:\n            return None\n        elif len(matches) == 1:\n            return click.Group.get_command(self, ctx, matches[0])\n        ctx.fail('Command ambiguous, could be: %s' %\n                 ', '.join(sorted(matches)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a value from from_unit units to to_unit units", "response": "def convert(value, from_unit, to_unit):\n    \"\"\"\n    Converts a value from `from_unit` units to `to_unit` units\n\n    :param value: value to convert\n    :type value: int or str or decimal.Decimal\n\n    :param from_unit: unit to convert from\n    :type from_unit: str\n\n    :param to_unit: unit to convert to\n    :type to_unit: str\n\n    >>> convert(value='1.5', from_unit='xrb', to_unit='krai')\n    Decimal('0.0015')\n    \"\"\"\n\n    if isinstance(value, float):\n        raise ValueError(\n            \"float values can lead to unexpected precision loss, please use a\"\n            \" Decimal or string eg.\"\n            \" convert('%s', %r, %r)\" % (value, from_unit, to_unit)\n        )\n\n    if from_unit not in UNITS_TO_RAW:\n        raise ValueError('unknown unit: %r' % from_unit)\n\n    if to_unit not in UNITS_TO_RAW:\n        raise ValueError('unknown unit: %r' % to_unit)\n\n    try:\n        value = Decimal(value)\n    except Exception:\n        raise ValueError('not a number: %r' % value)\n\n    from_value_in_base = UNITS_TO_RAW[from_unit]\n    to_value_in_base = UNITS_TO_RAW[to_unit]\n\n    result = value * (from_value_in_base / to_value_in_base)\n\n    return result.normalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(self, timeout=None):\n\n        def run(txn):\n            txn.execute(\"SELECT now()\")\n            rows = txn.fetchall()\n            res = \"{0}\".format(rows[0][0])\n            return res\n\n        return self._pool.runInteraction(run)", "response": "Get etcd cluster status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the keys in the key - value store.", "response": "def get(self,\n            key,\n            range_end=None,\n            count_only=None,\n            keys_only=None,\n            limit=None,\n            max_create_revision=None,\n            min_create_revision=None,\n            min_mod_revision=None,\n            revision=None,\n            serializable=None,\n            sort_order=None,\n            sort_target=None,\n            timeout=None):\n        \"\"\"\n        Range gets the keys in the range from the key-value store.\n\n        :param key: key is the first key for the range. If range_end is not given,\n            the request only looks up key.\n        :type key: bytes\n\n        :param range_end: range_end is the upper bound on the requested range\n            [key, range_end). If range_end is ``\\\\0``, the range is all keys ``\\u003e=`` key.\n            If the range_end is one bit larger than the given key, then the range requests\n            get the all keys with the prefix (the given key). If both key and range_end\n            are ``\\\\0``, then range requests returns all keys.\n        :type range_end: bytes\n\n        :param prefix: If set, and no range_end is given, compute range_end from key prefix.\n        :type prefix: bool\n\n        :param count_only: count_only when set returns only the count of the keys in the range.\n        :type count_only: bool\n\n        :param keys_only: keys_only when set returns only the keys and not the values.\n        :type keys_only: bool\n\n        :param limit: limit is a limit on the number of keys returned for the request.\n        :type limit: int\n\n        :param max_create_revision: max_create_revision is the upper bound for returned\n            key create revisions; all keys with greater create revisions will be filtered away.\n        :type max_create_revision: int\n\n        :param max_mod_revision: max_mod_revision is the upper bound for returned key\n            mod revisions; all keys with greater mod revisions will be filtered away.\n        :type max_mod_revision: int\n\n        :param min_create_revision: min_create_revision is the lower bound for returned\n            key create revisions; all keys with lesser create trevisions will be filtered away.\n        :type min_create_revision: int\n\n        :param min_mod_revision: min_mod_revision is the lower bound for returned key\n            mod revisions; all keys with lesser mod revisions will be filtered away.\n        :type min_min_revision: int\n\n        :param revision: revision is the point-in-time of the key-value store to use for the\n            range. If revision is less or equal to zero, the range is over the newest\n            key-value store. If the revision has been compacted, ErrCompacted is returned as\n            a response.\n        :type revision: int\n\n        :param serializable: serializable sets the range request to use serializable\n            member-local reads. Range requests are linearizable by default; linearizable\n            requests have higher latency and lower throughput than serializable requests\n            but reflect the current consensus of the cluster. For better performance, in\n            exchange for possible stale reads, a serializable range request is served\n            locally without needing to reach consensus with other nodes in the cluster.\n        :type serializable: bool\n\n        :param sort_order: Sort order for returned KVs,\n            one of :class:`txaioetcd.OpGet.SORT_ORDERS`.\n        :type sort_order: str\n\n        :param sort_target: Sort target for sorting returned KVs,\n            one of :class:`txaioetcd.OpGet.SORT_TARGETS`.\n        :type sort_taget: str or None\n\n        :param timeout: Request timeout in seconds.\n        :type timeout: int or None\n        \"\"\"\n\n        def run(pg_txn):\n            pg_txn.execute(\"SELECT pgetcd.get(%s,%s)\", (Binary(key), 10))\n            rows = pg_txn.fetchall()\n            res = \"{0}\".format(rows[0][0])\n            return res\n\n        return self._pool.runInteraction(run)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsubmits a transaction. Processes multiple requests in a single transaction. A transaction increments the revision of the key-value store and generates events with the same revision for every completed request. It is not allowed to modify the same key several times within one transaction. From google paxosdb paper: Our implementation hinges around a powerful primitive which we call MultiOp. All other database operations except for iteration are implemented as a single call to MultiOp. A MultiOp is applied atomically and consists of three components: 1. A list of tests called guard. Each test in guard checks a single entry in the database. It may check for the absence or presence of a value, or compare with a given value. Two different tests in the guard may apply to the same or different entries in the database. All tests in the guard are applied and MultiOp returns the results. If all tests are true, MultiOp executes t op (see item 2 below), otherwise it executes f op (see item 3 below). 2. A list of database operations called t op. Each operation in the list is either an insert, delete, or lookup operation, and applies to a single database entry. Two different operations in the list may apply to the same or different entries in the database. These operations are executed if guard evaluates to true. 3. A list of database operations called f op. Like t op, but executed if guard evaluates to false. :param txn: The transaction to submit. :type txn: instance of :class:`txaioetcd.Transaction` :param timeout: Request timeout in seconds. :type timeout: int :returns: An instance of :class:`txaioetcd.Success` or an exception of :class:`txioetcd.Failed` or :class:`txaioetcd.Error` :rtype: instance of :class:`txaioetcd.Success`, :class:`txaioetcd.Failed` or :class:`txaioetcd.Error`", "response": "def submit(self, txn, timeout=None):\n        \"\"\"\n        Submit a transaction.\n\n        Processes multiple requests in a single transaction.\n        A transaction increments the revision of the key-value store\n        and generates events with the same revision for every\n        completed request.\n\n        It is not allowed to modify the same key several times\n        within one transaction.\n\n        From google paxosdb paper:\n\n        Our implementation hinges around a powerful primitive which\n        we call MultiOp. All other database operations except for\n        iteration are implemented as a single call to MultiOp.\n        A MultiOp is applied atomically and consists of three components:\n\n        1. A list of tests called guard. Each test in guard checks\n           a single entry in the database. It may check for the absence\n           or presence of a value, or compare with a given value.\n           Two different tests in the guard may apply to the same or\n           different entries in the database. All tests in the guard\n           are applied and MultiOp returns the results. If all tests\n           are true, MultiOp executes t op (see item 2 below), otherwise\n           it executes f op (see item 3 below).\n\n        2. A list of database operations called t op. Each operation in\n           the list is either an insert, delete, or lookup operation, and\n           applies to a single database entry. Two different operations\n           in the list may apply to the same or different entries in\n           the database. These operations are executed if guard evaluates\n           to true.\n\n        3. A list of database operations called f op. Like t op, but\n           executed if guard evaluates to false.\n\n        :param txn: The transaction to submit.\n        :type txn: instance of :class:`txaioetcd.Transaction`\n\n        :param timeout: Request timeout in seconds.\n        :type timeout: int\n\n        :returns: An instance of :class:`txaioetcd.Success` or an exception\n            of :class:`txioetcd.Failed` or :class:`txaioetcd.Error`\n        :rtype: instance of :class:`txaioetcd.Success`,\n            :class:`txaioetcd.Failed` or :class:`txaioetcd.Error`\n        \"\"\"\n\n        def run(pg_txn):\n            val = Json(txn._marshal())\n            pg_txn.execute(\"SELECT pgetcd.submit(%s,%s)\", (val, 10))\n            rows = pg_txn.fetchall()\n            res = \"{0}\".format(rows[0][0])\n            return res\n\n        return self._pool.runInteraction(run)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to process a JSON message delivered from Amazon", "response": "def process_message(message, notification):\n    \"\"\"\n    Function to process a JSON message delivered from Amazon\n    \"\"\"\n    # Confirm that there are 'notificationType' and 'mail' fields in our\n    # message\n    if not set(VITAL_MESSAGE_FIELDS) <= set(message):\n        # At this point we're sure that it's Amazon sending the message\n        # If we don't return a 200 status code, Amazon will attempt to send us\n        # this same message a few seconds later.\n        logger.info('JSON Message Missing Vital Fields')\n        return HttpResponse('Missing Vital Fields')\n\n    if message['notificationType'] == 'Complaint':\n        return process_complaint(message, notification)\n    if message['notificationType'] == 'Bounce':\n        return process_bounce(message, notification)\n    if message['notificationType'] == 'Delivery':\n        return process_delivery(message, notification)\n    else:\n        return HttpResponse('Unknown Notification Type')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to process a bounce notification", "response": "def process_bounce(message, notification):\n    \"\"\"Function to process a bounce notification\"\"\"\n    mail = message['mail']\n    bounce = message['bounce']\n\n    bounces = []\n    for recipient in bounce['bouncedRecipients']:\n        # Create each bounce record. Add to a list for reference later.\n        bounces += [Bounce.objects.create(\n            sns_topic=notification['TopicArn'],\n            sns_messageid=notification['MessageId'],\n            mail_timestamp=clean_time(mail['timestamp']),\n            mail_id=mail['messageId'],\n            mail_from=mail['source'],\n            address=recipient['emailAddress'],\n            feedback_id=bounce['feedbackId'],\n            feedback_timestamp=clean_time(bounce['timestamp']),\n            hard=bool(bounce['bounceType'] == 'Permanent'),\n            bounce_type=bounce['bounceType'],\n            bounce_subtype=bounce['bounceSubType'],\n            reporting_mta=bounce.get('reportingMTA'),\n            action=recipient.get('action'),\n            status=recipient.get('status'),\n            diagnostic_code=recipient.get('diagnosticCode')\n        )]\n\n    # Send signals for each bounce.\n    for bounce in bounces:\n        signals.feedback.send(\n            sender=Bounce,\n            instance=bounce,\n            message=message,\n            notification=notification\n        )\n\n    logger.info('Logged %s Bounce(s)', str(len(bounces)))\n\n    return HttpResponse('Bounce Processed')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction to process a complaint notification", "response": "def process_complaint(message, notification):\n    \"\"\"Function to process a complaint notification\"\"\"\n    mail = message['mail']\n    complaint = message['complaint']\n\n    if 'arrivalDate' in complaint:\n        arrival_date = clean_time(complaint['arrivalDate'])\n    else:\n        arrival_date = None\n\n    complaints = []\n    for recipient in complaint['complainedRecipients']:\n        # Create each Complaint. Save in a list for reference later.\n        complaints += [Complaint.objects.create(\n            sns_topic=notification['TopicArn'],\n            sns_messageid=notification['MessageId'],\n            mail_timestamp=clean_time(mail['timestamp']),\n            mail_id=mail['messageId'],\n            mail_from=mail['source'],\n            address=recipient['emailAddress'],\n            feedback_id=complaint['feedbackId'],\n            feedback_timestamp=clean_time(complaint['timestamp']),\n            useragent=complaint.get('userAgent'),\n            feedback_type=complaint.get('complaintFeedbackType'),\n            arrival_date=arrival_date\n        )]\n\n    # Send signals for each complaint.\n    for complaint in complaints:\n        signals.feedback.send(\n            sender=Complaint,\n            instance=complaint,\n            message=message,\n            notification=notification\n        )\n\n    logger.info('Logged %s Complaint(s)', str(len(complaints)))\n\n    return HttpResponse('Complaint Processed')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to process a delivery notification", "response": "def process_delivery(message, notification):\n    \"\"\"Function to process a delivery notification\"\"\"\n    mail = message['mail']\n    delivery = message['delivery']\n\n    if 'timestamp' in delivery:\n        delivered_datetime = clean_time(delivery['timestamp'])\n    else:\n        delivered_datetime = None\n\n    deliveries = []\n    for eachrecipient in delivery['recipients']:\n        # Create each delivery \n        deliveries += [Delivery.objects.create(\n            sns_topic=notification['TopicArn'],\n            sns_messageid=notification['MessageId'],\n            mail_timestamp=clean_time(mail['timestamp']),\n            mail_id=mail['messageId'],\n            mail_from=mail['source'],\n            address=eachrecipient,\n            # delivery\n            delivered_time=delivered_datetime,\n            processing_time=int(delivery['processingTimeMillis']),\n            smtp_response=delivery['smtpResponse']\n        )]\n\n    # Send signals for each delivery.\n    for eachdelivery in deliveries:\n        signals.feedback.send(\n            sender=Delivery,\n            instance=eachdelivery,\n            message=message,\n            notification=notification\n        )\n\n    logger.info('Logged %s Deliveries(s)', str(len(deliveries)))\n\n    return HttpResponse('Delivery Processed')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef click_on_label(step, label):\n\n    with AssertContextManager(step):\n        elem = world.browser.find_element_by_xpath(str(\n            '//label[normalize-space(text()) = \"%s\"]' % label))\n        elem.click()", "response": "Click on a label"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the element is focused", "response": "def element_focused(step, id):\n    \"\"\"\n    Check if the element is focused\n    \"\"\"\n\n    elem = world.browser.find_element_by_xpath(str('id(\"{id}\")'.format(id=id)))\n    focused = world.browser.switch_to_active_element()\n\n    assert_true(step, elem == focused)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the element is not focused", "response": "def element_not_focused(step, id):\n    \"\"\"\n    Check if the element is not focused\n    \"\"\"\n\n    elem = world.browser.find_element_by_xpath(str('id(\"{id}\")'.format(id=id)))\n    focused = world.browser.switch_to_active_element()\n\n    assert_false(step, elem == focused)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef input_has_value(step, field_name, value):\n    with AssertContextManager(step):\n        text_field = find_any_field(world.browser,\n                                    DATE_FIELDS + TEXT_FIELDS,\n                                    field_name)\n        assert_false(step, text_field is False,\n                     'Can not find a field named \"%s\"' % field_name)\n        assert_equals(text_field.get_attribute('value'), value)", "response": "Check that the form input element has given value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubmitting the form having given id.", "response": "def submit_form_id(step, id):\n    \"\"\"\n    Submit the form having given id.\n    \"\"\"\n    form = world.browser.find_element_by_xpath(str('id(\"{id}\")'.format(id=id)))\n    form.submit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubmit the form having given action URL.", "response": "def submit_form_action(step, url):\n    \"\"\"\n    Submit the form having given action URL.\n    \"\"\"\n    form = world.browser.find_element_by_xpath(str('//form[@action=\"%s\"]' %\n                                                   url))\n    form.submit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the alert text", "response": "def check_alert(step, text):\n    \"\"\"\n    Check the alert text\n    \"\"\"\n\n    try:\n        alert = Alert(world.browser)\n        assert_equals(alert.text, text)\n    except WebDriverException:\n        # PhantomJS is kinda poor\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if a button having a given tooltip.", "response": "def see_tooltip(step, tooltip):\n    \"\"\"\n    Press a button having a given tooltip.\n    \"\"\"\n    elem = world.browser.find_elements_by_xpath(str(\n        '//*[@title=\"%(tooltip)s\" or @data-original-title=\"%(tooltip)s\"]' %\n        dict(tooltip=tooltip)))\n    elem = [e for e in elem if e.is_displayed()]\n    assert_true(step, elem)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npress a button having a given tooltip.", "response": "def press_by_tooltip(step, tooltip):\n    \"\"\"\n    Press a button having a given tooltip.\n    \"\"\"\n    with AssertContextManager(step):\n        for button in world.browser.find_elements_by_xpath(str(\n            '//*[@title=\"%(tooltip)s\" or @data-original-title=\"%(tooltip)s\"]' %\n                dict(tooltip=tooltip))):\n            try:\n                button.click()\n                break\n            except Exception:\n                pass\n        else:\n            raise AssertionError(\"No button with tooltip '{0}' found\"\n                                 .format(tooltip))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef page_title(step, title):\n\n    with AssertContextManager(step):\n        assert_equals(world.browser.title, title)", "response": "Check that the page title matches the given one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, resource=None, sort=None):\n        schema = TagSchema()\n        resp = self.service.get(self.base, params={'resource': resource, 'sort': sort})\n        return self.service.decode(schema, resp, many=True)", "response": "Get a list of tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a tag. :param name: Tag name as string. :return: :class:`tags.Tag <tags.Tag>` object :rtype: tags.Tag", "response": "def get(self, name):\n        \"\"\"Get a tag.\n\n        :param name: Tag name as string.\n        :return: :class:`tags.Tag <tags.Tag>` object\n        :rtype: tags.Tag\n        \"\"\"\n        schema = TagSchema()\n        resp = self.service.get_id(self.base, name)\n        return self.service.decode(schema, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef edit(self, resource):\n        schema = TagSchema(only=('name', 'configs', 'devices', 'packages', 'results'))\n        json = self.service.encode(schema, resource)\n\n        schema = TagSchema()\n        resp = self.service.edit(self.base, resource.name, json)\n        return self.service.decode(schema, resp)", "response": "Edit a tag.\n\n        :param resource: :class:`tags.Tag <tags.Tag>` object\n        :return: :class:`tags.Tag <tags.Tag>` object\n        :rtype: tags.Tag"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remaining(self):\n        if self._expired:\n            raise Expired()\n\n        obj = {\n            u'ID': self.lease_id,\n        }\n        data = json.dumps(obj).encode('utf8')\n\n        url = u'{}/v3alpha/kv/lease/timetolive'.format(self._client._url).encode()\n        response = yield treq.post(url, data, headers=self._client._REQ_HEADERS)\n\n        obj = yield treq.json_content(response)\n\n        ttl = obj.get(u'TTL', None)\n        if not ttl:\n            self._expired = True\n            raise Expired()\n\n        # grantedTTL = int(obj[u'grantedTTL'])\n        # header = Header._parse(obj[u'header']) if u'header' in obj else None\n\n        returnValue(ttl)", "response": "Get the remaining time - to - live of this lease."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrevokes a lease. All keys attached to the lease will expire and be deleted. :returns: Response header. :rtype: instance of :class:`txaioetcd.Header`", "response": "def revoke(self):\n        \"\"\"\n        Revokes a lease. All keys attached to the lease will expire\n        and be deleted.\n\n        :returns: Response header.\n        :rtype: instance of :class:`txaioetcd.Header`\n        \"\"\"\n        if self._expired:\n            raise Expired()\n\n        obj = {\n            # ID is the lease ID to revoke. When the ID is revoked, all\n            # associated keys will be deleted.\n            u'ID': self.lease_id,\n        }\n        data = json.dumps(obj).encode('utf8')\n\n        url = u'{}/v3alpha/kv/lease/revoke'.format(self._client._url).encode()\n        response = yield treq.post(url, data, headers=self._client._REQ_HEADERS)\n\n        obj = yield treq.json_content(response)\n\n        header = Header._parse(obj[u'header']) if u'header' in obj else None\n\n        self._expired = True\n\n        returnValue(header)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh(self):\n        if self._expired:\n            raise Expired()\n\n        obj = {\n            # ID is the lease ID for the lease to keep alive.\n            u'ID': self.lease_id,\n        }\n        data = json.dumps(obj).encode('utf8')\n\n        url = u'{}/v3alpha/lease/keepalive'.format(self._client._url).encode()\n        response = yield treq.post(url, data, headers=self._client._REQ_HEADERS)\n\n        obj = yield treq.json_content(response)\n\n        if u'result' not in obj:\n            raise Exception('bogus lease refresh response (missing \"result\") in {}'.format(obj))\n\n        ttl = obj[u'result'].get(u'TTL', None)\n        if not ttl:\n            self._expired = True\n            raise Expired()\n\n        header = Header._parse(obj[u'result'][u'header']) if u'header' in obj[u'result'] else None\n\n        self._expired = False\n\n        returnValue(header)", "response": "Keeps the lease alive by streaming keep alive requests to the server and streaming keep alive responses to the client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_links_file(self,file_path):\n        '''\n        Read links and associated categories for specified articles \n        in text file seperated by a space\n\n        Args:\n            file_path (str): The path to text file with news article links\n                             and category\n\n        Returns:\n            articles: Array of tuples that contains article link & cateogory\n                      ex. [('IPO','www.cs.columbia.edu')]\n        '''\n\n        articles = []\n        with open(file_path) as f:\n            for line in f:\n                line = line.strip()\n                #Ignore blank lines\n                if len(line) != 0:\n                    link,category = line.split(' ')\n                    articles.append((category.rstrip(),link.strip()))\n\n        return articles", "response": "Reads links and associated categories for specified articles \n        in text file seperated by a space and returns an array of tuples that contains article link and category."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch Google News API for articles.", "response": "def google_news_search(self,query,category_label,num=50):\n        '''\n        Searches Google News.\n        NOTE: Official Google News API is deprecated https://developers.google.com/news-search/?hl=en\n        NOTE: Google limits the maximum number of documents per query to 100.\n              Use multiple related queries to get a bigger corpus. \n\n        Args:\n            query (str): The search term.\n            category_label (str): The category to assign to the articles. These\n                                  categories are the labels in the generated corpus\n\n            num (Optional[int]): The numnber of results to return.\n\n        Returns:\n            articles: Array of tuples that contains article link & cateogory\n                      ex. [('IPO','www.cs.columbia.edu')]\n        '''\n\n        url = 'https://news.google.com/news?hl=en&q='+self._encode_query(query) \\\n                +'&num='+str(num)+'&output=rss'\n\n        rss = feedparser.parse(url)\n        entries = rss['entries']\n        articles = []\n\n        for entry in entries:\n            link = entry['link']\n            articles.append((category_label,link))\n        return articles"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call(self, action, params=None):\n        params = params or {}\n        params['action'] = action\n\n        resp = self.session.post(self.host, json=params, timeout=self.timeout)\n\n        result = resp.json()\n\n        if 'error' in result:\n            raise RPCException(result['error'])\n\n        return result", "response": "Makes an RPC call to the server and returns the json response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_value(self, value, type):\n\n        if not isinstance(value, six.string_types + (list,)):\n            value = json.dumps(value)\n        return value", "response": "Process a value that will be sent to backend\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning how many RAW is owned and how many have not yet received by account", "response": "def account_balance(self, account):\n        \"\"\"\n        Returns how many RAW is owned and how many have not yet been received\n        by **account**\n\n        :param account: Account id to return balance of\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.account_balance(\n        ...     account=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n        ... )\n        {\n          \"balance\": 10000,\n          \"pending\": 10000\n        }\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('account_balance', payload)\n\n        for k, v in resp.items():\n            resp[k] = int(v)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accounts_balances(self, accounts):\n\n        accounts = self._process_value(accounts, 'list')\n\n        payload = {\"accounts\": accounts}\n\n        resp = self.call('accounts_balances', payload)\n        accounts_balances = resp.get('balances') or {}\n\n        for account, balances in accounts_balances.items():\n            for k in balances:\n                balances[k] = int(balances[k])\n\n        return accounts_balances", "response": "Returns how many RAW is owned and how many have not yet been received by accounts list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget number of blocks for a specific account", "response": "def account_block_count(self, account):\n        \"\"\"\n        Get number of blocks for a specific **account**\n\n        :param account: Account to get number of blocks for\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.account_block_count(account=\"xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\")\n        19\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('account_block_count', payload)\n\n        return int(resp['block_count'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate new accounts in wallet.", "response": "def accounts_create(self, wallet, count, work=True):\n        \"\"\"\n        Creates new accounts, insert next deterministic keys in **wallet** up\n        to **count**\n\n        .. enable_control required\n        .. version 8.0 required\n\n        :param wallet: Wallet to create new accounts in\n        :type wallet: str\n\n        :param count: Number of accounts to create\n        :type count: int\n\n        :param work: If false, disables work generation after creating account\n        :type work: bool\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.accounts_create(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     count=2\n        ... )\n        [\n            \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n            \"xrb_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3s00000000\"\n        ]\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        count = self._process_value(count, 'int')\n\n        payload = {\"wallet\": wallet, \"count\": count}\n\n        if not work:\n            payload['work'] = self._process_value(work, 'strbool')\n\n        resp = self.call('accounts_create', payload)\n\n        return resp.get('accounts') or []"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accounts_frontiers(self, accounts):\n\n        accounts = self._process_value(accounts, 'list')\n\n        payload = {\"accounts\": accounts}\n\n        resp = self.call('accounts_frontiers', payload)\n\n        return resp.get('frontiers') or {}", "response": "Returns a list of pairs of account and block hash representing the frontier blocks for the given list of accounts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef account_info(self, account, representative=False, weight=False, pending=False):\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        if representative:\n            payload['representative'] = self._process_value(representative, 'strbool')\n        if weight:\n            payload['weight'] = self._process_value(weight, 'strbool')\n        if pending:\n            payload['pending'] = self._process_value(pending, 'strbool')\n\n        resp = self.call('account_info', payload)\n\n        for key in (\n            'modified_timestamp',\n            'block_count',\n            'balance',\n            'pending',\n            'weight',\n        ):\n            if key in resp:\n                resp[key] = int(resp[key])\n\n        return resp", "response": "Return the info for a specific account."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef account_create(self, wallet, work=True):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        if not work:\n            payload['work'] = self._process_value(work, 'strbool')\n\n        resp = self.call('account_create', payload)\n\n        return resp['account']", "response": "Create a new account in the given wallet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef account_get(self, key):\n\n        key = self._process_value(key, 'publickey')\n\n        payload = {\"key\": key}\n\n        resp = self.call('account_get', payload)\n\n        return resp['account']", "response": "Get the account number for the public key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting send and receive information for a given account.", "response": "def account_history(self, account, count):\n        \"\"\"\n        Reports send/receive information for a **account**\n\n        :param account: Account to get send/receive information for\n        :type account: str\n\n        :param count: number of blocks to return\n        :type count: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.account_history(\n        ...     account=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n        ...     count=1\n        ... )\n        [\n            {\n              \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n              \"type\": \"receive\",\n              \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n              \"amount\": 100000000000000000000000000000000\n            }\n        ]\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n        count = self._process_value(count, 'int')\n\n        payload = {\"account\": account, \"count\": count}\n\n        resp = self.call('account_history', payload)\n        history = resp.get('history') or []\n\n        for entry in history:\n            entry['amount'] = int(entry['amount'])\n\n        return history"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef account_list(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('account_list', payload)\n\n        return resp.get('accounts') or []", "response": "Get all the accounts in a wallet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving accounts from source to wallet.", "response": "def account_move(self, source, wallet, accounts):\n        \"\"\"\n        Moves **accounts** from **source** to **wallet**\n\n        .. enable_control required\n\n        :param source: wallet to move accounts from\n        :type source: str\n\n        :param wallet: wallet to move accounts to\n        :type wallet: str\n\n        :param accounts: accounts to move\n        :type accounts: list of str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.account_move(\n        ...     source=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     accounts=[\n        ...         \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n        ...     ]\n        ... )\n        True\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        source = self._process_value(source, 'wallet')\n        accounts = self._process_value(accounts, 'list')\n\n        payload = {\"wallet\": wallet, \"source\": source, \"accounts\": accounts}\n\n        resp = self.call('account_move', payload)\n\n        return resp['moved'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of block hashes which have not yet been received by these accounts.", "response": "def accounts_pending(self, accounts, count=None, threshold=None, source=False):\n        \"\"\"\n        Returns a list of block hashes which have not yet been received by\n        these **accounts**\n\n        :param accounts: Accounts to return list of block hashes for\n        :type accounts: list of str\n\n        :param count: Max number of blocks to returns\n        :type count: int\n\n        :param threshold: Minimum amount in raw per block\n        :type threshold: int\n\n        :param source: if True returns the source as well\n        :type source: bool\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.accounts_pending(\n        ...     accounts=[\n        ...         \"xrb_1111111111111111111111111111111111111111111111111117353trpda\",\n        ...         \"xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n        ...     ],\n        ...     count=1\n        ... )\n        {\n            \"xrb_1111111111111111111111111111111111111111111111111117353trpda\": [\n                \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\"\n            ],\n            \"xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": [\n                \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\"\n            ]\n        }\n\n        \"\"\"\n\n        payload = {\"accounts\": accounts}\n\n        accounts = self._process_value(accounts, 'list')\n        if count is not None:\n            payload['count'] = self._process_value(count, 'int')\n\n        if threshold is not None:\n            payload['threshold'] = self._process_value(threshold, 'int')\n\n        if source:\n            payload['source'] = self._process_value(source, 'strbool')\n\n        resp = self.call('accounts_pending', payload)\n\n        blocks = resp.get('blocks') or {}\n        for account, data in blocks.items():\n            if isinstance(data, list):  # list of block hashes, no change needed\n                continue\n            if not data:\n                blocks[account] = []  # convert a \"\" response to []\n                continue\n            for key, value in data.items():\n                if isinstance(value, six.string_types):  # amount\n                    data[key] = int(value)\n                elif isinstance(value, dict):  # dict with \"amount\" and \"source\"\n                    for key in ('amount',):\n                        if key in value:\n                            value[key] = int(value[key])\n\n        return blocks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the public key for the account", "response": "def account_key(self, account):\n        \"\"\"\n        Get the public key for **account**\n\n        :param account: Account to get public key for\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.account_key(\n        ...     account=\"xrb_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n        ... )\n        \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\"\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('account_key', payload)\n\n        return resp['key']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef account_remove(self, wallet, account):\n\n        wallet = self._process_value(wallet, 'wallet')\n        account = self._process_value(account, 'account')\n\n        payload = {\"wallet\": wallet, \"account\": account}\n\n        resp = self.call('account_remove', payload)\n\n        return resp['removed'] == '1'", "response": "Remove account from wallet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef account_representative(self, account):\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('account_representative', payload)\n\n        return resp['representative']", "response": "Returns the representative for the given account"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef account_representative_set(self, wallet, account, representative, work=None):\n\n        wallet = self._process_value(wallet, 'wallet')\n        account = self._process_value(account, 'account')\n        representative = self._process_value(representative, 'account')\n\n        payload = {\n            \"wallet\": wallet,\n            \"account\": account,\n            \"representative\": representative,\n        }\n\n        if work is not None:\n            payload['work'] = self._process_value(work, 'work')\n\n        resp = self.call('account_representative_set', payload)\n\n        return resp['block']", "response": "Set the representative for the account in wallet for the given account."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the voting weight for the account", "response": "def account_weight(self, account):\n        \"\"\"\n        Returns the voting weight for **account**\n\n        :param account: Account to get voting weight for\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.account_weight(\n        ...     account=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n        ... )\n        10000\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('account_weight', payload)\n\n        return int(resp['weight'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves a json representation of a block.", "response": "def block(self, hash):\n        \"\"\"\n        Retrieves a json representation of **block**\n\n        :param hash: Hash of block to return representation for\n        :type hash: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.block(\n        ...     hash=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        {\n            \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n            \"work\": \"0000000000000000\",\n            \"source\": \"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n            \"representative\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n            \"signature\": \"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n            \"type\": \"open\"\n        }\n\n        \"\"\"\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        resp = self.call('block', payload)\n\n        return json.loads(resp['contents'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a json representation of the blocks for the given list of block hashes.", "response": "def blocks(self, hashes):\n        \"\"\"\n        Retrieves a json representations of **blocks**\n\n        :param hashes: List of block hashes to return\n        :type hashes: list of str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.blocks(\n        ...     hashes=[\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"]\n        ... )\n        {\n            \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\": {\n                \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n                \"work\": \"0000000000000000\",\n                \"source\": \"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n                \"representative\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n                \"signature\": \"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n                \"type\": \"open\"\n            }\n        }\n\n        \"\"\"\n\n        hashes = self._process_value(hashes, 'list')\n\n        payload = {\"hashes\": hashes}\n\n        resp = self.call('blocks', payload)\n        blocks = resp.get('blocks') or {}\n\n        for k, v in blocks.items():\n            blocks[k] = json.loads(v)\n\n        return blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef blocks_info(self, hashes, pending=False, source=False):\n\n        hashes = self._process_value(hashes, 'list')\n\n        payload = {\"hashes\": hashes}\n\n        if pending:\n            payload['pending'] = self._process_value(pending, 'strbool')\n        if source:\n            payload['source'] = self._process_value(source, 'strbool')\n\n        resp = self.call('blocks_info', payload)\n\n        blocks = resp.get('blocks') or {}\n\n        for block, data in blocks.items():\n            data['contents'] = json.loads(data['contents'])\n            for key in ('amount', 'pending'):\n                if key in data:\n                    data[key] = int(data[key])\n\n        return blocks", "response": "Returns a json representation of the blocks with transaction\n        amount & block account and block account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef block_account(self, hash):\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        resp = self.call('block_account', payload)\n\n        return resp['account']", "response": "Returns the account containing the block with the given hash"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef block_count(self):\n\n        resp = self.call('block_count')\n\n        for k, v in resp.items():\n            resp[k] = int(v)\n\n        return resp", "response": "Returns the number of blocks in the ledger and unchecked synchronizing\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef block_count_type(self):\n\n        resp = self.call('block_count_type')\n\n        for k, v in resp.items():\n            resp[k] = int(v)\n\n        return resp", "response": "Returns the number of blocks in the ledger by type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef block_create(\n        self,\n        type,\n        account,\n        wallet=None,\n        representative=None,\n        key=None,\n        destination=None,\n        amount=None,\n        balance=None,\n        previous=None,\n        source=None,\n        work=None,\n    ):\n        \"\"\"\n        Creates a json representations of new block based on input data &\n        signed with private key or account in **wallet** for offline signing\n\n        .. enable_control required\n        .. version 8.1 required\n\n        :param type: Type of block to create one of **open**, **receive**,\n                     **change**, **send**\n        :type type: str\n\n        :param account: Account for the signed block\n        :type account: str\n\n        :param wallet: Wallet to use\n        :type wallet: str\n\n        :param representative: Representative account for **open** and\n                               **change** blocks\n        :type representative: str\n\n        :param key: Private key to use to open account for **open** blocks\n        :type key: str\n\n        :param destination: Destination account for **send** blocks\n        :type destination: str\n\n        :param amount: Amount in raw for **send** blocks\n        :type amount: int\n\n        :param balance: Balance in raw of account for **send** blocks\n        :type balance: int\n\n        :param previous: Previous block hash for **receive**, **send**\n                       and **change** blocks\n        :type previous: str\n\n        :param source: Source block for **open** and **receive** blocks\n        :type source: str\n\n        :param work: Work value to use for block from external source\n        :type work: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.block_create(\n        ...     type=\"open\",\n        ...     account=\"xrb_3kdbxitaj7f6mrir6miiwtw4muhcc58e6tn5st6rfaxsdnb7gr4roudwn951\",\n        ...     source=\"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n        ...     representative=\"xrb_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n        ...     key=\"0000000000000000000000000000000000000000000000000000000000000001\"\n        ... )\n        {\n            \"block\": {\n                \"account\": \"xrb_3kdbxitaj7f6mrir6miiwtw4muhcc58e6tn5st6rfaxsdnb7gr4roudwn951\",\n                \"representative\": \"xrb_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n                \"signature\": \"5974324F8CC42DA56F62FC212A17886BDCB18DE363D04DA84EEDC99CB4A33919D14A2CF9DE9D534FAA6D0B91D01F0622205D898293525E692586C84F2DCF9208\",\n                \"source\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n                \"type\": \"open\",\n                \"work\": \"4ec76c9bda2325ed\"\n            },\n            \"hash\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\"\n        }\n\n        >>> rpc.block_create(\n        ...     type=\"receive\",\n        ...     account=\"xrb_3kdbxitaj7f6mrir6miiwtw4muhcc58e6tn5st6rfaxsdnb7gr4roudwn951\",\n        ...     previous=\"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\",\n        ...     source=\"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ... )\n        {\n            \"block\": {\n                \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\",\n                \"signature\": \"A13FD22527771667D5DFF33D69787D734836A3561D8A490C1F4917A05D77EA09860461D5FBFC99246A4EAB5627F119AD477598E22EE021C4711FACF4F3C80D0E\",\n                \"source\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n                \"type\": \"receive\",\n                \"work\": \"6acb5dd43a38d76a\"\n            },\n            \"hash\": \"314BA8D9057678C1F53371C2DB3026C1FAC01EC8E7802FD9A2E8130FC523429E\"\n        }\n\n        >>> rpc.block_create(\n        ...     type=\"send\",\n        ...     account=\"xrb_3kdbxitaj7f6mrir6miiwtw4muhcc58e6tn5st6rfaxsdnb7gr4roudwn951\",\n        ...     amount=10000000000000000000000000000000,\n        ...     balance=20000000000000000000000000000000,\n        ...     destination=\"xrb_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n        ...     previous=\"314BA8D9057678C1F53371C2DB3026C1FAC01EC8E7802FD9A2E8130FC523429E\",\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     work=\"478563b2d9facfd4\",\n        ... )\n        {\n            \"block\": {\n                \"balance\": \"0000007E37BE2022C0914B2680000000\",\n                \"destination\": \"xrb_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n                \"previous\": \"314BA8D9057678C1F53371C2DB3026C1FAC01EC8E7802FD9A2E8130FC523429E\",\n                \"signature\": \"F19CA177EFA8692C8CBF7478CE3213F56E4A85DF760DA7A9E69141849831F8FD79BA9ED89CEC807B690FB4AA42D5008F9DBA7115E63C935401F1F0EFA547BC00\",\n                \"type\": \"send\",\n                \"work\": \"478563b2d9facfd4\"\n            },\n            \"hash\": \"F958305C0FF0551421D4ABEDCCF302079D020A0A3833E33F185E2B0415D4567A\"\n        }\n\n        >>> rpc.block_create(\n        ...     type=\"change\",\n        ...     account=\"xrb_3kdbxitaj7f6mrir6miiwtw4muhcc58e6tn5st6rfaxsdnb7gr4roudwn951\",\n        ...     representative=\"xrb_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n        ...     previous=\"F958305C0FF0551421D4ABEDCCF302079D020A0A3833E33F185E2B0415D4567A\",\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ... )\n        {\n            \"block\": {\n                \"previous\": \"F958305C0FF0551421D4ABEDCCF302079D020A0A3833E33F185E2B0415D4567A\",\n                \"representative\": \"xrb_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n                \"signature\": \"98B4D56881D9A88B170A6B2976AE21900C26A27F0E2C338D93FDED56183B73D19AA5BEB48E43FCBB8FF8293FDD368CEF50600FECEFD490A0855ED702ED209E04\",\n                \"type\": \"change\",\n                \"work\": \"55e5b7a83edc3f4f\"\n            },\n            \"hash\": \"654FA425CEBFC9E7726089E4EDE7A105462D93DBC915FFB70B50909920A7D286\"\n        }\n        \"\"\"\n\n        payload = {\n            \"type\": self._process_value(type, 'blocktype'),\n            \"account\": self._process_value(account, 'account'),\n        }\n\n        if representative is not None:\n            payload['representative'] = self._process_value(representative, 'account')\n\n        if key is not None:\n            payload['key'] = self._process_value(key, 'privatekey')\n\n        if source is not None:\n            payload['source'] = self._process_value(source, 'block')\n\n        if destination is not None:\n            payload['destination'] = self._process_value(destination, 'account')\n\n        if amount is not None:\n            payload['amount'] = self._process_value(amount, 'int')\n\n        if balance is not None:\n            payload['balance'] = self._process_value(balance, 'int')\n\n        if previous is not None:\n            payload['previous'] = self._process_value(previous, 'block')\n\n        if wallet is not None:\n            payload['wallet'] = self._process_value(wallet, 'wallet')\n\n        if work is not None:\n            payload['work'] = self._process_value(work, 'work')\n\n        resp = self.call('block_create', payload)\n        resp['block'] = json.loads(resp['block'])\n\n        return resp", "response": "Create a new block for the given key pair pair."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the Nagios node s bootstrap to specific IP address and port.", "response": "def bootstrap(self, address, port):\n        \"\"\"\n        Initialize bootstrap to specific **IP address** and **port**\n\n        :param address: Ip address to bootstrap\n        :type address: str\n\n        :param port: Port to bootstrap\n        :type port: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.bootstrap(address=\"::ffff:138.201.94.249\", port=\"7075\")\n        True\n        \"\"\"\n\n        address = self._process_value(address, 'ipaddr')\n        port = self._process_value(port, 'int')\n\n        payload = {\"address\": address, \"port\": port}\n\n        resp = self.call('bootstrap', payload)\n\n        return 'success' in resp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chain(self, block, count):\n\n        block = self._process_value(block, 'block')\n        count = self._process_value(count, 'int')\n\n        payload = {\"block\": block, \"count\": count}\n\n        resp = self.call('chain', payload)\n\n        return resp.get('blocks') or []", "response": "Returns a list of block hashes in the account chain starting at the given block hash."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of pairs of delegator names given account aracation and balance.", "response": "def delegators(self, account):\n        \"\"\"\n        Returns a list of pairs of delegator names given **account** a\n        representative and its balance\n\n        .. version 8.0 required\n\n        :param account: Account to return delegators for\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.delegators(\n        ...     account=\"xrb_1111111111111111111111111111111111111111111111111117353trpda\"\n        ... )\n        {\n            \"xrb_13bqhi1cdqq8yb9szneoc38qk899d58i5rcrgdk5mkdm86hekpoez3zxw5sd\":\n                \"500000000000000000000000000000000000\",\n            \"xrb_17k6ug685154an8gri9whhe5kb5z1mf5w6y39gokc1657sh95fegm8ht1zpn\":\n                \"961647970820730000000000000000000000\"\n        }\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('delegators', payload)\n        delegators = resp.get('delegators') or {}\n\n        for k, v in delegators.items():\n            delegators[k] = int(v)\n\n        return delegators"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets number of delegators for a specific representative account.", "response": "def delegators_count(self, account):\n        \"\"\"\n        Get number of delegators for a specific representative **account**\n\n        .. version 8.0 required\n\n        :param account: Account to get number of delegators for\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.delegators_count(\n        ...     account=\"xrb_1111111111111111111111111111111111111111111111111117353trpda\"\n        ... )\n        2\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('delegators_count', payload)\n\n        return int(resp['count'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deterministic_key(self, seed, index):\n\n        seed = self._process_value(seed, 'seed')\n        index = self._process_value(index, 'int')\n\n        payload = {\"seed\": seed, \"index\": index}\n\n        resp = self.call('deterministic_key', payload)\n\n        return resp", "response": "Derive a deterministic keypair from seed based on index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef frontiers(self, account, count):\n\n        account = self._process_value(account, 'account')\n        count = self._process_value(count, 'int')\n\n        payload = {\"account\": account, \"count\": count}\n\n        resp = self.call('frontiers', payload)\n\n        return resp.get('frontiers') or {}", "response": "Returns a list of pairs of account and block hash representing the frontier blocks starting at account up to count."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of send or receive information for a specific block.", "response": "def history(self, hash, count):\n        \"\"\"\n        Reports send/receive information for a chain of blocks\n\n        :param hash: Hash of block to receive history for\n        :type hash: str\n\n        :param count: Max number of blocks to return\n        :type count: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.history(\n        ...     hash=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     count=1\n        ... )\n        [\n            {\n              \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n              \"type\": \"receive\",\n              \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n              \"amount\": \"100000000000000000000000000000000\"\n            }\n        ]\n\n        \"\"\"\n\n        hash = self._process_value(hash, 'block')\n        count = self._process_value(count, 'int')\n\n        payload = {\"hash\": hash, \"count\": count}\n\n        resp = self.call('history', payload)\n\n        history = resp.get('history') or []\n\n        for entry in history:\n            entry['amount'] = int(entry['amount'])\n\n        return history"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mrai_from_raw(self, amount):\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('mrai_from_raw', payload)\n\n        return int(resp['amount'])", "response": "Divide a raw amount down by the Mrai ratio."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mrai_to_raw(self, amount):\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('mrai_to_raw', payload)\n\n        return int(resp['amount'])", "response": "Multiply an amount in Mrai by the Mrai ratio."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef krai_from_raw(self, amount):\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('krai_from_raw', payload)\n\n        return int(resp['amount'])", "response": "Divide a raw amount down by the krai ratio."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmultiply an amount in krai by the krai ratio.", "response": "def krai_to_raw(self, amount):\n        \"\"\"\n        Multiply an krai amount by the krai ratio.\n\n        :param amount: Amount in krai to convert to raw\n        :type amount: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.krai_to_raw(amount=1)\n        1000000000000000000000000000\n\n        \"\"\"\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('krai_to_raw', payload)\n\n        return int(resp['amount'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rai_from_raw(self, amount):\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('rai_from_raw', payload)\n\n        return int(resp['amount'])", "response": "Divide a raw amount down by the rai ratio."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rai_to_raw(self, amount):\n\n        amount = self._process_value(amount, 'int')\n\n        payload = {\"amount\": amount}\n\n        resp = self.call('rai_to_raw', payload)\n\n        return int(resp['amount'])", "response": "Multiply an rai amount by the rai ratio."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nderive public key and account number from private key and public key of a specific class.", "response": "def key_expand(self, key):\n        \"\"\"\n        Derive public key and account number from **private key**\n\n        :param key: Private key to generate account and public key of\n        :type key: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.key_expand(\n            key=\"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\"\n        )\n        {\n          \"private\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\",\n          \"public\": \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\",\n          \"account\": \"xrb_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n        }\n\n        \"\"\"\n\n        key = self._process_value(key, 'privatekey')\n\n        payload = {\"key\": key}\n\n        resp = self.call('key_expand', payload)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a keepalive packet to the node.", "response": "def keepalive(self, address, port):\n        \"\"\"\n        Tells the node to send a keepalive packet to **address**:**port**\n\n        .. enable_control required\n\n        :param address: IP address of node to send keepalive packet to\n        :type address: str\n\n        :param port: Port of node to send keepalive packet to\n        :type port: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.keepalive(address=\"::ffff:192.168.1.1\", port=1024)\n        True\n        \"\"\"\n\n        address = self._process_value(address, 'ipaddr')\n        port = self._process_value(port, 'int')\n\n        payload = {\"address\": address, \"port\": port}\n\n        resp = self.call('keepalive', payload)\n\n        return resp == {}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ledger(\n        self,\n        account,\n        count=None,\n        representative=False,\n        weight=False,\n        pending=False,\n        sorting=False,\n    ):\n        \"\"\"\n        Returns frontier, open block, change representative block, balance,\n        last modified timestamp from local database & block count starting at\n        **account** up to **count**\n\n        .. enable_control required\n        .. version 8.0 required\n\n        :param account: Account to return blocks for\n        :type account: str\n\n        :param count: Max number of blocks to return\n        :type count: int\n\n        :param representative: If true, returns the representative as well\n        :type representative: bool\n\n        :param weight: If true, returns the voting weight as well\n        :type weight: bool\n\n        :param pending: If true, returns the pending amount as well\n        :type pending: bool\n\n        :param sorting: If true, sorts the response by balance\n        :type sorting: bool\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.ledger(\n        ...     account=\"xrb_1111111111111111111111111111111111111111111111111111hifc8npp\",\n        ...     count=1\n        ... )\n        {\n            \"xrb_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\": {\n                \"frontier\": \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\",\n                \"open_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n                \"representative_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n                \"balance\": 0,\n                \"modified_timestamp\": 1511476234,\n                \"block_count\": 2\n            }\n        }\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        if count is not None:\n            payload['count'] = self._process_value(count, 'int')\n\n        if sorting:\n            payload['sorting'] = self._process_value(sorting, 'strbool')\n\n        if representative:\n            payload['representative'] = self._process_value(representative, 'strbool')\n\n        if weight:\n            payload['weight'] = self._process_value(weight, 'strbool')\n\n        if pending:\n            payload['pending'] = self._process_value(pending, 'strbool')\n\n        resp = self.call('ledger', payload)\n        accounts = resp.get('accounts') or {}\n\n        int_keys = ('balance', 'modified_timestamp', 'block_count', 'weight', 'pending')\n        for account, frontier in accounts.items():\n            for key in int_keys:\n                if key in frontier:\n                    frontier[key] = int(frontier[key])\n\n        return accounts", "response": "Returns the ledger for the given entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef payment_begin(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('payment_begin', payload)\n\n        return resp['account']", "response": "Begin a new payment session."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitiate a payment in the wallet.", "response": "def payment_init(self, wallet):\n        \"\"\"\n        Marks all accounts in wallet as available for being used as a payment\n        session.\n\n        :param wallet: Wallet to init payment in\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.payment_init(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        True\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('payment_init', payload)\n\n        return resp['status'] == 'Ready'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef payment_end(self, account, wallet):\n\n        account = self._process_value(account, 'account')\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"account\": account, \"wallet\": wallet}\n\n        resp = self.call('payment_end', payload)\n\n        return resp == {}", "response": "End a payment session."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for payment of amount to arrive in account or until timeout has elapsed.", "response": "def payment_wait(self, account, amount, timeout):\n        \"\"\"\n        Wait for payment of **amount** to arrive in **account** or until **timeout**\n        milliseconds have elapsed.\n\n        :param account: Account to wait for payment\n        :type account: str\n\n        :param amount: Amount in raw of funds to wait for payment to arrive\n        :type amount: int\n\n        :param timeout: Timeout in milliseconds to wait for\n        :type timeout: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.payment_wait(\n        ...     account=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n        ...     amount=1,\n        ...     timeout=1000\n        ... )\n        True\n\n        \"\"\"\n\n        account = self._process_value(account, 'account')\n        amount = self._process_value(amount, 'int')\n        timeout = self._process_value(timeout, 'int')\n\n        payload = {\"account\": account, \"amount\": amount, \"timeout\": timeout}\n\n        resp = self.call('payment_wait', payload)\n\n        return resp['status'] == 'success'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing a block to the network and returns the hash of the block.", "response": "def process(self, block):\n        \"\"\"\n        Publish **block** to the network\n\n        :param block: Block to publish\n        :type block: dict or json\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> block = {\n            \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n            \"work\": \"0000000000000000\",\n            \"source\": \"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n            \"representative\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n            \"signature\": \"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n            \"type\": \"open\"\n        }\n\n        >>> rpc.process(block=block)\n        \"42A723D2B60462BF7C9A003FE9A70057D3A6355CA5F1D0A57581000000000000\"\n\n        >>> rpc.process(json.dumps(block))\n        \"42A723D2B60462BF7C9A003FE9A70057D3A6355CA5F1D0A57581000000000000\"\n\n        \"\"\"\n\n        if isinstance(block, dict):\n            block = json.dumps(block, sort_keys=True)\n\n        payload = {\"block\": block}\n\n        resp = self.call('process', payload)\n\n        return resp['hash']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receive(self, wallet, account, block, work=None):\n\n        wallet = self._process_value(wallet, 'wallet')\n        account = self._process_value(account, 'account')\n        block = self._process_value(block, 'block')\n\n        payload = {\"wallet\": wallet, \"account\": account, \"block\": block}\n\n        if work:\n            payload['work'] = self._process_value(work, 'work')\n\n        resp = self.call('receive', payload)\n\n        return resp['block']", "response": "Receive a pending block for the given account."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef representatives(self, count=None, sorting=False):\n        payload = {}\n\n        if count is not None:\n            payload['count'] = self._process_value(count, 'int')\n\n        if sorting:\n            payload['sorting'] = self._process_value(sorting, 'strbool')\n\n        resp = self.call('representatives', payload)\n\n        representatives = resp.get('representatives') or {}\n\n        for k, v in representatives.items():\n            representatives[k] = int(v)\n\n        return representatives", "response": "Returns a list of pairs of representative and its voting weight."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of pairs of unchecked synchronizing block hash and its json representation up to count blocks.", "response": "def unchecked(self, count=None):\n        \"\"\"\n        Returns a list of pairs of unchecked synchronizing block hash and its\n        json representation up to **count**\n\n        .. version 8.0 required\n\n        :param count: Max amount of unchecked blocks to return\n        :type count: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.unchecked(count=1)\n        {\n            \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\": {\n                \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n                \"work\": \"0000000000000000\",\n                \"source\": \"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n                \"representative\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n                \"signature\": \"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n                \"type\": \"open\"\n            }\n        }\n\n        \"\"\"\n\n        payload = {}\n\n        if count is not None:\n            payload[\"count\"] = self._process_value(count, 'int')\n\n        resp = self.call('unchecked', payload)\n\n        blocks = resp.get('blocks') or {}\n        for block, block_json in blocks.items():\n            blocks[block] = json.loads(block_json)\n\n        return blocks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of unchecked database keys and blocks hashes and a json representation of unchecked pending blocks starting from key up to count.", "response": "def unchecked_keys(self, key=None, count=None):\n        \"\"\"\n        Retrieves unchecked database keys, blocks hashes & a json\n        representations of unchecked pending blocks starting from **key** up\n        to **count**\n\n        .. version 8.0 required\n\n        :param key: Starting key to return unchecked keys for\n        :type key: str\n\n        :param count: Max number of keys/blocks to return\n        :type count: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.unchecked_keys(\n        ...     key=\"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n        ...     count=1\n        ... )\n        [\n            {\n                \"key\": \"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n                \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n                \"contents\": {\n                    \"account\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n                    \"work\": \"0000000000000000\",\n                    \"source\": \"FA5B51D063BADDF345EFD7EF0D3C5FB115C85B1EF4CDE89D8B7DF3EAF60A04A4\",\n                    \"representative\": \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n                    \"signature\": \"00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n                    \"type\": \"open\"\n                }\n            }\n        ]\n\n        \"\"\"\n\n        payload = {}\n\n        if key:\n            payload['key'] = self._process_value(key, 'publickey')\n\n        if count is not None:\n            payload['count'] = self._process_value(count, 'int')\n\n        resp = self.call('unchecked_keys', payload)\n        unchecked = resp.get('unchecked') or []\n\n        for entry in unchecked:\n            entry['contents'] = json.loads(entry['contents'])\n\n        return unchecked"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_account_number(self, account):\n\n        account = self._process_value(account, 'account')\n\n        payload = {\"account\": account}\n\n        resp = self.call('validate_account_number', payload)\n\n        return resp['valid'] == '1'", "response": "Check whether the account number is a valid account number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the default representative for the given wallet.", "response": "def wallet_representative(self, wallet):\n        \"\"\"\n        Returns the default representative for **wallet**\n\n        :param wallet: Wallet to get default representative account for\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_representative(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_representative', payload)\n\n        return resp['representative']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the default representative account for a specific wallet.", "response": "def wallet_representative_set(self, wallet, representative):\n        \"\"\"\n        Sets the default **representative** for **wallet**\n\n        .. enable_control required\n\n        :param wallet: Wallet to set default representative account for\n        :type wallet: str\n\n        :param representative: Representative account to set for **wallet**\n        :type representative: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_representative_set(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     representative=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n        ... )\n        True\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        representative = self._process_value(representative, 'account')\n\n        payload = {\"wallet\": wallet, \"representative\": representative}\n\n        resp = self.call('wallet_representative_set', payload)\n\n        return resp['set'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wallet_add(self, wallet, key, work=True):\n\n        wallet = self._process_value(wallet, 'wallet')\n        key = self._process_value(key, 'privatekey')\n\n        payload = {\"wallet\": wallet, \"key\": key}\n\n        if not work:\n            payload['work'] = self._process_value(work, 'strbool')\n\n        resp = self.call('wallet_add', payload)\n\n        return resp['account']", "response": "Add an adhoc private key to a wallet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the sum of all accounts balances in wallet", "response": "def wallet_balance_total(self, wallet):\n        \"\"\"\n        Returns the sum of all accounts balances in **wallet**\n\n        :param wallet: Wallet to return sum of balances for\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_balance_total(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        {\n          \"balance\": 10000,\n          \"pending\": 10000\n        }\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_balance_total', payload)\n\n        for k, v in resp.items():\n            resp[k] = int(v)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wallet_balances(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_balances', payload)\n        balances = resp.get('balances') or {}\n        for account, balance in balances.items():\n            for k, v in balances[account].items():\n                balances[account][k] = int(v)\n\n        return balances", "response": "Get the balances for the current wallet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wallet_change_seed(self, wallet, seed):\n\n        wallet = self._process_value(wallet, 'wallet')\n        seed = self._process_value(seed, 'seed')\n\n        payload = {\"wallet\": wallet, \"seed\": seed}\n\n        resp = self.call('wallet_change_seed', payload)\n\n        return 'success' in resp", "response": "Change the seed for the specified wallet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wallet_contains(self, wallet, account):\n\n        wallet = self._process_value(wallet, 'wallet')\n        account = self._process_value(account, 'account')\n\n        payload = {\"wallet\": wallet, \"account\": account}\n\n        resp = self.call('wallet_contains', payload)\n\n        return resp['exists'] == '1'", "response": "Check whether wallet contains account"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndestroying all contained accounts", "response": "def wallet_destroy(self, wallet):\n        \"\"\"\n        Destroys **wallet** and all contained accounts\n\n        .. enable_control required\n\n        :param wallet: Wallet to destroy\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_destroy(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        True\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_destroy', payload)\n\n        return resp == {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a json representation of the wallet", "response": "def wallet_export(self, wallet):\n        \"\"\"\n        Return a json representation of **wallet**\n\n        :param wallet: Wallet to export\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_export(wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\")\n        {\n            \"0000000000000000000000000000000000000000000000000000000000000000\": \"0000000000000000000000000000000000000000000000000000000000000001\"\n        }\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_export', payload)\n\n        return json.loads(resp['json'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of pairs of account and block hash representing the next head block starting for accounts from wallet.", "response": "def wallet_frontiers(self, wallet):\n        \"\"\"\n        Returns a list of pairs of account and block hash representing the\n        head block starting for accounts from **wallet**\n\n        :param wallet: Wallet to return frontiers for\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_frontiers(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        {\n            \"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        }\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_frontiers', payload)\n\n        return resp.get('frontiers') or {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wallet_key_valid(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_key_valid', payload)\n\n        return resp['valid'] == '1'", "response": "Check if a wallet key is valid for a given set of keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wallet_lock(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_lock', payload)\n\n        return resp['locked'] == '1'", "response": "Locks a **wallet**\n\n        :param wallet: Wallet to lock\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_lock(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wallet_locked(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_locked', payload)\n\n        return resp['locked'] == '1'", "response": "Checks whether the wallet is locked."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wallet_unlock(self, wallet, password):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet, \"password\": password}\n\n        resp = self.call('wallet_unlock', payload)\n\n        return resp['valid'] == '1'", "response": "Unlocks the specified wallet using the specified password."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrebroadcasting the given number of blocks for the given wallet.", "response": "def wallet_republish(self, wallet, count):\n        \"\"\"\n        Rebroadcast blocks for accounts from **wallet** starting at frontier\n        down to **count** to the network\n\n        .. enable_control required\n        .. version 8.0 required\n\n        :param wallet: Wallet to rebroadcast blocks for\n        :type wallet: str\n\n        :param count: Max amount of blocks to rebroadcast since frontier block\n        :type count: int\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_republish(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     count=2\n        ... )\n        [\n            \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n            \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\",\n            \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\"\n        ]\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        count = self._process_value(count, 'int')\n\n        payload = {\"wallet\": wallet, \"count\": count}\n\n        resp = self.call('wallet_republish', payload)\n\n        return resp.get('blocks') or []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of pairs of account and work from wallet.", "response": "def wallet_work_get(self, wallet):\n        \"\"\"\n        Returns a list of pairs of account and work from **wallet**\n\n        .. enable_control required\n        .. version 8.0 required\n\n        :param wallet: Wallet to return work for\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.wallet_work_get(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        {\n            \"xrb_1111111111111111111111111111111111111111111111111111hifc8npp\":\n                \"432e5cf728c90f4f\"\n        }\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('wallet_work_get', payload)\n\n        return resp.get('works') or {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchanges the password for the current user for the current locale.", "response": "def password_change(self, wallet, password):\n        \"\"\"\n        Changes the password for **wallet** to **password**\n\n        .. enable_control required\n\n        :param wallet: Wallet to change password for\n        :type wallet: str\n\n        :param password: Password to set\n        :type password: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.password_change(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     password=\"test\"\n        ... )\n        True\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet, \"password\": password}\n\n        resp = self.call('password_change', payload)\n\n        return resp['changed'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nenter a password for a specific wallet", "response": "def password_enter(self, wallet, password):\n        \"\"\"\n        Enters the **password** in to **wallet**\n\n        :param wallet: Wallet to enter password for\n        :type wallet: str\n\n        :param password: Password to enter\n        :type password: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.password_enter(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     password=\"test\"\n        ... )\n        True\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet, \"password\": password}\n\n        resp = self.call('password_enter', payload)\n\n        return resp['valid'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef password_valid(self, wallet):\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('password_valid', payload)\n\n        return resp['valid'] == '1'", "response": "Checks whether the password entered for the given wallet is valid for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of pairs of peer IPv6 : port and its node network version", "response": "def peers(self):\n        \"\"\"\n        Returns a list of pairs of peer IPv6:port and its node network version\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.peers()\n        {\n            \"[::ffff:172.17.0.1]:32841\": 3\n        }\n        \"\"\"\n\n        resp = self.call('peers')\n\n        result = {}\n        peers = resp.get('peers') or {}\n\n        for host, version in peers.items():\n            result[host] = int(version)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether a block is pending by hash.", "response": "def pending_exists(self, hash):\n        \"\"\"\n        Check whether block is pending by **hash**\n\n        .. version 8.0 required\n\n        :param hash: Hash of block to check if pending\n        :type hash: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.pending_exists(\n            hash=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        )\n        True\n        \"\"\"\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        resp = self.call('pending_exists', payload)\n\n        return resp['exists'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops generating work for a specific block.", "response": "def work_cancel(self, hash):\n        \"\"\"\n        Stop generating **work** for block\n\n        .. enable_control required\n\n        :param hash: Hash to stop generating work for\n        :type hash: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.work_cancel(\n        ...     hash=\"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\"\n        ... )\n        True\n\n        \"\"\"\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        resp = self.call('work_cancel', payload)\n        return resp == {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef work_generate(self, hash):\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        resp = self.call('work_generate', payload)\n\n        return resp['work']", "response": "Generates a set of work for the given hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget work for account in wallet", "response": "def work_get(self, wallet, account):\n        \"\"\"\n        Retrieves work for **account** in **wallet**\n\n        .. enable_control required\n        .. version 8.0 required\n\n        :param wallet: Wallet to get account work for\n        :type wallet: str\n\n        :param account: Account to get work for\n        :type account: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.work_get(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     account=\"xrb_1111111111111111111111111111111111111111111111111111hifc8npp\"\n        ... )\n        \"432e5cf728c90f4f\"\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        account = self._process_value(account, 'account')\n\n        payload = {\"wallet\": wallet, \"account\": account}\n\n        resp = self.call('work_get', payload)\n\n        return resp['work']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets work for account in wallet", "response": "def work_set(self, wallet, account, work):\n        \"\"\"\n        Set **work** for **account** in **wallet**\n\n        .. enable_control required\n        .. version 8.0 required\n\n        :param wallet: Wallet to set work for account for\n        :type wallet: str\n\n        :param account: Account to set work for\n        :type account: str\n\n        :param work: Work to set for account in wallet\n        :type work: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.work_set(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     account=\"xrb_1111111111111111111111111111111111111111111111111111hifc8npp\",\n        ...     work=\"0000000000000000\"\n        ... )\n        True\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        account = self._process_value(account, 'account')\n        work = self._process_value(work, 'work')\n\n        payload = {\"wallet\": wallet, \"account\": account, \"work\": work}\n\n        resp = self.call('work_set', payload)\n\n        return 'success' in resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef work_peer_add(self, address, port):\n\n        address = self._process_value(address, 'ipaddr')\n        port = self._process_value(port, 'int')\n\n        payload = {\"address\": address, \"port\": port}\n\n        resp = self.call('work_peer_add', payload)\n\n        return 'success' in resp", "response": "Add specific IP address and port as work peer for node until restart_control is set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef work_validate(self, work, hash):\n\n        work = self._process_value(work, 'work')\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"work\": work, \"hash\": hash}\n\n        resp = self.call('work_validate', payload)\n\n        return resp['valid'] == '1'", "response": "Check whether a work is valid for a block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef republish(self, hash, count=None, sources=None, destinations=None):\n\n        hash = self._process_value(hash, 'block')\n\n        payload = {\"hash\": hash}\n\n        if count is not None:\n            payload['count'] = self._process_value(count, 'int')\n\n        if sources is not None:\n            payload['sources'] = self._process_value(sources, 'int')\n\n        if destinations is not None:\n            payload['destinations'] = self._process_value(destinations, 'int')\n\n        resp = self.call('republish', payload)\n\n        return resp.get('blocks') or []", "response": "Republishes the blocks starting at hash to the network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch for pending blocks for any account in", "response": "def search_pending(self, wallet):\n        \"\"\"\n        Tells the node to look for pending blocks for any account in\n        **wallet**\n\n        .. enable_control required\n\n        :param wallet: Wallet to search for pending blocks\n        :type wallet: str\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.search_pending(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n        ... )\n        True\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n\n        payload = {\"wallet\": wallet}\n\n        resp = self.call('search_pending', payload)\n\n        return resp['started'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends amount funds from source to destination in wallet.", "response": "def send(self, wallet, source, destination, amount, work=None, id=None):\n        \"\"\"\n        Send **amount** from **source** in **wallet** to **destination**\n\n        .. enable_control required\n\n        :param wallet: Wallet of account used to send funds\n        :type wallet: str\n\n        :param source: Account to send funds from\n        :type source: str\n\n        :param destination: Account to send funds to\n        :type destination: str\n\n        :param amount: Amount in raw to send\n        :type amount: int\n\n        :param work: If set, uses this work for the block\n        :type work: str\n\n        :param id:  Unique identifier for this request\n        :param id: str\n\n                    .. version 10.0 required\n\n                    You can (and should) specify a unique id for each spend\n                    to provide idempotency. That means that if you call send\n                    two times with the same id, the second request won't\n                    send any additional Nano, and will return the first\n                    block instead. The id can be any string. This may be a\n                    required parameter in the future.\n\n                    If you accidentally reuse an id, the send will not go\n                    through (it will be seen as a duplicate request), so\n                    make sure your ids are unique! They must be unique per\n                    node, and are not segregated per wallet.\n\n                    Using the same id for requests with different parameters\n                    (wallet, source, destination, and amount) is undefined\n                    behavior and may result in an error in the future.\n\n        :raises: :py:exc:`nano.rpc.RPCException`\n\n        >>> rpc.send(\n        ...     wallet=\"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n        ...     source=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n        ...     destination=\"xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n        ...     amount=1000000,\n        ...     work=\"2bf29ef00786a6bc\",\n        ...     id=\"tx-13258\"\n        ... )\n        \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n\n        \"\"\"\n\n        wallet = self._process_value(wallet, 'wallet')\n        source = self._process_value(source, 'account')\n        destination = self._process_value(destination, 'account')\n        amount = self._process_value(amount, 'int')\n\n        payload = {\n            \"wallet\": wallet,\n            \"source\": source,\n            \"destination\": destination,\n            \"amount\": amount,\n        }\n\n        if id is not None:\n            payload[\"id\"] = self._process_value(id, 'string')\n\n        if work is not None:\n            payload['work'] = self._process_value(work, 'work')\n\n        resp = self.call('send', payload)\n\n        return resp['block']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version(self):\n\n        resp = self.call('version')\n\n        for key in ('rpc_version', 'store_version'):\n            resp[key] = int(resp[key])\n\n        return resp", "response": "Returns the node s RPC version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nauthenticate via username and password.", "response": "def authenticate(self, retries=3):\n        \"\"\"Set API token by authenticating via username/password.\n\n        :param retries: Number of authentication attempts to make before giving up as an int.\n        :return: Learned API token\n        :rtype: string\n        \"\"\"\n\n        username = self.username or self._getuser(self.base)\n        password = self.password\n\n        while retries > 0:\n            if password is None:\n                password = self._getpass(self.base, username)\n\n            try:\n                resp = self.post(self.base+'/authenticate', params={'username': username, 'password': password})\n\n                schema = UserSchema()\n                u = self.decode(schema, resp)\n\n                if u.token is not None:\n                    self.lock.acquire()\n                    self.token = u.token\n                    self.lock.release()\n                    break\n            except CDRouterError as cde:\n                password = None\n                retries -= 1\n                if retries == 0:\n                    raise cde\n\n        return self.token"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract_email(gh):\n    return next(\n        (x.email for x in gh.emails() if x.verified and x.primary), None)", "response": "Extract user email from github."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves remote account information from github3.", "response": "def account_info(remote, resp):\n    \"\"\"Retrieve remote account information used to find local user.\n\n    It returns a dictionary with the following structure:\n\n    .. code-block:: python\n\n        {\n            'user': {\n                'email': '...',\n                'profile': {\n                    'username': '...',\n                    'full_name': '...',\n                }\n            },\n            'external_id': 'github-unique-identifier',\n            'external_method': 'github',\n        }\n\n    Information inside the user dictionary are available for other modules.\n    For example, they are used from the module invenio-userprofiles to fill\n    the user profile.\n\n    :param remote: The remote application.\n    :param resp: The response.\n    :returns: A dictionary with the user information.\n    \"\"\"\n    gh = github3.login(token=resp['access_token'])\n    me = gh.me()\n    return dict(\n        user=dict(\n            email=_extract_email(gh),\n            profile=dict(\n                username=me.login,\n                full_name=me.name,\n            ),\n        ),\n        external_id=str(me.id),\n        external_method='github'\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef account_setup(remote, token, resp):\n    gh = github3.login(token=resp['access_token'])\n    with db.session.begin_nested():\n        me = gh.me()\n\n        token.remote_account.extra_data = {'login': me.login, 'id': me.id}\n\n        # Create user <-> external id link.\n        oauth_link_external_id(\n            token.remote_account.user, dict(\n                id=str(me.id),\n                method='github')\n        )", "response": "Perform additional setup after user have been logged in."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthorizes callback handler for GitHub.", "response": "def authorized(resp, remote):\n    \"\"\"Authorized callback handler for GitHub.\n\n    :param resp: The response.\n    :param remote: The remote application.\n    \"\"\"\n    if resp and 'error' in resp:\n        if resp['error'] == 'bad_verification_code':\n            # See https://developer.github.com/v3/oauth/#bad-verification-code\n            # which recommends starting auth flow again.\n            return redirect(url_for('invenio_oauthclient.login',\n                                    remote_app='github'))\n        elif resp['error'] in ['incorrect_client_credentials',\n                               'redirect_uri_mismatch']:\n            raise OAuthResponseError(\n                'Application mis-configuration in GitHub', remote, resp\n            )\n\n    return authorized_signup_handler(resp, remote)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eq(self, value):\n        self.op = '='\n        self.negate_op = '!='\n        self.value = self._value(value)\n        return self", "response": "Construct an equal to filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct a not equal to filter.", "response": "def ne(self, value):\n        \"\"\"Construct a not equal to (``!=``) filter.\n\n        :param value: Filter value\n        :return: :class:`filters.Field <filters.Field>` object\n        :rtype: filters.Field\n        \"\"\"\n        self.op = '!='\n        self.negate_op = '='\n        self.value = self._value(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gt(self, value):\n        self.op = '>'\n        self.negate_op = '<='\n        self.value = self._value(value)\n        return self", "response": "Construct a greater than filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a greater than or equal to filter.", "response": "def ge(self, value):\n        \"\"\"Construct a greater than or equal to (``>=``) filter.\n\n        :param value: Filter value\n        :return: :class:`filters.Field <filters.Field>` object\n        :rtype: filters.Field\n        \"\"\"\n        self.op = '>='\n        self.negate_op = '<'\n        self.value = self._value(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lt(self, value):\n        self.op = '<'\n        self.negate_op = '>='\n        self.value = self._value(value)\n        return self", "response": "Construct a less than filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a less than or equal to filter.", "response": "def le(self, value):\n        \"\"\"Construct a less than or equal to (``<=``) filter.\n\n        :param value: Filter value\n        :return: :class:`filters.Field <filters.Field>` object\n        :rtype: filters.Field\n        \"\"\"\n        self.op = '<='\n        self.negate_op = '>'\n        self.value = self._value(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match(self, value, ignorecase=False):\n        if not ignorecase:\n            self.op = '~'\n            self.negate_op = '!~'\n        else:\n            self.op = '~*'\n            self.negate_op = '!~*'\n        self.value = self._value(value)\n        return self", "response": "Construct a regexp match filter. Combine with not_ method to construct a negative regexp match."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contains(self, *args):\n        self.op = '@>'\n        self.negate_op = None\n        self.value = self._array_value(args)\n        return self", "response": "Construct an array contains filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef contained_by(self, *args):\n        self.op = '<@'\n        self.negate_op = None\n        self.value = self._array_value(args)\n        return self", "response": "Construct an array contained by filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef overlaps(self, *args):\n        self.op = '&&'\n        self.negate_op = None\n        self.value = self._array_value(args)\n        return self", "response": "Construct an array overlaps filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all unique sequences from a list of reads.", "response": "def initial_variant_sequences_from_reads(\n        variant_reads,\n        max_nucleotides_before_variant=None,\n        max_nucleotides_after_variant=None):\n    \"\"\"\n    Get all unique sequences from reads spanning a variant locus. This will\n    include partial sequences due to reads starting in the middle of the\n    sequence around around a variant.\n    \"\"\"\n    unique_sequence_groups = group_unique_sequences(\n        variant_reads,\n        max_prefix_size=max_nucleotides_before_variant,\n        max_suffix_size=max_nucleotides_after_variant)\n\n    return [\n        VariantSequence(\n            prefix=prefix,\n            alt=alt,\n            suffix=suffix,\n            reads=reads)\n        for ((prefix, alt, suffix), reads)\n        in unique_sequence_groups.items()\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trim_variant_sequences(variant_sequences, min_variant_sequence_coverage):\n    n_total = len(variant_sequences)\n    trimmed_variant_sequences = [\n        variant_sequence.trim_by_coverage(min_variant_sequence_coverage)\n        for variant_sequence in variant_sequences\n    ]\n    collapsed_variant_sequences = collapse_substrings(trimmed_variant_sequences)\n    n_after_trimming = len(collapsed_variant_sequences)\n    logger.info(\n        \"Kept %d/%d variant sequences after read coverage trimming to >=%dx\",\n        n_after_trimming,\n        n_total,\n        min_variant_sequence_coverage)\n    return collapsed_variant_sequences", "response": "Trims VariantSequences to desired coverage and then combine anyAcquireSequence subsequences which get generated."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_variant_sequences(\n        variant_sequences,\n        preferred_sequence_length,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,):\n    \"\"\"\n    Drop variant sequences which are shorter than request or don't have\n    enough supporting reads.\n    \"\"\"\n    variant_sequences = trim_variant_sequences(\n        variant_sequences, min_variant_sequence_coverage)\n\n    return filter_variant_sequences_by_length(\n        variant_sequences=variant_sequences,\n        preferred_sequence_length=preferred_sequence_length)", "response": "Filter out all the variant sequences that are shorter than the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reads_to_variant_sequences(\n        variant,\n        reads,\n        preferred_sequence_length,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\n    Collapse variant-supporting RNA reads into consensus sequences of\n    approximately the preferred length (may differ at the ends of transcripts),\n    filter consensus sequences by length and number of supporting RNA reads.\n\n    Parameters\n    ----------\n    variant : varcode.Variant\n\n    reads : list of AlleleRead objects\n        Should all support the same variant allele nucleotides.\n\n    preferred_sequence_length : int\n        Total number of nucleotides in the assembled sequences, including\n        variant nucleotides.\n\n    min_alt_rna_reads : int\n        Drop sequences from loci which lack at least this number of reads\n        that agree with the variant allele.\n\n    min_variant_sequence_coverage : int\n        Drop sequences which don't at least have this number of reads\n        covering each cDNA position.\n\n    variant_sequence_assembly : bool\n        Construct variant sequences by merging overlapping reads. If False\n        then variant sequences must be fully spanned by cDNA reads.\n\n    Returns a collection of VariantSequence objects\n    \"\"\"\n    # just in case variant_reads is a generator, convert it to a list\n    variant_reads = list(filter_non_alt_reads_for_variant(variant, reads))\n\n    if len(variant_reads) < min_alt_rna_reads:\n        logger.info(\n            \"Skipping %s because only %d alt RNA reads (min=%d)\",\n            variant,\n            len(variant_reads),\n            min_alt_rna_reads)\n        return []\n    if len(variant_reads) == 0:\n        return []\n\n    alt_seq = get_single_allele_from_reads(variant_reads)\n\n    # the number of context nucleotides on either side of the variant\n    # is half the desired length (minus the number of variant nucleotides)\n    n_alt_nucleotides = len(alt_seq)\n\n    n_surrounding_nucleotides = preferred_sequence_length - n_alt_nucleotides\n    max_nucleotides_after_variant = n_surrounding_nucleotides // 2\n\n    # if the number of nucleotides we need isn't divisible by 2 then\n    # prefer to have one more *before* the variant since we need the\n    # prefix sequence to match against reference transcripts\n    max_nucleotides_before_variant = (\n        n_surrounding_nucleotides - max_nucleotides_after_variant)\n\n    variant_sequences = initial_variant_sequences_from_reads(\n        variant_reads=variant_reads,\n        max_nucleotides_before_variant=max_nucleotides_before_variant,\n        max_nucleotides_after_variant=max_nucleotides_after_variant)\n\n    logger.info(\n        \"Initial pool of %d variant sequences (min length=%d, max length=%d)\",\n        len(variant_sequences),\n        min(len(s) for s in variant_sequences),\n        max(len(s) for s in variant_sequences))\n\n    if variant_sequence_assembly:\n        # this is a tricky parameter to set correctly:\n        # by how many bases should two sequences overlap before\n        # we merge, currently defaulting to either half the non-variant\n        # nucleotides or 30 (whichever is smaller)\n        variant_sequences = iterative_overlap_assembly(\n            variant_sequences,\n            min_overlap_size=min(\n                MIN_VARIANT_SEQUENCE_ASSEMBLY_OVERLAP_SIZE,\n                n_surrounding_nucleotides // 2))\n\n    if variant_sequences:\n        logger.info(\n            \"After overlap assembly: %d variant sequences (min length=%d, max length=%d)\",\n            len(variant_sequences),\n            min(len(s) for s in variant_sequences),\n            max(len(s) for s in variant_sequences))\n    else:\n        logger.info(\"After overlap assembly: 0 variant sequences\")\n        return []\n\n    variant_sequences = filter_variant_sequences(\n        variant_sequences=variant_sequences,\n        preferred_sequence_length=preferred_sequence_length,\n        min_variant_sequence_coverage=min_variant_sequence_coverage)\n\n    if variant_sequences:\n        logger.info(\n            (\"After coverage & length filtering: %d variant sequences \"\n             \"(min length=%d, max length=%d)\"),\n            len(variant_sequences),\n            min(len(s) for s in variant_sequences),\n            max(len(s) for s in variant_sequences))\n    else:\n        logger.info(\"After coverage & length filtering: 0 variant sequences\")\n        return []\n\n    # sort VariantSequence objects by decreasing order of supporting read\n    # counts\n    variant_sequences.sort(key=lambda vs: -len(vs.reads))\n    return variant_sequences", "response": "Converts a list of AlleleRead objects into a list of VariantSequence objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reads_generator_to_sequences_generator(\n        variant_and_reads_generator,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        preferred_sequence_length=VARIANT_SEQUENCE_LENGTH,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\n    For each variant, collect all possible sequence contexts around the\n    variant which are spanned by at least min_reads.\n\n    Parameters\n    ----------\n    variant_and_reads_generator : generator\n        Sequence of Variant objects paired with a list of reads which\n        overlap that variant.\n\n    min_alt_rna_reads : int\n        Minimum number of RNA reads supporting variant allele\n\n    min_variant_sequence_coverage : int\n        Minimum number of RNA reads supporting each nucleotide of the\n        variant cDNA sequence\n\n    sequence_length : int\n        Desired sequence length, including variant nucleotides\n\n    variant_sequence_assembly : bool\n        Construct variant sequences by merging overlapping reads. If False\n        then variant sequences must be fully spanned by cDNA reads.\n\n    Yields pairs with the following fields:\n        - Variant\n        - list of VariantSequence objects\n    \"\"\"\n    for variant, variant_reads in variant_and_reads_generator:\n        variant_sequences = reads_to_variant_sequences(\n            variant=variant,\n            reads=variant_reads,\n            min_alt_rna_reads=min_alt_rna_reads,\n            min_variant_sequence_coverage=min_variant_sequence_coverage,\n            preferred_sequence_length=preferred_sequence_length,\n            variant_sequence_assembly=variant_sequence_assembly)\n        yield variant, variant_sequences", "response": "Generates a generator of all possible sequence contexts around the given variant_and_reads_generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef variant_sequences_generator_to_dataframe(variant_sequences_generator):\n    # TODO: Change VariantSequence.alt to VariantSequence.alt_nucleotides\n    # or something else that doesn't clash with a variant's `alt` field\n    return dataframe_from_generator(\n        VariantSequence,\n        variant_sequences_generator,\n        rename_dict={\"alt\": \"allele\"},\n        extra_column_fns={\n            \"gene\": lambda variant, _: \";\".join(variant.gene_names),\n        })", "response": "Creates a dataframe from a generator which yields\n            VariantSequence pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contains(self, other):\n        return (self.alt == other.alt and\n                self.prefix.endswith(other.prefix) and\n                self.suffix.startswith(other.suffix))", "response": "Returns True if this VariantSequence contains the other VariantSequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if this VariantSequence overlaps another VariantSequence.", "response": "def left_overlaps(self, other, min_overlap_size=1):\n        \"\"\"\n        Does this VariantSequence overlap another on the left side?\n        \"\"\"\n\n        if self.alt != other.alt:\n            # allele must match!\n            return False\n\n        if len(other.prefix) > len(self.prefix):\n            # only consider strings that overlap like:\n            #   self: ppppAssss\n            #   other:   ppAsssssss\n            # which excludes cases where the other sequence has a longer\n            # prefix\n            return False\n        elif len(other.suffix) < len(self.suffix):\n            # similarly, we throw away cases where the other sequence is shorter\n            # after the alt nucleotides than this sequence\n            return False\n\n        # is the other sequence a prefix of this sequence?\n        # Example:\n        # p1 a1 s1 = XXXXXXXX Y ZZZZZZ\n        # p2 a2 s2 =       XX Y ZZZZZZZZZ\n        # ...\n        # then we can combine them into a longer sequence\n        sequence_overlaps = (\n            self.prefix.endswith(other.prefix) and\n            other.suffix.startswith(self.suffix)\n        )\n        prefix_overlap_size = min(len(self.prefix), len(other.prefix))\n        suffix_overlap_size = min(len(other.suffix), len(self.suffix))\n        overlap_size = (\n            prefix_overlap_size + suffix_overlap_size + len(self.alt))\n\n        return sequence_overlaps and overlap_size >= min_overlap_size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating another VariantSequence with more supporting reads.", "response": "def add_reads(self, reads):\n        \"\"\"\n        Create another VariantSequence with more supporting reads.\n        \"\"\"\n        if len(reads) == 0:\n            return self\n        new_reads = self.reads.union(reads)\n        if len(new_reads) > len(self.reads):\n            return VariantSequence(\n                prefix=self.prefix,\n                alt=self.alt,\n                suffix=self.suffix,\n                reads=new_reads)\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef combine(self, other_sequence):\n        if other_sequence.alt != self.alt:\n            logger.warn(\n                \"Cannot combine %s and %s with mismatching alt sequences\",\n                self,\n                other_sequence)\n            return None\n        elif self.contains(other_sequence):\n            return self.add_reads(other_sequence.reads)\n        elif other_sequence.contains(self):\n            return other_sequence.add_reads(self.reads)\n        elif self.left_overlaps(other_sequence):\n            # If sequences are like AABC and ABCC\n            return VariantSequence(\n                prefix=self.prefix,\n                alt=self.alt,\n                suffix=other_sequence.suffix,\n                reads=self.reads.union(other_sequence.reads))\n        elif other_sequence.left_overlaps(self):\n            return VariantSequence(\n                prefix=other_sequence.prefix,\n                alt=self.alt,\n                suffix=self.suffix,\n                reads=self.reads.union(other_sequence.reads))\n        else:\n            # sequences don't overlap\n            return None", "response": "Combine two VariantSequence objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the start and end indices of the base - 0 index of the alt - base - 0 sequence.", "response": "def variant_indices(self):\n        \"\"\"\n        When we combine prefix + alt + suffix into a single string,\n        what are is base-0 index interval which gets us back the alt\n        sequence? First returned index is inclusive, the second is exclusive.\n        \"\"\"\n        variant_start_index = len(self.prefix)\n        variant_len = len(self.alt)\n        variant_end_index = variant_start_index + variant_len\n        return variant_start_index, variant_end_index"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns NumPy array indicating number of reads covering each sequence s nucleotides.", "response": "def coverage(self):\n        \"\"\"\n        Returns NumPy array indicating number of reads covering each\n        nucleotides of this sequence.\n        \"\"\"\n        variant_start_index, variant_end_index = self.variant_indices()\n        n_nucleotides = len(self)\n        coverage_array = np.zeros(n_nucleotides, dtype=\"int32\")\n        for read in self.reads:\n            coverage_array[\n                max(0, variant_start_index - len(read.prefix)):\n                min(n_nucleotides, variant_end_index + len(read.suffix))] += 1\n        return coverage_array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trim_by_coverage(self, min_reads):\n        read_count_array = self.coverage()\n        logger.info(\"Coverage: %s (len=%d)\" % (\n            read_count_array, len(read_count_array)))\n        sufficient_coverage_mask = read_count_array >= min_reads\n        sufficient_coverage_indices = np.argwhere(sufficient_coverage_mask)\n        if len(sufficient_coverage_indices) == 0:\n            logger.debug(\"No bases in %s have coverage >= %d\" % (self, min_reads))\n            return VariantSequence(prefix=\"\", alt=\"\", suffix=\"\", reads=self.reads)\n        variant_start_index, variant_end_index = self.variant_indices()\n        # assuming that coverage drops off monotonically away from\n        # variant nucleotides\n        first_covered_index = sufficient_coverage_indices.min()\n        last_covered_index = sufficient_coverage_indices.max()\n        # adding 1 to last_covered_index since it's an inclusive index\n        # whereas variant_end_index is the end of a half-open interval\n        if (first_covered_index > variant_start_index or\n                last_covered_index + 1 < variant_end_index):\n            # Example:\n            #   Nucleotide sequence:\n            #       ACCCTTTT|AA|GGCGCGCC\n            #   Coverage:\n            #       12222333|44|33333211\n            # Then the mask for bases covered >= 4x would be:\n            #       ________|**|________\n            # with indices:\n            #       first_covered_index = 9\n            #       last_covered_index = 10\n            #       variant_start_index = 9\n            #       variant_end_index = 11\n            logger.debug(\"Some variant bases in %s don't have coverage >= %d\" % (\n                self, min_reads))\n            return VariantSequence(prefix=\"\", alt=\"\", suffix=\"\", reads=self.reads)\n        return VariantSequence(\n            prefix=self.prefix[first_covered_index:],\n            alt=self.alt,\n            suffix=self.suffix[:last_covered_index - variant_end_index + 1],\n            reads=self.reads)", "response": "This method trims the nucleotide sequence by getting rid of positions\n            which are overlapped by fewer reads than specified."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef records():\n    with db.session.begin_nested():\n        for idx in range(20):\n            # create the record\n            id_ = uuid.uuid4()\n            Record.create({\n                'title': 'LHC experiment {}'.format(idx),\n                'description': 'Data from experiment {}.'.format(idx),\n                'type': 'data',\n                'recid': idx\n            }, id_=id_)\n            PersistentIdentifier.create(\n                pid_type='recid',\n                pid_value=idx,\n                object_type='rec',\n                object_uuid=id_,\n                status=PIDStatus.REGISTERED,\n            )\n\n    db.session.commit()", "response": "Load test data fixture."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trim_N_nucleotides(prefix, suffix):\n    if 'N' in prefix:\n        # trim prefix to exclude all occurrences of N\n        rightmost_index = prefix.rfind('N')\n        logger.debug(\n            \"Trimming %d nucleotides from read prefix '%s'\",\n            rightmost_index + 1, prefix)\n        prefix = prefix[rightmost_index + 1:]\n\n    if 'N' in suffix:\n        leftmost_index = suffix.find('N')\n        logger.debug(\n            \"Trimming %d nucleotides from read suffix '%s'\",\n            len(suffix) - leftmost_index,\n            suffix)\n        suffix = suffix[:leftmost_index]\n\n    return prefix, suffix", "response": "Removes all occurrences of N from prefix and suffix nucleotide strings\n    by trimming."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_from_bytes_if_necessary(prefix, suffix):\n    if isinstance(prefix, bytes):\n        prefix = prefix.decode('ascii')\n\n    if isinstance(suffix, bytes):\n        suffix = suffix.decode('ascii')\n\n    return prefix, suffix", "response": "Convert from bytes to unicode if necessary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a sequence of reads which are paired with each variant in the given collection of variants.", "response": "def reads_supporting_variants(variants, samfile, **kwargs):\n    \"\"\"\n    Given a SAM/BAM file and a collection of variants, generates a sequence\n    of variants paired with reads which support each variant.\n    \"\"\"\n    for variant, allele_reads in reads_overlapping_variants(\n            variants=variants,\n            samfile=samfile,\n            **kwargs):\n        yield variant, filter_non_alt_reads_for_variant(variant, allele_reads)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(self, record):\n        index, doc_type = self.record_to_index(record)\n\n        return self.client.index(\n            id=str(record.id),\n            version=record.revision_id,\n            version_type=self._version_type,\n            index=index,\n            doc_type=doc_type,\n            body=self._prepare_record(record, index, doc_type),\n        )", "response": "Index a record.\n\n        The caller is responsible for ensuring that the record has already been\n        committed to the database. If a newer version of a record has already\n        been indexed then the provided record will not be indexed. This\n        behavior can be controlled by providing a different ``version_type``\n        when initializing ``RecordIndexer``.\n\n        :param record: Record instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a record. :param record: Record instance.", "response": "def delete(self, record):\n        \"\"\"Delete a record.\n\n        :param record: Record instance.\n        \"\"\"\n        index, doc_type = self.record_to_index(record)\n\n        return self.client.delete(\n            id=str(record.id),\n            index=index,\n            doc_type=doc_type,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_bulk_queue(self, es_bulk_kwargs=None):\n        with current_celery_app.pool.acquire(block=True) as conn:\n            consumer = Consumer(\n                connection=conn,\n                queue=self.mq_queue.name,\n                exchange=self.mq_exchange.name,\n                routing_key=self.mq_routing_key,\n            )\n\n            req_timeout = current_app.config['INDEXER_BULK_REQUEST_TIMEOUT']\n\n            es_bulk_kwargs = es_bulk_kwargs or {}\n            count = bulk(\n                self.client,\n                self._actionsiter(consumer.iterqueue()),\n                stats_only=True,\n                request_timeout=req_timeout,\n                **es_bulk_kwargs\n            )\n\n            consumer.close()\n\n        return count", "response": "Process bulk indexing queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nindexing record in Elasticsearch asynchronously.", "response": "def _bulk_op(self, record_id_iterator, op_type, index=None, doc_type=None):\n        \"\"\"Index record in Elasticsearch asynchronously.\n\n        :param record_id_iterator: Iterator that yields record UUIDs.\n        :param op_type: Indexing operation (one of ``index``, ``create``,\n            ``delete`` or ``update``).\n        :param index: The Elasticsearch index. (Default: ``None``)\n        :param doc_type: The Elasticsearch doc_type. (Default: ``None``)\n        \"\"\"\n        with self.create_producer() as producer:\n            for rec in record_id_iterator:\n                producer.publish(dict(\n                    id=str(rec),\n                    op=op_type,\n                    index=index,\n                    doc_type=doc_type\n                ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate bulk actions. :param message_iterator: Iterator yielding messages from a queue.", "response": "def _actionsiter(self, message_iterator):\n        \"\"\"Iterate bulk actions.\n\n        :param message_iterator: Iterator yielding messages from a queue.\n        \"\"\"\n        for message in message_iterator:\n            payload = message.decode()\n            try:\n                if payload['op'] == 'delete':\n                    yield self._delete_action(payload)\n                else:\n                    yield self._index_action(payload)\n                message.ack()\n            except NoResultFound:\n                message.reject()\n            except Exception:\n                message.reject()\n                current_app.logger.error(\n                    \"Failed to index record {0}\".format(payload.get('id')),\n                    exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbulk delete action. :param payload: Decoded message body. :returns: Dictionary defining an Elasticsearch bulk 'delete' action.", "response": "def _delete_action(self, payload):\n        \"\"\"Bulk delete action.\n\n        :param payload: Decoded message body.\n        :returns: Dictionary defining an Elasticsearch bulk 'delete' action.\n        \"\"\"\n        index, doc_type = payload.get('index'), payload.get('doc_type')\n        if not (index and doc_type):\n            record = Record.get_record(payload['id'])\n            index, doc_type = self.record_to_index(record)\n\n        return {\n            '_op_type': 'delete',\n            '_index': index,\n            '_type': doc_type,\n            '_id': payload['id'],\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _index_action(self, payload):\n        record = Record.get_record(payload['id'])\n        index, doc_type = self.record_to_index(record)\n\n        return {\n            '_op_type': 'index',\n            '_index': index,\n            '_type': doc_type,\n            '_id': str(record.id),\n            '_version': record.revision_id,\n            '_version_type': self._version_type,\n            '_source': self._prepare_record(record, index, doc_type),\n        }", "response": "Bulk index action.\n\n        :param payload: Decoded message body.\n        :returns: Dictionary defining an Elasticsearch bulk 'index' action."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares record data for indexing.", "response": "def _prepare_record(record, index, doc_type):\n        \"\"\"Prepare record data for indexing.\n\n        :param record: The record to prepare.\n        :param index: The Elasticsearch index.\n        :param doc_type: The Elasticsearch document type.\n        :returns: The record metadata.\n        \"\"\"\n        if current_app.config['INDEXER_REPLACE_REFS']:\n            data = copy.deepcopy(record.replace_refs())\n        else:\n            data = record.dumps()\n\n        data['_created'] = pytz.utc.localize(record.created).isoformat() \\\n            if record.created else None\n        data['_updated'] = pytz.utc.localize(record.updated).isoformat() \\\n            if record.updated else None\n\n        # Allow modification of data prior to sending to Elasticsearch.\n        before_record_index.send(\n            current_app._get_current_object(),\n            json=data,\n            record=record,\n            index=index,\n            doc_type=doc_type,\n        )\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef greedy_merge_helper(\n        variant_sequences,\n        min_overlap_size=MIN_VARIANT_SEQUENCE_ASSEMBLY_OVERLAP_SIZE):\n    \"\"\"\n    Returns a list of merged VariantSequence objects, and True if any\n    were successfully merged.\n    \"\"\"\n    merged_variant_sequences = {}\n    merged_any = False\n\n    # here we'll keep track of sequences that haven't been merged yet, and add them in at the end\n    unmerged_variant_sequences = set(variant_sequences)\n    for i in range(len(variant_sequences)):\n        sequence1 = variant_sequences[i]\n        # it works to loop over the triangle (i+1 onwards) because combine() tries flipping the\n        # arguments if sequence1 is on the right of sequence2\n        for j in range(i + 1, len(variant_sequences)):\n            sequence2 = variant_sequences[j]\n            combined = sequence1.combine(sequence2)\n            if combined is None:\n                continue\n            if combined.sequence in merged_variant_sequences:\n                existing = merged_variant_sequences[combined.sequence]\n                # the existing VariantSequence and the newly merged\n                # VariantSequence should differ only in which reads support them\n                combined = combined.add_reads(existing.reads)\n            merged_variant_sequences[combined.sequence] = combined\n            unmerged_variant_sequences.discard(sequence1)\n            unmerged_variant_sequences.discard(sequence2)\n            merged_any = True\n    result = list(merged_variant_sequences.values()) + list(unmerged_variant_sequences)\n    return result, merged_any", "response": "Greedy merge of two VariantSequence objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collapse_substrings(variant_sequences):\n    if len(variant_sequences) <= 1:\n        # if we don't have at least two VariantSequences then just\n        # return your input\n        return variant_sequences\n\n    # dictionary mapping VariantSequence objects to lists of reads\n    # they absorb from substring VariantSequences\n    extra_reads_from_substrings = defaultdict(set)\n    result_list = []\n    # sort by longest to shortest total length\n    for short_variant_sequence in sorted(\n            variant_sequences,\n            key=lambda seq: -len(seq)):\n        found_superstring = False\n        for long_variant_sequence in result_list:\n            found_superstring = long_variant_sequence.contains(short_variant_sequence)\n            if found_superstring:\n                extra_reads_from_substrings[long_variant_sequence].update(\n                    short_variant_sequence.reads)\n        if not found_superstring:\n            result_list.append(short_variant_sequence)\n    # add to each VariantSequence the reads it absorbed from dropped substrings\n    # and then return\n    return [\n        variant_sequence.add_reads(\n            extra_reads_from_substrings[variant_sequence])\n        for variant_sequence in result_list\n    ]", "response": "Combine shorter sequences which are fully contained in longer sequences and return a list of lists of all reads that are absorbed from dropped substrings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating over the longer sequences of a given set of reads and return a list of longer sequences sorted by decreasing read support.", "response": "def iterative_overlap_assembly(\n        variant_sequences,\n        min_overlap_size=MIN_VARIANT_SEQUENCE_ASSEMBLY_OVERLAP_SIZE):\n    \"\"\"\n    Assembles longer sequences from reads centered on a variant by\n    between merging all pairs of overlapping sequences and collapsing\n    shorter sequences onto every longer sequence which contains them.\n\n    Returns a list of variant sequences, sorted by decreasing read support.\n    \"\"\"\n    if len(variant_sequences) <= 1:\n        # if we don't have at least two sequences to start with then\n        # skip the whole mess below\n        return variant_sequences\n\n    # reduce the number of inputs to the merge algorithm by first collapsing\n    # shorter sequences onto the longer sequences which contain them\n    n_before_collapse = len(variant_sequences)\n    variant_sequences = collapse_substrings(variant_sequences)\n    n_after_collapse = len(variant_sequences)\n    logger.info(\n        \"Collapsed %d -> %d sequences\",\n        n_before_collapse,\n        n_after_collapse)\n\n    merged_variant_sequences = greedy_merge(variant_sequences, min_overlap_size)\n    return list(sorted(\n        merged_variant_sequences,\n        key=lambda seq: -len(seq.reads)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef groupby(xs, key_fn):\n    result = defaultdict(list)\n    for x in xs:\n        key = key_fn(x)\n        result[key].append(x)\n    return result", "response": "Groups the elements of the list xs by keys generated from calling key_fn."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate an orthonormal basis in the plane perpendicular to normal.", "response": "def ortho_basis(normal, ref_vec=None):\n    \"\"\"Generates an orthonormal basis in the plane perpendicular to `normal`\n\n    The orthonormal basis generated spans the plane defined with `normal` as\n    its normal vector.  The handedness of `on1` and `on2` in the returned\n    basis is such that:\n\n    .. math::\n\n            \\\\mathsf{on1} \\\\times \\\\mathsf{on2} =\n            {\\\\mathsf{normal} \\\\over \\\\left\\\\| \\\\mathsf{normal}\\\\right\\\\|}\n\n    `normal` must be expressible as a one-dimensional |nparray| of length 3.\n\n    Parameters\n    ----------\n    normal\n        length-3 |npfloat_| --\n        The orthonormal basis output will span the plane perpendicular\n        to `normal`.\n\n    ref_vec\n        length-3 |npfloat_|, optional --\n        If specified, `on1` will be the normalized projection of `ref_vec`\n        onto the plane perpendicular to `normal`. Default is |None|.\n\n    Returns\n    -------\n    on1\n        length-3 |npfloat_| --\n        First vector defining the orthonormal basis in the plane\n        normal to `normal`\n\n    on2\n        length-3 |npfloat_| --\n        Second vector defining the orthonormal basis in the plane\n        normal to `normal`\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If `normal` or `ref_vec` is not expressible as a 1-D vector\n        with 3 elements\n\n    ~opan.error.VectorError\n        (typecode :attr:`~opan.error.VectorError.NONPRL`)\n        If `ref_vec` is specified and it is insufficiently non-\n        parallel with respect to `normal`\n\n    \"\"\"\n\n    # Imports for library functions\n    import numpy as np\n    from scipy import linalg as spla\n    from scipy import random as sprnd\n    from ..const import PRM\n    from ..error import VectorError\n\n    # Internal parameters\n    # Magnitude of the perturbation from 'normal' in constructing a random rv\n    RAND_MAG = 0.25\n\n    # Test 'normal' for shape and length\n    if not len(normal.shape) == 1:\n        raise ValueError(\"'normal' is not a vector\")\n    ## end if\n    if not normal.shape[0] == 3:\n        raise ValueError(\"Length of 'normal' is not three\")\n    ## end if\n\n    # Normalize to concise variable 'nv'\n    nv = normal / spla.norm(normal)\n\n    # Test for specification of ref_vec in the function call\n    if ref_vec is None:\n        # ref_vec not specified.\n        #\n        # Generate reference vector by generation of a random perturbation\n        #  vector suitably non-parallel to norm_vec\n        # Generate suitable randomizer, looping as needed\n        rv = nv\n        while parallel_check(nv, rv):\n            rv = np.float64(1.0 - RAND_MAG + 2 * RAND_MAG * sprnd.rand(3))\n        ## do loop\n\n        # Calculate rejection of perturbed vector on the normal, then\n        #  normalize\n        rv = rej(rv, nv)\n        rv = rv / spla.norm(rv)\n\n    else:\n        # ref_vec specified, go ahead and use.  Start with validity check.\n        if not len(ref_vec.shape) == 1:\n            raise ValueError(\"ref_vec is not a vector\")\n        ## end if\n        if not ref_vec.shape[0] == 3:\n            raise ValueError(\"ref_vec length is not three\")\n        ## end if\n\n        # Normalize ref_vec to 'rv'\n        rv = ref_vec / spla.norm(ref_vec)\n\n        # Check for collinearity of nv and rv; raise error if too close\n        if parallel_check(nv, rv):\n            # Essentially equal or opposite vectors, making them too nearly\n            #  parallel.\n            raise VectorError(VectorError.NONPRL,\n                    \"'normal' and 'ref_vec' are too nearly parallel.\", \"\")\n        ## end if\n\n        # rv is ok to use from here\n\n    ## end try\n\n    # on2 is the unit vector parallel to nv x rv\n    on2 = np.cross(nv, rv)\n    on2 = on2 / spla.norm(on2)\n\n    # on1 is on2 x nv (normalization should not be necessary here, but is\n    #  performed just in case)\n    on1 = np.cross(on2, nv)\n    on1 = on1 / spla.norm(on1)\n\n    # Return the spanning vectors\n    return on1, on2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef orthonorm_check(a, tol=_DEF.ORTHONORM_TOL, report=False):\n\n    # Imports\n    import numpy as np\n    from .base import delta_fxn\n\n    #!TODO? orthonorm_check Must add traps to ensure a is a single array,\n    #    that it is 2D, that it's all real? To enforce the limits stated\n    #    in the docstring?\n\n    # Initialize return variables\n    orth = True\n    n_fail = []\n    o_fail = []\n\n    # Coerce to float_ matrix. Must treat 1-D vector as column vector.\n    #  Should raise an exception for any objects with more than\n    #  two dimensions; real and all-numeric are still not yet checked, but\n    #  will probably be run-time caught if too bad an object is passed.\n    if len(a.shape) == 1:\n        a_mx = np.matrix(a, dtype=np.float_).T\n    else:\n        a_mx = np.matrix(a, dtype=np.float_)\n\n    # Split matrix into separate vectors for convenient indexing.\n    a_split = np.hsplit(a_mx, a_mx.shape[1])\n\n    # Loop over vectors and check orthonormality.\n    for iter1 in range(a_mx.shape[1]):\n        for iter2 in range(iter1,a_mx.shape[1]):\n            if not abs((a_split[iter1].T * a_split[iter2])[0,0] -\n                        np.float_(delta_fxn(iter1, iter2))) <= tol:\n                orth = False\n                if report:\n                    if iter1 == iter2:\n                        n_fail.append(iter1)\n                    else:\n                        o_fail.append((iter1, iter2))\n\n    # Return results\n    if report:\n        return orth, n_fail, o_fail\n    else:\n        return orth, None, None", "response": "Checks the orthonormality of the column vectors of a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether two vectors are parallel OR anti - parallel.", "response": "def parallel_check(vec1, vec2):\n    \"\"\"Checks whether two vectors are parallel OR anti-parallel.\n\n    Vectors must be of the same dimension.\n\n    Parameters\n    ----------\n    vec1\n        length-R |npfloat_| --\n        First vector to compare\n\n    vec2\n        length-R |npfloat_| --\n        Second vector to compare\n\n    Returns\n    -------\n    par\n        |bool| --\n        |True| if (anti-)parallel to within\n        :data:`opan.const.PRM.NON_PARALLEL_TOL` degrees.  |False| otherwise.\n\n    \"\"\"\n\n    # Imports\n    from ..const import PRM\n    import numpy as np\n\n    # Initialize False\n    par = False\n\n    # Shape check\n    for n,v in enumerate([vec1, vec2]):\n        if not len(v.shape) == 1:\n            raise ValueError(\"Bad shape for vector #{0}\".format(n))\n        ## end if\n    ## next v,n\n    if not vec1.shape[0] == vec2.shape[0]:\n        raise ValueError(\"Vector length mismatch\")\n    ## end if\n\n    # Check for (anti-)parallel character and return\n    angle = vec_angle(vec1, vec2)\n    if min([abs(angle), abs(angle - 180.)]) < PRM.NON_PARALLEL_TOL:\n        par = True\n    ## end if\n\n    return par"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvectoring projection. Calculated as: .. math:: \\\\mathsf{vec\\\\_onto} * \\\\frac{\\\\mathsf{vec}\\\\cdot\\\\mathsf{vec\\\\_onto}} {\\\\mathsf{vec\\\\_onto}\\\\cdot\\\\mathsf{vec\\\\_onto}} Parameters ---------- vec length-R |npfloat_| -- Vector to project vec_onto length-R |npfloat_| -- Vector onto which `vec` is to be projected Returns ------- proj_vec length-R |npfloat_| -- Projection of `vec` onto `vec_onto`", "response": "def proj(vec, vec_onto):\n    \"\"\" Vector projection.\n\n    Calculated as:\n\n    .. math::\n\n         \\\\mathsf{vec\\\\_onto} * \\\\frac{\\\\mathsf{vec}\\\\cdot\\\\mathsf{vec\\\\_onto}}\n         {\\\\mathsf{vec\\\\_onto}\\\\cdot\\\\mathsf{vec\\\\_onto}}\n\n    Parameters\n    ----------\n    vec\n        length-R |npfloat_| --\n        Vector to project\n\n    vec_onto\n        length-R |npfloat_| --\n        Vector onto which `vec` is to be projected\n\n    Returns\n    -------\n    proj_vec\n        length-R |npfloat_| --\n        Projection of `vec` onto `vec_onto`\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Ensure vectors\n    if not len(vec.shape) == 1:\n        raise ValueError(\"'vec' is not a vector\")\n    ## end if\n    if not len(vec_onto.shape) == 1:\n        raise ValueError(\"'vec_onto' is not a vector\")\n    ## end if\n    if not vec.shape[0] == vec_onto.shape[0]:\n        raise ValueError(\"Shape mismatch between vectors\")\n    ## end if\n\n    # Calculate the projection and return\n    proj_vec = np.float_(np.asscalar(np.dot(vec.T, vec_onto))) / \\\n                np.float_(np.asscalar(np.dot(vec_onto.T, vec_onto))) * vec_onto\n    return proj_vec"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rej(vec, vec_onto):\n\n    # Imports\n    import numpy as np\n\n    # Calculate and return.\n    rej_vec = vec - proj(vec, vec_onto)\n    return rej_vec", "response": "Vector rejection.\n\n    Calculated by subtracting from `vec` the projection of `vec` onto\n    `vec_onto`:\n\n    .. math::\n\n        \\\\mathsf{vec} - \\\\mathrm{proj}\\\\left(\\\\mathsf{vec},\n        \\\\ \\\\mathsf{vec\\\\_onto}\\\\right)\n\n    Parameters\n    ----------\n    vec\n        length-R |npfloat_| --\n        Vector to reject\n\n    vec_onto\n        length-R |npfloat_| --\n        Vector onto which `vec` is to be rejected\n\n    Returns\n    -------\n    rej_vec\n        length-R |npfloat_| --\n        Rejection of `vec` onto `vec_onto`"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vec_angle(vec1, vec2):\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM\n\n    # Check shape and equal length\n    if len(vec1.shape) != 1:\n        raise ValueError(\"'vec1' is not a vector\")\n    ## end if\n    if len(vec2.shape) != 1:\n        raise ValueError(\"'vec2' is not a vector\")\n    ## end if\n    if vec1.shape[0] != vec2.shape[0]:\n        raise ValueError(\"Vector lengths are not equal\")\n    ## end if\n\n    # Check magnitudes\n    if spla.norm(vec1) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"'vec1' norm is too small\")\n    ## end if\n    if spla.norm(vec2) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"'vec2' norm is too small\")\n    ## end if\n\n    # Calculate the angle and return. Do in multiple steps to test for\n    #  possible >1 or <-1 values from numerical precision errors.\n    dotp = np.dot(vec1, vec2) / spla.norm(vec1) / spla.norm(vec2)\n\n    if dotp > 1:\n        angle = 0. # pragma: no cover\n    elif dotp < -1:\n        angle = 180. # pragma: no cover\n    else:\n        angle = np.degrees(np.arccos(dotp))\n    ## end if\n\n    return angle", "response": "Returns the angle between two vectors in degrees."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new module with the given name.", "response": "def new_module(name):\n    \"\"\"\n    Do all of the gruntwork associated with creating a new module.\n\n    \"\"\"\n    parent = None\n    if '.' in name:\n        parent_name = name.rsplit('.', 1)[0]\n        parent = __import__(parent_name, fromlist=[''])\n\n    module = imp.new_module(name)\n    sys.modules[name] = module\n    if parent:\n        setattr(parent, name.rsplit('.', 1)[1], module)\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allele_counts_dataframe(variant_and_allele_reads_generator):\n    df_builder = DataFrameBuilder(\n        AlleleCount,\n        extra_column_fns={\n            \"gene\": lambda variant, _: \";\".join(variant.gene_names),\n        })\n    for variant, allele_reads in variant_and_allele_reads_generator:\n        counts = count_alleles_at_variant_locus(variant, allele_reads)\n        df_builder.add(variant, counts)\n    return df_builder.to_dataframe()", "response": "Creates a DataFrame containing the number of reads supporting the variant and all of the alleles at each variant."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_extension(conn, extension: str) -> bool:\n\n    query = 'SELECT installed_version FROM pg_available_extensions WHERE name=%s;'\n\n    with conn.cursor() as cursor:\n        cursor.execute(query, (extension,))\n        result = cursor.fetchone()\n\n    if result is None:\n        raise psycopg2.ProgrammingError(\n            'Extension is not available for installation.', extension\n        )\n    else:\n        extension_version = result[0]\n\n        return bool(extension_version)", "response": "Check to see if an extension is installed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count(self, i):\n        if self._stop > self._start and self._step > 0:\n            return int(self._start <= i < self._stop and\n                       (i - self._start) % self._step == 0)\n        elif self._stop < self._start and self._step < 0:\n            return int(self._start >= i > self._stop and\n                       (i - self._start) % self._step == 0)\n        else:\n            return False", "response": "count returns number of occurrences of value i in the range object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures obj is iterable.", "response": "def make_iterable(obj, default=None):\n    \"\"\" Ensure obj is iterable. \"\"\"\n    if obj is None:\n        return default or []\n    if isinstance(obj, (compat.string_types, compat.integer_types)):\n        return [obj]\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter_documents(self, fileids=None, categories=None, _destroy=False):\n        doc_ids = self._filter_ids(fileids, categories)\n        for doc in imap(self.get_document, doc_ids):\n            yield doc\n            if _destroy:\n                doc.destroy()", "response": "Return an iterator over corpus documents."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef catalog(self, categories=None):\n        ids = self._filter_ids(None, categories)\n        doc_meta = self._get_meta()\n        return [(doc_id, doc_meta[doc_id].title) for doc_id in ids]", "response": "Return information about documents in corpora"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_meta_cache(self):\n        try:\n            with open(self._cache_filename, 'wb') as f:\n                compat.pickle.dump(self._document_meta, f, 1)\n        except (IOError, compat.pickle.PickleError):\n            pass", "response": "Try to dump metadata to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_meta_cache(self):\n        try:\n            if self._should_invalidate_cache():\n                os.remove(self._cache_filename)\n            else:\n                with open(self._cache_filename, 'rb') as f:\n                    self._document_meta = compat.pickle.load(f)\n        except (OSError, IOError, compat.pickle.PickleError,\n                ImportError, AttributeError):\n            pass", "response": "Try to load metadata from file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing meta information that can be used for fast document lookups.", "response": "def _compute_document_meta(self):\n        \"\"\"\n        Return documents meta information that can\n        be used for fast document lookups. Meta information\n        consists of documents titles, categories and positions\n        in file.\n        \"\"\"\n        meta = OrderedDict()\n\n        bounds_iter = xml_utils.bounds(self.filename,\n                            start_re=r'<text id=\"(\\d+)\"[^>]*name=\"([^\"]*)\"',\n                            end_re=r'</text>')\n\n        for match, bounds in bounds_iter:\n            doc_id, title = str(match.group(1)), match.group(2)\n            title = xml_utils.unescape_attribute(title)\n\n            # cache categories\n            xml_data = xml_utils.load_chunk(self.filename, bounds)\n            doc = Document(compat.ElementTree.XML(xml_data.encode('utf8')))\n\n            meta[doc_id] = _DocumentMeta(title, bounds, doc.categories())\n        return meta"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _document_xml(self, doc_id):\n        doc_str = self._get_doc_by_raw_offset(str(doc_id))\n        return compat.ElementTree.XML(doc_str.encode('utf8'))", "response": "Return the xml Element for the document document_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a document from xml using bytes offset information.", "response": "def _get_doc_by_raw_offset(self, doc_id):\n        \"\"\"\n        Load document from xml using bytes offset information.\n        XXX: this is not tested under Windows.\n        \"\"\"\n        bounds = self._get_meta()[str(doc_id)].bounds\n        return xml_utils.load_chunk(self.filename, bounds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a document from xml using line offset information.", "response": "def _get_doc_by_line_offset(self, doc_id):\n        \"\"\"\n        Load document from xml using line offset information.\n        This is much slower than _get_doc_by_raw_offset but should\n        work everywhere.\n        \"\"\"\n        bounds = self._get_meta()[str(doc_id)].bounds\n        return xml_utils.load_chunk(self.filename, bounds, slow=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn Ma where M is a 3x3 transformation matrix for each pixel", "response": "def _threeDdot_simple(M,a):\n    \"Return Ma, where M is a 3x3 transformation matrix, for each pixel\"\n\n    result = np.empty(a.shape,dtype=a.dtype)\n\n    for i in range(a.shape[0]):\n        for j in range(a.shape[1]):\n            A = np.array([a[i,j,0],a[i,j,1],a[i,j,2]]).reshape((3,1))\n            L = np.dot(M,A)\n            result[i,j,0] = L[0]\n            result[i,j,1] = L[1]\n            result[i,j,2] = L[2]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _swaplch(LCH):\n    \"Reverse the order of an LCH numpy dstack or tuple for analysis.\"\n    try: # Numpy array\n        L,C,H = np.dsplit(LCH,3)\n        return np.dstack((H,C,L))\n    except: # Tuple\n        L,C,H = LCH\n        return H,C,L", "response": "Reverse the order of an LCH numpy dstack or tuple for analysis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert image or color from from_ colorpace to what.", "response": "def convert(self, from_, to, what):\n        \"\"\"\n        Convert image or color \"what\" from \"from_\" colorpace to \"to\"\n        colorspace.  E.g.: ``convert(\"rgb\", \"hsv\", X)``, where X is a\n        numpy dstack or a color tuple.\n        \"\"\"\n\n        if(from_.lower()==to.lower()):\n            return what\n\n        # Check if there exist an optimized function that performs\n        # from_to_to conversion\n        direct_conversion = '%s_to_%s'%(from_.lower(),to.lower())\n        if( hasattr(self, direct_conversion ) ):\n            fn = getattr(self, direct_conversion)\n            return fn(what)\n\n        from_to_xyz = getattr(self, '%s_to_xyz'%(from_.lower()) )\n        xyz_to_to = getattr(self, 'xyz_to_%s'%(to.lower()) )\n\n        return xyz_to_to( from_to_xyz(what) )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms images i provided into the specified working color space.", "response": "def image2working(self,i):\n        \"\"\"Transform images i provided into the specified working\n        color space.\"\"\"\n        return self.colorspace.convert(self.image_space,\n                                       self.working_space, i)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms working space inputs to the analysis color space.", "response": "def working2analysis(self,r):\n        \"Transform working space inputs to the analysis color space.\"\n        a = self.colorspace.convert(self.working_space, self.analysis_space, r)\n        return self.swap_polar_HSVorder[self.analysis_space](a)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting back from the analysis color space to the working space.", "response": "def analysis2working(self,a):\n        \"Convert back from the analysis color space to the working space.\"\n        a = self.swap_polar_HSVorder[self.analysis_space](a)\n        return self.colorspace.convert(self.analysis_space, self.working_space, a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef analysis2display(self,a):\n        a = self.swap_polar_HSVorder[self.analysis_space](a)\n        return self.colorspace.convert(self.analysis_space.lower(), 'gammargb', a)", "response": "Utility conversion function that transforms data from the analysis color space to the display color space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bounds(filename, start_re, end_re, encoding='utf8'):\n    start_re, end_re = re.compile(start_re), re.compile(end_re)\n    mo, line_start, line_end, byte_start, byte_end = [None]*5\n    offset = 0\n\n    with open(filename, 'rb') as f:\n        for index, line in enumerate(f):\n            line_text = line.decode(encoding)\n            start_match = re.match(start_re, line_text)\n            if start_match:\n                mo, line_start, byte_start = start_match, index, offset\n\n            offset += len(line)\n\n            end_match = re.match(end_re, line_text)\n            if end_match:\n                yield mo, Bounds(line_start, index, byte_start, offset)\n                mo, line_start, line_end, byte_start, byte_end = [None]*5", "response": "Compute chunk bounds from text file according to start_re and end_re."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_chunk(filename, bounds, encoding='utf8', slow=False):\n    if slow:\n        return _load_chunk_slow(filename, bounds, encoding)\n\n    with open(filename, 'rb') as f:\n        f.seek(bounds.byte_start)\n        size = bounds.byte_end - bounds.byte_start\n        return f.read(size).decode(encoding)", "response": "Load a chunk from file using Bounds info."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_reference_context_args(parser):\n    reference_context_group = parser.add_argument_group(\"Reference Transcripts\")\n    parser.add_argument(\n        \"--context-size\",\n        default=CDNA_CONTEXT_SIZE,\n        type=int)\n    return reference_context_group", "response": "Adds the necessary arguments to the given ArgumentParser instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate postgresql numeric range and label for insertion.", "response": "def generate_numeric_range(items, lower_bound, upper_bound):\n    \"\"\"Generate postgresql numeric range and label for insertion.\n\n    Parameters\n    ----------\n    items: iterable labels for ranges.\n    lower_bound: numeric lower bound\n    upper_bound: numeric upper bound\n    \"\"\"\n\n    quantile_grid = create_quantiles(items, lower_bound, upper_bound)\n    labels, bounds = (zip(*quantile_grid))\n    ranges = ((label, NumericRange(*bound))\n              for label, bound in zip(labels, bounds))\n    return ranges"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the mean value around the edge of an array.", "response": "def edge_average(a):\n    \"Return the mean value around the edge of an array.\"\n\n    if len(np.ravel(a)) < 2:\n        return float(a[0])\n    else:\n        top_edge = a[0]\n        bottom_edge = a[-1]\n        left_edge = a[1:-1,0]\n        right_edge = a[1:-1,-1]\n\n        edge_sum = np.sum(top_edge) + np.sum(bottom_edge) + np.sum(left_edge) + np.sum(right_edge)\n        num_values = len(top_edge)+len(bottom_edge)+len(left_edge)+len(right_edge)\n\n        return float(edge_sum)/num_values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreduce version of the function call.", "response": "def _reduced_call(self, **params_to_override):\n        \"\"\"\n        Simplified version of PatternGenerator's __call__ method.\n        \"\"\"\n        p=param.ParamOverrides(self,params_to_override)\n\n        fn_result = self.function(p)\n        self._apply_mask(p,fn_result)\n        result = p.scale*fn_result+p.offset\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_channels(self,p,**params_to_override):\n        orig_image = self._image\n\n        for i in range(len(self._channel_data)):\n            self._image = self._original_channel_data[i]\n            self._channel_data[i] = self._reduced_call(**params_to_override)\n        self._image = orig_image\n        return self._channel_data", "response": "Process the channel data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_pil_image(self, filename):\n        self._channel_data = []\n        self._original_channel_data = []\n\n        im = Image.open(filename)\n        self._image = ImageOps.grayscale(im)\n        im.load()\n\n        file_data = np.asarray(im, float)\n        file_data = file_data / file_data.max()\n\n        # if the image has more than one channel, load them\n        if( len(file_data.shape) == 3 ):\n            num_channels = file_data.shape[2]\n            for i in range(num_channels):\n                self._channel_data.append( file_data[:, :, i])\n                self._original_channel_data.append( file_data[:, :, i] )", "response": "Load image using PIL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading image using Numpy.", "response": "def _load_npy(self, filename):\n        \"\"\"\n        Load image using Numpy.\n        \"\"\"\n        self._channel_data = []\n        self._original_channel_data = []\n        file_channel_data = np.load(filename)\n        file_channel_data = file_channel_data / file_channel_data.max()\n\n        for i in range(file_channel_data.shape[2]):\n            self._channel_data.append(file_channel_data[:, :, i])\n            self._original_channel_data.append(file_channel_data[:, :, i])\n\n        self._image = file_channel_data.sum(2) / file_channel_data.shape[2]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_protein_sequence_args(parser):\n    protein_sequence_group = parser.add_argument_group(\n        \"Protein sequences (grouping equivalent translations)\")\n    protein_sequence_group.add_argument(\n        \"--max-protein-sequences-per-variant\",\n        type=int,\n        default=MAX_PROTEIN_SEQUENCES_PER_VARIANT)\n    return protein_sequence_group", "response": "Adds all the required arguments to the given ArgumentParser instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning bulk record indexing.", "response": "def run(delayed, concurrency, version_type=None, queue=None,\n        raise_on_error=True):\n    \"\"\"Run bulk record indexing.\"\"\"\n    if delayed:\n        celery_kwargs = {\n            'kwargs': {\n                'version_type': version_type,\n                'es_bulk_kwargs': {'raise_on_error': raise_on_error},\n            }\n        }\n        click.secho(\n            'Starting {0} tasks for indexing records...'.format(concurrency),\n            fg='green')\n        if queue is not None:\n            celery_kwargs.update({'queue': queue})\n        for c in range(0, concurrency):\n            process_bulk_queue.apply_async(**celery_kwargs)\n    else:\n        click.secho('Indexing records...', fg='green')\n        RecordIndexer(version_type=version_type).process_bulk_queue(\n            es_bulk_kwargs={'raise_on_error': raise_on_error})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reindex(pid_type):\n    click.secho('Sending records to indexing queue ...', fg='green')\n\n    query = (x[0] for x in PersistentIdentifier.query.filter_by(\n        object_type='rec', status=PIDStatus.REGISTERED\n    ).filter(\n        PersistentIdentifier.pid_type.in_(pid_type)\n    ).values(\n        PersistentIdentifier.object_uuid\n    ))\n    RecordIndexer().bulk_index(query)\n    click.secho('Execute \"run\" command to process the queue!',\n                fg='yellow')", "response": "Reindex all records.\n\n    :param pid_type: Pid type."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a variant is on the reference sequence", "response": "def variant_matches_reference_sequence(variant, ref_seq_on_transcript, strand):\n    \"\"\"\n    Make sure that reference nucleotides we expect to see on the reference\n    transcript from a variant are the same ones we encounter.\n    \"\"\"\n    if strand == \"-\":\n        ref_seq_on_transcript = reverse_complement_dna(ref_seq_on_transcript)\n    return ref_seq_on_transcript == variant.ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a SequenceKey object for the given variant and transcript.", "response": "def from_variant_and_transcript(\n            cls, variant, transcript, context_size):\n        \"\"\"\n        Extracts the reference sequence around a variant locus on a particular\n        transcript.\n\n        Parameters\n        ----------\n        variant : varcode.Variant\n\n        transcript : pyensembl.Transcript\n\n        context_size : int\n\n        Returns SequenceKey object.\n\n        Can also return None if Transcript lacks sufficiently long sequence\n        \"\"\"\n\n        full_transcript_sequence = transcript.sequence\n\n        if full_transcript_sequence is None:\n            logger.warn(\n                \"Expected transcript %s (overlapping %s) to have sequence\",\n                transcript.name,\n                variant)\n            return None\n\n        # get the interbase range of offsets which capture all reference\n        # bases modified by the variant\n        variant_start_offset, variant_end_offset = \\\n            interbase_range_affected_by_variant_on_transcript(\n                variant=variant,\n                transcript=transcript)\n\n        reference_cdna_at_variant = full_transcript_sequence[\n            variant_start_offset:variant_end_offset]\n\n        if not variant_matches_reference_sequence(\n                variant=variant,\n                strand=transcript.strand,\n                ref_seq_on_transcript=reference_cdna_at_variant):\n            logger.warn(\n                \"Variant %s doesn't match reference sequence on transcript %s: \"\n                \"may span splice junction\",\n                variant,\n                transcript)\n            return None\n\n        if len(full_transcript_sequence) < 6:\n            # need at least 6 nucleotides for a start and stop codon\n            logger.warn(\n                \"Sequence of %s (overlapping %s) too short: %d\",\n                transcript,\n                variant,\n                len(full_transcript_sequence))\n            return None\n\n        logger.info(\n            \"Interbase offset range on %s for variant %s = %d:%d\",\n            transcript.name,\n            variant,\n            variant_start_offset,\n            variant_end_offset)\n\n        reference_cdna_before_variant = full_transcript_sequence[\n            max(0, variant_start_offset - context_size):\n            variant_start_offset]\n\n        reference_cdna_after_variant = full_transcript_sequence[\n            variant_end_offset:\n            variant_end_offset + context_size]\n\n        return ReferenceSequenceKey(\n            strand=transcript.strand,\n            sequence_before_variant_locus=reference_cdna_before_variant,\n            sequence_at_variant_locus=reference_cdna_at_variant,\n            sequence_after_variant_locus=reference_cdna_after_variant)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ellipsize(s, max_length=60):\n    if len(s) > max_length:\n        ellipsis = '...'\n        return s[:(max_length - len(ellipsis))] + ellipsis\n    else:\n        return s", "response": "ellipsize a string into a single word list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap(lower, upper, x):\n    #I have no idea how I came up with this algorithm; it should be simplified.\n    #\n    # Note that Python's % operator works on floats and arrays;\n    # usually one can simply use that instead.  E.g. to wrap array or\n    # scalar x into 0,2*pi, just use \"x % (2*pi)\".\n    range_=upper-lower\n    return lower + np.fmod(x-lower + 2*range_*(1-np.floor(x/(2*range_))), range_)", "response": "Wrap x into the range [ lower upper )."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sine grating pattern ( two - dimensional sine wave.", "response": "def function(self,p):\n        \"\"\"Return a sine grating pattern (two-dimensional sine wave).\"\"\"\n        return 0.5 + 0.5*np.sin(p.frequency*2*pi*self.pattern_y + p.phase)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the line width necessary to cover at least one pixel on all axes.", "response": "def _pixelsize(self, p):\n        \"\"\"Calculate line width necessary to cover at least one pixel on all axes.\"\"\"\n        xpixelsize = 1./float(p.xdensity)\n        ypixelsize = 1./float(p.ydensity)\n        return max([xpixelsize,ypixelsize])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _count_pixels_on_line(self, y, p):\n        h = line(y, self._effective_thickness(p), 0.0)\n        return h.sum()", "response": "Count the number of pixels rendered on this line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the minimal y value for a no - cache entry.", "response": "def _minimal_y(self, p):\n        \"\"\"\n        For the specified y and one offset by half a pixel, return the\n        one that results in the fewest pixels turned on, so that when\n        the thickness has been enforced to be at least one pixel, no\n        extra pixels are needlessly included (which would cause\n        double-width lines).\n        \"\"\"\n        y0 = self.pattern_y\n        y1 = y0 + self._pixelsize(p)/2.\n        return y0 if self._count_pixels_on_line(y0, p) < self._count_pixels_on_line(y1, p) else y1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a square - wave grating of the given assessment.", "response": "def function(self,p):\n        \"\"\"\n        Return a square-wave grating (alternating black and white bars).\n        \"\"\"\n        return np.around(\n            0.5 +\n            0.5*np.sin(pi*(p.duty_cycle-0.5)) +\n            0.5*np.sin(p.frequency*2*pi*self.pattern_y + p.phase))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef function(self,p):\n        int_index=int(len(p.generators)*wrap(0,1.0,p.index))\n        pg=p.generators[int_index]\n\n        image_array = pg(xdensity=p.xdensity,ydensity=p.ydensity,bounds=p.bounds,\n                         x=p.x+p.size*(pg.x*np.cos(p.orientation)-pg.y*np.sin(p.orientation)),\n                         y=p.y+p.size*(pg.x*np.sin(p.orientation)+pg.y*np.cos(p.orientation)),\n                         orientation=pg.orientation+p.orientation,size=pg.size*p.size,\n                         scale=pg.scale*p.scale,offset=pg.offset+p.offset)\n\n        return image_array", "response": "Selects and returns one of the patterns in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the current generator.", "response": "def get_current_generator(self):\n        \"\"\"Return the current generator (as specified by self.index).\"\"\"\n        int_index=int(len(self.generators)*wrap(0,1.0,self.inspect_value('index')))\n        return self.generators[int_index]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef channels(self, use_cached=False, **params_to_override):\n        default = self(**params_to_override)\n        current_generator = self.get_current_generator()\n\n        res = current_generator.channels(use_cached=True)\n        res['default'] = default\n\n        return res", "response": "Get the channel data from the current generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef num_channels(self):\n        if(self.inspect_value('index') is None):\n            if(len(self.generators)>0):\n                return self.generators[0].num_channels()\n            return 0\n\n        return self.get_current_generator().num_channels()", "response": "Get the number of channels in the input generators."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nproducing pattern coordinate matrices from the bounds and density (or rows and cols), and transforms them according to x, y, and orientation.", "response": "def _setup_xy(self, p):\n        \"\"\"\n        Produce pattern coordinate matrices from the bounds and\n        density (or rows and cols), and transforms them according to\n        x, y, and orientation.\n        \"\"\"\n        self.debug(\"bounds=%s, xdensity=%s, ydensity=%s, x=%s, y=%s, orientation=%s\",p.bounds, p.xdensity, p.ydensity, p.x, p.y, p.orientation)\n\n        x_points,y_points = SheetCoordinateSystem(p.bounds, p.xdensity, p.ydensity).sheetcoordinates_of_matrixidx()\n\n        self.pattern_x, self.pattern_y = self._create_and_rotate_coordinate_arrays(x_points-p.x, y_points-p.y, p)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_and_rotate_coordinate_arrays(self, x, y, p):\n\n        if p.aspect_ratio == 0 or p.size == 0:\n            x = x * 0.0\n            y = y * 0.0\n        else:\n            x = (x*10.0) / (p.size*p.aspect_ratio)\n            y = (y*10.0) / p.size\n\n        offset = np.exp(p.size)\n        pattern_x = np.add.outer(np.sin(p.orientation)*y, np.cos(p.orientation)*x) + offset\n        pattern_y = np.subtract.outer(np.cos(p.orientation)*y, np.sin(p.orientation)*x) + offset\n\n        np.clip(pattern_x, 0, np.Infinity, out=pattern_x)\n        np.clip(pattern_y, 0, np.Infinity, out=pattern_y)\n\n        return pattern_x, pattern_y", "response": "Create and rotate the matrix from x and y vectors and create the pattern matrices from x and y vectors and rotate them to the specified orientation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract a specific interval from the time series.", "response": "def extract_specific_interval(self, interval_start, interval_end):\n        \"\"\"\n        Overload if special behaviour is required when a series ends.\n        \"\"\"\n\n        interval_start = int(interval_start)\n        interval_end = int(interval_end)\n\n        if interval_start >= interval_end:\n            raise ValueError(\"Requested interval's start point is past the requested end point.\")\n\n        elif interval_start > self.time_series.size:\n            if self.repeat:\n                interval_end = interval_end - interval_start\n                interval_start = 0\n            else:\n                raise ValueError(\"Requested interval's start point is past the end of the time series.\")\n\n        if interval_end < self.time_series.size:\n            interval = self.time_series[interval_start:interval_end]\n\n        else:\n            requested_interval_size = interval_end - interval_start\n            remaining_signal = self.time_series[interval_start:self.time_series.size]\n\n            if self.repeat:\n                if requested_interval_size < self.time_series.size:\n                    self._next_interval_start = requested_interval_size-remaining_signal.size\n                    interval = np.hstack((remaining_signal, self.time_series[0:self._next_interval_start]))\n\n                else:\n                    repeated_signal = np.repeat(self.time_series, np.floor(requested_interval_size/self.time_series.size))\n                    self._next_interval_start = requested_interval_size % self.time_series.size\n\n                    interval = (np.hstack((remaining_signal, repeated_signal)))[0:requested_interval_size]\n\n            else:\n                self.warning(\"Returning last interval of the time series.\")\n                self._next_interval_start = self.time_series.size + 1\n\n                samples_per_interval = self.interval_length*self.sample_rate\n                interval = np.hstack((remaining_signal, np.zeros(samples_per_interval-remaining_signal.size)))\n\n        return interval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the frequency spacing for the available entry classes.", "response": "def _set_frequency_spacing(self, min_freq, max_freq):\n        \"\"\"\n        Frequency spacing to use, i.e. how to map the available\n        frequency range to the discrete sheet rows.\n\n        NOTE: We're calculating the spacing of a range between the\n        highest and lowest frequencies, the actual segmentation and\n        averaging of the frequencies to fit this spacing occurs in\n        _getAmplitudes().\n\n        This method is here solely to provide a minimal overload if\n        custom spacing is required.\n        \"\"\"\n\n        self.frequency_spacing = np.linspace(min_freq, max_freq, num=self._sheet_dimensions[0]+1, endpoint=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the amplitudes of the current record in the worksheet.", "response": "def _get_row_amplitudes(self):\n        \"\"\"\n        Perform a real Discrete Fourier Transform (DFT; implemented\n        using a Fast Fourier Transform algorithm, FFT) of the current\n        sample from the signal multiplied by the smoothing window.\n\n        See numpy.rfft for information about the Fourier transform.\n        \"\"\"\n\n        signal_interval = self.signal()\n        sample_rate = self.signal.sample_rate\n\n        # A signal window *must* span one sample rate\n        signal_window = np.tile(signal_interval, int(np.ceil(1.0/self.signal.interval_length)))\n\n        if self.windowing_function:\n            smoothed_window = signal_window[0:sample_rate] * self.windowing_function(sample_rate)\n        else:\n            smoothed_window = signal_window[0:sample_rate]\n\n        amplitudes = (np.abs(np.fft.rfft(smoothed_window))[0:sample_rate/2] + self.offset) * self.scale\n\n        for index in range(0, self._sheet_dimensions[0]-2):\n            start_frequency = self.frequency_spacing[index]\n            end_frequency = self.frequency_spacing[index+1]\n\n            normalisation_factor =  end_frequency - start_frequency\n            if normalisation_factor == 0:\n                amplitudes[index] = amplitudes[start_frequency]\n            else:\n                amplitudes[index] = np.sum(amplitudes[int(start_frequency):int(end_frequency)]) / normalisation_factor\n\n        return np.flipud(amplitudes[0:self._sheet_dimensions[0]].reshape(-1,1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_graph(grid):\n    try:\n        import numpy as np\n    except ImportError:\n        print(\n            \"NumPY is not installed. segraph needs NumPY to function. Please use 'pip install numpy' to install numpy.\")\n        exit(0)\n    print(\"Creating a graph using segmented grid..\")\n    # get an array of unique labels\n    try:\n        vertices = np.unique(grid)\n\n        # get number of vertices\n        num_vertices = len(vertices)\n\n        # map these unique labels to [1,...,N], where N is the number of labels (vertices)\n        mapping = dict(zip(vertices, np.arange(num_vertices)))\n        mapped_grid = np.array([mapping[x] for x in grid.flat]).reshape(grid.shape)\n\n        # create edges, going left to right and top to bottom\n        l2r = np.c_[mapped_grid[:, :-1].ravel(), mapped_grid[:, 1:].ravel()]\n        t2b = np.c_[mapped_grid[:-1, :].ravel(), mapped_grid[1:, :].ravel()]\n\n        # stack for entire graph\n        edges = np.vstack([l2r, t2b])\n        edges = edges[edges[:, 0] != edges[:, 1], :]\n        edges = np.sort(edges, axis=1)\n\n        # create a edge map, a hashmap\n        edge_map = edges[:, 0] + num_vertices * edges[:, 1]\n\n        # filter unique connections as edges\n        edges = np.unique(edge_map)\n\n        # reverse map and form edges as pairs\n        edges = [[vertices[edge % num_vertices],\n                  vertices[edge // num_vertices]] for edge in edges]\n    except:\n        print(\"Invalid argument supplied !\")\n        return None\n\n    return vertices, edges", "response": "This function creates a graph of vertices and edges from a segmented grid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_record_to_index(record):\n    index_names = current_search.mappings.keys()\n    schema = record.get('$schema', '')\n    if isinstance(schema, dict):\n        schema = schema.get('$ref', '')\n\n    index, doc_type = schema_to_index(schema, index_names=index_names)\n\n    if index and doc_type:\n        return index, doc_type\n    else:\n        return (current_app.config['INDEXER_DEFAULT_INDEX'],\n                current_app.config['INDEXER_DEFAULT_DOC_TYPE'])", "response": "Get index and doc_type given a record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the postgres encoding for the given Python encoding.", "response": "def get_postgres_encoding(python_encoding: str) -> str:\n    \"\"\"Python to postgres encoding map.\"\"\"\n\n    encoding = normalize_encoding(python_encoding.lower())\n    encoding_ = aliases.aliases[encoding.replace('_', '', 1)].upper()\n    pg_encoding = PG_ENCODING_MAP[encoding_.replace('_', '')]\n\n    return pg_encoding"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries loading each binding in turn and return the base object.", "response": "def _init():\n    \"\"\"Try loading each binding in turn\n\n    Please note: the entire Qt module is replaced with this code:\n        sys.modules[\"Qt\"] = binding()\n\n    This means no functions or variables can be called after\n    this has executed.\n\n    \"\"\"\n\n    preferred = os.getenv(\"QT_PREFERRED_BINDING\")\n    verbose = os.getenv(\"QT_VERBOSE\") is not None\n\n    if preferred:\n\n        # Debug mode, used in installer\n        if preferred == \"None\":\n            sys.modules[__name__].__wrapper_version__ = __version__\n            return\n\n        available = {\n            \"PySide2\": _pyside2,\n            \"PySide\": _pyside,\n            \"PyQt5\": _pyqt5,\n            \"PyQt4\": _pyqt4\n        }\n\n        if preferred not in available:\n            raise ImportError(\"Preferred Qt binding \\\"%s\\\" \"\n                              \"not available\" % preferred)\n\n        binding = available[preferred]\n        sys.modules[__name__] = binding()\n        return\n\n    else:\n        for binding in (_pyside2,\n                        _pyqt5,\n                        _pyside,\n                        _pyqt4):\n\n            if verbose:\n                sys.stdout.write(\"Trying %s\" % binding.__name__[1:])\n\n            try:\n                sys.modules[__name__] = binding()\n                return\n\n            except ImportError as e:\n\n                if verbose:\n                    sys.stdout.write(\" - ImportError(\\\"%s\\\")\\n\" % e)\n\n                continue\n\n    # If not binding were found, throw this error\n    raise ImportError(\"No Qt binding were found.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef en_last(self):\n\n        # Initialize the return dict\n        last_ens = dict()\n\n        # Iterate and store\n        for (k,l) in self.en.items():\n            last_ens.update({ k : l[-1] if l != [] else None })\n        ##next (k,l)\n\n        # Should be ready to return?\n        return last_ens", "response": "Report the energies from the last SCF present in the output."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a database connection.", "response": "def connect(host=None, database=None, user=None, password=None, **kwargs):\n    \"\"\"Create a database connection.\"\"\"\n\n    host = host or os.environ['PGHOST']\n    database = database or os.environ['PGDATABASE']\n    user = user or os.environ['PGUSER']\n    password = password or os.environ['PGPASSWORD']\n\n    return psycopg2.connect(host=host,\n                            database=database,\n                            user=user,\n                            password=password,\n                            **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes |orca| on a dynamically constructed input file.", "response": "def execute_orca(inp_tp, work_dir, exec_cmd, subs=None, subs_delims=(\"<\",\">\"),\n            sim_name=\"orcarun\",\n            inp_ext=_DEF.FILE_EXTS[_E_SW.ORCA][_E_FT.INPUTFILE],\n            out_ext=_DEF.FILE_EXTS[_E_SW.ORCA][_E_FT.OUTPUT],\n            wait_to_complete=True,\n            bohrs=False):\n    \"\"\"Executes |orca| on a dynamically constructed input file.\n\n    .. warning:: Function is still under active development! Execution with\n        `wait_to_complete` == |True| should be robust, however.\n\n    **Execution**\n\n    Generates an |orca| input file dynamically from information passed into the\n    various arguments, performs the run, and returns with exit info and\n    computation results *(in some fashion; still under development)*.\n    Any required resources (.gbw,\n    .xyz, etc.) MUST already be present in `work_dir`. No check for pre-existing\n    files of the same base name is made; any such will be overwritten.\n\n    |orca| MUST be called using a wrapper script; this function does not\n    implement the redirection necessary to send output from a direct |orca| call\n    to a file on disk.\n\n    If `wait_to_complete` is |True|, the :func:`subprocess.call` syntax will\n    be used and the function will not return until execution of the\n    wrapper script completes.\n    If |False|, *[indicate what will be returned if not waiting]*.\n\n    .. todo:: execute_orca: The different output modes, depending on waiting\n              or not.\n\n    The command to call |orca| must be specified in the parameter list syntax of\n    the `args` argument to the :class:`subprocess.Popen` constructor.\n    The implementation is flexible and general, to allow interface with local\n    scripts for, e.g., submission to a job queue in a shared-resource\n    environment.\n\n    Valid |orca| input syntax of the resulting text is NOT checked\n    before calling |orca|.\n\n    No mechanism is implemented to detect hangs of |orca|. Periodic manual\n    oversight is recommended.\n\n    **Template Substitution**\n\n    See :func:`utils.template_subst <opan.utils.base.template_subst>` for\n    implementation details of the tag substitution mechanism.\n\n    Here, in addition to performing any substitutions on the input file\n    template as indicated by `subs`,\n    the special tags **INP** and **OUT**, enclosed with the\n    `subs_delims` delimiters, will be replaced with ``sim_name + '.' + inp_ext``\n    and ``sim_name + '.' + out_ext``, respectively, in the input template and\n    in all elements of\n    `exec_cmd` before executing the call. In the special case of\n    `inp_ext` == |None|, the **INP** tag will be replaced with just\n    `sim_name` (no extension), and similarly for **OUT** if\n    `out_ext` == |None|. The tag **NAME** will be replaced just with\n    `sim_name` in all cases.\n\n    `inp_ext` and `out_ext` must be different, to avoid collisions.\n\n    **Return Values**\n\n    The information returned depends on the value of `wait_to_complete`:\n\n    If `wait_to_complete` == |True|:\n\n        A |tuple| of objects is returned, with elements of type ::\n\n            (OrcaOutput, OpanXYZ, OrcaEngrad, OrcaHess)\n\n        These objects contain the corresponding results from the computation,\n        if the latter exist, or |None| if they are missing.\n\n    If `wait_to_complete` == |False|:\n\n        **TBD**, but current intention is to return the PID of the spawned\n        subprocess.\n\n\n    **Signature**\n\n\n    Parameters\n    ----------\n    inp_tp\n        |str| --\n        Template text for the input file to be generated.\n\n    work_dir\n        |str| --\n        Path to base working directory. Must already exist and contain any\n        resource files (.gbw, .xyz, etc.) required for the calculation.\n\n    exec_cmd\n        |list| of |str| --\n        Sequence of strings defining the |orca| execution call in the syntax of\n        the :class:`~subprocess.Popen` constructor. This call must\n        be to a local script; stream redirection of the forked process\n        is not supported in this function.\n\n    subs\n        |dict| of |str|, optional --\n        Substitutions to be performed in the template (see *Template\n        Substitution*, above).\n\n    subs_delims\n        2-|tuple| of |str|, optional --\n        Tag delimiters passed directly to\n        :func:`~opan.utils.base.template_subst`.  Defaults to ``('<','>')``.\n\n    sim_name\n        |str|, optional --\n        Basename to use for the input/output/working files.\n        If omitted, \"orcarun\" will be used.\n\n    inp_ext\n        |str|, optional --\n        Extension to be used for the input file generated\n        (default is 'txt').\n\n    out_ext\n        |str|, optional --\n        Extension to be used for the output file generated\n        (default is 'out').\n\n    wait_to_complete\n        |bool|, optional --\n        Whether to wait within this function for |orca| execution to\n        complete (|True|), or to spawn/fork a child process and return\n        (|False|). Default is |True|. |False| **IS NOT YET IMPLEMENTED**.\n\n    bohrs\n        |bool|, optional --\n        Flag to indicate the units (Bohrs or Angstroms) of the\n        coordinates in .xyz and .trj files.\n\n\n    Returns\n    -------\n    [varies]\n        |tuple| of objects or |int| PID.\n        Varies depending on `wait_to_complete`; see *Return Values* above\n\n\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If `inp_ext` and `out_ext` are identical.\n\n    ~exceptions.KeyError\n        If special tag names **INP**, **OUT**, or **NAME** are defined in `subs`\n\n    ~exceptions.TypeError\n        If any elements in `subs` are not tuples\n\n    \"\"\"\n\n    # Imports\n    import os, subprocess as sp\n    from ..output import OrcaOutput\n    from ..xyz import OpanXYZ\n    from ..grad import OrcaEngrad\n    from ..hess import OrcaHess\n    from ..utils import template_subst\n\n    # Special key constants\n    INPKEY = \"INP\"\n    OUTKEY = \"OUT\"\n    NAMEKEY = \"NAME\"\n\n    # Store old dir; switch to new; default exception fine for\n    #  handling case of invalid dir.\n    olddir = os.getcwd()\n    os.chdir(work_dir)\n\n    # Check for inp_ext identical to out_ext\n    if inp_ext == out_ext:\n        raise ValueError(\"'inp_ext' and 'out_ext' cannot be identical.\")\n    ##end if\n\n    # Build the input and output file names and store the substitution keys\n    if inp_ext:\n        inp_fname = sim_name + '.' + inp_ext\n    else:\n        inp_fname = sim_name\n    ##end if\n    if out_ext:\n        out_fname = sim_name + '.' + out_ext\n    else:\n        out_fname = sim_name\n    ##end if\n\n    SPECIALSUBS = {INPKEY: inp_fname, OUTKEY: out_fname, NAMEKEY: sim_name}\n\n    # Complain if special tags used in subs\n    if not set(SPECIALSUBS.keys()).isdisjoint(subs):\n        raise KeyError(\"Redefinition of special tag(s) is forbidden: {0}\"\n                .format(list(set(SPECIALSUBS.keys()).intersection(subs))))\n    ## end if\n\n    # Perform the replacement into the exec_cmd of the input and output\n    #  filenames.\n    exec_cmd_subs = [\n                s.replace(subs_delims[0] + INPKEY + subs_delims[1], inp_fname)\n            for s in exec_cmd]\n    exec_cmd_subs = [\n                s.replace(subs_delims[0] + OUTKEY + subs_delims[1], out_fname)\n            for s in exec_cmd_subs]\n    exec_cmd_subs = [\n                s.replace(subs_delims[0] + NAMEKEY + subs_delims[1], sim_name)\n            for s in exec_cmd_subs]\n\n    # Perform the content substitutions into the template string\n    augsubs = subs.copy().update(SPECIALSUBS)\n    input_text = template_subst(inp_tp, augsubs, delims=subs_delims)\n\n    # Create and write the input file\n    with open(inp_fname, 'w') as input_file:\n        input_file.write(input_text)\n    ##end with\n\n    # Perform the ORCA call; collect return values as appropriate\n    #!TODO: execute_orca: Implement non-waiting return\n    if wait_to_complete:\n        # Run ORCA\n        sp.call(exec_cmd_subs, cwd=os.getcwd())\n\n        # Bind ORCA_XXXXX objects and return. Have to address possibility of\n        #  any or all of these not existing.\n        try:\n            o_out = OrcaOutput(out_fname,'file')\n        except IOError:\n            o_out = None\n        ## end try\n\n        try:\n            o_xyz = OpanXYZ(path=os.path.join(work_dir, sim_name + \".xyz\"), \\\n                                                                bohrs=bohrs)\n        except IOError:\n            o_xyz = None\n        ## end try\n\n        try:\n            o_trj = OpanXYZ(path=os.path.join(work_dir, sim_name + \".trj\"), \\\n                                                                bohrs=bohrs)\n        except IOError:\n            o_trj = None\n        ## end try\n\n        try:\n            o_engrad = OrcaEngrad(os.path.join(work_dir, sim_name + \".engrad\"))\n        except IOError:\n            o_engrad = None\n        ## end try\n\n        try:\n            o_hess = OrcaHess(os.path.join(work_dir, sim_name + \".hess\"))\n        except IOError:\n            o_hess = None\n        ## end try\n\n    else:\n        raise NotImplementedError(\"Background execution not yet implemented.\")\n    ## end if\n\n    # Return to prior working directory\n    os.chdir(olddir)\n\n    # Return something appropriate, either computation results or information\n    #  on the queued computation.\n    #TODO: execute_orca: Must refine this, esp for the different exec modes\n    return o_out, o_xyz, o_engrad, o_hess"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setup():\n    _SOCKET.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n    _SOCKET.bind(('', PORT))\n    udp = threading.Thread(target=_listen, daemon=True)\n    udp.start()", "response": "Set up module.\n\n    Open a UDP socket, and listen in a thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndiscovers devices on the local network.", "response": "def discover(timeout=DISCOVERY_TIMEOUT):\n    \"\"\" Discover devices on the local network.\n\n    :param timeout: Optional timeout in seconds.\n    :returns: Set of discovered host addresses.\n    \"\"\"\n    hosts = {}\n    payload = MAGIC + DISCOVERY\n    for _ in range(RETRIES):\n        _SOCKET.sendto(bytearray(payload), ('255.255.255.255', PORT))\n        start = time.time()\n        while time.time() < start + timeout:\n            for host, data in _BUFFER.copy().items():\n                if not _is_discovery_response(data):\n                    continue\n                if host not in hosts:\n                    _LOGGER.debug(\"Discovered device at %s\", host)\n                    entry = {}\n                    entry['mac'] = data[7:13]\n                    entry['imac'] = data[19:25]\n                    entry['next'] = 0\n                    entry['st'] = int(data[-1])\n                    entry['time'] = _device_time(data[37:41])\n                    entry['serverTime'] = int(time.time())\n                    hosts[host] = entry\n    return hosts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _discover_mac(self):\n        mac = None\n        mac_reversed = None\n        cmd = MAGIC + DISCOVERY\n        resp = self._udp_transact(cmd, self._discovery_resp,\n                                  broadcast=True,\n                                  timeout=DISCOVERY_TIMEOUT)\n        if resp:\n            (mac, mac_reversed) = resp\n        if mac is None:\n            raise S20Exception(\"Couldn't discover {}\".format(self.host))\n        return (mac, mac_reversed)", "response": "Discovers MAC address of device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _subscribe(self):\n        cmd = MAGIC + SUBSCRIBE + self._mac \\\n            + PADDING_1 + self._mac_reversed + PADDING_1\n        status = self._udp_transact(cmd, self._subscribe_resp)\n        if status is not None:\n            self.last_subscribed = time.time()\n            return status == ON\n        else:\n            raise S20Exception(\n                \"No status could be found for {}\".format(self.host))", "response": "Subscribe to the device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend control command to device.", "response": "def _control(self, state):\n        \"\"\" Control device state.\n\n        Possible states are ON or OFF.\n\n        :param state: Switch to this state.\n        \"\"\"\n\n        # Renew subscription if necessary\n        if not self._subscription_is_recent():\n            self._subscribe()\n\n        cmd = MAGIC + CONTROL + self._mac + PADDING_1 + PADDING_2 + state\n        _LOGGER.debug(\"Sending new state to %s: %s\", self.host, ord(state))\n        ack_state = self._udp_transact(cmd, self._control_resp, state)\n        if ack_state is None:\n            raise S20Exception(\n                \"Device didn't acknowledge control request: {}\".format(\n                    self.host))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a discovery response.", "response": "def _discovery_resp(self, data):\n        \"\"\" Handle a discovery response.\n\n        :param data: Payload.\n        :param addr: Address tuple.\n        :returns: MAC and reversed MAC.\n        \"\"\"\n        if _is_discovery_response(data):\n            _LOGGER.debug(\"Discovered MAC of %s: %s\", self.host,\n                          binascii.hexlify(data[7:13]).decode())\n            return (data[7:13], data[19:25])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _subscribe_resp(self, data):\n        if _is_subscribe_response(data):\n            status = bytes([data[23]])\n            _LOGGER.debug(\"Successfully subscribed to %s, state: %s\",\n                          self.host, ord(status))\n            return status", "response": "Handle a subscribe response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _control_resp(self, data, state):\n        if _is_control_response(data):\n            ack_state = bytes([data[22]])\n            if state == ack_state:\n                _LOGGER.debug(\"Received state ack from %s, state: %s\",\n                              self.host, ord(ack_state))\n                return ack_state", "response": "Handle a control response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a payload to the UDP socket and then call the handler function with the response.", "response": "def _udp_transact(self, payload, handler, *args,\n                      broadcast=False, timeout=TIMEOUT):\n        \"\"\" Complete a UDP transaction.\n\n        UDP is stateless and not guaranteed, so we have to\n        take some mitigation steps:\n        - Send payload multiple times.\n        - Wait for awhile to receive response.\n\n        :param payload: Payload to send.\n        :param handler: Response handler.\n        :param args: Arguments to pass to response handler.\n        :param broadcast: Send a broadcast instead.\n        :param timeout: Timeout in seconds.\n        \"\"\"\n        if self.host in _BUFFER:\n            del _BUFFER[self.host]\n        host = self.host\n        if broadcast:\n            host = '255.255.255.255'\n        retval = None\n        for _ in range(RETRIES):\n            _SOCKET.sendto(bytearray(payload), (host, PORT))\n            start = time.time()\n            while time.time() < start + timeout:\n                data = _BUFFER.get(self.host, None)\n                if data:\n                    retval = handler(data, *args)\n                # Return as soon as a response is received\n                if retval:\n                    return retval"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(source):\n    parser = get_xml_parser()\n    return etree.parse(source, parser=parser).getroot()", "response": "Load OpenCorpora corpus.\n\n    The ``source`` can be any of the following:\n\n    - a file name/path\n    - a file object\n    - a file-like object\n    - a URL using the HTTP or FTP protocol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_mutant_amino_acid_interval(\n        cdna_sequence,\n        cdna_first_codon_offset,\n        cdna_variant_start_offset,\n        cdna_variant_end_offset,\n        n_ref,\n        n_amino_acids):\n    \"\"\"\n    Parameters\n    ----------\n    cdna_sequence : skbio.DNA or str\n        cDNA sequence found in RNAseq data\n\n    cdna_first_codon_offset : int\n        Offset into cDNA sequence to first complete codon, lets us skip\n        past UTR region and incomplete codons.\n\n    cdna_variant_start_offset : int\n        Interbase start offset into cDNA sequence for selecting mutant\n        nucleotides.\n\n    cdna_variant_end_offset : int\n        Interbase end offset into cDNA sequence for selecting mutant\n        nucleotides.\n\n    n_ref : int\n        Number of reference nucleotides\n\n    n_amino_acids : int\n        Number of translated amino acids\n\n    Returns tuple with three fields:\n        1) Start offset for interval of mutant amino acids in translated sequence\n        2) End offset for interval of mutant amino acids in translated sequence\n        3) Boolean flag indicating whether the variant was a frameshift.\n    \"\"\"\n    cdna_alt_nucleotides = cdna_sequence[\n        cdna_variant_start_offset:cdna_variant_end_offset]\n\n    n_alt = len(cdna_alt_nucleotides)\n\n    # sequence of nucleotides before the variant starting from the first codon\n    cdna_coding_prefix = cdna_sequence[cdna_first_codon_offset:cdna_variant_start_offset]\n\n    # rounding down since a change in the middle of a codon should count\n    # toward the variant codons\n    n_coding_nucleotides_before_variant = len(cdna_coding_prefix)\n\n    n_complete_prefix_codons = n_coding_nucleotides_before_variant // 3\n\n    frame_of_variant_nucleotides = n_coding_nucleotides_before_variant % 3\n    frameshift = abs(n_ref - n_alt) % 3 != 0\n    indel = n_ref != n_alt\n\n    variant_aa_interval_start = n_complete_prefix_codons\n\n    if frameshift:\n        # if mutation is a frame shift then every amino acid from the\n        # first affected codon to the stop is considered mutant\n        #\n        # TODO: what if the first k amino acids are synonymous with the\n        # reference sequence?\n        variant_aa_interval_end = n_amino_acids\n    else:\n        n_alt_codons = int(math.ceil(n_alt / 3.0))\n        if indel:\n            # We need to adjust the number of affected codons by whether the\n            # variant is aligned with codon boundaries, since in-frame indels\n            # may still be split across multiple codons.\n            #\n            # Example of in-frame deletion of 3 nucleotides which leaves\n            # 0 variant codons in the sequence (interval = 1:1)\n            #   ref = CCC|AAA|GGG|TTT\n            #   alt = CCC|GGG|TTT\n            #\n            # Example of in-frame deletion of 3 nucleotides which leaves\n            # 1 variant codon in the sequence (interval = 1:2)\n            #   ref = CCC|AAA|GGG|TTT\n            #   alt = CCC|AGG|TTT\n            #\n            # Example of in-frame insertion of 3 nucleotides which\n            # yields two variant codons:\n            #   ref = CCC|AAA|GGG|TTT\n            #   alt = CTT|TCC|AAA|GGG|TTT\n            extra_affected_codon = int(frame_of_variant_nucleotides != 0)\n            variant_aa_interval_end = (\n                variant_aa_interval_start + n_alt_codons + extra_affected_codon)\n        else:\n            # if the variant is a simple substitution then it only affects\n            # as many codons as are in the alternate sequence\n            variant_aa_interval_end = variant_aa_interval_start + n_alt_codons\n    return variant_aa_interval_start, variant_aa_interval_end, frameshift", "response": "This function finds the interval of the mutant amino acid in the sequence of nucleotides in the original sequence that is not part of the original sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a generator that takes a list of VariantSequence objects for a particular variant and all the ReferenceContext objects for that variant and all the ReferenceContext objects for that variant.", "response": "def translation_generator(\n        variant_sequences,\n        reference_contexts,\n        min_transcript_prefix_length,\n        max_transcript_mismatches,\n        include_mismatches_after_variant,\n        protein_sequence_length=None):\n    \"\"\"\n    Given all detected VariantSequence objects for a particular variant\n    and all the ReferenceContext objects for that locus, translate\n    multiple protein sequences, up to the number specified by the argument\n    max_protein_sequences_per_variant.\n\n    Parameters\n    ----------\n    variant_sequences : list of VariantSequence objects\n        Variant sequences overlapping a single original variant\n\n    reference_contexts : list of ReferenceContext objects\n        Reference sequence contexts from the same variant as the variant_sequences\n\n    min_transcript_prefix_length : int\n        Minimum number of nucleotides before the variant to test whether\n        our variant sequence can use the reading frame from a reference\n        transcript.\n\n    max_transcript_mismatches : int\n        Maximum number of mismatches between coding sequence before variant\n        and reference transcript we're considering for determing the reading\n        frame.\n\n    include_mismatches_after_variant : bool\n        If true, mismatches occurring after the variant locus will also count\n        toward max_transcript_mismatches filtering.\n\n    protein_sequence_length : int, optional\n        Truncate protein to be at most this long.\n\n    Yields a sequence of Translation objects.\n    \"\"\"\n    for reference_context in reference_contexts:\n        for variant_sequence in variant_sequences:\n            translation = Translation.from_variant_sequence_and_reference_context(\n                variant_sequence=variant_sequence,\n                reference_context=reference_context,\n                min_transcript_prefix_length=min_transcript_prefix_length,\n                max_transcript_mismatches=max_transcript_mismatches,\n                include_mismatches_after_variant=include_mismatches_after_variant,\n                protein_sequence_length=protein_sequence_length)\n            if translation is not None:\n                yield translation"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate_variant_reads(\n        variant,\n        variant_reads,\n        protein_sequence_length,\n        transcript_id_whitelist=None,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        min_transcript_prefix_length=MIN_TRANSCRIPT_PREFIX_LENGTH,\n        max_transcript_mismatches=MAX_REFERENCE_TRANSCRIPT_MISMATCHES,\n        include_mismatches_after_variant=INCLUDE_MISMATCHES_AFTER_VARIANT,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\n    Given a variant and its associated alt reads, construct variant sequences\n    and translate them into Translation objects.\n\n    Returns 0 or more Translation objects.\n\n    Parameters\n    ----------\n    variant : varcode.Variant\n\n    variant_reads : sequence or generator\n        AlleleRead objects supporting the variant\n\n    protein_sequence_length : int\n        Try to translate protein sequences of this length, though sometimes\n        we'll have to return something shorter (depending on the RNAseq data,\n        and presence of stop codons).\n\n    transcript_id_whitelist : set, optional\n        If given, expected to be a set of transcript IDs which we should use\n        for determining the reading frame around a variant. If omitted, then\n        try to use all overlapping reference transcripts.\n\n    min_alt_rna_reads : int\n        Drop variant sequences from loci with fewer than this number of\n        RNA reads supporting the alt allele.\n\n    min_variant_sequence_coverage : int\n        Trim variant sequences to nucleotides covered by at least this many\n        reads.\n\n    min_transcript_prefix_length : int\n        Minimum number of bases we need to try matching between the reference\n        context and variant sequence.\n\n    max_transcript_mismatches : int\n        Don't try to determine the reading frame for a transcript if more\n        than this number of bases differ.\n\n    include_mismatches_after_variant : bool\n        Include mismatches after the variant locus in the count compared\n        against max_transcript_mismatches.\n\n    variant_sequence_assembly : bool\n        Use overlap assembly to construct longer variant cDNA sequences.\n    \"\"\"\n    if len(variant_reads) == 0:\n        logger.info(\"No supporting reads for variant %s\", variant)\n        return []\n\n    # Adding an extra codon to the desired RNA sequence length in case we\n    # need to clip nucleotides at the start/end of the sequence\n    cdna_sequence_length = (protein_sequence_length + 1) * 3\n\n    variant_sequences = reads_to_variant_sequences(\n        variant=variant,\n        reads=variant_reads,\n        preferred_sequence_length=cdna_sequence_length,\n        min_alt_rna_reads=min_alt_rna_reads,\n        min_variant_sequence_coverage=min_variant_sequence_coverage,\n        variant_sequence_assembly=variant_sequence_assembly)\n\n    if not variant_sequences:\n        logger.info(\"No spanning cDNA sequences for variant %s\", variant)\n        return []\n\n    # try translating the variant sequences from the same set of\n    # ReferenceContext objects, which requires using the longest\n    # context_size to be compatible with all of the sequences. Some\n    # sequences maybe have fewer nucleotides than this before the variant\n    # and will thus have to be trimmed.\n    context_size = max(\n        len(variant_sequence.prefix)\n        for variant_sequence in variant_sequences)\n\n    reference_contexts = reference_contexts_for_variant(\n        variant,\n        context_size=context_size,\n        transcript_id_whitelist=transcript_id_whitelist)\n\n    return list(translation_generator(\n        variant_sequences=variant_sequences,\n        reference_contexts=reference_contexts,\n        min_transcript_prefix_length=min_transcript_prefix_length,\n        max_transcript_mismatches=max_transcript_mismatches,\n        include_mismatches_after_variant=include_mismatches_after_variant,\n        protein_sequence_length=protein_sequence_length))", "response": "Given a variant and its associated alt reads construct a Translation object for the variant sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_variants(\n        variants_with_supporting_reads,\n        transcript_id_whitelist=None,\n        protein_sequence_length=PROTEIN_SEQUENCE_LENGTH,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        min_transcript_prefix_length=MIN_TRANSCRIPT_PREFIX_LENGTH,\n        max_transcript_mismatches=MAX_REFERENCE_TRANSCRIPT_MISMATCHES,\n        include_mismatches_after_variant=INCLUDE_MISMATCHES_AFTER_VARIANT,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\n    Translates each coding variant in a collection to one or more protein\n    fragment sequences (if the variant is not filtered and its spanning RNA\n    sequences can be given a reading frame).\n\n    Parameters\n    ----------\n    variants_with_reads : sequence or generator\n        Each item of this sequence should be a pair containing a varcode.Variant\n        and a list of AlleleRead objects supporting that variant.\n\n    transcript_id_whitelist : set, optional\n        If given, expected to be a set of transcript IDs which we should use\n        for determining the reading frame around a variant. If omitted, then\n        try to use all overlapping reference transcripts.\n\n    protein_sequence_length : int\n        Try to translate protein sequences of this length, though sometimes\n        we'll have to return something shorter (depending on the RNAseq data,\n        and presence of stop codons).\n\n    min_alt_rna_reads : int\n        Drop variant sequences from loci with fewer than this number of\n        RNA reads supporting the alt allele.\n\n    min_variant_sequence_coverage : int\n        Trim variant sequences to nucleotides covered by at least this many\n        reads.\n\n    min_transcript_prefix_length : int\n        Minimum number of bases we need to try matching between the reference\n        context and variant sequence.\n\n    max_transcript_mismatches : int\n        Don't try to determine the reading frame for a transcript if more\n        than this number of bases differ.\n\n    include_mismatches_after_variant : bool\n        Include mismatches after the variant locus in the count compared\n        against max_transcript_mismatches.\n\n    variant_sequence_assembly : bool\n        Use overlap assembly to construct longer variant cDNA sequences.\n\n    Yields pairs of a Variant and a sequence of all its candidate\n    Translation objects.\n    \"\"\"\n    for variant, variant_reads in variants_with_supporting_reads:\n        translations = translate_variant_reads(\n            variant=variant,\n            variant_reads=variant_reads,\n            protein_sequence_length=protein_sequence_length,\n            transcript_id_whitelist=transcript_id_whitelist,\n            min_alt_rna_reads=min_alt_rna_reads,\n            min_variant_sequence_coverage=min_variant_sequence_coverage,\n            min_transcript_prefix_length=min_transcript_prefix_length,\n            max_transcript_mismatches=max_transcript_mismatches,\n            include_mismatches_after_variant=include_mismatches_after_variant,\n            variant_sequence_assembly=variant_sequence_assembly)\n        yield variant, translations", "response": "Translate a collection of variants into a single sequence of single - length RNA sequences."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef translations_generator_to_dataframe(translations_generator):\n    return dataframe_from_generator(\n        element_class=Translation,\n        variant_and_elements_generator=translations_generator,\n        exclude=[],\n        converters={\n            \"untrimmed_variant_sequence\": lambda vs: vs.sequence,\n            \"variant_sequence_in_reading_frame\": (\n                lambda vs: vs.in_frame_cdna_sequence),\n            \"reference_context\": (\n                lambda rc: \";\".join([\n                    transcript.name for\n                    transcript in rc.transcripts]))\n        },\n        extra_column_fns={\n            \"untrimmed_variant_sequence_read_count\": (\n                lambda _, t: len(t.untrimmed_variant_sequence.reads)),\n        })", "response": "Given a generator of Variant objects returns a DataFrame of translated protein fragments with columns\n    for each field of a Translation object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a TranslationKey object which can be used as a translation key.", "response": "def as_translation_key(self):\n        \"\"\"\n        Project Translation object or any other derived class into just a\n        TranslationKey, which has fewer fields and can be used as a\n        dictionary key.\n        \"\"\"\n        return TranslationKey(**{\n            name: getattr(self, name)\n            for name in TranslationKey._fields})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_variant_sequence_and_reference_context(\n            cls,\n            variant_sequence,\n            reference_context,\n            min_transcript_prefix_length,\n            max_transcript_mismatches,\n            include_mismatches_after_variant,\n            protein_sequence_length=None):\n        \"\"\"\n        Attempt to translate a single VariantSequence using the reading frame\n        from a single ReferenceContext.\n\n        Parameters\n        ----------\n        variant_sequence : VariantSequence\n\n        reference_context : ReferenceContext\n\n        min_transcript_prefix_length : int\n            Minimum number of nucleotides before the variant to test whether\n            our variant sequence can use the reading frame from a reference\n            transcript.\n\n        max_transcript_mismatches : int\n            Don't use the reading frame from a context where the cDNA variant\n            sequences disagrees at more than this number of positions before the\n            variant nucleotides.\n\n        include_mismatches_after_variant : bool\n            If true, mismatches after the variant nucleotides will also count\n            against max_transcript_mismatches filtering.\n\n        protein_sequence_length : int, optional\n            Truncate protein to be at most this long\n\n        Returns either a ProteinSequence object or None if the number of\n        mismatches between the RNA and reference transcript sequences exceeds\n        given threshold.\n        \"\"\"\n        variant_sequence_in_reading_frame = match_variant_sequence_to_reference_context(\n            variant_sequence,\n            reference_context,\n            min_transcript_prefix_length=min_transcript_prefix_length,\n            max_transcript_mismatches=max_transcript_mismatches,\n            include_mismatches_after_variant=include_mismatches_after_variant)\n\n        if variant_sequence_in_reading_frame is None:\n            logger.info(\"Unable to determine reading frame for %s\", variant_sequence)\n            return None\n\n        cdna_sequence = variant_sequence_in_reading_frame.cdna_sequence\n        cdna_codon_offset = variant_sequence_in_reading_frame.offset_to_first_complete_codon\n\n        # get the offsets into the cDNA sequence which pick out the variant nucleotides\n        cdna_variant_start_offset = variant_sequence_in_reading_frame.variant_cdna_interval_start\n        cdna_variant_end_offset = variant_sequence_in_reading_frame.variant_cdna_interval_end\n\n        # TODO: determine if the first codon is the start codon of a\n        # transcript, for now any of the unusual start codons like CTG\n        # will translate to leucine instead of methionine.\n        variant_amino_acids, ends_with_stop_codon = translate_cdna(\n            cdna_sequence[cdna_codon_offset:],\n            first_codon_is_start=False,\n            mitochondrial=reference_context.mitochondrial)\n\n        variant_aa_interval_start, variant_aa_interval_end, frameshift = \\\n            find_mutant_amino_acid_interval(\n                cdna_sequence=cdna_sequence,\n                cdna_first_codon_offset=cdna_codon_offset,\n                cdna_variant_start_offset=cdna_variant_start_offset,\n                cdna_variant_end_offset=cdna_variant_end_offset,\n                n_ref=len(reference_context.sequence_at_variant_locus),\n                n_amino_acids=len(variant_amino_acids))\n\n        if protein_sequence_length and len(variant_amino_acids) > protein_sequence_length:\n            if protein_sequence_length <= variant_aa_interval_start:\n                logger.warn(\n                    (\"Truncating amino acid sequence %s \"\n                     \"to only %d elements loses all variant residues\"),\n                    variant_amino_acids,\n                    protein_sequence_length)\n                return None\n            # if the protein is too long then shorten it, which implies\n            # we're no longer stopping due to a stop codon and that the variant\n            # amino acids might need a new stop index\n            variant_amino_acids = variant_amino_acids[:protein_sequence_length]\n            variant_aa_interval_end = min(variant_aa_interval_end, protein_sequence_length)\n            ends_with_stop_codon = False\n\n        return Translation(\n            amino_acids=variant_amino_acids,\n            frameshift=frameshift,\n            ends_with_stop_codon=ends_with_stop_codon,\n            variant_aa_interval_start=variant_aa_interval_start,\n            variant_aa_interval_end=variant_aa_interval_end,\n            untrimmed_variant_sequence=variant_sequence,\n            reference_context=reference_context,\n            variant_sequence_in_reading_frame=variant_sequence_in_reading_frame)", "response": "Translate a single VariantSequence into a single ReferenceContext."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef postComponents(self, name, status, **kwargs):\n        '''Create a new component.\n\n        :param name: Name of the component\n        :param status: Status of the component; 1-4\n        :param description: (optional) Description of the component\n        :param link: (optional) A hyperlink to the component\n        :param order: (optional) Order of the component\n        :param group_id: (optional) The group id that the component is within\n        :param enabled: (optional)\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        '''\n\n        kwargs['name'] = name\n        kwargs['status'] = status\n        return self.__postRequest('/components', kwargs)", "response": "Create a new component."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef postIncidents(self, name, message, status, visible, **kwargs):\n        '''Create a new incident.\n\n        :param name: Name of the incident\n        :param message: A message (supporting Markdown) to explain more.\n        :param status: Status of the incident.\n        :param visible: Whether the incident is publicly visible.\n        :param component_id: (optional) Component to update.\n        :param component_status: (optional) The status to update the given component with.\n        :param notify: (optional) Whether to notify subscribers.\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        '''\n\n        kwargs['name'] = name\n        kwargs['message'] = message\n        kwargs['status'] = status\n        kwargs['visible'] = visible\n        return self.__postRequest('/incidents', kwargs)", "response": "Create a new incident."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef postMetrics(self, name, suffix, description, default_value, **kwargs):\n        '''Create a new metric.\n\n        :param name: Name of metric\n        :param suffix: Measurments in\n        :param description: Description of what the metric is measuring\n        :param default_value: The default value to use when a point is added\n        :param display_chart: (optional) Whether to display the chart on the status page\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        '''\n\n        kwargs['name'] = name\n        kwargs['suffix'] = suffix\n        kwargs['description'] = description\n        kwargs['default_value'] = default_value\n        return self.__postRequest('/metrics', kwargs)", "response": "Create a new metric."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a metric point to a given metric.", "response": "def postMetricsPointsByID(self, id, value, **kwargs):\n        '''Add a metric point to a given metric.\n\n        :param id: Metric ID\n        :param value: Value to plot on the metric graph\n        :param timestamp: Unix timestamp of the point was measured\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        '''\n\n        kwargs['value'] = value\n        return self.__postRequest('/metrics/%s/points' % id, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ctr_mass(geom, masses):\n\n    # Imports\n    import numpy as np\n    from .base import safe_cast as scast\n\n    # Shape check\n    if len(geom.shape) != 1:\n        raise ValueError(\"Geometry is not a vector\")\n    ## end if\n    if len(masses.shape) != 1:\n        raise ValueError(\"Masses cannot be parsed as a vector\")\n    ## end if\n    if not geom.shape[0] % 3 == 0:\n        raise ValueError(\"Geometry is not length-3N\")\n    ## end if\n    if geom.shape[0] != 3*masses.shape[0] and geom.shape[0] != masses.shape[0]:\n        raise ValueError(\"Inconsistent geometry and masses vector lengths\")\n    ## end if\n\n    # If N masses are provided, expand to 3N; if 3N, retain.\n    if geom.shape[0] == 3*masses.shape[0]:\n        masses = masses.repeat(3)\n    ## end if\n\n    # Calculate the mass-weighted coordinates, reshape to group by coordinate\n    #  column-wise, sum each column, then divide by the sum of masses, which\n    #  must further be divided by three because there are three replicates\n    #  (possibly perturbed) of the mass of each atom.\n    ctr = np.multiply(geom, masses).reshape((geom.shape[0]//3, 3)) \\\n                                .sum(axis=0).squeeze() / (masses.sum() / 3)\n\n    # Return the vector\n    return ctr", "response": "Calculate the center of mass of a geometry and atom masses."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a shifted geometry to the center of mass.", "response": "def ctr_geom(geom, masses):\n    \"\"\" Returns geometry shifted to center of mass.\n\n    Helper function to automate / encapsulate translation of a geometry to its\n    center of mass.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Original coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    Returns\n    -------\n    ctr_geom\n        length-3N |npfloat_| --\n        Atomic coordinates after shift to center of mass\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If shapes of `geom` & `masses` are inconsistent\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Calculate the shift vector. Possible bad shape of geom or masses is\n    #  addressed internally by the ctr_mass call.\n    shift = np.tile(ctr_mass(geom, masses), geom.shape[0] / 3)\n\n    # Shift the geometry and return\n    ctr_geom = geom - shift\n    return ctr_geom"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the 3x3 moment - of - inertia tensor for a single system.", "response": "def inertia_tensor(geom, masses):\n    \"\"\"Generate the 3x3 moment-of-inertia tensor.\n\n    Compute the 3x3 moment-of-inertia tensor for the\n    provided geometry and atomic masses.  Always recenters the\n    geometry to the center of mass as the first step.\n\n    Reference for inertia tensor: [Kro92]_, Eq. (2.26)\n\n    .. todo:: Replace cite eventually with link to exposition in user guide.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    Returns\n    -------\n    tensor\n        3 x 3 |npfloat_| --\n        Moment of inertia tensor for the system\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If shapes of `geom` & `masses` are inconsistent\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Center the geometry. Takes care of any improper shapes of geom or\n    #  masses via the internal call to 'ctr_mass' within the call to 'ctr_geom'\n    geom = ctr_geom(geom, masses)\n\n    # Expand the masses if required. Shape should only ever be (N,) or (3N,),\n    #  else would raise an exception within the above 'ctr_geom' call\n    if geom.shape[0] == 3*masses.shape[0]:\n        masses = masses.repeat(3)\n    ## end if\n\n    # Initialize the tensor matrix\n    tensor = np.zeros((3,3))\n\n    # Fill the matrix\n    for i in range(3):\n        for j in range(i,3):\n            if i == j:\n                # On-diagonal element; calculate indices to include\n                ind = np.concatenate([np.array(list(map(lambda v: v % 3,\n                                        range(i+1, i+3)))) + o for o in\n                                        range(0,geom.shape[0],3)])\n\n                # Calculate the tensor element\n                tensor[i,i] = np.multiply(np.square(geom[ind]),\n                                                        masses[ind]).sum()\n            else:\n                # Off-diagonal element; calculate the indices\n                ind_i = np.array(range(i,geom.shape[0]+i,3))\n                ind_j = np.array(range(j,geom.shape[0]+j,3))\n\n                # Calculate the tensor element and its symmetric partner\n                tensor[i,j] = np.multiply(\n                        np.sqrt(np.multiply(masses[ind_i], masses[ind_j])) ,\n                        np.multiply(geom[ind_i], geom[ind_j]) ).sum() * -1\n                tensor[j,i] = tensor[i,j]\n            ## end if\n        ## next j\n    ## next i\n\n    # Return the tensor\n    return tensor"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a base - type of a new set of principal axes and moments for the given geometry.", "response": "def principals(geom, masses, on_tol=_DEF.ORTHONORM_TOL):\n    \"\"\"Principal axes and moments of inertia for the indicated geometry.\n\n    Calculated by :func:`scipy.linalg.eigh`, since the moment of inertia tensor\n    is symmetric (real-Hermitian) by construction.  More convenient to\n    compute both the axes and moments at the same time since the eigenvectors\n    must be processed to ensure repeatable results.\n\n    The principal axes (inertia tensor eigenvectors) are processed in a\n    fashion to ensure repeatable, **identical** generation, including\n    orientation AND directionality.\n\n    .. todo:: Add ref to exposition in webdocs once written up.\n\n    Parameters\n    ----------\n    geom\n        length-3N |npfloat_| --\n        Coordinates of the atoms\n\n    masses\n        length-N OR length-3N |npfloat_| --\n        Atomic masses of the atoms. Length-3N option is to allow calculation of\n        a per-coordinate perturbed value.\n\n    on_tol\n        |npfloat_|,  optional --\n        Tolerance for deviation from unity/zero for principal axis dot products\n        within which axes are considered orthonormal. Default is\n        :data:`opan.const.DEF.ORTHONORM_TOL`.\n\n    Returns\n    -------\n    moments\n        length-3 |npfloat_| --\n        Principal inertial moments, sorted in increasing order\n        :math:`\\\\left(0 \\\\leq I_A \\\\leq I_B \\\\leq I_C\\\\right)`\n\n    axes\n        3 x 3 |npfloat_| --\n        Principal axes, as column vectors, sorted with the principal moments\n        and processed for repeatability. The axis corresponding to\n        ``moments[i]`` is retrieved as ``axes[:,i]``\n\n    top\n        :class:`~opan.const.EnumTopType` --\n        Detected molecular top type\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM, EnumTopType as ETT\n    from ..error import InertiaError, VectorError\n    from .vector import rej, parallel_check as prlchk\n    from .vector import orthonorm_check as orthchk\n\n    # Center the geometry. Takes care of any improper shapes of geom or\n    #  masses via the internal call to 'ctr_mass' within the call to\n    #  'ctr_geom'.  Will need the centered geometry eventually anyways.\n    geom = ctr_geom(geom, masses)\n\n    # Get the inertia tensor\n    tensor = inertia_tensor(geom, masses)\n\n    # Orthogonalize and store eigenvalues/-vectors. eigh documentation says it\n    #  will return ordered eigenvalues.... Store eigenvalues directly to\n    #  the return variable; since eigenvectors probably need work, store them\n    #  to a holding variable.\n    moments, vecs = spla.eigh(tensor)\n\n    # 'fail' init for 'top\n    top = None\n\n    # Detect top type; start with error check\n    if moments[0] < -PRM.ZERO_MOMENT_TOL:  # pragma: no cover\n        # Invalid moment; raise error. Should be impossible!\n        raise InertiaError(InertiaError.NEG_MOMENT,\n                    \"Negative principal inertial moment\", \"\")\n    elif moments[0] < PRM.ZERO_MOMENT_TOL:\n        # Zero first moment. Check whether others are too\n        if all(moments < PRM.ZERO_MOMENT_TOL):\n            top = ETT.ATOM\n        else:\n            top = ETT.LINEAR\n        ## end if\n    else:\n        if abs((moments[1] / moments[0]) - 1.0) < PRM.EQUAL_MOMENT_TOL:\n            # Spherical or oblate symmetrical\n            if abs((moments[2] / moments[1]) - 1.0) < PRM.EQUAL_MOMENT_TOL:\n                top = ETT.SPHERICAL\n            else:\n                top = ETT.SYMM_OBL\n            ## end if\n        else:\n            # Prolate symmetrical or Asymmetric\n            if abs((moments[2] / moments[1]) - 1.0) < PRM.EQUAL_MOMENT_TOL:\n                top = ETT.SYMM_PROL\n            else:\n                top = ETT.ASYMM\n            ## end if\n        ## end if\n    ## end if\n\n    # Check for nothing assigned (this should never occur!)\n    if top is None:  # pragma: no cover\n        raise InertiaError(InertiaError.TOP_TYPE,\n                    \"Unrecognized molecular top type\",\"\")\n    ## end if\n\n    # Initialize the axes\n    axes = np.zeros((3,3))\n\n    # Define the axes depending on the top type\n    if top == ETT.ATOM:\n        # Just use the coordinate axes\n        axes = np.identity(3, dtype=np.float_)\n\n    elif top == ETT.LINEAR:\n        # Zero-moment (molecular) axis always pointed toward the first atom,\n        #  or the second if the first is at center-of-mass\n        if spla.norm(geom[0:3]) >= PRM.ZERO_VEC_TOL:\n            axes[:,0] = geom[0:3] / spla.norm(geom[0:3])\n        else:  # pragma: no cover (assume alt case ok)\n            axes[:,0] = geom[3:6] / spla.norm(geom[3:6])\n        ## end if\n\n        # Second axis is the normalized rejection of the x-axis on the first\n        #  axis, unless the molecule lies along the x-axis in which case it\n        #  is taken as the normalized rejection of the y-axis on the first vec.\n        if prlchk(axes[:,0], np.array([1.,0.,0.])):\n            # Too nearly (anti-)parallel\n            axes[:,1] = rej(np.array([0.,1.,0.]), axes[:,0])\n        else:  # pragma: no cover (assume alt case ok)\n            # Sufficiently non-(anti-)parallel\n            axes[:,1] = rej(np.array([1.,0.,0.]), axes[:,0])\n        ## end if\n        axes[:,1] /= spla.norm(axes[:,1])\n\n        # Third axis is the first crossed with the second\n        axes[:,2] = np.cross(axes[:,0], axes[:,1])\n\n    elif top == ETT.ASYMM:\n        # Vectors should already be orthonormal; following error should\n        #  never occur\n        if not orthchk(vecs, tol=on_tol):  # pragma: no cover\n            raise VectorError(VectorError.ORTHONORM,\n                         \"'eigh' produced non-orthonormal axes\", \"\")\n        ## end if\n\n        # Duplicate the vectors to the axes object\n        axes = vecs.copy()\n\n        # Orient first two axes to have positive dot products with their\n        #  respective first non-zero, non-orthogonal atomic displacements.\n        #  Possibly fragile to some sort of highly unusual geometry.\n        axes[:,0] *= np.sign(np.dot(vecs[:,0], _fadn_orth(vecs[:,0], geom)))\n        axes[:,1] *= np.sign(np.dot(vecs[:,1], _fadn_orth(vecs[:,1], geom)))\n\n        # Orient the third axis such that a3 = a1 {cross} a2\n        axes[:,2] *= np.sign(np.dot(axes[:,2], np.cross(axes[:,0], axes[:,1])))\n\n    elif top == ETT.SYMM_OBL:\n        # First axis is taken as the normalized rejection of the first\n        #  non-(anti)parallel atomic displacement onto the third eigenvector.\n        axes[:,0] = rej(_fadn_par(vecs[:,2], geom), vecs[:,2])\n        axes[:,0] /= spla.norm(axes[:,0])\n\n        # Try to take the third axis directionality as that giving a positive\n        #  dot product with the first non-orthogonal atomic displacement.\n        # A planar system will cause an error in the _fadn_orth call, that\n        #  is trapped here.\n        # If planar, take the third axis as the normalized cross product\n        #  of the first and second nonzero atomic displacements.\n\n        try:\n            axes[:,2] = vecs[:,2] * np.sign(np.dot(vecs[:,2],\n                                                _fadn_orth(vecs[:,2], geom)))\n        except InertiaError as IE:\n            # Check that typecode is as expected for error from planar system.\n            if not IE.tc == InertiaError.BAD_GEOM:  # pragma: no cover\n                raise\n            ## end if\n\n            # Select the appropriate displacements to define the third axis\n            if spla.norm(geom[0:3]) < PRM.ZERO_VEC_TOL:\n                # First displacement is zero\n                axes[:,2] = np.cross(geom[3:6], geom[6:9]) # pragma: no cover\n            elif spla.norm(geom[3:6]) < PRM.ZERO_VEC_TOL:\n                # Second displacement is zero\n                axes[:,2] = np.cross(geom[0:3], geom[6:9]) # pragma: no cover\n            else:\n                # First and second displacements are okay\n                axes[:,2] = np.cross(geom[0:3], geom[3:6])\n            ## end if\n\n            # Regardless of which calculation, normalize the vector\n        finally:\n            axes[:,2] /= spla.norm(axes[:,2])\n        ## end try\n\n        # Second axis is the third axis crossed with the first\n        axes[:,1] = np.cross(axes[:,2], axes[:,0])\n\n    elif top == ETT.SYMM_PROL:\n        # Special case of prolate symmetric is linear, which is separately\n        #  detected and already addressed.\n        # First (non-degenerate) axis is just taken to have a positive dot\n        #  product with its first non-orthogonal nonzero displacement\n        axes[:,0] = vecs[:,0] * np.sign(np.dot(vecs[:,0],\n                                                    _fadn_orth(vecs[:,0], geom)))\n\n        # Second (first degenerate) axis is the normalized rejection of the\n        #  first non-parallel displacement onto the first axis\n        axes[:,1] = rej(_fadn_par(axes[:,0], geom), axes[:,0])\n        axes[:,1] /= spla.norm(axes[:,1])\n\n        # Third (second degenerate) axis is just the first axis crossed with\n        #  the second.\n        axes[:,2] = np.cross(axes[:,0], axes[:,1])\n\n    elif top == ETT.SPHERICAL:\n        # No preferred orientation -- ALL vectors are degenerate axes\n        # First axis is the first nonzero displacement, normalized\n        axes[:,0] = geom[3:6] if spla.norm(geom[0:3]) < PRM.ZERO_VEC_TOL \\\n                                                                else geom[0:3]\n        axes[:,0] /= spla.norm(axes[:,0])\n\n        # Second axis is the normalized rejection onto the first axis of the\n        #  first nonzero non-parallel displacement from that first axis\n        axes[:,1] = rej(_fadn_par(axes[:,0], geom), axes[:,0])\n        axes[:,1] /= spla.norm(axes[:,1])\n\n        # Third axis is the first crossed with the second\n        axes[:,2] = np.cross(axes[:,0], axes[:,1])\n\n    ## end if\n\n    # Reconfirm orthonormality. Again, the error should never occur.\n    if not orthchk(axes, tol=on_tol): # pragma: no cover\n        raise VectorError(VectorError.ORTHONORM,\n                    \"Axis conditioning broke orthonormality\",\"\")\n    ## end if\n\n    # Return the moments, axes, and top type\n    return moments, axes, top"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rot_consts(geom, masses, units=_EURC.INV_INERTIA, on_tol=_DEF.ORTHONORM_TOL):\n\n    # Imports\n    import numpy as np\n    from ..const import EnumTopType as ETT, EnumUnitsRotConst as EURC, PRM, PHYS\n\n    # Ensure units are valid\n    if not units in EURC:\n        raise ValueError(\"'{0}' is not a valid units value\".format(units))\n    ## end if\n\n    # Retrieve the moments, axes and top type. Geom and masses are proofed\n    #  internally in this call.\n    mom, ax, top = principals(geom, masses, on_tol)\n\n    # Check for special cases\n    if top == ETT.ATOM:\n        # All moments are zero; set to zero-moment threshold\n        mom = np.repeat(PRM.ZERO_MOMENT_TOL, 3)\n    elif top == ETT.LINEAR:\n        # First moment is zero; set to zero-moment threshold\n        mom[0] = PRM.ZERO_MOMENT_TOL\n    ## end if\n\n    # Calculate the values in the indicated units\n    if units == EURC.INV_INERTIA:            # 1/(amu*B^2)\n        rc = 1.0 / (2.0 * mom)\n    elif units == EURC.ANGFREQ_ATOMIC:       # 1/Ta\n        rc = PHYS.PLANCK_BAR / (2.0 * mom * PHYS.ME_PER_AMU)\n    elif units == EURC.ANGFREQ_SECS:      # 1/s\n        rc = PHYS.PLANCK_BAR / (2.0 * mom * PHYS.ME_PER_AMU) / PHYS.SEC_PER_TA\n    elif units == EURC.CYCFREQ_ATOMIC:    # cyc/Ta\n        rc = PHYS.PLANCK_BAR / (4.0 * np.pi * mom * PHYS.ME_PER_AMU)\n    elif units == EURC.CYCFREQ_HZ:        # cyc/s\n        rc = PHYS.PLANCK_BAR / (4.0 * np.pi * mom * PHYS.ME_PER_AMU) / \\\n                                                            PHYS.SEC_PER_TA\n    elif units == EURC.CYCFREQ_MHZ:       # Mcyc/s\n        rc = PHYS.PLANCK_BAR / (4.0 * np.pi * mom * PHYS.ME_PER_AMU) / \\\n                                                    PHYS.SEC_PER_TA / 1.0e6\n    elif units == EURC.WAVENUM_ATOMIC:       # cyc/B\n        rc = PHYS.PLANCK / (mom * PHYS.ME_PER_AMU) / \\\n            (8.0 * np.pi**2.0 * PHYS.LIGHT_SPEED)\n    elif units == EURC.WAVENUM_CM:           # cyc/cm\n        rc = PHYS.PLANCK / (mom * PHYS.ME_PER_AMU) / \\\n            (8.0 * np.pi**2.0 * PHYS.LIGHT_SPEED * PHYS.ANG_PER_BOHR) * 1.0e8\n    else:               # pragma: no cover -- Valid units; not implemented\n        raise NotImplementedError(\"Units conversion not yet implemented.\")\n    ## end if\n\n    # Return the result\n    return rc", "response": "Returns the rotational constants for a given molecular system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of ReferenceContext objects for the given variant and context size.", "response": "def reference_contexts_for_variant(\n        variant,\n        context_size,\n        transcript_id_whitelist=None):\n    \"\"\"\n    variant : varcode.Variant\n\n    context_size : int\n        Max of nucleotides to include to the left and right of the variant\n        in the context sequence.\n\n    transcript_id_whitelist : set, optional\n        If given, then only consider transcripts whose IDs are in this set.\n\n    Returns list of ReferenceContext objects, sorted by maximum length of\n    coding sequence of any supporting transcripts.\n    \"\"\"\n    overlapping_transcripts = reference_transcripts_for_variant(\n        variant=variant,\n        transcript_id_whitelist=transcript_id_whitelist)\n\n    # dictionary mapping SequenceKeyWithReadingFrame keys to list of\n    # transcript objects\n    sequence_groups = defaultdict(list)\n\n    for transcript in overlapping_transcripts:\n        sequence_key_with_reading_frame = \\\n            ReferenceCodingSequenceKey.from_variant_and_transcript(\n                variant=variant,\n                transcript=transcript,\n                context_size=context_size)\n        if sequence_key_with_reading_frame is not None:\n            sequence_groups[sequence_key_with_reading_frame].append(transcript)\n\n    reference_contexts = [\n        ReferenceContext.from_reference_coding_sequence_key(\n            key, variant, matching_transcripts)\n        for (key, matching_transcripts) in sequence_groups.items()\n    ]\n    reference_contexts.sort(\n        key=ReferenceContext.sort_key_decreasing_max_length_transcript_cds)\n    return reference_contexts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reference_contexts_for_variants(\n        variants,\n        context_size,\n        transcript_id_whitelist=None):\n    \"\"\"\n    Extract a set of reference contexts for each variant in the collection.\n\n    Parameters\n    ----------\n    variants : varcode.VariantCollection\n\n    context_size : int\n        Max of nucleotides to include to the left and right of the variant\n        in the context sequence.\n\n    transcript_id_whitelist : set, optional\n        If given, then only consider transcripts whose IDs are in this set.\n\n    Returns a dictionary from variants to lists of ReferenceContext objects,\n    sorted by max coding sequence length of any transcript.\n    \"\"\"\n    result = OrderedDict()\n    for variant in variants:\n        result[variant] = reference_contexts_for_variant(\n            variant=variant,\n            context_size=context_size,\n            transcript_id_whitelist=transcript_id_whitelist)\n    return result", "response": "Returns a dictionary of ReferenceContext objects for each variant in the given collection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a collection of variants find all reference sequence contexts around each variant and return a DataFrame with the columns chr pos ref alt.", "response": "def variants_to_reference_contexts_dataframe(\n        variants,\n        context_size,\n        transcript_id_whitelist=None):\n    \"\"\"\n    Given a collection of variants, find all reference sequence contexts\n    around each variant.\n\n    Parameters\n    ----------\n    variants : varcode.VariantCollection\n\n    context_size : int\n        Max of nucleotides to include to the left and right of the variant\n        in the context sequence.\n\n    transcript_id_whitelist : set, optional\n        If given, then only consider transcripts whose IDs are in this set.\n\n    Returns a DataFrame with {\"chr\", \"pos\", \"ref\", \"alt\"} columns for variants,\n    as well as all the fields of ReferenceContext.\n    \"\"\"\n\n    df_builder = DataFrameBuilder(\n        ReferenceContext,\n        exclude=[\"variant\"],\n        converters=dict(transcripts=lambda ts: \";\".join(t.name for t in ts)),\n        extra_column_fns={\n            \"gene\": lambda variant, _: \";\".join(variant.gene_names),\n        })\n    for variant, reference_contexts in reference_contexts_for_variants(\n            variants=variants,\n            context_size=context_size,\n            transcript_id_whitelist=transcript_id_whitelist).items():\n        df_builder.add_many(variant, reference_contexts)\n    return df_builder.to_dataframe()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing a 2D Gaussian pattern.", "response": "def gaussian(x, y, xsigma, ysigma):\n    \"\"\"\n    Two-dimensional oriented Gaussian pattern (i.e., 2D version of a\n    bell curve, like a normal distribution but not necessarily summing\n    to 1.0).\n    \"\"\"\n    if xsigma==0.0 or ysigma==0.0:\n        return x*0.0\n\n    with float_error_ignore():\n        x_w = np.divide(x,xsigma)\n        y_h = np.divide(y,ysigma)\n        return np.exp(-0.5*x_w*x_w + -0.5*y_h*y_h)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_gaussian(x, y, x_sigma, y_sigma, mu):\n    if x_sigma==0.0 or y_sigma==0.0:\n        return x * 0.0\n\n    with float_error_ignore():\n        x_w = np.divide(np.log(x)-mu, x_sigma*x_sigma)\n        y_h = np.divide(np.log(y)-mu, y_sigma*y_sigma)\n\n        return np.exp(-0.5*x_w*x_w + -0.5*y_h*y_h)", "response": "Two-dimensional oriented Log Gaussian pattern (i.e., 2D version of a\n    bell curve with an independent, movable peak). Much like a normal\n    distribution, but not necessarily placing the peak above the center,\n    and not necessarily summing to 1.0)."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exponential(x, y, xscale, yscale):\n    if xscale==0.0 or yscale==0.0:\n        return x*0.0\n\n    with float_error_ignore():\n        x_w = np.divide(x,xscale)\n        y_h = np.divide(y,yscale)\n        return np.exp(-np.sqrt(x_w*x_w+y_h*y_h))", "response": "Exponential decay of two - dimensional vectors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef line(y, thickness, gaussian_width):\n    distance_from_line = abs(y)\n    gaussian_y_coord = distance_from_line - thickness/2.0\n    sigmasq = gaussian_width*gaussian_width\n\n    if sigmasq==0.0:\n        falloff = y*0.0\n    else:\n        with float_error_ignore():\n            falloff = np.exp(np.divide(-gaussian_y_coord*gaussian_y_coord,2*sigmasq))\n\n    return np.where(gaussian_y_coord<=0, 1.0, falloff)", "response": "Infinite - length line with a solid central region then Gaussian fall - off at the edges."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the circular disk of the specified location.", "response": "def disk(x, y, height, gaussian_width):\n    \"\"\"\n    Circular disk with Gaussian fall-off after the solid central region.\n    \"\"\"\n    disk_radius = height/2.0\n\n    distance_from_origin = np.sqrt(x**2+y**2)\n    distance_outside_disk = distance_from_origin - disk_radius\n    sigmasq = gaussian_width*gaussian_width\n\n    if sigmasq==0.0:\n        falloff = x*0.0\n    else:\n        with float_error_ignore():\n            falloff = np.exp(np.divide(-distance_outside_disk*distance_outside_disk,\n                                  2*sigmasq))\n\n    return np.where(distance_outside_disk<=0,1.0,falloff)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ring(x, y, height, thickness, gaussian_width):\n    radius = height/2.0\n    half_thickness = thickness/2.0\n\n    distance_from_origin = np.sqrt(x**2+y**2)\n    distance_outside_outer_disk = distance_from_origin - radius - half_thickness\n    distance_inside_inner_disk = radius - half_thickness - distance_from_origin\n\n    ring = 1.0-np.bitwise_xor(np.greater_equal(distance_inside_inner_disk,0.0),\n                              np.greater_equal(distance_outside_outer_disk,0.0))\n\n    sigmasq = gaussian_width*gaussian_width\n\n    if sigmasq==0.0:\n        inner_falloff = x*0.0\n        outer_falloff = x*0.0\n    else:\n        with float_error_ignore():\n            inner_falloff = np.exp(np.divide(-distance_inside_inner_disk*distance_inside_inner_disk, 2.0*sigmasq))\n            outer_falloff = np.exp(np.divide(-distance_outside_outer_disk*distance_outside_outer_disk, 2.0*sigmasq))\n\n    return np.maximum(inner_falloff,np.maximum(outer_falloff,ring))", "response": "Returns the circular ring of the specified size."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smooth_rectangle(x, y, rec_w, rec_h, gaussian_width_x, gaussian_width_y):\n\n    gaussian_x_coord = abs(x)-rec_w/2.0\n    gaussian_y_coord = abs(y)-rec_h/2.0\n\n    box_x=np.less(gaussian_x_coord,0.0)\n    box_y=np.less(gaussian_y_coord,0.0)\n    sigmasq_x=gaussian_width_x*gaussian_width_x\n    sigmasq_y=gaussian_width_y*gaussian_width_y\n\n    with float_error_ignore():\n        falloff_x=x*0.0 if sigmasq_x==0.0 else \\\n            np.exp(np.divide(-gaussian_x_coord*gaussian_x_coord,2*sigmasq_x))\n        falloff_y=y*0.0 if sigmasq_y==0.0 else \\\n            np.exp(np.divide(-gaussian_y_coord*gaussian_y_coord,2*sigmasq_y))\n\n    return np.minimum(np.maximum(box_x,falloff_x), np.maximum(box_y,falloff_y))", "response": "Smooth a rectangle by a Gaussian."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a Radial arc by radian.", "response": "def arc_by_radian(x, y, height, radian_range, thickness, gaussian_width):\n    \"\"\"\n    Radial arc with Gaussian fall-off after the solid ring-shaped\n    region with the given thickness, with shape specified by the\n    (start,end) radian_range.\n    \"\"\"\n\n    # Create a circular ring (copied from the ring function)\n    radius = height/2.0\n    half_thickness = thickness/2.0\n\n    distance_from_origin = np.sqrt(x**2+y**2)\n    distance_outside_outer_disk = distance_from_origin - radius - half_thickness\n    distance_inside_inner_disk = radius - half_thickness - distance_from_origin\n\n    ring = 1.0-np.bitwise_xor(np.greater_equal(distance_inside_inner_disk,0.0),\n                              np.greater_equal(distance_outside_outer_disk,0.0))\n\n    sigmasq = gaussian_width*gaussian_width\n\n    if sigmasq==0.0:\n        inner_falloff = x*0.0\n        outer_falloff = x*0.0\n    else:\n        with float_error_ignore():\n            inner_falloff = np.exp(np.divide(-distance_inside_inner_disk*distance_inside_inner_disk, 2.0*sigmasq))\n            outer_falloff = np.exp(np.divide(-distance_outside_outer_disk*distance_outside_outer_disk, 2.0*sigmasq))\n\n    output_ring = np.maximum(inner_falloff,np.maximum(outer_falloff,ring))\n\n    # Calculate radians (in 4 phases) and cut according to the set range)\n\n    # RZHACKALERT:\n    # Function float_error_ignore() cannot catch the exception when\n    # both np.dividend and divisor are 0.0, and when only divisor is 0.0\n    # it returns 'Inf' rather than 0.0. In x, y and\n    # distance_from_origin, only one point in distance_from_origin can\n    # be 0.0 (circle center) and in this point x and y must be 0.0 as\n    # well. So here is a hack to avoid the 'invalid value encountered\n    # in divide' error by turning 0.0 to 1e-5 in distance_from_origin.\n    distance_from_origin += np.where(distance_from_origin == 0.0, 1e-5, 0)\n\n    with float_error_ignore():\n        sines = np.divide(y, distance_from_origin)\n        cosines = np.divide(x, distance_from_origin)\n        arcsines = np.arcsin(sines)\n\n    phase_1 = np.where(np.logical_and(sines >= 0, cosines >= 0), 2*pi-arcsines, 0)\n    phase_2 = np.where(np.logical_and(sines >= 0, cosines <  0), pi+arcsines,   0)\n    phase_3 = np.where(np.logical_and(sines <  0, cosines <  0), pi+arcsines,   0)\n    phase_4 = np.where(np.logical_and(sines <  0, cosines >= 0), -arcsines,     0)\n    arcsines = phase_1 + phase_2 + phase_3 + phase_4\n\n    if radian_range[0] <= radian_range[1]:\n        return np.where(np.logical_and(arcsines >= radian_range[0], arcsines <= radian_range[1]),\n                        output_ring, 0.0)\n    else:\n        return np.where(np.logical_or(arcsines >= radian_range[0], arcsines <= radian_range[1]),\n                        output_ring, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arc_by_center(x, y, arc_box, constant_length, thickness, gaussian_width):\n\n    arc_w=arc_box[0]\n    arc_h=abs(arc_box[1])\n\n    if arc_w==0.0: # arc_w=0, don't draw anything\n        radius=0.0\n        angles=(0.0,0.0)\n    elif arc_h==0.0:  # draw a horizontal line, width=arc_w\n        return smooth_rectangle(x, y, arc_w, thickness, 0.0, gaussian_width)\n    else:\n        if constant_length:\n            curvature=arc_h/arc_w\n            radius=arc_w/(2*pi*curvature)\n            angle=curvature*(2*pi)/2.0\n        else:  # constant width\n            radius=arc_h/2.0+arc_w**2.0/(8*arc_h)\n            angle=np.arcsin(arc_w/2.0/radius)\n        if arc_box[1]<0: # convex shape\n            y=y+radius\n            angles=(3.0/2.0*pi-angle, 3.0/2.0*pi+angle)\n        else:  # concave shape\n            y=y-radius\n            angles=(pi/2.0-angle, pi/2.0+angle)\n\n    return arc_by_radian(x, y, radius*2.0, angles, thickness, gaussian_width)", "response": "This function calculates the start and end radian of the arc by the center of the arc."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nskipping PG versions below specific version i.e. (9, 5).", "response": "def skipPGVersionBefore(*ver):\n    \"\"\"Skip PG versions below specific version i.e. (9, 5).\"\"\"\n\n    ver = ver + (0,) * (3 - len(ver))\n\n    def skip_before_postgres_(func):\n        @wraps(func)\n        def skip_before_postgres__(obj, *args, **kwargs):\n\n            if hasattr(obj.conn, 'server_version'):\n                server_version = obj.conn.server_version\n            else:  # Assume Sqlalchemy\n                server_version = obj.conn.connection.connection.server_version\n\n            if server_version < int('%d%02d%02d' % ver):\n                return obj.skipTest(\"Skipped because PostgreSQL {}\".format(\n                    server_version))\n            else:\n                return func(obj, *args, **kwargs)\n        return skip_before_postgres__\n    return skip_before_postgres_"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npacking an arbitrary set of iterables and non - iterables into tuples.", "response": "def pack_tups(*args):\n    \"\"\"Pack an arbitrary set of iterables and non-iterables into tuples.\n\n    Function packs a set of inputs with arbitrary iterability into tuples.\n    Iterability is tested with :func:`iterable`. Non-iterable inputs\n    are repeated in each output tuple. Iterable inputs are expanded\n    uniformly across the output tuples.  For consistency, all iterables must\n    be the same length.\n\n    The input arguments are parsed such that bare strings are treated as\n    **NON-ITERABLE**, through the use of a local subclass of |str| that\n    cripples the ``__iter__()`` method. Any strings passed are returned\n    in the packed tuples as standard, **ITERABLE** instances of |str|, however.\n\n    The order of the input arguments is retained within each output tuple.\n\n    No structural conversion is attempted on the arguments.\n\n    If all inputs are non-iterable, a list containing a single |tuple| will be\n    returned.\n\n    Parameters\n    ----------\n    \\*args\n        Arbitrary number of arbitrary mix of iterable and non-iterable\n        objects to be packed into tuples.\n\n    Returns\n    -------\n    tups\n        |list| of |tuple| --\n        Number of tuples returned is equal to the length of the iterables\n        passed in `*args`\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If any iterable objects are of different lengths\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Debug flag\n    _DEBUG = False\n\n    # Marker value for non-iterable items\n    NOT_ITER = -1\n\n    # Uninitialized test value\n    UNINIT_VAL = -1\n\n    # Print the input if in debug mode\n    if _DEBUG: # pragma: no cover\n        print(\"args = {0}\".format(args))\n\n    # Non-iterable subclass of str\n    class StrNoIter(str):\n        \"\"\" Non-iterable subclass of |str|. \"\"\"\n        def __iter__(self):\n            raise NotImplementedError(\"Non-iterable string\")\n        ## end def __iter__\n    ## end class StrNoIter\n\n    # Re-wrap input arguments with non-iterable strings if required\n    mod_args = [(StrNoIter(a) if isinstance(a, str) else a) for a in args]\n\n    # Determine the length or non-iterable status of each item and store\n    #  the maximum value (depends on NOT_ITER < 0)\n    iterlens = [(len(a) if iterable(a) else NOT_ITER) for a in mod_args]\n    maxiter = max(iterlens)\n\n    # Check to ensure all iterables are the same length\n    if not all(map(lambda v: v in (NOT_ITER, maxiter), iterlens)):\n        raise ValueError(\"All iterable items must be of equal length\")\n    ## end if\n\n    # If everything is non-iterable, just return the args tuple wrapped in\n    #  a list (as above, depends on NOT_ITER < 0)\n    if maxiter == NOT_ITER:\n        return [args]\n    ## end if\n\n    # Swap any non-iterables for a suitable length repeat, and zip to\n    #  tuples for return\n    tups = list(zip(*[(np.repeat(a, maxiter) if l == NOT_ITER else a)\n            for (a,l) in zip(mod_args, iterlens)]))\n\n    # Dump the resulting tuples, if in debug mode\n    if _DEBUG:  # pragma: no cover\n        print(\"tups = {0}\".format(tups))\n    ## end if\n\n    # Return the tuples\n    return tups"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a safe typecast of the input variable to the given type.", "response": "def safe_cast(invar, totype):\n    \"\"\"Performs a \"safe\" typecast.\n\n    Ensures that `invar` properly casts to `totype`. Checks after\n    casting that the result is actually of type `totype`. Any exceptions raised\n    by the typecast itself are unhandled.\n\n    Parameters\n    ----------\n    invar\n        (arbitrary) -- Value to be typecast.\n\n    totype\n        |type| --  Type to which `invar` is to be cast.\n\n    Returns\n    -------\n    outvar\n        `type 'totype'` --  Typecast version of `invar`\n\n    Raises\n    ------\n    ~exceptions.TypeError\n        If result of typecast is not of type `totype`\n\n    \"\"\"\n\n    # Make the typecast. Just use Python built-in exceptioning\n    outvar = totype(invar)\n\n    # Check that the cast type matches\n    if not isinstance(outvar, totype):\n        raise TypeError(\"Result of cast to '{0}' is '{1}'\"\n                                            .format(totype, type(outvar)))\n    ## end if\n\n    # Success; return the cast value\n    return outvar"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a hour - minutes - seconds timestamp from an interval in seconds.", "response": "def make_timestamp(el_time):\n    \"\"\" Generate an hour-minutes-seconds timestamp from an interval in seconds.\n\n    Assumes numeric input of a time interval in seconds.  Converts this\n    interval to a string of the format \"#h #m #s\", indicating the number of\n    hours, minutes, and seconds in the interval.  Intervals greater than 24h\n    are unproblematic.\n\n    Parameters\n    ----------\n    el_time\n        |int| or |float| --\n        Time interval in seconds to be converted to h/m/s format\n\n    Returns\n    -------\n    stamp\n        |str| -- String timestamp in #h #m #s format\n\n    \"\"\"\n\n    # Calc hours\n    hrs = el_time // 3600.0\n\n    # Calc minutes\n    mins = (el_time % 3600.0) // 60.0\n\n    # Calc seconds\n    secs = el_time % 60.0\n\n    # Construct timestamp string\n    stamp = \"{0}h {1}m {2}s\".format(int(hrs), int(mins), int(secs))\n\n    # Return\n    return stamp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if two geometries are consistent with the input atom symbol lists c1 a2 and c3.", "response": "def check_geom(c1, a1, c2, a2, tol=_DEF.XYZ_COORD_MATCH_TOL):\n    \"\"\" Check for consistency of two geometries and atom symbol lists\n\n    Cartesian coordinates are considered consistent with the input\n    coords if each component matches to within `tol`.  If coords or\n    atoms vectors are passed that are of mismatched lengths, a\n    |False| value is returned.\n\n    Both coords vectors must be three times the length of the atoms vectors\n    or a :exc:`~exceptions.ValueError` is raised.\n\n    Parameters\n    ----------\n    c1\n        length-3N |npfloat_| --\n        Vector of first set of stacked 'lab-frame' Cartesian coordinates\n\n    a1\n        length-N |str| or |int| --\n        Vector of first set of atom symbols or atomic numbers\n\n    c2\n        length-3N |npfloat_| --\n        Vector of second set of stacked 'lab-frame' Cartesian coordinates\n\n    a2\n        length-N |str| or |int| --\n        Vector of second set of atom symbols or atomic numbers\n\n    tol\n        |float|, optional --\n        Tolerance for acceptable deviation of each geometry coordinate\n        from that in the reference instance to still be considered\n        matching. Default value is specified by\n        :attr:`opan.const.DEF.XYZ_COORD_MATCH_TOL`)\n\n    Returns\n    -------\n    match\n        |bool| --\n        Whether input coords and atoms match (|True|) or\n        not (|False|)\n\n    fail_type\n        :class:`~opan.const.EnumCheckGeomMismatch` or |None|\n        -- Type of check failure\n\n        If `match` == |True|:\n\n            Returns as |None|\n\n        If `match` == |False|:\n\n            An :class:`~opan.const.EnumCheckGeomMismatch` value\n            indicating the reason for the failed match:\n\n                :attr:`~opan.const.EnumCheckGeomMismatch.DIMENSION`\n                -- Mismatch in geometry size (number of atoms)\n\n                :attr:`~opan.const.EnumCheckGeomMismatch.COORDS`\n                -- Mismatch in one or more coordinates\n\n                :attr:`~opan.const.EnumCheckGeomMismatch.ATOMS`\n                -- Mismatch in one or more atoms\n\n    fail_loc\n        length-3N |bool| or length-N |bool| or |None| --\n        Mismatched elements\n\n        If `match` == |True|:\n\n            Returns as |None|\n\n        If `match` == |False|:\n\n            For \"array-level\" problems such as a dimension mismatch, a\n            |None| value is returned.\n\n            For \"element-level\" problems, a vector is returned\n            indicating positions of mismatch in either `coords` or `atoms`,\n            depending on the value of `fail_type`.\n\n                |True| elements indicate **MATCHING** values\n\n                |False| elements mark **MISMATCHES**\n\n    Raises\n    ------\n    ~exceptions.ValueError\n        If a pair of coords & atoms array lengths is inconsistent:\n\n        .. code-block:: python\n\n            if len(c1) != 3 * len(a1) or len(c2) != 3 * len(a2):\n                raise ValueError(...)\n\n    \"\"\"\n\n    # Import(s)\n    from ..const import atom_num\n    import numpy as np\n    from ..const import EnumCheckGeomMismatch as ECGM\n\n    # Initialize return value to success condition\n    match = True\n\n    #** Check coords for suitable shape. Assume 1-D np.arrays.\n    if not len(c1.shape) == 1:\n        # Cannot coerce to vector; complain.\n        raise ValueError((\"'c1' is not a vector.\"))\n    ## end if\n    if not len(c2.shape) == 1:\n        # Cannot coerce to vector; complain.\n        raise ValueError((\"'c2' is not a vector.\"))\n    ## end if\n\n    #** Check atoms for suitable shape. Assume lists of strings, so\n    # convert to np.array to check.\n    if not len(a1.shape) == 1:\n        # Not a vector; complain\n        raise ValueError((\"'a1' is not a simple list.\"))\n    ## end if\n    if not len(a2.shape) == 1:\n        # Not a vector; complain.\n        raise ValueError((\"'a2' is not a simple list.\"))\n    ## end if\n\n    #** Confirm proper lengths of coords vs atoms\n    if not c1.shape[0] == 3 * a1.shape[0]:\n        raise ValueError(\"len(c1) != 3*len(a1)\")\n    ## end if\n    if not c2.shape[0] == 3 * a2.shape[0]:\n        raise ValueError(\"len(c2) != 3*len(a2)\")\n    ## end if\n\n    #** Confirm matching lengths of coords and atoms w/corresponding\n    #  objects among the two geometries\n    if not c1.shape[0] == c2.shape[0]:\n        match = False\n        fail_type = ECGM.DIMENSION\n        return match, fail_type, None\n    ## end if\n\n    #** Element-wise check for geometry match to within 'tol'\n    fail_loc = np.less_equal(np.abs(np.subtract(c1,c2)), tol)\n    if sum(fail_loc) != c2.shape[0]:\n        # Count of matching coordinates should equal the number of\n        #  coordinates. If not, complain with 'coord_mismatch' fail type.\n        match = False\n        fail_type = ECGM.COORDS\n        return match, fail_type, fail_loc\n    ## end if\n\n    #** Element-wise check for atoms match. Quietly convert both input and\n    #  instance atom arrays to atom_nums to allow np.equals comparison.\n    if np.issubdtype(a1.dtype, np.dtype('str')):\n        # Presume atomic symbol data and attempt conversion\n        a1 = np.array([atom_num[e] for e in a1])\n    ## end if\n    if np.issubdtype(a2.dtype, np.dtype('str')):\n        # Presume atomic symbol data and attempt conversion\n        a2 = np.array([atom_num[e] for e in a2])\n    ## end if\n    fail_loc = np.equal(a1, a2)\n\n    #** Perform the test to ensure all atoms match.\n    if sum(fail_loc) != a2.shape[0]:\n        # Count of matching atoms should equal number of atoms. If not,\n        #  complain with the 'atom_mismatch' fail type.\n        match = False\n        fail_type = ECGM.ATOMS\n        return match, fail_type, fail_loc\n\n    #** If reached here, all tests passed; return success.\n    return match, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubstitute a template with a list of strings.", "response": "def template_subst(template, subs, delims=('<', '>')):\n    \"\"\" Perform substitution of content into tagged string.\n\n    For substitutions into template input files for external computational\n    packages, no checks for valid syntax are performed.\n\n    Each key in `subs` corresponds to a delimited\n    substitution tag to be replaced in `template` by the entire text of the\n    value of that key. For example, the dict ``{\"ABC\": \"text\"}`` would\n    convert ``The <ABC> is working`` to  ``The text is working``, using the\n    default delimiters of '<' and '>'. Substitutions are performed in\n    iteration order from `subs`; recursive substitution\n    as the tag parsing proceeds is thus\n    feasible if an :class:`~collections.OrderedDict` is used and substitution\n    key/value pairs are added in the proper order.\n\n    Start and end delimiters for the tags are modified by `delims`. For\n    example, to substitute a tag of the form **{\\|TAG\\|}**, the tuple\n    ``(\"{|\",\"|}\")`` should be passed to `subs_delims`.  Any elements in\n    `delims` past the second are ignored. No checking is\n    performed for whether the delimiters are \"sensible\" or not.\n\n    Parameters\n    ----------\n    template\n        |str| --\n        Template containing tags delimited by `subs_delims`,\n        with tag names and substitution contents provided in `subs`\n\n    subs\n        |dict| of |str| --\n        Each item's key and value are the tag name and corresponding content to\n        be substituted into the provided template.\n\n    delims\n        iterable of |str| --\n        Iterable containing the 'open' and 'close' strings used to mark tags\n        in the template, which are drawn from elements zero and one,\n        respectively. Any elements beyond these are ignored.\n\n    Returns\n    -------\n    subst_text\n        |str| --\n        String generated from the parsed template, with all tag\n        substitutions performed.\n\n    \"\"\"\n\n    # Store the template into the working variable\n    subst_text = template\n\n    # Iterate over subs and perform the .replace() calls\n    for (k,v) in subs.items():\n        subst_text = subst_text.replace(\n                delims[0] + k + delims[1], v)\n    ## next tup\n\n    # Return the result\n    return subst_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assert_npfloatarray(obj, varname, desc, exc, tc, errsrc):\n\n    # Imports\n    import numpy as np\n\n    # Check for whether member or object is to be checked\n    if varname is None:\n        var = obj\n    else:\n        # Try to get the variable to be typechecked\n        try:\n            var = getattr(obj, varname)\n        except AttributeError:\n            raise exc(tc, \"Attribute '{0}' not defined in '{1}'\"\n                    .format(varname, obj), errsrc)\n        ## end try\n    ## end if\n\n    # Try to pull the np dtype off of it\n    try:\n        dt = var.dtype\n    except AttributeError:\n        raise exc(tc, \"'{0}' is not an np.array (lacks a 'dtype' member)\"\n                    .format(desc), errsrc)\n    else:\n        if not var.shape:\n            raise exc(tc, \"'{0}' is not an np.array ('len(shape)' < 1)\"\n                    .format(desc), errsrc)\n    ## end try\n\n    # Confirm dtype inherits from np.float\n    if not np.issubdtype(dt, np.float):\n        raise exc(tc, \"'{0}' is not an np.array of np.float\".format(desc),\n                errsrc)", "response": "Assert a value is an |nparray| of NumPy floats."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadvance the base iterator publish to constituent iterators.", "response": "def advance(self):\n        \"\"\"Advance the base iterator, publish to constituent iterators.\"\"\"\n        elem = next(self._iterable)\n        for deque in self._deques:\n            deque.append(elem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns true if the distance between the x y locations of the generator g0 and g1 is greater than a minimum separation.", "response": "def __distance_valid(self, g0, g1, p):\n        \"\"\"\n        Returns true if the distance between the (x,y) locations of\n        two generators g0 and g1 is greater than a minimum separation.\n\n        Can be extended easily to support other criteria.\n        \"\"\"\n        dist = np.sqrt((g1.x - g0.x) ** 2 +\n                    (g1.y - g0.y) ** 2)\n        return dist >= p.min_separation"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadvances the parameters for each generator for each pattern and return a list of generators that are accepted by the given constraints.", "response": "def _advance_pattern_generators(self,p):\n        \"\"\"\n        Advance the parameters for each generator for this\n        presentation.\n\n        Picks a position for each generator that is accepted by\n        __distance_valid for all combinations.  Returns a new list of\n        the generators, with some potentially omitted due to failure\n        to meet the constraints.\n        \"\"\"\n\n        valid_generators = []\n        for g in p.generators:\n\n            for trial in range(self.max_trials):\n                # Generate a new position and add generator if it's ok\n\n                if np.alltrue([self.__distance_valid(g,v,p) for v in valid_generators]):\n                    valid_generators.append(g)\n                    break\n\n                g.force_new_dynamic_value('x')\n                g.force_new_dynamic_value('y')\n\n            else:\n                self.warning(\"Unable to place pattern %s subject to given constraints\" %\n                             g.name)\n\n        return valid_generators"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef function(self,p):\n        pg = p.generator\n        motion_orientation=p.orientation+pi/2.0\n\n        new_x = p.x+p.size*pg.x\n        new_y = p.y+p.size*pg.y\n\n        image_array = pg(xdensity=p.xdensity,ydensity=p.ydensity,bounds=p.bounds,\n                         x=new_x + p.speed*p.step*np.cos(motion_orientation),\n                         y=new_y + p.speed*p.step*np.sin(motion_orientation),\n                         orientation=p.orientation,\n                         scale=pg.scale*p.scale,offset=pg.offset+p.offset)\n\n        return image_array", "response": "Selects and returns one of the patterns in the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the Hessian geometry with input coordinates and atoms are consistent with the Hessian object.", "response": "def check_geom(self, coords, atoms, tol=_DEF.HESS_COORD_MATCH_TOL):\n        \"\"\" Check for consistency of Hessian geometry with input coords/atoms.\n\n        The cartesian coordinates associated with a Hessian object\n        are considered consistent with the input `coords` and `atoms`\n        if each component matches to within `tol` and all atoms\n        are identical.  If\n        `coords` or `atoms` vectors are passed that are of different\n        length than those stored in the instance, a |False| value is\n        returned, rather than an exception raised.\n\n        Parameters\n        ----------\n        coords\n            length-3N |npfloat_| --\n            Vector of stacked 'lab-frame' Cartesian coordinates\n\n        atoms\n            length-N |str| or |int| --\n            Vector of atom symbols or atomic numbers\n\n        tol\n            |float|, optional --\n            Tolerance for acceptable deviation of each passed geometry\n            coordinate  from that in the instance to still be considered\n            matching. Default value is\n            :data:`DEF.HESS_COORD_MATCH_TOL\n            <opan.const.DEF.HESS_COORD_MATCH_TOL>`\n\n\n        See :func:`opan.utils.check_geom <opan.utils.base.check_geom>` for\n        details on return values and exceptions raised.\n\n        \"\"\"\n\n        # Import(s)\n        from .utils import check_geom as ucg\n\n        # Wrapper call\n        result = ucg(self.geom, self.atom_syms, coords, atoms, tol=tol)\n\n        # Return result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load(self, **kwargs):\n\n        # Local method(s)\n        def parse_multiblock(hesstext, p_block, p_sec, p_line, num_ats,\n                                                            blockname, tc):\n            \"\"\" Helper function for importing blocks with multiple sections.\n\n            Parsing of data spanning multiple sections of columns is somewhat\n            involved. This function encapsulates the process for cleaner\n            code.  The structure depends critically on several formatting\n            features of |orca| .hess files.\n\n            Note the search groups that must be present in the `p_block` and\n            `p_line` Regex patterns.\n\n            Parameters\n            ----------\n            hesstest\n                |str| --\n                Complete text of the .hess file\n\n            p_block\n                |re.compile| pattern --\n                Retrieves the **entirety** of the relevant block\n                Required groups:\n                    dim     : overall dimension of the data block\n                    block   : contents of the block, including column headers\n\n            p_sec\n                |re.compile| pattern --\n                Retrieves each section of data columns\n\n            p_line\n                |re.compile| pattern --\n                Retrieves individual lines of a section\n                Required groups:\n                    row     : Row index into the final data block\n                    e#      : Column index into the data section (# in range(6))\n\n            num_ats\n                |int| --\n                Number of atoms in the geometry\n\n            blockname\n                |str| --\n                Brief text description of the block being imported, if needed\n                for error reporting purposes\n\n            tc\n                :class:`~opan.error.HessError` typecode --\n                Type of error to be thrown, if required\n\n            Returns\n            -------\n            workmtx\n                3N x 3N |npfloat_| --\n                Assembled array for storage\n\n            \"\"\"\n\n            # Pull the block\n            m_block = p_block.search(hesstext)\n\n            # Confirm the anticipated matrix size matches 3*num_ats\n            if not int(m_block.group(\"dim\")) == 3*num_ats:\n                raise HessError(tc, blockname + \" dimension \" +\n                        \"specification mismatched with geometry\",\n                        \"HESS File: \" + hess_path)\n            ## end if\n\n            # Initialize the working matrix\n            workmtx = np.zeros((3*num_ats, 3*num_ats), dtype=np.float_)\n\n            # Initialize the column offset for populating the matrix\n            col_offset = 0\n\n            # Initialize the counter for the number of row sections imported\n            rows_counter = 0\n\n            # Loop through the subsections of the matrix\n            for m_sec in p_sec.finditer(m_block.group(\"block\")):\n                # Loop through each entry\n                for m_line in p_line.finditer(m_sec.group(0)):\n                    # Store the row; expect base zero so no adjustment needed.\n                    rowval = scast(m_line.group(\"row\"), np.int_)\n\n                    # Loop to fill the row\n                    for i in range(6):\n                        # Store the element\n                        val = scast(m_line.group('e{0}'.format(i)), np.float_)\n\n                        # Only store to matrix if a value actually retrieved.\n                        #  This protects against the final three-column section\n                        #  in blocks for systems with an odd number of atoms.\n                        if not np.isnan(val):\n                            workmtx[rowval, col_offset + i] = val\n                        ## end if\n                    ## next i\n\n                    # Increment the row-read counter\n                    rows_counter += 1\n\n                ## next m_hess_line\n\n                # Last thing is to increment the offset by six. Don't have to\n                #  worry about offsetting for a section only three columns wide\n                #  because that SHOULD only ever occur at the last section\n                col_offset += 6\n\n            ## next m_hess_sec\n\n            # Check to ensure that the column offset is high enough to have\n            #  fully populated the matrix based on the number of atoms. This is\n            #  a check against malformation of the HESS file, resulting in a\n            #  reduced number of sections being retrieved.\n            if not col_offset >= (3 * num_ats):\n                raise HessError(tc, \"Insufficient number of \" + blockname +\n                        \" sections found\",\n                        \"HESS File: \" + hess_path)\n            ## end if\n\n            # Additional cross-check on number of rows imported\n            if (rows_counter % (3*num_ats)) != 0:\n                # Not the right number of rows; complain\n                raise HessError(tc,\n                            blockname + \" row count mismatch\",\n                            \"HESS File: \" + hess_path)\n            ## end if\n\n            # Return the working matrix\n            return workmtx\n\n        ## end def parse_multiblock\n\n        # Imports\n        import re, numpy as np\n        from .error import HessError\n        from .utils import safe_cast as scast\n        from .const import atom_num, atom_sym, PRM, DEF\n\n        # Check if instantiated; complain if so\n        if 'hess_path' in dir(self):\n            raise HessError(HessError.OVERWRITE,\n                    \"Cannot overwrite contents of existing OrcaHess\", \"\")\n        ## end if\n\n        # Retrieve the file target and store\n        hess_path = kwargs['path']\n        self.hess_path = hess_path\n\n        # Open file, read contents, close stream\n        with open(hess_path,'rU') as in_fl:\n            self.in_str = in_fl.read()\n        ## end with\n\n        # Store the source string\n        srcstr = \"HESS File: {0}\".format(hess_path)\n\n        # Check to ensure all required data blocks are found\n        if not OrcaHess.Pat.at_block.search(self.in_str):\n            raise HessError(HessError.AT_BLOCK,\n                    \"Atom specification block not found\", srcstr)\n        ## end if\n        if not OrcaHess.Pat.hess_block.search(self.in_str):\n            raise HessError(HessError.HESS_BLOCK,\n                    \"Hessian block not found\", srcstr)\n        ## end if\n        if not OrcaHess.Pat.freq_block.search(self.in_str):\n            raise HessError(HessError.FREQ_BLOCK,\n                    \"Frequencies block (cm**-1 units) not found\", srcstr)\n        ## end if\n        if not OrcaHess.Pat.modes_block.search(self.in_str):\n            raise HessError(HessError.MODES_BLOCK,\n                    \"Normal modes block not found\", srcstr)\n        ## end if\n        if not OrcaHess.Pat.energy.search(self.in_str):\n            raise HessError(HessError.ENERGY,\n                    \"Energy value not found\", srcstr)\n        ## end if\n        if not OrcaHess.Pat.temp.search(self.in_str):\n            raise HessError(HessError.TEMP,\n                    \"'Actual temperature' value not found\", srcstr)\n        ## end if\n\n\n        #=== Geometry spec block ===#\n        # Store the block\n        m_work = self.Pat.at_block.search(self.in_str)\n\n        # Bring in the number of atoms\n        self.num_ats = np.int_(m_work.group(\"num\"))\n\n        # Initialize the vectors of atomic symbols, masses, and the\n        #  geometry\n        self.atom_syms = []\n        self.atom_masses = []\n        self.geom = []\n\n        # Parse the list of atoms\n        for m in OrcaHess.Pat.at_line.finditer(m_work.group(\"block\")):\n            # Parse the element symbol or atomic number\n            try:\n                # See if it casts as an int\n                num = scast(m.group('el'), np.int_)\n            except (ValueError, TypeError):\n                # Nope, must be letters. Check if valid by poking it into the\n                #  dict. If not valid, should raise another error.\n                num = atom_num[m.group('el').upper()]\n            ## end try\n\n            # If this point is reached, either it's cast ok to an int,\n            #  or the string has been passed through the atom_num dict and\n            #  is a valid element symbol. SO, convert back to atom_sym and\n            #  store - this will also check for an invalid int entry\n            self.atom_syms.append(atom_sym[num])\n\n            # Parse the atomic weight; should be a simple append?\n            self.atom_masses.append(scast(m.group(\"mass\"), np.float_))\n\n            # Build geometry as a 1-D list\n            self.geom.extend([scast(m.group(gp), np.float_) for\n                                                gp in ['c1', 'c2', 'c3']])\n        ## next m\n\n        # Double-check that the number of atoms retrieved matches the\n        #  number indicated in the HESS file. Checks of atomic masses\n        #  and geometry length are presumably redundant.\n        if not len(self.atom_syms) == self.num_ats:\n            raise HessError(HessError.AT_BLOCK, \"Atomic symbol dimension \" +\n                    \"mismatch with HESS atom specification\", srcstr)\n        ## end if\n\n        # Convert geometry to numpy storage form\n        self.geom = np.array(self.geom, dtype=np.float_)\n\n        #=== Hessian and modes ===#\n        # Pull the Hessian\n        self.hess = parse_multiblock(self.in_str, self.Pat.hess_block,\n                self.Pat.hess_sec, self.Pat.hess_line, self.num_ats,\n                \"Hessian\", HessError.HESS_BLOCK)\n\n        # Pull the modes\n        self.modes = parse_multiblock(self.in_str, self.Pat.modes_block,\n                self.Pat.modes_sec, self.Pat.modes_line, self.num_ats,\n                \"modes\", HessError.MODES_BLOCK)\n\n        # Extra check of 'dim' vs 'dim2' on modes\n        m_work = self.Pat.modes_block.search(self.in_str)\n        if scast(m_work.group(\"dim\"), np.int_) != \\\n                            scast(m_work.group(\"dim2\"), np.int_):\n            raise HessError(HessError.MODES_BLOCK,\n                    \"Normal mode block dimension specification mismatch\",\n                    srcstr)\n        ## end if\n\n        #=== Frequencies ===#\n        # Pull the block\n        m_work = self.Pat.freq_block.search(self.in_str)\n\n        # Check that number of frequencies indicated in the block matches\n        #  that expected from the number of atoms\n        if 3*self.num_ats != scast(m_work.group(\"num\"), np.int_):\n            raise HessError(HessError.FREQ_BLOCK,\n                    \"Count in frequencies block != 3 * number of atoms\",\n                    srcstr)\n        ## end if\n\n        # Retrieve the frequencies\n        self.freqs = np.array(\n                [scast(m.group(\"freq\"), np.float_) for m in\n                self.Pat.freq_line.finditer(m_work.group(\"block\"))])\n\n        # Proofread for proper size\n        if not self.freqs.shape[0] == 3*self.num_ats:\n            raise HessError(HessError.FREQ_BLOCK,\n                    \"Number of frequencies != 3 * number of atoms\", srcstr)\n        ## end if\n\n\n        #=== Pull the single values that should always be present ===#\n        # Store the reported energy\n        self.energy = scast(self.Pat.energy.search(self.in_str).group(\"en\"),\n                                                                    np.float_)\n\n        # Store the reported 'actual temperature'\n        self.temp = scast(self.Pat.temp.search(self.in_str).group(\"temp\"),\n                                                                    np.float_)\n\n        #=== Dipole derivatives ===#\n        # Check if block found. Store None if not; otherwise import\n        m_work = self.Pat.dipder_block.search(self.in_str)\n        if m_work is None:\n            self.dipders = None\n        else:\n            # Check that number of derivatives rows indicated in the block\n            #  matches that expected from the number of atoms\n            if 3*self.num_ats != scast(m_work.group(\"dim\"), np.int_):\n                raise HessError(HessError.DIPDER_BLOCK,\n                        \"Count in dipole derivatives block != 3 * # of atoms\",\n                        srcstr)\n            ## end if\n\n            # Retrieve the derivatives\n            self.dipders = np.array(\n                    [[scast(m.group(\"e{0}\".format(i)), np.float_)\n                        for i in range(3)]\n                        for m in self.Pat.dipder_line.finditer(\n                                                    m_work.group(\"block\")) ])\n\n            # Proofread for proper size. Don't have to proofread the width of\n            #  three, since any row not containing three numerical values will\n            #  result in the block getting truncated, per the Regex constrution.\n            if not self.dipders.shape[0] == 3*self.num_ats:\n                raise HessError(HessError.DIPDER_BLOCK,\n                        \"Number of dipole derivative rows != \\\n                        3 * number of atoms\", srcstr)\n            ## end if\n\n            # If max-absolute element is too big, overwrite with None\n            if np.max(np.abs(self.dipders)) > PRM.MAX_SANE_DIPDER:\n                self.dipders = None\n            ## end if\n        ## end if\n\n\n        #=== IR Spectrum ===#\n        # If dipole derivs absent or munged, or if block missing, then skip\n        m_work = self.Pat.ir_block.search(self.in_str)\n        if self.dipders is None or m_work is None:\n            self.ir_comps = None\n            self.ir_mags = None\n        else:\n            # Complain if number of stated modes mismatches expectation\n            if 3*self.num_ats != np.int_(m_work.group(\"dim\")):\n                raise HessError(HessError.IR_BLOCK,\n                        \"Count in IR spectrum block != 3 * # of atoms\",\n                        srcstr)\n            ## end if\n\n            # Pull the blocks\n            self.ir_comps = np.array(\n                    [[scast(m.group(\"e{0}\".format(i)), np.float_)\n                        for i in range(3)]\n                        for m in self.Pat.ir_line.finditer(\n                                                    m_work.group(\"block\")) ])\n            self.ir_mags = np.array(\n                    [scast(m.group(\"mag\"), np.float_)\n                        for m in self.Pat.ir_line.finditer(\n                                                    m_work.group(\"block\")) ])\n\n            # Confirm length of ir_mags conforms. Shouldn't need to check both,\n            #  since they both rely equally on Pat.ir_line.finditer.\n            if 3*self.num_ats != self.ir_mags.shape[0]:\n                raise HessError(HessError.IR_BLOCK,\n                        \"Number of IR spectrum rows != \\\n                        3 * number of atoms\", srcstr)\n            ## end if\n\n            # Confirm match of all frequencies with those reported separately\n            if not np.allclose(\n                    self.freqs,\n                    np.array([np.float_(m.group('freq'))\n                                for m in self.Pat.ir_line.finditer(\n                                m_work.group(\"block\") )]),\n                    rtol=0,\n                    atol=DEF.HESS_IR_MATCH_TOL):\n                raise HessError(HessError.IR_BLOCK,\n                        \"Frequency mismatch between freq and IR blocks\",\n                        srcstr)\n            ## end if\n        ## end if\n\n\n        #=== Polarizability Derivatives ===#\n        # If block is missing, skip it\n        m_work = self.Pat.polder_block.search(self.in_str)\n        if m_work is None:\n            self.polders = None\n        else:\n            # Check that number of derivatives rows indicated in the block\n            #  matches that expected from the number of atoms\n            if 3*self.num_ats != np.int_(m_work.group(\"dim\")):\n                raise HessError(HessError.POLDER_BLOCK,\n                        \"Count in polarizability derivatives block \\\n                        != 3 * # of atoms\", srcstr)\n            ## end if\n\n            # Retrieve the derivatives\n            self.polders = np.array(\n                    [[scast(m.group(\"e{0}\".format(i)), np.float_)\n                        for i in range(6)]\n                        for m in self.Pat.polder_line.finditer(\n                                                    m_work.group(\"block\")) ])\n\n            # Proofread for proper size. Don't have to proofread the width of\n            #  six, since any row not containing six numerical values will\n            #  result in the block getting truncated.\n            if not self.polders.shape[0] == 3*self.num_ats:\n                raise HessError(HessError.POLDER_BLOCK,\n                        \"Number of polarizability derivative rows != \\\n                        3 * number of atoms\", srcstr)\n            ## end if\n        ## end if\n\n\n        #=== Raman Spectrum ===#\n        # If polarizability derivs absent or munged, or if block missing,\n        #  then skip\n        m_work = self.Pat.raman_block.search(self.in_str)\n        if self.polders is None or m_work is None:\n            self.raman_acts = None\n            self.raman_depols = None\n        else:\n            # Complain if number of stated modes mismatches expectation\n            if 3*self.num_ats != np.int_(m_work.group(\"dim\")):\n                raise HessError(HessError.RAMAN_BLOCK,\n                        \"Count in Raman spectrum block != 3 * # of atoms\",\n                        srcstr)\n            ## end if\n\n            # Pull the blocks\n            self.raman_acts = np.array(\n                    [np.float_(m.group(\"act\"))\n                        for m in self.Pat.raman_line.finditer(\n                                                    m_work.group(\"block\")) ])\n            self.raman_depols = np.array(\n                    [np.float_(m.group(\"depol\"))\n                        for m in self.Pat.raman_line.finditer(\n                                                    m_work.group(\"block\")) ])\n\n            # Confirm length of raman_acts conforms. Shouldn't need to check\n            #  both, since they both rely equally on Pat.raman_line.finditer.\n            if 3*self.num_ats != self.raman_acts.shape[0]:\n                raise HessError(HessError.RAMAN_BLOCK,\n                        \"Number of Raman spectrum rows != \\\n                        3 * number of atoms\", srcstr)\n            ## end if\n\n            # Confirm match of all frequencies with those reported separately\n            if not np.allclose(\n                    self.freqs,\n                    np.array([np.float_(m.group('freq'))\n                                for m in self.Pat.raman_line.finditer(\n                                m_work.group(\"block\")) ]),\n                    rtol=0,\n                    atol=DEF.HESS_IR_MATCH_TOL):\n                raise HessError(HessError.RAMAN_BLOCK,\n                        \"Frequency mismatch between freq and Raman blocks\",\n                        srcstr)\n            ## end if\n        ## end if\n\n\n        #=== Job list ===#\n        # Check if block found. Store None if not; otherwise import\n        m_work = self.Pat.jobs_block.search(self.in_str)\n        if m_work is None:\n            self.joblist = None\n        else:\n            # Check that number of joblist rows indicated in the block\n            #  matches that expected from the number of atoms\n            if 3*self.num_ats != np.int_(m_work.group(\"dim\")):\n                raise HessError(HessError.JOB_BLOCK,\n                        \"Count in job list block != 3 * # of atoms\", srcstr)\n            ## end if\n\n            # Retrieve the job list\n            self.joblist = np.array(\n                    [[scast(m.group(\"e{0}\".format(i)), np.float_)\n                        for i in range(3)]\n                        for m in self.Pat.jobs_line.finditer(\n                                                    m_work.group(\"block\")) ])\n\n            # Proofread for proper size. Don't have to proofread the width of\n            #  three, since any row not containing three numerical values will\n            #  result in the block getting truncated.\n            if not self.joblist.shape[0] == self.num_ats:\n                raise HessError(HessError.JOB_BLOCK,\n                        \"Number of job list rows != number of atoms\", srcstr)\n            ## end if\n\n            # Convert to boolean\n            self.joblist = np.equal(self.joblist, np.ones_like(self.joblist))\n\n        ## end if\n\n\n        #=== Mass-weighted Hessian -- Eigenvalues ===#\n        # Pull the block; continue only if block is present\n        m_work = self.Pat.eigvals_block.search(self.in_str)\n        if m_work is None:\n            self.mwh_eigvals = None\n        else:\n            # Check that number of eigenvalues indicated in the block matches\n            #  that expected from the number of atoms\n            if 3*self.num_ats != np.int_(m_work.group(\"dim\")):\n                raise HessError(HessError.EIGVAL_BLOCK,\n                        \"Count in MWH eigenvalues block != 3 * number of atoms\",\n                        srcstr)\n            ## end if\n\n            # Retrieve the eigenvalues\n            self.mwh_eigvals = np.array(\n                    [np.float_(m.group(\"eig\")) for m in\n                    self.Pat.eigvals_line.finditer(m_work.group(\"block\"))])\n\n            # Proofread for proper size\n            if not self.mwh_eigvals.shape[0] == 3*self.num_ats:\n                raise HessError(HessError.EIGVAL_BLOCK,\n                        \"Number of MWH eigenvalues != 3 * number of atoms\",\n                        srcstr)\n            ## end if\n\n        ## end if\n\n\n        #=== Mass-weighted Hessian -- Eigenvalues ===#\n        # See if the block is there; import if so\n        m_work = self.Pat.eigvecs_block.search(self.in_str)\n        if m_work is None:\n            self.mwh_eigvecs = None\n        else:\n            # Pull the eigenvectors\n            self.mwh_eigvecs = \\\n                    parse_multiblock(self.in_str, self.Pat.eigvecs_block,\n                    self.Pat.eigvecs_sec, self.Pat.eigvecs_line, self.num_ats,\n                    \"MWH eigenvectors\", HessError.EIGVEC_BLOCK)\n\n            # Extra check of 'dim' vs 'dim2' on modes\n            if scast(m_work.group(\"dim\"), np.int_) != \\\n                                scast(m_work.group(\"dim2\"), np.int_):\n                raise HessError(HessError.EIGVEC_BLOCK,\n                        \"MWH eigenvectors dimension specification mismatch\",\n                        srcstr)", "response": "Loads the OrcaHess Hessian file and returns a new object with the attributes of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a settings class with the switcher.", "response": "def register(self, settings_class=NoSwitcher, *simple_checks,\n                 **conditions):\n        \"\"\"\n        Register a settings class with the switcher. Can be passed the settings\n        class to register or be used as a decorator.\n\n        :param settings_class: The class to register with the provided\n                conditions.\n        :param *simple_checks: A list of conditions for using the settings\n                class. If any of the values are falsy, the class will not be\n                used. If any of the values are callable, they will be called\n                before evaluating.\n        :param **conditions: Values to check. The key specifies which of the\n                check functions (registered with ``add_check``) to use; the\n                value is passed to the check function.\n        \"\"\"\n        if settings_class is NoSwitcher:\n            def decorator(cls):\n                self.register(cls, *simple_checks, **conditions)\n                return cls\n            return decorator\n\n        available_checks = self.checks.keys()\n        for condition in conditions.keys():\n            if condition not in available_checks:\n                raise InvalidCondition(\n                    'There is no check for the condition \"%s\"' % condition)\n\n        self._registry.append((settings_class, simple_checks, conditions))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the next line without consuming it.", "response": "def _peek_buffer(self, i=0):\n        \"\"\"Get the next line without consuming it.\"\"\"\n        while len(self._buffer) <= i:\n            self._buffer.append(next(self._source))\n        return self._buffer[i]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a readline - like function which peeks into the source.", "response": "def _make_readline_peeker(self):\n        \"\"\"Make a readline-like function which peeks into the source.\"\"\"\n        counter = itertools.count(0)\n        def readline():\n            try:\n                return self._peek_buffer(next(counter))\n            except StopIteration:\n                return ''\n        return readline"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconsume the buffer up to the given token. Returns a single string that was consumed.", "response": "def _consume_python_token(self, token):\n        \"\"\"Consume the buffer up to the given token (from _peek_python_tokens).\n\n        Returns a single string that was consumed.\n\n        \"\"\"\n        ret = []\n        line, col = token[3]\n        if line > 1:\n            ret = self._buffer[:line-1]\n            self._buffer[:line-1] = []\n        ret.append(self._buffer[0][:col])\n        self._buffer[0] = self._buffer[0][col:]\n        return ''.join(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_node(self, node, depth):\n        self._topmost_node.add_child(node, bool(depth[1]))\n        self._stack.append((depth, node))", "response": "Add a node to the graph and the stack."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_data(self, atom_syms, coords, bohrs=True):\n\n        # Imports\n        import numpy as np\n        from .const import atom_num, PHYS\n        from .error import XYZError\n\n        # Gripe if already initialized\n        if 'geoms' in dir(self):\n            raise XYZError(XYZError.OVERWRITE,\n                    \"Cannot overwrite contents of existing OpanXYZ\", \"\")\n        ## end if\n\n        # Check and store dimensions\n        if not len(coords.shape) == 1:\n            raise ValueError(\"Coordinates are not a vector\")\n        ## end if\n        if not len(atom_syms.shape) == 1:\n            raise ValueError(\"Atom symbols are not a simple list\")\n        ## end if\n        if not coords.shape[0] == 3 * atom_syms.shape[0]:\n            raise ValueError(\"len(coords) != 3 * len(atom_syms)\")\n        ## end if\n\n        # Proof the atoms list\n        if not all( (atom_syms[i].upper() in atom_num)\n                                for i in range(atom_syms.shape[0]) ):\n            # Invalid atoms specified\n            raise ValueError(\"Invalid atoms specified: {0}\".format(\n                    [(j, atom_syms[j]) for j in\n                        (i for (i, valid) in\n                            enumerate(map(lambda k: k in atom_num, atom_syms))\n                            if not valid\n                        )\n                    ] ))\n        ## end if\n\n        # Ensure the geometry is all numeric\n        if not all(map(np.isreal, coords)):\n            raise ValueError(\"All coordinates must be real numeric\")\n        ## end if\n\n        # Store the number of atoms. Only one geometry. Standard string\n        #  content for things only relevant to file load.\n        self.num_atoms = atom_syms.shape[0]\n        self.num_geoms = 1\n        self.in_str = self.LOAD_DATA_FLAG\n        self.descs = np.array([self.LOAD_DATA_FLAG])\n        self.XYZ_path = self.LOAD_DATA_FLAG\n\n        # Store the atoms as vector\n        self.atom_syms = list(map(str.upper, list(atom_syms)))\n\n        # Store the single geometry by bracketing with an array\n        self.geoms = [coords / (1.0 if bohrs else PHYS.ANG_PER_BOHR)]", "response": "Internal function for making an Opan XYZ object from explicit geom data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload an OpanXYZ geometry object from a file.", "response": "def _load_file(self, XYZ_path, bohrs=False):\n        \"\"\" Initialize OpanXYZ geometry object from OpenBabel file\n\n        Import of an arbitrary number of multiple geometries from an OpenBabel\n        file. All geometries must have the same number and type of atoms,\n        and the ordering of atom types must be retained throughout.\n\n        Parameters\n        ----------\n        XYZ_path\n            |str| --\n            Complete path to the .xyz / .trj file to be read\n\n        bohrs\n            |bool|, optional --\n            Flag for whether coordinates are interpreted as in Bohrs or\n            Angstroms. Default is |False| (Angstroms).\n\n        Raises\n        ------\n        ~opan.error.XYZError\n            (typecode :attr:`~opan.error.XYZError.XYZFILE`)\n            If indicated geometry file is malformed in some fashion\n\n        ~exceptions.IOError\n            If the indicated file does not exist or cannot be read\n\n        \"\"\"\n\n        # Imports\n        import numpy as np\n        from .const import CIC, PHYS, atom_num, atom_sym\n        from .error import XYZError\n        from .utils import safe_cast as scast\n\n        # Complain if already initialized\n        if 'geoms' in dir(self):\n            raise XYZError(XYZError.OVERWRITE,\n                    \"Cannot overwrite contents of existing OpanXYZ\", \"\")\n        ## end if\n\n        # Open file, read contents, close stream\n        # No particular exception handling; that will be the responsibility\n        #  of the calling routine.\n        # May want to add a check for text file format; but, really, a check\n        #  for no-found-geometry-information will likely cover such a case.\n        with open(XYZ_path,'rU') as in_fl:\n            self.XYZ_path = XYZ_path #: Path of file\n            self.in_str = in_fl.read()\n\n        # Check to ensure at least one geom match; else raise some sort of\n        #  error\n        if not OpanXYZ.p_geom.search(self.in_str):\n            raise XYZError(XYZError.XYZFILE,\n                    \"No valid geometry found\",\n                    \"XYZ file: \" + XYZ_path)\n        ## end if\n\n        # Store the number of atoms. XYZ files with multiple geometries will\n        #  be required to have the same number of atoms in all geometries.\n        #  This is fine for Open Anharmonic, but may be highly undesirable\n        #  in other applications.  Beware.\n        # If the .match() call doesn't have a group attribute, catch the\n        #  resulting AttributeError and throw an XYZError. Can't think of any\n        #  other situation that would throw an AttributeError here, so probably\n        #  I don't have to check for a subtype of AttributeError...\n        # Can't think of a need for an else or a finally here\n        try:\n            self.num_atoms = scast(OpanXYZ.p_geom.match(self.in_str)\n                                            .group(\"num\"), np.int_)\n        except AttributeError:\n            raise XYZError(XYZError.XYZFILE,\n                    \"No geometry block found at start of file\",\n                    \"XYZ file: \" + XYZ_path)\n        ## end try\n\n        # Initialize the description vector and geometry array\n        # CANNOT use matrix type for the geometry since it's 3D.\n        # Retriever function for geometry should convert the given slice\n        #  to a vector as an np.matrix, though.\n        # Geometry is constructed as a length-3N vector of\n        #  coordinates, where atom 1's x/y/z coordinates are sequential,\n        #  then atom 2's x/y/z coordinates are sequential, etc.\n        # Multiple geometries in a single XYZ file are stacked in a simple\n        #  array.\n        self.descs = []\n        self.geoms = []\n\n        # Initialize the atom symbols vector\n        self.atom_syms = []\n\n        # Define a counter for the number of geometries. Store as a persistent\n        #  instance variable because it will be useful later.\n        self.num_geoms = 0\n\n        # Loop over the geometry blocks found in the input file\n        for mch in OpanXYZ.p_geom.finditer(self.in_str):\n            # Check that the number of atoms is consistent with the spec\n            #  found in the first geometry block\n            if not scast(mch.group(\"num\"), np.int_) == self.num_atoms:\n                raise XYZError(XYZError.XYZFILE,\n                        \"Non-constant number of atoms in multiple geometry\",\n                        \"XYZ file: \" + XYZ_path)\n            ## end if\n\n            # Store the description for the current geometry\n            self.descs.append(mch.group(\"desc\"))\n\n            # Assemble the coordinates vector and assemble/check the element\n            #  ID vector.\n            # Reset the atom counter and the coordinates vector\n            atom_count = 0\n            coord_vec = np.empty((0,),dtype=np.float_)\n            for line_mch in OpanXYZ.p_coords.finditer(mch.group(\"coord\")):\n                # Check for whether element list has been fully populated\n                if len(self.atom_syms) < self.num_atoms:\n                    # If not, continue populating it; have to check for\n                    #  whether it's an atomic number or an element symbol\n                    if line_mch.group(\"el\").isdigit():\n                        # Atomic number\n                        # Check for valid number\n                        at_num = scast(line_mch.group(\"el\"), np.int_)\n                        if not (CIC.MIN_ATOMIC_NUM <= at_num\n                                                    <= CIC.MAX_ATOMIC_NUM):\n                            raise XYZError(XYZError.XYZFILE,\n                                    \"Geometry #{0}, atom #{1} is an \\\n                                        unsupported element\"\n                                        .format(self.num_geoms, atom_count),\n                                     \"XYZ file: {0}\".format(XYZ_path))\n                        ##end if\n\n                        # Tag on the new symbol\n                        self.atom_syms.append(atom_sym[at_num])\n                    else:\n                        # Element symbol; store as all caps\n                        # Check for valid element, first by catching if the\n                        #  specified element string is even valid\n                        try:\n                            at_num = atom_num[line_mch.group(\"el\").upper()]\n                        except KeyError:\n                            raise XYZError(XYZError.XYZFILE,\n                                    \"Geometry #{0}, atom #{1} is an \\\n                                        unrecognized element\"\n                                        .format(self.num_geoms, atom_count),\n                                     \"XYZ file: {0}\".format(XYZ_path))\n                        ## end try\n\n                        # Tag on the new symbol\n                        self.atom_syms.append(line_mch.group(\"el\").upper())\n                    ## end if\n                else: # List is fully populated\n                    # If so, confirm that the element specified at the current\n                    #  line matches that of the first geometry of the file\n                    # Have to check whether it's an atomic number or symbol.\n                    if line_mch.group(\"el\").isdigit():\n                        # Atomic number; don't need safe cast; must trap for\n                        #  a bad atomic number\n                        at_num = scast(line_mch.group(\"el\"), np.int_)\n                        if not (CIC.MIN_ATOMIC_NUM <= at_num\n                                                    <= CIC.MAX_ATOMIC_NUM):\n                            raise XYZError(XYZError.XYZFILE,\n                                    \"Geometry #{0}, atom #{1} is an \\\n                                        unsupported element\"\n                                        .format(self.num_geoms, atom_count),\n                                     \"XYZ file: {0}\".format(XYZ_path))\n                        ## end if\n                        if not atom_sym[at_num] == self.atom_syms[atom_count]:\n                            raise XYZError(XYZError.XYZFILE,\n                                    \"Geometry #{0}, atom #{1} is inconsistent \\\n                                        with geometry #0\"\n                                        .format(self.num_geoms, atom_count),\n                                     \"XYZ file: {0}\".format(XYZ_path))\n                        ## end if\n\n                    else:\n                        # Element symbol\n                        # Check for valid element, first by catching if the\n                        #  specified element string is even valid\n                        try:\n                            at_num = atom_num[line_mch.group(\"el\").upper()]\n                        except KeyError:\n                            raise XYZError(XYZError.XYZFILE,\n                                    \"Geometry #{0}, atom #{1} is an \\\n                                        unrecognized element\"\n                                        .format(self.num_geoms, atom_count),\n                                     \"XYZ file: {0}\".format(XYZ_path))\n                        ## end try\n                        # Confirm symbol matches the initial geometry\n                        if not line_mch.group(\"el\").upper() == \\\n                                                self.atom_syms[atom_count]:\n                            raise XYZError(XYZError.XYZFILE,\n                                    \"Geometry #{0}, atom #{1} is inconsistent \\\n                                        with geometry #0\"\n                                        .format(self.num_geoms, atom_count),\n                                    \"XYZ file: {0}\".format(XYZ_path))\n                        ## end if\n                    ## end if\n                ## end if\n\n                # Append the three coordinates of the current atom to the\n                #  temp coordinates vector, converting to Bohrs if indicated.\n                # Working in Bohrs is desired because they are atomic units\n                #  and thus are part of the internal unit definition of the\n                #  Hartree.\n                for c_str in range(1,4):\n                    coord_vec = np.concatenate(\n                            (coord_vec, [\n                        scast(line_mch.group(\"c{0}\".format(c_str)), np.float_) /\n                        (1.0 if bohrs else PHYS.ANG_PER_BOHR)\n                                        ]), axis=0)\n                ## next c_str\n\n                # Increment the atom_count for the atom number\n                atom_count += 1\n\n            ## next line_mch\n\n            # Confirm that number of imported coordinates matches the\n            #  number expected from self.num_atoms\n            if not coord_vec.shape[0] == 3*self.num_atoms:\n                raise XYZError(XYZError.XYZFILE,\n                        \"Geometry #{0} atom count is inconsistent\"\n                            .format(self.num_geoms),\n                        \"XYZ file: {0}\".format(XYZ_path))\n            ## end if\n\n            # Assemble the coordinates vector into the actual coordinates\n            #  stack for the XYZ\n            self.geoms.append(coord_vec)\n\n            # Increment the count of the number of geometries. Once the\n            #  'mch' iteration is completed, this will accurately reflect\n            #  the number of geometries read from the file.\n            self.num_geoms += 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geom_iter(self, g_nums):\n        # Using the custom coded pack_tups to not have to care whether the\n        #  input is iterable\n        from .utils import pack_tups\n\n        vals = pack_tups(g_nums)\n        for val in vals:\n            yield self.geom_single(val[0])", "response": "Iterator over a subset of geometries."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the distance between two atoms in a single geometry.", "response": "def dist_single(self, g_num, at_1, at_2):\n        \"\"\" Distance between two atoms.\n\n        Parameters\n        ----------\n        g_num\n            |int| -- Index of the desired geometry\n\n        at_1\n            |int| -- Index of the first atom\n\n        at_2\n            |int| -- Index of the second atom\n\n        Returns\n        -------\n        dist\n            |npfloat_| --\n            Distance in Bohrs between `at_1` and `at_2` from\n            geometry `g_num`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided\n\n        \"\"\"\n\n        # Import used math library function(s)\n        import numpy as np\n        from scipy import linalg as spla\n        from .utils import safe_cast as scast\n\n        # The below errors are explicitly thrown since values are multiplied by\n        #  three when they are used as an index and thus give non-intuitive\n        #  errors in subsequent code.\n        # Complain if at_1 is invalid\n        if not (-self.num_atoms <= at_1 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_1' ({0})\".format(at_1))\n\n        # Complain if at_2 is invalid\n        if not (-self.num_atoms <= at_2 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_2' ({0})\".format(at_2))\n\n        # Should never be necessary (save for badly erroneous calling code),\n        #  but coerce at_1 and at_2 to their floor() values.  This is again\n        #  needed since they are multiplied by three in the index expresssions\n        #  below, and can cause funny behavior when truncated by the indexing\n        at_1 = scast(np.floor(at_1), np.int_)\n        at_2 = scast(np.floor(at_2), np.int_)\n\n        # Calculate the interatomic distance and return. Return identically\n        #  zero if the indices are equal\n        if at_1 == at_2:\n            dist = 0.0\n        else:\n            dist = scast(\n                    spla.norm(self.displ_single(g_num, at_1, at_2)),\n                            np.float_)\n        ## end if\n\n        return dist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef angle_single(self, g_num, at_1, at_2, at_3):\n\n        # Imports\n        import numpy as np\n        from .utils import safe_cast as scast\n        from .utils.vector import vec_angle\n\n        # The below errors are explicitly thrown since they are multiplied by\n        #  three when they are used as an index and thus give non-intuitive\n        #  errors in later code.\n        # Complain if at_1 is invalid\n        if not(-self.num_atoms <= at_1 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_1' ({0})\".format(at_1))\n\n        # Complain if at_2 is invalid\n        if not(-self.num_atoms <= at_2 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_2' ({0})\".format(at_2))\n\n        # Complain if at_3 is invalid\n        if not(-self.num_atoms <= at_3 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_3' ({0})\".format(at_3))\n\n        # Should never be necessary (save for badly erroneous calling code),\n        #  but coerce the at_x to their floor() values.  This is again\n        #  needed since they are multiplied by three in the index expresssions\n        #  below, and can cause funny behavior when truncated by the indexing\n        at_1 = scast(np.floor(at_1), np.int_)\n        at_2 = scast(np.floor(at_2), np.int_)\n        at_3 = scast(np.floor(at_3), np.int_)\n\n        # Complain if at_2 is equal to either at_1 or at_3.  Must factor in\n        #  the possibility of negative indexing via modulo arithmetic.\n        if (at_2 % self.num_atoms) == (at_1 % self.num_atoms):\n            raise ValueError(\"'at_1' and 'at_2' must be different\")\n        if (at_2 % self.num_atoms) == (at_3 % self.num_atoms):\n            raise ValueError(\"'at_2' and 'at_3' must be different\")\n\n        # Trivial return if at_1 and at_3 are the same\n        if (at_1 % self.num_atoms) == (at_3 % self.num_atoms):\n            # Angle is identically zero in this case\n            return 0.0\n        ## end if\n\n        # Store the displacement vectors from at_2 to at_1 and to at_3\n        # The np.float64 type should be retained through the displ_single call.\n        vec_2_1 = self.displ_single(g_num, at_2, at_1)\n        vec_2_3 = self.displ_single(g_num, at_2, at_3)\n\n        # Compute and return the calculated angle, in degrees\n        # v1 {dot} v2 == |v1||v2| * cos(theta)\n        angle = vec_angle(vec_2_1, vec_2_3)\n        return angle", "response": "Return the angle between two atoms in a single geometry."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the dihedral angle among four atoms.", "response": "def dihed_single(self, g_num, at_1, at_2, at_3, at_4):\n        \"\"\" Dihedral/out-of-plane angle among four atoms.\n\n        Returns the out-of-plane angle among four atoms from geometry\n        `g_num`, in degrees.  The reference plane\n        is spanned by `at_1`, `at_2` and `at_3`. The out-of-plane angle is\n        defined such that a positive angle represents a counter-clockwise\n        rotation of the projected `at_3`\\\\ :math:`\\\\rightarrow`\\\\ `at_4`\n        vector with respect to the\n        reference plane when looking from `at_3` toward `at_2`.\n        Zero rotation corresponds to occlusion of `at_1` and `at_4`;\n        that is, the case where\n        the respective rejections of `at_1`\n        :math:`\\\\rightarrow`\\\\ `at_2` and\n        `at_3`\\\\ :math:`\\\\rightarrow`\\\\ `at_4` onto\n        `at_2`\\\\ :math:`\\\\rightarrow`\\\\ `at_3`\n        are ANTI-PARALLEL.\n\n        .. todo:: Pull the above to User Guide eventually, with figures.\n\n        All four atom indices must be distinct. Both of the atom trios 1-2-3\n        and 2-3-4 must be sufficiently nonlinear, as diagnosed by a bend\n        angle different from 0 or 180 degrees by at least\n        :data:`PRM.NON_PARALLEL_TOL <opan.const.PRM.NON_PARALLEL_TOL>`.\n\n        Parameters\n        ----------\n        g_num\n            |int| -- Index of the desired geometry\n\n        at_1\n            |int| -- Index of the first atom\n\n        at_2\n            |int| -- Index of the second atom\n\n        at_3\n            |int| -- Index of the third atom\n\n        at_4\n            |int| -- Index of the fourth atom\n\n        Returns\n        -------\n        dihed\n            |npfloat_| --\n            Out-of-plane/dihedral angle in degrees for the indicated `at_#`,\n            drawn from geometry `g_num`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided\n\n        ~exceptions.ValueError\n            If any indices `at_#` are equal\n\n        ~opan.error.XYZError\n            (typecode :data:`~opan.error.XYZError.DIHED`) If either\n            of the atom trios (1-2-3 or 2-3-4) is too close to linearity\n\n        \"\"\"\n        # library imports\n        import numpy as np\n        from scipy import linalg as spla\n        from .utils.vector import ortho_basis, rej, vec_angle\n        from .utils import safe_cast as scast\n        from .error import XYZError\n        from .const import PRM\n\n        # The below errors are explicitly checked and raised since the indices\n        #  are multiplied by three when they are used as an index\n        #  and thus give non-intuitive errors in later code.\n        # Complain if at_1 is invalid\n        if not(-self.num_atoms <= at_1 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_1' ({0})\".format(at_1))\n\n        # Complain if at_2 is invalid\n        if not(-self.num_atoms <= at_2 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_2' ({0})\".format(at_2))\n\n        # Complain if at_3 is invalid\n        if not(-self.num_atoms <= at_3 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_3' ({0})\".format(at_3))\n\n        # Complain if at_4 is invalid\n        if not(-self.num_atoms <= at_4 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_4' ({0})\".format(at_4))\n\n        # Should never be necessary (save for badly erroneous calling code),\n        #  but coerce the at_x to their floor() values.  This is again\n        #  needed since they are multiplied by three in the index expresssions\n        #  below, and can cause funny behavior when truncated by the indexing\n        at_1 = scast(np.floor(at_1), np.int_)\n        at_2 = scast(np.floor(at_2), np.int_)\n        at_3 = scast(np.floor(at_3), np.int_)\n        at_4 = scast(np.floor(at_4), np.int_)\n\n        # Proofread the atom numbers. Performed by double-iterative scan of\n        #  the atom numbers, converting the index equality test results to\n        #  ints and summing the results.  Since each ats_n is not compared to\n        #  itself, a sum of zero should diagnose the required mutually\n        #  nonidentical indices.\n        #\n        # Pile the atom indices into a vector\n        ats = [at_1, at_2, at_3, at_4]\n\n        # Scan over the vector of indices pairwise without repetition, and\n        #  without examining for at_i == at_i (which is trivially and always\n        #  True).  Store the outcomes as integers (True == 1; False == 0)\n        ats_test = [int(ats[x] == ats[y]) for x in range(4) \\\n                                        for y in range(x+1,4)]\n\n        # For a proper set of indices, the sum over ats_test will be zero.\n        if sum(ats_test) > 0:\n            # Improper set of indices; at least one pair is duplicated.\n            #  Collate the duplicative pairings and raise ValueError.\n            #  np.triu_indices generates index pairs in the same sequence as\n            #  the above double iteration over ats, but as a list of two\n            #  np.arrays.  column_stack puts them together as column vectors,\n            #  allowing the conditional iteration over x to select only those\n            #  index pairs that correspond to duplicated indices.  The\n            #  resulting filtered pairs are converted to tuples for concise\n            #  formatting in the output.\n            ats_pairs = [tuple(np.column_stack(np.triu_indices(4,1))[x])\n                                        for x in range(6) if ats_test[x] == 1]\n            raise ValueError(\"Duplicate atom indices: {0}\".format(ats_pairs))\n        ## end if\n\n        # Check to ensure non-collinearity of the 1-2-3 and 2-3-4 atom trios\n        for idx in range(2):\n            # Store the relevant angle\n            ang = self.angle_single(g_num, [at_2, at_3][idx],\n                                         [at_1, at_2][idx],\n                                         [at_3, at_4][idx])\n\n            # Check for whether angle is too close to zero or 180 degrees\n            if np.min([ang, 180.0 - ang]) < PRM.NON_PARALLEL_TOL:\n                # Too close; raise error\n                raise XYZError(XYZError.DIHED,\n                        \"Angle {0} is insufficiently nonlinear\"\n                            .format([(at_2, at_1, at_3),\n                            (at_3, at_2, at_4)][idx]),\n                        \"XYZ file: {0}\".format(self.XYZ_path))\n            ## end if\n        ## next idx\n\n        # Store normalized atomic displacement vector at_2 --> at_3 as that\n        #  defining the projection plane\n        plane_norm = self.displ_single(g_num, at_2, at_3)\n        plane_norm /= spla.norm(plane_norm)\n\n        # Retrieve the orthonormal basis in the projection plane, with the\n        #  first vector being the normalized projection of the at_1 --> at_2\n        #  displacement onto that plane\n        on1, on2 = ortho_basis(plane_norm, \\\n                            self.displ_single(g_num, at_1, at_2))\n\n        # Project the at_3 --> at_4 displacement onto the plane\n        #\n        # Retrieve the \"back-side\" displacement vector\n        back_vec = self.displ_single(g_num, at_3, at_4)\n\n        # Project onto the plane by subtracting out the plane_norm projection\n        #  and re-normalize\n        back_vec = rej(back_vec, plane_norm)\n        back_vec /= spla.norm(back_vec)\n\n        # Calculate the absolute value of the departure of the dihedral/\n        #  out-of-plane angle from 180 degrees as derived from the dot-product\n        #  of on1 and back_vec. Both should be normalized at this point, so\n        #  the calculation is straightforward\n        dihed = vec_angle(back_vec, on1)\n\n        # Given the handedness of the spanning vectors provided by ortho_basis,\n        #  the sign of the dihed departure is that of the dot product\n        #  of back_vec and on2.\n        dihed *= np.sign(np.dot(back_vec, on2))\n\n        # Conversion to the stated typical definition of a dihedral now\n        #  requires addition of 180 degrees.\n        dihed += 180.0\n\n        # Should be set to return the value\n        return dihed"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the displacement vector between two atoms.", "response": "def displ_single(self, g_num, at_1, at_2):\n        \"\"\" Displacement vector between two atoms.\n\n        Returns the displacement vector pointing from `at_1`\n        toward `at_2` from geometry `g_num`.\n        If `at_1` == `at_2` a strict zero vector is returned.\n\n        Displacement vector is returned in units of Bohrs.\n\n        Parameters\n        ----------\n        g_num\n            |int| -- Index of the desired geometry\n\n        at_1\n            |int| -- Index of the first atom\n\n        at_2\n            |int| -- Index of the second atom\n\n        Returns\n        -------\n        displ\n            length-3 |npfloat_| --\n            Displacement vector from `at_1` to `at_2`\n\n        Raises\n        ------\n        ~exceptions.IndexError\n            If an invalid (out-of-range) `g_num` or `at_#` is provided\n\n        \"\"\"\n\n        # Library imports\n        import numpy as np\n        from .utils import safe_cast as scast\n\n        # The below errors are explicitly thrown since they are multiplied by\n        #  three when they are used as an index and thus give non-intuitive\n        #  errors.\n        # Complain if at_1 is invalid\n        if not (-self.num_atoms <= at_1 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_1' ({0})\".format(at_1))\n\n        # Complain if at_2 is invalid\n        if not (-self.num_atoms <= at_2 < self.num_atoms):\n            raise IndexError(\"Invalid index for 'at_2' ({0})\".format(at_2))\n\n        # Should never be necessary (save for badly erroneous calling code),\n        #  but coerce at_1 and at_2 to their floor() values.  This is again\n        #  needed since they are multiplied by three in the index expresssions\n        #  below, and can cause funny behavior when truncated by the indexing\n        at_1 = scast(np.floor(at_1), np.int_)\n        at_2 = scast(np.floor(at_2), np.int_)\n\n        # If the atom indices are the same, return trivial zero vector\n        if (at_1 % self.num_atoms) == (at_2 % self.num_atoms):\n            return np.array([0.0, 0.0, 0.0])\n        ## end if\n\n        # Retrieve the geometry; np.float_ type should be retained\n        g = self.geom_single(g_num)\n\n        # Calculate the displacement vector and return\n        displ = np.array([ g[i + 3*at_2] - g[i + 3*at_1] for i in range(3) ])\n\n        # Return the displacement vector\n        return displ"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef displ_iter(self, g_nums, ats_1, ats_2, invalid_error=False):\n\n        # Import the tuple-generating function\n        from .utils import pack_tups\n\n        # Print the function inputs if debug mode is on\n        if _DEBUG:  # pragma: no cover\n            print(\"g_nums = {0}\".format(g_nums))\n            print(\"ats_1 = {0}\".format(ats_1))\n            print(\"ats_2 = {0}\".format(ats_2))\n        ## end if\n\n        # Perform the None substitution\n        arglist = self._none_subst(g_nums, ats_1, ats_2)\n\n        # Expand/pack the tuples from the inputs\n        tups = pack_tups(*arglist)\n\n        # Dump the results if debug mode is on\n        if _DEBUG:  # pragma: no cover\n            print(tups)\n        ## end if\n\n        # Construct the generator using the packed tuples.\n        for tup in tups:\n            yield self._iter_return(tup, self.displ_single, invalid_error)", "response": "Iterator over the displacement vectors in Bohrs as with displ_single."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _iter_return(tup, fxn, invalid_error):\n\n        try:\n            val = fxn(*tup)\n        except (IndexError, ValueError):\n            if invalid_error:\n                # Raise the exception if invalid_error indicates\n                raise\n            else:\n                # Otherwise, just return a 'None' value\n                return None\n            ## end if\n        else:\n            # Good value; just generate it\n            return val", "response": "Wrapper for the iter_return method of X_iter methods."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nguessing the external URL for a given local host and port.", "response": "def guess_external_url(local_host, port):\n    \"\"\"Return a URL that is most likely to route to `local_host` from outside.\n\n    The point is that we may be running on a remote host from the user's\n    point of view, so they can't access `local_host` from a Web browser just\n    by typing ``http://localhost:12345/``.\n    \"\"\"\n    if local_host in ['0.0.0.0', '::']:\n        # The server is listening on all interfaces, but we have to pick one.\n        # The system's FQDN should give us a hint.\n        local_host = socket.getfqdn()\n\n        # https://github.com/vfaronov/turq/issues/9\n        match = IPV4_REVERSE_DNS.match(local_host)\n        if match:\n            local_host = '.'.join(reversed(match.groups()))\n        else:\n            match = IPV6_REVERSE_DNS.match(local_host)\n            if match:\n                address_as_int = int(''.join(reversed(match.groups())), 16)\n                local_host = str(IPv6Address(address_as_int))\n\n    if ':' in local_host:\n        # Looks like an IPv6 literal. Has to be wrapped in brackets in a URL.\n        # Also, an IPv6 address can have a zone ID tacked on the end,\n        # like \"%3\". RFC 6874 allows encoding them in URLs as well,\n        # but in my experiments on Windows 8.1, I had more success\n        # removing the zone ID altogether. After all this is just a guess.\n        local_host = '[%s]' % local_host.rsplit('%', 1)[0]\n\n    return 'http://%s:%d/' % (local_host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_column_lengths(self):\n        column_lengths_dict = {\n            name: len(xs)\n            for (name, xs)\n            in self.columns_dict.items()\n        }\n        unique_column_lengths = set(column_lengths_dict.values())\n        if len(unique_column_lengths) != 1:\n            raise ValueError(\n                \"Mismatch between lengths of columns: %s\" % (column_lengths_dict,))", "response": "Check that the columns of the log entry are of the same length or if they are not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize with data from files.", "response": "def new_from_files(self, basepath, basename, repo, \\\n                    bohrs=False, \\\n                    software=_E_SW.ORCA, \\\n                    repo_clobber=False, **kwargs):\n        \"\"\" Initialize with data from files.\n\n        \"\"\"\n\n        # Imports\n        import os\n        from os import path as osp\n        from ..xyz import OpanXYZ as OX\n        from ..grad import OrcaEngrad as OE\n        from ..hess import OrcaHess as OH\n        from .repo import OpanAnharmRepo as OR\n        from ..const import EnumDispDirection as E_DDir, EnumFileType as E_FT\n        from ..const import EnumSoftware as E_SW\n        from ..const import DEF\n        from ..error import AnharmError as ANHErr\n\n##        # Store working directory for restore?\n##        prev_dir = os.getcwd()\n\n        # Complain if anything is already bound\n        if not self.w_xyz == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"XYZ object is already bound\",\n                    \"\")\n        ## end if\n        if not self.w_grad == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"GRAD object is already bound\",\n                    \"\")\n        ## end if\n        if not self.w_hess == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"HESS object is already bound\",\n                    \"\")\n        ## end if\n        if not self.repo == None:\n            raise ANHErr(ANHErr.STATUS,\n                    \"Repository object is already bound\",\n                    \"\")\n        ## end if\n\n        # RESUME: vpt2--factor for loading from different software pkgs\n\n        # Load the three data files\n        self.w_xyz = OX( osp.join(basepath, \\\n                basename + osp.extsep + xyz_ext) )\n        self.w_grad = OE( osp.join(basepath, \\\n                basename + osp.extsep + engrad_ext), \\\n                0, E_DDir.NO_DISP, 0.0 )\n        self.w_hess = OH( osp.join(basepath, \\\n                basename + osp.extsep + hess_ext), \\\n                0, E_DDir.NO_DISP, 0.0 )\n\n        # Only accept new repos for now\n        if not isinstance(repo, str):\n            raise TypeError(\"Must create new repository when loading \" +\n                    \"a new dataset.\")\n        ## end if\n\n        # Repo is string, treat as filename and try to load\n        # Check if it's a complete path\n        # If it's a relative path, prepend the basepath\n        if osp.split(repo[0]) > 0 and not osp.isabs(repo):\n            repo = osp.join(basepath, repo)\n        ## end if\n\n        # Complain if it's a directory\n        if osp.isdir(repo):\n            raise IOError(\"Cannot bind repository -- specified \" +\n                    \"location is a directory\")\n        ## end if\n\n        # If file exists ...\n        if osp.isfile(repo):\n                # Depending on clobber, either delete existing or raise error\n                if repo_clobber:\n                    # Clobber old repo\n                    os.remove(repo)\n                else:\n                    # Raise error\n                    raise IOError(\"Target repository file exists and \" +\n                            \"clobber is disabled.\")\n                ## end if\n            ## end if\n\n        # Should be good to create the repo\n        self.repo = OR(repo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef literal_eval(node_or_string):\n    _safe_names = {\n        'None': None,\n        'True': True,\n        'False': False,\n        'dict': dict,\n        'list': list,\n        'sorted': sorted\n    }\n    \n    if isinstance(node_or_string, basestring):\n        node_or_string = parse(node_or_string, mode='eval')\n        \n    if isinstance(node_or_string, ast.Expression):\n        node_or_string = node_or_string.body\n        \n    def _convert(node):\n        \n        if isinstance(node, ast.Str):\n            return node.s\n        \n        elif isinstance(node, ast.Num):\n            return node.n\n        \n        elif isinstance(node, ast.Tuple):\n            return tuple(map(_convert, node.elts))\n        \n        elif isinstance(node, ast.List):\n            return list(map(_convert, node.elts))\n        \n        elif isinstance(node, ast.Dict):\n            return dict((_convert(k), _convert(v)) for k, v\n                        in zip(node.keys, node.values))\n        \n        elif isinstance(node, ast.Name):\n            if node.id in _safe_names:\n                return _safe_names[node.id]\n        \n        elif isinstance(node, ast.BinOp):\n            left = _convert(node.left)\n            right = _convert(node.right)\n            op = {\n                ast.Add: operator.add,\n                ast.Sub: operator.sub,\n                ast.Mult: operator.mul,\n                ast.Div: operator.div,\n                ast.Mod: operator.mod\n            }.get(type(node.op), None)\n            if op:\n                return op(left, right)\n        \n        elif isinstance(node, ast.Call):\n            func = _convert(node.func)\n            args = map(_convert, node.args)\n            kwargs = dict((kw.arg, _convert(kw.value)) for kw in node.keywords)\n            if node.starargs:\n                args.extend(_convert(node.starargs))\n            if node.kwargs:\n                kwargs.update(_convert(node.kwargs))\n            return func(*args, **kwargs)\n        \n        elif isinstance(node, ast.Attribute):\n            if not node.attr.startswith('_'):\n                return getattr(_convert(node.value), node.attr)\n        \n        raise ValueError('malformed string: %r' % node)\n    return _convert(node_or_string)", "response": "Safely evaluate an expression node or a string containing a Python\n    expression."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef allele_reads_from_locus_reads(locus_reads, n_ref):\n\n    for locus_read in locus_reads:\n        allele_read = AlleleRead.from_locus_read(locus_read, n_ref)\n        if allele_read is None:\n            continue\n        else:\n            yield allele_read", "response": "Returns a generator that yields AlleleRead objects for each of the given locus reads."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reads_overlapping_variant(\n        samfile,\n        variant,\n        chromosome=None,\n        use_duplicate_reads=USE_DUPLICATE_READS,\n        use_secondary_alignments=USE_SECONDARY_ALIGNMENTS,\n        min_mapping_quality=MIN_READ_MAPPING_QUALITY):\n    \"\"\"\n    Find reads in the given SAM/BAM file which overlap the given variant and\n    return them as a list of AlleleRead objects.\n\n    Parameters\n    ----------\n    samfile : pysam.AlignmentFile\n\n    variant : varcode.Variant\n\n    chromosome : str\n\n    use_duplicate_reads : bool\n        Should we use reads that have been marked as PCR duplicates\n\n    use_secondary_alignments : bool\n        Should we use reads at locations other than their best alignment\n\n    min_mapping_quality : int\n        Drop reads below this mapping quality\n\n    only_alt_allele : bool\n        Filter reads to only include those that support the alt allele of\n        the variant.\n\n    Returns sequence of AlleleRead objects.\n    \"\"\"\n    logger.info(\"Gathering reads for %s\", variant)\n    if chromosome is None:\n        chromosome = variant.contig\n\n    logger.info(\n        \"Gathering variant reads for variant %s (chromosome = %s, gene names = %s)\",\n        variant,\n        chromosome,\n        variant.gene_names)\n\n    base1_position, ref, alt = trim_variant(variant)\n\n    if len(ref) == 0:\n        # if the variant is an insertion\n        base1_position_before_variant = base1_position\n        base1_position_after_variant = base1_position + 1\n    else:\n        base1_position_before_variant = base1_position - 1\n        base1_position_after_variant = base1_position + len(ref)\n\n    locus_reads = locus_read_generator(\n        samfile=samfile,\n        chromosome=chromosome,\n        base1_position_before_variant=base1_position_before_variant,\n        base1_position_after_variant=base1_position_after_variant,\n        use_duplicate_reads=use_duplicate_reads,\n        use_secondary_alignments=use_secondary_alignments,\n        min_mapping_quality=min_mapping_quality)\n\n    allele_reads = allele_reads_from_locus_reads(\n        locus_reads=locus_reads,\n        n_ref=len(ref))\n\n    return allele_reads", "response": "Returns a list of AlleleRead objects that are found in the given variant and are not in the same chromosome as the given variant."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reads_overlapping_variants(variants, samfile, **kwargs):\n    chromosome_names = set(samfile.references)\n    for variant in variants:\n        # I imagine the conversation went like this:\n        # A: \"Hey, I have an awesome idea\"\n        # B: \"What's up?\"\n        # A: \"Let's make two nearly identical reference genomes\"\n        # B: \"But...that sounds like it might confuse people.\"\n        # A: \"Nah, it's cool, we'll give the chromosomes different prefixes!\"\n        # B: \"OK, sounds like a good idea.\"\n        if variant.contig in chromosome_names:\n            chromosome = variant.contig\n        elif \"chr\" + variant.contig in chromosome_names:\n            chromosome = \"chr\" + variant.contig\n        else:\n            logger.warn(\n                \"Chromosome '%s' from variant %s not in alignment file %s\",\n                chromosome,\n                variant,\n                samfile.filename)\n            yield variant, []\n            continue\n        allele_reads = reads_overlapping_variant(\n            samfile=samfile,\n            chromosome=chromosome,\n            variant=variant,\n            **kwargs)\n        yield variant, allele_reads", "response": "Generates sequence of tuples each containing a variant and a list of AlleleRead objects that are not in the same chromosome as the variant in the alignment file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary mapping each allele s nucleotide sequence to a list of AlleleRead objects.", "response": "def group_reads_by_allele(allele_reads):\n    \"\"\"\n    Returns dictionary mapping each allele's nucleotide sequence to a list of\n    supporting AlleleRead objects.\n    \"\"\"\n    allele_to_reads_dict = defaultdict(list)\n    for allele_read in allele_reads:\n        allele_to_reads_dict[allele_read.allele].append(allele_read)\n    return allele_to_reads_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reads_to_dataframe(variants_and_allele_reads):\n    df_builder = DataFrameBuilder(\n        AlleleRead,\n        extra_column_fns={\n            \"gene\": lambda variant, _: \";\".join(variant.gene_names),\n        })\n    for variant, allele_reads in variants_and_allele_reads:\n        df_builder.add_many(variant, allele_reads)\n    return df_builder.to_dataframe()", "response": "Converts a list of Variant and AlleleRead objects into a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_locus_read(cls, locus_read, n_ref):\n        sequence = locus_read.sequence\n        reference_positions = locus_read.reference_positions\n\n        # positions of the nucleotides before and after the variant within\n        # the read sequence\n        read_pos_before = locus_read.base0_read_position_before_variant\n        read_pos_after = locus_read.base0_read_position_after_variant\n\n        # positions of the nucleotides before and after the variant on the\n        # reference genome\n        ref_pos_before = reference_positions[read_pos_before]\n\n        if ref_pos_before is None:\n            logger.warn(\n                \"Missing reference pos for nucleotide before variant on read: %s\",\n                locus_read)\n            return None\n\n        ref_pos_after = reference_positions[read_pos_after]\n\n        if ref_pos_after is None:\n            logger.warn(\n                \"Missing reference pos for nucleotide after variant on read: %s\",\n                locus_read)\n            return None\n\n        if n_ref == 0:\n            if ref_pos_after - ref_pos_before != 1:\n                # if the number of nucleotides skipped isn't the same\n                # as the number of reference nucleotides in the variant then\n                # don't use this read\n                logger.debug(\n                    \"Positions before (%d) and after (%d) variant should be adjacent on read %s\",\n                    ref_pos_before,\n                    ref_pos_after,\n                    locus_read)\n                return None\n\n            # insertions require a sequence of non-aligned bases\n            # followed by the subsequence reference position\n            ref_positions_for_inserted = reference_positions[\n                read_pos_before + 1:read_pos_after]\n            if any(insert_pos is not None for insert_pos in ref_positions_for_inserted):\n                # all these inserted nucleotides should *not* align to the\n                # reference\n                logger.debug(\n                    \"Skipping read, inserted nucleotides shouldn't map to reference\")\n                return None\n        else:\n            # substitutions and deletions\n            if ref_pos_after - ref_pos_before != n_ref + 1:\n                # if the number of nucleotides skipped isn't the same\n                # as the number of reference nucleotides in the variant then\n                # don't use this read\n                logger.debug(\n                    (\"Positions before (%d) and after (%d) variant should be \"\n                     \"adjacent on read %s\"),\n                    ref_pos_before,\n                    ref_pos_after,\n                    locus_read)\n                return None\n\n        nucleotides_at_variant_locus = sequence[read_pos_before + 1:read_pos_after]\n\n        prefix = sequence[:read_pos_before + 1]\n        suffix = sequence[read_pos_after:]\n\n        prefix, suffix = convert_from_bytes_if_necessary(prefix, suffix)\n        prefix, suffix = trim_N_nucleotides(prefix, suffix)\n\n        return cls(\n            prefix,\n            nucleotides_at_variant_locus,\n            suffix,\n            name=locus_read.name)", "response": "Returns an AlleleRead object for the specified LocusRead object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nucleotide_counts(variant_reads):\n    variant_seq = get_single_allele_from_reads(variant_reads)\n\n    prefix_suffix_pairs = make_prefix_suffix_pairs(variant_reads)\n    n_reads = len(prefix_suffix_pairs)\n    max_prefix_length = max(len(p) for (p, _) in prefix_suffix_pairs)\n    max_suffix_length = max(len(s) for (_, s) in prefix_suffix_pairs)\n    n_variant_nucleotides = len(variant_seq)\n\n    n_cols = max_prefix_length + max_suffix_length + n_variant_nucleotides\n\n    counts = np.zeros((4, n_cols), dtype=int)\n\n    variant_column_indices = []\n\n    # first fill in the variant nucleotide counts, since they'll\n    # be invariant across all the supporting reads\n    for i, nucleotide in enumerate(variant_seq):\n        variant_col_idx = max_prefix_length + i\n        variant_column_indices.append(variant_col_idx)\n        row_idx = dna_nucleotide_to_index[dna_nucleotide_to_index]\n        counts[row_idx, variant_col_idx] = n_reads\n\n    for p, s in prefix_suffix_pairs:\n        for i, prefix_col_idx in enumerate(range(\n                max_prefix_length - len(p),\n                max_prefix_length)):\n            row_idx = dna_nucleotide_to_index[p[i]]\n            counts[row_idx, prefix_col_idx] += 1\n        for i, suffix_col_idx in enumerate(range(\n                max_prefix_length + n_variant_nucleotides,\n                max_prefix_length + n_variant_nucleotides + len(s))):\n            row_idx = dna_nucleotide_to_index[s[i]]\n            counts[row_idx, suffix_col_idx] += 1\n    return counts, variant_column_indices", "response": "Counts the number of times each nucleotide occur at each position to the base of the specified variant."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef most_common_nucleotides(partitioned_read_sequences):\n    counts, variant_column_indices = nucleotide_counts(\n        partitioned_read_sequences)\n    max_count_per_column = counts.max(axis=0)\n\n    assert len(max_count_per_column) == counts.shape[1]\n    max_nucleotide_index_per_column = np.argmax(counts, axis=0)\n    assert len(max_nucleotide_index_per_column) == counts.shape[1]\n    nucleotides = [\n        index_to_dna_nucleotide[idx]\n        for idx in max_nucleotide_index_per_column\n    ]\n    other_nucleotide_counts = counts.sum(axis=0) - max_count_per_column\n    return \"\".join(nucleotides), max_count_per_column, other_nucleotide_counts", "response": "Returns the most common nucleotide sequence from the left and right of a variant."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef point_displ(pt1, pt2):\n\n    #Imports\n    import numpy as np\n\n    # Make iterable\n    if not np.iterable(pt1):\n        pt1 = np.float64(np.array([pt1]))\n    else:\n        pt1 = np.float64(np.array(pt1).squeeze())\n    ## end if\n    if not np.iterable(pt2):\n        pt2 = np.float64(np.array([pt2]))\n    else:\n        pt2 = np.float64(np.array(pt2).squeeze())\n    ## end if\n\n    # Calculate the displacement vector and return\n    displ = np.matrix(np.subtract(pt2, pt1)).reshape(3,1)\n    return displ", "response": "Calculate the displacement vector between two n - D points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef point_dist(pt1, pt2):\n\n    # Imports\n    from scipy import linalg as spla\n\n    dist = spla.norm(point_displ(pt1, pt2))\n    return dist", "response": "Calculate the Euclidean distance between two n - D points."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef point_rotate(pt, ax, theta):\n\n    # Imports\n    import numpy as np\n\n    # Ensure pt is reducible to 3-D vector.\n    pt = make_nd_vec(pt, nd=3, t=np.float64, norm=False)\n\n    # Calculate the rotation\n    rot_pt = np.dot(mtx_rot(ax, theta, reps=1), pt)\n\n    # Should be ready to return\n    return rot_pt", "response": "Rotate a point around a 3 - D axis through the origin."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef point_reflect(pt, nv):\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n\n    # Ensure pt is reducible to 3-D vector\n    pt = make_nd_vec(pt, nd=3, t=np.float64, norm=False)\n\n    # Transform the point and return\n    refl_pt = np.dot(mtx_refl(nv, reps=1), pt)\n    return refl_pt", "response": "Reflect a 3 - D point through a plane intersecting the origin."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef geom_reflect(g, nv):\n\n    # Imports\n    import numpy as np\n\n    # Force g to n-vector\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n\n    # Transform the geometry and return\n    refl_g = np.dot(mtx_refl(nv, reps=(g.shape[0] // 3)), g) \\\n                .reshape((g.shape[0],1))\n    return refl_g", "response": "Reflection symmetry operation.\n\n    nv is normal vector to reflection plane\n    g is assumed already translated to center of mass @ origin\n\n    .. todo:: Complete geom_reflect docstring"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef symm_op(g, ax, theta, do_refl):\n\n    # Imports\n    import numpy as np\n\n    # Depend on lower functions' geometry vector coercion. Just\n    #  do the rotation and, if indicated, the reflection.\n    gx = geom_rotate(g, ax, theta)\n    if do_refl:\n        gx = geom_reflect(gx, ax)\n    ## end if\n\n    # Should be good to go\n    return gx", "response": "Perform general point symmetry operation on a geometry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef geom_symm_match(g, atwts, ax, theta, do_refl):\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n\n    # Convert g and atwts to n-D vectors\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n    atwts = make_nd_vec(atwts, nd=None, t=np.float64, norm=False)\n\n    # Ensure proper dimensionality\n    if not g.shape[0] == 3 * atwts.shape[0]:\n        raise ValueError(\"Size of 'g' is not 3*size of 'atwts'\")\n    ## end if\n\n    # Calculate transformed geometry\n    gx = symm_op(g, ax, theta, do_refl)\n\n    # Push g to a column vector\n    g = g.reshape((g.shape[0],1))\n\n    # Augment g and gx with imaginary atomic weights\n    ex_wts = atwts.repeat(3,axis=0).T.reshape((atwts.shape[0]*3,1)) * 1.j\n    g = np.add(g, ex_wts)\n    gx = np.add(gx, ex_wts)\n\n##        # Define calc as the outer product of the augmented vectors\n##        calc = np.dot(g.reshape((g.shape[0],1)), \\\n##                            np.reciprocal(gx.reshape((1,gx.shape[0]))))\n##\n##        # Calculate the complex magnitude of each element and take log10,\n##        #  then abs again\n##        calc = np.abs(np.log10(np.abs(calc)))\n\n    # Expand g and gx as column vectors of coordinates\n    calc_g = g.reshape((g.shape[0] // 3, 3))\n    calc_gx = gx.reshape((gx.shape[0] // 3, 3))\n##\n##        # Expand each into a square matrix of identical column vectors\n##        calc_g = calc_g.repeat(g.shape[0], axis=1)\n##        calc_gx = gx.repeat(gx.shape[0], axis=1)\n\n    # Calc is the absolute distance between the calc-ed values,\n    #  scaled by the maximum of the individual atom distances or unity.\n\n    # Calculate the unscaled distances\n    calc = [[spla.norm(np.subtract(calc_g[i,:], calc_gx[j,:])) \\\n                            for j in range(calc_gx.shape[0])] \\\n                            for i in range(calc_g.shape[0])]\n\n    # Calculate the scale factors\n    scale_g = np.array([spla.norm(calc_g[i,:]) for i in \\\n                range(calc_g.shape[0])]).reshape((calc_g.shape[0],1)) \\\n                .repeat(calc_g.shape[0], axis=1)\n    scale_gx = np.array([spla.norm(calc_gx[j,:]) for j in \\\n                range(calc_g.shape[0])]).reshape((1,calc_gx.shape[0])) \\\n                .repeat(calc_gx.shape[0], axis=0)\n    scale = np.maximum(np.maximum(scale_g, scale_gx),\n                np.ones_like(scale_g, dtype=np.float64))\n\n    # Scale calc\n    calc = np.divide(calc, scale)\n\n    # Take the minimum of each row\n    mins = np.min(calc, axis=1)\n\n    # Take the maximum of the minima for the final factor\n    fac = np.max(mins)\n\n    # Using the atomic weights for checking matching can result in 'fac'\n    #  being greater than unity. Return the minimum of fac and unity.\n    fac = min(fac, 1.0)\n    return fac", "response": "Calculates the symmetric match factor of a geometry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef geom_find_rotsymm(g, atwts, ax, improp, \\\n        nmax=_DEF.SYMM_MATCH_NMAX, \\\n        tol=_DEF.SYMM_MATCH_TOL):\n    \"\"\" Identify highest-order symmetry for a geometry on a given axis.\n\n    Regular and improper axes possible.\n\n    .. todo:: Complete geom_find_rotsymm docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Vectorize the geometry\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n\n    # Ensure a 3-D axis vector\n    ax = make_nd_vec(ax, nd=3, t=np.float64, norm=True)\n\n    # Loop downward either until a good axis is found or nval < 1\n    #  Should never traverse below n == 1 for regular rotation check;\n    #  could for improper, though.\n    nval = nmax + 1\n    nfac = 1.0\n    while nfac > tol and nval > 0:\n        nval = nval - 1\n        try:\n            nfac = geom_symm_match(g, atwts, ax, \\\n                                    2*np.pi/nval, improp)\n\n        except ZeroDivisionError as zde:\n            # If it's because nval == zero, ignore. Else re-raise.\n            if nval > 0:\n                raise zde\n            ## end if\n        ## end try\n    ## loop\n\n    # Should be good to return\n    return nval, nfac", "response": "Find the highest - order symmetry for a geometry on a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef geom_check_axis(g, atwts, ax,\n        nmax=_DEF.SYMM_MATCH_NMAX,\n        tol=_DEF.SYMM_MATCH_TOL):\n    \"\"\" [Get max proper order and reflection for an axis]\n\n    .. todo:: Complete geom_parse_axis docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Store the max found rotation order of the geometry.\n    order = geom_find_rotsymm(g, atwts, ax, \\\n                                        False, nmax, tol)[0]\n\n    # Store the presence/absence of a reflection plane.\n    refl = geom_symm_match(g, atwts, ax, 0, True) < tol\n\n    # Return the pair of values for outside handling\n    return order, refl", "response": "Check if a geometry is within an axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geom_find_group(g, atwts, pr_ax, mom, tt, \\\n        nmax=_DEF.SYMM_MATCH_NMAX, \\\n        tol=_DEF.SYMM_MATCH_TOL, \\\n        dig=_DEF.SYMM_ATWT_ROUND_DIGITS,\n        avmax=_DEF.SYMM_AVG_MAX):\n    \"\"\" [Find all(?) proper rotation axes (n > 1) and reflection planes.]\n\n    .. todo:: Complete geom_find_axes docstring INCLUDING NEW HEADER LINE\n\n    DEPENDS on principal axes and moments being sorted such that:\n        I_A <= I_B <= I_C\n\n    Logic flow developed using:\n        1) http://symmetry.otterbein.edu/common/images/flowchart.pdf\n            Accessed 6 Mar 2015 (flow chart)\n        2) Largent et al. J Comp Chem 22: 1637-1642 (2012).\n            doi: 10.1002/jcc.22995\n\n    Helpful examples and descriptions of point groups from:\n        1) Wilson, Decius & Cross. \"Molecular Vibrations.\" New York:\n            Dover (1980), pp 82-85.\n        2) \"Molecular Structures of Organic Compounds -- Symmetry of\n            Molecules.\" Website of Prof. Dr. Stefan Immel, TU Darmstadt.\n            http://http://csi.chemie.tu-darmstadt.de/ak/immel/script/\n            redirect.cgi?filename=http://csi.chemie.tu-darmstadt.de/ak/\n            immel/tutorials/symmetry/index7.html. Accessed 6 Mar 2015.\n\n    Rotational symmetry numbers defined per:\n        Irikura, K. K. \"Thermochemistry: Appendix B: Essential Statistical\n        Thermodynamics.\" Table II. NIST Computational Chemistry Comparison\n        & Benchmark Database. Online resource: http://cccbdb.nist.gov/\n        thermo.asp. Accessed 6 Mar 2015.\n\n    \"\"\"\n    #!TODO: Implement principal axes threshold checking to tell if a\n    #  not-strictly spherical top is far enough from spherical to ignore\n    #  looking for cubic groups.  Ugh. Doesn't find the reflection planes\n    #  in NH3. Going to have to explicitly deal with top type, since axes\n    #  *must* be principal axes of the molecule, and off-principal axes\n    #  will definitely never be symmetry elements.\n    #  If asymmetric, only do pr_ax\n    #  If symmetric, do the unique pr_ax and projections of atoms and\n    #   midpoints normal to that axis\n    #  If spherical, do everything, since every axis is inertially valid.\n    #  If linear, pretty much just checking for inversion center to tell\n    #   between C*v and D*h\n\n    # Imports\n    import numpy as np, itertools as itt\n    from scipy import linalg as spla\n    from ..const import PRM, EnumTopType as ETT\n    from itertools import combinations as nCr\n    from collections import namedtuple\n    from ..error import SymmError\n\n    # Define the Axis class\n    Axis = namedtuple('Axis', 'vector order refl')\n\n    # First, look for linear; exploit the top type, as linear should never\n    #  be mis-attributed\n    if tt == ETT.LINEAR:\n        # Check for plane of symmetry; if there, D*h; if not, C*v\n        #!TODO: Once symmetry element reporting structure is established,\n        #  revise here to report the molecular axis as the symmetry element.\n        if geom_symm_match(g, atwts, pr_ax[:,0], 0., True) < tol:\n            # Has symmetry plane; D*h\n            group = \"D*h\"\n            symm_fac = 2\n            return group, symm_fac\n        else:\n            # No symmetry plane; C*v\n            group = \"C*v\"\n            symm_fac = 1\n            return group, symm_fac\n        ## end if\n    ## end if\n\n    # Then, check for an atom\n    if tt == ETT.ATOM:\n        # Simple return\n        group= \"Kh\"\n        symm_fac = 1\n        return group, symm_fac\n    ## end if\n\n    # Generally, trust that the top classification is going to be more\n    #  rigorous than the symmetry identification.  Thus, Spherical\n    #  will almost certainly indicate a cubic group; Symmetrical, whether\n    #  oblate or prolate, will indicate either a cubic group or a non-cubic\n    #  with a principal rotation axis of order > 2; and Asymmetrical leaves\n    #  room for any group to be found.\n    # (move much of this comment to the docstring once it's working)\n\n    # Vectorize the geometry and atwts\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n    atwts = make_nd_vec(atwts, nd=None, t=np.float64, norm=False)\n\n    # Also make coordinate-split geometry\n    g_coord = g.reshape((g.shape[0] // 3, 3))\n\n    # Handle Spherical case\n    if tt == ETT.SPHERICAL:\n        # Build the list of atom midpoint axes\n        ax_midpts = []\n        for atwt in np.unique(atwts):\n            # Retrieve the sub-geometry\n            g_atwt = g_subset(g, atwts, atwt, dig)\n\n            # Only have axes to store if more than one atom\n            if g_atwt.shape[0] > 3:\n                # Reshape to grouped coordinates (row vectors)\n                g_atwt = g_atwt.reshape((g_atwt.shape[0] // 3, 3))\n\n                # Iterate over all unique index tuples of pairs\n                for tup in nCr(range(g_atwt.shape[0]), 2):\n                    # Just vector-add the appropriate atomic\n                    #  coordinates; no need to normalize.\n                    ax_midpts.append(np.add(*g_atwt[tup,:]))\n                ## next tup\n            ## end if more than one matched atom\n        ## next atwt, to index all midpoint axes in the system\n\n        # Convert to 2-D array\n        ax_midpts = np.array(ax_midpts)\n\n        # Know for a fact that it should be a cubic group. Start looking at\n        #  atom-wise vectors until an order > 1 axis is found.\n        order = i = 0\n        while order < 2 and i < g_coord.shape[0]:\n            # Store the axis\n            ax = g_coord[i,:]\n\n            # Only check if norm is large enough\n            if spla.norm(ax) > PRM.ZERO_VEC_TOL:\n                order, refl = geom_check_axis(g, atwts, ax, nmax, \\\n                                                                    tol)\n            ## end if\n\n            # Increment\n            i += 1\n        ## loop\n\n        # At this point, check to see if nothing found (could happen, e.g.\n        #  in C60 buckyball) and, if not, search midpoints between like\n        #  atoms, again until an order > 1 axis is found.\n        #  Otherwise, store the axis information as the initial reference.\n        if order >= 2:\n            # Found a good axis.  Store as Axis.\n            ref_Axis = Axis(vector=ax, order=order, refl=refl)\n        else:\n            # No good axis found along atom positions. Search midpoints.\n            i = 0\n            while order < 2 and i < len(ax_midpts):\n                # Store the axis\n                ax = ax_midpts[i,:]\n\n                # Only check if norm is large enough\n                if spla.norm(ax) > PRM.ZERO_VEC_TOL:\n                    order, refl = geom_check_axis(g, atwts, ax, \\\n                                                                nmax, tol)\n                ## end if\n\n                # Increment\n                i += 1\n            ## loop\n\n            # If nothing found here, raise exception\n            if order < 2:\n                raise SymmError(SymmError.NOTFOUND,\n                        \"Cubic point group not found in spherical top \" +\n                        \"molecule.\", \"geom_find_group()\")\n            ## end if\n\n            # Store the found vector as Axis\n            ref_Axis = Axis(vector=ax, order=order, refl=refl)\n        ## end if\n\n        #!RESUME: Search for other axes depending on the order of the axis found.\n        return ref_Axis\n\n        ## end if order < 2, triggering check of atom pairs\n\n#   Leftover from originally not trusting top type\n##        # Must actually search for axes &c.\n##        #\n##        # Initialize the container for the principal axes\n##        Axes_pr = []\n##        for ax in [pr_ax[:,i] for i in range(3)]:\n##            order, refl = geom_check_axis(g, atwts, ax, nmax, tol)\n##            if order > 1 or refl:\n##                Axes_pr.append(Axis(vector=ax, order=order, refl=refl))\n##            ## end if\n##        ## next ax\n##        return Axes_pr\n##\n##        # What is the max order found?\n##        # If < 3, asym or sph\n##        # If >=3, sym or sph; if multiple >2 then sph definitely\n##\n#    Not doing it this way (brute force) any more.\n##        # Initialize the axes list to the principal axes (matrix of column\n##        #  vectors)\n##        ax_list = pr_ax\n##\n##        # Vectorize the geometry\n##        g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n##\n##        # Break into 3-vectors\n##        g_vecs = np.array(np.split(g, g.shape[0] // 3))\n##\n##        # Add all the atom displacements to the axes list\n##        ax_list = np.column_stack((ax_list, g_vecs.T))\n##\n##        # In each block of atom types, add axes up to 5th-order midpoints\n##        for atwt in np.unique(atwts):\n##            # Retrieve the sub-geometry\n##            g_atwt = g_subset(g, atwts, atwt, dig)\n##\n##            # Reshape to grouped coordinates (row vectors)\n##            g_atwt = g_atwt.reshape((g_atwt.shape[0] // 3, 3))\n##\n##            # If more than one atom with the given weight, start at pairs\n##            #  and go up from there\n##            if g_atwt.shape[0] >= 2:\n##                for grp_order in range(2, 1 + min(avmax, g_atwt.shape[0])):\n##                    # Retrieve all unique index tuples for the indicated order\n##                    for tup in nCr(range(g_atwt.shape[0]), grp_order):\n##                        # Just vector-add the appropriate atomic coordinates.\n##                        #  No need to normalize or anything.\n##                        ax_list = np.column_stack((ax_list, \\\n##                                reduce(np.add,[g_atwt[i,:] for i in tup]).T))\n##                    ## next tup\n##                ## next order\n##            ## end if\n##        ## next atwt\n##\n##        # Scrub any collinear axes down to uniques\n##        # Filter parallel axes\n##        i = 0\n##        while i < ax_list.shape[1] - 1:\n##            j = i + 1\n##            while j < ax_list.shape[1]:\n##                # For ANY collinear axes, remove until only one remains.\n##                v1 = ax_list[:,i]\n##                v2 = ax_list[:,j]\n##                if 1 - np.abs(np.dot(v1, v2) / spla.norm(v1) / spla.norm(v2)) \\\n##                                                    < PRM.NON_PARALLEL_TOL:\n##                    # Strip the duplicate vector\n##                    ax_list = np.column_stack((\n##                            [ax_list[:,c] for c in \\\n##                                    range(ax_list.shape[1]) if c <> j]\n##                                                ))\n##\n##                    # Decrement j so that nothing is skipped\n##                    j -= 1\n##\n##                # Increment j\n##                j += 1\n##            ## loop j\n##\n##            # Increment i\n##            i += 1\n##        ## loop i\n##\n##        # Cull any too-small axes\n##        i = 0\n##        while i < ax_list.shape[1]:\n##            # Store vector\n##            v = ax_list[:,i]\n##\n##            # Check magnitude\n##            if spla.norm(v) < PRM.ZERO_VEC_TOL:\n##                # Strip if too small of magnitude\n##                ax_list = np.column_stack((\n##                        [ax_list[:,c] for c in \\\n##                                range(ax_list.shape[1]) if c <> i]\n##                                            ))\n##\n##                # Decrement counter to maintain position in reduced array\n##                i -= 1\n##            ## end if\n##\n##            # Increment counter\n##            i +=1\n##        ## loop\n##\n##        # Search all remaining axes for rotations and reflections\n##        prop_list = []\n##        for v in [ax_list[:,i] for i in range(ax_list.shape[1])]:\n##            order = geom_find_rotsymm(g, atwts, v, \\\n##                                                False, nmax, tol)[0]\n##            #print(\"Prin: \" + str(v))\n##            if order > 1:\n##                # Rotational axis worth reporting is found. Check reflection\n##                if geom_symm_match(g, atwts, v, 0, True) < tol:\n##                    # Does have a reflection\n##                    prop_list.append((v,order,True))\n##                else:\n##                    # No reflection\n##                    prop_list.append((v,order,False))\n##                ## end if\n##            else:\n##                # No rotation, but check for reflection\n##                if geom_symm_match(g, atwts, v, 0, True) < tol:\n##                    # Has a reflection; do report\n##                    prop_list.append((v,1,True))\n##                ## end if\n##            ## end if\n##        ## next v\n##\n##        # Then test all rotations for 2x-order impropers\n##\n##        # Finally test for inversion center\n##\n##        # Then search the point group catalog and assign\n\n\n\n    return prop_list", "response": "Find all point groups in a given group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef g_subset(g, atwts, atwt,\n            digits=_DEF.SYMM_ATWT_ROUND_DIGITS):\n    \"\"\" Extract a subset of a geometry matching a desired atom.\n\n    .. todo:: Complete g_subset docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n\n    # Ensure g and atwts are n-D vectors\n    g = make_nd_vec(g, nd=None, t=np.float64, norm=False)\n    atwts = make_nd_vec(atwts, nd=None, t=np.float64, norm=False)\n\n    # Ensure dims match (should already be checked at object creation...)\n    if not (len(g) == 3*len(atwts)):\n        raise ValueError(\"Dim mismatch [len(g) != 3*len(ats)].\")\n    ## end if\n\n    # Pull into coordinate groups\n    co = np.split(g, g.shape[0] // 3)\n\n    # Filter by the indicated atomic weight\n    cf = [c for (c,a) in zip(co, atwts) if \\\n                    np.round(a, digits) == np.round(atwt, digits)]\n\n    # Expand back to single vector, if possible\n    if not cf == []:\n        g_sub = np.concatenate(cf, axis=0)\n        g_sub = g_sub.reshape((g_sub.shape[0],1))\n    else:\n        g_sub = []\n    ## end if\n\n    # Return the subset\n    return g_sub", "response": "Extract a subset of a geometry matching a desired atom."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_nd_vec(v, nd=None, t=None, norm=False):\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n\n    # Reduce the input to the extent possible\n    out_v = np.array(v, dtype=t).squeeze()\n\n    # Confirm vector form\n    if not len(out_v.shape) == 1:\n        raise ValueError(\"'v' is not reducible to a vector.\")\n    ## end if\n\n    # If indicated, confirm dimensionality\n    if nd and not out_v.shape[0] == nd:\n        raise ValueError(\"'v' dimension is \" + str(out_v.shape[0]) +\n                \", not \" + str(nd))\n    ## end if\n\n    # Normalize, if indicated\n    if norm:\n        out_v = out_v / spla.norm(out_v)\n    ## end if\n\n    # Return result\n    return out_v", "response": "Coerce input to np. array and validate dimensionality."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mtx_refl(nv, reps=1):\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM\n\n    # Ensure |nv| is large enough for confident directionality\n    if spla.norm(nv) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"Norm of 'nv' is too small.\")\n    ## end if\n\n    # Ensure nv is a normalized np.float64 3-vector\n    nv = make_nd_vec(nv, nd=3, t=np.float64, norm=True)\n\n    # Ensure reps is a positive scalar integer\n    if not np.isscalar(reps):\n        raise ValueError(\"'reps' must be scalar.\")\n    ## end if\n    if not np.issubdtype(type(reps), int):\n        raise ValueError(\"'reps' must be an integer.\")\n    ## end if\n    if not reps > 0:\n        raise ValueError(\"'reps' must be a positive integer.\")\n    ## end if\n\n    # Initialize the single-point reflection transform matrix\n    base_mtx = np.zeros(shape=(3,3), dtype=np.float64)\n\n    # Construct the single-point transform matrix\n    for i in range(3):\n        for j in range(i,3):\n            if i==j:\n                base_mtx[i,j] = 1 - 2*nv[i]**2\n            else:\n                base_mtx[i,j] = base_mtx[j,i] = -2*nv[i]*nv[j]\n            ## end if\n        ## next j\n    ## next i\n\n    # Construct the block-diagonal replicated reflection matrix\n    refl_mtx= spla.block_diag(*[base_mtx for i in range(reps)])\n\n    # Return the result\n    return refl_mtx", "response": "Generate the block - diagonal reflection matrix about the given object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the block - diagonal rotation matrix about ax and theta.", "response": "def mtx_rot(ax, theta, reps=1):\n    \"\"\" Generate block-diagonal rotation matrix about ax.\n\n    [copy handedness from somewhere]\n\n    .. todo:: Complete mtx_rot docstring\n\n    \"\"\"\n\n    # Imports\n    import numpy as np\n    from scipy import linalg as spla\n    from ..const import PRM\n\n    # Ensure |ax| is large enough for confident directionality\n    if spla.norm(ax) < PRM.ZERO_VEC_TOL:\n        raise ValueError(\"Norm of 'ax' is too small.\")\n    ## end if\n\n    # Ensure ax is a normalized np.float64 3-vector\n    ax = make_nd_vec(ax, nd=3, t=np.float64, norm=True)\n\n    # Ensure reps is a positive scalar integer\n    if not np.isscalar(reps):\n        raise ValueError(\"'reps' must be scalar.\")\n    ## end if\n    if not np.issubdtype(type(reps), int):\n        raise ValueError(\"'reps' must be an integer.\")\n    ## end if\n    if not reps > 0:\n        raise ValueError(\"'reps' must be a positive integer.\")\n    ## end if\n\n    # Ensure theta is scalar\n    if not np.isscalar(theta):\n        raise ValueError(\"'theta' must be scalar.\")\n    ## end if\n\n    # Assemble the modified Levi-Civita matrix\n    mod_lc = np.array([ [0, -ax[2], ax[1]],\n                    [ax[2], 0, -ax[0]],\n                    [-ax[1], ax[0], 0] ], dtype=np.float64)\n\n    # Compute the outer product of the axis vector\n    ax_oprod = np.dot(ax.reshape((3,1)), ax.reshape((1,3)))\n\n    # Construct the base matrix\n    #  Will need to refer to external math to explain this.\n    base_mtx = np.add(\n                        np.add( (1.0 - np.cos(theta)) * ax_oprod,\n                                            np.cos(theta) * np.eye(3)\n                              ),\n                        np.sin(theta) * mod_lc\n                     )\n\n    # Construct the block-diagonal replicated reflection matrix\n    rot_mtx= spla.block_diag(*[base_mtx for i in range(reps)])\n\n    # Return the result\n    return rot_mtx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mr(items, targets, **kwargs):\n    bins = [(target, []) for target in targets]\n    skip = []\n\n    for item in items:\n        capacities = [target - sum(content) for target, content in bins]\n        weighted = weight(capacities, **kwargs)\n\n        (target, content), capacity, _ = max(zip(bins, capacities, weighted),\n                                             key=operator.itemgetter(2))\n        if item <= capacity:\n            content.append(item)\n        else:\n            skip.append(item)\n    return bins, skip", "response": "Max - Rest\n    Complexity O ( n^2 )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbest - Fit Complexity O ( n^2 )", "response": "def bf(items, targets, **kwargs):\n    \"\"\"Best-Fit\n\n    Complexity O(n^2)\n    \"\"\"\n    bins = [(target, []) for target in targets]\n    skip = []\n\n    for item in items:\n        containers = []\n        capacities = []\n        for target, content in bins:\n            capacity = target - sum(content)\n            if item <= capacity:\n                containers.append(content)\n                capacities.append(capacity - item)\n\n        if len(capacities):\n            weighted = zip(containers, weight(capacities, **kwargs))\n            content, _ = min(weighted, key=operator.itemgetter(1))\n            content.append(item)\n        else:\n            skip.append(item)\n    return bins, skip"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bfd(items, targets, **kwargs):\n    sizes = zip(items, weight(items, **kwargs))\n    sizes = sorted(sizes, key=operator.itemgetter(1), reverse=True)\n    items = map(operator.itemgetter(0), sizes)\n    return bf(items, targets, **kwargs)", "response": "Best - Fit Decreasing\n    Complexity O ( n^2 )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trim_sequences(variant_sequence, reference_context):\n    cdna_prefix = variant_sequence.prefix\n    cdna_alt = variant_sequence.alt\n    cdna_suffix = variant_sequence.suffix\n\n    # if the transcript is on the reverse strand then we have to\n    # take the sequence PREFIX|VARIANT|SUFFIX\n    # and take the complement of XIFFUS|TNAIRAV|XIFERP\n    if reference_context.strand == \"-\":\n        # notice that we are setting the *prefix* to be reverse complement\n        # of the *suffix* and vice versa\n        cdna_prefix, cdna_alt, cdna_suffix = (\n            reverse_complement_dna(cdna_suffix),\n            reverse_complement_dna(cdna_alt),\n            reverse_complement_dna(cdna_prefix)\n        )\n\n    reference_sequence_before_variant = reference_context.sequence_before_variant_locus\n    reference_sequence_after_variant = reference_context.sequence_after_variant_locus\n\n    # trim the reference prefix and the RNA-derived prefix sequences to the same length\n    if len(reference_sequence_before_variant) > len(cdna_prefix):\n        n_trimmed_from_reference = len(reference_sequence_before_variant) - len(cdna_prefix)\n        n_trimmed_from_variant = 0\n    elif len(reference_sequence_before_variant) < len(cdna_prefix):\n        n_trimmed_from_variant = len(cdna_prefix) - len(reference_sequence_before_variant)\n        n_trimmed_from_reference = 0\n    else:\n        n_trimmed_from_variant = 0\n        n_trimmed_from_reference = 0\n\n    reference_sequence_before_variant = reference_sequence_before_variant[\n        n_trimmed_from_reference:]\n    cdna_prefix = cdna_prefix[n_trimmed_from_variant:]\n\n    return (\n        cdna_prefix,\n        cdna_alt,\n        cdna_suffix,\n        reference_sequence_before_variant,\n        reference_sequence_after_variant,\n        n_trimmed_from_reference\n    )", "response": "This function takes a variant sequence and a ReferenceContext and trims the nucleotide sequences from the original sequence to the original sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of mismatching nucleotides between two reference nucleotides before a variant locus.", "response": "def count_mismatches_before_variant(reference_prefix, cdna_prefix):\n    \"\"\"\n    Computes the number of mismatching nucleotides between two cDNA sequences before a variant\n    locus.\n\n    Parameters\n    ----------\n    reference_prefix : str\n        cDNA sequence of a reference transcript before a variant locus\n\n    cdna_prefix : str\n        cDNA sequence detected from RNAseq before a variant locus\n    \"\"\"\n    if len(reference_prefix) != len(cdna_prefix):\n        raise ValueError(\n            \"Expected reference prefix '%s' to be same length as %s\" % (\n                reference_prefix, cdna_prefix))\n    return sum(xi != yi for (xi, yi) in zip(reference_prefix, cdna_prefix))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef count_mismatches_after_variant(reference_suffix, cdna_suffix):\n\n    len_diff = len(cdna_suffix) - len(reference_suffix)\n\n    # if the reference is shorter than the read, the read runs into the intron - these count as\n    # mismatches\n    return sum(xi != yi for (xi, yi) in zip(reference_suffix, cdna_suffix)) + max(0, len_diff)", "response": "Count the number of mismatches between two cDNA sequences after a variant locus."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the offset into the variant sequence that starts from the first complete codon.", "response": "def compute_offset_to_first_complete_codon(\n        offset_to_first_complete_reference_codon,\n        n_trimmed_from_reference_sequence):\n    \"\"\"\n    Once we've aligned the variant sequence to the ReferenceContext, we need\n    to transfer reading frame from the reference transcripts to the variant\n    sequences.\n\n    Parameters\n    ----------\n    offset_to_first_complete_reference_codon : int\n\n    n_trimmed_from_reference_sequence : int\n\n    Returns an offset into the variant sequence that starts from a complete\n    codon.\n    \"\"\"\n    if n_trimmed_from_reference_sequence <= offset_to_first_complete_reference_codon:\n        return (\n            offset_to_first_complete_reference_codon -\n            n_trimmed_from_reference_sequence)\n    else:\n        n_nucleotides_trimmed_after_first_codon = (\n            n_trimmed_from_reference_sequence -\n            offset_to_first_complete_reference_codon)\n        frame = n_nucleotides_trimmed_after_first_codon % 3\n        return (3 - frame) % 3"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a variant sequence and a reference context return the first non - empty subsequence that matches the given reference context.", "response": "def match_variant_sequence_to_reference_context(\n        variant_sequence,\n        reference_context,\n        min_transcript_prefix_length,\n        max_transcript_mismatches,\n        include_mismatches_after_variant=False,\n        max_trimming_attempts=2):\n    \"\"\"\n    Iteratively trim low-coverage subsequences of a variant sequence\n    until it either matches the given reference context or there\n    are too few nucleotides left in the variant sequence.\n\n    Parameters\n    ----------\n    variant_sequence : VariantSequence\n        Assembled sequence from RNA reads, will need to be to be reverse\n        complemented if matching against a reference transcript on the\n        negative strand.\n\n    reference_context : ReferenceContext\n        Sequence of reference transcript before the variant and associated\n        metadata.\n\n    min_transcript_prefix_length : int\n        Minimum number of nucleotides we try to match against a reference\n        transcript.\n\n    max_transcript_mismatches : int\n        Maximum number of nucleotide differences between reference transcript\n        sequence and the variant sequence.\n\n    include_mismatches_after_variant : bool\n        Set to true if the number of mismatches after the variant locus should\n        count toward the total max_transcript_mismatches, which by default\n        only counts mismatches before the variant locus.\n\n    max_trimming_attempts : int\n        How many times do we try trimming the VariantSequence to higher\n        levels of coverage before giving up?\n\n    Returns VariantSequenceInReadingFrame or None\n    \"\"\"\n    variant_sequence_in_reading_frame = None\n\n    # if we can't get the variant sequence to match this reference\n    # context then keep trimming it by coverage until either\n    for i in range(max_trimming_attempts + 1):\n        # check the reverse-complemented prefix if the reference context is\n        # on the negative strand since variant sequence is aligned to\n        # genomic DNA (positive strand)\n        variant_sequence_too_short = (\n            (reference_context.strand == \"+\" and\n                len(variant_sequence.prefix) < min_transcript_prefix_length) or\n            (reference_context.strand == \"-\" and\n                len(variant_sequence.suffix) < min_transcript_prefix_length)\n        )\n        if variant_sequence_too_short:\n            logger.info(\n                \"Variant sequence %s shorter than min allowed %d (iter=%d)\",\n                variant_sequence,\n                min_transcript_prefix_length,\n                i + 1)\n            return None\n\n        variant_sequence_in_reading_frame = \\\n            VariantSequenceInReadingFrame.from_variant_sequence_and_reference_context(\n                variant_sequence=variant_sequence,\n                reference_context=reference_context)\n\n        if variant_sequence_in_reading_frame is None:\n            return None\n\n        n_mismatch_before_variant = (\n            variant_sequence_in_reading_frame.number_mismatches_before_variant)\n        n_mismatch_after_variant = (\n            variant_sequence_in_reading_frame.number_mismatches_after_variant)\n\n        logger.info(\"Iter #%d/%d: %s\" % (\n            i + 1,\n            max_trimming_attempts + 1,\n            variant_sequence_in_reading_frame))\n\n        total_mismatches = n_mismatch_before_variant\n        if include_mismatches_after_variant:\n            total_mismatches += n_mismatch_after_variant\n        if total_mismatches <= max_transcript_mismatches:\n            # if we got a variant sequence + reading frame with sufficiently\n            # few mismatches then call it a day\n            return variant_sequence_in_reading_frame\n\n        logger.info(\n            (\"Too many mismatches (%d) between variant sequence %s and \"\n             \"reference context %s (attempt=%d/%d)\"),\n            n_mismatch_before_variant,\n            variant_sequence,\n            reference_context,\n            i + 1,\n            max_trimming_attempts + 1)\n        # if portions of the sequence are supported by only 1 read\n        # then try trimming to 2 to see if the better supported\n        # subsequence can be better matched against the reference\n        current_min_coverage = variant_sequence.min_coverage()\n        logger.info(\n            \"Trimming to subsequence covered by at least %d reads\",\n            current_min_coverage + 1)\n        variant_sequence = variant_sequence.trim_by_coverage(\n            current_min_coverage + 1)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_variant_sequence_and_reference_context(\n            cls, variant_sequence, reference_context):\n        \"\"\"\n        Combines a VariantSequence with the reading frame implied by a\n        ReferenceContext, reverse complementing if necessary and finding the\n        offset to the first complete codon in the cDNA sequence.\n        Parameters\n        ----------\n        variant_sequence : VariantSequence\n\n        reference_context : ReferenceContext\n\n        Returns a VariantSequenceInReadingFrame object\n        \"\"\"\n        (cdna_prefix, cdna_alt, cdna_suffix,\n            reference_prefix, reference_suffix, n_trimmed_from_reference) = trim_sequences(\n                variant_sequence, reference_context)\n\n        logger.info(\n            (\"cdna_predix='%s', cdna_alt='%s', cdna_suffix='%s', \"\n             \"reference_prefix='%s', reference_suffix='%s', n_trimmed=%d\"),\n            cdna_prefix,\n            cdna_alt,\n            cdna_suffix,\n            reference_prefix,\n            reference_suffix,\n            n_trimmed_from_reference)\n\n        n_mismatch_before_variant = count_mismatches_before_variant(reference_prefix, cdna_prefix)\n        n_mismatch_after_variant = count_mismatches_after_variant(reference_suffix, cdna_suffix)\n\n        ref_codon_offset = reference_context.offset_to_first_complete_codon\n\n        # ReferenceContext carries with an offset to the first complete codon\n        # in the reference sequence. This may need to be adjusted if the reference\n        # sequence is longer than the variant sequence (and thus needs to be trimmed)\n        offset_to_first_complete_codon = compute_offset_to_first_complete_codon(\n            offset_to_first_complete_reference_codon=ref_codon_offset,\n            n_trimmed_from_reference_sequence=n_trimmed_from_reference)\n\n        cdna_sequence = cdna_prefix + cdna_alt + cdna_suffix\n        variant_interval_start = len(cdna_prefix)\n        variant_interval_end = variant_interval_start + len(cdna_alt)\n\n        return VariantSequenceInReadingFrame(\n            cdna_sequence=cdna_sequence,\n            offset_to_first_complete_codon=offset_to_first_complete_codon,\n            variant_cdna_interval_start=variant_interval_start,\n            variant_cdna_interval_end=variant_interval_end,\n            reference_cdna_sequence_before_variant=reference_prefix,\n            reference_cdna_sequence_after_variant=reference_suffix,\n            number_mismatches_before_variant=n_mismatch_before_variant,\n            number_mismatches_after_variant=n_mismatch_after_variant)", "response": "Combines a VariantSequence with the reading frame implied by a ReferenceContext and returns a VariantSequenceInReadingFrame object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef translate_cdna(\n        cdna_sequence,\n        first_codon_is_start=False,\n        mitochondrial=False):\n    \"\"\"\n    Given a cDNA sequence which is aligned to a reading frame, returns\n    the translated protein sequence and a boolean flag indicating whether\n    the translated sequence ended on a stop codon (or just ran out of codons).\n\n    Parameters\n    ----------\n    cdna_sequence : str\n        cDNA sequence which is expected to start and end on complete codons.\n\n    first_codon_is_start : bool\n\n    mitochondrial : bool\n        Use the mitochondrial codon table instead of standard\n        codon to amino acid table.\n    \"\"\"\n    # once we drop some of the prefix nucleotides, we should be in a reading frame\n    # which allows us to translate this protein\n    if mitochondrial:\n        genetic_code = vertebrate_mitochondrial_genetic_code\n    else:\n        genetic_code = standard_genetic_code_with_extra_start_codons\n\n    return genetic_code.translate(\n        cdna_sequence=cdna_sequence,\n        first_codon_is_start=first_codon_is_start)", "response": "Translate a cDNA sequence to a amino acid sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if codons are present in codon table and if not add them.", "response": "def _check_codons(self):\n        \"\"\"\n        If codon table is missing stop codons, then add them.\n        \"\"\"\n        for stop_codon in self.stop_codons:\n            if stop_codon in self.codon_table:\n                if self.codon_table[stop_codon] != \"*\":\n                    raise ValueError(\n                        (\"Codon '%s' not found in stop_codons, but codon table \"\n                         \"indicates that it should be\") % (stop_codon,))\n            else:\n                self.codon_table[stop_codon] = \"*\"\n\n        for start_codon in self.start_codons:\n            if start_codon not in self.codon_table:\n                raise ValueError(\n                    \"Start codon '%s' missing from codon table\" % (\n                        start_codon,))\n\n        for codon, amino_acid in self.codon_table.items():\n            if amino_acid == \"*\" and codon not in self.stop_codons:\n                raise ValueError(\n                    \"Non-stop codon '%s' can't translate to '*'\" % (\n                        codon,))\n\n        if len(self.codon_table) != 64:\n            raise ValueError(\n                \"Expected 64 codons but found %d in codon table\" % (\n                    len(self.codon_table,)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate(self, cdna_sequence, first_codon_is_start=False):\n        if not isinstance(cdna_sequence, str):\n            cdna_sequence = str(cdna_sequence)\n        n = len(cdna_sequence)\n\n        # trim to multiple of 3 length, if there are 1 or 2 nucleotides\n        # dangling at the end of an mRNA they will not affect translation\n        # since ribosome will fall off at that point\n        end_idx = 3 * (n // 3)\n\n        codon_table = self.codon_table\n        if first_codon_is_start and cdna_sequence[:3] in self.start_codons:\n            amino_acid_list = ['M']\n            start_index = 3\n        else:\n            start_index = 0\n            amino_acid_list = []\n\n        ends_with_stop_codon = False\n        for i in range(start_index, end_idx, 3):\n            codon = cdna_sequence[i:i + 3]\n            aa = codon_table[codon]\n\n            if aa == \"*\":\n                ends_with_stop_codon = True\n                break\n            amino_acid_list.append(aa)\n\n        amino_acids = \"\".join(amino_acid_list)\n        return amino_acids, ends_with_stop_codon", "response": "Translate a cDNA sequence into a list of amino acids and a boolean indicating whether the translated sequence ended on a stop codon."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a copy of this GeneticCode object with optional replacement values for all fields.", "response": "def copy(\n            self,\n            name,\n            start_codons=None,\n            stop_codons=None,\n            codon_table=None,\n            codon_table_changes=None):\n        \"\"\"\n        Make copy of this GeneticCode object with optional replacement\n        values for all fields.\n        \"\"\"\n        new_start_codons = (\n            self.start_codons.copy()\n            if start_codons is None\n            else start_codons)\n\n        new_stop_codons = (\n            self.stop_codons.copy()\n            if stop_codons is None\n            else stop_codons)\n\n        new_codon_table = (\n            self.codon_table.copy()\n            if codon_table is None\n            else codon_table)\n\n        if codon_table_changes is not None:\n            new_codon_table.update(codon_table_changes)\n\n        return GeneticCode(\n            name=name,\n            start_codons=new_start_codons,\n            stop_codons=new_stop_codons,\n            codon_table=new_codon_table)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload an OrcaEngrad object from a. engrad file and stores it in the internal dictionary.", "response": "def _load(self, **kwargs):\n        \"\"\" Initialize :class:`OrcaEngrad` object from .engrad file\n\n        Searches indicated file for energy, geometry, gradient, and number\n        of atoms and stores in the corresponding instance variables.\n\n\n        Parameters\n        ----------\n        path\n            |str| -- Complete path to the .engrad file to be read.\n\n        Raises\n        ------\n        ~opan.error.GradError\n\n            Typecode :attr:`~opan.error.GradError.OVERWRITE` --\n            If :class:`~orca.grad.OrcaEngrad` instance has already\n            been instantiated.\n\n            Various typecodes --\n            If indicated gradient file is malformed in some fashion\n\n        ~exceptions.IOError\n            If the indicated file does not exist or cannot be read\n\n        \"\"\"\n\n        # Imports\n        from .const import CIC, atom_sym, atom_num\n        from .error import GradError\n        from .utils import safe_cast as scast\n        import numpy as np\n\n        # Check if instantiated; complain if so\n        if 'engrad_path' in dir(self):\n            raise GradError(GradError.OVERWRITE,\n                    \"Cannot overwrite contents of existing OrcaEngrad\", \"\")\n        ## end if\n\n        # Retrieve the file target\n        engrad_path = kwargs['path']\n\n        # Open file, read contents, close stream\n        with open(engrad_path,'rU') as in_fl:\n            self.engrad_path = engrad_path\n            self.in_str = in_fl.read()\n        ## end with\n\n        # Store source string\n        srcstr = \"ENGRAD File: {0}\".format(engrad_path)\n\n        # Check to ensure all relevant data blocks are found\n        if not self.Pat.numats.search(self.in_str):\n            raise GradError(GradError.NUMATS,\n                    \"Number of atoms specification not found\", srcstr)\n        ## end if\n        if not self.Pat.energy.search(self.in_str):\n            raise GradError(GradError.ENERGY,\n                    \"Energy specification not found\", srcstr)\n        ## end if\n        if not self.Pat.gradblock.search(self.in_str):\n            raise GradError(GradError.GRADBLOCK,\n                    \"Gradient data block not found\", srcstr)\n        ## end if\n        if not self.Pat.atblock.search(self.in_str):\n            raise GradError(GradError.GEOMBLOCK,\n                    \"Geometry data block not found\", srcstr)\n        ## end if\n\n        # Retrieve the number of atoms\n        self.num_ats = np.int_(self.Pat.numats.search(self.in_str).group(\"num\"))\n\n        # Retrieve the energy\n        self.energy = np.float_(self.Pat.energy.search(self.in_str).group(\"en\"))\n\n        # Retrieve the gradient and store numerically. Raise an error if\n        #  the number of gradient elements is not equal to three times the\n        #  number of atoms.\n        grad_str = self.Pat.gradblock.search(self.in_str).group(\"block\")\n        if not len(grad_str.splitlines()) == 3 * self.num_ats:\n            raise GradError(GradError.GRADBLOCK,\n                    \"Gradient block size mismatch with number of atoms\",\n                    srcstr)\n        ## end if\n        self.gradient = np.array(grad_str.splitlines(), dtype=np.float_)\n\n        # Pull and store the geometry block\n        geom_str = self.Pat.atblock.search(self.in_str).group(\"block\")\n\n        # Confirm the correct number of atoms\n        if not len(self.Pat.atline.findall(geom_str)) ==  self.num_ats:\n            raise GradError(GradError.GEOMBLOCK,\n                    \"Inconsistent number of atom coordinates in \\\n                    geometry block\", srcstr)\n        ## end if\n\n        # Initialize the atom symbols list\n        self.atom_syms = []\n\n        # Assemble the coordinates vector and assemble/check the element\n        #  ID vector.\n        # Init the atom counter and the coordinates vector\n        atom_count = 0\n        self.geom = np.zeros((0,), dtype=np.float_)\n\n        # Iterate over the atom spec lines and store element and coordinates\n        for line_mch in self.Pat.atline.finditer(geom_str):\n            # Populate the atom symbols list; have to check for\n            #  whether it's an atomic number or an element symbol\n            if str.isdigit(line_mch.group(\"at\")):\n                # Atomic number\n                # Check for valid number\n                at_num = scast(line_mch.group(\"at\"), np.int_)\n                if not (CIC.MIN_ATOMIC_NUM <= at_num <= CIC.MAX_ATOMIC_NUM):\n                    raise GradError(GradError.GEOMBLOCK,\n                            \"Atom #{0} is an unsupported element\"\n                            .format(atom_count), srcstr)\n                ##end if\n\n                # Tag on the new symbol\n                self.atom_syms.append(atom_sym[at_num])\n\n            else:\n                # Element symbol; store as all caps\n                # Check for valid element, first by catching if the\n                #  specified element string is even valid\n                try:\n                    at_num = atom_num[line_mch.group(\"at\").upper()]\n                except KeyError:\n                    raise GradError(GradError.GEOMBLOCK,\n                            \"Atom #{0} is an unrecognized element\"\n                            .format(atom_count), srcstr)\n                ## end try\n\n                # Tag on the new symbol\n                self.atom_syms.append(line_mch.group(\"at\").upper())\n            ## end if\n\n            # Append the three coordinates of the current atom to the\n            #  temp coordinates vector. Unit conversion not needed since\n            #  ENGRAD files report coordinates in Bohrs.\n            self.geom = np.concatenate(\n                    (\n                        self.geom,\n                        [scast(line_mch.group(\"c{0}\".format(i)), np.float_)\n                                                        for i in range(1,4)]\n                     ))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart listening to changes", "response": "def start(self):\n        \"\"\"\n        Start listening to changes\n        \"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._main_loop)\n        self.thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subscribe(self, field_names):\n        available_controls = dict(self.raildriver.get_controller_list()).values()\n        for field in field_names:\n            if field not in available_controls:\n                raise ValueError('Cannot subscribe to a missing controller {}'.format(field))\n        self.subscribed_fields = field_names", "response": "Subscribe to given fields."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of all channels in the current directory.", "response": "def channels(self, use_cached=False, **params_to_override):\n        \"\"\"\n        Channels() adds a shared interface for single channel and\n        multichannel structures.  It will always return an ordered\n        dict: its first element is the single channel of the pattern\n        (if single-channel) or the channel average (if multichannel);\n        the successive elements are the individual channels' arrays\n        (key: 0,1,..N-1).\n        \"\"\"\n        return collections.OrderedDict({ 'default':self.__call__(**params_to_override) })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setup_xy(self,bounds,xdensity,ydensity,x,y,orientation):\n        self.debug(\"bounds=%s, xdensity=%s, ydensity=%s, x=%s, y=%s, orientation=%s\",bounds,xdensity,ydensity,x,y,orientation)\n        # Generate vectors representing coordinates at which the pattern\n        # will be sampled.\n\n        # CB: note to myself - use slice_._scs if supplied?\n        x_points,y_points = SheetCoordinateSystem(bounds,xdensity,ydensity).sheetcoordinates_of_matrixidx()\n\n        # Generate matrices of x and y sheet coordinates at which to\n        # sample pattern, at the correct orientation\n        self.pattern_x, self.pattern_y = self._create_and_rotate_coordinate_arrays(x_points-x,y_points-y,orientation)", "response": "Generate x and y vectors for the pattern."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate matrix matrices from x and y vectors and rotate them to the specified orientation.", "response": "def _create_and_rotate_coordinate_arrays(self, x, y, orientation):\n        \"\"\"\n        Create pattern matrices from x and y vectors, and rotate them\n        to the specified orientation.\n        \"\"\"\n        # Using this two-liner requires that x increase from left to\n        # right and y decrease from left to right; I don't think it\n        # can be rewritten in so little code otherwise - but please\n        # prove me wrong.\n        pattern_y = np.subtract.outer(np.cos(orientation)*y, np.sin(orientation)*x)\n        pattern_x = np.add.outer(np.sin(orientation)*y, np.cos(orientation)*x)\n        return pattern_x, pattern_y"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_mask(self,p,mat):\n        mask = p.mask\n        ms=p.mask_shape\n        if ms is not None:\n            mask = ms(x=p.x+p.size*(ms.x*np.cos(p.orientation)-ms.y*np.sin(p.orientation)),\n                      y=p.y+p.size*(ms.x*np.sin(p.orientation)+ms.y*np.cos(p.orientation)),\n                      orientation=ms.orientation+p.orientation,size=ms.size*p.size,\n                      bounds=p.bounds,ydensity=p.ydensity,xdensity=p.xdensity)\n        if mask is not None:\n            mat*=mask", "response": "Create if necessary and apply the mask to the given matrix mat."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the dimensions of the matrix into which the pattern is drawn.", "response": "def set_matrix_dimensions(self, bounds, xdensity, ydensity):\n        \"\"\"\n        Change the dimensions of the matrix into which the pattern\n        will be drawn.  Users of this class should call this method\n        rather than changing the bounds, xdensity, and ydensity\n        parameters directly.  Subclasses can override this method to\n        update any internal data structures that may depend on the\n        matrix dimensions.\n        \"\"\"\n        self.bounds = bounds\n        self.xdensity = xdensity\n        self.ydensity = ydensity\n        scs = SheetCoordinateSystem(bounds, xdensity, ydensity)\n        for of in self.output_fns:\n            if isinstance(of, TransferFn):\n                of.initialize(SCS=scs, shape=scs.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef state_push(self):\n        \"Save the state of the output functions, to be restored with state_pop.\"\n        for of in self.output_fns:\n            if hasattr(of,'state_push'):\n                of.state_push()\n        super(PatternGenerator, self).state_push()", "response": "Save the state of the output functions to be restored with state_pop."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestoring the state of the output functions saved by state_push.", "response": "def state_pop(self):\n        \"Restore the state of the output functions saved by state_push.\"\n        for of in self.output_fns:\n            if hasattr(of,'state_pop'):\n                of.state_pop()\n        super(PatternGenerator, self).state_pop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nanimate the current state of the sequence with the given time - function.", "response": "def anim(self, duration, offset=0, timestep=1,\n             label=None, unit=None,\n             time_fn=param.Dynamic.time_fn):\n        \"\"\"\n        duration: The temporal duration to animate in the units\n        defined on the global time function.\n\n        offset: The temporal offset from which the animation is\n        generated given the supplied pattern\n\n        timestep: The time interval between successive frames. The\n        duration must be an exact multiple of the timestep.\n\n        label: A label string to override the label of the global time\n        function (if not None).\n\n        unit: The unit string to override the unit value of the global\n        time function (if not None).\n\n        time_fn: The global time function object that is shared across\n        the time-varying objects that are being sampled.\n\n        Note that the offset, timestep and time_fn only affect\n        patterns parameterized by time-dependent number\n        generators. Otherwise, the frames are generated by successive\n        call to the pattern which may or may not be varying (e.g to\n        view the patterns contained within a Selector).\n        \"\"\"\n        frames = (duration // timestep) + 1\n        if duration % timestep != 0:\n            raise ValueError(\"The duration value must be an exact multiple of the timestep.\")\n\n        if label is None:\n            label = time_fn.label if hasattr(time_fn, 'label') else 'Time'\n\n        unit = time_fn.unit if (not unit and hasattr(time_fn, 'unit')) else unit\n        vmap = HoloMap(kdims=[Dimension(label, unit=unit if unit else '')])\n\n        self.state_push()\n        with time_fn as t:\n            t(offset)\n            for i in range(frames):\n                vmap[t()] = self[:]\n                t += timestep\n        self.state_pop()\n        return vmap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pil(self, **params_to_override):\n        from PIL.Image import fromarray\n        nchans = self.num_channels()\n\n        if nchans in [0, 1]:\n            mode, arr = None, self(**params_to_override)\n            arr = (255.0 / arr.max() * (arr - arr.min())).astype(np.uint8)\n\n        elif nchans in [3,4]:\n            mode = 'RGB' if nchans==3 else 'RGBA'\n            arr = np.dstack(self.channels(**params_to_override).values()[1:])\n            arr = (255.0*arr).astype(np.uint8)\n\n        else:\n            raise ValueError(\"Unsupported number of channels\")\n\n        return fromarray(arr, mode)", "response": "Returns a PIL image for this pattern overriding parameters if provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npushes the state of all the generators in the composite", "response": "def state_push(self):\n        \"\"\"\n        Push the state of all generators\n        \"\"\"\n        super(Composite,self).state_push()\n        for gen in self.generators:\n            gen.state_push()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state_pop(self):\n        super(Composite,self).state_pop()\n        for gen in self.generators:\n            gen.state_pop()", "response": "Pop the state of all generators and the ones in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct combined pattern out of the individual ones.", "response": "def function(self,p):\n        \"\"\"Constructs combined pattern out of the individual ones.\"\"\"\n        generators = self._advance_pattern_generators(p)\n\n        assert hasattr(p.operator,'reduce'),repr(p.operator)+\" does not support 'reduce'.\"\n\n        # CEBALERT: mask gets applied by all PGs including the Composite itself\n        # (leads to redundant calculations in current lissom_oo_or usage, but\n        # will lead to problems/limitations in the future).\n        patterns = [pg(xdensity=p.xdensity,ydensity=p.ydensity,\n                       bounds=p.bounds,mask=p.mask,\n                       x=p.x+p.size*(pg.x*np.cos(p.orientation)- pg.y*np.sin(p.orientation)),\n                       y=p.y+p.size*(pg.x*np.sin(p.orientation)+ pg.y*np.cos(p.orientation)),\n                       orientation=pg.orientation+p.orientation,\n                       size=pg.size*p.size)\n                    for pg in generators]\n        image_array = p.operator.reduce(patterns)\n        return image_array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile_create_table(qualified_name: str, column_statement: str,\n                         primary_key_statement: str) -> str:\n    \"\"\"Postgresql Create Table statement formatter.\"\"\"\n\n    statement = \"\"\"\n                CREATE TABLE {table} ({columns} {primary_keys});\n                \"\"\".format(table=qualified_name,\n                           columns=column_statement,\n                           primary_keys=primary_key_statement)\n    return statement", "response": "Compile the Postgresql Create Table statement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate column definition statement.", "response": "def compile_column(name: str, data_type: str, nullable: bool) -> str:\n    \"\"\"Create column definition statement.\"\"\"\n\n    null_str = 'NULL' if nullable else 'NOT NULL'\n\n    return '{name} {data_type} {null},'.format(name=name,\n                                               data_type=data_type,\n                                               null=null_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a set of predicted effects for a given variant.", "response": "def predicted_effects_for_variant(\n        variant,\n        transcript_id_whitelist=None,\n        only_coding_changes=True):\n    \"\"\"\n    For a given variant, return its set of predicted effects. Optionally\n    filter to transcripts where this variant results in a non-synonymous\n    change to the protein sequence.\n\n    Parameters\n    ----------\n    variant : varcode.Variant\n\n    transcript_id_whitelist : set\n        Filter effect predictions to only include these transcripts\n\n    Returns a varcode.EffectCollection object\n    \"\"\"\n\n    effects = []\n    for transcript in variant.transcripts:\n        if only_coding_changes and not transcript.complete:\n            logger.info(\n                \"Skipping transcript %s for variant %s because it's incomplete\",\n                transcript.name,\n                variant)\n            continue\n\n        if transcript_id_whitelist and transcript.id not in transcript_id_whitelist:\n            logger.info(\n                \"Skipping transcript %s for variant %s because it's not one of %d allowed\",\n                transcript.name,\n                variant,\n                len(transcript_id_whitelist))\n            continue\n        effects.append(variant.effect_on_transcript(transcript))\n\n    effects = EffectCollection(effects)\n\n    n_total_effects = len(effects)\n    logger.info(\"Predicted total %d effects for variant %s\" % (\n        n_total_effects,\n        variant))\n    if not only_coding_changes:\n        return effects\n    else:\n        nonsynonymous_coding_effects = effects.drop_silent_and_noncoding()\n        logger.info(\n            \"Keeping %d/%d effects which affect protein coding sequence for %s: %s\",\n            len(nonsynonymous_coding_effects),\n            n_total_effects,\n            variant,\n            nonsynonymous_coding_effects)\n\n        usable_effects = [\n            effect\n            for effect in nonsynonymous_coding_effects\n            if effect.mutant_protein_sequence is not None\n        ]\n        logger.info(\n            \"Keeping %d effects with predictable AA sequences for %s: %s\",\n            len(usable_effects),\n            variant,\n            usable_effects)\n        return usable_effects"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of transcripts that overlap the amino acid sequence of the given variant.", "response": "def reference_transcripts_for_variant(\n        variant,\n        transcript_id_whitelist=None,\n        only_coding_changes=True):\n    \"\"\"\n    For a given variant, find all the transcripts which overlap the\n    variant and for which it has a predictable effect on the amino acid\n    sequence of the protein.\n    \"\"\"\n    predicted_effects = predicted_effects_for_variant(\n        variant=variant,\n        transcript_id_whitelist=transcript_id_whitelist,\n        only_coding_changes=only_coding_changes)\n    return [effect.transcript for effect in predicted_effects]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of pileup reads at the specified position.", "response": "def pileup_reads_at_position(samfile, chromosome, base0_position):\n    \"\"\"\n    Returns a pileup column at the specified position. Unclear if a function\n    like this is hiding somewhere in pysam API.\n    \"\"\"\n\n    # TODO: I want to pass truncate=True, stepper=\"all\"\n    # but for some reason I get this error:\n    #      pileup() got an unexpected keyword argument 'truncate'\n    # ...even though these options are listed in the docs for pysam 0.9.0\n    #\n    for column in samfile.pileup(\n            chromosome,\n            start=base0_position,\n            end=base0_position + 1):\n\n        if column.pos != base0_position:\n            # if this column isn't centered on the base before the\n            # variant then keep going\n            continue\n\n        return column.pileups\n\n    # if we get to this point then we never saw a pileup at the\n    # desired position\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a generator that yields a sequence of ReadAtLocus records for the given base1_position_before_variant and base1_position_after_variant.", "response": "def locus_read_generator(\n        samfile,\n        chromosome,\n        base1_position_before_variant,\n        base1_position_after_variant,\n        use_duplicate_reads=USE_DUPLICATE_READS,\n        use_secondary_alignments=USE_SECONDARY_ALIGNMENTS,\n        min_mapping_quality=MIN_READ_MAPPING_QUALITY):\n    \"\"\"\n    Generator that yields a sequence of ReadAtLocus records for reads which\n    contain the positions before and after a variant. The actual work to figure\n    out if what's between those positions matches a variant happens later in\n    the `variant_reads` module.\n\n    Parameters\n    ----------\n    samfile : pysam.AlignmentFile\n\n    chromosome : str\n\n    base1_position_before_variant : int\n        Genomic position of reference nucleotide before a variant\n\n    base1_position_after_variant : int\n        Genomic position of reference nucleotide before a variant\n\n    use_duplicate_reads : bool\n        By default, we're ignoring any duplicate reads\n\n    use_secondary_alignments : bool\n        By default we are using secondary alignments, set this to False to\n        only use primary alignments of reads.\n\n    min_mapping_quality : int\n        Drop reads below this mapping quality\n\n    Yields ReadAtLocus objects\n    \"\"\"\n    logger.debug(\n        \"Gathering reads at locus %s: %d-%d\",\n        chromosome,\n        base1_position_before_variant,\n        base1_position_after_variant)\n    base0_position_before_variant = base1_position_before_variant - 1\n    base0_position_after_variant = base1_position_after_variant - 1\n\n    count = 0\n\n    # We get a pileup at the base before the variant and then check to make sure\n    # that reads also overlap the reference position after the variant.\n    #\n    # TODO: scan over a wider interval of pileups and collect reads that don't\n    # overlap the bases before/after a variant due to splicing\n    for pileup_element in pileup_reads_at_position(\n            samfile=samfile,\n            chromosome=chromosome,\n            base0_position=base0_position_before_variant):\n        read = LocusRead.from_pysam_pileup_element(\n            pileup_element,\n            base0_position_before_variant=base0_position_before_variant,\n            base0_position_after_variant=base0_position_after_variant,\n            use_secondary_alignments=use_secondary_alignments,\n            use_duplicate_reads=use_duplicate_reads,\n            min_mapping_quality=min_mapping_quality)\n\n        if read is not None:\n            count += 1\n            yield read\n\n    logger.info(\n        \"Found %d reads overlapping locus %s: %d-%d\",\n        count,\n        chromosome,\n        base1_position_before_variant,\n        base1_position_after_variant)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef locus_reads_dataframe(*args, **kwargs):\n    df_builder = DataFrameBuilder(\n        LocusRead,\n        variant_columns=False,\n        converters={\n            \"reference_positions\": list_to_string,\n            \"quality_scores\": list_to_string,\n        })\n    for locus_read in locus_read_generator(*args, **kwargs):\n        df_builder.add(variant=None, element=locus_read)\n    return df_builder.to_dataframe()", "response": "Returns a DataFrame containing all the reads overlapping a specified locus."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_pysam_pileup_element(\n            cls,\n            pileup_element,\n            base0_position_before_variant,\n            base0_position_after_variant,\n            use_secondary_alignments,\n            use_duplicate_reads,\n            min_mapping_quality,\n            use_soft_clipped_bases=False):\n        \"\"\"\n        Parameters\n        ----------\n        pileup_element : pysam.PileupRead\n\n        base0_position_before_variant : int\n\n        base0_position_after_variant : int\n\n        use_secondary_alignments : bool\n\n        use_duplicate_reads : bool\n\n        min_mapping_quality : int\n\n        use_soft_clipped_bases : bool. Default false; set to true to keep soft-clipped bases\n\n        Returns LocusRead or None\n        \"\"\"\n        read = pileup_element.alignment\n\n        # For future reference,  may get overlapping reads\n        # which can be identified by having the same name\n        name = read.query_name\n\n        if name is None:\n            logger.warn(\n                \"Read missing name at position %d\",\n                base0_position_before_variant + 1)\n            return None\n\n        if read.is_unmapped:\n            logger.warn(\n                \"How did we get unmapped read '%s' in a pileup?\", name)\n            return None\n\n        if pileup_element.is_refskip:\n            # if read sequence doesn't actually align to the reference\n            # base before a variant, skip it\n            logger.debug(\"Skipping pileup element with CIGAR alignment N (intron)\")\n            return None\n        elif pileup_element.is_del:\n            logger.debug(\n                \"Skipping deletion at position %d (read name = %s)\",\n                base0_position_before_variant + 1,\n                name)\n            return None\n\n        if read.is_secondary and not use_secondary_alignments:\n            logger.debug(\"Skipping secondary alignment of read '%s'\", name)\n            return None\n\n        if read.is_duplicate and not use_duplicate_reads:\n            logger.debug(\"Skipping duplicate read '%s'\", name)\n            return None\n\n        mapping_quality = read.mapping_quality\n\n        missing_mapping_quality = mapping_quality is None\n\n        if min_mapping_quality > 0 and missing_mapping_quality:\n            logger.debug(\"Skipping read '%s' due to missing MAPQ\", name)\n            return None\n        elif mapping_quality < min_mapping_quality:\n            logger.debug(\n                \"Skipping read '%s' due to low MAPQ: %d < %d\",\n                read.mapping_quality,\n                mapping_quality,\n                min_mapping_quality)\n            return None\n\n        sequence = read.query_sequence\n\n        if sequence is None:\n            logger.warn(\"Read '%s' missing sequence\", name)\n            return None\n\n        base_qualities = read.query_qualities\n\n        if base_qualities is None:\n            logger.warn(\"Read '%s' missing base qualities\", name)\n            return None\n\n        # Documentation for pysam.AlignedSegment.get_reference_positions:\n        # ------------------------------------------------------------------\n        # By default, this method only returns positions in the reference\n        # that are within the alignment. If full_length is set, None values\n        # will be included for any soft-clipped or unaligned positions\n        # within the read. The returned list will thus be of the same length\n        # as the read.\n        #\n        # Source:\n        # http://pysam.readthedocs.org/en/latest/\n        # api.html#pysam.AlignedSegment.get_reference_positions\n        #\n        # We want a None value for every read position that does not have a\n        # corresponding reference position.\n        reference_positions = read.get_reference_positions(\n            full_length=True)\n\n        # pysam uses base-0 positions everywhere except region strings\n        # Source:\n        # http://pysam.readthedocs.org/en/latest/faq.html#pysam-coordinates-are-wrong\n        if base0_position_before_variant not in reference_positions:\n            logger.debug(\n                \"Skipping read '%s' because first position %d not mapped\",\n                name,\n                base0_position_before_variant)\n            return None\n        else:\n            base0_read_position_before_variant = reference_positions.index(\n                base0_position_before_variant)\n\n        if base0_position_after_variant not in reference_positions:\n            logger.debug(\n                \"Skipping read '%s' because last position %d not mapped\",\n                name,\n                base0_position_after_variant)\n            return None\n        else:\n            base0_read_position_after_variant = reference_positions.index(\n                base0_position_after_variant)\n\n        if isinstance(sequence, bytes):\n            sequence = sequence.decode('ascii')\n\n        if not use_soft_clipped_bases:\n            start = read.query_alignment_start\n            end = read.query_alignment_end\n            sequence = sequence[start:end]\n            reference_positions = reference_positions[start:end]\n            base_qualities = base_qualities[start:end]\n            base0_read_position_before_variant -= start\n            base0_read_position_after_variant -= start\n\n        return cls(\n            name=name,\n            sequence=sequence,\n            reference_positions=reference_positions,\n            quality_scores=base_qualities,\n            base0_read_position_before_variant=base0_read_position_before_variant,\n            base0_read_position_after_variant=base0_read_position_after_variant)", "response": "Creates a LocusRead object from a pysam. PileupRead object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_from_csv_sql(qualified_name: str, delimiter=',', encoding='utf8',\n                      null_str='', header=True, escape_str='\\\\', quote_char='\"',\n                      force_not_null=None, force_null=None):\n    \"\"\"Generate copy from csv statement.\"\"\"\n\n    options = []\n    options.append(\"DELIMITER '%s'\" % delimiter)\n    options.append(\"NULL '%s'\" % null_str)\n\n    if header:\n        options.append('HEADER')\n\n    options.append(\"QUOTE '%s'\" % quote_char)\n    options.append(\"ESCAPE '%s'\" % escape_str)\n\n    if force_not_null:\n        options.append(_format_force_not_null(column_names=force_not_null))\n\n    if force_null:\n        options.append(_format_force_null(column_names=force_null))\n\n    postgres_encoding = get_postgres_encoding(encoding)\n    options.append(\"ENCODING '%s'\" % postgres_encoding)\n\n    copy_sql = _format_copy_csv_sql(qualified_name, copy_options=options)\n\n    return copy_sql", "response": "Generate copy from csv statement."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsorting protein sequences in decreasing order of priority", "response": "def sort_protein_sequences(protein_sequences):\n    \"\"\"\n    Sort protein sequences in decreasing order of priority\n    \"\"\"\n    return list(\n        sorted(\n            protein_sequences,\n            key=ProteinSequence.ascending_sort_key,\n            reverse=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reads_generator_to_protein_sequences_generator(\n        variant_and_overlapping_reads_generator,\n        transcript_id_whitelist=None,\n        protein_sequence_length=PROTEIN_SEQUENCE_LENGTH,\n        min_alt_rna_reads=MIN_ALT_RNA_READS,\n        min_variant_sequence_coverage=MIN_VARIANT_SEQUENCE_COVERAGE,\n        min_transcript_prefix_length=MIN_TRANSCRIPT_PREFIX_LENGTH,\n        max_transcript_mismatches=MAX_REFERENCE_TRANSCRIPT_MISMATCHES,\n        include_mismatches_after_variant=INCLUDE_MISMATCHES_AFTER_VARIANT,\n        max_protein_sequences_per_variant=MAX_PROTEIN_SEQUENCES_PER_VARIANT,\n        variant_sequence_assembly=VARIANT_SEQUENCE_ASSEMBLY):\n    \"\"\"\"\n    Translates each coding variant in a collection to one or more\n    Translation objects, which are then aggregated into equivalent\n    ProteinSequence objects.\n\n    Parameters\n    ----------\n    variant_and_overlapping_reads_generator : generator\n        Yields sequence of varcode.Variant objects paired with sequences\n        of AlleleRead objects that support that variant.\n\n    transcript_id_whitelist : set, optional\n        If given, expected to be a set of transcript IDs which we should use\n        for determining the reading frame around a variant. If omitted, then\n        try to use all overlapping reference transcripts.\n\n    protein_sequence_length : int\n        Try to translate protein sequences of this length, though sometimes\n        we'll have to return something shorter (depending on the RNAseq data,\n        and presence of stop codons).\n\n    min_alt_rna_reads : int\n        Drop variant sequences at loci with fewer than this number of reads\n        supporting the alt allele.\n\n    min_variant_sequence_coverage : int\n        Trim variant sequences to positions supported by at least this number\n        of RNA reads.\n\n    min_transcript_prefix_length : int\n        Minimum number of bases we need to try matching between the reference\n        context and variant sequence.\n\n    max_transcript_mismatches : int\n        Don't try to determine the reading frame for a transcript if more\n        than this number of bases differ.\n\n    include_mismatches_after_variant : bool\n        Include mismatches after the variant locus in the count compared\n        against max_transcript_mismatches.\n\n    max_protein_sequences_per_variant : int\n        Number of protein sequences to return for each ProteinSequence\n\n    variant_cdna_sequence_assembly : bool\n        If True, then assemble variant cDNA sequences based on overlap of\n        RNA reads. If False, then variant cDNA sequences must be fully spanned\n        and contained within RNA reads.\n\n    Yields pairs of a Variant and a list of ProteinSequence objects\n    \"\"\"\n\n    for (variant, overlapping_reads) in variant_and_overlapping_reads_generator:\n        overlapping_transcript_ids = [\n            t.id\n            for t in variant.transcripts\n            if t.is_protein_coding\n        ]\n        _, ref, alt = trim_variant(variant)\n        overlapping_reads = list(overlapping_reads)\n        reads_grouped_by_allele = group_reads_by_allele(overlapping_reads)\n\n        ref_reads = reads_grouped_by_allele.get(ref, [])\n        alt_reads = reads_grouped_by_allele.get(alt, [])\n\n        translations = translate_variant_reads(\n            variant=variant,\n            variant_reads=alt_reads,\n            transcript_id_whitelist=transcript_id_whitelist,\n            protein_sequence_length=protein_sequence_length,\n            min_alt_rna_reads=min_alt_rna_reads,\n            min_variant_sequence_coverage=min_variant_sequence_coverage,\n            min_transcript_prefix_length=min_transcript_prefix_length,\n            max_transcript_mismatches=max_transcript_mismatches,\n            include_mismatches_after_variant=include_mismatches_after_variant,\n            variant_sequence_assembly=variant_sequence_assembly)\n\n        protein_sequences = []\n        for (key, equivalent_translations) in groupby(\n                translations, key_fn=Translation.as_translation_key).items():\n\n            # get the variant read names, transcript IDs and gene names for\n            # protein sequence we're about to construct\n            alt_reads_supporting_protein_sequence, group_transcript_ids, group_gene_names = \\\n                ProteinSequence._summarize_translations(equivalent_translations)\n\n            logger.info(\n                \"%s: %s alt reads supporting protein sequence (gene names = %s)\",\n                key,\n                len(alt_reads_supporting_protein_sequence),\n                group_gene_names)\n\n            protein_sequence = ProteinSequence.from_translation_key(\n                translation_key=key,\n                translations=equivalent_translations,\n                overlapping_reads=overlapping_reads,\n                alt_reads=alt_reads,\n                ref_reads=ref_reads,\n                alt_reads_supporting_protein_sequence=alt_reads_supporting_protein_sequence,\n                transcripts_supporting_protein_sequence=group_transcript_ids,\n                transcripts_overlapping_variant=overlapping_transcript_ids,\n                gene=list(group_gene_names))\n            logger.info(\"%s: protein sequence = %s\" % (key, protein_sequence.amino_acids))\n            protein_sequences.append(protein_sequence)\n\n        # sort protein sequences before returning the top results\n        protein_sequences = sort_protein_sequences(protein_sequences)\n\n        yield variant, protein_sequences[:max_protein_sequences_per_variant]", "response": "Generates a generator that returns all the variant sequences that are paired with the given variant and overlapping reads."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef protein_sequences_generator_to_dataframe(variant_and_protein_sequences_generator):\n    return dataframe_from_generator(\n        element_class=ProteinSequence,\n        variant_and_elements_generator=variant_and_protein_sequences_generator,\n        converters=dict(\n            gene=lambda x: \";\".join(x)))", "response": "Given a generator which yields ( Variant list ) elements returns a pandas. DataFrame\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _summarize_translations(cls, translations):\n        read_name_to_reads = {}\n        gene_names = set([])\n        transcript_ids = set([])\n        for translation in translations:\n            for read in translation.reads:\n                read_name_to_reads[read.name] = read\n            for transcript in translation.reference_context.transcripts:\n                transcript_ids.add(transcript.id)\n                gene_names.add(transcript.gene.name)\n        unique_reads = list(read_name_to_reads.values())\n        return unique_reads, transcript_ids, gene_names", "response": "Summarize a collection of Translation objects into three values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new instance of a ProteinSequence from a TranslationKey.", "response": "def from_translation_key(\n            cls,\n            translation_key,\n            translations,\n            overlapping_reads,\n            ref_reads,\n            alt_reads,\n            alt_reads_supporting_protein_sequence,\n            transcripts_overlapping_variant,\n            transcripts_supporting_protein_sequence,\n            gene):\n        \"\"\"\n        Create a ProteinSequence object from a TranslationKey, along with\n        all the extra fields a ProteinSequence requires.\n        \"\"\"\n        return cls(\n            amino_acids=translation_key.amino_acids,\n            variant_aa_interval_start=translation_key.variant_aa_interval_start,\n            variant_aa_interval_end=translation_key.variant_aa_interval_end,\n            ends_with_stop_codon=translation_key.ends_with_stop_codon,\n            frameshift=translation_key.frameshift,\n            translations=translations,\n            overlapping_reads=overlapping_reads,\n            ref_reads=ref_reads,\n            alt_reads=alt_reads,\n            alt_reads_supporting_protein_sequence=(\n                alt_reads_supporting_protein_sequence),\n            transcripts_overlapping_variant=transcripts_overlapping_variant,\n            transcripts_supporting_protein_sequence=(\n                transcripts_supporting_protein_sequence),\n            gene=gene)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting protein sequences lexicographically by three criteria.", "response": "def ascending_sort_key(self):\n        \"\"\"\n        Sort protein sequences lexicographically by three criteria:\n            - number of unique supporting reads\n            - minimum mismatch versus a supporting reference transcript before variant\n            - minimum mismatch versus a supporting reference transcript after variant\n            - number of supporting reference transcripts\n\n        TODO: Add sort criterion:\n            - min number of reads covering each nucleotide of\n              the protein sequence >= 2\n        \"\"\"\n        return (\n            len(self.alt_reads_supporting_protein_sequence),\n            min(t.number_mismatches_before_variant for t in self.translations),\n            min(t.number_mismatches_after_variant for t in self.translations),\n            len(self.transcripts_supporting_protein_sequence)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a table referencing a delete from using primary key join.", "response": "def make_delete_table(table: Table, delete_prefix='delete_from__') -> Table:\n    \"\"\"Table referencing a delete from using primary key join.\"\"\"\n\n    name = delete_prefix + table.name\n    primary_key = table.primary_key\n    key_names = set(primary_key.column_names)\n    columns = [column for column in table.columns if column.name in key_names]\n    table = Table(name, columns, primary_key)\n\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrecord table column s and primary key columns by specified order.", "response": "def order_table_columns(table: Table, column_names: list) -> Table:\n    \"\"\"Record table column(s) and primary key columns by specified order.\"\"\"\n\n    unordered_columns = table.column_names\n    index_order = (unordered_columns.index(name) for name in column_names)\n    ordered_columns = [table.columns[i] for i in index_order]\n    ordered_pkey_names = [column for column in column_names\n                          if column in table.primary_key_columns]\n    primary_key = PrimaryKey(ordered_pkey_names)\n\n    return Table(table.name, ordered_columns, primary_key, table.schema)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrim common prefixes from the ref and alt sequences Returns the adjusted triplet", "response": "def trim_variant_fields(location, ref, alt):\n    \"\"\"\n    Trims common prefixes from the ref and alt sequences\n\n    Parameters\n    ----------\n    location : int\n        Position (starting from 1) on some chromosome\n\n    ref : str\n        Reference nucleotides\n\n    alt : str\n        Alternate (mutant) nucleotide\n\n    Returns adjusted triplet (location, ref, alt)\n    \"\"\"\n    if len(alt) > 0 and ref.startswith(alt):\n        # if alt is a prefix of the ref sequence then we actually have a\n        # deletion like:\n        #   g.10 GTT > GT\n        # which can be trimmed to\n        #   g.12 'T'>''\n        ref = ref[len(alt):]\n        location += len(alt)\n        alt = \"\"\n    if len(ref) > 0 and alt.startswith(ref):\n        # if ref sequence is a prefix of the alt sequence then we actually have\n        # an insertion like:\n        #   g.10 GT>GTT\n        # which can be trimmed to\n        #   g.11 ''>'T'\n        # Note that we are selecting the position *before* the insertion\n        # (as an arbitrary convention)\n        alt = alt[len(ref):]\n        location += len(ref) - 1\n        ref = \"\"\n    return location, ref, alt"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the start and end offsets of the base - 1 interval of the affected reference positions for the particular variant s primary fields.", "response": "def base0_interval_for_variant_fields(base1_location, ref, alt):\n    \"\"\"\n    Inteval of interbase offsets of the affected reference positions for a\n    particular variant's primary fields (pos, ref, alt).\n\n    Parameters\n    ----------\n    base1_location : int\n        First reference nucleotide of variant or, for insertions, the base\n        before the insertion.\n\n    ref : str\n        Reference nucleotides\n\n    alt : str\n        Alternative nucleotides\n    \"\"\"\n    if len(ref) == 0:\n        # in interbase coordinates, the insertion happens\n        # at the same start/end offsets, since those are already between\n        # reference bases. Furthermore, since the convention for base-1\n        # coordinates is to locate the insertion *after* the position,\n        # in this case the interbase and base-1 positions coincide.\n        base0_start = base1_location\n        base0_end = base1_location\n    else:\n        # substitution or deletion\n        base0_start = base1_location - 1\n        base0_end = base0_start + len(ref)\n    return base0_start, base0_end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the interval of interbase offsets of the affected reference positions for a particular variant.", "response": "def base0_interval_for_variant(variant):\n    \"\"\"\n    Inteval of interbase offsets of the affected reference positions for a\n    particular variant.\n\n    Parameters\n    ----------\n    variant : varcode.Variant\n\n    Returns triplet of (base1_location, ref, alt)\n    \"\"\"\n    base1_location, ref, alt = trim_variant(variant)\n    return base0_interval_for_variant_fields(\n        base1_location=base1_location,\n        ref=ref,\n        alt=alt)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interbase_range_affected_by_variant_on_transcript(variant, transcript):\n    if variant.is_insertion:\n        if transcript.strand == \"+\":\n            # base-1 position of an insertion is the genomic nucleotide\n            # before any inserted mutant nucleotides, so the start offset\n            # of the actual inserted nucleotides is one past that reference\n            # position\n            start_offset = transcript.spliced_offset(variant.start) + 1\n        else:\n            # on the negative strand the genomic base-1 position actually\n            # refers to the transcript base *after* the insertion, so we can\n            # use that as the interbase coordinate for where the insertion\n            # occurs\n            start_offset = transcript.spliced_offset(variant.start)\n        # an insertion happens *between* two reference bases\n        # so the start:end offsets coincide\n        end_offset = start_offset\n    else:\n        # reference bases affected by substitution or deletion defined by\n        # range starting at first affected base\n        offsets = []\n        assert len(variant.ref) > 0\n        for dna_pos in range(variant.start, variant.start + len(variant.ref)):\n            try:\n                offsets.append(transcript.spliced_offset(dna_pos))\n            except ValueError:\n                logger.info(\n                    \"Couldn't find position %d from %s on exons of %s\",\n                    dna_pos,\n                    variant,\n                    transcript)\n        if len(offsets) == 0:\n            raise ValueError(\n                \"Couldn't find any exonic reference bases affected by %s on %s\",\n                variant,\n                transcript)\n        start_offset = min(offsets)\n        end_offset = max(offsets) + 1\n    return (start_offset, end_offset)", "response": "Convert from a variant s position in global genomic coordinates on the genomic coordinates on the specified transcript s mRNA to an interval of interbase offsets on a particular variant s mRNA."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert(conn, qualified_name: str, column_names, records):\n\n    query = create_insert_statement(qualified_name, column_names)\n\n    with conn:\n        with conn.cursor(cursor_factory=NamedTupleCursor) as cursor:\n            for record in records:\n                cursor.execute(query, record)", "response": "Insert a collection of namedtuple records."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninserting many records into the table.", "response": "def insert_many(conn, tablename, column_names, records, chunksize=2500):\n    \"\"\"Insert many records by chunking data into insert statements.\n\n    Notes\n    -----\n    records should be Iterable collection of namedtuples or tuples.\n    \"\"\"\n\n    groups = chunks(records, chunksize)\n    column_str = ','.join(column_names)\n    insert_template = 'INSERT INTO {table} ({columns}) VALUES {values}'.format(\n        table=tablename, columns=column_str, values='{0}')\n\n    with conn:\n        with conn.cursor() as cursor:\n            for recs in groups:\n                record_group = list(recs)\n                records_template_str = ','.join(['%s'] * len(record_group))\n                insert_query = insert_template.format(records_template_str)\n                cursor.execute(insert_query, record_group)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_joined_table_sql(qualified_name, removing_qualified_name, primary_key):\n\n    condition_template = 't.{}=d.{}'\n    where_clause = ' AND '.join(condition_template.format(pkey, pkey)\n                                for pkey in primary_key)\n    delete_statement = (\n        'DELETE FROM {table} t'\n        ' USING {delete_table} d'\n        ' WHERE {where_clause}').format(table=qualified_name,\n                                        delete_table=removing_qualified_name,\n                                        where_clause=where_clause)\n    return delete_statement", "response": "Generate an SQL statement for a joined delete from."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_from_csv(conn, file, qualified_name: str, delimiter=',', encoding='utf8',\n                  null_str='', header=True, escape_str='\\\\', quote_char='\"',\n                  force_not_null=None, force_null=None):\n    \"\"\"Copy file-like object to database table.\n\n    Notes\n    -----\n    Implementation defaults to postgres standard except for encoding.\n    Postgres falls back on client encoding, while function defaults to utf-8.\n\n    References\n    ----------\n    https://www.postgresql.org/docs/current/static/sql-copy.html\n\n    \"\"\"\n\n    copy_sql = copy_from_csv_sql(qualified_name, delimiter, encoding,\n                                 null_str=null_str, header=header,\n                                 escape_str=escape_str, quote_char=quote_char,\n                                 force_not_null=force_not_null,\n                                 force_null=force_null)\n\n    with conn:\n        with conn.cursor() as cursor:\n            cursor.copy_expert(copy_sql, file)", "response": "Copy file - like object to database table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_user_tables(conn):\n\n    query_string = \"select schemaname, relname from pg_stat_user_tables;\"\n    with conn.cursor() as cursor:\n        cursor.execute(query_string)\n        tables = cursor.fetchall()\n\n    return tables", "response": "Retrieve all user tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_primary_keys(conn, table: str, schema='public'):\n\n    query = \"\"\"\\\nSELECT\n  c.constraint_name AS pkey_constraint_name,\n  c.column_name     AS column_name\nFROM\n  information_schema.key_column_usage AS c\n  JOIN information_schema.table_constraints AS t\n    ON t.constraint_name = c.constraint_name\n       AND t.table_catalog = c.table_catalog\n       AND t.table_schema = c.table_schema\n       AND t.table_name = c.table_name\nWHERE t.constraint_type = 'PRIMARY KEY'\n  AND c.table_schema=%s\n  AND c.table_name=%s\nORDER BY c.ordinal_position\"\"\"\n\n    for record in select_dict(conn, query, params=(schema, table)):\n        yield record['column_name']", "response": "Returns a generator that yields the primary key columns for a specific table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the column metadata for the given table.", "response": "def get_column_metadata(conn, table: str, schema='public'):\n    \"\"\"Returns column data following db.Column parameter specification.\"\"\"\n    query = \"\"\"\\\nSELECT\n  attname as name,\n  format_type(atttypid, atttypmod) AS data_type,\n  NOT attnotnull AS nullable\nFROM pg_catalog.pg_attribute\nWHERE attrelid=%s::regclass\n  AND attnum > 0 AND NOT attisdropped\nORDER BY attnum;\"\"\"\n\n    qualified_name = compile_qualified_name(table, schema=schema)\n\n    for record in select_dict(conn, query, params=(qualified_name,)):\n        yield record"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reflect_table(conn, table_name, schema='public'):\n\n    column_meta = list(get_column_metadata(conn, table_name, schema=schema))\n    primary_key_columns = list(get_primary_keys(conn, table_name, schema=schema))\n\n    columns = [Column(**column_data) for column_data in column_meta]\n    primary_key = PrimaryKey(primary_key_columns)\n\n    return Table(table_name, columns, primary_key, schema=schema)", "response": "Reflect basic table attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install_extensions(extensions, **connection_parameters):\n\n    from postpy.connections import connect\n\n    conn = connect(**connection_parameters)\n    conn.autocommit = True\n\n    for extension in extensions:\n        install_extension(conn, extension)", "response": "Install Postgres extensions if available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a status update to the framework scheduler.", "response": "def update(self, status):\n        \"\"\"Sends a status update to the framework scheduler.\n\n        Retrying as necessary until an acknowledgement has been received or the\n        executor is terminated (in which case, a TASK_LOST status update will be\n        sent).\n        See Scheduler.statusUpdate for more information about status update\n        acknowledgements.\n        \"\"\"\n        logging.info('Executor sends status update {} for task {}'.format(\n                     status.state, status.task_id))\n        return self.driver.sendStatusUpdate(encode(status))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef message(self, data):\n        logging.info('Driver sends framework message {}'.format(data))\n        return self.driver.sendFrameworkMessage(data)", "response": "Sends a message to the framework scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterable of tuples containing index controller_name pairs.", "response": "def get_controller_list(self):\n        \"\"\"\n        Returns an iterable of tuples containing (index, controller_name) pairs.\n\n        Controller indexes start at 0.\n\n        You may easily transform this to a {name: index} mapping by using:\n\n        >>> controllers = {name: index for index, name in raildriver.get_controller_list()}\n\n        :return enumerate\n        \"\"\"\n        ret_str = self.dll.GetControllerList().decode()\n        if not ret_str:\n            return []\n        return enumerate(ret_str.split('::'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_controller_value(self, index_or_name, value_type):\n        if not isinstance(index_or_name, int):\n            index = self.get_controller_index(index_or_name)\n        else:\n            index = index_or_name\n        return self.dll.GetControllerValue(index, value_type)", "response": "Returns current min max value of controller at given index or name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_current_time(self):\n        hms = [int(self.get_current_controller_value(i)) for i in range(406, 409)]\n        return datetime.time(*hms)", "response": "Get current time\n\n        :return: datetime.time"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_loco_name(self):\n        ret_str = self.dll.GetLocoName().decode()\n        if not ret_str:\n            return\n        return ret_str.split('.:.')", "response": "Returns the Provider Product and Engine name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of the controller in the controller table.", "response": "def set_controller_value(self, index_or_name, value):\n        \"\"\"\n        Sets controller value\n\n        :param index_or_name integer index or string name\n        :param value float\n        \"\"\"\n        if not isinstance(index_or_name, int):\n            index = self.get_controller_index(index_or_name)\n        else:\n            index = index_or_name\n        self.dll.SetControllerValue(index, ctypes.c_float(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nflasks application initialization. :param app: The Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\n\n        :param app: The Flask application.\n        \"\"\"\n        self.init_config(app)\n        app.extensions['invenio-indexer'] = self\n\n        hooks = app.config.get('INDEXER_BEFORE_INDEX_HOOKS', [])\n        for hook in hooks:\n            if isinstance(hook, six.string_types):\n                hook = import_string(hook)\n            before_record_index.connect_via(app)(hook)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the current object and the repository.", "response": "def close(self):\n        \"\"\" .. todo:: REPO.close docstring\n        \"\"\"\n\n        # Imports\n        import h5py as h5\n        from ..error import RepoError\n\n        # Close the repo if it's bound, and wipe link; else complain\n        if self._repo != None:\n            self._repo.close()\n            self._repo = None\n            # Leave self.fname defined for potential easy re-opening later on.\n        else:\n            raise RepoError(RepoError.STATUS,\n                    \"Cannot close; no repository open\",\n                    \"Last repo: {0}\".format(self.fname))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, fname):\n\n        # Imports\n        import h5py as h5\n        from ..error import RepoError\n\n        # If repo not None, complain\n        if not self._repo == None:\n            raise RepoError(RepoError.STATUS,\n                    \"Repository already open\",\n                    \"File: {0}\".format(self.fname))\n        ## end if\n\n        # If string passed, try opening h5.File; otherwise complain\n        if isinstance(fname, str):\n            self.fname = fname\n            self._repo = h5.File(fname)\n        else:\n            raise TypeError(\"Invalid filename type: {0}\".format(type(fname)))", "response": "Load a new object from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_open(self):\n\n        # Imports\n        import h5py as h5\n\n        # Return whether repo is bound; depends on the 'None' assignment in\n        #  'close'\n        retval = isinstance(self._repo, h5.File)\n        return retval", "response": "Return True if the repository is open."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef store_data(self, data, datatype, mode, disp, clobber=False):\n\n        # Imports\n        import h5py as h5\n        from ..error import RepoError as RErr\n        from ..const import EnumDispDirection as _E_DD\n        from ..const import EnumAnharmRepoData\n\n        # Must be valid mode\n        if not (mode >=0 and isinstance(mode, int)):\n            raise ValueError(\"Mode must be a non-negative integer\")\n        ## end if\n\n        # Must be a valid disp direction\n        if not disp in _E_DD:\n            raise ValueError(\"'{0}' is not a valid \" +\n                    \"displacement enum value\".format(disp))\n        ## end if\n\n        # Must be a valid repo data type\n        if not datatype in EnumAnharmRepoData:\n            raise ValueError(\"'{0}' is not a valid \" +\n                    \"data type enum value\".format(datatype))\n        ## end if\n\n        # Get the appropriate geom group name\n        if disp == _E_DD.NO_DISP:\n            grpname = self.G_geom_ref\n        else:\n            grpname = self.F_mode_fmt % (mode, self.dircode[disp])\n        ## end if\n\n        # Get the group, creating if absent\n        try:\n            grp = self._repo.require_group(grpname)\n        except AttributeError:\n            # Presume repo not open/attached\n            raise RErr(RErr.STATUS,\n                        \"Cannot store; no repository open\", \"\")\n        ## end try\n\n        # If dataset exists in repo group, obliterate or complain. Can't use\n        #  'require_dataset' since the object could be changing dimension(s)\n        #  and h5py can't do that\n        if datatype in grp.keys():\n            if clobber:\n                grp.pop(datatype)\n            else:\n                raise RErr(RErr.DATA,\n                        \"Dataset to be stored exists and clobber == False\",\n                        self._repo.filename)\n            ## end if\n        ## end if\n\n        # Store the new data. DOES NOT ENSURE CONSISTENCY with any\n        #  other data in the repository.\n        grp.create_dataset(datatype, data=data)\n\n        # Set as dirty and flush the repo\n        self.set_dirty(True)\n        self._repo.flush()", "response": "Store data in the object store it in the repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data(self, datatype, mode, disp):\n\n        # Imports\n        import os\n        from ..const import EnumDispDirection as _E_DD\n        from ..const import EnumAnharmRepoData\n        from ..error import RepoError as RErr\n\n        # Must be valid mode\n        if not (mode >=0 and isinstance(mode, int)):\n            raise ValueError(\"Mode must be a non-negative integer\")\n        ## end if\n\n        # Must be a valid disp direction\n        if not disp in _E_DD:\n            raise ValueError(\"'{0}' is not a valid \" +\n                    \"displacement enum value\".format(disp))\n        ## end if\n\n        # Must be a valid data type\n        if not datatype in EnumAnharmRepoData:\n            raise ValueError(\"'{0}' is not a valid \" +\n                    \"repository data type enum value\".format(datatype))\n        ## end if\n\n        # Get the appropriate geom group name\n        if disp == _E_DD.NO_DISP:\n            grpname = self.G_geom_ref\n        else:\n            grpname = self.F_mode_fmt % \\\n                                    (mode, self.dircode[disp])\n        ## end if\n\n        # Get the group, complaining if repo not bound\n        try:\n            grp = self._repo.get(grpname)\n        except AttributeError:\n            raise RErr(RErr.STATUS,\n                        \"Cannot load; no repository open\", \"\")\n        ## end try\n\n        # If succeeded, check if group not found\n        if grp is None:\n            raise RErr(RErr.GROUP,\n                    \"Group '\" + grpname + \"' not found\",\n                    self.fname)\n        ## end if\n\n        # Group found, try loading the data object; complain if not found\n        try:\n            out_data = grp.get(datatype).value\n        except AttributeError:\n            raise RErr(RErr.DATA,\n                    \"Dataset '\" + datatype + \"' not found\",\n                    self.fname)\n        ## end try\n\n        # Return as-is (h5py creates NumPy arrays of appropriate dimensions)\n        return out_data", "response": "Get the data of the current object in the system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_data(self, datatype, mode, disp):\n\n        # Imports\n        from ..error import RepoError\n\n        # Just try to get the data. Simply pass up all exceptions except for\n        #  those if the group or data doesn't exist. DO re-raise a non-bound\n        #  repo. Initialize value to DATA PRESENT (True) for case where data\n        #  is present and the 'try' succeeds.\n        retval = True\n        try:\n            self.get_data(datatype, mode, disp)\n        except RepoError as RErr:\n            if RErr.tc in (RErr.DATA, RErr.GROUP):\n                retval = False\n            ## end if\n        ## end try\n\n        # Should be good to return\n        return retval", "response": "Check if the data is present in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores the value of a parameter in the repository.", "response": "def store_param(self, value, param, clobber=False):\n        \"\"\" .. todo:: store_param docstring\n        \"\"\"\n\n        # Imports\n        from ..const import EnumAnharmRepoParam\n        from ..error import RepoError as RErr\n\n        # Must be a valid parameter name\n        if not param in EnumAnharmRepoParam:\n            raise ValueError(\"'{0}' is not a valid \" +\n                    \"parameter enum value\".format(param))\n        ## end if\n\n        # Get the params group, complaining if repo not bound\n        try:\n            grp = self._repo.require_group(self.G_param)\n        except AttributeError:\n            raise RErr(RErr.STATUS,\n                        \"Cannot store; no repository open\", \"\")\n        ## end try\n\n        # If succeeded, check if group not found\n        if grp is None:\n            raise RErr(RErr.GROUP,\n                    \"Parameters group not found\",\n                    self.fname)\n        ## end if\n\n        # If dataset exists in repo group, obliterate or complain. Can't use\n        #  'require_dataset' since the object could be changing dimension(s)\n        #  and h5py can't do that\n        if param in grp.keys():\n            if clobber:\n                grp.pop(param)\n            else:\n                raise RErr(RErr.DATA,\n                        \"Parameter to be stored exists and clobber == False\",\n                        self._repo.filename)\n            ## end if\n        ## end if\n\n        # Store the new data. DOES NOT ENSURE CONSISTENCY with any\n        #  other data in the repository.\n        grp.create_dataset(param, data=value)\n\n        # Set as dirty and flush the repo\n        self.set_dirty(True)\n        self._repo.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the parameter from the repository.", "response": "def get_param(self, param):\n        \"\"\" .. todo:: docstring for get_param\n        \"\"\"\n\n        # Imports\n        import os\n        from ..const import EnumAnharmRepoParam\n        from ..error import RepoError as RErr\n\n        # Must be a valid parameter name\n        if not param in EnumAnharmRepoParam:\n            raise ValueError(\"'{0}' is not a valid \" +\n                    \"parameter enum value\".format(param))\n        ## end if\n\n        # Get the params group, complaining if repo not bound\n        try:\n            grp = self._repo.require_group(self.G_param)\n        except AttributeError:\n            raise RErr(RErr.STATUS,\n                        \"Cannot load; no repository open\", \"\")\n        ## end try\n\n        # Group should be guaranteed present with 'require_group', try\n        #  loading the parameter; complain if not found.\n        try:\n            out_param = grp.get(param).value\n        except AttributeError:\n            raise RErr(RErr.DATA,\n                    \"Parameter '\" + param + \"' not found\",\n                    self.fname)\n        ## end try\n\n        # Return\n        self._repo.flush()\n        return out_param"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a parameter exists in the cache.", "response": "def has_param(self, param):\n        \"\"\" .. todo:: has_param docstring\n        \"\"\"\n\n        # Imports\n        from ..error import RepoError\n\n        # Try to get the param; pass along all errors, except 'data' error\n        #  from RepoError\n        retval = True\n        try:\n            self.get_param(param)\n        except RepoError as RErr:\n            if RErr.tc == RErr.DATA:\n                retval = False\n            ## end if\n        ## end try\n\n        # Should be good to return\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the current version of the object is dirty.", "response": "def is_dirty(self):\n        \"\"\" .. todo:: docstring for is_dirty\n        \"\"\"\n\n        # Imports\n        from ..error import RepoError as RErr\n\n        # Get the return value from the dataset, complaining if repo not\n        #  bound. Using 'require_dataset' since any repo w/o a defined\n        #  'dirty' value is just going to be assumed to be dirty.\n        try:\n            retval = self._repo.require_dataset(self.N_dirty, \\\n                                shape=(), dtype=bool, data=True).value\n        except AttributeError:\n            raise RErr(RErr.STATUS,\n                        \"Cannot report dirty status; no repository open\", \"\")\n        ## end try\n\n        # Either way it evaluated, should be good to return. Flush first.\n        self._repo.flush()\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the dirty status of the entry in the database.", "response": "def set_dirty(self, dirty):\n        \"\"\" .. todo:: set_clean docstring\n        \"\"\"\n\n        # Complain if 'dirty' isn't boolean\n        if not isinstance(dirty, bool):\n            raise ValueError(\"'dirty' must be Boolean\")\n        ## end if\n\n        # Try to retrieve the dataset; complain if repo not bound.\n        try:\n            dset = self._repo.require_dataset(self.N_dirty, \\\n                                shape=(), dtype=bool)\n        except AttributeError:\n            raise RErr(RErr.STATUS,\n                        \"Cannot set dirty status; no repository open\", \"\")\n        ## end try\n\n        # Change the value to the indicated value\n        dset[()] = dirty"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_XYZ(self, mode, disp):\n\n        # Imports\n        from ..xyz import OpanXYZ as XYZ\n        from ..const import EnumAnharmRepoParam, EnumAnharmRepoData\n\n        # Generate XYZ and return\n        out_XYZ = XYZ(atom_syms=self.get_param(EnumAnharmRepoParam.atoms), \\\n                        coords=self.get_data(EnumAnharmRepoData.geom, mode, disp))\n        return out_XYZ", "response": "Generate XYZ object for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping the scheduler driver.", "response": "def stop(self, failover=False):\n        \"\"\"Stops the scheduler driver.\n\n        If the 'failover' flag is set to False then it is expected that this\n        framework will never reconnect to Mesos and all of its executors and\n        tasks can be terminated.  Otherwise, all executors and tasks will\n        remain running (for some framework specific failover timeout) allowing\n        the scheduler to reconnect (possibly in the same process, or from a\n        different process, for example, on a different machine.)\n        \"\"\"\n        logging.info('Stops Scheduler Driver')\n        return self.driver.stop(failover)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting resources from Mesos.", "response": "def request(self, requests):\n        \"\"\"Requests resources from Mesos.\n\n        (see mesos.proto for a description of Request and how, for example, to\n        request resources from specific slaves.)\n\n        Any resources available are offered to the framework via\n        Scheduler.resourceOffers callback, asynchronously.\n        \"\"\"\n        logging.info('Request resources from Mesos')\n        return self.driver.requestResources(map(encode, requests))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch the given set of tasks.", "response": "def launch(self, offer_id, tasks, filters=Filters()):\n        \"\"\"Launches the given set of tasks.\n\n        Any resources remaining (i.e., not used by the tasks or their executors)\n        will be considered declined.\n        The specified filters are applied on all unused resources (see\n        mesos.proto for a description of Filters). Available resources are\n        aggregated when multiple offers are provided. Note that all offers must\n        belong to the same slave. Invoking this function with an empty\n        collection of tasks declines the offers in entirety (see\n        Scheduler.decline).\n\n        Note that passing a single offer is also supported.\n        \"\"\"\n        logging.info('Launches tasks {}'.format(tasks))\n        return self.driver.launchTasks(encode(offer_id),\n                                       map(encode, tasks),\n                                       encode(filters))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kill(self, task_id):\n        logging.info('Kills task {}'.format(task_id))\n        return self.driver.killTask(encode(task_id))", "response": "Kills the specified task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reconcile(self, statuses):\n        logging.info('Reconciles task statuses {}'.format(statuses))\n        return self.driver.reconcileTasks(map(encode, statuses))", "response": "Reconciles the statuses of tasks in the master."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecline an offer in its entirety and applies the specified Filters", "response": "def decline(self, offer_id, filters=Filters()):\n        \"\"\"Declines an offer in its entirety and applies the specified\n           filters on the resources (see mesos.proto for a description of\n           Filters).\n\n        Note that this can be done at any time, it is not necessary to do this\n        within the Scheduler::resourceOffers callback.\n        \"\"\"\n        logging.info('Declines offer {}'.format(offer_id))\n        return self.driver.declineOffer(encode(offer_id),\n                                        encode(filters))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef accept(self, offer_ids, operations, filters=Filters()):\n        logging.info('Accepts offers {}'.format(offer_ids))\n        return self.driver.acceptOffers(map(encode, offer_ids),\n                                        map(encode, operations),\n                                        encode(filters))", "response": "Accepts the given offers and performs a sequence of operations\n           on those accepted offers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef acknowledge(self, status):\n        logging.info('Acknowledges status update {}'.format(status))\n        return self.driver.acknowledgeStatusUpdate(encode(status))", "response": "Acknowledges the status update."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef message(self, executor_id, slave_id, message):\n        logging.info('Sends message `{}` to executor `{}` on slave `{}`'.format(\n                     message, executor_id, slave_id))\n        return self.driver.sendFrameworkMessage(encode(executor_id),\n                                                encode(slave_id),\n                                                message)", "response": "Sends a message from one of the executors to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles GtkBuilder signal connect events", "response": "def _connect_func(builder, obj, signal_name, handler_name,\n                  connect_object, flags, cls):\n    '''Handles GtkBuilder signal connect events'''\n\n    if connect_object is None:\n        extra = ()\n    else:\n        extra = (connect_object,)\n\n    # The handler name refers to an attribute on the template instance,\n    # so ask GtkBuilder for the template instance\n    template_inst = builder.get_object(cls.__gtype_name__)\n\n    if template_inst is None:  # This should never happen\n        errmsg = \"Internal error: cannot find template instance! obj: %s; \" \\\n                 \"signal: %s; handler: %s; connect_obj: %s; class: %s\" % \\\n                 (obj, signal_name, handler_name, connect_object, cls)\n        warnings.warn(errmsg, GtkTemplateWarning)\n        return\n\n    handler = getattr(template_inst, handler_name)\n\n    if flags == GObject.ConnectFlags.AFTER:\n        obj.connect_after(signal_name, handler, *extra)\n    else:\n        obj.connect(signal_name, handler, *extra)\n\n    template_inst.__connected_template_signals__.add(handler_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _register_template(cls, template_bytes):\n    '''Registers the template for the widget and hooks init_template'''\n\n    # This implementation won't work if there are nested templates, but\n    # we can't do that anyways due to PyGObject limitations so it's ok\n\n    if not hasattr(cls, 'set_template'):\n        raise TypeError(\"Requires PyGObject 3.13.2 or greater\")\n\n    cls.set_template(template_bytes)\n\n    bound_methods = set()\n    bound_widgets = set()\n\n    # Walk the class, find marked callbacks and child attributes\n    for name in dir(cls):\n        o = getattr(cls, name, None)\n\n        if inspect.ismethod(o):\n            if hasattr(o, '_gtk_callback'):\n                bound_methods.add(name)\n                # Don't need to call this, as connect_func always gets called\n                #cls.bind_template_callback_full(name, o)\n        elif isinstance(o, _Child):\n            cls.bind_template_child_full(name, True, 0)\n            bound_widgets.add(name)\n\n    # Have to setup a special connect function to connect at template init\n    # because the methods are not bound yet\n    cls.set_connect_func(_connect_func, cls)\n\n    cls.__gtemplate_methods__ = bound_methods\n    cls.__gtemplate_widgets__ = bound_widgets\n\n    base_init_template = cls.init_template\n    cls.init_template = lambda s: _init_template(s, cls, base_init_template)", "response": "Registers the template for the widget and hooks init_template"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_template(self, cls, base_init_template):\n    '''This would be better as an override for Gtk.Widget'''\n\n    # TODO: could disallow using a metaclass.. but this is good enough\n    # .. if you disagree, feel free to fix it and issue a PR :)\n    if self.__class__ is not cls:\n        raise TypeError(\"Inheritance from classes with @GtkTemplate decorators \"\n                        \"is not allowed at this time\")\n\n    connected_signals = set()\n    self.__connected_template_signals__ = connected_signals\n\n    base_init_template(self)\n\n    for name in self.__gtemplate_widgets__:\n        widget = self.get_template_child(cls, name)\n        self.__dict__[name] = widget\n\n        if widget is None:\n            # Bug: if you bind a template child, and one of them was\n            #      not present, then the whole template is broken (and\n            #      it's not currently possible for us to know which\n            #      one is broken either -- but the stderr should show\n            #      something useful with a Gtk-CRITICAL message)\n            raise AttributeError(\"A missing child widget was set using \"\n                                 \"GtkTemplate.Child and the entire \"\n                                 \"template is now broken (widgets: %s)\" %\n                                 ', '.join(self.__gtemplate_widgets__))\n\n    for name in self.__gtemplate_methods__.difference(connected_signals):\n        errmsg = (\"Signal '%s' was declared with @GtkTemplate.Callback \" +\n                  \"but was not present in template\") % name\n        warnings.warn(errmsg, GtkTemplateWarning)", "response": "Initializes the template with the given class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract babel translation tokens from a file object", "response": "def extract_haml(fileobj, keywords, comment_tags, options):\n    \"\"\" babel translation token extract function for haml files \"\"\"\n\n    import haml\n    from mako import lexer, parsetree\n    from mako.ext.babelplugin import extract_nodes \n\n    encoding = options.get('input_encoding', options.get('encoding', None))\n    template_node = lexer.Lexer(haml.preprocessor(fileobj.read()), input_encoding=encoding).parse()\n    for extracted in extract_nodes(template_node.get_children(), keywords, comment_tags, options):\n        yield extracted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_patterns(self, properties=None):\n        return [self.pattern_type(**self.pattern_parameters)\n                for i in range(self.patterns_per_label)]", "response": "Create a list of PatternGenerator instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_rna_args(\n        parser,\n        min_mapping_quality_default=MIN_READ_MAPPING_QUALITY):\n    \"\"\"\n    Extends an ArgumentParser instance with the following commandline arguments:\n        --bam\n        --min-reads\n        --min-mapping-quality\n        --use-duplicate-reads\n        --drop-secondary-alignments\n    \"\"\"\n    rna_group = parser.add_argument_group(\"RNA\")\n    rna_group.add_argument(\n        \"--bam\",\n        required=True,\n        help=\"BAM file containing RNAseq reads\")\n\n    rna_group.add_argument(\n        \"--min-mapping-quality\",\n        type=int,\n        default=min_mapping_quality_default,\n        help=\"Minimum MAPQ value to allow for a read (default %(default)s)\")\n\n    rna_group.add_argument(\n        \"--use-duplicate-reads\",\n        default=False,\n        action=\"store_true\")\n\n    rna_group.add_argument(\n        \"--drop-secondary-alignments\",\n        default=False,\n        action=\"store_true\")\n    return rna_group", "response": "Adds the RNAseq command line arguments to the given ArgumentParser instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an argument parser for the variant sequence command line.", "response": "def make_variant_sequences_arg_parser(add_sequence_length_arg=False, **kwargs):\n    \"\"\"\n    Parameters\n    ----------\n    add_sequence_length_arg : bool\n        If True then add the `--cdna-sequence-length` argument. This may be\n        omitted if the cDNA sequence length is inferred from a protein length.\n\n    **kwargs : dict\n        Passed directly to argparse.ArgumentParser\n\n    Creates argparse.ArgumentParser instance with all of the options\n    needed to translate each distinct cDNA sequence determined from\n    variants & RNAseq.\n\n    See `args.variant_sequences` for commandline parameters which aren't added\n    in this module.\n    \"\"\"\n    parser = make_rna_reads_arg_parser(**kwargs)\n    add_variant_sequence_args(\n        parser=parser,\n        add_sequence_length_arg=add_sequence_length_arg)\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a sequence of AlleleRead objects which are expected to all have the same allele return that allele.", "response": "def get_single_allele_from_reads(allele_reads):\n    \"\"\"\n    Given a sequence of AlleleRead objects, which are expected to all have\n    the same allele, return that allele.\n    \"\"\"\n    allele_reads = list(allele_reads)\n\n    if len(allele_reads) == 0:\n        raise ValueError(\"Expected non-empty list of AlleleRead objects\")\n\n    seq = allele_reads[0].allele\n    if any(read.allele != seq for read in allele_reads):\n        raise ValueError(\"Expected all AlleleRead objects to have same allele '%s', got %s\" % (\n            seq, allele_reads))\n    return seq"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef group_unique_sequences(\n        allele_reads,\n        max_prefix_size=None,\n        max_suffix_size=None):\n    \"\"\"\n    Given a list of AlleleRead objects, extracts all unique\n    (prefix, allele, suffix) sequences and associate each with a list\n    of reads that contained that sequence.\n    \"\"\"\n    groups = defaultdict(set)\n    for r in allele_reads:\n        prefix = r.prefix\n        allele = r.allele\n        suffix = r.suffix\n        if max_prefix_size and len(prefix) > max_prefix_size:\n            prefix = prefix[-max_prefix_size:]\n        if max_suffix_size and len(suffix) > max_suffix_size:\n            suffix = suffix[:max_suffix_size]\n        key = (prefix, allele, suffix)\n        groups[key].add(r)\n    return groups", "response": "Given a list of AlleleRead objects extracts all unique sequences and associates each with a list\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a list of AlleleRead objects extracts all unique sequences and associates each with the number of reads that contain that sequence.", "response": "def count_unique_sequences(\n        allele_reads,\n        max_prefix_size=None,\n        max_suffix_size=None):\n    \"\"\"\n    Given a list of AlleleRead objects, extracts all unique\n    (prefix, allele, suffix) sequences and associate each with the number\n    of reads that contain that sequence.\n    \"\"\"\n    groups = group_unique_sequences(\n        allele_reads,\n        max_prefix_size=max_prefix_size,\n        max_suffix_size=max_suffix_size)\n    return {\n        seq_tuple: len(read_names)\n        for (seq_tuple, read_names) in groups.items()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract a specific interval from the time series.", "response": "def extract_specific_interval(self, interval_start, interval_end):\n        \"\"\"\n        Overload if special behaviour is required when a series ends.\n        \"\"\"\n\n        interval_start = int(interval_start)\n        interval_end = int(interval_end)\n\n        if interval_start >= interval_end:\n            raise ValueError(\"Requested interval's start point is past the requested end point.\")\n\n        elif interval_start > self.time_series.size:\n            if self.repeat:\n                interval_end = interval_end - interval_start\n                interval_start = 0\n            else:\n                raise ValueError(\"Requested interval's start point is past the end of the time series.\")\n\n        if interval_end < self.time_series.size:\n            interval = self.time_series[interval_start:interval_end]\n\n        else:\n            requested_interval_size = interval_end - interval_start\n            remaining_signal = self.time_series[interval_start:self.time_series.size]\n\n            if self.next_file == len(self.sound_files) and self.repeat:\n                self.next_file = 0\n\n            if self.next_file < len(self.sound_files):\n                next_source = audiolab.Sndfile(self.sound_files[self.next_file], 'r')\n                self.next_file += 1\n\n                if next_source.samplerate != self.sample_rate:\n                    raise ValueError(\"All sound files must be of the same sample rate\")\n\n                if self.gap_between_sounds > 0:\n                    remaining_signal = hstack((remaining_signal, zeros(int(self.gap_between_sounds*self.sample_rate), dtype=self.precision)))\n\n                self.time_series = hstack((remaining_signal, next_source.read_frames(next_source.nframes, dtype=self.precision)))\n\n                interval = self.time_series[0:requested_interval_size]\n                self._next_interval_start = requested_interval_size\n\n            else:\n                self.warning(\"Returning last interval of the time series.\")\n                self._next_interval_start = self.time_series.size + 1\n\n                samples_per_interval = self.interval_length*self.sample_rate\n                interval = hstack((remaining_signal, zeros(samples_per_interval-remaining_signal.size)))\n\n        return interval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the row amplitudes of the current record set.", "response": "def _get_row_amplitudes(self):\n        \"\"\"\n        Perform a real Discrete Fourier Transform (DFT; implemented\n        using a Fast Fourier Transform algorithm, FFT) of the current\n        sample from the signal multiplied by the smoothing window.\n\n        See numpy.rfft for information about the Fourier transform.\n        \"\"\"\n\n        sample_rate = self.signal.sample_rate\n\n        # A signal window *must* span one sample rate, irrespective of interval length.\n        signal_window = tile(self.signal(), ceil(1.0/self.signal.interval_length))\n\n        if self.windowing_function == None:\n            smoothed_window = signal_window[0:sample_rate]\n        else:\n            smoothed_window = signal_window[0:sample_rate] * self.windowing_function(sample_rate)\n\n        row_amplitudes = abs(fft.rfft(smoothed_window))[0:sample_rate/2]\n        row_amplitudes = row_amplitudes.reshape(1,sample_rate/2.0)\n\n        filter_responses = multiply(self.cochlear_channels, row_amplitudes)\n        sheet_responses = zeros(self._num_of_channels)\n\n        for channel in range(0,self._num_of_channels):\n            time_responses = abs(fft.ifft(filter_responses[channel]))\n            sheet_responses[channel] = sum(time_responses) / (sample_rate/2.0)\n\n        return sheet_responses.reshape(self._num_of_channels, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator that yields every node which is a child of this one. This includes inline children and control structure else clauses.", "response": "def iter_all_children(self):\n        '''Return an iterator that yields every node which is a child of this one.\n\n        This includes inline children, and control structure `else` clauses.\n        '''\n        \n        if self.inline_child:\n            yield self.inline_child\n        for x in self.children:\n            yield x"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the data structures for the specified data structures.", "response": "def initialize(self,  **kwargs):\n        \"\"\"\n        Transfer functions may need additional information before the\n        supplied numpy array can be modified in place. For instance,\n        transfer functions may have state which needs to be allocated\n        in memory with a certain size. In other cases, the transfer\n        function may need to know about the coordinate system\n        associated with the input data.\n        \"\"\"\n        if not set(kwargs.keys()).issuperset(self.init_keys):\n            raise Exception(\"TransferFn needs to be initialized with %s\"\n                            % ','.join(repr(el) for el in self.init_keys))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef override_plasticity_state(self, new_plasticity_state):\n        self._plasticity_setting_stack.append(self.plastic)\n        self.plastic=new_plasticity_state", "response": "Override the plasticity state of the internal state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup(console=False, port=None):\n\n    if self._has_been_setup:\n        teardown()\n\n    register_plugins()\n    register_host()\n\n    self._has_been_setup = True\n    print(\"pyblish: Pyblish loaded successfully.\")", "response": "Setup integration\n\n    Register plug-ins and integrate into the host\n\n    Arguments:\n        console (bool): DEPRECATED\n        port (int, optional): DEPRECATED"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaintaining selection during context", "response": "def maintained_selection():\n    \"\"\"Maintain selection during context\n\n    Example:\n        >>> with maintained_selection():\n        ...     # Modify selection\n        ...     node.setSelected(on=False, clear_all_selected=True)\n        >>> # Selection restored\n\n    \"\"\"\n\n    previous_selection = hou.selectedNodes()\n    try:\n        yield\n    finally:\n        if previous_selection:\n            for node in previous_selection:\n                node.setSelected(on=True)\n        else:\n            for node in previous_selection:\n                node.setSelected(on=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_transaction(conn, statements: Iterable):\n\n    with conn:\n        with conn.cursor() as cursor:\n            for statement in statements:\n                cursor.execute(statement)\n        conn.commit()", "response": "Execute several statements in single DB transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting several statements each as a single DB transaction.", "response": "def execute_transactions(conn, statements: Iterable):\n    \"\"\"Execute several statements each as a single DB transaction.\"\"\"\n\n    with conn.cursor() as cursor:\n        for statement in statements:\n            try:\n                cursor.execute(statement)\n                conn.commit()\n            except psycopg2.ProgrammingError:\n                conn.rollback()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a connection commit a transaction and close it.", "response": "def execute_closing_transaction(statements: Iterable):\n    \"\"\"Open a connection, commit a transaction, and close it.\"\"\"\n\n    with closing(connect()) as conn:\n        with conn.cursor() as cursor:\n            for statement in statements:\n                cursor.execute(statement)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select(conn, query: str, params=None, name=None, itersize=5000):\n\n    with conn.cursor(name, cursor_factory=NamedTupleCursor) as cursor:\n        cursor.itersize = itersize\n        cursor.execute(query, params)\n\n        for result in cursor:\n            yield result", "response": "Returns a select statement s results as a namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_dict(conn, query: str, params=None, name=None, itersize=5000):\n\n    with conn.cursor(name, cursor_factory=RealDictCursor) as cursor:\n        cursor.itersize = itersize\n        cursor.execute(query, params)\n\n        for result in cursor:\n            yield result", "response": "Return a select statement s results as dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_each(conn, query: str, parameter_groups, name=None):\n\n    with conn:\n        with conn.cursor(name=name) as cursor:\n            for parameters in parameter_groups:\n                cursor.execute(query, parameters)\n                yield cursor.fetchone()", "response": "Run select query for each parameter set in single transaction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_columns(conn, query, name=None):\n\n    with conn.cursor(name) as cursor:\n        cursor.itersize = 1\n        cursor.execute(query)\n        cursor.fetchmany(0)\n        column_names = [column.name for column in cursor.description]\n\n    return column_names", "response": "Lightweight query to retrieve column list of select query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a Variant and a Transcript and a sequence key return a ReferenceCodingSequenceKey object.", "response": "def from_variant_and_transcript_and_sequence_key(\n            cls, variant, transcript, sequence_key):\n        \"\"\"\n        Assuming that the transcript has a coding sequence, take a\n        ReferenceSequenceKey (region of the transcript around the variant) and\n        return a ReferenceCodingSequenceKey (or None).\n        \"\"\"\n        # get the interbase range of offsets which capture all reference\n        # bases modified by the variant\n        variant_start_offset, variant_end_offset = \\\n            interbase_range_affected_by_variant_on_transcript(\n                variant=variant,\n                transcript=transcript)\n\n        start_codon_idx = min(transcript.start_codon_spliced_offsets)\n\n        # skip any variants which occur in the 5' UTR or overlap the start codon\n        # since\n        #   (1) UTR variants have unclear coding effects and\n        #   (2) start-loss variants may result in a new start codon / reading\n        #       frame but we're not sure which one!\n        if variant_start_offset < start_codon_idx + 3:\n            logger.info(\n                \"Skipping transcript %s for variant %s, must be after start codon\",\n                transcript.name,\n                variant)\n            return None\n\n        stop_codon_idx = min(transcript.stop_codon_spliced_offsets)\n\n        # skip variants which affect the 3' UTR of the transcript since\n        # they don't have obvious coding effects on the protein sequence\n        if variant_start_offset >= stop_codon_idx + 3:\n            logger.info(\n                \"Skipping transcript %s for variant %s, occurs in 3' UTR\",\n                transcript,\n                variant)\n            return None\n\n        n_prefix = len(sequence_key.sequence_before_variant_locus)\n        prefix_start_idx = variant_start_offset - n_prefix\n        n_bases_between_start_and_variant = variant_start_offset - start_codon_idx\n        n_full_codons_before_variant = n_bases_between_start_and_variant // 3\n\n        # if the sequence before the variant contains more bases than the\n        # distance to the start codon, then by definition it must contain\n        # some untranslated bases\n        contains_five_prime_utr = (n_prefix > n_bases_between_start_and_variant)\n        # allows for the possibility that the first base in the sequence might\n        # be the first nucleotide of the start codon\n        contains_start_codon = (n_prefix >= n_bases_between_start_and_variant)\n        # the sequence context might only include the 2nd or 3rd bases of\n        # the start codon\n        overlaps_start_codon = (n_prefix > n_bases_between_start_and_variant - 3)\n\n        if contains_start_codon:\n            offset_to_first_complete_codon = start_codon_idx - prefix_start_idx\n            amino_acids_before_variant = transcript.protein_sequence[:n_full_codons_before_variant]\n        else:\n            reading_frame = (prefix_start_idx - start_codon_idx) % 3\n            offset_to_first_complete_codon = reading_frame_to_offset(reading_frame)\n            n_codons_in_prefix = (n_prefix - offset_to_first_complete_codon) // 3\n            amino_acids_before_variant = transcript.protein_sequence[\n                n_full_codons_before_variant - n_codons_in_prefix:\n                n_full_codons_before_variant]\n\n        return cls(\n            strand=sequence_key.strand,\n            sequence_before_variant_locus=sequence_key.sequence_before_variant_locus,\n            sequence_at_variant_locus=sequence_key.sequence_at_variant_locus,\n            sequence_after_variant_locus=sequence_key.sequence_after_variant_locus,\n            offset_to_first_complete_codon=offset_to_first_complete_codon,\n            contains_start_codon=contains_start_codon,\n            overlaps_start_codon=overlaps_start_codon,\n            contains_five_prime_utr=contains_five_prime_utr,\n            amino_acids_before_variant=amino_acids_before_variant)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a SequenceKeyWithReadingFrame object for the given Variant and Transcript.", "response": "def from_variant_and_transcript(\n            cls,\n            variant,\n            transcript,\n            context_size):\n        \"\"\"\n        Extracts the reference sequence around a variant locus on a particular\n        transcript and determines the reading frame at the start of that\n        sequence context.\n\n        Parameters\n        ----------\n        variant : varcode.Variant\n\n        transcript : pyensembl.Transcript\n\n        context_size : int\n\n        Returns SequenceKeyWithReadingFrame object or None if Transcript lacks\n        coding sequence, protein sequence or annotated start/stop codons.\n        \"\"\"\n        if not transcript.contains_start_codon:\n            logger.info(\n                \"Expected transcript %s for variant %s to have start codon\",\n                transcript.name,\n                variant)\n            return None\n\n        if not transcript.contains_stop_codon:\n            logger.info(\n                \"Expected transcript %s for variant %s to have stop codon\",\n                transcript.name,\n                variant)\n            return None\n\n        if not transcript.protein_sequence:\n            logger.info(\n                \"Expected transript %s for variant %s to have protein sequence\",\n                transcript.name,\n                variant)\n            return None\n\n        sequence_key = ReferenceSequenceKey.from_variant_and_transcript(\n            variant=variant,\n            transcript=transcript,\n            context_size=context_size)\n\n        if sequence_key is None:\n            logger.info(\n                \"No sequence key for variant %s on transcript %s\",\n                variant,\n                transcript.name)\n            return None\n\n        return cls.from_variant_and_transcript_and_sequence_key(\n            variant=variant,\n            transcript=transcript,\n            sequence_key=sequence_key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the command line arguments and return the args and destination", "response": "def parse_arguments():\n    \"\"\"\n    Parse the command line arguments\n    :return:\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"-c\", dest=\"count\", default=0, type=int,\n        help=\"Number of pings to send\"\n    )\n    parser.add_argument(\n        \"-i\", dest=\"interval\", default=1, type=float, help=\"Ping interval\"\n    )\n    parser.add_argument(\n        \"-d\", dest=\"timings\", default=False, action=\"store_true\",\n        help=\"Show timings for the entire connection\"\n    )\n    parser.add_argument(\n        'destination', nargs='+', help='Destination host or URL'\n    )\n    args = parser.parse_args()\n    return args, args.destination"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates new sketch with the specified parameters.", "response": "def create(self, width=0, depth=0, path=None, flags=0, seed=0):\n        \"\"\"Create new sketch\n        Params:\n            <int> width\n            <str> path\n            <int> flags\n            <int> seed\n        \"\"\"\n        return self.create_method(self, width, depth, path, flags, seed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, key, key_length=0):\n        if key_length < 1:\n            key_length = len(key)\n        return self.get_method(self, key, key_length)", "response": "Get a key from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, key, value, key_length=0):\n        if key_length < 1:\n            key_length = len(key)\n        if self.k:\n            self._update(key, value)\n        return self.set_method(self, key, key_length, value)", "response": "Set value to key - value\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, key, value, key_length=0):\n        if key_length < 1:\n            key_length = len(key)\n        val = self.add_method(self, key, key_length, value)\n        if self.k:\n            self._update(key, value)\n        return val", "response": "Add value to key - value\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd value to key - value", "response": "def inc(self, key, key_length=0):\n        \"\"\"Add value to key-value\n        Params:\n            <str> key\n            <int> value\n            <int> key_length\n        Return:\n            <int> key_value\n        \"\"\"\n        if key_length < 1:\n            key_length = len(key)\n        val = self.add_method(self, key, key_length, 1)\n        if self.k:\n            self._update(key, val)\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self):\n        self.ranking = []\n        heapq.heapify(self.ranking)\n        self.dq = deque(maxlen=self.k)\n        self.num = 0\n        return self.clear_method(self)", "response": "Clear the current set of keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shrink(self, src, width=0, path=None, flags=0):\n        self.shrink_method(self, src, width, path, flags)", "response": "Shrink sketch\n        Params:\n            <Sketch> src_sketch\n            <int> width\n            <str> path\n            <int> flags"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge(self, rhs, lhs_filter=None, rhs_filter=None):\n        if lhs_filter or rhs_filter:\n            get_ = self.get___method\n            set_ = self.set___method\n            max_value = _madoka.Sketch_max_value(self)\n            for table_id in range(self.depth):\n                for cell_id in range(self.width):\n                    lhs_val = get_(self, table_id, cell_id)\n                    rhs_val = get_(rhs, table_id, cell_id)\n                    if lhs_filter:\n                        lhs_val = lhs_filter(lhs_val)\n                    if rhs_filter:\n                        rhs_val = rhs_filter(rhs_val)\n                    if (lhs_val >= max_value) or (rhs_val >= (max_value - lhs_val)):\n                        lhs_val = self.max_value\n                    else:\n                        lhs_val += rhs_val\n                    set_(self, table_id, cell_id, lhs_val)\n        else:\n            self.merge_method(self, rhs)\n            if rhs.k:\n                for (key, val) in rhs.most_common(rhs.k):\n                    self._update(key, val)", "response": "Merge two sketches into this one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter(self, given_filter, apply_zerovalue=False):\n        get_ = self.get___method\n        set_ = self.set___method\n        max_value = self.max_value\n        for table_id in range(self.depth):\n            for cell_id in range(self.width):\n                val = get_(self, table_id, cell_id)\n                if val or apply_zerovalue:\n                    val = given_filter(val)\n                    val = max_value if val > max_value else val\n                    set_(self, table_id, cell_id, val)", "response": "Apply filter into all values\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps all values in a table.", "response": "def values(self):\n        \"\"\"Dump all values\n        Return:\n            <generator> <int> val\n        \"\"\"\n        table_id = 0\n        get = self.get___method\n        for cell_id in range(self.width):\n            val = get(self, table_id, cell_id)\n            if val:\n                yield val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset values from dict src_dict Params : method = set", "response": "def fromdict(self, src_dict, method='set'):\n        \"\"\"Set values from dict\n        Params:\n            <dict <str> <int>> src_dict\n        \"\"\"\n        if method == 'set':\n            _method = self.set_method\n        else:\n            _method = self.add_method\n        if hasattr(src_dict, 'iteritems'):\n            for (key, val) in src_dict.iteritems():\n                _method(self, key, len(key), val)\n                if self.k:\n                    self._update(key, val)\n        else:\n            for (key, val) in src_dict.items():\n                _method(self, key, len(key), val)\n                if self.k:\n                    self._update(key, val)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating new sketch with the specified parameters.", "response": "def create(self, width=0, max_value=0, path=None, flags=0, seed=0):\n        \"\"\"Create new sketch\n        Params:\n            <int> width\n            <int> max_value\n            <str> path\n            <int> flags\n            <int> seed\n        \"\"\"\n        return _madoka.Sketch_create(self, width, max_value, path, flags, seed)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inc(self, key, key_length=0):\n        if key_length < 1:\n            key_length = len(key)\n        return _madoka.Sketch_inc(self, key, key_length)", "response": "Increment the value of a key in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshrink sketch Params: <Sketch> src_sketch <int> width <int> max_value <lambda> | <function> filter <str> path <int> flags", "response": "def shrink(self, src, width=0, max_value=0, filter_method=None,\n               path=None, flags=0):\n        \"\"\"Shrink sketch\n        Params:\n            <Sketch> src_sketch\n            <int> width\n            <int> max_value\n            <lambda> | <function> filter\n            <str> path\n            <int> flags\n        \"\"\"\n        if filter_method:\n            get_ = _madoka.Sketch_get__\n            set_ = _madoka.Sketch_set__\n            new_sketch = Sketch(width, max_value, path, flags, src.seed)\n            for table_id in range(SKETCH_DEPTH):\n                for offset in range(width, src.width, width):\n                    for cell_id in range(width):\n                        val = get_(src, table_id, offset + cell_id)\n                        val = filter_method(val)\n                        val = max_value if val > max_value else val\n                        if val > get_(new_sketch, table_id, cell_id):\n                            set_(new_sketch, table_id, cell_id, val)\n            self.swap(new_sketch)\n        else:\n            _madoka.Sketch_shrink(self, src, width, max_value, None, path, flags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_readme_with_long_description():\n    '''Try to convert content of README.md into rst format using pypandoc,\n    write it into README and return it.\n\n    If pypandoc cannot be imported write content of README.md unchanged into\n    README and return it.\n    '''\n    this_dir = os.path.abspath(os.path.dirname(__file__))\n\n    readme_md = os.path.join(this_dir, 'README.md')\n    readme = os.path.join(this_dir, 'README')\n\n    if os.path.exists(readme_md):\n        # this is the case when running `python setup.py sdist`\n        if os.path.exists(readme):\n            os.remove(readme)\n\n        try:\n            import pypandoc\n            long_description = pypandoc.convert(readme_md, 'rst', format='md')\n        except(ImportError):\n            with open(readme_md, encoding='utf-8') as in_:\n                long_description = in_.read()\n\n        with open(readme, 'w') as out:\n            out.write(long_description)\n    else:\n        # this is in case of `pip install fabsetup-x.y.z.tar.gz`\n        with open(readme, encoding='utf-8') as in_:\n            long_description = in_.read()\n\n    return long_description", "response": "Try to convert content of README. md into rst format using pypandoc and return it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef openssl(version='master', ignore_test_fail=False):\n    '''\n    Install or update OpenSSL from source (statically linked, no shared libs).\n\n    Args:\n        version (str): Git tag or branch to install from. Default: 'master'\n        ignore_test_fail: Continue with installation if `make test` fails.\n                          Default: False\n\n    Example:\n        > fab setup.openssl:version=OpenSSL_1_1_0-stable\n\n    Created files and dirs:\n\n        > tree ~/repos\n        \u2514\u2500\u2500 openssl          <--- checked out git repository with openssl source\n\n        > tree ~/bin\n        \u2502\n        \u251c\u2500\u2500 c_rehash -> openssl-inst/active/bin/c_rehash  \\__ command links\n        \u251c\u2500\u2500 openssl  -> openssl-inst/active/bin/openssl   /\n        \u2502\n        \u2514\u2500\u2500 openssl-inst\n            \u251c\u2500\u2500 active -> OpenSSL_1_1_0-stable     <--- here 1.1.0 is \"active\"\n            \u251c\u2500\u2500 master                             <--- installed via:\n            \u2502\u00a0\u00a0 \u251c\u2500\u2500 bin                                 `fab setup.openssl`\n            \u2502\u00a0\u00a0 \u251c\u2500\u2500 include\n            \u2502\u00a0\u00a0 \u251c\u2500\u2500 lib\n            \u2502\u00a0\u00a0 \u251c\u2500\u2500 openssldir   <--- openssl configs and default cert/key store\n            \u2502\u00a0\u00a0 \u2514\u2500\u2500 share\n            \u2514\u2500\u2500 OpenSSL_1_1_0-stable              <---.\n                \u251c\u2500\u2500 bin               installed via: -\u00b4\n                \u251c\u2500\u2500 include     `fab setup.openssl:version=OpenSSL_1_1_0-stable`\n                \u251c\u2500\u2500 lib\n                \u251c\u2500\u2500 openssldir   <--- openssl configs and default cert/key store\n                \u2514\u2500\u2500 share\n    '''\n    src_base = '~/repos'\n    srcdir = flo('{src_base}/openssl')\n\n    inst_base = '~/bin/openssl-inst'\n    instdir = flo('{inst_base}/{version}')\n\n    # dir for openssl config files, and default certificate and key store\n    confdir = flo('{instdir}/openssldir')\n\n    download(src_base, version, srcdir)\n    compile(srcdir, instdir, confdir)\n    test(srcdir, ignore_test_fail)\n    install(srcdir, inst_base, version, instdir)", "response": "Install or update OpenSSL from source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stat(package, graph):\n    client = requests.Session()\n    for name_or_url in package:\n        package = get_package(name_or_url, client)\n        if not package:\n            secho(u'Invalid name or URL: \"{name}\"'.format(name=name_or_url),\n                  fg='red', file=sys.stderr)\n            continue\n        try:\n            version_downloads = package.version_downloads\n        except NotFoundError:\n            secho(u'No versions found for \"{0}\". '\n                  u'Skipping. . .'.format(package.name),\n                  fg='red', file=sys.stderr)\n            continue\n        echo(u\"Fetching statistics for '{url}'. . .\".format(\n            url=package.package_url))\n        min_ver, min_downloads = package.min_version\n        max_ver, max_downloads = package.max_version\n        if min_ver is None or max_ver is None:\n            raise click.ClickException('Package has no releases')\n        avg_downloads = package.average_downloads\n        total = package.downloads\n        echo()\n        header = u'Download statistics for {name}'.format(name=package.name)\n        echo_header(header)\n        if graph:\n            echo()\n            echo('Downloads by version')\n            echo(package.chart())\n        echo()\n        echo(\"Min downloads:   {min_downloads:12,} ({min_ver})\".format(\n            **locals()))\n        echo(\"Max downloads:   {max_downloads:12,} ({max_ver})\".format(\n            **locals()))\n        echo(\"Avg downloads:   {avg_downloads:12,}\".format(**locals()))\n        echo(\"Total downloads: {total:12,}\".format(**locals()))\n        echo()\n        echo_download_summary(package)\n        echo()", "response": "Print download statistics for a package."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbrowses to a package s PyPI or project homepage.", "response": "def browse(package, homepage):\n    \"\"\"Browse to a package's PyPI or project homepage.\"\"\"\n    p = Package(package)\n    try:\n        if homepage:\n            secho(u'Opening homepage for \"{0}\"...'.format(package), bold=True)\n            url = p.home_page\n        else:\n            secho(u'Opening PyPI page for \"{0}\"...'.format(package), bold=True)\n            url = p.package_url\n    except NotFoundError:\n        abort_not_found(package)\n    click.launch(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(query, n_results, web):\n    if web:\n        secho(u'Opening search page for \"{0}\"...'.format(query), bold=True)\n        url = SEARCH_URL.format(query=urlquote(query))\n        click.launch(url)\n    else:\n        searcher = Searcher()\n        results = searcher.search(query, n=n_results)\n        first_line = style(u'Search results for \"{0}\"\\n'.format(query),\n                           bold=True)\n        echo_via_pager(\n            first_line +\n            '\\n'.join([format_result(result) for result in results])\n        )", "response": "Search for a pypi package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info(package, long_description, classifiers, license):\n    client = requests.Session()\n    for name_or_url in package:\n        package = get_package(name_or_url, client)\n        if not package:\n            secho(u'Invalid name or URL: \"{name}\"'.format(name=name_or_url),\n                  fg='red', file=sys.stderr)\n            continue\n\n        # Name and summary\n        try:\n            info = package.data['info']\n        except NotFoundError:\n            secho(u'No versions found for \"{0}\". '\n                  u'Skipping. . .'.format(package.name),\n                  fg='red', file=sys.stderr)\n            continue\n        echo_header(name_or_url)\n        if package.summary:\n            echo(package.summary)\n\n        # Version info\n        echo()\n        echo('Latest release:   {version:12}'.format(version=info['version']))\n\n        # Long description\n        if long_description:\n            echo()\n            echo(package.description)\n\n        # Download info\n        echo()\n        echo_download_summary(package)\n\n        # Author info\n        echo()\n        author, author_email = package.author, package.author_email\n        if author:\n            echo(u'Author:   {author:12}'.format(**locals()))\n        if author_email:\n            echo(u'Author email: {author_email:12}'.format(**locals()))\n\n        # Maintainer info\n        maintainer, maintainer_email = (package.maintainer,\n                                        package.maintainer_email)\n        if maintainer or maintainer_email:\n            echo()\n        if maintainer:\n            echo(u'Maintainer:   {maintainer:12}'.format(**locals()))\n        if maintainer_email:\n            echo(u'Maintainer email: {maintainer_email:12}'.format(**locals()))\n\n        # URLS\n        echo()\n        echo(u'PyPI URL:  {pypi_url:12}'.format(pypi_url=package.package_url))\n        if package.home_page:\n            echo(u'Home Page: {home_page:12}'.format(\n                home_page=package.home_page))\n        if package.docs_url:\n            echo(u'Documentation: {docs_url:12}'.format(\n                docs_url=package.docs_url))\n\n        # Classifiers\n        if classifiers:\n            echo()\n            echo(u'Classifiers: ')\n            for each in info.get('classifiers', []):\n                echo('\\t' + each)\n\n        if license and package.license:\n            echo()\n            echo(u'License: ', nl=False)\n            # license may be just a name, e.g. 'BSD' or the full license text\n            # If a new line is found in the text, print a new line\n            if package.license.find('\\n') >= 0 or len(package.license) > 80:\n                echo()\n            echo(package.license)\n        echo()", "response": "Get info about a package or packages."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a bar graph as a string given a dictionary of data.", "response": "def bargraph(data, max_key_width=30):\n    \"\"\"Return a bar graph as a string, given a dictionary of data.\"\"\"\n    lines = []\n    max_length = min(max(len(key) for key in data.keys()), max_key_width)\n    max_val = max(data.values())\n    max_val_length = max(\n        len(_style_value(val))\n        for val in data.values())\n    term_width = get_terminal_size()[0]\n    max_bar_width = term_width - MARGIN - (max_length + 3 + max_val_length + 3)\n    template = u\"{key:{key_width}} [ {value:{val_width}} ] {bar}\"\n    for key, value in data.items():\n        try:\n            bar = int(math.ceil(max_bar_width * value / max_val)) * TICK\n        except ZeroDivisionError:\n            bar = ''\n        line = template.format(\n            key=key[:max_length],\n            value=_style_value(value),\n            bar=bar,\n            key_width=max_length,\n            val_width=max_val_length\n        )\n        lines.append(line)\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef version_downloads(self):\n        ret = OrderedDict()\n        for release, info in self.release_info:\n            download_count = sum(file_['downloads'] for file_ in info)\n            ret[release] = download_count\n        return ret", "response": "Return a dictionary of version : download_count pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef max_version(self):\n        data = self.version_downloads\n        if not data:\n            return None, 0\n        return max(data.items(), key=lambda item: item[1])", "response": "Version with the most downloads."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef min_version(self):\n        data = self.version_downloads\n        if not data:\n            return (None, 0)\n        return min(data.items(), key=lambda item: item[1])", "response": "Version with the fewest downloads."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef elasprep(self):\n    \n    if self.Method != 'SAS_NG':\n      self.dx4 = self.dx**4\n      self.dy4 = self.dy**4\n      self.dx2dy2 = self.dx**2 * self.dy**2\n    self.D = self.E*self.Te**3/(12*(1-self.nu**2))", "response": "This function is used to create the 2D finite \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect the boundary conditions E-W is for inside each panel N-S is for the block diagonal matrix (\"with fringes\") Then calls the function to build the diagonal matrix The current method of coefficient matrix construction utilizes longer-range symmetry in the coefficient matrix to build it block-wise, as opposed to the much less computationally efficient row-by-row (\"serial\") method that was previously employed. The method is spread across the subroutines here. Important to this is the use of np.roll() to properly offset the diagonals that end up in the main matrix: spdiags() will put each vector on the proper diagonal, but will align them such that their first cell is along the first column, instead of using a 45 degrees to matrix corner baseline that would stagger them appropriately for this solution method. Therefore, np.roll() effectively does this staggering by having the appropriate cell in the vector start at the first column.", "response": "def BC_selector_and_coeff_matrix_creator(self):\n    \"\"\"\n    Selects the boundary conditions\n    E-W is for inside each panel\n    N-S is for the block diagonal matrix (\"with fringes\")\n    Then calls the function to build the diagonal matrix\n\n    The current method of coefficient matrix construction utilizes longer-range\n    symmetry in the coefficient matrix to build it block-wise, as opposed to\n    the much less computationally efficient row-by-row (\"serial\") method \n    that was previously employed.\n    \n    The method is spread across the subroutines here.\n    \n    Important to this is the use of np.roll() to properly offset the \n    diagonals that end up in the main matrix: spdiags() will put each vector\n    on the proper diagonal, but will align them such that their first cell is \n    along the first column, instead of using a 45 degrees to matrix corner \n    baseline that would stagger them appropriately for this solution method.\n    Therefore, np.roll() effectively does this staggering by having the \n    appropriate cell in the vector start at the first column.\n    \"\"\"\n    \n    # Zeroth, start the timer and print the boundary conditions to the screen\n    self.coeff_start_time = time.time()\n    if self.Verbose:\n      print(\"Boundary condition, West:\", self.BC_W, type(self.BC_W))\n      print(\"Boundary condition, East:\", self.BC_E, type(self.BC_E))\n      print(\"Boundary condition, North:\", self.BC_N, type(self.BC_N))\n      print(\"Boundary condition, South:\", self.BC_S, type(self.BC_S))\n    \n    # First, set flexural rigidity boundary conditions to flesh out this padded\n    # array\n    self.BC_Rigidity()\n    \n    # Second, build the coefficient arrays -- with the rigidity b.c.'s\n    self.get_coeff_values()\n    \n    # Third, apply boundary conditions to the coeff_arrays to create the \n    # flexural solution\n    self.BC_Flexure()\n    \n    # Fourth, construct the sparse diagonal array\n    self.build_diagonals()\n\n    # Finally, compute the total time this process took    \n    self.coeff_creation_time = time.time() - self.coeff_start_time\n    if self.Quiet == False:\n      print(\"Time to construct coefficient (operator) array [s]:\", self.coeff_creation_time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_coeff_values(self):\n\n    # don't want to keep typing \"self.\" everwhere!\n    D = self.D\n    drho = self.drho\n    dx4 = self.dx4\n    dy4 = self.dy4\n    dx2dy2 = self.dx2dy2\n    nu = self.nu\n    g = self.g\n\n    if np.isscalar(self.Te):\n      # So much simpler with constant D! And symmetrical stencil\n      self.cj2i0 = D/dy4\n      self.cj1i_1 = 2*D/dx2dy2\n      self.cj1i0 = -4*D/dy4 - 4*D/dx2dy2\n      self.cj1i1 = 2*D/dx2dy2\n      self.cj0i_2 = D/dx4\n      self.cj0i_1 = -4*D/dx4 - 4*D/dx2dy2\n      self.cj0i0 = 6*D/dx4 + 6*D/dy4 + 8*D/dx2dy2 + drho*g\n      self.cj0i1 = -4*D/dx4 - 4*D/dx2dy2 # Symmetry\n      self.cj0i2 = D/dx4 # Symmetry\n      self.cj_1i_1 = 2*D/dx2dy2 # Symmetry\n      self.cj_1i0 = -4*D/dy4 - 4*D/dx2dy2 # Symmetry\n      self.cj_1i1 = 2*D/dx2dy2 # Symmetry\n      self.cj_2i0 = D/dy4 # Symmetry\n      # Bring up to size\n      self.cj2i0 *= np.ones(self.qs.shape)\n      self.cj1i_1 *= np.ones(self.qs.shape)\n      self.cj1i0 *= np.ones(self.qs.shape)\n      self.cj1i1 *= np.ones(self.qs.shape)\n      self.cj0i_2 *= np.ones(self.qs.shape)\n      self.cj0i_1 *= np.ones(self.qs.shape)\n      self.cj0i0 *= np.ones(self.qs.shape)\n      self.cj0i1 *= np.ones(self.qs.shape)\n      self.cj0i2 *= np.ones(self.qs.shape)\n      self.cj_1i_1 *= np.ones(self.qs.shape)\n      self.cj_1i0 *= np.ones(self.qs.shape)\n      self.cj_1i1 *= np.ones(self.qs.shape)\n      self.cj_2i0 *= np.ones(self.qs.shape)\n      # Create coefficient arrays to manage boundary conditions\n      self.cj2i0_coeff_ij = self.cj2i0.copy()\n      self.cj1i_1_coeff_ij = self.cj1i_1.copy()\n      self.cj1i0_coeff_ij = self.cj1i0.copy()\n      self.cj1i1_coeff_ij = self.cj1i1.copy()\n      self.cj0i_2_coeff_ij = self.cj0i_2.copy()\n      self.cj0i_1_coeff_ij = self.cj0i_1.copy()\n      self.cj0i0_coeff_ij = self.cj0i0.copy()\n      self.cj0i1_coeff_ij = self.cj0i1.copy()\n      self.cj0i2_coeff_ij = self.cj0i2.copy()\n      self.cj_1i_1_coeff_ij = self.cj_1i_1.copy()\n      self.cj_1i0_coeff_ij = self.cj_1i0.copy()\n      self.cj_1i1_coeff_ij = self.cj_1i1.copy()\n      self.cj_2i0_coeff_ij = self.cj_2i0.copy()\n      \n    elif type(self.Te) == np.ndarray:\n    \n      #######################################################\n      # GENERATE COEFFICIENT VALUES FOR EACH SOLUTION TYPE. #\n      #    \"vWC1994\" IS THE BEST: LOOSEST ASSUMPTIONS.      #\n      #        OTHERS HERE LARGELY FOR COMPARISON           #\n      #######################################################\n      \n      # All derivatives here, to make reading the equations below easier\n      D00 = D[1:-1,1:-1]\n      D10 = D[1:-1,2:]\n      D_10 = D[1:-1,:-2]\n      D01 = D[2:,1:-1]\n      D0_1 = D[:-2,1:-1]\n      D11 = D[2:,2:]\n      D_11 = D[2:,:-2]\n      D1_1 = D[:-2,2:]\n      D_1_1 = D[:-2,:-2]\n      # Derivatives of D -- not including /(dx^a dy^b)\n      D0  = D00\n      Dx  = (-D_10 + D10)/2.\n      Dy  = (-D0_1 + D01)/2.\n      Dxx = (D_10 - 2.*D00 + D10)\n      Dyy = (D0_1 - 2.*D00 + D01)\n      Dxy = (D_1_1 - D_11 - D1_1 + D11)/4.\n      \n      if self.PlateSolutionType == 'vWC1994':\n        # van Wees and Cloetingh (1994) solution, re-discretized by me\n        # using a central difference approx. to 2nd order precision\n        # NEW STENCIL\n        # x = -2, y = 0\n        self.cj_2i0_coeff_ij = (D0 - Dx) / dx4\n        # x = 0, y = -2\n        self.cj0i_2_coeff_ij = (D0 - Dy) / dy4\n        # x = 0, y = 2\n        self.cj0i2_coeff_ij = (D0 + Dy) / dy4\n        # x = 2, y = 0\n        self.cj2i0_coeff_ij = (D0 + Dx) / dx4\n        # x = -1, y = -1\n        self.cj_1i_1_coeff_ij = (2.*D0 - Dx - Dy + Dxy*(1-nu)/2.) / dx2dy2\n        # x = -1, y = 1\n        self.cj_1i1_coeff_ij = (2.*D0 - Dx + Dy - Dxy*(1-nu)/2.) / dx2dy2\n        # x = 1, y = -1\n        self.cj1i_1_coeff_ij = (2.*D0 + Dx - Dy - Dxy*(1-nu)/2.) / dx2dy2\n        # x = 1, y = 1\n        self.cj1i1_coeff_ij = (2.*D0 + Dx + Dy + Dxy*(1-nu)/2.) / dx2dy2\n        # x = -1, y = 0\n        self.cj_1i0_coeff_ij = (-4.*D0 + 2.*Dx + Dxx)/dx4 + (-4.*D0 + 2.*Dx + nu*Dyy)/dx2dy2\n        # x = 0, y = -1\n        self.cj0i_1_coeff_ij = (-4.*D0 + 2.*Dy + Dyy)/dy4 + (-4.*D0 + 2.*Dy + nu*Dxx)/dx2dy2\n        # x = 0, y = 1\n        self.cj0i1_coeff_ij = (-4.*D0 - 2.*Dy + Dyy)/dy4 + (-4.*D0 - 2.*Dy + nu*Dxx)/dx2dy2\n        # x = 1, y = 0\n        self.cj1i0_coeff_ij = (-4.*D0 - 2.*Dx + Dxx)/dx4 + (-4.*D0 - 2.*Dx + nu*Dyy)/dx2dy2\n        # x = 0, y = 0\n        self.cj0i0_coeff_ij = (6.*D0 - 2.*Dxx)/dx4 \\\n                     + (6.*D0 - 2.*Dyy)/dy4 \\\n                     + (8.*D0 - 2.*nu*Dxx - 2.*nu*Dyy)/dx2dy2 \\\n                     + drho*g\n                     \n      elif self.PlateSolutionType == 'G2009':\n        # STENCIL FROM GOVERS ET AL. 2009 -- first-order differences\n        # x is j and y is i b/c matrix row/column notation\n        # Note that this breaks down with b.c.'s that place too much control \n        # on the solution -- harmonic wavetrains\n        # x = -2, y = 0\n        self.cj_2i0_coeff_ij = D_10/dx4\n        # x = -1, y = -1\n        self.cj_1i_1_coeff_ij = (D_10 + D0_1)/dx2dy2\n        # x = -1, y = 0\n        self.cj_1i0_coeff_ij = -2. * ( (D0_1 + D00)/dx2dy2 + (D00 + D_10)/dx4 )\n        # x = -1, y = 1\n        self.cj_1i1_coeff_ij = (D_10 + D01)/dx2dy2\n        # x = 0, y = -2\n        self.cj0i_2_coeff_ij = D0_1/dy4\n        # x = 0, y = -1\n        self.cj0i_1_coeff_ij = -2. * ( (D0_1 + D00)/dx2dy2 + (D00 + D0_1)/dy4)\n        # x = 0, y = 0\n        self.cj0i0_coeff_ij = (D10 + 4.*D00 + D_10)/dx4 + (D01 + 4.*D00 + D0_1)/dy4 + (8.*D00/dx2dy2) + drho*g\n        # x = 0, y = 1\n        self.cj0i1_coeff_ij = -2. * ( (D01 + D00)/dy4 + (D00 + D01)/dx2dy2 )\n        # x = 0, y = 2\n        self.cj0i2_coeff_ij = D0_1/dy4\n        # x = 1, y = -1\n        self.cj1i_1_coeff_ij = (D10+D0_1)/dx2dy2\n        # x = 1, y = 0\n        self.cj1i0_coeff_ij = -2. * ( (D10 + D00)/dx4 + (D10 + D00)/dx2dy2 )\n        # x = 1, y = 1\n        self.cj1i1_coeff_ij = (D10 + D01)/dx2dy2\n        # x = 2, y = 0\n        self.cj2i0_coeff_ij = D10/dx4\n      else:\n        sys.exit(\"Not an acceptable plate solution type. Please choose from:\\n\"+\n                  \"* vWC1994\\n\"+\n                  \"* G2009\\n\"+\n                  \"\")\n                  \n      ################################################################\n      # CREATE COEFFICIENT ARRAYS: PLAIN, WITH NO B.C.'S YET APPLIED #\n      ################################################################\n      # x = -2, y = 0\n      self.cj_2i0 = self.cj_2i0_coeff_ij.copy()\n      # x = -1, y = -1\n      self.cj_1i_1 = self.cj_1i_1_coeff_ij.copy()\n      # x = -1, y = 0\n      self.cj_1i0 = self.cj_1i0_coeff_ij.copy()\n      # x = -1, y = 1\n      self.cj_1i1 = self.cj_1i1_coeff_ij.copy()\n      # x = 0, y = -2\n      self.cj0i_2 = self.cj0i_2_coeff_ij.copy()\n      # x = 0, y = -1\n      self.cj0i_1 = self.cj0i_1_coeff_ij.copy()\n      # x = 0, y = 0\n      self.cj0i0 = self.cj0i0_coeff_ij.copy()\n      # x = 0, y = 1\n      self.cj0i1 = self.cj0i1_coeff_ij.copy()\n      # x = 0, y = 2\n      self.cj0i2 = self.cj0i2_coeff_ij.copy()\n      # x = 1, y = -1\n      self.cj1i_1 = self.cj1i_1_coeff_ij.copy()\n      # x = 1, y = 0\n      self.cj1i0 = self.cj1i0_coeff_ij.copy()\n      # x = 1, y = 1\n      self.cj1i1 = self.cj1i1_coeff_ij.copy()\n      # x = 2, y = 0\n      self.cj2i0 = self.cj2i0_coeff_ij.copy()\n\n    # Provide rows and columns in the 2D input to later functions\n    self.ncolsx = self.cj0i0.shape[1]\n    self.nrowsy = self.cj0i0.shape[0]", "response": "Calculates the coefficients that are later used via sparse matrix decomposition."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the approximate maximum flexural wavelength of a single grid", "response": "def calc_max_flexural_wavelength(self):\n    \"\"\"\n    Returns the approximate maximum flexural wavelength\n    This is important when padding of the grid is required: in Flexure (this \n    code), grids are padded out to one maximum flexural wavelength, but in any \n    case, the flexural wavelength is a good characteristic distance for any \n    truncation limit\n    \"\"\"\n    if np.isscalar(self.D):\n      Dmax = self.D\n    else:\n      Dmax = self.D.max()\n    # This is an approximation if there is fill that evolves with iterations \n    # (e.g., water), but should be good enough that this won't do much to it\n    alpha = (4*Dmax/(self.drho*self.g))**.25 # 2D flexural parameter\n    self.maxFlexuralWavelength = 2*np.pi*alpha\n    self.maxFlexuralWavelength_ncells_x = int(np.ceil(self.maxFlexuralWavelength / self.dx))\n    self.maxFlexuralWavelength_ncells_y = int(np.ceil(self.maxFlexuralWavelength / self.dy))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsolving the Fourier domain problem with the Fourier domain.", "response": "def fd_solve(self):\n    \"\"\"\n    w = fd_solve()\n    Sparse flexural response calculation.\n    Can be performed by direct factorization with UMFpack (defuault) \n    or by an iterative minimum residual technique\n    These are both the fastest of the standard Scipy builtin techniques in \n    their respective classes \n    Requires the coefficient matrix from \"2D.coeff_matrix\"\n    \"\"\"\n    \n    if self.Debug:\n      try:\n        # Will fail if scalar\n        print(\"self.Te\", self.Te.shape)\n      except:\n        pass\n      print(\"self.qs\", self.qs.shape)\n      self.calc_max_flexural_wavelength()\n      print(\"maxFlexuralWavelength_ncells: (x, y):\", self.maxFlexuralWavelength_ncells_x, self.maxFlexuralWavelength_ncells_y)\n    \n    q0vector = self.qs.reshape(-1, order='C')\n    if self.Solver == \"iterative\" or self.Solver == \"Iterative\":\n      if self.Debug:\n        print(\"Using generalized minimal residual method for iterative solution\")\n      if self.Verbose:\n        print(\"Converging to a tolerance of\", self.iterative_ConvergenceTolerance, \"m between iterations\")\n      wvector = scipy.sparse.linalg.isolve.lgmres(self.coeff_matrix, q0vector)#, tol=1E-10)#,x0=woldvector)#,x0=wvector,tol=1E-15)    \n      wvector = wvector[0] # Reach into tuple to get my array back\n    else:\n      if self.Solver == \"direct\" or self.Solver == \"Direct\":\n        if self.Debug:\n          print(\"Using direct solution with UMFpack\")\n      else:\n        if self.Quiet == False:\n          print(\"Solution type not understood:\")\n          print(\"Defaulting to direct solution with UMFpack\")\n      wvector = scipy.sparse.linalg.spsolve(self.coeff_matrix, q0vector, use_umfpack=True)\n\n    # Reshape into grid\n    self.w = -wvector.reshape(self.qs.shape)\n    self.w_padded = self.w.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ripping_of_cds():\n    '''Install the tools ripit and burnit in order to rip and burn audio cds.\n\n    More info: http://forums.debian.net/viewtopic.php?f=16&t=36826\n    '''\n    # install and configure ripit\n    install_package('ripit')\n    install_file_legacy(path='~/.ripit/config', username=env.user)\n    # install burnit\n    run('mkdir -p  ~/bin')\n    install_file_legacy('~/bin/burnit')\n    run('chmod 755 ~/bin/burnit')", "response": "Install the tools ripit and burnit in order to rip audio cds."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls and customize the tiling window manager i3.", "response": "def i3():\n    '''Install and customize the tiling window manager i3.'''\n    install_package('i3')\n    install_file_legacy(path='~/.i3/config', username=env.user, repos_dir='repos')\n\n    # setup: hide the mouse if not in use\n    # in ~/.i3/config: 'exec /home/<USERNAME>/repos/hhpc/hhpc -i 10 &'\n    install_packages(['make', 'pkg-config', 'gcc', 'libc6-dev', 'libx11-dev'])\n    checkup_git_repo_legacy(url='https://github.com/aktau/hhpc.git')\n    run('cd ~/repos/hhpc  &&  make')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets solarized colors in urxvt tmux and vim.", "response": "def solarized():\n    '''Set solarized colors in urxvt, tmux, and vim.\n\n    More Infos:\n    * Getting solarized colors right with urxvt, st, tmux and vim:\n      https://bbs.archlinux.org/viewtopic.php?id=164108\n\n    * Creating ~/.Xresources:\n      https://wiki.archlinux.org/index.php/Rxvt-unicode#Creating_.7E.2F.Xresources\n\n    * Select a good font on Ubuntu:\n      https://michaelheap.com/getting-solarized-working-on-ubuntu/\n\n    * tmux and 256 colors:\n      http://unix.stackexchange.com/a/118903\n    '''\n    install_packages(['rxvt-unicode', 'tmux', 'vim'])\n    install_file_legacy('~/.Xresources')\n    if env.host_string == 'localhost':\n        run('xrdb  ~/.Xresources')\n\n    # install and call term_colors\n    run('mkdir -p  ~/bin')\n    install_file_legacy('~/bin/term_colors')\n    run('chmod 755 ~/bin/term_colors')\n    run('~/bin/term_colors')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncustomizes vim install vim - pathogen and vim - nerdtree - tabs and tagbar.", "response": "def vim():\n    '''Customize vim, install package manager pathogen and some vim-packages.\n\n    pathogen will be installed as a git repo at ~/repos/vim-pathogen and\n    activated in vim by a symbolic link at ~/.vim/autoload/pathogen.vim\n\n    A ~/.vimrc will be installed which loads the package manager within of vim.\n\n    The vim packages vim-colors-solarized, nerdtree, and tagbar are installed\n    as git repos placed at dir ~/.vim/bundle/\n\n    If you want to install more vim packages also place them at this dir, cf.\n    https://logicalfriday.com/2011/07/18/using-vim-with-pathogen/\n    '''\n    install_package('vim')\n\n    print_msg('## install ~/.vimrc\\n')\n    install_file_legacy('~/.vimrc')\n\n    print_msg('\\n## set up pathogen\\n')\n    run('mkdir -p  ~/.vim/autoload  ~/.vim/bundle')\n    checkup_git_repo_legacy(url='https://github.com/tpope/vim-pathogen.git')\n    run('ln -snf  ~/repos/vim-pathogen/autoload/pathogen.vim  '\n        '~/.vim/autoload/pathogen.vim')\n\n    print_msg('\\n## install vim packages\\n')\n    install_package('ctags')  # required by package tagbar\n    repos = [\n        {\n            'name': 'vim-colors-solarized',\n            'url': 'git://github.com/altercation/vim-colors-solarized.git',\n        },\n        {\n            'name': 'nerdtree',\n            'url': 'https://github.com/scrooloose/nerdtree.git',\n        },\n        {\n            'name': 'vim-nerdtree-tabs',\n            'url': 'https://github.com/jistr/vim-nerdtree-tabs.git',\n        },\n        {\n            'name': 'tagbar',\n            'url': 'https://github.com/majutsushi/tagbar.git',\n        },\n    ]\n    checkup_git_repos_legacy(repos, base_dir='~/.vim/bundle')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pyenv():\n    '''Install or update the pyenv python environment.\n\n    Checkout or update the pyenv repo at ~/.pyenv and enable the pyenv.\n    Pyenv wird also als Github-Repo \"installiert\" unter ~/.pyenv\n\n    More info:\n     * https://github.com/yyuu/pyenv\n     * https://github.com/yyuu/pyenv/wiki/Common-build-problems#requirements\n    Tutorial:\n     * http://amaral-lab.org/resources/guides/pyenv-tutorial\n    '''\n    install_packages([\n        'make',\n        'build-essential',\n        'libssl-dev',\n        'zlib1g-dev',\n        'libbz2-dev',\n        'libreadline-dev',\n        'libsqlite3-dev',\n        'wget',\n        'curl',\n        'llvm',\n        'libncurses5-dev',\n        'libncursesw5-dev',\n    ])\n    if exists('~/.pyenv'):\n        run('cd ~/.pyenv  &&  git pull')\n        run('~/.pyenv/bin/pyenv update')\n    else:\n        run('curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/'\n            'master/bin/pyenv-installer | bash')\n\n    # add pyenv to $PATH and set up pyenv init\n    bash_snippet = '~/.bashrc_pyenv'\n    install_file_legacy(path=bash_snippet)\n    prefix = flo('if [ -f {bash_snippet} ]; ')\n    enabler = flo('if [ -f {bash_snippet} ]; then source {bash_snippet}; fi')\n    if env.host == 'localhost':\n        # FIXME: next function currently only works for localhost\n        uncomment_or_update_or_append_line(filename='~/.bashrc', prefix=prefix,\n                                           new_line=enabler)\n    else:\n        print(cyan('\\nappend to ~/.bashrc:\\n\\n    ') + enabler)", "response": "Install or update the pyenv python environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef virtualbox_host():\n    '''Install a VirtualBox host system.\n\n    More Infos:\n     * overview:     https://wiki.ubuntuusers.de/VirtualBox/\n     * installation: https://wiki.ubuntuusers.de/VirtualBox/Installation/\n    '''\n    if query_yes_no(question='Uninstall virtualbox-dkms?', default='yes'):\n        run('sudo apt-get remove virtualbox-dkms')\n    install_packages([\n        'virtualbox',\n        'virtualbox-qt',\n        'virtualbox-dkms',\n        'virtualbox-guest-dkms',\n        'virtualbox-guest-additions-iso',\n    ])\n    users = [env.user]\n    for username in users:\n        run(flo('sudo  adduser {username} vboxusers'))", "response": "Install a VirtualBox host system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef server_customizations():\n    '''Customize the server (user, authorized_keys, ...).'''\n\n    username = env.user\n    env.user = 'root'\n\n    # create user\n    all_users = run('cut -d: -f1 /etc/passwd').split()\n    if username not in all_users:\n\n        host = env.host\n\n        run(flo('adduser {username}'))\n\n        # add user to the sudo group, cf. http://askubuntu.com/a/7484\n        #run('sudo adduser {username} sudo'.format(**locals()))\n        # http://jeromejaglale.com/doc/unix/ubuntu_sudo_without_password\n        append('/etc/sudoers', flo('{username} ALL=(ALL) NOPASSWD: ALL'),\n               use_sudo=True)\n\n        # set up password-less login\n        local(flo('ssh-copy-id -i ~/.ssh/id_rsa.pub  {username}@{host}'))\n\n        env.user = username\n\n        # Disable service apache2 httpd, cf. http://askubuntu.com/a/355102\n        sudo('update-rc.d apache2 disable')\n    else:\n        print(magenta(flo(' nothing to do, user {username} already exists')))\n        env.user = username", "response": "Customize the server (user, authorized_keys, ...)."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling or update latest Pencil version 2.", "response": "def pencil2():\n    '''Install or update latest Pencil version 2, a GUI prototyping tool.\n\n    Tip: For svg exports displayed proper in other programs (eg. inkscape,\n    okular, reveal.js presentations) only use the 'Common Shapes' and\n    'Desktop - Sketchy GUI' elements.\n\n    More info:\n        github repo (forked version 2): https://github.com/prikhi/pencil\n    '''\n    repo_name = 'pencil2'\n    repo_dir = flo('~/repos/{repo_name}')\n\n    print_msg('## fetch latest pencil\\n')\n    checkup_git_repo_legacy(url='https://github.com/prikhi/pencil.git',\n                            name=repo_name)\n\n    print_msg('\\n## build properties\\n')\n    update_or_append_line(flo('{repo_dir}/build/properties.sh'),\n                          prefix='export MAX_VERSION=',\n                          new_line=\"export MAX_VERSION='100.*'\")\n    run(flo('cat {repo_dir}/build/properties.sh'))\n\n    run(flo('cd {repo_dir}/build && ./build.sh  linux'),\n        msg='\\n## build pencil\\n')\n    install_user_command_legacy('pencil2', pencil2_repodir=repo_dir)\n    print_msg('\\nNow You can start pencil version 2 with this command:\\n\\n'\n              '    pencil2')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall or update latest Pencil version 3.", "response": "def pencil3():\n    '''Install or update latest Pencil version 3, a GUI prototyping tool.\n\n    While it is the newer one and the GUI is more fancy, it is the \"more beta\"\n    version of pencil.  For exmaple, to display a svg export may fail from\n    within a reveal.js presentation.\n\n    More info:\n        Homepage: http://pencil.evolus.vn/Next.html\n        github repo: https://github.com/evolus/pencil\n    '''\n    repo_name = 'pencil3'\n    repo_dir = flo('~/repos/{repo_name}')\n    print_msg('## fetch latest pencil\\n')\n    checkup_git_repo_legacy(url='https://github.com/evolus/pencil.git',\n                            name=repo_name)\n    run(flo('cd {repo_dir} && npm install'), msg='\\n## install npms\\n')\n    install_user_command_legacy('pencil3', pencil3_repodir=repo_dir)\n    print_msg('\\nNow You can start pencil version 3 with this command:\\n\\n'\n              '    pencil3')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef server_prepare_root_bin_dir():\n    '''Install custom commands for user root at '/root/bin/'.'''\n    commands = ['run_backup']\n    for command in commands:\n        install_file_legacy(flo('/root/bin/{command}'), sudo=True)\n        sudo(flo('chmod 755 /root/bin/{command}'))\n        if command == 'run_backup':\n            sudo('ln -snf /root/bin/run_backup /etc/cron.daily/run_backup')", "response": "Install custom commands for user root at '/root/bin/'."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls and set up powerline - shell.", "response": "def powerline_shell():\n    '''Install and set up powerline-shell prompt.\n\n    More infos:\n     * https://github.com/banga/powerline-shell\n     * https://github.com/ohnonot/powerline-shell\n     * https://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin\n    '''\n    assert env.host == 'localhost', 'This task cannot run on a remote host'\n\n    # set up fonts for powerline\n\n    checkup_git_repo_legacy('https://github.com/powerline/fonts.git',\n                            name='powerline-fonts')\n    run('cd ~/repos/powerline-fonts && ./install.sh')\n#    run('fc-cache -vf ~/.local/share/fonts')\n    prefix = 'URxvt*font: '\n    from config import fontlist\n    line = prefix + fontlist\n    update_or_append_line(filename='~/.Xresources', prefix=prefix,\n            new_line=line)\n    if env.host_string == 'localhost':\n        run('xrdb  ~/.Xresources')\n\n    # set up powerline-shell\n\n    checkup_git_repo_legacy('https://github.com/banga/powerline-shell.git')\n#    checkup_git_repo_legacy('https://github.com/ohnonot/powerline-shell.git')\n    install_file_legacy(path='~/repos/powerline-shell/config.py')\n    run('cd ~/repos/powerline-shell && ./install.py')\n\n    question = 'Use normal question mark (u003F) for untracked files instead '\\\n        'of fancy \"black question mark ornament\" (u2753, which may not work)?'\n    if query_yes_no(question, default='yes'):\n        filename = '~/repos/powerline-shell/powerline-shell.py'\n        update_or_append_line(filename, keep_backup=False,\n                              prefix=\"        'untracked': u'\\u2753',\",\n                              new_line=\"        'untracked': u'\\u003F',\")\n        run(flo('chmod u+x  {filename}'))\n\n    bash_snippet = '~/.bashrc_powerline_shell'\n    install_file_legacy(path=bash_snippet)\n    prefix = flo('if [ -f {bash_snippet} ]; ')\n    enabler = flo('if [ -f {bash_snippet} ]; then source {bash_snippet}; fi')\n    uncomment_or_update_or_append_line(filename='~/.bashrc', prefix=prefix,\n                                       new_line=enabler)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall Telegram desktop client for linux.", "response": "def telegram():\n    '''Install Telegram desktop client for linux (x64).\n\n    More infos:\n      https://telegram.org\n      https://desktop.telegram.org/\n    '''\n    if not exists('~/bin/Telegram', msg='Download and install Telegram:'):\n        run('mkdir -p /tmp/telegram')\n        run('cd /tmp/telegram  &&  wget https://telegram.org/dl/desktop/linux')\n        run('cd /tmp/telegram  &&  tar xf linux')\n        with warn_only():\n            run('mv /tmp/telegram/Telegram  ~/bin')\n        run('rm -rf /tmp/telegram')\n    else:\n        print('skip download, dir ~/bin/Telegram already exists')\n    run('ln -snf ~/bin/Telegram/Telegram  ~/bin/telegram',\n            msg=\"\\nCreate executable 'telegram':\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_boto3_clients(self, profile, region):\n        try:\n            session = None\n            if profile and region:\n                session = boto3.session.Session(profile_name=profile, region_name=region)\n            elif profile:\n                session = boto3.session.Session(profile_name=profile)\n            elif region:\n                session = boto3.session.Session(region_name=region)\n            else:\n                session = boto3.session.Session()\n\n            self._cloud_formation = session.client('cloudformation')\n            return True\n        except Exception as wtf:\n            logging.error(wtf, exc_info=True)\n            return False", "response": "Initialize the boto3 clients."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if drift of the stack is complete or not.", "response": "def determine_drift(self):\n        \"\"\"\n        Determine the drift of the stack.\n\n        Args:\n            None\n\n        Returns:\n            Good or Bad; True or False\n        \"\"\"\n        try:\n            response = self._cloud_formation.detect_stack_drift(StackName=self._stack_name)\n            drift_request_id = response.get('StackDriftDetectionId', None)\n            if drift_request_id:\n                logging.info('drift_request_id: %s - polling', drift_request_id)\n                drift_calc_done = False\n                while not drift_calc_done:\n                    time.sleep(self.nap_time)\n                    response = self._cloud_formation.describe_stack_drift_detection_status(\n                        StackDriftDetectionId=drift_request_id\n                    )\n                    current_state = response.get('DetectionStatus', None)\n                    logging.info(\n                        'describe_stack_drift_detection_status(): {}'.format(current_state)\n                    )\n                    drift_calc_done = current_state in CALC_DONE_STATES\n                    drift_answer = response.get('StackDriftStatus', 'UNKNOWN')\n\n                logging.info('drift of {}: {}'.format(\n                    self._stack_name,\n                    drift_answer\n                ))\n\n                if drift_answer == 'DRIFTED':\n                    if self._verbose:\n                        self._print_drift_report()\n                    return False\n                else:\n                    return True\n            else:\n                logging.warning('drift_request_id is None')\n\n            return False\n        except Exception as wtf:\n            logging.error(wtf, exc_info=True)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _print_drift_report(self):\n        try:\n            response = self._cloud_formation.describe_stack_resources(StackName=self._stack_name)\n            rows = []\n            for resource in response.get('StackResources', []):\n                row = []\n                row.append(resource.get('LogicalResourceId', 'unknown'))\n                row.append(resource.get('PhysicalResourceId', 'unknown'))\n                row.append(resource.get('ResourceStatus', 'unknown'))\n                row.append(resource.get('DriftInformation', {}).get('StackResourceDriftStatus', 'unknown'))\n                rows.append(row)\n\n            print('Drift Report:')\n            print(tabulate(rows, headers=[\n                'Logical ID',\n                'Physical ID',\n                'Resource Status',\n                'Drift Info'\n            ]))\n        except Exception as wtf:\n            logging.error(wtf, exc_info=True)\n            return False\n\n        return True", "response": "Prints the drift report of the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a single DJANGO_HISTORY_SETTINGS setting value.", "response": "def get_setting(name):\n    \"\"\" Looks for settings under DJANGO_HISTORY_SETTINGS, supporting dot notation for nested lookups,\n    eg. get_setting('EXCLUDE_CHANGES.fields') \"\"\"\n    dh = getattr(settings, 'DJANGO_HISTORY_SETTINGS', {})\n    result = None\n    for k in name.split('.'):\n        if dh is None:\n            continue\n        result = dh.get(k, None)\n        dh = result\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a tuple of (description, data) where description is the the description that was passed to the CryptProtectData call and data is the decrypted result.", "response": "def CryptUnprotectData(\n\tdata, optional_entropy=None, prompt_struct=None, flags=0):\n\t\"\"\"\n\tReturns a tuple of (description, data) where description is the\n\tthe description that was passed to the CryptProtectData call and\n\tdata is the decrypted result.\n\t\"\"\"\n\tdata_in = DATA_BLOB(data)\n\tentropy = DATA_BLOB(optional_entropy) if optional_entropy else None\n\tdata_out = DATA_BLOB()\n\tptr_description = wintypes.LPWSTR()\n\tres = _CryptUnprotectData(\n\t\tdata_in,\n\t\tctypes.byref(ptr_description),\n\t\tentropy,\n\t\tNone,  # reserved\n\t\tprompt_struct,\n\t\tflags | CRYPTPROTECT_UI_FORBIDDEN,\n\t\tdata_out,\n\t)\n\thandle_nonzero_success(res)\n\tdescription = ptr_description.value\n\tif ptr_description.value is not None:\n\t\tctypes.windll.kernel32.LocalFree(ptr_description)\n\tres = data_out.get_data()\n\tdata_out.free()\n\treturn description, res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to set the data for this blob", "response": "def set_data(self, data):\n\t\t\"Use this method to set the data for this blob\"\n\t\tif data is None:\n\t\t\tself.data_size = 0\n\t\t\tself.data = None\n\t\t\treturn\n\t\tself.data_size = len(data)\n\t\t# create a string buffer so that null bytes aren't interpreted\n\t\t#  as the end of the string\n\t\tself.data = ctypes.cast(ctypes.create_string_buffer(data), ctypes.c_void_p)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the data for this blob", "response": "def get_data(self):\n\t\t\"Get the data for this blob\"\n\t\tarray = ctypes.POINTER(ctypes.c_char * len(self))\n\t\treturn ctypes.cast(self.data, array).contents.raw"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasking a question for input via raw_input and return their answer.", "response": "def query_input(question, default=None, color=default_color):\n    \"\"\"Ask a question for input via raw_input() and return their answer.\n\n    \"question\" is a string that is presented to the user.\n    \"default\" is the presumed answer if the user just hits <Enter>.\n\n    The \"answer\" return value is a str.\n    \"\"\"\n    if default is None or default == '':\n        prompt = ' '\n    elif type(default) == str:\n        prompt = flo(' [{default}] ')\n    else:\n        raise ValueError(\"invalid default answer: '%s'\" % default)\n\n    while True:\n        sys.stdout.write(color(question + prompt))\n        choice = raw_input()\n        if default is not None and choice == '':\n            return default\n        if choice != '':\n            return choice"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef git_ssh_or_die(username, key_dir='~/.ssh'):\n    ''' Check if a ssh-key is created and imported in github.  Else, exit with\n    return value 1 (die).\n    '''\n    key_dir_expanded = os.path.expanduser(key_dir)\n    # ssh pub key dictionary\n    pub_keys = []\n\n    # check if ~/.ssh exists, if not die\n    if not os.path.isdir(key_dir_expanded):\n        print(red(flo('Could not open folder `{key_dir}`.  If you do not have '\n                      'a public ssh key, create one and place it in '\n                      '`~/.ssh/arbitrarykeyname.pub`.  Name your public key '\n                      '`.pub` at the end and run this command again')))\n        sys.exit(0)\n\n    # loop through files in ~/.ssh and search for ssh public keys\n    for name in os.listdir(key_dir_expanded):\n        filename = os.path.join(key_dir_expanded, name)\n        if re.search(\"\\.pub$\", filename):\n            # filename ends with .pub\n            try:\n                with open(filename, 'r') as fh:\n                    for line in fh.readlines():\n                        # ssh public key if *.pub is not empty\n                        pub_keys.append(line.split()[1])\n            except (IOError, OSError):\n                print(red(flo(\n                    'Could not read {filename}. Still moving on ...')))\n\n    if len(pub_keys) < 1:\n        print(red('You do not have a ssh public key.  '\n                  'Please create one first and import it into your github '\n                  'account.  Then restart this command.'))\n        sys.exit(2)\n\n    # get github pub keys from user\n    github_pub_keys = os.popen(flo(\n        'curl -s https://github.com/{username}.keys')).read()\n    if github_pub_keys:\n        for line in github_pub_keys.splitlines():\n            line = line.split()\n            pub_keys.append(line[1])\n\n    # check if matching keys are found\n    if len(pub_keys) == len(set(pub_keys)):\n        print(red('Could not find your public key at github.  '\n                  'Please import your public key into github '\n                  'and rerun this command.'))\n        sys.exit(3)", "response": "Check if a ssh - key is created and imported in github."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new fabsetup - task addon.", "response": "def new_addon():\n    '''Create a repository for a new fabsetup-task addon.\n\n    The repo will contain the fabsetup addon boilerplate.\n\n    Running this task you have to enter:\n    * your github user account (your pypi account should be the same or similar)\n    * addon name\n    * task name\n    * headline, short description, and touched (and created) files and dirs\n      for the task docstring and the README.md\n\n    Created files and dirs:\n\n        ~/.fabsetup-addon-repos/fabsetup-{user}-{addon}\n                                \u251c\u2500\u2500 fabfile-dev.py\n                                \u251c\u2500\u2500 fabfile.py\n                                \u251c\u2500\u2500 fabsetup_{user}_{task}\n                                \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n                                \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 home\n                                \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 USERNAME\n                                \u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 bin\n                                \u2502\u00a0\u00a0 \u2502\u00a0\u00a0             \u2514\u2500\u2500 termdown.template\n                                \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py  <--.\n                                \u2502\u00a0\u00a0 \u2514\u2500\u2500 _version.py      `- task definition\n                                \u251c\u2500\u2500 .git\n                                \u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n                                \u2502\u00a0\u00a0 \u251c\u2500\u2500 config\n                                \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n                                \u251c\u2500\u2500 .gitignore\n                                \u251c\u2500\u2500 README.md\n                                \u251c\u2500\u2500 requirements.txt\n                                \u2514\u2500\u2500 setup.py\n    '''\n    author, author_email = git_name_and_email_or_die()\n\n    username = query_input('github username:')\n\n    git_ssh_or_die(username)\n\n    addonname = query_input('\\naddon name:', default='termdown')\n    addonname = addonname.replace('_', '-').replace(' ', '-')  # minus only\n    full_addonname = flo('fabsetup-{username}-{addonname}')\n    print('\u2514\u2500> full addon name: {0}\\n'.format(\n        cyan(full_addonname)))\n\n    taskname = query_input('task name:', default=addonname.replace('-', '_'))\n    taskname = taskname.replace('-', '_').replace(' ', '_')  # underscores only\n    print('\u2514\u2500> full task name: {0}'.format(\n        cyan(flo('{username}.{taskname}\\n'))))\n\n    addon_dir = os.path.expanduser(flo(\n        '~/.fabsetup-addon-repos/fabsetup-{username}-{addonname}'))\n\n    if os.path.exists(addon_dir):\n        print(red(flo('\\n{addon_dir} already exists.')))\n        print('abort')\n    else:\n        print('~/.gitconfig')\n        print('\u251c\u2500> author: {0} \u2500> LICENSE, setup.py'.format(cyan(author)))\n        print('\u2514\u2500> author email: {0} \u2500> setup.py'.format(cyan(author_email)))\n\n        headline = query_input(\n            '\\nshort task headline:',\n            default='Install or update termdown.')\n\n        description = query_input(\n            '\\ndescribing infos:',\n            default='''Termdown (https://github.com/trehn/termdown) is a\n    \"[c]ountdown timer and stopwatch in your terminal\".\n\n    It installs termdown via `pip install --user termdown`.  Also, it installs a\n    bash-wrapper script at `~/bin/termdown` which is convenient to time pomodoro\n    sessions and pops up a notification when the timer finishes.''')\n\n        touched_files = query_input(\n            '\\naffected files, dirs, and installed packages:',\n            default='~/bin/termdown\\n        '\n                    'pip-package termdown (`--user` install)')\n\n        print('\\naddon git-repository dir: {0}'.format(cyan(addon_dir)))\n        if not query_yes_no('\\ncreate new addon?', default='yes'):\n            print('abort')\n        else:\n            create_files(addon_dir, username, addonname, taskname,\n                         author, author_email,\n                         headline, description, touched_files)\n            init_git_repo(addon_dir)\n            create_github_remote_repo(basedir=addon_dir,\n                                      github_user=username,\n                                      github_repo=full_addonname)\n            summary(addon_dir, username, taskname)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef printMetaDataFor(archive, location):\n    desc = archive.getMetadataForLocation(location)\n    if desc.isEmpty():\n        print(\"  no metadata for '{0}'\".format(location))\n        return None\n\n    print(\"  metadata for '{0}':\".format(location))\n    print(\"     Created : {0}\".format(desc.getCreated().getDateAsString()))\n    for i in range(desc.getNumModified()):\n        print(\"     Modified : {0}\".format(desc.getModified(i).getDateAsString()))\n\n    print(\"     # Creators: {0}\".format(desc.getNumCreators()))\n    for i in range(desc.getNumCreators()):\n        creator = desc.getCreator(i)\n        print(\"       {0} {1}\".format(creator.getGivenName(), creator.getFamilyName()))", "response": "Prints metadata for given location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the content of the combine archive", "response": "def printArchive(fileName):\n    \"\"\" Prints content of combine archive\n\n    :param fileName: path of archive\n    :return: None\n    \"\"\"\n    archive = CombineArchive()\n    if archive.initializeFromArchive(fileName) is None:\n        print(\"Invalid Combine Archive\")\n        return None\n\n    print('*'*80)\n    print('Print archive:', fileName)\n    print('*' * 80)\n    printMetaDataFor(archive, \".\")\n    print(\"Num Entries: {0}\".format(archive.getNumEntries()))\n\n    for i in range(archive.getNumEntries()):\n        entry = archive.getEntry(i)\n        print(\" {0}: location: {1} format: {2}\".format(i, entry.getLocation(), entry.getFormat()))\n        printMetaDataFor(archive, entry.getLocation())\n\n        for j in range(entry.getNumCrossRefs()):\n            print(\"  {0}: crossRef location {1}\".format(j, entry.getCrossRef(j).getLocation()))\n\n        # the entry could now be extracted via\n        # archive.extractEntry(entry.getLocation(), <filename or folder>)\n\n        # or used as string\n        # content = archive.extractEntryToString(entry.getLocation());\n\n    archive.cleanUp()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking cmd. exe s mklink except it will infer directory status of the target.", "response": "def mklink():\n\t\"\"\"\n\tLike cmd.exe's mklink except it will infer directory status of the\n\ttarget.\n\t\"\"\"\n\tfrom optparse import OptionParser\n\tparser = OptionParser(usage=\"usage: %prog [options] link target\")\n\tparser.add_option(\n\t\t'-d', '--directory',\n\t\thelp=\"Target is a directory (only necessary if not present)\",\n\t\taction=\"store_true\")\n\toptions, args = parser.parse_args()\n\ttry:\n\t\tlink, target = args\n\texcept ValueError:\n\t\tparser.error(\"incorrect number of arguments\")\n\tsymlink(target, link, options.directory)\n\tsys.stdout.write(\"Symbolic link created: %(link)s --> %(target)s\\n\" % vars())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _is_target_a_directory(link, rel_target):\n\ttarget = os.path.join(os.path.dirname(link), rel_target)\n\treturn os.path.isdir(target)", "response": "Determine if a target is a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_reparse_point(path):\n\tres = api.GetFileAttributes(path)\n\treturn (\n\t\tres != api.INVALID_FILE_ATTRIBUTES\n\t\tand bool(res & api.FILE_ATTRIBUTE_REPARSE_POINT)\n\t)", "response": "Determines if the given path is a reparse point."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npatch the path to be absolute and prepended with \\\\?", "response": "def _patch_path(path):\n\tr\"\"\"\n\tPaths have a max length of api.MAX_PATH characters (260). If a target path\n\tis longer than that, it needs to be made absolute and prepended with\n\t\\\\?\\ in order to work with API calls.\n\tSee http://msdn.microsoft.com/en-us/library/aa365247%28v=vs.85%29.aspx for\n\tdetails.\n\t\"\"\"\n\tif path.startswith('\\\\\\\\?\\\\'):\n\t\treturn path\n\tabs_path = os.path.abspath(path)\n\tif not abs_path[1] == ':':\n\t\t# python doesn't include the drive letter, but \\\\?\\ requires it\n\t\tabs_path = os.getcwd()[:2] + abs_path\n\treturn '\\\\\\\\?\\\\' + abs_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if a path is a symlink.", "response": "def is_symlink(path):\n\t\"\"\"\n\tAssuming path is a reparse point, determine if it's a symlink.\n\t\"\"\"\n\tpath = _patch_path(path)\n\ttry:\n\t\treturn _is_symlink(next(find_files(path)))\n\t# comment below workaround for PyCQA/pyflakes#376\n\texcept WindowsError as orig_error:  # noqa: F841\n\t\ttmpl = \"Error accessing {path}: {orig_error.message}\"\n\t\traise builtins.WindowsError(tmpl.format(**locals()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds files in a Windows path.", "response": "def find_files(spec):\n\tr\"\"\"\n\tA pythonic wrapper around the FindFirstFile/FindNextFile win32 api.\n\n\t>>> root_files = tuple(find_files(r'c:\\*'))\n\t>>> len(root_files) > 1\n\tTrue\n\t>>> root_files[0].filename == root_files[1].filename\n\tFalse\n\n\tThis test might fail on a non-standard installation\n\t>>> 'Windows' in (fd.filename for fd in root_files)\n\tTrue\n\t\"\"\"\n\tfd = api.WIN32_FIND_DATA()\n\thandle = api.FindFirstFile(spec, byref(fd))\n\twhile True:\n\t\tif handle == api.INVALID_HANDLE_VALUE:\n\t\t\traise WindowsError()\n\t\tyield fd\n\t\tfd = api.WIN32_FIND_DATA()\n\t\tres = api.FindNextFile(handle, byref(fd))\n\t\tif res == 0:  # error\n\t\t\terror = WindowsError()\n\t\t\tif error.code == api.ERROR_NO_MORE_FILES:\n\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\traise error\n\t# todo: how to close handle when generator is destroyed?\n\t# hint: catch GeneratorExit\n\twindll.kernel32.FindClose(handle)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_final_path(path):\n\tdesired_access = api.NULL\n\tshare_mode = (\n\t\tapi.FILE_SHARE_READ | api.FILE_SHARE_WRITE | api.FILE_SHARE_DELETE\n\t)\n\tsecurity_attributes = api.LPSECURITY_ATTRIBUTES()  # NULL pointer\n\thFile = api.CreateFile(\n\t\tpath,\n\t\tdesired_access,\n\t\tshare_mode,\n\t\tsecurity_attributes,\n\t\tapi.OPEN_EXISTING,\n\t\tapi.FILE_FLAG_BACKUP_SEMANTICS,\n\t\tapi.NULL,\n\t)\n\n\tif hFile == api.INVALID_HANDLE_VALUE:\n\t\traise WindowsError()\n\n\tbuf_size = api.GetFinalPathNameByHandle(\n\t\thFile, LPWSTR(), 0, api.VOLUME_NAME_DOS)\n\thandle_nonzero_success(buf_size)\n\tbuf = create_unicode_buffer(buf_size)\n\tresult_length = api.GetFinalPathNameByHandle(\n\t\thFile, buf, len(buf), api.VOLUME_NAME_DOS)\n\n\tassert result_length < len(buf)\n\thandle_nonzero_success(result_length)\n\thandle_nonzero_success(api.CloseHandle(hFile))\n\n\treturn buf[:result_length]", "response": "This function returns the ultimate location of a given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a path from start to target where target is relative to start.", "response": "def resolve_path(target, start=os.path.curdir):\n\tr\"\"\"\n\tFind a path from start to target where target is relative to start.\n\n\t>>> tmp = str(getfixture('tmpdir_as_cwd'))\n\n\t>>> findpath('d:\\\\')\n\t'd:\\\\'\n\n\t>>> findpath('d:\\\\', tmp)\n\t'd:\\\\'\n\n\t>>> findpath('\\\\bar', 'd:\\\\')\n\t'd:\\\\bar'\n\n\t>>> findpath('\\\\bar', 'd:\\\\foo') # fails with '\\\\bar'\n\t'd:\\\\bar'\n\n\t>>> findpath('bar', 'd:\\\\foo')\n\t'd:\\\\foo\\\\bar'\n\n\t>>> findpath('\\\\baz', 'd:\\\\foo\\\\bar') # fails with '\\\\baz'\n\t'd:\\\\baz'\n\n\t>>> os.path.abspath(findpath('\\\\bar')).lower()\n\t'c:\\\\bar'\n\n\t>>> os.path.abspath(findpath('bar'))\n\t'...\\\\bar'\n\n\t>>> findpath('..', 'd:\\\\foo\\\\bar')\n\t'd:\\\\foo'\n\n\tThe parent of the root directory is the root directory.\n\t>>> findpath('..', 'd:\\\\')\n\t'd:\\\\'\n\t\"\"\"\n\treturn os.path.normpath(join(start, target))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace_symlink_target(link):\n\n\tif not is_symlink(link):\n\t\traise ValueError(\"link must point to a symlink on the system\")\n\twhile is_symlink(link):\n\t\torig = os.path.dirname(link)\n\t\tlink = readlink(link)\n\t\tlink = resolve_path(link, orig)\n\treturn link", "response": "Trace a symlink target."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a symbolic link and returns the path to that symbolic link.", "response": "def readlink(link):\n\t\"\"\"\n\treadlink(link) -> target\n\tReturn a string representing the path to which the symbolic link points.\n\t\"\"\"\n\thandle = api.CreateFile(\n\t\tlink,\n\t\t0,\n\t\t0,\n\t\tNone,\n\t\tapi.OPEN_EXISTING,\n\t\tapi.FILE_FLAG_OPEN_REPARSE_POINT | api.FILE_FLAG_BACKUP_SEMANTICS,\n\t\tNone,\n\t)\n\n\tif handle == api.INVALID_HANDLE_VALUE:\n\t\traise WindowsError()\n\n\tres = reparse.DeviceIoControl(\n\t\thandle, api.FSCTL_GET_REPARSE_POINT, None, 10240)\n\n\tbytes = create_string_buffer(res)\n\tp_rdb = cast(bytes, POINTER(api.REPARSE_DATA_BUFFER))\n\trdb = p_rdb.contents\n\tif not rdb.tag == api.IO_REPARSE_TAG_SYMLINK:\n\t\traise RuntimeError(\"Expected IO_REPARSE_TAG_SYMLINK, but got %d\" % rdb.tag)\n\n\thandle_nonzero_success(api.CloseHandle(handle))\n\treturn rdb.get_substitute_name()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patch_os_module():\n\tif not hasattr(os, 'symlink'):\n\t\tos.symlink = symlink\n\t\tos.path.islink = islink\n\tif not hasattr(os, 'readlink'):\n\t\tos.readlink = readlink", "response": "Patch the os module to include the symlink and readlink functions if not present."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset file attributes. e. g. hidden read_only hidden read_only.", "response": "def SetFileAttributes(filepath, *attrs):\n\t\"\"\"\n\tSet file attributes. e.g.:\n\n\t\tSetFileAttributes('C:\\\\foo', 'hidden')\n\n\tEach attr must be either a numeric value, a constant defined in\n\tjaraco.windows.filesystem.api, or one of the nice names\n\tdefined in this function.\n\t\"\"\"\n\tnice_names = collections.defaultdict(\n\t\tlambda key: key,\n\t\thidden='FILE_ATTRIBUTE_HIDDEN',\n\t\tread_only='FILE_ATTRIBUTE_READONLY',\n\t)\n\tflags = (getattr(api, nice_names[attr], attr) for attr in attrs)\n\tflags = functools.reduce(operator.or_, flags)\n\thandle_nonzero_success(api.SetFileAttributes(filepath, flags))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef needs_repo_fabsetup_custom(func):\n    '''Decorator, ensures that fabsetup-custom exists and it is a git repo.'''\n    from fabric.api import local\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if not os.path.exists(FABSETUP_CUSTOM_DIR):\n            msg = '''\\\nGit repository ~/.fabsetup-custom with configurations does not exist.\nThis configs are required to use fabsetup.\n\nClone it if you already have your own fabsetup-custom repository:\n\n    git clone <user>@<hostname>:/path/to/fabsetup-custom.git  ~/.fabetup-custom\n\nElse, initialize a new repository.\n\nInit a new repository `~/.fabsetup-custom`?'''\n            if not query_yes_no(msg, default='yes'):\n                sys.exit('abort')\n            custom_dir = FABSETUP_CUSTOM_DIR\n            presetting_dir = join(FABFILE_DATA_DIR,\n                                  'presetting-fabsetup-custom')\n            if not isdir(custom_dir):\n                print(yellow('\\n** **     Init ') +\n                      yellow('~/.fabsetup-custom', bold=True) +\n                      yellow('      ** **\\n'))\n                print(yellow(flo('** Create files in dir {custom_dir} **')))\n                local(flo('mkdir -p {custom_dir}'))\n                local(flo('cp -r --no-clobber {presetting_dir}/. {custom_dir}'))\n                import_fabsetup_custom(globals())\n            else:\n                with quiet():\n                    local(flo(\n                        'cp -r --no-clobber {presetting_dir}/. {custom_dir}'))\n\n            if not isdir(join(custom_dir, '.git')):\n                print(yellow(\n                    '\\n** Git repo ~/.fabsetup-custom: '\n                    'init and first commit **'))\n                local(flo('cd {custom_dir} && git init'))\n                local(flo('cd {custom_dir} && git add .'))\n                local(flo('cd {custom_dir} && git commit -am \"Initial commit\"'))\n                print(yellow(\"** Done. Don't forget to create a backup of your \"\n                             '~/.fabsetup-custom repo **\\n'))\n                print(yellow(\"** But do not make it public, it's custom **\\n\",\n                             bold=True))\n            else:\n                with quiet():\n                    cmd = flo('cd {custom_dir} && git status --porcelain')\n                    res = local(cmd, capture=True)\n                    if res:\n                        print(yellow('\\n** git repo  ') +\n                              magenta('~/.fabsetup-custom  ') +\n                              yellow('has uncommitted changes: **'))\n                        print(cmd)\n                        print(yellow(res, bold=True))\n                        print(yellow(\n                            \"** Don't forget to commit them and make a \"\n                            \"backup of your repo **\\n\"))\n        return func(*args, **kwargs)\n    return wrapper", "response": "Decorator that ensures that fabsetup - custom exists and it is a git repo."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef needs_packages(*packages):\n    '''Decorator: ensure that packages are installed on host given by fabric\n    argument `-H` (local or remote).\n    '''\n    def real_decorator(func):\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            non_installed = _non_installed(packages)\n            if non_installed:\n                what_for = 'in order to run this task'\n                install_packages(non_installed, what_for=what_for)\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return real_decorator", "response": "Decorator that ensures that packages are installed on host given by fabric\n    argument - H."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef task(func, *args, **kwargs):\n    '''Composition of decorator functions for inherent self-documentation on\n    task execution.\n\n    On execution, each task prints out its name and its first docstring line.\n    '''\n    prefix = '\\n# '\n    tail = '\\n'\n    return fabric.api.task(\n        print_full_name(color=magenta,\n                        prefix=prefix,\n                        tail=tail)(print_doc1(func)),\n        *args,\n        **kwargs)", "response": "A decorator function for inherent self - documentation on\n    task execution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if current user is a sudoer else False.", "response": "def _is_sudoer(what_for=''):\n    '''Return True if current user is a sudoer, else False.\n\n    Should be called non-eager if sudo is wanted only.\n    '''\n    if env.get('nosudo', None) is None:\n        if what_for:\n            print(yellow(what_for))\n        with quiet():\n            # possible outputs:\n            #  en: \"Sorry, user winhost-tester may not run sudo on <hostname>\"\n            #  en: \"sudo: a password is required\"     (=> is sudoer)\n            #  de: \"sudo: Ein Passwort ist notwendig\" (=> is sudoer)\n            output = run('sudo -nv', capture=True)\n            env.nosudo = not (output.startswith('sudo: ') or output == '')\n        if env.nosudo:\n            print('Cannot execute sudo-commands')\n    return not env.nosudo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to install. deb packages given by list.", "response": "def install_packages(packages,\n                     what_for='for a complete setup to work properly'):\n    '''Try to install .deb packages given by list.\n\n    Return True, if packages could be installed or are installed already, or if\n    they cannot be installed but the user gives feedback to continue.\n\n    Else return False.\n    '''\n    res = True\n    non_installed_packages = _non_installed(packages)\n    packages_str = '  '.join(non_installed_packages)\n    if non_installed_packages:\n        with quiet():\n            dpkg = _has_dpkg()\n        hint = '  (You may have to install them manually)'\n        do_install = False\n        go_on = True\n        if dpkg:\n            if _is_sudoer('Want to install dpkg packages'):\n                do_install = True\n            else:\n                do_install is False  # cannot install anything\n                info = yellow(' '.join([\n                    'This deb packages are missing to be installed',\n                    flo(\"{what_for}: \"), ', '.join(non_installed_packages),\n                ]))\n                question = '  Continue anyway?'\n                go_on = query_yes_no(info + hint + question, default='no')\n        else:\n            # dpkg == False, unable to determine if packages are installed\n            do_install = False  # cannot install anything\n            info = yellow(' '.join([\n                flo('Required {what_for}: '),\n                ', '.join(non_installed_packages),\n            ]))\n            go_on = query_yes_no(info + hint + '  Continue?', default='yes')\n        if not go_on:\n            sys.exit('Abort')\n        if do_install:\n            command = flo('sudo  apt-get install {packages_str}')\n            res = run(command).return_code == 0\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef checkup_git_repo_legacy(url, name=None, base_dir='~/repos',\n                            verbose=False, prefix='', postfix=''):\n    '''Checkout or update a git repo.'''\n    if not name:\n        match = re.match(r'.*/(.+)\\.git', url)\n        assert match, flo(\"Unable to extract repo name from '{url}'\")\n        name = match.group(1)\n    assert name is not None, flo('Cannot extract repo name from repo: {url}')\n    assert name != '', flo('Cannot extract repo name from repo: {url} (empty)')\n    if verbose:\n        name_blue = blue(name)\n        print_msg(flo('{prefix}Checkout or update {name_blue}{postfix}'))\n    if not exists(base_dir):\n        run(flo('mkdir -p {base_dir}'))\n    if not exists(flo('{base_dir}/{name}/.git')):\n        run(flo('  &&  '.join([\n                'cd {base_dir}',\n                'git clone  {url}  {name}'])),\n            msg='clone repo')\n    else:\n        if verbose:\n            print_msg('update: pull from origin')\n        run(flo('cd {base_dir}/{name}  &&  git pull'))\n    return name", "response": "Checkout or update a git repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls file with path on the host target.", "response": "def install_file_legacy(path, sudo=False, from_path=None, **substitutions):\n    '''Install file with path on the host target.\n\n    The from file is the first of this list which exists:\n     * custom file\n     * custom file.template\n     * common file\n     * common file.template\n    '''\n    # source paths 'from_custom' and 'from_common'\n    from_path = from_path or path\n    # remove beginning '/' (if any), eg '/foo/bar' -> 'foo/bar'\n    from_tail = join('files', from_path.lstrip(os.sep))\n    if from_path.startswith('~/'):\n        from_tail = join('files', 'home', 'USERNAME',\n                         from_path[2:])  # without beginning '~/'\n    from_common = join(FABFILE_DATA_DIR, from_tail)\n    from_custom = join(FABSETUP_CUSTOM_DIR, from_tail)\n\n    # target path 'to_' (path or tempfile)\n    for subst in ['SITENAME', 'USER', 'ADDON', 'TASK']:\n        sitename = substitutions.get(subst, False)\n        if sitename:\n            path = path.replace(subst, sitename)\n    to_ = path\n    if sudo:\n        to_ = join(os.sep, 'tmp', 'fabsetup_' + os.path.basename(path))\n    path_dir = dirname(path)\n\n    # copy file\n    if isfile(from_custom):\n        run(flo('mkdir -p  {path_dir}'))\n        put(from_custom, to_)\n    elif isfile(from_custom + '.template'):\n        _install_file_from_template_legacy(from_custom + '.template', to_=to_,\n                                    **substitutions)\n    elif isfile(from_common):\n        run(flo('mkdir -p  {path_dir}'))\n        put(from_common, to_)\n    else:\n        _install_file_from_template_legacy(from_common + '.template', to_=to_,\n                                    **substitutions)\n    if sudo:\n        run(flo('sudo mv --force  {to_}  {path}'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_user_command_legacy(command, **substitutions):\n    '''Install command executable file into users bin dir.\n\n    If a custom executable exists it would be installed instead of the \"normal\"\n    one.  The executable also could exist as a <command>.template file.\n    '''\n    path = flo('~/bin/{command}')\n    install_file_legacy(path, **substitutions)\n    run(flo('chmod 755 {path}'))", "response": "Install command executable file into users bin dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns 2 - Tuple of from_custom from_default for a given path.", "response": "def _determine_froms(addon_package, path):\n    '''Return 2-Tuple (from_custom, from_default) for a given path.\n\n    Example:\n\n        >>> FABSETUP_CUSTOM_DIR = '/home/theno/.fabsetup-custom'\n        >>>\n        >>> # path is an abpath\n        ...\n        >>> addon_package = AddonPackage(module_dir='/home/theno/'\n        ...                              '.fabsetup-addon-repos/'\n        ...                              'fabsetup-theno-termdown/'\n        ...                              'fabsetup_theno_termdown')\n        >>> _determine_froms(addon_package, path='/absolute/path/foo.bar')\n        ('/home/theno/.fabsetup-custom/fabsetup-theno-termdown/files/absolute/path/foo.bar', '/home/theno/.fabsetup-addon-repos/fabsetup-theno-termdown/fabsetup_theno_termdown/files/absolute/path/foo.bar')\n        >>>\n        >>> # with home-dir expansion\n        ...\n        >>> addon_package = AddonPackage(module_dir='/home/theno/'\n        ...                              '.fabsetup-addon-repos/'\n        ...                              'fabsetup-theno-termdown/'\n        ...                              'fabsetup_theno_termdown')\n        >>> _determine_froms(addon_package, path='~/foo/bar.baz')\n        ('/home/theno/.fabsetup-custom/fabsetup-theno-termdown/files/home/USERNAME/foo/bar.baz', '/home/theno/.fabsetup-addon-repos/fabsetup-theno-termdown/fabsetup_theno_termdown/files/home/USERNAME/foo/bar.baz')\n\n    '''\n    # from_tail\n    if path.startswith('~/'):\n        path_tail = path[2:]  # path without beginning '~/'\n        from_tail = join('home', 'USERNAME', path_tail)\n    else:\n        # remove beginning '/' (if any), eg '/foo/bar' -> 'foo/bar'\n        from_tail = path.lstrip(os.sep)\n\n    from_default = join(addon_package.default_files_basedir, from_tail)\n    from_custom = join(addon_package.custom_files_basedir, from_tail)\n\n    return from_custom, from_default"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_or_append_line(filename, prefix, new_line, keep_backup=True,\n                          append=True):\n    '''Search in file 'filename' for a line starting with 'prefix' and replace\n    the line by 'new_line'.\n\n    If a line starting with 'prefix' not exists 'new_line' will be appended.\n    If the file not exists, it will be created.\n\n    Return False if new_line was appended, else True (i.e. if the prefix was\n    found within of the file).\n    '''\n    result = None\n    if env.host_string == 'localhost':\n        result = update_or_append_local(filename, prefix, new_line,\n                                        keep_backup, append)\n    else:\n        tmp_dir = tempfile.mkdtemp(suffix='', prefix='fabsetup_')\n        # fabric.api.local(flo('chmod 777 {tmp_dir}'))\n        local_path = os.path.join(tmp_dir, os.path.basename(filename))\n        fabric.operations.get(remote_path=filename, local_path=local_path,\n                              use_sudo=True, temp_dir='/tmp')\n        result = update_or_append_local(local_path, prefix, new_line,\n                                        keep_backup, append)\n        put(local_path, remote_path=filename, use_sudo=True, temp_dir='/tmp')\n        with quiet():\n            fabric.api.local(flo('rm -rf {tmp_dir}'))\n    return result", "response": "Search in file filename for a line starting with prefix and replace\n    the line by new_line. Return False if the line was not found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommenting out a line in a file.", "response": "def comment_out_line(filename, line, comment='#'):\n    '''Comment line out by putting a comment sign in front of the line.\n\n    If the file does not contain the line, the files content will not be\n    changed (but the file will be touched in every case).\n    '''\n    return comment_out_local(filename, line, comment,\n                             update_or_append_line=update_or_append_line)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uncomment_or_update_or_append_line(filename, prefix, new_line, comment='#',\n                                       keep_backup=True):\n    '''Remove the comment of an commented out line and make the line \"active\".\n\n    If such an commented out line not exists it would be appended.\n    '''\n    return uua_local(filename, prefix, new_line, comment, keep_backup,\n                     update_or_append_line=update_or_append_line)", "response": "Uncomment a line in a UUA file and update the active line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _line_2_pair(line):\n    '''Return bash variable declaration as name-value pair.\n\n    Name as lower case str. Value itself only without surrounding '\"' (if any).\n\n    For example, _line_2_pair('NAME=\"Ubuntu\"') will return ('name', 'Ubuntu')\n    '''\n    key, val = line.split('=')\n    return key.lower(), val.strip('\"')", "response": "Return bash variable declaration as name - value pair."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fetch_os_release_infos():\n    '''Return variable content of file '/etc/os-release' as dict.\n\n    Return-example (in case of an Ubuntu 16.04):\n        {\n            'name': 'Ubuntu',\n            'version': '16.04.1 LTS (Xenial Xerus)',\n            'version_id': '16.04',\n            ...\n        }\n    '''\n    os_release_dict = {}\n    lines = []\n    with fabric.api.hide('output'):\n        lines = run('cat /etc/os-release', capture=True).split('\\n')\n    os_release_dict = dict([_line_2_pair(line.strip('\\r'))\n                            for line in lines\n                            if line.strip() != ''])\n    return os_release_dict", "response": "Return variable content of file '/etc / os - release as dict.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if OS name in the given fabric param - H is the same as given by argument False otherwise.", "response": "def is_os(name, version_id=None):\n    '''Return True if OS name in /etc/lsb-release of host given by fabric param\n    `-H` is the same as given by argument, False else.\n\n    If arg version_id is not None only return True if it is the same as in\n    /etc/lsb-release, too.\n\n    Args:\n        name: 'Debian GNU/Linux', 'Ubuntu'\n        version_id(None or str): None,\n                                '14.04', (Ubuntu)\n                                '16.04', (Ubuntu)\n                                '8', (Debian)\n    '''\n    result = False\n    os_release_infos = _fetch_os_release_infos()\n\n    if name == os_release_infos.get('name', None):\n\n        if version_id is None:\n            result = True\n        elif version_id == os_release_infos.get('version_id', None):\n            result = True\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dn_cn_of_certificate_with_san(domain):\n    '''Return the Common Name (cn) from the Distinguished Name (dn) of the\n    certificate which contains the `domain` in its Subject Alternativ Name (san)\n    list.\n\n    Needs repo ~/.fabsetup-custom.\n\n    Return None if no certificate is configured with `domain` in SAN.\n    '''\n    cn_dn = None\n    from config import domain_groups\n    cns = [domains[0]\n           for domains\n           in domain_groups\n           if domain in domains]\n    if cns:\n        if len(cns) > 1:\n            print_msg(yellow(flo('Several certificates are configured to '\n                                 'contain {domain} '\n                                 '(You should clean-up your config.py)\\n')))\n        cn_dn = cns[0]\n    return cn_dn", "response": "Return the Common Name ( cn ) of the Distinguished Name of the certificate which contains the domain in its Subject Alternativ Name ( san."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract supported python minor versions from setup. py and return them as a list of str.", "response": "def extract_minors_from_setup_py(filename_setup_py):\n    '''Extract supported python minor versions from setup.py and return them\n    as a list of str.\n\n    Return example:\n\n        ['2.6', '2.7', '3.3', '3.4', '3.5', '3.6']\n    '''\n    # eg: minors_str = '2.6\\n2.7\\n3.3\\n3.4\\n3.5\\n3.6'\n    minors_str = fabric.api.local(\n        flo('grep --perl-regexp --only-matching '\n            '\"(?<=Programming Language :: Python :: )\\\\d+\\\\.\\\\d+\" '\n            '{filename_setup_py}'),\n        capture=True)\n    # eg: minors = ['2.6', '2.7', '3.3', '3.4', '3.5', '3.6']\n    minors = minors_str.split()\n    return minors"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the highest minor version of a list of stable ( semantic ) versions.", "response": "def highest_minor(python_versions):\n    '''Return highest minor of a list of stable (semantic) versions.\n\n    Example:\n        >>> python_versions = [\n        ...     '2.6.9', '2.7.14', '3.3.7', '3.4.8', '3.5.5', '3.6.4']\n        >>> highest_minor(python_versions)\n        '3.6'\n\n    '''\n    highest = python_versions[-1]\n    major, minor, patch = highest.split('.', 2)\n    return flo('{major}.{minor}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vim_janus(uninstall=None):\n    '''Install or update Janus, a distribution of addons and mappings for vim.\n\n    More info:\n      https://github.com/carlhuda/janus\n      Customization: https://github.com/carlhuda/janus/wiki/Customization\n\n    Args:\n        uninstall: If not None, Uninstall janus and restore old vim config\n    '''\n    if uninstall is not None:\n        uninstall_janus()\n    else:\n        if not exists('~/.vim/janus'):\n            print_msg('not installed => install')\n            install_janus()\n        else:\n            print_msg('already installed => update')\n            update_janus()\n        customize_janus()\n        show_files_used_by_vim_and_janus()", "response": "Install or update Janus a distribution of addons and mappings for vim."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uninstall_janus():\n    '''Remove all janus files and dirs and (try to) restore previous vim config.\n    '''\n    if exists('~/.vim/janus'):\n        run('rm -rf ~/.vim', msg='delete janus repo dir')\n        with warn_only():\n            run('rm -rf ~/.janus', msg='delete ~/.janus dir')\n            run('bash -c \"rm ~/.{,g}vimrc{,.before,.after}\"',\n                msg='delete ~/.vimrc, ~/.vimrc.before, ~/.vimrc.after, '\n                    '~/.gvimrc, ~/.gvimrc.before and ~/.gvimrc.after')\n            if exists('~/.vim.old'):\n                run('mv ~/.vim.old  ~/.vim', msg='restore ~/.vim dir')\n            for fname in ['~/.vimrc', '~/.gvimrc']:\n                if exists(flo('{fname}.old')):\n                    run(flo('mv {fname}.old  {fname}'),\n                        msg=flo('restore {fname}'))\n        run('ls -hal ~/.*vim*', msg='\\nvim config restored:')\n    else:\n        print_msg('janus is not installed; nothing to do (abort)')\n        exit(1)", "response": "Uninstall all janus files and directories and restore previous vim config."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scan(host, port=80, url=None, https=False, timeout=1, max_size=65535):\n    starts = OrderedDict()\n    ends = OrderedDict()\n    port = int(port)\n    result = dict(\n        host=host, port=port, state='closed', durations=OrderedDict()\n    )\n    if url:\n        timeout = 1\n        result['code'] = None\n\n    starts['all'] = starts['dns'] = datetime.datetime.now()\n\n    # DNS Lookup\n    try:\n        hostip = socket.gethostbyname(host)\n        result['ip'] = hostip\n        ends['dns'] = datetime.datetime.now()\n    except socket.gaierror:\n        raise ScanFailed('DNS Lookup failed', result=result)\n\n    # TCP Connect\n    starts['connect'] = datetime.datetime.now()\n    network_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    network_socket.settimeout(timeout)\n    result_connection = network_socket.connect_ex((hostip, port))\n    ends['connect'] = datetime.datetime.now()\n\n    # SSL\n    if https:\n        starts['ssl'] = datetime.datetime.now()\n        try:\n            network_socket = ssl.wrap_socket(network_socket)\n        except socket.timeout:\n            raise ScanFailed('SSL socket timeout', result=result)\n        ends['ssl'] = datetime.datetime.now()\n\n    # Get request\n    if result_connection == 0 and url:\n        starts['request'] = datetime.datetime.now()\n        network_socket.send(\n            \"GET {0} HTTP/1.0\\r\\nHost: {1}\\r\\n\\r\\n\".format(\n                url, host\n            ).encode('ascii'))\n        if max_size:\n            data = network_socket.recv(max_size)\n        else:\n            data = network_socket.recv()\n        result['length'] = len(data)\n        data = data.decode('ascii', errors='ignore')\n        result['response'] = (data)\n        try:\n            result['code'] = int(data.split('\\n')[0].split()[1])\n        except IndexError:\n            pass\n        ends['request'] = datetime.datetime.now()\n    network_socket.close()\n\n    # Calculate durations\n    ends['all'] = datetime.datetime.now()\n    for duration in starts.keys():\n        if duration in ends.keys():\n            result['durations'][duration] = ends[duration] - starts[duration]\n    if result_connection == 0:\n        result['state'] = 'open'\n    return result", "response": "Scan a network port and return a dictionary of the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ping(host, port=80, url=None, https=False, timeout=1, max_size=65535, sequence=0):\n    try:\n        result = scan(host=host, port=port, url=url, https=https, timeout=timeout, max_size=max_size)\n    except ScanFailed as failure:\n        result = failure.result\n        result['error'] = True\n        result['error_message'] = str(failure)\n    result_obj = PingResponse(\n        host=host, port=port, ip=result.get('ip', None), sequence=sequence,\n        durations=result.get('durations', None),\n        code=result.get('code', None),\n        state=result.get('state', 'unknown'),\n        length=result.get('length', 0),\n        response=result.get('response', None),\n        error=result.get('error', False),\n        error_message=result.get('error_message', None),\n        responding=True if result.get('state', 'unknown') in ['open'] else False,\n        start=datetime.datetime.now(),\n        end=datetime.datetime.now() + result['durations'].get('all', datetime.timedelta(0)) if result.get('durations', None) else None\n    )\n    return result_obj", "response": "Ping a host and return a PingResponse object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upsert(version, stack, ini, dryrun, yaml, no_poll, work_directory):\n    ini_data = read_config_info(ini)\n    if 'environment' not in ini_data:\n        print('[environment] section is required in the INI file')\n        sys.exit(1)\n\n    if version:\n        ini_data['codeVersion'] = version\n    else:\n        ini_data['codeVersion'] = str(int(time.time()))\n\n    if 'region' not in ini_data['environment']:\n        ini_data['environment']['region'] = find_myself()\n\n    ini_data['yaml'] = bool(yaml)\n    ini_data['no_poll'] = bool(no_poll)\n    ini_data['dryrun'] = bool(dryrun)\n\n    if stack:\n        ini_data['environment']['stack_name'] = stack\n\n    if work_directory:\n        try:\n            os.chdir(work_directory)\n        except Exception as wtf:\n            logging.error(wtf)\n            sys.exit(2)\n\n    print(json.dumps(ini_data, indent=2))\n    start_upsert(ini_data)", "response": "This function is used to create or update a CloudFormation stack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(stack, region, profile):\n    ini_data = {}\n    environment = {}\n\n    environment['stack_name'] = stack\n    if region:\n        environment['region'] = region\n    else:\n        environment['region'] = find_myself()\n\n    if profile:\n        environment['profile'] = profile\n\n    ini_data['environment'] = environment\n\n    if start_smash(ini_data):\n        sys.exit(0)\n    else:\n        sys.exit(1)", "response": "Delete the given CloudFormation stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all CloudFormation stacks in the given region.", "response": "def list(region, profile):\n    \"\"\"\n    List all the CloudFormation stacks in the given region.\n    \"\"\"\n    ini_data = {}\n    environment = {}\n\n    if region:\n        environment['region'] = region\n    else:\n        environment['region'] = find_myself()\n\n    if profile:\n        environment['profile'] = profile\n\n    ini_data['environment'] = environment\n    if start_list(ini_data):\n        sys.exit(0)\n    else:\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nproduce a CloudFormation drift report for the given stack.", "response": "def drift(stack, region, profile):\n    \"\"\"\n    Produce a CloudFormation drift report for the given stack.\n    \"\"\"\n    logging.debug('finding drift - stack: {}'.format(stack))\n    logging.debug('region: {}'.format(region))\n    logging.debug('profile: {}'.format(profile))\n    tool = DriftTool(\n        Stack=stack,\n        Region=region,\n        Profile=profile,\n        Verbose=True\n    )\n\n    if tool.determine_drift():\n        sys.exit(0)\n    else:\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the INI file and return a dictionary of stuff from the INI file", "response": "def read_config_info(ini_file):\n    \"\"\"\n    Read the INI file\n\n    Args:\n        ini_file - path to the file\n\n    Returns:\n        A dictionary of stuff from the INI file\n\n    Exits:\n        1 - if problems are encountered\n    \"\"\"\n    try:\n        config = RawConfigParser()\n        config.optionxform = lambda option: option\n        config.read(ini_file)\n        the_stuff = {}\n        for section in config.sections():\n            the_stuff[section] = {}\n            for option in config.options(section):\n                the_stuff[section][option] = config.get(section, option)\n\n        return the_stuff\n    except Exception as wtf:\n        logging.error('Exception caught in read_config_info(): {}'.format(wtf))\n        traceback.print_exc(file=sys.stdout)\n        return sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the stack info.", "response": "def print_stack_info(self):\n        '''\n        List resources from the given stack\n\n        Args:\n            None\n\n        Returns:\n            A dictionary filled resources or None if things went sideways\n        '''\n        try:\n            rest_api_id = None\n            deployment_found = False\n\n            response = self._cf_client.describe_stack_resources(\n                StackName=self._stack_name\n            )\n\n            print('\\nThe following resources were created:')\n            rows = []\n            for resource in response['StackResources']:\n                if resource['ResourceType'] == 'AWS::ApiGateway::RestApi':\n                    rest_api_id = resource['PhysicalResourceId']\n                elif resource['ResourceType'] == 'AWS::ApiGateway::Deployment':\n                    deployment_found = True\n\n                row = []\n                row.append(resource['ResourceType'])\n                row.append(resource['LogicalResourceId'])\n                row.append(resource['PhysicalResourceId'])\n                rows.append(row)\n                '''\n                print('\\t{}\\t{}\\t{}'.format(\n                        resource['ResourceType'],\n                        resource['LogicalResourceId'],\n                        resource['PhysicalResourceId']\n                    )\n                )\n                '''\n            print(tabulate(rows, headers=['Resource Type', 'Logical ID', 'Physical ID']))\n\n            if rest_api_id and deployment_found:\n                url = 'https://{}.execute-api.{}.amazonaws.com/{}'.format(\n                    rest_api_id,\n                    self._region,\n                    '<stage>'\n                )\n                print('\\nThe deployed service can be found at this URL:')\n                print('\\t{}\\n'.format(url))\n\n            return response\n        except Exception as wtf:\n            print(wtf)\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_stack_events(self):\n        '''\n        List events from the given stack\n\n        Args:\n            None\n\n        Returns:\n            None\n        '''\n        first_token = '7be7981bd6287dd8112305e8f3822a6f'\n        keep_going = True\n        next_token = first_token\n        current_request_token = None\n        rows = []\n        try:\n            while keep_going and next_token:\n                if next_token == first_token:\n                    response = self._cf_client.describe_stack_events(\n                        StackName=self._stack_name\n                    )\n                else:\n                    response = self._cf_client.describe_stack_events(\n                        StackName=self._stack_name,\n                        NextToken=next_token\n                    )\n\n                next_token = response.get('NextToken', None)\n                for event in response['StackEvents']:\n                    row = []\n                    event_time = event.get('Timestamp')\n                    request_token = event.get('ClientRequestToken', 'unknown')\n                    if current_request_token is None:\n                        current_request_token = request_token\n                    elif current_request_token != request_token:\n                        keep_going = False\n                        break\n\n                    row.append(event_time.strftime('%x %X'))\n                    row.append(event.get('LogicalResourceId'))\n                    row.append(event.get('ResourceStatus'))\n                    row.append(event.get('ResourceStatusReason', ''))\n                    rows.append(row)\n\n            if len(rows) > 0:\n                print('\\nEvents for the current upsert:')\n                print(tabulate(rows, headers=['Time', 'Logical ID', 'Status', 'Message']))\n                return True\n            else:\n                print('\\nNo stack events found\\n')\n        except Exception as wtf:\n            print(wtf)\n\n        return False", "response": "Prints the list of events from the given stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets up or update a trac project.", "response": "def trac():\n    '''Set up or update a trac project.\n\n    This trac installation uses python2, git, sqlite (trac-default), gunicorn,\n    and nginx.\n\n    The connection is https-only and secured by a letsencrypt certificate.  This\n    certificate must be created separately with task setup.server_letsencrypt.\n\n    This task installes or updates to the latest trac version hosted at\n    https://pypi.python.org/pypi/Trac\n\n    Created and modified files and dirs of this task:\n\n        ```\n        ~/sites/<sitename>      <--- example: sitename = trac.example.com\n        \u2502\n        \u251c\u2500\u2500 backup.sh           <--- create a local backup (deletes dir backup/\n        \u251c\u2500\u2500 backup                                     |    before it creates\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 <sitename>_tracenv_hotcopy.tar.gz  <--\u00b4     the tarball)\n        \u251c\u2500\u2500 run\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 trac.sock       <--- file-socket for binding to nginx\n        \u251c\u2500\u2500 scripts\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 tracwsgi.py\n        \u251c\u2500\u2500 tracenv\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 conf\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 trac.htpasswd   <--- trac user password hashes\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 trac.ini        <--- trac config file\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 db\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 trac.db         <--- sqlite database\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 git\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 htdocs\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 log\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 plugins\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 README\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 VERSION\n        \u2514\u2500\u2500 virtualenv\n            \u251c\u2500\u2500 bin\n            \u251c\u2500\u2500 include\n            \u251c\u2500\u2500 lib\n            \u251c\u2500\u2500 local\n            \u2514\u2500\u2500 pip-selfcheck.json\n        ```\n\n    How to create a backup tarball \"manually\":\n    `~/sites/<sitename>/backup/tracenv_hotcopy_<yyyy-mm-dd>.tar.gz`:\n\n        ```\n        cd ~/sites/<sitename>  &&  rm -rf ./backup\n        ./virtualenv/bin/trac-admin ./tracenv  hotcopy ./backup/tracenv_hotcopy\n        mkdir -p ./backup  &&  cd ./backup\n        tar czf <sitename>_tracenv_hotcopy_$(date +%F).tar.gz  tracenv_hotcopy/\n        rm -rf tracenv_hotcopy; ls -hl\n        ```\n\n    More infos:\n      https://trac.edgewall.org/wiki/TracInstall\n      https://trac.edgewall.org/wiki/TracFastCgi#NginxConfiguration\n      https://trac.edgewall.org/wiki/TracNginxRecipe\n      https://trac.edgewall.org/wiki/Gunicorn\n      http://www.obeythetestinggoat.com/book/chapter_08.html#_getting_to_a_production_ready_deployment\n      Setting REMOTE_USER for Trac in Gunicorn behind Nginx:\n        http://serverfault.com/a/392096\n      https://trac.edgewall.org/wiki/TracBackup\n    '''\n    hostname = re.sub(r'^[^@]+@', '', env.host)  # without username if any\n    sitename = query_input(\n                   question='\\nEnter site-name of Your trac web service',\n                   default=flo('trac.{hostname}'))\n    username = env.user\n\n    site_dir = flo('/home/{username}/sites/{sitename}')\n    bin_dir = flo('{site_dir}/virtualenv/bin')\n\n    # provisioning steps\n    install_or_upgrade_virtualenv_pip_package()\n    create_directory_structure(site_dir)\n    update_virtualenv(site_dir, sitename)\n    set_up_trac_plugins(sitename, site_dir, bin_dir)\n    set_up_gunicorn(site_dir, sitename)\n    configure_nginx(username, sitename, hostname)\n\n    if query_yes_no('\\nRestore trac environment from backup tarball?',\n                    default='no'):\n        restore_tracenv_from_backup_tarball(site_dir, bin_dir)\n    elif not tracenv_exists(site_dir):\n        init_tracenv(site_dir, bin_dir, username)\n\n    upgrade_tracenv(site_dir, bin_dir)\n\n    set_up_upstart_for_gunicorn(sitename, username, site_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the System API for the current version of the current version of the user.", "response": "async def query(self, path, method='get', **params):\n        \"\"\"\n        Do a query to the System API\n\n        :param path: url to the API\n        :param method: the kind of query to do\n        :param params: a dict with all the\n        necessary things to query the API\n        :return json data\n        \"\"\"\n        if method in ('get', 'post', 'patch', 'delete', 'put'):\n            full_path = self.host + path\n            if method == 'get':\n                resp = await self.aio_sess.get(full_path, params=params)\n            elif method == 'post':\n                resp = await self.aio_sess.post(full_path, data=params)\n            elif method == 'patch':\n                resp = await self.aio_sess.patch(full_path, data=params)\n            elif method == 'delete':\n                resp = await self.aio_sess.delete(full_path, params=params, headers=params)\n            elif method == 'put':\n                resp = await self.aio_sess.put(full_path, data=params)\n\n            async with resp:\n                # return the content if its a binary one\n                if resp.content_type.startswith('application/pdf') or \\\n                        resp.content_type.startswith('application/epub'):\n                    return await resp.read()\n\n                return await self.handle_json_response(resp)\n        else:\n            raise ValueError('method expected: get, post, patch, delete, put')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def handle_json_response(responses):\n        json_data = {}\n        if responses.status != 200:\n            err_msg = HttpProcessingError(code=responses.status,\n                                          message=await responses.json())\n            logging.error(\"Wallabag: aiohttp error {err_msg}\".format(\n                err_msg=err_msg))\n        else:\n            try:\n                json_data = responses.json()\n            except ClientResponseError as e:\n                # sometimes json_data does not return any json() without\n                # any error. This is due to the grabbing URL which \"rejects\"\n                # the URL\n                logging.error(\"Wallabag: aiohttp error {code} {message}\"\n                              .format(code=e.code, message=e.message))\n        return await json_data", "response": "handle the json response from the Wallabag server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the value of a parm", "response": "def __get_attr(what, type_attr, value_attr, **kwargs):\n        \"\"\"\n        get the value of a parm\n        :param what: string parm\n        :param type_attr: type of parm\n        :param value_attr:\n        :param kwargs:\n        :return: value of the parm\n        \"\"\"\n        if what in kwargs:\n            value = int(kwargs[what]) if type_attr == 'int' else kwargs[what]\n            if value in value_attr:\n                return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve all entries in the specified format.", "response": "async def get_entries(self, **kwargs):\n        \"\"\"\n        GET /api/entries.{_format}\n\n        Retrieve all entries. It could be filtered by many options.\n\n        :param kwargs: can contain one of the following filters\n            archive:  '0' or '1', default '0' filter by archived status.\n            starred: '0' or '1', default '0' filter by starred status.\n            sort: 'created' or 'updated', default 'created'\n            order: 'asc' or 'desc', default 'desc'\n            page: int default 1 what page you want\n            perPage: int default 30 result per page\n            tags: list of tags url encoded.\n            since: int default 0 from what timestamp you want\n            Will returns entries that matches ALL tags\n        :return data related to the ext\n        \"\"\"\n        # default values\n        params = dict({'access_token': self.token,\n                       'sort': 'created',\n                       'order': 'desc',\n                       'page': 1,\n                       'perPage': 30,\n                       'tags': '',\n                       'since': 0})\n\n        if 'archive' in kwargs and int(kwargs['archive']) in (0, 1):\n            params['archive'] = int(kwargs['archive'])\n        if 'starred' in kwargs and int(kwargs['starred']) in (0, 1):\n            params['starred'] = int(kwargs['starred'])\n        if 'order' in kwargs and kwargs['order'] in ('asc', 'desc'):\n            params['order'] = kwargs['order']\n        if 'page' in kwargs and isinstance(kwargs['page'], int):\n            params['page'] = kwargs['page']\n        if 'perPage' in kwargs and isinstance(kwargs['perPage'], int):\n            params['perPage'] = kwargs['perPage']\n        if 'tags' in kwargs and isinstance(kwargs['tags'], list):\n            params['tags'] = ', '.join(kwargs['tags'])\n        if 'since' in kwargs and isinstance(kwargs['since'], int):\n            params['since'] = kwargs['since']\n\n        path = '/api/entries.{ext}'.format(ext=self.format)\n\n        return await self.query(path, \"get\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def post_entries(self, url, title='', tags='', starred=0, archive=0, content='', language='', published_at='',\n                           authors='', public=1, original_url=''):\n        \"\"\"\n        POST /api/entries.{_format}\n\n        Create an entry\n\n        :param url: the url of the note to store\n        :param title: Optional, we'll get the title from the page.\n        :param tags: tag1,tag2,tag3 a comma-separated list of tags.\n        :param starred entry already starred\n        :param archive entry already archived\n        :param content additionnal html content\n        :param language\n        :param published_at\n        :param authors\n        :param public\n        :param original_url\n        :return result\n        \"\"\"\n        params = {'access_token': self.token, 'url': url, 'title': title,\n                  'tags': tags, 'starred': starred, 'archive': archive,\n                  'content': content, 'language': language, 'published_at': published_at,\n                  'authors': authors, 'public': public, 'original_url': original_url}\n        if len(tags) > 0 and isinstance(tags, list):\n            params['tags'] = ', '.join(tags)\n        path = '/api/entries.{ext}'.format(ext=self.format)\n        return await self.query(path, \"post\", **params)", "response": "POST an entry to the note"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_entry(self, entry):\n        params = {'access_token': self.token}\n        url = '/api/entries/{entry}.{ext}'.format(entry=entry,\n                                                  ext=self.format)\n        return await self.query(url, \"get\", **params)", "response": "Get a single entry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npatching /api/entries/{entry}.{_format} Change several properties of an entry :param entry: the entry to 'patch' / update :param kwargs: can contain one of the following title: string tags: a list of tags tag1,tag2,tag3 archive: '0' or '1', default '0' archived the entry. starred: '0' or '1', default '0' starred the entry In case that you don't want to *really* remove it.. :return data related to the ext", "response": "async def patch_entries(self, entry, **kwargs):\n        \"\"\"\n        PATCH /api/entries/{entry}.{_format}\n\n        Change several properties of an entry\n\n        :param entry: the entry to 'patch' / update\n        :param kwargs: can contain one of the following\n            title: string\n            tags: a list of tags tag1,tag2,tag3\n            archive:  '0' or '1', default '0' archived the entry.\n            starred: '0' or '1', default '0' starred the entry\n            In case that you don't want to *really* remove it..\n        :return data related to the ext\n        \"\"\"\n        # default values\n        params = {'access_token': self.token,\n                  'title': '',\n                  'tags': []}\n\n        if 'title' in kwargs:\n            params['title'] = kwargs['title']\n        if 'tags' in kwargs and isinstance(kwargs['tags'], list):\n            params['tags'] = ', '.join(kwargs['tags'])\n\n        params['archive'] = self.__get_attr(what='archive',\n                                            type_attr=int,\n                                            value_attr=(0, 1),\n                                            **kwargs)\n        params['starred'] = self.__get_attr(what='starred',\n                                            type_attr=int,\n                                            value_attr=(0, 1),\n                                            **kwargs)\n        params['order'] = self.__get_attr(what='order',\n                                          type_attr=str,\n                                          value_attr=('asc', 'desc'),\n                                          **kwargs)\n\n        path = '/api/entries/{entry}.{ext}'.format(\n            entry=entry, ext=self.format)\n        return await self.query(path, \"patch\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def delete_entries(self, entry):\n\n        params = {'Authorization': 'Bearer {}'.format(self.token)}\n        path = '/api/entries/{entry}.{ext}'.format(\n            entry=entry, ext=self.format)\n        return await self.query(path, \"delete\", **params)", "response": "Delete permanently an entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if an entry exists by url.", "response": "async def entries_exists(self, url, urls=''):\n        \"\"\"\n        GET /api/entries/exists.{_format}\n\n        Check if an entry exist by url.\n\n        :param url \tstring \ttrue \tAn url \tUrl to check if it exists\n        :param urls string \tfalse \tAn array of urls\n        (?urls[]=http...&urls[]=http...) Urls (as an array)\n        to check if it exists\n\n        :return result\n        \"\"\"\n        params = {'access_token': self.token,\n                  'url': url,\n                  'urls': urls}\n\n        path = '/api/entries/exists.{ext}'.format(ext=self.format)\n        return await self.query(path, \"get\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nposts /api/entries/{entry}/tags.{_format} Add one or more tags to an entry :param entry: \\w+ an integer The Entry ID :param tags: list of tags (urlencoded) :return result", "response": "async def post_entry_tags(self, entry, tags):\n        \"\"\"\n        POST /api/entries/{entry}/tags.{_format}\n\n        Add one or more tags to an entry\n\n        :param entry: \\w+ an integer The Entry ID\n        :param tags: list of tags (urlencoded)\n        :return result\n        \"\"\"\n        params = {'access_token': self.token, 'tags': []}\n        if len(tags) > 0 and isinstance(tags, list):\n            params['tags'] = ', '.join(tags)\n        path = '/api/entries/{entry}/tags.{ext}'.format(\n            entry=entry, ext=self.format)\n        return await self.query(path, \"post\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def delete_entry_tag(self, entry, tag):\n        params = {'access_token': self.token}\n        url = '/api/entries/{entry}/tags/{tag}.{ext}'.format(\n            entry=entry, tag=tag, ext=self.format)\n        return await self.query(url, \"delete\", **params)", "response": "Permanently remove one tag for an entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_tags(self):\n        params = {'access_token': self.token}\n        path = '/api/tags.{ext}'.format(ext=self.format)\n        return await self.query(path, \"get\", **params)", "response": "Retrieve all tags related to the ext\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes /api/tags/{tag}.{_format} Permanently remove one tag from every entry :param tag: string The Tag :return data related to the ext", "response": "async def delete_tag(self, tag):\n        \"\"\"\n        DELETE /api/tags/{tag}.{_format}\n\n        Permanently remove one tag from every entry\n\n        :param tag: string The Tag\n        :return data related to the ext\n        \"\"\"\n        path = '/api/tags/{tag}.{ext}'.format(tag=tag, ext=self.format)\n        params = {'access_token': self.token}\n        return await self.query(path, \"delete\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def put_annotations(self, annotation):\n        params = {'access_token': self.token}\n        url = '/api/annotations/{annotation}.{ext}'.format(\n            annotation=annotation, ext=self.format)\n        return await self.query(url, \"put\", **params)", "response": "PUT /api/annotations/{annotation}.{_format}\n\n        Updates an annotation.\n\n        :param annotation \t\\w+ \tstring \tThe annotation ID\n\n        Will returns annotation for this entry\n        :return data related to the ext"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nposting an annotation for a specific entry.", "response": "async def post_annotations(self, entry, **kwargs):\n        \"\"\"\n        POST /api/annotations/{entry}.{_format}\n\n        Creates a new annotation.\n\n        :param entry \t\\w+ \tinteger \tThe entry ID\n\n        :return\n        \"\"\"\n        params = dict({'access_token': self.token,\n                       'ranges': [],\n                       'quote': '',\n                       'text': ''})\n        if 'ranges' in kwargs:\n            params['ranges'] = kwargs['ranges']\n        if 'quote' in kwargs:\n            params['quote'] = kwargs['quote']\n        if 'text' in kwargs:\n            params['text'] = kwargs['text']\n\n        url = '/api/annotations/{entry}.{ext}'.format(entry=entry,\n                                                      ext=self.format)\n        return await self.query(url, \"post\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves version number of the current locale", "response": "async def version(self):\n        \"\"\"\n        GET /api/version.{_format}\n\n        Retrieve version number\n\n        :return data related to the ext\n        \"\"\"\n        params = {'access_token': self.token}\n        url = '/api/version.{ext}'.format(ext=self.format)\n        return await self.query(url, \"get\", **params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npost / oauth / v2 / token", "response": "async def get_token(cls, host, **params):\n        \"\"\"\n        POST /oauth/v2/token\n\n        Get a new token\n\n        :param host: host of the service\n        :param params: will contain :\n\n        params = {\"grant_type\": \"password\",\n                  \"client_id\": \"a string\",\n                  \"client_secret\": \"a string\",\n                  \"username\": \"a login\",\n                  \"password\": \"a password\"}\n\n        :return: access token\n        \"\"\"\n        params['grant_type'] = \"password\"\n        path = \"/oauth/v2/token\"\n        async with aiohttp.ClientSession() as sess:\n            async with sess.post(host + path, data=params) as resp:\n                data = await cls.handle_json_response(resp)\n                return data.get(\"access_token\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating or update a reveals. js presentation with slides written in markdown.", "response": "def revealjs(basedir=None, title=None, subtitle=None, description=None,\n             github_user=None, github_repo=None):\n    '''Set up or update a reveals.js presentation with slides written in markdown.\n\n    Several reveal.js plugins will be set up, too.\n\n    More info:\n      Demo: https://theno.github.io/revealjs_template\n      http://lab.hakim.se/reveal-js/\n      https://github.com/hakimel/reveal.js\n      plugins:\n        https://github.com/hakimel/reveal.js/wiki/Plugins,-Tools-and-Hardware\n        https://github.com/rajgoel/reveal.js-plugins/\n        https://github.com/e-gor/Reveal.js-TOC-Progress\n        https://github.com/e-gor/Reveal.js-Title-Footer\n    '''\n    basedir = basedir or query_input('Base dir of the presentation?',\n                                     default='~/repos/my_presi')\n    revealjs_repo_name = 'reveal.js'\n    revealjs_dir = flo('{basedir}/{revealjs_repo_name}')\n\n    _lazy_dict['presi_title'] = title\n    _lazy_dict['presi_subtitle'] = subtitle\n    _lazy_dict['presi_description'] = description\n    _lazy_dict['github_user'] = github_user\n    _lazy_dict['github_repo'] = github_repo\n\n    question = flo(\"Base dir already contains a sub dir '{revealjs_repo_name}'.\"\n                   ' Reset (and re-download) reveal.js codebase?')\n    if not exists(revealjs_dir) or query_yes_no(question, default='no'):\n        run(flo('mkdir -p {basedir}'))\n        set_up_revealjs_codebase(basedir, revealjs_repo_name)\n        install_plugins(revealjs_dir)\n        apply_customizations(repo_dir=revealjs_dir)\n    if exists(revealjs_dir):\n        install_files_in_basedir(basedir, repo_dir=revealjs_dir)\n        init_git_repo(basedir)\n        create_github_remote_repo(basedir)\n        setup_npm(revealjs_dir)\n    else:\n        print('abort')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tweak_css(repo_dir):\n    '''Comment out some css settings.'''\n    print_msg(\"* don't capitalize titles (no uppercase headings)\")\n    files = [\n        'beige.css', 'black.css', 'blood.css', 'league.css', 'moon.css',\n        'night.css', 'serif.css', 'simple.css', 'sky.css', 'solarized.css',\n        'white.css',\n    ]\n    line = '  text-transform: uppercase;'\n    for file_ in files:\n        update_or_append_line(filename=flo('{repo_dir}/css/theme/{file_}'),\n                              prefix=line, new_line=flo('/*{line}*/'))\n\n    print_msg('* images without border')\n    data = [\n        {'file': 'beige.css',     'line': '  border: 4px solid #333;'},\n        {'file': 'black.css',     'line': '  border: 4px solid #fff;'},\n        {'file': 'blood.css',     'line': '  border: 4px solid #eee;'},\n        {'file': 'league.css',    'line': '  border: 4px solid #eee;'},\n        {'file': 'moon.css',      'line': '  border: 4px solid #93a1a1;'},\n        {'file': 'night.css',     'line': '  border: 4px solid #eee;'},\n        {'file': 'serif.css',     'line': '  border: 4px solid #000;'},\n        {'file': 'simple.css',    'line': '  border: 4px solid #000;'},\n        {'file': 'sky.css',       'line': '  border: 4px solid #333;'},\n        {'file': 'solarized.css', 'line': '  border: 4px solid #657b83;'},\n        {'file': 'white.css',     'line': '  border: 4px solid #222;'},\n    ]\n    for item in data:\n        file_ = item['file']\n        lines = [item['line'], ]\n        lines.extend(['  box-shadow: 0 0 10px rgba(0, 0, 0, 0.15); }',\n                      '  box-shadow: 0 0 20px rgba(0, 0, 0, 0.55); }'])\n        for line in lines:\n            update_or_append_line(filename=flo('{repo_dir}/css/theme/{file_}'),\n                                  prefix=line, new_line=flo('/*{line}*/'))", "response": "Comment out some css settings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_github_remote_repo(basedir):\n    '''More info:\n      https://help.github.com/articles/adding-an-existing-project-to-github-using-the-command-line/\n      https://developer.github.com/v3/repos/#create\n      https://stackoverflow.com/a/10325316\n    '''\n    github_user = _lazy('github_user')\n    github_repo = _lazy('github_repo', default=os.path.basename(basedir))\n\n    _insert_repo_infos_into_readme(basedir, github_user, github_repo)\n    run(flo('cd {basedir} && git add README.md'))\n    run(flo('cd {basedir} && git commit -am \"Add github repo and user '\n            'into README.md\"'))\n\n    print_msg('create github repo')\n    run(flo(\"cd {basedir}  &&  \"\n            \"curl -u '{github_user}' https://api.github.com/user/repos \"\n            \"-d '\") + '{\"name\":\"' + flo('{github_repo}\"') + \"}'\")\n    run(flo('cd {basedir}  &&  '\n            'git remote add origin '\n            'git@github.com:{github_user}/{github_repo}.git'))\n    run(flo('cd {basedir}  &&  git push origin master'))", "response": "Create a github remote repository."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decktape():\n    '''Install DeckTape.\n\n    DeckTape is a \"high-quality PDF exporter for HTML5 presentation\n    frameworks\".  It can be used to create PDFs from reveal.js presentations.\n\n    More info:\n      https://github.com/astefanutti/decktape\n      https://github.com/hakimel/reveal.js/issues/1252#issuecomment-198270915\n    '''\n    run('mkdir -p ~/bin/decktape')\n    if not exists('~/bin/decktape/decktape-1.0.0'):\n        print_msg('\\n## download decktape 1.0.0\\n')\n        run('cd ~/bin/decktape && '\n            'curl -L https://github.com/astefanutti/decktape/archive/'\n            'v1.0.0.tar.gz | tar -xz --exclude phantomjs')\n        run('cd ~/bin/decktape/decktape-1.0.0 && '\n            'curl -L https://github.com/astefanutti/decktape/releases/'\n            'download/v1.0.0/phantomjs-linux-x86-64 -o phantomjs')\n        run('cd ~/bin/decktape/decktape-1.0.0 && '\n            'chmod +x phantomjs')\n    run('ln -snf ~/bin/decktape/decktape-1.0.0 ~/bin/decktape/active',\n        msg='\\n## link installed decktape version as active')\n    print_msg('\\nCreate PDF from reveal.js presentation:\\n\\n    '\n              '# serve presentation:\\n    '\n              'cd ~/repos/my_presi/reveal.js/ && npm start\\n\\n    '\n              '# create pdf in another shell:\\n    '\n              'cd ~/bin/decktape/active && \\\\\\n    '\n              './phantomjs decktape.js --size 1280x800  localhost:8000  '\n              '~/repos/my_presi/my_presi.pdf')", "response": "Install DeckTape.\n\n    DeckTape is a \"high-quality PDF exporter for HTML5 presentation\n    frameworks\".  It can be used to create PDFs from reveal.js presentations.\n\n    More info:\n      https://github.com/astefanutti/decktape\n      https://github.com/hakimel/reveal.js/issues/1252#issuecomment-198270915"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revealjs_template():\n    '''Create or update the template presentation demo using task `revealjs`.\n    '''\n    from config import basedir, github_user, github_repo\n\n    run(flo('rm -f {basedir}/index.html'))\n    run(flo('rm -f {basedir}/slides.md'))\n    run(flo('rm -f {basedir}/README.md'))\n    run(flo('rm -rf {basedir}/img/'))\n\n    title = 'reveal.js template'\n    subtitle = '[reveal.js][3] presentation written ' \\\n               'in [markdown][4] set up with [fabric][5] & [fabsetup][6]'\n    description = '''\\\nThis presentation shows how to create a reveal.js presentation which will be\nset up with the fabric task `setup.revealjs` of fabsetup.\n\nAlso, you can use this presentation source as a reveal.js template:\n* Checkout this repo\n* Then set the title in the `index.html` and edit the\n  `slides.md`.'''\n\n    execute(revealjs, basedir, title, subtitle, description,\n            github_user, github_repo)\n\n    # (README.md was removed, but not the github remote repo)\n    print_msg('\\n## Re-add github repo infos into README.md')\n    basename = os.path.basename(basedir)\n    _insert_repo_infos_into_readme(basedir, github_user=_lazy('github_user'),\n                                   github_repo=_lazy('github_repo',\n                                                     default=basename))\n\n    print_msg('\\n## Assure symbolic link not tracked by git exists\\n')\n    run(flo('ln -snf ../reveal.js  {basedir}/reveal.js/reveal.js'))", "response": "Create or update the template presentation demo using task revealjs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new array with the first two elements of the spatial domain that is not gridded.", "response": "def spatialDomainNoGrid(self):\r\n    \"\"\"\r\n    Superposition of analytical solutions without a gridded domain\r\n    \"\"\"\r\n    self.w = np.zeros(self.xw.shape)\r\n\r\n    if self.Debug:\r\n      print(\"w = \")\r\n      print(self.w.shape)\r\n    \r\n    for i in range(len(self.q)):\r\n      # More efficient if we have created some 0-load points\r\n      # (e.g., for where we want output)\r\n      if self.q[i] != 0:\r\n        dist = np.abs(self.xw - self.x[i])\r\n        self.w -= self.q[i] * self.coeff * np.exp(-dist/self.alpha) * \\\r\n          ( np.cos(dist/self.alpha) + np.sin(dist/self.alpha) )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BC_Rigidity(self):\r\n\r\n    #########################################\r\n    # FLEXURAL RIGIDITY BOUNDARY CONDITIONS #\r\n    #########################################\r\n    # West\r\n    if self.BC_W == 'Periodic':\r\n      self.BC_Rigidity_W = 'periodic'\r\n    elif (self.BC_W == np.array(['0Displacement0Slope', '0Moment0Shear', '0Slope0Shear'])).any():\r\n      self.BC_Rigidity_W = '0 curvature'\r\n    elif self.BC_W == 'Mirror':\r\n      self.BC_Rigidity_W = 'mirror symmetry'\r\n    else:\r\n      sys.exit(\"Invalid Te B.C. case\")\r\n    # East\r\n    if self.BC_E == 'Periodic':\r\n      self.BC_Rigidity_E = 'periodic'\r\n    elif (self.BC_E == np.array(['0Displacement0Slope', '0Moment0Shear', '0Slope0Shear'])).any():\r\n      self.BC_Rigidity_E = '0 curvature'\r\n    elif self.BC_E == 'Mirror':\r\n      self.BC_Rigidity_E = 'mirror symmetry'\r\n    else:\r\n      sys.exit(\"Invalid Te B.C. case\")\r\n    \r\n    #############\r\n    # PAD ARRAY #\r\n    #############\r\n    if np.isscalar(self.Te):\r\n      self.D *= np.ones(self.qs.shape) # And leave Te as a scalar for checks\r\n    else:\r\n      self.Te_unpadded = self.Te.copy()\r\n    # F2D keeps this inside the \"else\" and handles this differently, \r\n    # largely because it has different ways of computing the flexural\r\n    # response with variable Te. We'll keep everything simpler here and \r\n    # just pad this array so it can be sent through the same process\r\n    # to create the coefficient arrays.\r\n    self.D = np.hstack([np.nan, self.D, np.nan])\r\n\r\n    ###############################################################\r\n    # APPLY FLEXURAL RIGIDITY BOUNDARY CONDITIONS TO PADDED ARRAY #\r\n    ###############################################################\r\n    if self.BC_Rigidity_W == \"0 curvature\":\r\n      self.D[0] = 2*self.D[1] - self.D[2]\r\n    if self.BC_Rigidity_E == \"0 curvature\":\r\n      self.D[-1] = 2*self.D[-2] - self.D[-3]\r\n    if self.BC_Rigidity_W == \"mirror symmetry\":\r\n      self.D[0] = self.D[2]\r\n    if self.BC_Rigidity_E == \"mirror symmetry\":\r\n      self.D[-1] = self.D[-3]\r\n    if self.BC_Rigidity_W == \"periodic\":\r\n      self.D[0] = self.D[-2]\r\n    if self.BC_Rigidity_E == \"periodic\":\r\n      self.D[-1] = self.D[-3]", "response": "Utility function to help implement boundary conditions by specifying them for and applying them to the elastic thickness grid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_diagonals(self):\r\n\r\n    ##########################################################\r\n    # INCORPORATE BOUNDARY CONDITIONS INTO COEFFICIENT ARRAY #\r\n    ##########################################################\r\n\r\n    # Roll to keep the proper coefficients at the proper places in the\r\n    # arrays: Python will naturally just do vertical shifts instead of \r\n    # diagonal shifts, so this takes into account the horizontal compoent \r\n    # to ensure that boundary values are at the right place.\r\n    self.l2 = np.roll(self.l2, -2)\r\n    self.l1 = np.roll(self.l1, -1)\r\n    self.r1 = np.roll(self.r1, 1)\r\n    self.r2 = np.roll(self.r2, 2)\r\n\r\n    # Then assemble these rows: this is where the periodic boundary condition \r\n    # can matter.\r\n    if self.coeff_matrix is not None:\r\n      pass\r\n    elif self.BC_E == 'Periodic' and self.BC_W == 'Periodic':\r\n      # In this case, the boundary-condition-related stacking has already \r\n      # happened inside b.c.-handling function. This is because periodic\r\n      # boundary conditions require extra diagonals to exist on the edges of \r\n      # the solution array\r\n      pass\r\n    else:\r\n      self.diags = np.vstack((self.l2,self.l1,self.c0,self.r1,self.r2))\r\n      self.offsets = np.array([-2,-1,0,1,2])\r\n\r\n    # Everybody now (including periodic b.c. cases)\r\n    self.coeff_matrix = spdiags(self.diags, self.offsets, self.nx, self.nx, format='csr')", "response": "Builds the diagonals for the coefficient array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef BC_Periodic(self):\r\n    if self.BC_E == 'Periodic' and self.BC_W == 'Periodic':\r\n      # If both boundaries are periodic, we are good to go (and self-consistent)\r\n      pass # It is just a shift in the coeff. matrix creation.\r\n    else:\r\n      # If only one boundary is periodic and the other doesn't implicitly \r\n      # involve a periodic boundary, this is illegal!\r\n      # I could allow it, but would have to rewrite the Periodic b.c. case,\r\n      # which I don't want to do to allow something that doesn't make \r\n      # physical sense... so if anyone wants to do this for some unforeseen \r\n      # reason, they can just split my function into two pieces themselves.i\r\n      sys.exit(\"Having the boundary opposite a periodic boundary condition\\n\"+\r\n               \"be fixed and not include an implicit periodic boundary\\n\"+\r\n               \"condition makes no physical sense.\\n\"+\r\n               \"Please fix the input boundary conditions. Aborting.\")\r\n    self.diags = np.vstack((self.r1,self.r2,self.l2,self.l1,self.c0,self.r1,self.r2,self.l2,self.l1))\r\n    self.offsets = np.array([1-self.ncolsx,2-self.ncolsx,-2,-1,0,1,2,self.ncolsx-2,self.ncolsx-1])", "response": "This method is used to make the boundary condition a periodic boundary condition."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new array with boundary conditions for 0 deflection.", "response": "def BC_0Displacement0Slope(self):\r\n    \"\"\"\r\n    0Displacement0Slope boundary condition for 0 deflection.\r\n    This requires that nothing be done to the edges of the solution array, \r\n    because the lack of the off-grid terms implies that they go to 0\r\n    Here we just turn the cells outside the array into nan, to ensure that \r\n    we are not accidentally including the wrong cells here (and for consistency \r\n    with the other solution types -- this takes negligible time)\r\n    \"\"\"\r\n    if self.BC_W == '0Displacement0Slope':\r\n      i=0\r\n      self.l2[i] = np.nan\r\n      self.l1[i] = np.nan\r\n      self.c0[i] += 0\r\n      self.r1[i] += 0\r\n      self.r2[i] += 0\r\n      i=1\r\n      self.l2[i] = np.nan\r\n      self.l1[i] += 0\r\n      self.c0[i] += 0\r\n      self.r1[i] += 0\r\n      self.r2[i] += 0\r\n    if self.BC_E == '0Displacement0Slope':\r\n      i=-2\r\n      self.l2[i] += 0\r\n      self.l1[i] += 0\r\n      self.c0[i] += 0\r\n      self.r1[i] += 0\r\n      self.r2[i] = np.nan\r\n      i=-1\r\n      self.l2[i] += 0\r\n      self.l1[i] += 0\r\n      self.c0[i] += 0\r\n      self.r1[i] = np.nan\r\n      self.r2[i] = np.nan"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef BC_Mirror(self):\r\n    if self.BC_W == 'Mirror':\r\n      i=0\r\n      #self.l2[i] += np.nan\r\n      #self.l1[i] += np.nan\r\n      self.c0[i] += 0\r\n      self.r1[i] += self.l1_coeff_i[i]\r\n      self.r2[i] += self.l2_coeff_i[i]\r\n      i=1\r\n      #self.l2[i] += np.nan\r\n      self.l1[i] += 0\r\n      self.c0[i] += self.l2_coeff_i[i]\r\n      self.r1[i] += 0\r\n      self.r2[i] += 0\r\n    \r\n    if self.BC_E == 'Mirror':\r\n      i=-2\r\n      self.l2[i] += 0\r\n      self.l1[i] += 0\r\n      self.c0[i] += self.r2_coeff_i[i]\r\n      self.r1[i] += 0\r\n      #self.r2[i] += np.nan\r\n      i=-1\r\n      self.l2[i] += self.r2_coeff_i[i]\r\n      self.l1[i] += self.r1_coeff_i[i]\r\n      self.c0[i] += 0", "response": "A method to modify the internal representation of the Mirror class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calc_max_flexural_wavelength(self):\r\n    if np.isscalar(self.D):\r\n      Dmax = self.D\r\n    else:\r\n      Dmax = self.D.max()\r\n    # This is an approximation if there is fill that evolves with iterations \r\n    # (e.g., water), but should be good enough that this won't do much to it\r\n    alpha = (4*Dmax/(self.drho*self.g))**.25 # 2D flexural parameter\r\n    self.maxFlexuralWavelength = 2*np.pi*alpha\r\n    self.maxFlexuralWavelength_ncells = int(np.ceil(self.maxFlexuralWavelength / self.dx))", "response": "Calculates the approximate maximum flexural wavelength of a single node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving the sparse coefficient matrix and return the array of loads.", "response": "def fd_solve(self):\r\n    \"\"\"\r\n    w = fd_solve()\r\n      where coeff is the sparse coefficient matrix output from function\r\n      coeff_matrix and qs is the array of loads (stresses)\r\n\r\n    Sparse solver for one-dimensional flexure of an elastic plate\r\n    \"\"\"\r\n    \r\n    if self.Debug:\r\n      print(\"qs\", self.qs.shape)\r\n      print(\"Te\", self.Te.shape)\r\n      self.calc_max_flexural_wavelength()\r\n      print(\"maxFlexuralWavelength_ncells', self.maxFlexuralWavelength_ncells\")\r\n    \r\n    if self.Solver == \"iterative\" or self.Solver == \"Iterative\":\r\n      if self.Debug:\r\n        print(\"Using generalized minimal residual method for iterative solution\")\r\n      if self.Verbose:\r\n        print(\"Converging to a tolerance of\", self.iterative_ConvergenceTolerance, \"m between iterations\")\r\n      # qs negative so bends down with positive load, bends up with neative load \r\n      # (i.e. material removed)\r\n      w = isolve.lgmres(self.coeff_matrix, -self.qs, tol=self.iterative_ConvergenceTolerance)  \r\n      self.w = w[0] # Reach into tuple to get my array back\r\n    else:\r\n      if self.Solver == 'direct' or self.Solver == 'Direct':\r\n        if self.Debug:\r\n          print(\"Using direct solution with UMFpack\")\r\n      else:\r\n        print(\"Solution type not understood:\")\r\n        print(\"Defaulting to direct solution with UMFpack\")\r\n      # UMFpack is now the default, but setting true just to be sure in case\r\n      # anything changes\r\n      # qs negative so bends down with positive load, bends up with neative load \r\n      # (i.e. material removed)\r\n      self.w = spsolve(self.coeff_matrix, -self.qs, use_umfpack=True)\r\n    \r\n    if self.Debug:\r\n      print(\"w.shape:\")\r\n      print(self.w.shape)\r\n      print(\"w:\")\r\n      print(self.w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gt_from_lt(self, other):\n    op_result = self.__lt__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result and self != other", "response": "Return a > b. Computed by total_ordering from"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _le_from_lt(self, other):\n    op_result = self.__lt__(other)\n    return op_result or self == other", "response": "Return True if self < other. Computed by total_ordering from ( a < b."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a > = b. Computed by total_ordering from ( not a < b.", "response": "def _ge_from_lt(self, other):\n    \"\"\"Return a >= b.  Computed by @total_ordering from (not a < b).\"\"\"\n    op_result = self.__lt__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if self < = other. Computed by total_ordering from", "response": "def _ge_from_le(self, other):\n    \"\"\"Return a >= b.  Computed by @total_ordering from (not a <= b) or (a == b).\"\"\"\n    op_result = self.__le__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result or self == other"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if self < other.", "response": "def _lt_from_le(self, other):\n    \"\"\"Return a < b.  Computed by @total_ordering from (a <= b) and (a != b).\"\"\"\n    op_result = self.__le__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return op_result and self != other"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _gt_from_le(self, other):\n    op_result = self.__le__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result", "response": "Return a > b. Computed by total_ordering from ( not a < b."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a < b. Computed by total_ordering from", "response": "def _lt_from_gt(self, other):\n    \"\"\"Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).\"\"\"\n    op_result = self.__gt__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result and self != other"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if self > = other. Computed by total_ordering from ( a > b ).", "response": "def _ge_from_gt(self, other):\n    \"\"\"Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).\"\"\"\n    op_result = self.__gt__(other)\n    return op_result or self == other"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _le_from_gt(self, other):\n    op_result = self.__gt__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result", "response": "Return a < b. Computed by total_ordering from ( not a > b."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _le_from_ge(self, other):\n    op_result = self.__ge__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result or self == other", "response": "Return True if self < = other."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _gt_from_ge(self, other):\n    op_result = self.__ge__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return op_result and self != other", "response": "Return True if self > = other."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _lt_from_ge(self, other):\n    op_result = self.__ge__(other)\n    if op_result is NotImplemented:\n        return NotImplemented\n    return not op_result", "response": "Return a < b. Computed by total_ordering from ( not a < b."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclass decorator that fills in missing ordering methods", "response": "def total_ordering(cls):\n    \"\"\"Class decorator that fills in missing ordering methods\"\"\"\n    convert = {  # :off\n        '__lt__': [('__gt__', _gt_from_lt),\n                   ('__le__', _le_from_lt),\n                   ('__ge__', _ge_from_lt)],\n        '__le__': [('__ge__', _ge_from_le),\n                   ('__lt__', _lt_from_le),\n                   ('__gt__', _gt_from_le)],\n        '__gt__': [('__lt__', _lt_from_gt),\n                   ('__ge__', _ge_from_gt),\n                   ('__le__', _le_from_gt)],\n        '__ge__': [('__le__', _le_from_ge),\n                   ('__gt__', _gt_from_ge),\n                   ('__lt__', _lt_from_ge)]\n    }  # :on\n    # Find user-defined comparisons (not those inherited from object).\n    roots = [  # :off\n        op\n        for op in convert\n        if getattr(cls, op, None) is not getattr(object, op, None)\n    ]  # :on\n    if not roots:\n        raise ValueError('must define at least one ordering operation: < > <= >=')\n    root = max(roots)  # prefer __lt__ to __le__ to __gt__ to __ge__\n    for opname, opfunc in convert[root]:\n        if opname not in roots:\n            opfunc.__name__ = opname\n            setattr(cls, opname, opfunc)\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createArchiveExample(fileName):\n    print('*' * 80)\n    print('Create archive')\n    print('*' * 80)\n\n    archive = CombineArchive()\n    archive.addFile(\n        fileName,  # filename\n        \"./models/model.xml\",  # target file name\n        KnownFormats.lookupFormat(\"sbml\"),  # look up identifier for SBML models\n        True  # mark file as master\n    )\n\n    # add metadata to the archive itself\n    description = OmexDescription()\n    description.setAbout(\".\")\n    description.setDescription(\"Simple test archive including one SBML model\")\n    description.setCreated(OmexDescription.getCurrentDateAndTime())\n\n    creator = VCard()\n    creator.setFamilyName(\"Bergmann\")\n    creator.setGivenName(\"Frank\")\n    creator.setEmail(\"fbergman@caltech.edu\")\n    creator.setOrganization(\"Caltech\")\n\n    description.addCreator(creator)\n\n    archive.addMetadata(\".\", description)\n\n    # add metadata to the added file\n    location = \"./models/model.xml\"\n    description = OmexDescription()\n    description.setAbout(location)\n    description.setDescription(\"SBML model\")\n    description.setCreated(OmexDescription.getCurrentDateAndTime())\n    archive.addMetadata(location, description)\n\n    # write the archive\n    out_file = \"out.omex\"\n    archive.writeToFile(out_file)\n\n    print('Archive created:', out_file)", "response": "Creates Combine Archive containing the given file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean():\n    '''Delete temporary files not under version control.'''\n\n    basedir = dirname(__file__)\n\n    print(cyan('delete temp files and dirs for packaging'))\n    local(flo(\n        'rm -rf  '\n        '{basedir}/.eggs/  '\n        '{basedir}/fabsetup.egg-info/  '\n        '{basedir}/dist  '\n        '{basedir}/README  '\n        '{basedir}/build/  '\n    ))\n\n    print(cyan('\\ndelete temp files and dirs for editing'))\n    local(flo(\n        'rm -rf  '\n        '{basedir}/.cache  '\n        '{basedir}/.ropeproject  '\n    ))\n\n    print(cyan('\\ndelete bytecode compiled versions of the python src'))\n    # cf. http://stackoverflow.com/a/30659970\n    local(flo('find  {basedir}/fabsetup  '\n              'fabfile*  ') +\n          '\\( -name \\*pyc -o -name \\*.pyo -o -name __pycache__ '\n          '-o -name \\*.so -o -name \\*.o -o -name \\*.c \\) '\n          '-prune '\n          '-exec rm -rf {} + || true')", "response": "Delete temporary files not under version control."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds and upload to pypi.", "response": "def pypi():\n    '''Build package and upload to pypi.'''\n    if not query_yes_no('version updated in '\n                        '`fabsetup/_version.py`?'):\n        print('abort')\n    else:\n        print(cyan('\\n## clean-up\\n'))\n        execute(clean)\n\n        basedir = dirname(__file__)\n\n        # latest_pythons = _determine_latest_pythons()\n        # # e.g. highest_minor: '3.6'\n        # highest_minor = _highest_minor(latest_pythons)\n        # python = flo('python{highest_minor}')\n        python = 'python'\n\n        print(cyan('\\n## build package'))\n        local(flo('cd {basedir}  &&  {python}  setup.py  sdist'))\n\n        print(cyan('\\n## upload package'))\n        local(flo('cd {basedir}  &&  {python} -m twine upload  dist/*'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the standard deviation of a list of values", "response": "def calc_deviation(values, average):\n    \"\"\"\n    Calculate the standard deviation of a list of values\n    @param values: list(float)\n    @param average:\n    @return:\n    \"\"\"\n    size = len(values)\n    if size < 2:\n        return 0\n    calc_sum = 0.0\n\n    for number in range(0, size):\n        calc_sum += math.sqrt((values[number] - average) ** 2)\n    return math.sqrt((1.0 / (size - 1)) * (calc_sum / size))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nappend a value to the stats list.", "response": "def append(self, value):\n        \"\"\"\n        Append a value to the stats list\n\n        Parameters\n        ----------\n        value : float\n            The value to add\n        \"\"\"\n        self.count += 1\n\n        if self.count == 1:\n            self.old_m = self.new_m = value\n            self.old_s = 0\n        else:\n            self.new_m = self.old_m + (value - self.old_m) / self.count\n            self.new_s = self.old_s + (value - self.old_m) * (value - self.new_m)\n\n            self.old_m = self.new_m\n            self.old_s = self.new_s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchaining results from a list of functions. Inverted reduce. :param (function) steps: List of function callbacks :param initial: Starting value for pipeline.", "response": "def pipeline(steps, initial=None):\n    \"\"\"\n    Chain results from a list of functions. Inverted reduce.\n\n    :param (function) steps: List of function callbacks\n    :param initial: Starting value for pipeline.\n    \"\"\"\n\n    def apply(result, step):\n        return step(result)\n\n    return reduce(apply, steps, initial)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhelp for the enver command line interface.", "response": "def enver(*args):\n\t\"\"\"\n\t%prog [<name>=[value]]\n\n\tTo show all environment variables, call with no parameters:\n\t\t%prog\n\tTo Add/Modify/Delete environment variable:\n\t\t%prog <name>=[value]\n\n\tIf <name> is PATH or PATHEXT, %prog will by default append the value using\n\ta semicolon as a separator. Use -r to disable this behavior or -a to force\n\tit for variables other than PATH and PATHEXT.\n\n\tIf append is prescribed, but the value doesn't exist, the value will be\n\tcreated.\n\n\tIf there is no value, %prog will delete the <name> environment variable.\n\ti.e. \"PATH=\"\n\n\tTo remove a specific value or values from a semicolon-separated\n\tmulti-value variable (such as PATH), use --remove-value.\n\n\te.g. enver --remove-value PATH=C:\\\\Unwanted\\\\Dir\\\\In\\\\Path\n\n\tRemove-value matches case-insensitive and also matches any substring\n\tso the following would also be sufficient to remove the aforementioned\n\tundesirable dir.\n\n\tenver --remove-value PATH=UNWANTED\n\n\tNote that %prog does not affect the current running environment, and can\n\tonly affect subsequently spawned applications.\n\t\"\"\"\n\tfrom optparse import OptionParser\n\tparser = OptionParser(usage=trim(enver.__doc__))\n\tparser.add_option(\n\t\t'-U', '--user-environment',\n\t\taction='store_const', const=UserRegisteredEnvironment,\n\t\tdefault=MachineRegisteredEnvironment,\n\t\tdest='class_',\n\t\thelp=\"Use the current user's environment\",\n\t)\n\tparser.add_option(\n\t\t'-a', '--append',\n\t\taction='store_true', default=False,\n\t\thelp=\"Append the value to any existing value (default for PATH and PATHEXT)\",\n\t)\n\tparser.add_option(\n\t\t'-r', '--replace',\n\t\taction='store_true', default=False,\n\t\thelp=\"Replace any existing value (used to override default append \"\n\t\t\"for PATH and PATHEXT)\",\n\t)\n\tparser.add_option(\n\t\t'--remove-value', action='store_true', default=False,\n\t\thelp=\"Remove any matching values from a semicolon-separated \"\n\t\t\"multi-value variable\",\n\t)\n\tparser.add_option(\n\t\t'-e', '--edit', action='store_true', default=False,\n\t\thelp=\"Edit the value in a local editor\",\n\t)\n\toptions, args = parser.parse_args(*args)\n\n\ttry:\n\t\tparam = args.pop()\n\t\tif args:\n\t\t\tparser.error(\"Too many parameters specified\")\n\t\t\traise SystemExit(1)\n\t\tif '=' not in param and not options.edit:\n\t\t\tparser.error(\"Expected <name>= or <name>=<value>\")\n\t\t\traise SystemExit(2)\n\t\tname, sep, value = param.partition('=')\n\t\tmethod_name = 'set'\n\t\tif options.remove_value:\n\t\t\tmethod_name = 'remove_values'\n\t\tif options.edit:\n\t\t\tmethod_name = 'edit'\n\t\tmethod = getattr(options.class_, method_name)\n\t\tmethod(name, value, options)\n\texcept IndexError:\n\t\toptions.class_.show()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(class_, name, value, sep=';'):\n\t\tvalues = class_.get_values_list(name, sep)\n\t\tif value in values:\n\t\t\treturn\n\t\tnew_value = sep.join(values + [value])\n\t\twinreg.SetValueEx(\n\t\t\tclass_.key, name, 0, winreg.REG_EXPAND_SZ, new_value)\n\t\tclass_.notify()", "response": "Add a value to a delimited variable but only when the value isn t already present."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnotify other windows that the environment has changed.", "response": "def notify(class_):\n\t\t\"\"\"\n\t\tNotify other windows that the environment has changed (following\n\t\thttp://support.microsoft.com/kb/104011).\n\t\t\"\"\"\n\t\t# TODO: Implement Microsoft UIPI (User Interface Privilege Isolation) to\n\t\t#  elevate privilege to system level so the system gets this notification\n\t\t# for now, this must be run as admin to work as expected\n\t\treturn_val = ctypes.wintypes.DWORD()\n\t\tres = message.SendMessageTimeout(\n\t\t\tmessage.HWND_BROADCAST,\n\t\t\tmessage.WM_SETTINGCHANGE,\n\t\t\t0,  # wparam must be null\n\t\t\t'Environment',\n\t\t\tmessage.SMTO_ABORTIFHUNG,\n\t\t\t5000,  # timeout in ms\n\t\t\treturn_val,\n\t\t)\n\t\terror.handle_nonzero_success(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef current(class_):\n\t\t\"Windows Platform SDK GetTimeZoneInformation\"\n\t\ttzi = class_()\n\t\tkernel32 = ctypes.windll.kernel32\n\t\tgetter = kernel32.GetTimeZoneInformation\n\t\tgetter = getattr(kernel32, 'GetDynamicTimeZoneInformation', getter)\n\t\tcode = getter(ctypes.byref(tzi))\n\t\treturn code, tzi", "response": "Windows Platform SDK GetTimeZoneInformation"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a map that for a given year will return the correct Info", "response": "def dynamic_info(self):\n\t\t\"Return a map that for a given year will return the correct Info\"\n\t\tif self.key_name:\n\t\t\tdyn_key = self.get_key().subkey('Dynamic DST')\n\t\t\tdel dyn_key['FirstEntry']\n\t\t\tdel dyn_key['LastEntry']\n\t\t\tyears = map(int, dyn_key.keys())\n\t\t\tvalues = map(Info, dyn_key.values())\n\t\t\t# create a range mapping that searches by descending year and matches\n\t\t\t# if the target year is greater or equal.\n\t\t\treturn RangeMap(zip(years, values), RangeMap.descending, operator.ge)\n\t\telse:\n\t\t\treturn AnyDict(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlocate the actual day of the given date.", "response": "def _locate_day(year, cutoff):\n\t\t\"\"\"\n\t\tTakes a SYSTEMTIME object, such as retrieved from a TIME_ZONE_INFORMATION\n\t\tstructure or call to GetTimeZoneInformation and interprets\n\t\tit based on the given\n\t\tyear to identify the actual day.\n\n\t\tThis method is necessary because the SYSTEMTIME structure\n\t\trefers to a day by its\n\t\tday of the week and week of the month (e.g. 4th saturday in March).\n\n\t\t>>> SATURDAY = 6\n\t\t>>> MARCH = 3\n\t\t>>> st = SYSTEMTIME(2000, MARCH, SATURDAY, 4, 0, 0, 0, 0)\n\n\t\t# according to my calendar, the 4th Saturday in March in 2009 was the 28th\n\t\t>>> expected_date = datetime.datetime(2009, 3, 28)\n\t\t>>> Info._locate_day(2009, st) == expected_date\n\t\tTrue\n\t\t\"\"\"\n\t\t# MS stores Sunday as 0, Python datetime stores Monday as zero\n\t\ttarget_weekday = (cutoff.day_of_week + 6) % 7\n\t\t# For SYSTEMTIMEs relating to time zone inforamtion, cutoff.day\n\t\t#  is the week of the month\n\t\tweek_of_month = cutoff.day\n\t\t# so the following is the first day of that week\n\t\tday = (week_of_month - 1) * 7 + 1\n\t\tresult = datetime.datetime(\n\t\t\tyear, cutoff.month, day,\n\t\t\tcutoff.hour, cutoff.minute, cutoff.second, cutoff.millisecond)\n\t\t# now the result is the correct week, but not necessarily\n\t\t# the correct day of the week\n\t\tdays_to_go = (target_weekday - result.weekday()) % 7\n\t\tresult += datetime.timedelta(days_to_go)\n\t\t# if we selected a day in the month following the target month,\n\t\t#  move back a week or two.\n\t\t# This is necessary because Microsoft defines the fifth week in a month\n\t\t#  to be the last week in a month and adding the time delta might have\n\t\t#  pushed the result into the next month.\n\t\twhile result.month == cutoff.month + 1:\n\t\t\tresult -= datetime.timedelta(weeks=1)\n\t\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef no_redirect(pattern, locale_prefix=True, re_flags=None):\n    if locale_prefix:\n        pattern = pattern.lstrip('^/')\n        pattern = LOCALE_RE + pattern\n\n    if re_flags:\n        pattern = '(?{})'.format(re_flags) + pattern\n\n    def _view(request, *args, **kwargs):\n        return None\n\n    return url(pattern, _view)", "response": "Returns a url matcher that will not redirect to the given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a url matcher suited for redirecting the requested URL to another URL.", "response": "def redirect(pattern, to, permanent=True, locale_prefix=True, anchor=None, name=None,\n             query=None, vary=None, cache_timeout=12, decorators=None, re_flags=None,\n             to_args=None, to_kwargs=None, prepend_locale=True, merge_query=False):\n    \"\"\"\n    Return a url matcher suited for urlpatterns.\n\n    pattern: the regex against which to match the requested URL.\n    to: either a url name that `reverse` will find, a url that will simply be returned,\n        or a function that will be given the request and url captures, and return the\n        destination.\n    permanent: boolean whether to send a 301 or 302 response.\n    locale_prefix: automatically prepend `pattern` with a regex for an optional locale\n        in the url. This locale (or None) will show up in captured kwargs as 'locale'.\n    anchor: if set it will be appended to the destination url after a '#'.\n    name: if used in a `urls.py` the redirect URL will be available as the name\n        for use in calls to `reverse()`. Does _NOT_ work if used in a `redirects.py` file.\n    query: a dict of query params to add to the destination url.\n    vary: if you used an HTTP header to decide where to send users you should include that\n        header's name in the `vary` arg.\n    cache_timeout: number of hours to cache this redirect. just sets the proper `cache-control`\n        and `expires` headers.\n    decorators: a callable (or list of callables) that will wrap the view used to redirect\n        the user. equivalent to adding a decorator to any other view.\n    re_flags: a string of any of the characters: \"iLmsux\". Will modify the `pattern` regex\n        based on the documented meaning of the flags (see python re module docs).\n    to_args: a tuple or list of args to pass to reverse if `to` is a url name.\n    to_kwargs: a dict of keyword args to pass to reverse if `to` is a url name.\n    prepend_locale: if true the redirect URL will be prepended with the locale from the\n        requested URL.\n    merge_query: merge the requested query params from the `query` arg with any query params\n        from the request.\n\n    Usage:\n    urlpatterns = [\n        redirect(r'projects/$', 'mozorg.product'),\n        redirect(r'^projects/seamonkey$', 'mozorg.product', locale_prefix=False),\n        redirect(r'apps/$', 'https://marketplace.firefox.com'),\n        redirect(r'firefox/$', 'firefox.new', name='firefox'),\n        redirect(r'the/dude$', 'abides', query={'aggression': 'not_stand'}),\n    ]\n    \"\"\"\n    if permanent:\n        redirect_class = HttpResponsePermanentRedirect\n    else:\n        redirect_class = HttpResponseRedirect\n\n    if locale_prefix:\n        pattern = pattern.lstrip('^/')\n        pattern = LOCALE_RE + pattern\n\n    if re_flags:\n        pattern = '(?{})'.format(re_flags) + pattern\n\n    view_decorators = []\n    if cache_timeout is not None:\n        view_decorators.append(cache_control_expires(cache_timeout))\n\n    if vary:\n        if isinstance(vary, basestring):\n            vary = [vary]\n        view_decorators.append(vary_on_headers(*vary))\n\n    if decorators:\n        if callable(decorators):\n            view_decorators.append(decorators)\n        else:\n            view_decorators.extend(decorators)\n\n    def _view(request, *args, **kwargs):\n        # don't want to have 'None' in substitutions\n        kwargs = {k: v or '' for k, v in kwargs.items()}\n        args = [x or '' for x in args]\n\n        # If it's a callable, call it and get the url out.\n        if callable(to):\n            to_value = to(request, *args, **kwargs)\n        else:\n            to_value = to\n\n        if to_value.startswith('/') or HTTP_RE.match(to_value):\n            redirect_url = to_value\n        else:\n            try:\n                redirect_url = reverse(to_value, args=to_args, kwargs=to_kwargs)\n            except NoReverseMatch:\n                # Assume it's a URL\n                redirect_url = to_value\n\n        if prepend_locale and redirect_url.startswith('/') and kwargs.get('locale'):\n            redirect_url = '/{locale}' + redirect_url.lstrip('/')\n\n        # use info from url captures.\n        if args or kwargs:\n            redirect_url = strip_tags(force_text(redirect_url).format(*args, **kwargs))\n\n        if query:\n            if merge_query:\n                req_query = parse_qs(request.META.get('QUERY_STRING'))\n                req_query.update(query)\n                querystring = urlencode(req_query, doseq=True)\n            else:\n                querystring = urlencode(query, doseq=True)\n        elif query is None:\n            querystring = request.META.get('QUERY_STRING')\n        else:\n            querystring = ''\n\n        if querystring:\n            redirect_url = '?'.join([redirect_url, querystring])\n\n        if anchor:\n            redirect_url = '#'.join([redirect_url, anchor])\n\n        if PROTOCOL_RELATIVE_RE.match(redirect_url):\n            redirect_url = '/' + redirect_url.lstrip('/')\n\n        return redirect_class(redirect_url)\n\n    # Apply decorators\n    try:\n        # Decorators should be applied in reverse order so that input\n        # can be sent in the order your would write nested decorators\n        # e.g. dec1(dec2(_view)) -> [dec1, dec2]\n        for decorator in reversed(view_decorators):\n            _view = decorator(_view)\n    except TypeError:\n        log.exception('decorators not iterable or does not contain '\n                      'callable items')\n\n    return url(pattern, _view, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findpath(target, start=os.path.curdir):\r\n\treturn os.path.normpath(os.path.join(start, target))", "response": "Find a path relative to target."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the size of the table.", "response": "def __get_table_size(self):\n\t\t\"\"\"\n\t\tRetrieve the size of the buffer needed by calling the method\n\t\twith a null pointer and length of zero. This should trigger an\n\t\tinsufficient buffer error and return the size needed for the\n\t\tbuffer.\n\t\t\"\"\"\n\t\tlength = ctypes.wintypes.DWORD()\n\t\tres = self.method(None, length, False)\n\t\tif res != errors.ERROR_INSUFFICIENT_BUFFER:\n\t\t\traise RuntimeError(\"Error getting table length (%d)\" % res)\n\t\treturn length.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the table of the current structure.", "response": "def get_table(self):\n\t\t\"\"\"\n\t\tGet the table\n\t\t\"\"\"\n\t\tbuffer_length = self.__get_table_size()\n\t\treturned_buffer_length = ctypes.wintypes.DWORD(buffer_length)\n\t\tbuffer = ctypes.create_string_buffer(buffer_length)\n\t\tpointer_type = ctypes.POINTER(self.structure)\n\t\ttable_p = ctypes.cast(buffer, pointer_type)\n\t\tres = self.method(table_p, returned_buffer_length, False)\n\t\tif res != errors.NO_ERROR:\n\t\t\traise RuntimeError(\"Error retrieving table (%d)\" % res)\n\t\treturn table_p.contents"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef entries(self):\n\t\ttable = self.get_table()\n\t\tentries_array = self.row_structure * table.num_entries\n\t\tpointer_type = ctypes.POINTER(entries_array)\n\t\treturn ctypes.cast(table.entries, pointer_type).contents", "response": "Returns the array of entries based on the table size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef owncloud():\n    '''Set up owncloud.\n\n    Package 'owncloud' pulls package 'mysql' which asks for a password.\n    '''\n    hostname = re.sub(r'^[^@]+@', '', env.host)  # without username if any\n    sitename = query_input(\n                   question='\\nEnter site-name of Your Owncloud web service',\n                   default=flo('owncloud.{hostname}'), color=cyan)\n    username = env.user\n\n    fabfile_data_dir = FABFILE_DATA_DIR\n\n    print(magenta(' install owncloud'))\n    repository = ''.join([\n        'http://download.opensuse.org/repositories/',\n        'isv:/ownCloud:/community/Debian_7.0/',\n    ])\n    with hide('output'):\n        sudo(flo('wget -O - {repository}Release.key | apt-key add -'))\n        filename = '/etc/apt/sources.list.d/owncloud.list'\n        sudo(flo(\"echo 'deb {repository} /' > {filename}\"))\n        sudo('apt-get update')\n    install_packages([\n        'owncloud',\n        'php5-fpm',\n        'php-apc',\n        'memcached',\n        'php5-memcache',\n    ])\n\n    # This server uses nginx. owncloud pulls apache2 => Disable apache2\n    print(magenta(' disable apache'))\n    with hide('output'):\n        sudo('service apache2 stop')\n        sudo('update-rc.d apache2 disable')\n\n    print(magenta(' nginx setup for owncloud'))\n    filename = 'owncloud_site_config.template'\n    path = flo('{fabfile_data_dir}/files/etc/nginx/sites-available/{filename}')\n    from_str = filled_out_template(path, username=username, sitename=sitename,\n                                   hostname=hostname)\n    with tempfile.NamedTemporaryFile(prefix=filename) as tmp_file:\n        with open(tmp_file.name, 'w') as fp:\n            fp.write(from_str)\n        put(tmp_file.name, flo('/tmp/{filename}'))\n    to = flo('/etc/nginx/sites-available/{sitename}')\n    sudo(flo('mv /tmp/{filename} {to}'))\n    sudo(flo('chown root.root {to}'))\n    sudo(flo('chmod 644 {to}'))\n    sudo(flo(' '.join([\n            'ln -snf ../sites-available/{sitename}',\n            '/etc/nginx/sites-enabled/{sitename}',\n    ])))\n\n    # php5 fpm fast-cgi config\n\n    template = 'www.conf'\n    to = flo('/etc/php5/fpm/pool.d/{template}')\n    from_ = flo('{fabfile_data_dir}/files{to}')\n    put(from_, '/tmp/')\n    sudo(flo('mv /tmp/{template} {to}'))\n    sudo(flo('chown root.root {to}'))\n    sudo(flo('chmod 644 {to}'))\n\n    template = 'php.ini'\n    to = flo('/etc/php5/fpm/{template}')\n    from_ = flo('{fabfile_data_dir}/files{to}')\n    put(from_, '/tmp/')\n    sudo(flo('mv /tmp/{template} {to}'))\n    sudo(flo('chown root.root {to}'))\n    sudo(flo('chmod 644 {to}'))\n\n    sudo('service php5-fpm restart')\n\n    sudo('service nginx reload')", "response": "Set up owncloud.\n\n    Package 'owncloud' pulls package 'mysql' which asks for a password."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fdroid():\n    '''Set up an F-Droid App Repo.\n\n    More infos:\n     * https://f-droid.org/wiki/page/Setup_an_FDroid_App_Repo\n     * https://f-droid.org/wiki/page/Installing_the_Server_and_Repo_Tools\n    '''\n    hostname = re.sub(r'^[^@]+@', '', env.host)  # without username if any\n    sitename = query_input(\n                   question='\\nEnter site-name of Your F-Droid web service',\n                   default=flo('fdroid.{hostname}'))\n    username = env.user\n\n    fabfile_data_dir = FABFILE_DATA_DIR\n\n    print(magenta(' install fdroidserver'))\n    res = run('dpkg --get-selections | '\n              'grep -q \"^fdroidserver[[:space:]]*install$\" >/dev/null',\n              warn_only=True)\n    package_installed = res.return_code == 0\n    question = 'package fdroidserver already installed, update? ' \\\n               '(needs some time)'\n    if package_installed and not query_yes_no(question, default='no'):\n        print('skip update')\n    else:\n        with hide('output'):\n            sudo('yes \"\" | add-apt-repository  ppa:guardianproject/ppa')\n            sudo('apt-get update')\n            # why 'android-libhost-dev' (avoid \"Failed to get apk information\"\n            # on 'fdroid update --create-metadata'):\n            # https://f-droid.org/forums/topic/failed-to-get-apk-information-2/#post-15777\n            install_packages(['fdroidserver', 'android-libhost-dev'])\n            sudo('yes \"\" | add-apt-repository --remove  '\n                 'ppa:guardianproject/ppa')\n            sudo('apt-get update')\n\n    site_dir = flo('/home/{username}/sites/{sitename}')\n    apks_dir   = flo('{site_dir}/apks')\n    fdroid_dir = flo('{site_dir}/fdroid')\n    repo_dir   = flo('{site_dir}/fdroid/repo')\n\n    print(magenta(' init f-droid repo'))\n    question = ' '.join(['already initialized, initialize again?',\n                         '(creates a new repo key)'])\n    if exists(repo_dir) and not query_yes_no(question, default='no'):\n        print('skip initialization')\n    else:\n        with warn_only():\n            run(flo('rm -rf  {fdroid_dir}'))\n        run(flo('mkdir -p  {repo_dir}'))\n        run(flo('cd {fdroid_dir}  &&  fdroid init'))\n        run(flo('cd {site_dir}  &&  tree'))\n\n    print(magenta(' update apk files of the fdroid repo'))\n    run(flo('mkdir -p  {apks_dir}'))\n    run(flo('rm -rf {repo_dir}/*.apk'))\n    run(flo(\"find {apks_dir} -type f | rename 's/ /_/g'\"))\n    run(flo(\"find {apks_dir} -type f | rename 's/[^[:ascii:]]//g'\"))\n    run(flo('chmod 644 {apks_dir}/*.apk'))\n    run(flo('cp -v {apks_dir}/*.apk  {repo_dir}'), warn_only=True)\n    run(flo('cd {fdroid_dir}  &&  fdroid update --create-metadata'))\n\n    print(magenta(' setup nginx for F-Droid'))\n\n    run(flo('echo -e \"User-agent: *\\\\nDisallow: /\" > {fdroid_dir}/robots.txt'))\n\n    filename = 'fdroid_site_config.template'\n    path = flo('{fabfile_data_dir}/files/etc/nginx/sites-available/{filename}')\n    from_str = filled_out_template(path, username=username, sitename=sitename,\n                                   hostname=hostname)\n    with tempfile.NamedTemporaryFile(prefix=filename) as tmp_file:\n        with open(tmp_file.name, 'w') as fp:\n            fp.write(from_str)\n        put(tmp_file.name, flo('/tmp/{filename}'))\n    to = flo('/etc/nginx/sites-available/{sitename}')\n    sudo(flo('mv /tmp/{filename} {to}'))\n    sudo(flo('chown root.root {to}'))\n    sudo(flo('chmod 644 {to}'))\n    sudo(flo(' '.join([\n            'ln -snf ../sites-available/{sitename}',\n            '/etc/nginx/sites-enabled/{sitename}',\n    ])))\n\n    sudo('service nginx reload')", "response": "Setup an F - Droid App Repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls and configure the dispmanx_vnc server on the OSMC raspberry pi.", "response": "def vnc_raspi_osmc():\n    '''Install and configure dispmanx_vnc server on osmc (raspberry pi).\n\n    More Infos:\n     * https://github.com/patrikolausson/dispmanx_vnc\n     * https://discourse.osmc.tv/t/howto-install-a-vnc-server-on-the-raspberry-pi/1517\n     * tightvnc:\n       * http://raspberry.tips/raspberrypi-einsteiger/raspberry-pi-einsteiger-guide-vnc-einrichten-teil-4/\n       * http://jankarres.de/2012/08/raspberry-pi-vnc-server-installieren/\n    '''\n    print(blue('Install dependencies'))\n    install_packages([\n            'git',\n            'build-essential',\n            'rbp-userland-dev-osmc',\n            'libvncserver-dev',\n            'libconfig++-dev',\n    ])\n\n    print(blue('Build vnc server for raspberry pi using dispmanx '\n               '(dispmanx_vnc)'))\n    checkup_git_repo_legacy(\n        url='https://github.com/patrikolausson/dispmanx_vnc.git')\n    run('mkdir -p ~/repos')\n    run('cd ~/repos/dispmanx_vnc  &&  make')\n\n    print(blue('set up dispmanx_vnc as a service'))\n    with warn_only():\n        run('sudo systemctl  stop  dispmanx_vncserver.service')\n    username = env.user\n    builddir = flo('/home/{username}/repos/dispmanx_vnc')\n    run(flo('sudo  cp  {builddir}/dispmanx_vncserver  /usr/bin'))\n    run('sudo  chmod +x  /usr/bin/dispmanx_vncserver')\n    fabfile_data_dir = FABFILE_DATA_DIR\n    put('{fabfile_data_dir}/files/etc/dispmanx_vncserver.conf', '/tmp/')\n    run('sudo mv  /tmp/dispmanx_vncserver.conf  /etc/dispmanx_vncserver.conf')\n    put('{fabfile_data_dir}/files/etc/systemd/system/dispmanx_vncserver.service',\n        '/tmp/')\n    run('sudo mv  /tmp/dispmanx_vncserver.service  '\n        '/etc/systemd/system/dispmanx_vncserver.service')\n    run('sudo systemctl start dispmanx_vncserver.service')\n    run('sudo systemctl enable dispmanx_vncserver.service')\n    run('sudo systemctl daemon-reload')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall and start a Logitech Media Server.", "response": "def lms():\n    '''Install and start a Logitech Media Server (lms).\n\n    More infos:\n     * http://wiki.slimdevices.com/index.php/Logitech_Media_Server\n     * http://wiki.slimdevices.com/index.php/DebianPackage\n     * http://www.mysqueezebox.com/download\n     * XSqueeze on Kodi:\n       * http://kodi.wiki/view/Add-on:XSqueeze\n       * http://forum.kodi.tv/showthread.php?tid=122199\n    '''\n    # cf. http://wiki.slimdevices.com/index.php/DebianPackage#installing_7.9.0\n    cmds = '''\\\nurl=\"http://www.mysqueezebox.com/update/?version=7.9.0&revision=1&geturl=1&os=deb\"\nlatest_lms=$(wget -q -O - \"$url\")\nmkdir -p ~/.logitech_media_server_sources\ncd ~/.logitech_media_server_sources\nwget $latest_lms\nlms_deb=${latest_lms##*/}\nsudo dpkg -i $lms_deb\n'''\n    run(cmds)\n    run('sudo usermod -aG audio  squeezeboxserver')\n    with warn_only():\n        run('sudo addgroup lms')\n    run('sudo usermod -aG lms  squeezeboxserver')\n    username = env.user\n    run(flo('sudo usermod -aG audio  {username}'))\n    print('\\n    Set correct folder permissions manually, eg:')\n    print('    > ' + cyan(flo('chown -R {username}.lms  <path/to/your/media>')))\n    hostname = env.host\n    print(flo('\\n    lms frontend available at http://{hostname}:9000'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls smb server samba and create a shared file", "response": "def samba():\n    '''Install smb server samba and create a share (common read-write-access).\n\n    More infos:\n     * https://wiki.ubuntuusers.de/Samba%20Server/\n    '''\n    username = env.user\n    install_packages(['samba'])\n    run(flo('sudo smbpasswd -a {username}'))\n\n    path = '$HOME/shared'\n    sharename = 'shared'\n    comment = '\"smb share; everyone has full access (read/write)\"'\n    acl = flo('Everyone:F,{username}:F guest_ok=y')\n\n    with warn_only():\n        run(flo('mkdir {path}'))\n    run(flo('sudo net usershare add {sharename} {path} {comment} {acl}'))\n    run(flo('sudo net usershare info {sharename}'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_scalar__literal(self, p):\n        scalar_group = ''.join(p[2])\n        p[0] = ScalarDispatch('%s\\n' % dedent(scalar_group).replace('\\n\\n\\n', '\\n'), cast='str')", "response": "scalar  : B_LITERAL_START scalar_group B_LITERAL_END"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfold version of the scalar.", "response": "def p_scalar__folded(self, p):\n        \"\"\"\n        scalar  : B_FOLD_START scalar_group B_FOLD_END\n        \"\"\"\n        scalar_group = ''.join(p[2])\n        folded_scalar = fold(dedent(scalar_group)).rstrip()\n        p[0] = ScalarDispatch('%s\\n' % folded_scalar, cast='str')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_scalar__indented_flow(self, p):\n        scalar_group = '\\n'.join(p[2])\n        folded_scalar = fold(dedent(scalar_group))\n        p[0] = ScalarDispatch(folded_scalar, cast='str')", "response": "scalar  : INDENT scalar_group DEDENT"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_scalar__string_indented_multi_line(self, p):\n        scalar = '\\n'.join([p[1].value, p[3]])\n\n        p[0] = ScalarDispatch(fold(scalar), cast='str')", "response": "scalar INDENT SCALAR DEDENTS scalar"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef doctree_read_handler(app, doctree):\n    # noinspection PyProtectedMember\n    docname = sys._getframe(2).f_locals['docname']\n    if docname.startswith('_partial'):\n        app.env.metadata[docname]['orphan'] = True", "response": "Handle doctree read events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nskip un parseable functions. :type app: sphinx.application.Sphinx :param str what: the type of the object which the docstring belongs to (one of \"module\", \"class\", \"exception\", \"function\", \"method\", \"attribute\") :param str name: the fully qualified name of the object :param type obj: the object itself :param bool skip: a boolean indicating if autodoc will skip this member :param sphinx.ext.autodoc.Options options: the options given to the directive :rtype: bool", "response": "def autodoc_skip_member_handler(app, what, name, obj, skip, options):\n    \"\"\"\n    Skip un parseable functions.\n\n    :type app: sphinx.application.Sphinx\n    :param str what: the type of the object which the docstring belongs to\n        (one of \"module\", \"class\", \"exception\", \"function\", \"method\", \"attribute\")\n    :param str name: the fully qualified name of the object\n    :param type obj: the object itself\n    :param bool skip: a boolean indicating if autodoc will skip this member\n    :param sphinx.ext.autodoc.Options options: the options given to the directive\n    :rtype: bool\n    \"\"\"\n    if 'YAMLTokens' in name:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configGet(self, vartype, category, name, optional=False, specialReturnMessage=None):\n    \n    try:\n      if vartype == 'float':\n        var = self.config.getfloat(category, name)\n      elif vartype == 'string' or vartype == 'str':\n        var = self.config.get(category, name)\n        if var == \"\"  and optional == False:\n          # but \"\" is acceptable for boundary conditions\n          if name[:17] != 'BoundaryCondition':\n            if self.Quiet != True:\n              print(\"An empty input string here is not an acceptable option.\")\n              print(name, \"is not optional.\")\n              print(\"Program crash likely to occur.\")\n      elif vartype == 'integer' or vartype == 'int':\n        var = self.config.getint(category, name)\n      elif vartype == 'boolean' or vartype == 'bool':\n        var = self.config.getboolean(category, name)\n      else:\n        print(\"Please enter 'float', 'string' (or 'str'), 'integer' (or 'int'), or 'boolean (or 'bool') for vartype\")\n        sys.exit() # Won't exit, but will lead to exception\n      return var\n    except:\n      if optional:\n        # Carry on if the variable is optional\n        var = None\n        if self.Verbose or self.Debug:\n          if self.grass == False:\n            print(\"\")\n            print('No value entered for optional parameter \"' + name + '\"')\n            print('in category \"' + category + '\" in configuration file.')\n            print(\"No action related to this optional parameter will be taken.\")\n            print(\"\")\n      else:\n        print('Problem loading ' + vartype + ' \"' + name + '\" in category \"' + category + '\" from configuration file.')\n        if specialReturnMessage:\n          print(specialReturnMessage)\n        sys.exit(\"Exiting.\")", "response": "Get a variable from the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the great circle distance between two points.", "response": "def greatCircleDistance(self, lat1, long1, lat2, long2, radius):\n    \"\"\"\n    Returns the great circle distance between two points.\n    Useful when using the SAS_NG solution in lat/lon coordinates\n    Modified from http://www.johndcook.com/blog/python_longitude_latitude/\n    It should be able to take numpy arrays.\n    \"\"\"\n\n    # Convert latitude and longitude to\n    # spherical coordinates in radians.\n    degrees_to_radians = np.pi/180.0\n         \n    # theta = colatitude = 90 - latitude\n    theta1rad = (90.0 - lat1)*degrees_to_radians\n    theta2rad = (90.0 - lat2)*degrees_to_radians\n         \n    # lambda = longitude\n    lambda1rad = long1*degrees_to_radians\n    lambda2rad = long2*degrees_to_radians\n         \n    # Compute spherical distance from spherical coordinates.\n         \n    # For two locations in spherical coordinates\n    # (1, theta, phi) and (1, theta, phi)\n    # cosine( arc length ) =\n    #    sin(theta) * sin(theta') * cos(theta-theta') + cos(phi) * cos(phi')\n    # distance = radius * arc length\n     \n    cos_arc_length = np.sin(theta1rad) * np.sin(theta2rad) * \\\n                     np.cos(lambda1rad - lambda2rad) + \\\n                     np.cos(theta1rad) * np.cos(theta2rad)\n    arc = np.arccos( cos_arc_length )\n \n    great_circle_distance = radius * arc\n    \n    return great_circle_distance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a file from the model python files.", "response": "def loadFile(self, var, close_on_fail = True):\n    \"\"\"\n    A special function to replate a variable name that is a string file path\n    with the loaded file.\n    var is a string on input\n    output is a numpy array or a None-type object (success vs. failure)\n    \"\"\"\n    out = None\n    try:\n      # First see if it is a full path or directly links from the current\n      # working directory\n      out = np.load(var)\n      if self.Verbose: print(\"Loading \"+var+\" from numpy binary\")\n    except:\n      try:\n        out = np.loadtxt(var)\n        if self.Verbose: print(\"Loading \"+var+\" ASCII\")\n      except:\n        # Then see if it is relative to the location of the configuration file\n        try:\n          out = load(self.inpath + var)\n          if self.Verbose: print(\"Loading \"+var+\" from numpy binary\")\n        except:\n          try:\n            out = np.loadtxt(self.inpath + var)\n            if self.Verbose: print(\"Loading \"+var+\" ASCII\")\n          # If failure\n          except:\n            if close_on_fail:\n              print(\"Cannot find \"+var+\" file\")\n              print(\"\"+var+\" path = \" + var)\n              print(\"Looked relative to model python files.\")\n              print(\"Also looked relative to configuration file path,\")\n              print(\"  \", self.inpath)\n              print(\"Exiting.\")\n              sys.exit()\n            else:\n              pass\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef surfplot(self, z, titletext):\n    if self.latlon:\n      plt.imshow(z, extent=(0, self.dx*z.shape[0], self.dy*z.shape[1], 0)) #,interpolation='nearest'\n      plt.xlabel('longitude [deg E]', fontsize=12, fontweight='bold')\n      plt.ylabel('latitude [deg N]', fontsize=12, fontweight='bold')\n    else:\n      plt.imshow(z, extent=(0, self.dx/1000.*z.shape[0], self.dy/1000.*z.shape[1], 0)) #,interpolation='nearest'\n      plt.xlabel('x [km]', fontsize=12, fontweight='bold')\n      plt.ylabel('y [km]', fontsize=12, fontweight='bold')\n    plt.colorbar()\n\n    plt.title(titletext,fontsize=16)", "response": "Plots the surface of the given z."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting multiple subplot figure for 2D array", "response": "def twoSurfplots(self):\n    \"\"\"\n    Plot multiple subplot figure for 2D array\n    \"\"\"\n    # Could more elegantly just call surfplot twice\n    # And also could include xyzinterp as an option inside surfplot.\n    # Noted here in case anyone wants to take that on in the future...\n\n    plt.subplot(211)\n    plt.title('Load thickness, mantle equivalent [m]',fontsize=16)\n    if self.latlon:\n      plt.imshow(self.qs/(self.rho_m*self.g), extent=(0, self.dx*self.qs.shape[0], self.dy*self.qs.shape[1], 0))\n      plt.xlabel('longitude [deg E]', fontsize=12, fontweight='bold')\n      plt.ylabel('latitude [deg N]', fontsize=12, fontweight='bold')\n    else:\n      plt.imshow(self.qs/(self.rho_m*self.g), extent=(0, self.dx/1000.*self.qs.shape[0], self.dy/1000.*self.qs.shape[1], 0))\n      plt.xlabel('x [km]', fontsize=12, fontweight='bold')\n      plt.ylabel('y [km]', fontsize=12, fontweight='bold')\n    plt.colorbar()\n\n    plt.subplot(212)\n    plt.title('Deflection [m]')\n    if self.latlon:\n      plt.imshow(self.w, extent=(0, self.dx*self.w.shape[0], self.dy*self.w.shape[1], 0))\n      plt.xlabel('longitude [deg E]', fontsize=12, fontweight='bold')\n      plt.ylabel('latitude [deg N]', fontsize=12, fontweight='bold')\n    else:\n      plt.imshow(self.w, extent=(0, self.dx/1000.*self.w.shape[0], self.dy/1000.*self.w.shape[1], 0))\n      plt.xlabel('x [km]', fontsize=12, fontweight='bold')\n      plt.ylabel('y [km]', fontsize=12, fontweight='bold')\n    plt.colorbar()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninterpolate and plots ungridded model outputs from SAS_NG solution", "response": "def xyzinterp(self, x, y, z, titletext):\n    \"\"\"\n    Interpolates and plots ungridded model outputs from SAS_NG solution\n    \"\"\"\n    # Help from http://wiki.scipy.org/Cookbook/Matplotlib/Gridding_irregularly_spaced_data\n    \n    if self.Verbose:\n      print(\"Starting to interpolate grid for plotting -- can be a slow process!\")\n    \n    from scipy.interpolate import griddata\n    import numpy.ma as ma\n    \n    # define grid.\n    xmin = np.min(self.xw)\n    xmean = np.mean(self.xw) # not used right now\n    xmax = np.max(self.xw)\n    ymin = np.min(self.yw)\n    ymean = np.mean(self.yw) # not used right now\n    ymax = np.max(self.yw)\n    x_range = xmax - xmin\n    y_range = ymax - ymin\n    \n    # x and y grids\n    # 100 cells on each side -- just for plotting, not so important\n    # to optimize with how many points are plotted\n    #xi = np.linspace(xmin-.05*x_range, xmax+.05*x_range, 200)\n    #yi = np.linspace(ymin-.05*y_range, ymax+.05*y_range, 200)\n    xi = np.linspace(xmin, xmax, 200)\n    yi = np.linspace(ymin, ymax, 200)\n    # grid the z-axis\n    zi = griddata((x, y), z, (xi[None,:], yi[:,None]), method='cubic')\n    # turn nan into 0 -- this will just be outside computation area for q\n    zi[np.isnan(zi)] = 0\n    # contour the gridded outputs, plotting dots at the randomly spaced data points.\n    #CS = plt.contour(xi,yi,zi,15,linewidths=0.5,colors='k') -- don't need lines\n    if self.latlon:\n      CS = plt.contourf(xi, yi, zi, 100, cmap=plt.cm.jet)\n    else:\n      CS = plt.contourf(xi/1000., yi/1000., zi, 100, cmap=plt.cm.jet)\n    plt.colorbar() # draw colorbar\n    # plot model points.\n    # Computed at\n    if self.latlon:\n      plt.plot(x, y, 'o', markerfacecolor='.6', markeredgecolor='.6', markersize=1)\n      plt.plot(self.x, self.y, 'o', markerfacecolor='.2', markeredgecolor='.2', markersize=1)\n    else:\n      plt.plot(x/1000., y/1000., 'o', markerfacecolor='.6', markeredgecolor='.6', markersize=1)\n      # Load sources (overlay computed at)\n      plt.plot(self.x/1000., self.y/1000., 'o', markerfacecolor='.2', markeredgecolor='.2', markersize=1)\n      #plt.hexbin(self.x, self.y, C=self.w) -- show colors on points -- harder to see\n    if self.latlon:\n      plt.xlabel('longitude [deg E]', fontsize=12, fontweight='bold')\n      plt.ylabel('latitude [deg N]', fontsize=12, fontweight='bold')\n    else:\n      plt.xlabel('x [km]', fontsize=12, fontweight='bold')\n      plt.ylabel('y [km]', fontsize=12, fontweight='bold')\n    # Limits -- to not get messed up by points (view wants to be wider so whole point visible)\n    if self.latlon:\n      plt.xlim( (xi[0], xi[-1]) )\n      plt.ylim( (yi[0], yi[-1]) )\n    else:\n      plt.xlim( (xi[0]/1000., xi[-1]/1000.) )\n      plt.ylim( (yi[0]/1000., yi[-1]/1000.) )\n    # Title\n    plt.title(titletext, fontsize=16)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef outputDeflections(self):\n    try:\n      # If wOutFile exists, has already been set by a setter\n      self.wOutFile\n      if self.Verbose:\n        print(\"Output filename provided.\")\n    # Otherwise, it needs to be set by an configuration file\n    except:\n      try:\n        self.wOutFile = self.configGet(\"string\", \"output\", \"DeflectionOut\", optional=True)\n      except:\n        # if there is no parsable output string, do not generate output;\n        # this allows the user to leave the line blank and produce no output\n        if self.Debug:\n          print(\"No output filename provided:\")\n          print(\"  not writing any deflection output to file\")\n    if self.wOutFile:\n        if self.wOutFile[-4:] == '.npy':\n          from numpy import save\n          save(self.wOutFile,self.w)\n        else:\n          from numpy import savetxt\n          # Shouldn't need more than mm precision, at very most\n          savetxt(self.wOutFile,self.w,fmt='%.3f')\n          if self.Verbose:\n            print(\"Saving deflections --> \" + self.wOutFile)", "response": "Outputs a grid of deflections to a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef coeffArraySizeCheck(self):\n    if prod(self.coeff_matrix.shape) != long(prod(np.array(self.qs.shape,dtype=int64)+2)**2):\n      print(\"Inconsistent size of q0 array and coefficient mattrix\")\n      print(\"Exiting.\")\n      sys.exit()", "response": "Check that the size of the coefficient array and q0 array are the right size compared to \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef TeArraySizeCheck(self):\n    # Only if they are both defined and are arrays\n    # Both being arrays is a possible bug in this check routine that I have \n    # intentionally introduced\n    if type(self.Te) == np.ndarray and type(self.qs) == np.ndarray:\n      # Doesn't touch non-arrays or 1D arrays\n      if type(self.Te) is np.ndarray:\n        if (np.array(self.Te.shape) != np.array(self.qs.shape)).any():\n          sys.exit(\"q0 and Te arrays have incompatible shapes. Exiting.\")\n      else:\n        if self.Debug: print(\"Te and qs array sizes pass consistency check\")", "response": "Checks that Te and q0 array sizes are compatible"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FD(self):\n    if self.Verbose:\n      print(\"Finite Difference Solution Technique\")\n    # Used to check for coeff_matrix here, but now doing so in self.bc_check()\n    # called by f1d and f2d at the start\n    # \n    # Define a stress-based qs = q0\n    # But only if the latter has not already been defined\n    # (e.g., by the getters and setters)\n    try:\n      self.qs\n    except:\n      self.qs = self.q0.copy()\n      # Remove self.q0 to avoid issues with multiply-defined inputs\n      # q0 is the parsable input to either a qs grid or contains (x,(y),q)\n      del self.q0\n    # Give it x and y dimensions for help with plotting tools\n    # (not implemented internally, but a help with external methods)\n    self.x = np.arange(self.dx/2., self.dx * self.qs.shape[0], self.dx)\n    if self.dimension == 2:\n      self.y = np.arange(self.dy/2., self.dy * self.qs.shape[1], self.dy)\n    # Is there a solver defined\n    try:\n      self.Solver # See if it exists already\n    except:\n      # Well, will fail if it doesn't see this, maybe not the most reasonable\n      # error message.\n      if self.filename:\n        self.Solver = self.configGet(\"string\", \"numerical\", \"Solver\")\n      else:\n        sys.exit(\"No solver defined!\")\n    # Check consistency of size if coeff array was loaded\n    if self.filename:\n      # In the case that it is iterative, find the convergence criterion\n      self.iterative_ConvergenceTolerance = self.configGet(\"float\", \"numerical\", \"ConvergenceTolerance\")    \n      # Try to import Te grid or scalar for the finite difference solution\n      try:\n        self.Te = self.configGet(\"float\", \"input\", \"ElasticThickness\", optional=False)\n        if self.Te is None:\n          Tepath = self.configGet(\"string\", \"input\", \"ElasticThickness\", optional=False)\n          self.Te = Tepath\n        else:\n          Tepath = None\n      except:\n        Tepath = self.configGet(\"string\", \"input\", \"ElasticThickness\", optional=False)\n        self.Te = Tepath\n      if self.Te is None:\n        if self.coeff_matrix is not None:\n          pass\n        else:\n          # Have to bring this out here in case it was discovered in the \n          # try statement that there is no value given\n          sys.exit(\"No input elastic thickness or coefficient matrix supplied.\")\n    # or if getter/setter\n    if type(self.Te) == str: \n      # Try to import Te grid or scalar for the finite difference solution\n      Tepath = self.Te\n    else:\n      Tepath = None # in case no self.filename present (like for GRASS GIS)\n    # If there is a Tepath, import Te\n    # Assume that even if a coeff_matrix is defined\n    # That the user wants Te if they gave the path\n    if Tepath:\n      self.Te = self.loadFile(self.Te, close_on_fail = False)\n      if self.Te is None:\n        print(\"Requested Te file is provided but cannot be located.\")\n        print(\"No scalar elastic thickness is provided in configuration file\")\n        print(\"(Typo in path to input Te grid?)\")\n        if self.coeff_matrix is not None:\n          print(\"But a coefficient matrix has been found.\")\n          print(\"Calculations will be carried forward using it.\")\n        else:\n          print(\"Exiting.\")\n          sys.exit()\n\n      # Check that Te is the proper size if it was loaded\n      # Will be array if it was loaded\n      if self.Te.any():\n        self.TeArraySizeCheck()", "response": "This method is called by the FD method in the class constructor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SAS(self):\n    if self.x is None:\n      self.x = np.arange(self.dx/2., self.dx * self.qs.shape[0], self.dx)\n    if self.filename:\n      # Define the (scalar) elastic thickness\n      self.Te = self.configGet(\"float\", \"input\", \"ElasticThickness\")\n      # Define a stress-based qs = q0\n      self.qs = self.q0.copy()\n      # Remove self.q0 to avoid issues with multiply-defined inputs\n      # q0 is the parsable input to either a qs grid or contains (x,(y),q)\n      del self.q0\n    if self.dimension == 2:\n      if self.y is None:\n        self.y = np.arange(self.dy/2., self.dy * self.qs.shape[0], self.dy)\n      # Define a stress-based qs = q0\n      # But only if the latter has not already been defined\n      # (e.g., by the getters and setters)\n      try:\n        self.qs\n      except:\n        self.qs = self.q0.copy()\n        # Remove self.q0 to avoid issues with multiply-defined inputs\n        # q0 is the parsable input to either a qs grid or contains (x,(y),q)\n        del self.q0\n      from scipy.special import kei", "response": "This method is used to set up the rectangularly - gridded superposition of analytical solutions \n    method for solving flexure of analytical solutions for solving flexure of analytical solutions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SAS_NG(self):\n    if self.filename:\n      # Define the (scalar) elastic thickness\n      self.Te = self.configGet(\"float\", \"input\", \"ElasticThickness\")\n      # See if it wants to be run in lat/lon\n      # Could put under in 2D if-statement, but could imagine an eventual desire\n      # to change this and have 1D lat/lon profiles as well.\n      # So while the options will be under \"numerical2D\", this place here will \n      # remain held for an eventual future.\n      self.latlon = self.configGet(\"string\", \"numerical2D\", \"latlon\", optional=True)\n      self.PlanetaryRadius = self.configGet(\"float\", \"numerical2D\", \"PlanetaryRadius\", optional=True)\n      if self.dimension == 2:\n        from scipy.special import kei\n    # Parse out input q0 into variables of imoprtance for solution\n    if self.dimension == 1:\n      try:\n        # If these have already been set, e.g., by getters/setters, great!\n        self.x\n        self.q\n      except:\n        # Using [x, y, w] configuration file\n        if self.q0.shape[1] == 2:\n          self.x = self.q0[:,0]\n          self.q = self.q0[:,1]\n        else:\n          sys.exit(\"For 1D (ungridded) SAS_NG configuration file, need [x,w] array. Your dimensions are: \"+str(self.q0.shape))\n    else:\n      try:\n        # If these have already been set, e.g., by getters/setters, great!\n        self.x\n        self.u\n        self.q\n      except:\n        # Using [x, y, w] configuration file\n        if self.q0.shape[1] == 3:\n          self.x = self.q0[:,0]\n          self.y = self.q0[:,1]\n          self.q = self.q0[:,2]\n        else:\n          sys.exit(\"For 2D (ungridded) SAS_NG configuration file, need [x,y,w] array. Your dimensions are: \"+str(self.q0.shape))\n    # x, y are in absolute coordinates. Create a local grid reference to \n    # these. This local grid, which starts at (0,0), is defined just so that \n    # we have a way of running the model without defined real-world \n    # coordinates\n    self.x = self.x\n    if self.dimension == 2:\n      self.y = self.y\n    # Remove self.q0 to avoid issues with multiply-defined inputs\n    # q0 is the parsable input to either a qs grid or contains (x,(y),q)\n    del self.q0\n    \n    # Check if a seperate output set of x,y points has been defined\n    # otherwise, set those values to None\n    # First, try to load the arrays\n    try:\n      self.xw\n    except:\n      try:\n        self.xw = self.configGet('string', \"input\", \"xw\", optional=True)\n        if self.xw == '':\n          self.xw = None\n      except:\n        self.xw = None\n    # If strings, load arrays\n    if type(self.xw) == str:\n      self.xw = self.loadFile(self.xw)\n    if self.dimension == 2:\n      try:\n        # already set by setter?\n        self.yw\n      except:\n        try:\n          self.yw = self.configGet('string', \"input\", \"yw\", optional=True )\n          if self.yw == '':\n            self.yw = None\n        except:\n          self.yw = None\n      # At this point, can check if we have both None or both defined\n      if (self.xw is not None and self.yw is None) \\\n        or (self.xw is None and self.yw is not None):\n        sys.exit(\"SAS_NG output at specified points requires both xw and yw to be defined\")\n      # All right, now just finish defining\n      if type(self.yw) == str:\n        self.yw = self.loadFile(self.yw)\n      elif self.yw is None:\n        self.yw = self.y.copy()\n    if self.xw is None:\n      self.xw = self.x.copy()", "response": "Set - up for the ungridded superposition of analytical solutions \n    method for solving flexure of analytical solutions"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges MROs in sequences into a single MRO.", "response": "def _c3_merge(sequences):  # noqa\n    \"\"\"Merges MROs in *sequences* to a single MRO using the C3 algorithm.\n\n    Adapted from http://www.python.org/download/releases/2.3/mro/.\n\n    \"\"\"\n    result = []\n    while True:\n        sequences = [s for s in sequences if s]  # purge empty sequences\n        if not sequences:\n            return result\n        for s1 in sequences:  # find merge candidates among seq heads\n            candidate = s1[0]\n            for s2 in sequences:\n                if candidate in s2[1:]:\n                    candidate = None\n                    break  # reject the current head, it appears later\n            else:\n                break\n        if not candidate:\n            raise RuntimeError(\"Inconsistent hierarchy\")\n        result.append(candidate)\n        # remove the chosen candidate\n        for seq in sequences:\n            if seq[0] == candidate:\n                del seq[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the method resolution order using extended C3 linearization.", "response": "def _c3_mro(cls, abcs=None):\n    \"\"\"Computes the method resolution order using extended C3 linearization.\n\n    If no *abcs* are given, the algorithm works exactly like the built-in C3\n    linearization used for method resolution.\n\n    If given, *abcs* is a list of abstract base classes that should be inserted\n    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the\n    result. The algorithm inserts ABCs where their functionality is introduced,\n    i.e. issubclass(cls, abc) returns True for the class itself but returns\n    False for all its direct base classes. Implicit ABCs for a given class\n    (either registered or inferred from the presence of a special method like\n    __len__) are inserted directly after the last ABC explicitly listed in the\n    MRO of said class. If two implicit ABCs end up next to each other in the\n    resulting MRO, their ordering depends on the order of types in *abcs*.\n\n    \"\"\"\n    for i, base in enumerate(reversed(cls.__bases__)):\n        if hasattr(base, '__abstractmethods__'):\n            boundary = len(cls.__bases__) - i\n            break  # Bases up to the last explicit ABC are considered first.\n    else:\n        boundary = 0\n    abcs = list(abcs) if abcs else []\n    explicit_bases = list(cls.__bases__[:boundary])\n    abstract_bases = []\n    other_bases = list(cls.__bases__[boundary:])\n    for base in abcs:\n        if issubclass(cls, base) and not any(issubclass(b, base) for b in cls.__bases__):\n            # If *cls* is the class that introduces behaviour described by\n            # an ABC *base*, insert said ABC to its MRO.\n            abstract_bases.append(base)\n    for base in abstract_bases:\n        abcs.remove(base)\n    explicit_c3_mros = [_c3_mro(base, abcs=abcs) for base in explicit_bases]\n    abstract_c3_mros = [_c3_mro(base, abcs=abcs) for base in abstract_bases]\n    other_c3_mros = [_c3_mro(base, abcs=abcs) for base in other_bases]\n    return _c3_merge(\n        [[cls]] + explicit_c3_mros + abstract_c3_mros + other_c3_mros + [explicit_bases] + [abstract_bases] + [\n            other_bases])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the method resolution order for a given class cls.", "response": "def _compose_mro(cls, types):  # noqa\n    \"\"\"Calculates the method resolution order for a given class *cls*.\n\n    Includes relevant abstract base classes (with their respective bases) from\n    the *types* iterable. Uses a modified C3 linearization algorithm.\n\n    \"\"\"\n    bases = set(cls.__mro__)\n\n    # Remove entries which are already present in the __mro__ or unrelated.\n    def is_related(_type):\n        return (  # :off\n            _type not in bases and\n            hasattr(_type, '__mro__') and\n            issubclass(cls, _type)\n        )  # :on\n\n    types = [n for n in types if is_related(n)]\n\n    # Remove entries which are strict bases of other entries (they will end up\n    # in the MRO anyway.\n    def is_strict_base(_typ):\n        for other in types:\n            if _typ != other and _typ in other.__mro__:\n                return True\n        return False\n\n    types = [n for n in types if not is_strict_base(n)]\n    # Subclasses of the ABCs in *types* which are also implemented by\n    # *cls* can be used to stabilize ABC ordering.\n    type_set = set(types)\n    mro = []\n    for typ in types:\n        found = []\n        for sub in typ.__subclasses__():\n            if sub not in bases and issubclass(cls, sub):\n                found.append([s for s in sub.__mro__ if s in type_set])\n        if not found:\n            mro.append(typ)\n            continue\n        # Favor subclasses with the biggest number of useful bases\n        found.sort(key=len, reverse=True)\n        for sub in found:\n            for subcls in sub:\n                if subcls not in mro:\n                    mro.append(subcls)\n    return _c3_mro(cls, abcs=mro)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the best matching implementation for the given base class.", "response": "def _find_impl(cls, registry):\n    \"\"\"Returns the best matching implementation from *registry* for type *cls*.\n\n    Where there is no registered implementation for a specific type, its method\n    resolution order is used to find a more generic implementation.\n\n    Note: if *registry* does not contain an implementation for the base\n    *object* type, this function may return None.\n\n    \"\"\"\n    mro = _compose_mro(cls, registry.keys())\n    match = None\n    for t in mro:\n        if match is not None:\n            # If *match* is an implicit ABC but there is another unrelated,\n            # equally matching implicit ABC, refuse the temptation to guess.\n            if (  # :off\n                t in registry and\n                t not in cls.__mro__ and\n                match not in cls.__mro__ and\n                not issubclass(match, t)\n            ):  # :on\n                raise RuntimeError(\"Ambiguous dispatch: {0} or {1}\".format(match, t))\n            break\n        if t in registry:\n            match = t\n    return registry.get(match)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef singledispatch(function):  # noqa\n    registry = {}\n    dispatch_cache = WeakKeyDictionary()\n\n    def ns():\n        pass\n\n    ns.cache_token = None\n\n    # noinspection PyIncorrectDocstring\n    def dispatch(cls):\n        \"\"\"generic_func.dispatch(cls) -> <function implementation>\n\n        Runs the dispatch algorithm to return the best available implementation\n        for the given *cls* registered on *generic_func*.\n\n        \"\"\"\n        if ns.cache_token is not None:\n            current_token = get_cache_token()\n            if ns.cache_token != current_token:\n                dispatch_cache.clear()\n                ns.cache_token = current_token\n        try:\n            impl = dispatch_cache[cls]\n        except KeyError:\n            try:\n                impl = registry[cls]\n            except KeyError:\n                impl = _find_impl(cls, registry)\n            dispatch_cache[cls] = impl\n        return impl\n\n    # noinspection PyIncorrectDocstring\n    def register(cls, func=None):\n        \"\"\"generic_func.register(cls, func) -> func\n\n        Registers a new implementation for the given *cls* on a *generic_func*.\n\n        \"\"\"\n        if func is None:\n            return lambda f: register(cls, f)\n        registry[cls] = func\n        if ns.cache_token is None and hasattr(cls, '__abstractmethods__'):\n            ns.cache_token = get_cache_token()\n        dispatch_cache.clear()\n        return func\n\n    def wrapper(*args, **kw):\n        return dispatch(args[0].__class__)(*args, **kw)\n\n    registry[object] = function\n    wrapper.register = register\n    wrapper.dispatch = dispatch\n    wrapper.registry = MappingProxyType(registry)\n    wrapper._clear_cache = dispatch_cache.clear\n    update_wrapper(wrapper, function)\n    return wrapper", "response": "Single - dispatch generic function decorator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SetClipboardData(type, content):\n\tallocators = {\n\t\tclipboard.CF_TEXT: ctypes.create_string_buffer,\n\t\tclipboard.CF_UNICODETEXT: ctypes.create_unicode_buffer,\n\t\tclipboard.CF_HTML: ctypes.create_string_buffer,\n\t}\n\tif type not in allocators:\n\t\traise NotImplementedError(\n\t\t\t\"Only text and HTML types are supported at this time\")\n\t# allocate the memory for the data\n\tcontent = allocators[type](content)\n\tflags = memory.GMEM_MOVEABLE\n\tsize = ctypes.sizeof(content)\n\thandle_to_copy = windll.kernel32.GlobalAlloc(flags, size)\n\twith LockedMemory(handle_to_copy) as lm:\n\t\tctypes.memmove(lm.data_ptr, content, size)\n\tresult = clipboard.SetClipboardData(type, handle_to_copy)\n\tif result is None:\n\t\traise WindowsError()", "response": "Set the clipboard data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_args(self, args):\n\n        parser = ArgumentParser(description=\"Runs pylint recursively on a directory\")\n\n        parser.add_argument(\n            \"-v\",\n            \"--verbose\",\n            dest=\"verbose\",\n            action=\"store_true\",\n            default=False,\n            help=\"Verbose mode (report which files were found for testing).\",\n        )\n\n        parser.add_argument(\n            \"--rcfile\",\n            dest=\"rcfile\",\n            action=\"store\",\n            default=\".pylintrc\",\n            help=\"A relative or absolute path to your pylint rcfile. Defaults to\\\n                            `.pylintrc` at the current working directory\",\n        )\n\n        parser.add_argument(\n            \"-V\",\n            \"--version\",\n            action=\"version\",\n            version=\"%(prog)s ({0}) for Python {1}\".format(__version__, PYTHON_VERSION),\n        )\n\n        options, _ = parser.parse_known_args(args)\n\n        self.verbose = options.verbose\n\n        if options.rcfile:\n            if not os.path.isfile(options.rcfile):\n                options.rcfile = os.getcwd() + \"/\" + options.rcfile\n            self.rcfile = options.rcfile\n\n        return options", "response": "Parses any supplied command - line args and provides help text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the ignores setting from the pylintrc file if available.", "response": "def _parse_ignores(self):\n        \"\"\" Parse the ignores setting from the pylintrc file if available. \"\"\"\n\n        error_message = (\n            colorama.Fore.RED\n            + \"{} does not appear to be a valid pylintrc file\".format(self.rcfile)\n            + colorama.Fore.RESET\n        )\n\n        if not os.path.isfile(self.rcfile):\n            if not self._is_using_default_rcfile():\n                print(error_message)\n                sys.exit(1)\n            else:\n                return\n\n        config = configparser.ConfigParser()\n        try:\n            config.read(self.rcfile)\n        except configparser.MissingSectionHeaderError:\n            print(error_message)\n            sys.exit(1)\n\n        if config.has_section(\"MASTER\") and config.get(\"MASTER\", \"ignore\"):\n            self.ignore_folders += config.get(\"MASTER\", \"ignore\").split(\",\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_files_from_dir(self, current_dir):\n        if current_dir[-1] != \"/\" and current_dir != \".\":\n            current_dir += \"/\"\n\n        files = []\n\n        for dir_file in os.listdir(current_dir):\n            if current_dir != \".\":\n                file_path = current_dir + dir_file\n            else:\n                file_path = dir_file\n\n            if os.path.isfile(file_path):\n                file_split = os.path.splitext(dir_file)\n                if len(file_split) == 2 and file_split[0] != \"\" \\\n                        and file_split[1] == \".py\":\n                    files.append(file_path)\n            elif (os.path.isdir(dir_file) or os.path.isdir(file_path)) \\\n                    and dir_file not in self.ignore_folders:\n                path = dir_file + os.path.sep\n                if current_dir not in [\"\", \".\"]:\n                    path = os.path.join(current_dir.rstrip(os.path.sep), path)\n                files += self.get_files_from_dir(path)\n        return files", "response": "Recursively walk through a directory and get all python files and return a list of all python files that were found off current_dir"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, output=None, error=None):\n\n        pylint_output = output if output is not None else sys.stdout\n        pylint_error = error if error is not None else sys.stderr\n        savedout, savederr = sys.__stdout__, sys.__stderr__\n        sys.stdout = pylint_output\n        sys.stderr = pylint_error\n\n        pylint_files = self.get_files_from_dir(os.curdir)\n        self._print_line(\n            \"Using pylint \"\n            + colorama.Fore.RED\n            + pylint.__version__\n            + colorama.Fore.RESET\n            + \" for python \"\n            + colorama.Fore.RED\n            + PYTHON_VERSION\n            + colorama.Fore.RESET\n        )\n\n        self._print_line(\"pylint running on the following files:\")\n        for pylint_file in pylint_files:\n            # we need to recast this as a string, else pylint enters an endless recursion\n            split_file = str(pylint_file).split(\"/\")\n            split_file[-1] = colorama.Fore.CYAN + split_file[-1] + colorama.Fore.RESET\n            pylint_file = \"/\".join(split_file)\n            self._print_line(\"- \" + pylint_file)\n        self._print_line(\"----\")\n\n        if not self._is_using_default_rcfile():\n            self.args += [\"--rcfile={}\".format(self.rcfile)]\n\n        exit_kwarg = {\"do_exit\": False}\n\n        run = pylint.lint.Run(self.args + pylint_files, **exit_kwarg)\n        sys.stdout = savedout\n        sys.stderr = savederr\n\n        sys.exit(run.linter.msg_status)", "response": "Runs pylint on all python files in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strict(*types):\n\n    def decorate(func):\n        @wraps(func)\n        def wrapper(self, p):\n            func(self, p)\n            if not isinstance(p[0], types):\n                raise YAMLStrictTypeError(p[0], types, func)\n\n        wrapper.co_firstlineno = func.__code__.co_firstlineno\n        return wrapper\n\n    return decorate", "response": "Decorator to check that a function is a type check production rule output."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_column(t):\n    pos = t.lexer.lexpos\n    data = t.lexer.lexdata\n    last_cr = data.rfind('\\n', 0, pos)\n    if last_cr < 0:\n        last_cr = -1\n    column = pos - last_cr\n    return column", "response": "Get cursor position based on previous newline"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a custom request to the HS", "response": "def custom(self, payload):\r\n        \"\"\"\r\n\r\n        :param payload:\r\n            a key/value object containing the scimeta you want to store\r\n            e.g. {\"weather\": \"sunny\", \"temperature\": \"80C\" }\r\n        :return:\r\n            empty (200 status code)\r\n        \"\"\"\r\n        url = \"{url_base}/resource/{pid}/scimeta/custom/\".format(url_base=self.hs.url_base,\r\n                                                                 pid=self.pid)\r\n        r = self.hs._request('POST', url, data=payload)\r\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self):\r\n        url = \"{url_base}/resource/{pid}/scimeta/custom/\".format(url_base=self.hs.url_base,\r\n                                                                 pid=self.pid)\r\n        r = self.hs._request('GET', url)\r\n        return json.loads(r.text)", "response": "Returns a list of all the keys in the scimeta resource that are in the same order as the original."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all the file objects in the resource.", "response": "def all(self):\r\n        \"\"\"\r\n        :return:\r\n            array of file objects (200 status code)\r\n        \"\"\"\r\n        url = \"{url_base}/resource/{pid}/files/\".format(url_base=self.hs.url_base,\r\n                                                                 pid=self.pid)\r\n        r = self.hs._request('GET', url)\r\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the metadata for a single file.", "response": "def metadata(self, file_path, params=None):\r\n        \"\"\"\r\n        :params:\r\n            title: string\r\n            keywords: array\r\n            extra_metadata: array\r\n            temporal_coverage: coverage object\r\n            spatial_coverage: coverage object\r\n\r\n        :return:\r\n            file metadata object (200 status code)\r\n        \"\"\"\r\n\r\n        url_base = self.hs.url_base\r\n        url = \"{url_base}/resource/{pid}/files/metadata/{file_path}/\".format(url_base=url_base,\r\n                                                                            pid=self.pid,\r\n                                                                            file_path=file_path)\r\n\r\n        if params is None:\r\n            r = self.hs._request('GET', url)\r\n        else:\r\n            headers = {}\r\n            headers[\"Content-Type\"] = \"application/json\"\r\n            r = self.hs._request(\"PUT\", url, data=json.dumps(params), headers=headers)\r\n\r\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unzip(self, payload):\r\n        zip_with_rel_path = payload.pop('zip_with_rel_path')\r\n\r\n        url = \"{url_base}/resource/{pid}/functions/unzip/{path}/\".format(\r\n            url_base=self.hs.url_base,\r\n            path=zip_with_rel_path,\r\n            pid=self.pid)\r\n        r = self.hs._request('POST', url, None, payload)\r\n        return r", "response": "Unzips a file\r\n\r\n        :param payload:\r\n            zip_with_rel_path: string\r\n            remove_original_zip: boolean\r\n        :return: (object)\r\n            unzipped_path: string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_file_type(self, payload):\r\n        file_path = payload.pop('file_path')\r\n        hs_file_type = payload.pop('hs_file_type')\r\n\r\n        url = \"{url_base}/resource/{pid}/functions/set-file-type/{file_path}/{file_type}/\".format(\r\n            url_base=self.hs.url_base,\r\n            pid=self.pid,\r\n            file_path=file_path,\r\n            file_type=hs_file_type)\r\n        r = self.hs._request('POST', url, None, payload)\r\n        return r", "response": "Set a file to a specific HydroShare file type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flag(self, payload):\r\n        url = \"{url_base}/resource/{pid}/flag/\".format(url_base=self.hs.url_base,\r\n                                                       pid=self.pid)\r\n\r\n        r = self.hs._request('POST', url, None, payload)\r\n        return r", "response": "Set a single flag on a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload a file to a hydroshare resource.", "response": "def files(self, payload):\r\n        \"\"\"Upload a file to a hydroshare resource.\r\n\r\n        :param payload:\r\n            file: File object to upload to server\r\n            folder: folder path to upload the file to\r\n        :return: json object\r\n            resource_id: string resource id,\r\n            file_name: string name of file\r\n        \"\"\"\r\n        url = \"{url_base}/resource/{pid}/files/\".format(url_base=self.hs.url_base,\r\n                                                       pid=self.pid)\r\n\r\n        encoder = MultipartEncoder({\r\n            \"file\": (payload['file'], open(payload['file'], 'r')),\r\n            \"folder\": payload['folder']\r\n        })\r\n        monitor = MultipartEncoderMonitor(encoder, default_progress_callback)\r\n\r\n        r = self.hs._request('POST', url, None, data=monitor, headers={'Content-Type': monitor.content_type})\r\n        return r.text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npassing through helper function for flag function.", "response": "def public(self, boolean):\r\n        \"\"\"Pass through helper function for flag function.\"\"\"\r\n        if(boolean):\r\n            r = self.flag({\r\n                \"flag\": \"make_public\"\r\n            })\r\n        else:\r\n            r = self.flag({\r\n                \"flag\": \"make_private\"\r\n            })\r\n\r\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discoverable(self, boolean):\r\n        if(boolean):\r\n            r = self.flag({\r\n                \"flag\": \"make_discoverable\"\r\n            })\r\n        else:\r\n            r = self.flag({\r\n                \"flag\": \"make_not_discoverable\"\r\n            })\r\n\r\n        return r", "response": "Pass through helper function for flag function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shareable(self, boolean):\r\n        if(boolean):\r\n            r = self.flag({\r\n                \"flag\": \"make_shareable\"\r\n            })\r\n        else:\r\n            r = self.flag({\r\n                \"flag\": \"make_not_shareable\"\r\n            })\r\n\r\n        return r", "response": "Pass through helper function for flag function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls update and set up selfoss.", "response": "def selfoss(reset_password=False):\n    '''Install, update and set up selfoss.\n\n    This selfoss installation uses sqlite (selfoss-default), php5-fpm and nginx.\n\n    The connection is https-only and secured by a letsencrypt certificate.  This\n    certificate must be created separately with task setup.server_letsencrypt.\n\n    More infos:\n      https://selfoss.aditu.de/\n      https://github.com/SSilence/selfoss/wiki\n      https://www.heise.de/ct/ausgabe/2016-13-RSS-Reader-Selfoss-hat-die-Nachrichtenlage-im-Blick-3228045.html\n      https://ct.de/yqp7\n    '''\n    hostname = re.sub(r'^[^@]+@', '', env.host)  # without username if any\n    sitename = query_input(\n                   question='\\nEnter site-name of Your trac web service',\n                   default=flo('selfoss.{hostname}'))\n    username = env.user\n\n    site_dir = flo('/home/{username}/sites/{sitename}')\n\n    checkout_latest_release_of_selfoss()\n    create_directory_structure(site_dir)\n\n    restored = install_selfoss(sitename, site_dir, username)\n\n    nginx_site_config(username, sitename, hostname)\n    enable_php5_socket_file()\n\n    if not restored or reset_password:\n        setup_selfoss_user(username, sitename, site_dir)\n\n    print_msg('\\n## reload nginx and restart php\\n')\n    run('sudo service nginx reload')\n    run('sudo service php5-fpm restart')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a json file from the cache", "response": "def read(filename='cache'):\n\t\"\"\"\n\tparameter: file_path - path to cache file\n\treturn: data after parsing json file\"\"\"\n\tcache_path = get_cache_path(filename)\n\tif not os.path.exists(cache_path) or os.stat(cache_path).st_size == 0:\n\t\treturn None\n\twith open(cache_path, 'r') as file:\n\t\treturn json.load(file)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite data to cache file", "response": "def write(content, filename='cache'):\n\t\"\"\" write data to cache file\n\tparameters:\n\t\tcache_path - path to cache file\n\t\tcontent - a data structure to save into cache file\"\"\"\n\tcache_path = get_cache_path(filename)\n\twith open(cache_path, 'w') as file:\n\t\tif content is not None:\n\t\t\tjson.dump(content, file, indent=3, sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_security_attributes_for_user(user=None):\n\tif user is None:\n\t\tuser = get_current_user()\n\n\tassert isinstance(user, security.TOKEN_USER), (\n\t\t\"user must be TOKEN_USER instance\")\n\n\tSD = security.SECURITY_DESCRIPTOR()\n\tSA = security.SECURITY_ATTRIBUTES()\n\t# by attaching the actual security descriptor, it will be garbage-\n\t# collected with the security attributes\n\tSA.descriptor = SD\n\tSA.bInheritHandle = 1\n\n\tctypes.windll.advapi32.InitializeSecurityDescriptor(\n\t\tctypes.byref(SD),\n\t\tsecurity.SECURITY_DESCRIPTOR.REVISION)\n\tctypes.windll.advapi32.SetSecurityDescriptorOwner(\n\t\tctypes.byref(SD),\n\t\tuser.SID, 0)\n\treturn SA", "response": "Returns a SECURITY_ATTRIBUTES structure with the SID set to the\n\tspecified user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the current process token", "response": "def get_process_token():\n\t\"\"\"\n\tGet the current process token\n\t\"\"\"\n\ttoken = wintypes.HANDLE()\n\tres = process.OpenProcessToken(\n\t\tprocess.GetCurrentProcess(), process.TOKEN_ALL_ACCESS, token)\n\tif not res > 0:\n\t\traise RuntimeError(\"Couldn't get process token\")\n\treturn token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the LUID for the SeCreateSymbolicLinkPrivilege and raise a RuntimeError if the privilege value is not found", "response": "def get_symlink_luid():\n\t\"\"\"\n\tGet the LUID for the SeCreateSymbolicLinkPrivilege\n\t\"\"\"\n\tsymlink_luid = privilege.LUID()\n\tres = privilege.LookupPrivilegeValue(\n\t\tNone, \"SeCreateSymbolicLinkPrivilege\", symlink_luid)\n\tif not res > 0:\n\t\traise RuntimeError(\"Couldn't lookup privilege value\")\n\treturn symlink_luid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_privilege_information():\n\t# first call with zero length to determine what size buffer we need\n\n\treturn_length = wintypes.DWORD()\n\tparams = [\n\t\tget_process_token(),\n\t\tprivilege.TOKEN_INFORMATION_CLASS.TokenPrivileges,\n\t\tNone,\n\t\t0,\n\t\treturn_length,\n\t]\n\n\tres = privilege.GetTokenInformation(*params)\n\n\t# assume we now have the necessary length in return_length\n\n\tbuffer = ctypes.create_string_buffer(return_length.value)\n\tparams[2] = buffer\n\tparams[3] = return_length.value\n\n\tres = privilege.GetTokenInformation(*params)\n\tassert res > 0, \"Error in second GetTokenInformation (%d)\" % res\n\n\tprivileges = ctypes.cast(\n\t\tbuffer, ctypes.POINTER(privilege.TOKEN_PRIVILEGES)).contents\n\treturn privileges", "response": "Get all privileges associated with the current process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to assign the symlink privilege to the current process token. Return True if the assignment is successful.", "response": "def enable_symlink_privilege():\n\t\"\"\"\n\tTry to assign the symlink privilege to the current process token.\n\tReturn True if the assignment is successful.\n\t\"\"\"\n\t# create a space in memory for a TOKEN_PRIVILEGES structure\n\t#  with one element\n\tsize = ctypes.sizeof(privilege.TOKEN_PRIVILEGES)\n\tsize += ctypes.sizeof(privilege.LUID_AND_ATTRIBUTES)\n\tbuffer = ctypes.create_string_buffer(size)\n\ttp = ctypes.cast(buffer, ctypes.POINTER(privilege.TOKEN_PRIVILEGES)).contents\n\ttp.count = 1\n\ttp.get_array()[0].enable()\n\ttp.get_array()[0].LUID = get_symlink_luid()\n\ttoken = get_process_token()\n\tres = privilege.AdjustTokenPrivileges(token, False, tp, 0, None, None)\n\tif res == 0:\n\t\traise RuntimeError(\"Error in AdjustTokenPrivileges\")\n\n\tERROR_NOT_ALL_ASSIGNED = 1300\n\treturn ctypes.windll.kernel32.GetLastError() != ERROR_NOT_ALL_ASSIGNED"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngrant the create symlink privilege to who.", "response": "def grant_symlink_privilege(who, machine=''):\n\t\"\"\"\n\tGrant the 'create symlink' privilege to who.\n\n\tBased on http://support.microsoft.com/kb/132958\n\t\"\"\"\n\tflags = security.POLICY_CREATE_ACCOUNT | security.POLICY_LOOKUP_NAMES\n\tpolicy = OpenPolicy(machine, flags)\n\treturn policy"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a base - module or a sub - module from the dict addon_modules given by module_name.", "response": "def get_or_create_module_r(module_name, base_module=None):\n    '''Return a base-module (e.g. 'theno') or a sub-module (e.g.\n    'theno.service.raccoon') from the dict addon_modules given by param\n    'module_name'.\n\n    If the highest module (e.g. 'theno') not exists, an empty module will be\n    created.  This will be continued recursively until the lowest sub-module\n    exists which will be returned\n\n    Param 'base_module' is used for recursion only.\n    '''\n    module_names = module_name.split('.', 1)\n    if len(module_names) > 1:\n        # e.g. ['theno', 'service.wallabag']\n        highest_module_name, module_name_rest = module_names\n        highest_module = get_or_create_module_r(highest_module_name,\n                                                base_module)\n        if base_module:\n            # anchor highest_module to its direct base-module\n            base_module.__dict__[highest_module_name] = highest_module\n        return get_or_create_module_r(module_name_rest,\n                                      base_module=highest_module)\n    else:  # len(module_names) == 0\n        # module name does not contain any '.', e.g.: 'service'\n        module = addon_modules.setdefault(module_name,\n                                          imp.new_module(module_name))\n        if base_module:\n            # anchor module to its direct base-module\n            base_module.__dict__[module_name] = module\n        return module"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads an addon given by package_name and hook it in the base task namespace username.", "response": "def load_addon(username, package_name, _globals):\n    '''Load an fabsetup addon given by 'package_name' and hook it in the\n    base task namespace 'username'.\n\n    Args:\n        username(str)\n        package_name(str)\n        _globals(dict): the globals() namespace of the fabric script.\n\n    Return: None\n    '''\n    addon_module = get_or_create_module_r(username)\n    package_module = __import__(package_name)\n    add_tasks_r(addon_module, package_module, package_name)\n    _globals.update({username: addon_module})\n    del package_module\n    del addon_module"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload all known fabsetup addons which are installed as pypi pip - packages.", "response": "def load_pip_addons(_globals):\n    '''Load all known fabsetup addons which are installed as pypi pip-packages.\n\n    Args:\n        _globals(dict): the globals() namespace of the fabric script.\n\n    Return: None\n    '''\n    for package_name in known_pip_addons:\n        _, username = package_username(package_name)\n        try:\n            load_addon(username, package_name.replace('-', '_'), _globals)\n        except ImportError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef package_username(repo):\n    '''\n        >>> package_user('fabsetup-theno-termdown')\n        (termdown, theno)\n\n    '''\n    package = repo.replace('-', '_')\n    username = repo.split('-')[1]\n    return package, username", "response": "Return package and username for a given repo."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_repo_addons(_globals):\n    '''Load all fabsetup addons which are stored under ~/.fabsetup-addon-repos\n    as git repositories.\n\n    Args:\n        _globals(dict): the globals() namespace of the fabric script.\n\n    Return: None\n    '''\n    repos_dir = os.path.expanduser('~/.fabsetup-addon-repos')\n    if os.path.isdir(repos_dir):\n        basedir, repos, _ = next(os.walk(repos_dir))\n        for repo_dir in [os.path.join(basedir, repo)\n                         for repo in repos\n                         # omit dot dirs like '.rope'\n                         # or 'fabsetup-theno-termdown.disabled'\n                         if '.' not in repo]:\n            sys.path.append(repo_dir)\n            package_name, username = package_username(repo_dir.split('/')[-1])\n            load_addon(username, package_name, _globals)", "response": "Load all fabsetup addons which are stored under ~/.fabsetup - addon - repos as git repositories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nputting custom commands at ~ / bin /", "response": "def users_bin_dir():\n    '''Put custom commands at '~/bin/'\n\n    For the conversion of diagrams into the pdf format:\n    * dia2pdf, ep2svg, svg2pdf\n    * alldia2pdf, allep2svg, alldia2pdf\n    '''\n    # circumvent circular import, cf. http://stackoverflow.com/a/18486863\n    from fabfile.setup import pencil2\n    pencil2() # used by ~/bin/ep2svg\n    install_packages([\n        'dia',\n        'inkscape', # used by ~/bin/svg2pdf\n        'xsltproc', # used by ~/bin/ep2svg\n    ])\n    commands = [\n        'alldia2pdf',\n        'allep2svg',\n        'allepgz2ep',\n        'allsvg2pdf',\n        'dia2pdf',\n        'ep2svg',\n        'epgz2ep',\n        'greypdf',\n        'svg2pdf'\n    ]\n    for command in commands:\n        install_user_command_legacy(command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_ignore_INDENT(self, t):\n        r'\\n\\s*'\n\n        indent_status, curr_depth, next_depth = self.get_indent_status(t)\n\n        if indent_status == 'NODENT':\n            return\n\n        if indent_status == 'INDENT':\n            # note: also set by\n            #   * t_B_SEQUENCE_COMPACT_START\n            #   * t_B_MAP_COMPACT_KEY\n            #   * t_B_MAP_COMPACT_VALUE\n            self.indent_stack.append(next_depth)\n\n        if indent_status == 'DEDENT':\n            indent_delta = curr_depth - next_depth\n            step = self.indent_stack.pop() - self.indent_stack[-1]\n\n            # If dedent is larger then last indent\n            if indent_delta > step:\n                # Go back and reevaluate this token.\n                rollback_lexpos(t)\n\n        t.type = indent_status\n        return t", "response": "Ignore the indentation status of a token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_begin_singlequote(self, t):\n        r\"(?<!\\\\)'\"\n        t.lexer.push_state('singlequote')\n        # t.lexer.begin('singlequote')\n        t.type = 'CAST_TYPE'\n        t.type = 'SINGLEQUOTE_START'\n        return t", "response": "t_begin_singlequote - Starts a singlequote"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the science metadata for a resource in XML + RDF format.", "response": "def getScienceMetadataRDF(self, pid):\n        \"\"\" Get science metadata for a resource in XML+RDF format\n\n        :param pid: The HydroShare ID of the resource\n        :raises: HydroShareNotAuthorized if the user is not authorized to view the metadata.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException to signal an HTTP error.\n        :return: A string representing the XML+RDF serialization of science metadata.\n        Example of data XML+RDF returned:\n\n        <?xml version=\"1.0\"?>\n        <!DOCTYPE rdf:RDF PUBLIC \"-//DUBLIN CORE//DCMES DTD 2002/07/31//EN\"\n        \"http://dublincore.org/documents/2002/07/31/dcmes-xml/dcmes-xml-dtd.dtd\">\n        <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:hsterms=\"http://hydroshare.org/terms/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1=\"http://www.w3.org/2001/01/rdf-schema#\">\n          <rdf:Description rdf:about=\"http://www.hydroshare.org/resource/87ffb608900e407ab4b67d30c93b329e\">\n            <dc:title>Great Salt Lake Level and Volume</dc:title>\n            <dc:type rdf:resource=\"http://www.hydroshare.org/terms/GenericResource\"/>\n            <dc:description>\n              <rdf:Description>\n                <dcterms:abstract>Time series of level, area and volume in the Great Salt Lake. Volume and area of the Great Salt Lake are derived from recorded levels</dcterms:abstract>\n              </rdf:Description>\n            </dc:description>\n            <hsterms:awardInfo>\n              <rdf:Description rdf:about=\"http://www.nsf.gov\">\n                <hsterms:fundingAgencyName>National Science Foundation</hsterms:fundingAgencyName>\n                <hsterms:awardTitle>Model Execution Cyberinfrastructure </hsterms:awardTitle>\n                <hsterms:awardNumber>NSF_9087658_2017</hsterms:awardNumber>\n              </rdf:Description>\n            </hsterms:awardInfo>\n            <dc:creator>\n              <rdf:Description>\n                <hsterms:name>John Smith</hsterms:name>\n                <hsterms:creatorOrder>1</hsterms:creatorOrder>\n                <hsterms:organization>Utah State University</hsterms:organization>\n                <hsterms:email>john.smith@gmail.com</hsterms:email>\n                <hsterms:address>Engineering Building, USU, Logan, Utah</hsterms:address>\n                <hsterms:phone rdf:resource=\"tel:435-797-8967\"/>\n              </rdf:Description>\n            </dc:creator>\n            <dc:creator>\n              <rdf:Description>\n                <hsterms:name>Lisa Miller</hsterms:name>\n                <hsterms:creatorOrder>2</hsterms:creatorOrder>\n              </rdf:Description>\n            </dc:creator>\n            <dc:contributor>\n              <rdf:Description>\n                <hsterms:name>Jenny Parker</hsterms:name>\n                <hsterms:organization>Univesity of Utah</hsterms:organization>\n                <hsterms:email>jenny_parker@hotmail.com</hsterms:email>\n              </rdf:Description>\n            </dc:contributor>\n            <dc:coverage>\n              <dcterms:period>\n                <rdf:value>start=2000-01-01T00:00:00; end=2010-12-12T00:00:00; scheme=W3C-DTF</rdf:value>\n              </dcterms:period>\n            </dc:coverage>\n            <dc:date>\n              <dcterms:created>\n                <rdf:value>2017-01-03T17:06:18.932217+00:00</rdf:value>\n              </dcterms:created>\n            </dc:date>\n            <dc:date>\n              <dcterms:modified>\n                <rdf:value>2017-01-03T17:35:34.067279+00:00</rdf:value>\n              </dcterms:modified>\n            </dc:date>\n            <dc:format>image/tiff</dc:format>\n            <dc:identifier>\n              <rdf:Description>\n                <hsterms:hydroShareIdentifier>http://www.hydroshare.org/resource/87ffb608900e407ab4b67d30c93b329e</hsterms:hydroShareIdentifier>\n              </rdf:Description>\n            </dc:identifier>\n            <dc:language>eng</dc:language>\n            <dc:rights>\n              <rdf:Description>\n                <hsterms:rightsStatement>This resource is shared under the Creative Commons Attribution CC BY.</hsterms:rightsStatement>\n                <hsterms:URL rdf:resource=\"http://creativecommons.org/licenses/by/4.0/\"/>\n              </rdf:Description>\n            </dc:rights>\n            <dc:subject>NSF</dc:subject>\n            <dc:subject>Model</dc:subject>\n            <dc:subject>Cyberinfrastructure</dc:subject>\n            <hsterms:extendedMetadata>\n              <rdf:Description>\n                <hsterms:key>model</hsterms:key>\n                <hsterms:value>ueb</hsterms:value>\n              </rdf:Description>\n            </hsterms:extendedMetadata>\n            <hsterms:extendedMetadata>\n              <rdf:Description>\n                <hsterms:key>os</hsterms:key>\n                <hsterms:value>windows</hsterms:value>\n              </rdf:Description>\n            </hsterms:extendedMetadata>\n          </rdf:Description>\n          <rdf:Description rdf:about=\"http://www.hydroshare.org/terms/GenericResource\">\n            <rdfs1:label>Generic</rdfs1:label>\n            <rdfs1:isDefinedBy>http://www.hydroshare.org/terms</rdfs1:isDefinedBy>\n          </rdf:Description>\n        </rdf:RDF>\n        \"\"\"\n\n        url = \"{url_base}/scimeta/{pid}/\".format(url_base=self.url_base, pid=pid)\n        r = self._request('GET', url)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('GET', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        return str(r.content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getResource(self, pid, destination=None, unzip=False, wait_for_bag_creation=True):\n        stream = self._getBagStream(pid, wait_for_bag_creation)\n        if destination:\n            self._storeBagOnFilesystem(stream, pid, destination, unzip)\n            return None\n        else:\n            return stream", "response": "Get a resource in BagIt format and store it in a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getResourceTypes(self):\n        url = \"{url_base}/resource/types\".format(url_base=self.url_base)\n\n        r = self._request('GET', url)\n        if r.status_code != 200:\n            raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        resource_types = r.json()\n        return set([t['resource_type'] for t in resource_types])", "response": "Get the list of resource types supported by the HydroShare server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new resource in HydroShare.", "response": "def createResource(self, resource_type, title, resource_file=None, resource_filename=None,\n                       abstract=None, keywords=None,\n                       edit_users=None, view_users=None, edit_groups=None, view_groups=None,\n                       metadata=None, extra_metadata=None, progress_callback=None):\n        \"\"\" Create a new resource.\n\n        :param resource_type: string representing the a HydroShare resource type recognized by this\n            server.\n        :param title: string representing the title of the new resource\n        :param resource_file: a read-only binary file-like object (i.e. opened with the flag 'rb') or a string\n            representing path to file to be uploaded as part of the new resource\n        :param resource_filename: string representing the filename of the resource file.  Must be specified\n            if resource_file is a file-like object.  If resource_file is a string representing a valid file path,\n            and resource_filename is not specified, resource_filename will be equal to os.path.basename(resource_file).\n            is a string\n        :param abstract: string representing abstract of resource\n        :param keywords: list of strings representing keywords to associate with the resource\n        :param edit_users: list of HydroShare usernames who will be given edit permissions\n        :param view_users: list of HydroShare usernames who will be given view permissions\n        :param edit_groups: list of HydroShare group names that will be given edit permissions\n        :param view_groups: list of HydroShare group names that will be given view permissions\n        :param metadata: json string data for each of the metadata elements\n        :param extra_metadata: json string data for key/value pair metadata elements defined by user\n        :param progress_callback: user-defined function to provide feedback to the user about the progress\n            of the upload of resource_file.  For more information, see:\n            http://toolbelt.readthedocs.org/en/latest/uploading-data.html#monitoring-your-streaming-multipart-upload\n\n        :return: string representing ID of newly created resource.\n\n        :raises: HydroShareArgumentException if any parameters are invalid.\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n\n        \"\"\"\n        url = \"{url_base}/resource/\".format(url_base=self.url_base)\n\n        close_fd = False\n\n        if resource_type not in self.resource_types:\n            raise HydroShareArgumentException(\"Resource type {0} is not among known resources: {1}\".format(resource_type,\n                                                                                                           \", \".join([r for r in self.resource_types])))\n\n        # Prepare request\n        params = {'resource_type': resource_type, 'title': title}\n        if abstract:\n            params['abstract'] = abstract\n        if keywords:\n            # Put keywords in a format that django-rest's serializer will understand\n            for (i, kw) in enumerate(keywords):\n                key = \"keywords[{index}]\".format(index=i)\n                params[key] = kw\n        if edit_users:\n            params['edit_users'] = edit_users\n        if view_users:\n            params['view_users'] = view_users\n        if edit_groups:\n            params['edit_groups'] = edit_groups\n        if view_groups:\n            params['view_groups'] = view_groups\n\n        if metadata:\n            params['metadata'] = metadata\n\n        if extra_metadata:\n            params['extra_metadata'] = extra_metadata\n\n        if resource_file:\n            close_fd = self._prepareFileForUpload(params, resource_file, resource_filename)\n\n        encoder = MultipartEncoder(params)\n        if progress_callback is None:\n            progress_callback = default_progress_callback\n        monitor = MultipartEncoderMonitor(encoder, progress_callback)\n\n        r = self._request('POST', url, data=monitor, headers={'Content-Type': monitor.content_type})\n\n        if close_fd:\n            fd = params['file'][1]\n            fd.close()\n\n        if r.status_code != 201:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('POST', url))\n            else:\n                raise HydroShareHTTPException((url, 'POST', r.status_code, params))\n\n        response = r.json()\n        new_resource_id = response['resource_id']\n\n        return new_resource_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deleteResource(self, pid):\n        url = \"{url_base}/resource/{pid}/\".format(url_base=self.url_base,\n                                                  pid=pid)\n\n        r = self._request('DELETE', url)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('DELETE', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'DELETE', r.status_code))\n\n        resource = r.json()\n        assert(resource['resource_id'] == pid)\n        return resource['resource_id']", "response": "Delete a resource.\n\n        :param pid: The HydroShare ID of the resource"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setAccessRules(self, pid, public=False):\n        url = \"{url_base}/resource/accessRules/{pid}/\".format(url_base=self.url_base,\n                                                              pid=pid)\n        params = {'public': public}\n\n        r = self._request('PUT', url, data=params)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('PUT', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'PUT', r.status_code, params))\n\n        resource = r.json()\n        assert(resource['resource_id'] == pid)\n        return resource['resource_id']", "response": "Set the access rules for a resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new file to an existing resource.", "response": "def addResourceFile(self, pid, resource_file, resource_filename=None, progress_callback=None):\n        \"\"\" Add a new file to an existing resource\n\n        :param pid: The HydroShare ID of the resource\n        :param resource_file: a read-only binary file-like object (i.e. opened with the flag 'rb') or a string\n            representing path to file to be uploaded as part of the new resource\n        :param resource_filename: string representing the filename of the resource file.  Must be specified\n            if resource_file is a file-like object.  If resource_file is a string representing a valid file path,\n            and resource_filename is not specified, resource_filename will be equal to os.path.basename(resource_file).\n            is a string\n        :param progress_callback: user-defined function to provide feedback to the user about the progress\n            of the upload of resource_file.  For more information, see:\n            http://toolbelt.readthedocs.org/en/latest/uploading-data.html#monitoring-your-streaming-multipart-upload\n\n        :return: Dictionary containing 'resource_id' the ID of the resource to which the file was added, and\n                'file_name' the filename of the file added.\n\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/\".format(url_base=self.url_base,\n                                                        pid=pid)\n\n        params = {}\n        close_fd = self._prepareFileForUpload(params, resource_file, resource_filename)\n\n        encoder = MultipartEncoder(params)\n        if progress_callback is None:\n            progress_callback = default_progress_callback\n        monitor = MultipartEncoderMonitor(encoder, progress_callback)\n\n        r = self._request('POST', url, data=monitor, headers={'Content-Type': monitor.content_type})\n\n        if close_fd:\n            fd = params['file'][1]\n            fd.close()\n\n        if r.status_code != 201:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('POST', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'POST', r.status_code))\n\n        response = r.json()\n        # assert(response['resource_id'] == pid)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a file within a resource.", "response": "def getResourceFile(self, pid, filename, destination=None):\n        \"\"\" Get a file within a resource.\n\n        :param pid: The HydroShare ID of the resource\n        :param filename: String representing the name of the resource file to get.\n        :param destination: String representing the directory to save the resource file to. If None, a stream\n            to the resource file will be returned instead.\n        :return: The path of the downloaded file (if destination was specified), or a stream to the resource\n            file.\n\n        :raises: HydroShareArgumentException if any parameters are invalid.\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/{filename}\".format(url_base=self.url_base,\n                                                                  pid=pid,\n                                                                  filename=filename)\n\n        if destination:\n            if not os.path.isdir(destination):\n                raise HydroShareArgumentException(\"{0} is not a directory.\".format(destination))\n            if not os.access(destination, os.W_OK):\n                raise HydroShareArgumentException(\"You do not have write permissions to directory '{0}'.\".format(destination))\n\n        r = self._request('GET', url, stream=True)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('GET', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid, filename))\n            else:\n                raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        if destination is None:\n            return r.iter_content(STREAM_CHUNK_SIZE)\n        else:\n            filepath = os.path.join(destination, filename)\n            with open(filepath, 'wb') as fd:\n                for chunk in r.iter_content(STREAM_CHUNK_SIZE):\n                    fd.write(chunk)\n            return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a resource file from HydroShare.", "response": "def deleteResourceFile(self, pid, filename):\n        \"\"\"\n        Delete a resource file\n\n        :param pid: The HydroShare ID of the resource\n        :param filename: String representing the name of the resource file to delete\n\n        :return: Dictionary containing 'resource_id' the ID of the resource from which the file was deleted, and\n            'file_name' the filename of the file deleted.\n\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource or resource file was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n        \"\"\"\n        url = \"{url_base}/resource/{pid}/files/{filename}\".format(url_base=self.url_base,\n                                                                  pid=pid,\n                                                                  filename=filename)\n\n        r = self._request('DELETE', url)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('DELETE', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid, filename))\n            else:\n                raise HydroShareHTTPException((url, 'DELETE', r.status_code))\n\n        response = r.json()\n        assert(response['resource_id'] == pid)\n        return response['resource_id']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getResourceFileList(self, pid):\n        url = \"{url_base}/resource/{pid}/files/\".format(url_base=self.url_base,\n                                                            pid=pid)\n        return resultsListGenerator(self, url)", "response": "Returns a generator that returns a list of files within a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a listing of files and folders for a resource at the specified path.", "response": "def getResourceFolderContents(self, pid, pathname):\n        \"\"\" Get a listing of files and folders for a resource at the specified path (*pathname*)\n\n        :param pid: The HydroShare ID of the resource whose folder contents to be listed\n        :param pathname: Folder path for which contents (files and folders) need to be listed\n        :return: A JSON object representing the contents of the specified folder\n\n        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n        :raises: HydroShareNotFound if the resource or resource file was not found.\n        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n\n        Example of JSON data returned:\n        {\n            \"resource_id\": \"32a08bc23a86e471282a832143491b49\",\n            \"path\": \"model/initial\",\n            \"files\": [\"model.exe\", \"param.txt\"],\n            \"folders\": [\"run/1\", \"run/2\"]\n        }\n        \"\"\"\n\n        url = \"{url_base}/resource/{pid}/folders/{path}\".format(url_base=self.url_base, pid=pid, path=pathname)\n\n        r = self._request('GET', url)\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('GET', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a Referenced Content File.", "response": "def createReferenceURL(self, pid, name, ref_url, path=\"\", validate=True):\n        \"\"\"Create a Referenced Content File (.url)\n                        :param pid: The HydroShare ID of the resource for which the file should be created\n                        :param name: Filename for the referenced file\n                        :param ref_url: url to be used in the referenced file\n                        :param path: Optional, defaults to contents directory if not provided.  Folder path for the file to be created in\n                        :return: JsonResponse on success or HttpResponse with error status code on error\n\n                        :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n                        :raises: HydroShareNotFound if the resource or resource file was not found.\n                        :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered.\n                        \"\"\"\n        return self.createReferencedFile(pid, path, name, ref_url, validate)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updateReferenceURL(self, pid, name, ref_url, path=\"\"):\n        return self.updateReferencedFile(pid, path, name, ref_url)", "response": "Update a Referenced Content File."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef updateReferencedFile(self, pid, path, name, ref_url):\n\n        url = \"{url_base}/resource/data_store_edit_reference_url/\".format(url_base=self.url_base)\n\n        data = {'res_id': pid, 'curr_path': path, 'url_filename': name, 'new_ref_url': ref_url}\n\n        r = self._request('POST', url, data=data)\n\n        if r.status_code != 200:\n            if r.status_code == 403:\n                raise HydroShareNotAuthorized(('POST', url))\n            elif r.status_code == 404:\n                raise HydroShareNotFound((pid,))\n            else:\n                raise HydroShareHTTPException((url, 'POST', r.status_code))\n\n        return r.json()", "response": "Deprecated, use updateReferenceURL. Update a Referenced Content File (.url)\n\n                :param pid: The HydroShare ID of the resource for which the file should be updated\n                :param path: Folder path for the file to be updated in\n                :param name: Filename for the referenced file\n                :param ref_url: url to be updated in the referenced file\n                :return: JsonResponse on success or HttpResponse with error status code on error\n\n                :raises: HydroShareNotAuthorized if user is not authorized to perform action.\n                :raises: HydroShareNotFound if the resource or resource file was not found.\n                :raises: HydroShareHTTPException if an unexpected HTTP response code is encountered."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the GET / hsapi / userInfo / REST end point of the HydroShare server.", "response": "def getUserInfo(self):\n        \"\"\"\n        Query the GET /hsapi/userInfo/ REST end point of the HydroShare server.\n\n        :raises: HydroShareHTTPException to signal an HTTP error\n\n        :return: A JSON object representing user info, for example:\n\n        {\n            \"username\": \"username\",\n            \"first_name\": \"First\",\n            \"last_name\": \"Last\",\n            \"email\": \"user@domain.com\"\n        }\n        \"\"\"\n        url = \"{url_base}/userInfo/\".format(url_base=self.url_base)\n\n        r = self._request('GET', url)\n        if r.status_code != 200:\n            raise HydroShareHTTPException((url, 'GET', r.status_code))\n\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ssm_parameter(parameter_name):\n    '''\n    Get the decrypted value of an SSM parameter\n\n    Args:\n        parameter_name - the name of the stored parameter of interest\n\n    Return:\n        Value if allowed and present else None\n    '''\n    try:\n        response = boto3.client('ssm').get_parameters(\n            Names=[parameter_name],\n            WithDecryption=True\n        )\n\n        return response.get('Parameters', None)[0].get('Value', '')\n    except Exception:\n        pass\n\n    return ''", "response": "Get the decrypted value of an SSM parameter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef powerline():\n    '''Install and set up powerline for vim, bash, tmux, and i3.\n\n    It uses pip (python2) and the most up to date powerline version (trunk) from\n    the github repository.\n\n    More infos:\n      https://github.com/powerline/powerline\n      https://powerline.readthedocs.io/en/latest/installation.html\n      https://github.com/powerline/fonts\n      https://youtu.be/_D6RkmgShvU\n      http://www.tecmint.com/powerline-adds-powerful-statuslines-and-prompts-to-vim-and-bash/\n    '''\n    bindings_dir, scripts_dir = install_upgrade_powerline()\n    set_up_powerline_fonts()\n    set_up_powerline_daemon(scripts_dir)\n    powerline_for_vim(bindings_dir)\n    powerline_for_bash_or_powerline_shell(bindings_dir)\n    powerline_for_tmux(bindings_dir)\n    powerline_for_i3(bindings_dir)\n    print('\\nYou may have to reboot for make changes take effect')", "response": "Install and set up powerline for vim bash tmux and i3."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_special_glyphs():\n    '''\n    More infos:\n      https://powerline.readthedocs.io/en/latest/installation/linux.html#fonts-installation\n      https://wiki.archlinux.org/index.php/Font_configuration\n      $XDG_CONFIG_HOME: http://superuser.com/a/365918\n    '''\n    from_dir = '~/repos/powerline/font'\n\n    run('mkdir -p ~/.local/share/fonts')\n    run(flo('cp {from_dir}/PowerlineSymbols.otf  ~/.local/share/fonts'))\n\n    to_dir = '~/.config/fontconfig/conf.d/'\n    run(flo('mkdir -p {to_dir}'))\n    run(flo('cp {from_dir}/10-powerline-symbols.conf  {to_dir}'))", "response": "Installs special glyphs in the powerline font."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef powerline_for_bash_or_powerline_shell(bindings_dir):\n    '''Set up the bash extension of powerline or powerline_shell (another task).\n    '''\n    question = '\\nSet up powerline-shell instead of powerline bash extension?'\n    if query_yes_no(question, default='yes'):\n        from setup import powerline_shell\n        powerline_shell()\n        # disable powerline bash extension if it has been set up\n        powerline_bash_enabler = 'if [ -f ~/.bashrc_powerline_bash ]; then ' \\\n                                 'source ~/.bashrc_powerline_bash; fi'\n        comment_out_line(filename='~/.bashrc', line=powerline_bash_enabler)\n    else:\n        powerline_for_bash(bindings_dir)\n        # disable powerline_shell if it has been set up\n        powerline_shell_enabler = 'if [ -f ~/.bashrc_powerline_shell ]; then ' \\\n                                  'source ~/.bashrc_powerline_shell; fi'\n        comment_out_line(filename='~/.bashrc', line=powerline_shell_enabler)", "response": "Set up the bash extension of powerline or powerline_shell."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ifancestor(parser, token):\n    # Grab the contents between\n    contents = parser.parse(('endifancestor',))\n    parser.delete_first_token()\n\n    # If there is only one argument (2 including tag name)\n    # parse it as a variable\n    bits = token.split_contents()\n    if len(bits) == 2:\n        arg = parser.compile_filter(bits[1])\n    else:\n        arg = None\n\n    # Also pass all arguments to the original url tag\n    url_node = url(parser, token)\n\n    return AncestorNode(url_node, arg=arg, contents=contents)", "response": "Returns the contents of the current tag if the provided path consitutes the base of the current pages path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exit_statistics(hostname, start_time, count_sent, count_received, min_time, avg_time, max_time, deviation):\n    end_time = datetime.datetime.now()\n    duration = end_time - start_time\n    duration_sec = float(duration.seconds * 1000)\n    duration_ms = float(duration.microseconds / 1000)\n    duration = duration_sec + duration_ms\n    package_loss = 100 - ((float(count_received) / float(count_sent)) * 100)\n    print(f'\\b\\b--- {hostname} ping statistics ---')\n    try:\n        print(f'{count_sent} packages transmitted, {count_received} received, {package_loss}% package loss, time {duration}ms')\n    except ZeroDivisionError:\n        print(f'{count_sent} packets transmitted, {count_received} received, 100% packet loss, time {duration}ms')\n    print(\n        'rtt min/avg/max/dev = %.2f/%.2f/%.2f/%.2f ms' % (\n            min_time.seconds*1000 + float(min_time.microseconds)/1000,\n            float(avg_time) / 1000,\n            max_time.seconds*1000 + float(max_time.microseconds)/1000,\n            float(deviation)\n        )\n    )", "response": "Print ping exit statistics"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the appropriate Cache-Control and Expires headers for the given number of hours.", "response": "def cache_control_expires(num_hours):\n    \"\"\"\n    Set the appropriate Cache-Control and Expires headers for the given\n    number of hours.\n    \"\"\"\n    num_seconds = int(num_hours * 60 * 60)\n\n    def decorator(func):\n        @wraps(func)\n        def inner(request, *args, **kwargs):\n            response = func(request, *args, **kwargs)\n            patch_response_headers(response, num_seconds)\n            return response\n\n        return inner\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upsert(self):\n\n        required_parameters = []\n        self._stackParameters = []\n\n        try:\n            self._initialize_upsert()\n        except Exception:\n            return False\n\n        try:\n            available_parameters = self._parameters.keys()\n\n            for parameter_name in self._template.get('Parameters', {}):\n                required_parameters.append(str(parameter_name))\n\n            logging.info(' required parameters: ' + str(required_parameters))\n            logging.info('available parameters: ' + str(available_parameters))\n\n            parameters = []\n            for required_parameter in required_parameters:\n                parameter = {}\n                parameter['ParameterKey'] = str(required_parameter)\n\n                required_parameter = str(required_parameter)\n                if required_parameter in self._parameters:\n                    parameter['ParameterValue'] = self._parameters[required_parameter]\n                else:\n                    parameter['ParameterValue'] = self._parameters[required_parameter.lower()]\n\n                parameters.append(parameter)\n\n            if not self._analyze_stuff():\n                sys.exit(1)\n\n            if self._config.get('dryrun', False):\n                logging.info('Generating change set')\n                set_id = self._generate_change_set(parameters)\n                if set_id:\n                    self._describe_change_set(set_id)\n\n                logging.info('This was a dryrun')\n                sys.exit(0)\n\n            self._tags.append({\"Key\": \"CODE_VERSION_SD\", \"Value\": self._config.get('codeVersion')})\n            self._tags.append({\"Key\": \"ANSWER\", \"Value\": str(42)})\n            if self._updateStack:\n                stack = self._cloudFormation.update_stack(\n                    StackName=self._config.get('environment', {}).get('stack_name', None),\n                    TemplateURL=self._templateUrl,\n                    Parameters=parameters,\n                    Capabilities=['CAPABILITY_IAM', 'CAPABILITY_NAMED_IAM'],\n                    Tags=self._tags,\n                    ClientRequestToken=str(uuid.uuid4())\n                )\n                logging.info('existing stack ID: {}'.format(stack.get('StackId', 'unknown')))\n            else:\n                stack = self._cloudFormation.create_stack(\n                    StackName=self._config.get('environment', {}).get('stack_name', None),\n                    TemplateURL=self._templateUrl,\n                    Parameters=parameters,\n                    Capabilities=['CAPABILITY_IAM', 'CAPABILITY_NAMED_IAM'],\n                    Tags=self._tags,\n                    ClientRequestToken=str(uuid.uuid4())\n                )\n                logging.info('new stack ID: {}'.format(stack.get('StackId', 'unknown')))\n        except Exception as x:\n            if self._verbose:\n                logging.error(x, exc_info=True)\n            else:\n                logging.error(x, exc_info=False)\n\n            return False\n\n        return True", "response": "This method is called by the utility to create or update a Cloud Formation System."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting the existing stacks in the specified region.", "response": "def list(self):\n        \"\"\"\n        List the existing stacks in the indicated region\n\n        Args:\n            None\n\n        Returns:\n            True if True\n\n        Todo:\n            Figure out what could go wrong and take steps\n            to hanlde problems.\n        \"\"\"\n        self._initialize_list()\n        interested = True\n\n        response = self._cloudFormation.list_stacks()\n        print('Stack(s):')\n        while interested:\n            if 'StackSummaries' in response:\n                for stack in response['StackSummaries']:\n                    stack_status = stack['StackStatus']\n                    if stack_status != 'DELETE_COMPLETE':\n                        print('    [{}] - {}'.format(stack['StackStatus'], stack['StackName']))\n\n            next_token = response.get('NextToken', None)\n            if next_token:\n                response = self._cloudFormation.list_stacks(NextToken=next_token)\n            else:\n                interested = False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsmash the given stack and return the unique ID.", "response": "def smash(self):\n        \"\"\"\n        Smash the given stack\n\n        Args:\n            None\n\n        Returns:\n            True if True\n\n        Todo:\n            Figure out what could go wrong and take steps\n            to hanlde problems.\n        \"\"\"\n        self._initialize_smash()\n        try:\n            stack_name = self._config.get('environment', {}).get('stack_name', None)\n            response = self._cloudFormation.describe_stacks(StackName=stack_name)\n            logging.debug('smash pre-flight returned: {}'.format(\n                json.dumps(response,\n                           indent=4,\n                           default=json_util.default\n                           )))\n        except ClientError as wtf:\n            logging.warning('your stack is in another castle [0].')\n            return False\n        except Exception as wtf:\n            logging.error('failed to find intial status of smash candidate: {}'.format(wtf))\n            return False\n\n        response = self._cloudFormation.delete_stack(StackName=stack_name)\n        logging.info('delete started for stack: {}'.format(stack_name))\n        logging.debug('delete_stack returned: {}'.format(json.dumps(response, indent=4)))\n        return self.poll_stack()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_boto3_clients(self):\n        try:\n            profile = self._config.get('environment', {}).get('profile')\n            region = self._config.get('environment', {}).get('region')\n            if profile:\n                self._b3Sess = boto3.session.Session(profile_name=profile)\n            else:\n                self._b3Sess = boto3.session.Session()\n\n            self._s3 = self._b3Sess.client('s3')\n            self._cloudFormation = self._b3Sess.client('cloudformation', region_name=region)\n            self._ssm = self._b3Sess.client('ssm', region_name=region)\n\n            return True\n        except Exception as wtf:\n            logging.error('Exception caught in intialize_session(): {}'.format(wtf))\n            traceback.print_exc(file=sys.stdout)\n            return False", "response": "Initialize the boto3 clients for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a value from Simple Systems Manager", "response": "def _get_ssm_parameter(self, p):\n        \"\"\"\n        Get parameters from Simple Systems Manager\n\n        Args:\n            p - a parameter name\n\n        Returns:\n            a value, decrypted if needed, if successful or None if things go\n            sideways.\n        \"\"\"\n        try:\n            response = self._ssm.get_parameter(Name=p, WithDecryption=True)\n            return response.get('Parameter', {}).get('Value', None)\n        except Exception as ruh_roh:\n            logging.error(ruh_roh, exc_info=False)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fill_parameters(self):\n        self._parameters = self._config.get('parameters', {})\n        self._fill_defaults()\n\n        for k in self._parameters.keys():\n            try:\n                if self._parameters[k].startswith(self.SSM) and self._parameters[k].endswith(']'):\n                    parts = self._parameters[k].split(':')\n                    tmp = parts[1].replace(']', '')\n                    val = self._get_ssm_parameter(tmp)\n                    if val:\n                        self._parameters[k] = val\n                    else:\n                        logging.error('SSM parameter {} not found'.format(tmp))\n                        return False\n                elif self._parameters[k] == self.ASK:\n                    val = None\n                    a1 = '__x___'\n                    a2 = '__y___'\n                    prompt1 = \"Enter value for '{}': \".format(k)\n                    prompt2 = \"Confirm value for '{}': \".format(k)\n                    while a1 != a2:\n                        a1 = getpass.getpass(prompt=prompt1)\n                        a2 = getpass.getpass(prompt=prompt2)\n                        if a1 == a2:\n                            val = a1\n                        else:\n                            print('values do not match, try again')\n                    self._parameters[k] = val\n            except:\n                pass\n\n        return True", "response": "Fill in the _parameters dict from the properties file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the tags from the tags file and add them to the internal _tags dict.", "response": "def _read_tags(self):\n        \"\"\"\n        Fill in the _tags dict from the tags file.\n\n        Args:\n            None\n\n        Returns:\n            True\n\n        Todo:\n            Figure what could go wrong and at least acknowledge the\n            the fact that Murphy was an optimist.\n        \"\"\"\n        tags = self._config.get('tags', {})\n        logging.info('Tags:')\n        for tag_name in tags.keys():\n            tag = {}\n            tag['Key'] = tag_name\n            tag['Value'] = tags[tag_name]\n            self._tags.append(tag)\n            logging.info('{} = {}'.format(tag_name, tags[tag_name]))\n\n        logging.debug(json.dumps(\n            self._tags,\n            indent=2,\n            sort_keys=True\n        ))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if we are creating a new stack or updating an existing one.", "response": "def _set_update(self):\n        \"\"\"\n        Determine if we are creating a new stack or updating and existing one.\n        The update member is set as you would expect at the end of this query.\n\n        Args:\n            None\n\n        Returns:\n            True\n        \"\"\"\n        try:\n            self._updateStack = False\n            stack_name = self._config.get('environment', {}).get('stack_name', None)\n            response = self._cloudFormation.describe_stacks(StackName=stack_name)\n            stack = response['Stacks'][0]\n            if stack['StackStatus'] == 'ROLLBACK_COMPLETE':\n                logging.info('stack is in ROLLBACK_COMPLETE status and should be deleted')\n                del_stack_resp = self._cloudFormation.delete_stack(StackName=stack_name)\n                logging.info('delete started for stack: {}'.format(stack_name))\n                logging.debug('delete_stack returned: {}'.format(json.dumps(del_stack_resp, indent=4)))\n                stack_delete = self.poll_stack()\n                if not stack_delete:\n                    return False\n\n            if stack['StackStatus'] in ['CREATE_COMPLETE', 'UPDATE_COMPLETE', 'UPDATE_ROLLBACK_COMPLETE']:\n                self._updateStack = True\n        except:\n            self._updateStack = False\n\n        logging.info('update_stack: ' + str(self._updateStack))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _archive_elements(self):\n        try:\n            stackfile_key, propertyfile_key = self._craft_s3_keys()\n\n            template_file = self._config.get('environment', {}).get('template', None)\n            bucket = self._config.get('environment', {}).get('bucket', None)\n            if not os.path.isfile(template_file):\n                logging.info(\"{} is not actually a file\".format(template_file))\n                return False\n\n            logging.info('Copying parameters to s3://{}/{}'.format(bucket, propertyfile_key))\n            temp_file_name = '/tmp/{}'.format((str(uuid.uuid4()))[:8])\n            with open(temp_file_name, 'w') as dump_file:\n                json.dump(self._parameters, dump_file, indent=4)\n\n            self._s3.upload_file(temp_file_name, bucket, propertyfile_key)\n\n            logging.info('Copying {} to s3://{}/{}'.format(template_file, bucket, stackfile_key))\n            self._s3.upload_file(template_file, bucket, stackfile_key)\n\n            self._templateUrl = 'https://s3.amazonaws.com/{}/{}'.format(bucket, stackfile_key)\n            logging.info(\"template_url: \" + self._templateUrl)\n            return True\n        except Exception as x:\n            logging.error('Exception caught in copy_stuff_to_S3(): {}'.format(x))\n            traceback.print_exc(file=sys.stdout)\n            return False", "response": "This function copies the template file to S3 and stores the parameters file into S3."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef poll_stack(self):\n        logging.info('polling stack status, POLL_INTERVAL={}'.format(POLL_INTERVAL))\n        time.sleep(POLL_INTERVAL)\n        completed_states = [\n            'CREATE_COMPLETE',\n            'UPDATE_COMPLETE',\n            'DELETE_COMPLETE'\n        ]\n        stack_name = self._config.get('environment', {}).get('stack_name', None)\n        while True:\n            try:\n                response = self._cloudFormation.describe_stacks(StackName=stack_name)\n                stack = response['Stacks'][0]\n                current_status = stack['StackStatus']\n                logging.info('current status of {}: {}'.format(stack_name, current_status))\n                if current_status.endswith('COMPLETE') or current_status.endswith('FAILED'):\n                    if current_status in completed_states:\n                        return True\n                    else:\n                        return False\n\n                time.sleep(POLL_INTERVAL)\n            except ClientError as wtf:\n                if str(wtf).find('does not exist') == -1:\n                    logging.error('Exception caught in wait_for_stack(): {}'.format(wtf))\n                    traceback.print_exc(file=sys.stdout)\n                    return False\n                else:\n                    logging.info('{} is gone'.format(stack_name))\n                    return True\n            except Exception as wtf:\n                logging.error('Exception caught in wait_for_stack(): {}'.format(wtf))\n                traceback.print_exc(file=sys.stdout)\n                return False", "response": "Poll the Cloud Formation process for a stack and return True or False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_desktop():\n    '''Run setup tasks to set up a nicely configured desktop pc.\n\n    This is highly biased on my personal preference.\n\n    The task is defined in file fabsetup_custom/fabfile_addtitions/__init__.py\n    and could be customized by Your own needs.  More info: README.md\n    '''\n    run('sudo apt-get update')\n    install_packages(packages_desktop)\n    execute(custom.latex)\n    execute(setup.ripping_of_cds)\n    execute(setup.regex_repl)\n    execute(setup.i3)\n    execute(setup.solarized)\n    execute(setup.vim)\n    execute(setup.tmux)\n    execute(setup.pyenv)\n    # circumvent circular import, cf. http://stackoverflow.com/a/18486863\n    from fabfile import dfh, check_reboot\n    dfh()\n    check_reboot()", "response": "Run setup tasks to set up a nicely configured desktop pc."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns setup tasks to set up a nicely configured webserver.", "response": "def setup_webserver():\n    '''Run setup tasks to set up a nicely configured webserver.\n\n    Features:\n     * owncloud service\n     * fdroid repository\n     * certificates via letsencrypt\n     * and more\n\n    The task is defined in file fabsetup_custom/fabfile_addtitions/__init__.py\n    and could be customized by Your own needs.  More info: README.md\n    '''\n    run('sudo apt-get update')\n    install_packages(packages_webserver)\n    execute(custom.latex)\n    execute(setup.solarized)\n    execute(setup.vim)\n    execute(setup.tmux)\n    checkup_git_repo_legacy(url='git@github.com:letsencrypt/letsencrypt.git')\n    execute(setup.service.fdroid)\n    execute(setup.service.owncloud)\n    # circumvent circular import, cf. http://stackoverflow.com/a/18486863\n    from fabfile import dfh, check_reboot\n    dfh()\n    check_reboot()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a server on Unix Domain Socket and parse the messages.", "response": "def start_recv(sockfile=None):\n    '''Open a server on Unix Domain Socket'''\n\n    if sockfile is not None:\n        SOCKFILE = sockfile\n    else:\n        # default sockfile\n        SOCKFILE = \"/tmp/snort_alert\"\n\n    if os.path.exists(SOCKFILE):\n        os.unlink(SOCKFILE)\n    unsock = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)\n    unsock.bind(SOCKFILE)\n    logging.warning('Unix socket start listening...')\n    while True:\n        data = unsock.recv(BUFSIZE)\n        parsed_msg = alert.AlertPkt.parser(data)\n        if parsed_msg:\n            yield parsed_msg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(obj, fp=None, indent=None, sort_keys=False, **kw):\n\n    if fp:\n        iterable = YAMLEncoder(indent=indent, sort_keys=sort_keys, **kw).iterencode(obj)\n        for chunk in iterable:\n            fp.write(chunk)\n    else:\n        return dumps(obj, indent=indent, sort_keys=sort_keys, **kw)", "response": "Dump object to a file - like object or string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps object to YAML string.", "response": "def dumps(obj, indent=None, default=None, sort_keys=False, **kw):\n    \"\"\"Dump string.\"\"\"\n    return YAMLEncoder(indent=indent, default=default, sort_keys=sort_keys, **kw).encode(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(s, **kwargs):\n    try:\n        return loads(s, **kwargs)\n    except TypeError:\n        return loads(s.read(), **kwargs)", "response": "Load a yaml file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a string into a new object.", "response": "def loads(s, cls=None, **kwargs):\n    \"\"\"Load string\"\"\"\n    if not isinstance(s, string_types):\n        raise TypeError('the YAML object must be str, not {0!r}'.format(s.__class__.__name__))\n\n    cls = cls or YAMLDecoder\n    return cls(**kwargs).decode(s)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef address(self):\n\t\t\"The address in big-endian\"\n\t\t_ = struct.pack('L', self.address_num)\n\t\treturn struct.unpack('!L', _)[0]", "response": "The address in big - endian"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd to ~. bashrc", "response": "def enable_nvm():\n    '''add to ~/.bashrc:  Export of $NVM env variable and load nvm command.'''\n    bash_snippet = '~/.bashrc_nvm'\n    install_file_legacy(path=bash_snippet)\n    prefix = flo('if [ -f {bash_snippet} ]; ')\n    enabler = flo('if [ -f {bash_snippet} ]; then source {bash_snippet}; fi')\n    if env.host == 'localhost':\n        uncomment_or_update_or_append_line(filename='~/.bashrc', prefix=prefix,\n                                           new_line=enabler)\n    else:\n        print(cyan('\\nappend to ~/.bashrc:\\n\\n    ') + enabler)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nvm_primer():\n    '''Getting started with nvm (cf. https://github.com/creationix/nvm#usage).\n    '''\n    print('\\nDownload, compile and install the latest release of node:\\n\\n' +\n          cyan('    nvm install node'))\n    print('\\nAnd then in any new shell:\\n\\n' +\n          cyan('    nvm use node') + '  #  use the installed version\\n' +\n          cyan('    nvm run node --version') + '  #  run it\\n' +\n          cyan('    nvm exec 4.2 node --version') + '  #  run any arbitrary '\n          'command in a subshell with the desired version of node\\n' +\n          cyan('    nvm which 5.0') + '  # get the path to the executable to '\n          'where it was installed')\n    print('\\nlist installed node versions:\\n\\n' +\n          cyan('    nvm ls'))\n    print('\\nnvm usage:\\n\\n' +\n          cyan('    nvm --help'))\n    print('\\n\\n----\\nBut at first, use a new shell or run `source ~/.bashrc`')", "response": "Print the help message for the nvm node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_currency(*currencies):\n\tvalidated_currency = []\n\tif not currencies:\n\t\traise CurrencyException('My function need something to run, duh')\n\tfor currency in currencies:\n\t\tcurrency = currency.upper()\n\t\tif not isinstance(currency, str):\n\t\t\traise TypeError('Currency code should be a string: ' + repr(currency))\n\t\tif currency not in _currencies:\n\t\t\traise CurrencyException('Currency code not found: ' + repr(currency))\n\t\tvalidated_currency.append(currency)\n\treturn validated_currency[0] if len(validated_currency) == 1 else validated_currency", "response": "validate_currency - check the currency code"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn name of currency", "response": "def name(currency, *, plural=False):\n\t\"\"\" return name of currency \"\"\"\n\tcurrency = validate_currency(currency)\n\tif plural:\n\t\treturn _currencies[currency]['name_plural']\n\treturn _currencies[currency]['name']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef symbol(currency, *, native=True):\n\tcurrency = validate_currency(currency)\n\tif native:\n\t\treturn _currencies[currency]['symbol_native']\n\treturn _currencies[currency]['symbol']", "response": "return symbol of currency"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrounding currency value based on its max decimal digits", "response": "def rounding(price, currency):\n\t\"\"\" rounding currency value based on its max decimal digits \"\"\"\n\tcurrency = validate_currency(currency)\n\tprice = validate_price(price)\n\tif decimals(currency) == 0:\n\t\treturn round(int(price), decimals(currency))\n\treturn round(price, decimals(currency))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pretty(price, currency, *, abbrev=True, trim=True):\n\tcurrency = validate_currency(currency)\n\tprice = validate_price(price)\n\tspace = '' if nospace(currency) else ' '\n\tfmtstr = ''\n\tif trim:\n\t\tfmtstr = '{:0,.{x}f}'.format(price, x=decimals(currency)).rstrip('0').rstrip('.')\n\telse:\n\t\tfmtstr = '{:0,}'.format(price).rstrip('0').rstrip('.')\n\tif abbrev: # use currency symbol\n\t\tif issuffix(currency):\n\t\t\treturn fmtstr + space + symbol(currency)\n\t\treturn symbol(currency, native=False) + space + fmtstr\n\treturn fmtstr + ' ' + code(currency)", "response": "return format price with symbol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_update(from_currency, to_currency):\n\tif from_currency not in ccache: # if currency never get converted before\n\t\tccache[from_currency] = {}\n\tif ccache[from_currency].get(to_currency) is None:\n\t\tccache[from_currency][to_currency] = {'last_update': 0}\n\tlast_update = float(ccache[from_currency][to_currency]['last_update'])\n\tif time.time() - last_update >= 30 * 60: # if last update is more than 30 min ago\n\t\treturn True\n\treturn False", "response": "check if last update is over 30 mins ago. return True to update else False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_cache(from_currency, to_currency):\n\tif check_update(from_currency, to_currency) is True:\n\t\tccache[from_currency][to_currency]['value'] = convert_using_api(from_currency, to_currency)\n\t\tccache[from_currency][to_currency]['last_update'] = time.time()\n\t\tcache.write(ccache)", "response": "update from_currency to_currency pair in cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_using_api(from_currency, to_currency):\n\tconvert_str = from_currency + '_' + to_currency\n\toptions = {'compact': 'ultra', 'q': convert_str}\n\tapi_url = 'https://free.currencyconverterapi.com/api/v5/convert'\n\tresult = requests.get(api_url, params=options).json()\n\treturn result[convert_str]", "response": "convert from from_currency to to_currency by requesting API"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert(from_currency, to_currency, from_currency_price=1):\n\tget_cache()\n\tfrom_currency, to_currency = validate_currency(from_currency, to_currency)\n\tupdate_cache(from_currency, to_currency)\n\treturn ccache[from_currency][to_currency]['value'] * from_currency_price", "response": "convert from from_currency to to_currency using cached info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait for the signal to arrive.", "response": "def wait_for_signal(self, timeout=None):\n\t\t\"\"\"\n\t\twait for the signal; return after the signal has occurred or the\n\t\ttimeout in seconds elapses.\n\t\t\"\"\"\n\t\ttimeout_ms = int(timeout * 1000) if timeout else win32event.INFINITE\n\t\twin32event.WaitForSingleObject(self.signal_event, timeout_ms)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_message(self, recipient_list, subject, body):\n        url = 'http://www.shanbay.com/api/v1/message/'\n        recipient = ','.join(recipient_list)\n        data = {\n            'recipient': recipient,\n            'subject': subject,\n            'body': body,\n            'csrfmiddlewaretoken': self._request.cookies.get('csrftoken')\n        }\n        response = self.request(url, 'post', data=data)\n        return response.ok", "response": "Send a message to a list of recipients."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reply_message(self, message_url, body):\n        id = re.findall(r'(\\d+)/?$', message_url)[0]\n        api = 'http://www.shanbay.com/api/v1/message/%s/reply/'\n        url = api % id\n        data = {\n            'body': body\n        }\n        response = self.request(url, 'post', data=data)\n        return response.json()['status_code'] == 0", "response": "reply message to a specific user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ip_geoloc(ip, hit_api=True):\n    from ..logs.models import IPInfoCheck\n    try:\n        obj = IPInfoCheck.objects.get(ip_address=ip).ip_info\n    except IPInfoCheck.DoesNotExist:\n        if hit_api:\n            try:\n                obj = IPInfoCheck.check_ip(ip)\n            except RateExceededError:\n                return None\n        else:\n            return None\n    return obj.latitude, obj.longitude", "response": "Get IP geolocation.\n\n    Args:\n        ip (str): IP address to use if no data provided.\n        hit_api (bool): whether to hit api if info not found.\n\n    Returns:\n        str: latitude and longitude, comma-separated."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a link to google maps pointing on this IP s geolocation.", "response": "def google_maps_geoloc_link(data):\n    \"\"\"\n    Get a link to google maps pointing on this IP's geolocation.\n\n    Args:\n        data (str/tuple): IP address or (latitude, longitude).\n\n    Returns:\n        str: a link to google maps pointing on this IP's geolocation.\n    \"\"\"\n    if isinstance(data, str):\n        lat_lon = ip_geoloc(data)\n        if lat_lon is None:\n            return ''\n        lat, lon = lat_lon\n    else:\n        lat, lon = data\n    loc = '%s,%s' % (lat, lon)\n    return 'https://www.google.com/maps/place/@%s,17z/' \\\n           'data=!3m1!4b1!4m5!3m4!1s0x0:0x0!8m2!3d%s!4d%s' % (\n            loc, lat, lon)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a link to open street map pointing on this IP s geolocation.", "response": "def open_street_map_geoloc_link(data):\n    \"\"\"\n    Get a link to open street map pointing on this IP's geolocation.\n\n    Args:\n        data (str/tuple): IP address or (latitude, longitude).\n\n    Returns:\n        str: a link to open street map pointing on this IP's geolocation.\n    \"\"\"\n    if isinstance(data, str):\n        lat_lon = ip_geoloc(data)\n        if lat_lon is None:\n            return ''\n        lat, lon = lat_lon\n    else:\n        lat, lon = data\n    return 'https://www.openstreetmap.org/search' \\\n           '?query=%s%%2C%s#map=7/%s/%s' % (lat, lon, lat, lon)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a chart for status codes.", "response": "def status_codes_chart():\n    \"\"\"Chart for status codes.\"\"\"\n    stats = status_codes_stats()\n\n    chart_options = {\n        'chart': {\n            'type': 'pie'\n        },\n        'title': {\n            'text': ''\n        },\n        'subtitle': {\n            'text': ''\n        },\n        'tooltip': {\n          'formatter': \"return this.y + '/' + this.total + ' (' + \"\n                       \"Highcharts.numberFormat(this.percentage, 1) + '%)';\"\n        },\n        'legend': {\n            'enabled': True,\n        },\n        'plotOptions': {\n            'pie': {\n                'allowPointSelect': True,\n                'cursor': 'pointer',\n                'dataLabels': {\n                    'enabled': True,\n                    'format': '<b>{point.name}</b>: {point.y}/{point.total} '\n                              '({point.percentage:.1f}%)'\n                },\n                'showInLegend': True\n            }\n        },\n        'series': [{\n            'name': _('Status Codes'),\n            'colorByPoint': True,\n            'data': sorted(\n                [{'name': '%s %s' % (k, STATUS_CODES[int(k)]['name']), 'y': v}\n                 for k, v in stats.items()],\n                key=lambda x: x['y'],\n                reverse=True)\n        }]\n    }\n\n    return chart_options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchart for most visited pages legend.", "response": "def most_visited_pages_legend_chart():\n    \"\"\"Chart for most visited pages legend.\"\"\"\n    return {\n        'chart': {\n            'type': 'bar',\n            'height': 200,\n        },\n        'title': {\n            'text': _('Legend')\n        },\n        'xAxis': {\n            'categories': [\n                _('Project URL'),\n                _('Old project URL'),\n                _('Asset URL'),\n                _('Old asset URL'),\n                _('Common asset URL'),\n                _('False-negative project URL'),\n                _('Suspicious URL (potential attack)')\n            ],\n            'title': {\n                'text': None\n            }\n        },\n        'yAxis': {\n            'title': {\n                'text': None,\n                'align': 'high'\n            },\n            'labels': {\n                'overflow': 'justify'\n            }\n        },\n        'tooltip': {\n            'enabled': False\n        },\n        'legend': {\n            'enabled': False\n        },\n        'credits': {\n            'enabled': False\n        },\n        'series': [{\n            'name': _('Legend'),\n            'data': [\n                {'color': URL_TYPE_COLOR[PROJECT], 'y': 1},\n                {'color': URL_TYPE_COLOR[OLD_PROJECT], 'y': 1},\n                {'color': URL_TYPE_COLOR[ASSET], 'y': 1},\n                {'color': URL_TYPE_COLOR[OLD_ASSET], 'y': 1},\n                {'color': URL_TYPE_COLOR[COMMON_ASSET], 'y': 1},\n                {'color': URL_TYPE_COLOR[FALSE_NEGATIVE], 'y': 1},\n                {'color': URL_TYPE_COLOR[SUSPICIOUS], 'y': 1},\n            ]\n        }]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of dicts that can be used to display a chart for the most visited pages.", "response": "def most_visited_pages_charts():\n    \"\"\"Chart for most visited pages.\"\"\"\n    stats = most_visited_pages_stats()\n\n    charts = []\n\n    for i, stat in enumerate(stats['more_than_10']):\n        bound = stat['bound']\n        subset = stat['subset']\n\n        chart_options = {\n            'chart': {\n                'type': 'bar',\n                'height': 15 * len(subset) + 100\n            },\n            'title': {\n                'text': {0: _('More than %d times') % bound}.get(\n                    i, _('Between %d and %d times') % (\n                        bound, stats['more_than_10'][i - 1]['bound']))\n            },\n            'xAxis': {\n                'categories': [u for (u, c, t) in subset],\n                'title': {\n                    'text': None\n                }\n            },\n            'yAxis': {\n                'title': {\n                    'text': None\n                }\n            },\n            'plotOptions': {\n                'bar': {\n                    'dataLabels': {\n                        'enabled': True\n                    }\n                },\n            },\n            'tooltip': {\n                'enabled': False\n            },\n            'legend': {\n                'enabled': False\n            },\n            'credits': {\n                'enabled': False\n            },\n        }\n\n        series_data = []\n        for index, (url, count, url_type) in enumerate(subset):\n            data = {\n                'x': index,\n                'y': count\n            }\n            color = URL_TYPE_COLOR[url_type]\n            data['color'] = color\n            series_data.append(data)\n        chart_options['series'] = [{\n            'name': _('Requests'),\n            'data': series_data\n        }]\n\n        charts.append(chart_options)\n\n    point_formatter_code = \"\"\"\n        return '<br>%s: <strong>' + this.dis + '</strong>(' +\n        Highcharts.numberFormat(this.dis / this.total_dis * 100, 1) + '%%)' +\n        '<br>%s: <strong>' + this.occ + '</strong> (' +\n        Highcharts.numberFormat(this.occ / this.total_occ * 100, 1)  + '%%)';\n        \"\"\" % (_('Distinct URLs'), _('Occurrences'))\n\n    occurrences = stats['less_than_10']\n    total_distinct = sum([v['distinct'] for k, v in occurrences.items()])\n    total_occurrences = sum([v['total'] for k, v in occurrences.items()])\n    charts.append({\n        'chart': {\n            'plotBackgroundColor': None,\n            'plotBorderWidth': None,\n            'plotShadow': False,\n            'type': 'pie'\n        },\n        'title': {\n            'text': _('Less than 10 (type repartition)')\n        },\n        'plotOptions': {\n            'pie': {\n                'allowPointSelect': True,\n                'cursor': 'pointer',\n                'dataLabels': {\n                    'enabled': False\n                },\n                'showInLegend': True,\n                'tooltip': {\n                    'pointFormatter': point_formatter_code\n                },\n            }\n        },\n        'series': [{\n            'name': '',\n            'colorByPoint': True,\n            'data': [{\n                'name': _('Valid project URL'),\n                'dis': occurrences[PROJECT]['distinct'],\n                'y': occurrences[PROJECT]['total'],\n                'occ': occurrences[PROJECT]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[PROJECT]\n            }, {\n                'name': _('Old project URL'),\n                'dis': occurrences[OLD_PROJECT]['distinct'],\n                'y': occurrences[OLD_PROJECT]['total'],\n                'occ': occurrences[OLD_PROJECT]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[OLD_PROJECT]\n            }, {\n                'name': _('Valid asset URL'),\n                'dis': occurrences[ASSET]['distinct'],\n                'y': occurrences[ASSET]['total'],\n                'occ': occurrences[ASSET]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[ASSET]\n            }, {\n                'name': _('Old asset URL'),\n                'dis': occurrences[OLD_ASSET]['distinct'],\n                'y': occurrences[OLD_ASSET]['total'],\n                'occ': occurrences[OLD_ASSET]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[OLD_ASSET]\n            }, {\n                'name': _('Common asset URL'),\n                'dis': occurrences[COMMON_ASSET]['distinct'],\n                'y': occurrences[COMMON_ASSET]['total'],\n                'occ': occurrences[COMMON_ASSET]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[COMMON_ASSET]\n            }, {\n                'name': _('False-negative project URL'),\n                'dis': occurrences[FALSE_NEGATIVE]['distinct'],\n                'y': occurrences[FALSE_NEGATIVE]['total'],\n                'occ': occurrences[FALSE_NEGATIVE]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[FALSE_NEGATIVE]\n            }, {\n                'name': _('Suspicious URL (potential attack)'),\n                'dis': occurrences[SUSPICIOUS]['distinct'],\n                'y': occurrences[SUSPICIOUS]['total'],\n                'occ': occurrences[SUSPICIOUS]['total'],\n                'total_dis': total_distinct,\n                'total_occ': total_occurrences,\n                'color': URL_TYPE_COLOR[SUSPICIOUS]\n            }]\n        }]\n    })\n\n    return charts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_settings(mod, allow_extras=True, settings=django_settings):\n    extras = {}\n\n    for setting in dir(mod):\n        if setting == setting.upper():\n            setting_value = getattr(mod, setting)\n            if setting in TUPLE_SETTINGS and type(setting_value) == str:\n                setting_value = (setting_value,)  # In case the user forgot the comma.\n\n            # Any setting that starts with EXTRA_ and matches a setting that is a list or tuple\n            # will automatically append the values to the current setting.\n            # It might make sense to make this less magical\n            if setting.startswith('EXTRA_'):\n                base_setting = setting.split('EXTRA_', 1)[-1]\n                if isinstance(getattr(settings, base_setting), (list, tuple)):\n                    extras[base_setting] = setting_value\n                    continue\n\n            setattr(settings, setting, setting_value)\n\n    for key, value in extras.items():\n        curval = getattr(settings, key)\n        setattr(settings, key, curval + type(curval)(value))", "response": "Adds all settings that are part of mod to the global settings object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets urls method. Returns: list: the list of url objects.", "response": "def get_urls(self):\n        \"\"\"\n        Get urls method.\n\n        Returns:\n            list: the list of url objects.\n        \"\"\"\n        urls = super(DashboardSite, self).get_urls()\n        custom_urls = [\n            url(r'^$',\n                self.admin_view(HomeView.as_view()),\n                name='index'),\n            url(r'^logs/', include(logs_urlpatterns(self.admin_view))),\n        ]\n\n        custom_urls += get_realtime_urls(self.admin_view)\n\n        del urls[0]\n        return custom_urls + urls"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_form_widget_attr(field, attr_name, attr_value, replace=0):\n    if not replace:\n        attr = field.field.widget.attrs.get(attr_name, '')\n        attr += force_text(attr_value)\n        field.field.widget.attrs[attr_name] = attr\n        return field\n    else:\n        field.field.widget.attrs[attr_name] = attr_value\n        return field", "response": "Adds widget attributes to a bound form field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning any template filter into a blocktag.", "response": "def block_anyfilter(parser, token):\n    \"\"\"\n    Turn any template filter into a blocktag.\n\n    Usage::\n\n    {% load libs_tags %}\n    {% block_anyfilter django.template.defaultfilters.truncatewords_html 15 %}\n        // Something complex that generates html output\n    {% endblockanyfilter %}\n\n    \"\"\"\n    bits = token.contents.split()\n    nodelist = parser.parse(('endblockanyfilter',))\n    parser.delete_first_token()\n    return BlockAnyFilterNode(nodelist, bits[1], *bits[2:])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the thumbnail dimensions depending on the images format.", "response": "def calculate_dimensions(image, long_side, short_side):\n    \"\"\"Returns the thumbnail dimensions depending on the images format.\"\"\"\n    if image.width >= image.height:\n        return '{0}x{1}'.format(long_side, short_side)\n    return '{0}x{1}'.format(short_side, long_side)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nallows to call any method of any object with parameters. Because come on! It's bloody stupid that Django's templating engine doesn't allow that. Usage:: {% call myobj 'mymethod' myvar foobar=myvar2 as result %} {% call myobj 'mydict' 'mykey' as result %} {% call myobj 'myattribute' as result %} :param obj: The object which has the method that you would like to call :param method: A string representing the attribute on the object that should be called.", "response": "def call(obj, method, *args, **kwargs):\n    \"\"\"\n    Allows to call any method of any object with parameters.\n\n    Because come on! It's bloody stupid that Django's templating engine doesn't\n    allow that.\n\n    Usage::\n\n        {% call myobj 'mymethod' myvar foobar=myvar2 as result %}\n        {% call myobj 'mydict' 'mykey' as result %}\n        {% call myobj 'myattribute' as result %}\n\n    :param obj: The object which has the method that you would like to call\n    :param method: A string representing the attribute on the object that\n      should be called.\n\n    \"\"\"\n    function_or_dict_or_member = getattr(obj, method)\n    if callable(function_or_dict_or_member):\n        # If it is a function, let's call it\n        return function_or_dict_or_member(*args, **kwargs)\n    if not len(args):\n        # If it is a member, lets return it\n        return function_or_dict_or_member\n    # If it is a dict, let's access one of it's keys\n    return function_or_dict_or_member[args[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconcatenating the given strings.", "response": "def concatenate(*args, **kwargs):\n    \"\"\"\n    Concatenates the given strings.\n\n    Usage::\n\n        {% load libs_tags %}\n        {% concatenate \"foo\" \"bar\" as new_string %}\n        {% concatenate \"foo\" \"bar\" divider=\"_\" as another_string %}\n\n    The above would result in the strings \"foobar\" and \"foo_bar\".\n\n    \"\"\"\n    divider = kwargs.get('divider', '')\n    result = ''\n    for arg in args:\n        if result == '':\n            result += arg\n        else:\n            result += '{0}{1}'.format(divider, arg)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_content_type(obj, field_name=False):\n    content_type = ContentType.objects.get_for_model(obj)\n    if field_name:\n        return getattr(content_type, field_name, '')\n    return content_type", "response": "Returns the content type of an object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the verbose name of an object s field.", "response": "def get_verbose(obj, field_name=\"\"):\n    \"\"\"\n    Returns the verbose name of an object's field.\n\n    :param obj: A model instance.\n    :param field_name: The requested field value in string format.\n\n    \"\"\"\n    if hasattr(obj, \"_meta\") and hasattr(obj._meta, \"get_field_by_name\"):\n        try:\n            return obj._meta.get_field(field_name).verbose_name\n        except FieldDoesNotExist:\n            pass\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_query_params(request, *args):\n    query = request.GET.copy()\n    index = 1\n    key = ''\n    for arg in args:\n        if index % 2 != 0:\n            key = arg\n        else:\n            if arg == \"!remove\":\n                try:\n                    query.pop(key)\n                except KeyError:\n                    pass\n            else:\n                query[key] = arg\n        index += 1\n    return query.urlencode()", "response": "This function returns a URL query string that can be used to get the values of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the active name of the given URL.", "response": "def navactive(request, url, exact=0, use_resolver=1):\n    \"\"\"\n    Returns ``active`` if the given URL is in the url path, otherwise ''.\n\n    Usage::\n\n        {% load libs_tags %}\n        ...\n        <li class=\"{% navactive request \"/news/\" exact=1 %}\">\n\n    :param request: A request instance.\n    :param url: A string representing a part of the URL that needs to exist\n      in order for this method to return ``True``.\n    :param exact: If ``1`` then the parameter ``url`` must be equal to\n      ``request.path``, otherwise the parameter ``url`` can just be a part of\n      ``request.path``.\n    :use_resolver: If ``0`` we will not try to compare ``url`` with existing\n      view names but we will only compare it with ``request.path``.\n\n    \"\"\"\n    if use_resolver:\n        try:\n            if url == resolve(request.path).url_name:\n                # Checks the url pattern in case a view_name is posted\n                return 'active'\n            elif url == request.path:\n                # Workaround to catch URLs with more than one part, which don't\n                # raise a Resolver404 (e.g. '/index/info/')\n                match = request.path\n            else:\n                return ''\n        except Resolver404:\n            # Indicates, that a simple url string is used (e.g. '/index/')\n            match = request.path\n    else:\n        match = request.path\n\n    if exact and url == match:\n        return 'active'\n    elif not exact and url in request.path:\n        return 'active'\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_range_around(range_value, current_item, padding):\n    total_items = 1 + padding * 2\n    left_bound = padding\n    right_bound = range_value - padding\n    if range_value <= total_items:\n        range_items = range(1, range_value + 1)\n        return {\n            'range_items': range_items,\n            'left_padding': False,\n            'right_padding': False,\n        }\n    if current_item <= left_bound:\n        range_items = range(1, range_value + 1)[:total_items]\n        return {\n            'range_items': range_items,\n            'left_padding': range_items[0] > 1,\n            'right_padding': range_items[-1] < range_value,\n        }\n\n    if current_item >= right_bound:\n        range_items = range(1, range_value + 1)[-total_items:]\n        return {\n            'range_items': range_items,\n            'left_padding': range_items[0] > 1,\n            'right_padding': range_items[-1] < range_value,\n        }\n\n    range_items = range(current_item - padding, current_item + padding + 1)\n    return {\n        'range_items': range_items,\n        'left_padding': True,\n        'right_padding': True,\n    }", "response": "Returns a range of numbers around the given number."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sum(context, key, value, multiplier=1):\n    if key not in context.dicts[0]:\n        context.dicts[0][key] = 0\n    context.dicts[0][key] += value * multiplier\n    return ''", "response": "Adds the given value to the total value currently held in key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntags to render x - tmpl templates with Django template code.", "response": "def verbatim(parser, token):\n    \"\"\"Tag to render x-tmpl templates with Django template code.\"\"\"\n    text = []\n    while 1:\n        token = parser.tokens.pop(0)\n        if token.contents == 'endverbatim':\n            break\n        if token.token_type == TOKEN_VAR:\n            text.append('{{ ')\n        elif token.token_type == TOKEN_BLOCK:\n            text.append('{%')\n        text.append(token.contents)\n        if token.token_type == TOKEN_VAR:\n            text.append(' }}')\n        elif token.token_type == TOKEN_BLOCK:\n            if not text[-1].startswith('='):\n                text[-1:-1] = [' ']\n            text.append(' %}')\n    return VerbatimNode(''.join(text))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the possessive s after a string.", "response": "def append_s(value):\n    \"\"\"\n    Adds the possessive s after a string.\n\n    value = 'Hans' becomes Hans'\n    and value = 'Susi' becomes Susi's\n\n    \"\"\"\n    if value.endswith('s'):\n        return u\"{0}'\".format(value)\n    else:\n        return u\"{0}'s\".format(value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_args(args):\n    index = None\n    for arg_i, arg in enumerate(args):\n        if not arg.startswith('-'):\n            index = arg_i\n            break\n\n    # Unable to parse any arguments\n    if index is None:\n        return (args, None, [])\n\n    return (args[:index], args[index], args[(index + 1):])", "response": "Parses the arguments and returns a tuple containing the command and command_args."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring a new app.", "response": "def configure_app(config_path=None, project=None, default_config_path=None,\n                  default_settings=None, settings_initializer=None,\n                  settings_envvar=None, initializer=None, allow_extras=True,\n                  config_module_name=None, runner_name=None, on_configure=None):\n    \"\"\"\n    :param project: should represent the canonical name for the project, generally\n        the same name it assigned in distutils.\n    :param default_config_path: the default location for the configuration file.\n    :param default_settings: default settings to load (think inheritence).\n    :param settings_initializer: a callback function which should return a string\n        representing the default settings template to generate.\n    :param initializer: a callback function which will be executed before the command\n        is executed. It is passed a dictionary of various configuration attributes.\n    \"\"\"\n    global __configured\n\n    project_filename = sanitize_name(project)\n\n    if default_config_path is None:\n        default_config_path = '~/%s/%s.conf.py' % (project_filename, project_filename)\n\n    if settings_envvar is None:\n        settings_envvar = project_filename.upper() + '_CONF'\n\n    if config_module_name is None:\n        config_module_name = project_filename + '_config'\n\n    # normalize path\n    if settings_envvar in os.environ:\n        default_config_path = os.environ.get(settings_envvar)\n    else:\n        default_config_path = os.path.normpath(os.path.abspath(os.path.expanduser(default_config_path)))\n\n    if not config_path:\n        config_path = default_config_path\n\n    config_path = os.path.expanduser(config_path)\n\n    if not os.path.exists(config_path):\n        if runner_name:\n            raise ValueError(\"Configuration file does not exist. Use '%s init' to initialize the file.\" % (runner_name,))\n        raise ValueError(\"Configuration file does not exist at %r\" % (config_path,))\n\n    os.environ['DJANGO_SETTINGS_MODULE'] = config_module_name\n\n    def settings_callback(settings):\n        if initializer is None:\n            return\n\n        try:\n            initializer({\n                'project': project,\n                'config_path': config_path,\n                'settings': settings,\n            })\n        except Exception:\n            # XXX: Django doesn't like various errors in this path\n            import sys\n            import traceback\n            traceback.print_exc()\n            sys.exit(1)\n\n    importer.install(\n        config_module_name, config_path, default_settings,\n        allow_extras=allow_extras, callback=settings_callback)\n\n    __configured = True\n\n    # HACK(dcramer): we need to force access of django.conf.settings to\n    # ensure we don't hit any import-driven recursive behavior\n    from django.conf import settings\n    hasattr(settings, 'INSTALLED_APPS')\n\n    if on_configure:\n        on_configure({\n            'project': project,\n            'config_path': config_path,\n            'settings': settings,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of URL patterns for the logs views.", "response": "def logs_urlpatterns(admin_view=lambda x: x):\n    \"\"\"\n    Return the URL patterns for the logs views.\n\n    Args:\n        admin_view (callable): admin_view method from an AdminSite instance.\n\n    Returns:\n        list: the URL patterns for the logs views.\n    \"\"\"\n    return [\n        url(r'^$',\n            admin_view(LogsMenu.as_view()),\n            name='logs'),\n        url(r'^status_codes$',\n            admin_view(LogsStatusCodes.as_view()),\n            name='logs_status_codes'),\n        url(r'^status_codes_by_date$',\n            admin_view(LogsStatusCodesByDate.as_view()),\n            name='logs_status_codes_by_date'),\n        url(r'^most_visited_pages$',\n            admin_view(LogsMostVisitedPages.as_view()),\n            name='logs_most_visited_pages')\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets information about an IP.", "response": "def _get(self, ip):\n        \"\"\"\n        Get information about an IP.\n\n        Args:\n            ip (str): an IP (xxx.xxx.xxx.xxx).\n\n        Returns:\n            dict: see http://ipinfo.io/developers/getting-started\n        \"\"\"\n        # Geoloc updated up to once a week:\n        # http://ipinfo.io/developers/data#geolocation-data\n        retries = 10\n        for retry in range(retries):\n            try:\n                response = requests.get('http://ipinfo.io/%s/json' % ip,\n                                        verify=False, timeout=1)  # nosec\n                if response.status_code == 429:\n                    raise RateExceededError\n                return response.json()\n            except (requests.ReadTimeout, requests.ConnectTimeout):\n                pass\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a raw datagram and returns the right type of message", "response": "def parse(data):\n    \"\"\" Parses a raw datagram and return the right type of message \"\"\"\n\n    # convert to string\n    data = data.decode(\"ascii\")\n\n    if len(data) == 2 and data == \"A5\":\n        return AckMessage()\n\n    # split into bytes\n    raw = [data[i:i+2] for i in range(len(data)) if i % 2 == 0]\n\n    if len(raw) != 7:\n        return UnknownMessage(raw)\n\n    if raw[1] == \"B8\":\n        return StateMessage(raw)\n    elif raw[3] == \"12\":\n        return CommandMessage(raw)\n    elif raw[3] == \"14\":\n        return ScenarioTriggeredMessage(raw)\n    elif raw[3] == \"15\":\n        return RequestStatusMessage(raw)\n    else:\n        return UnknownMessage(raw)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a XOR of all the bytes specified inside of the given list", "response": "def checksum_bytes(data):\n    \"\"\" Returns a XOR of all the bytes specified inside of the given list \"\"\"\n\n    int_values = [int(x, 16) for x in data]\n    int_xor = reduce(lambda x, y: x ^ y, int_values)\n    hex_xor = \"{:X}\".format(int_xor)\n    if len(hex_xor) % 2 != 0:\n        hex_xor = \"0\" + hex_xor\n\n    return str.encode(hex_xor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompose a SCS message containing the body of the message.", "response": "def compose_telegram(body):\n    \"\"\" Compose a SCS message\n\n        body: list containing the body of the message.\n        returns: full telegram expressed (bytes instance)\n    \"\"\"\n\n    msg = [b\"A8\"] + body + [checksum_bytes(body)] + [b\"A3\"]\n    return str.encode(\"\".join([x.decode() for x in msg]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending an email based on templates for subject and body.", "response": "def send_email(request, context, subject_template, body_template,\n               from_email, recipients, priority=\"medium\", reply_to=None,\n               headers=None, cc=None, bcc=None):\n    \"\"\"\n    Sends an email based on templates for subject and body.\n\n    :param request: The current request instance.\n    :param context: A dictionary of items that should be added to the\n        templates' contexts.\n    :param subject_template: A string representing the path to the template of\n        of the email's subject.\n    :param body_template: A string representing the path to the template of\n        the email's body.\n    :param from_email: String that represents the sender of the email.\n    :param recipients: A list of tuples of recipients. The tuples are similar\n        to the ADMINS setting.\n    :param priority: Sets the priority of the email (only used by django-mailer\n        to prioritise email sendings).\n    :param reply_to: Optional email address to reply to.\n    :param headers: Additional dictionary to add header attributes.\n    :param cc: A list of CC recipients\n    :param bcc: A list of BCC recipients\n    \"\"\"\n    headers = headers or {}\n    if not reply_to:\n        reply_to = from_email\n\n    # Add additional context\n    if hasattr(settings, 'DJANGO_LIBS_EMAIL_CONTEXT'):\n        context_fn = load_member_from_setting('DJANGO_LIBS_EMAIL_CONTEXT')\n        context.update(context_fn(request))\n\n    if request and request.get_host():\n        domain = request.get_host()\n        protocol = 'https://' if request.is_secure() else 'http://'\n    else:\n        domain = getattr(settings, 'DOMAIN', Site.objects.get_current().domain)\n        protocol = getattr(settings, 'PROTOCOL', 'http://')\n    context.update({\n        'domain': domain,\n        'protocol': protocol,\n    })\n    subject = render_to_string(template_name=subject_template,\n                               context=context, request=request)\n    subject = ''.join(subject.splitlines())\n    message_html = render_to_string(template_name=body_template,\n                                    context=context, request=request)\n    message_plaintext = html_to_plain_text(message_html)\n    subject = force_text(subject)\n    message = force_text(message_plaintext)\n    email = EmailMultiAlternatives(\n        subject=subject,\n        body=message,\n        from_email=from_email,\n        to=recipients,\n        cc=cc,\n        bcc=bcc,\n        headers=headers,\n        reply_to=[reply_to],\n    )\n    email.attach_alternative(message_html, \"text/html\")\n    if settings.EMAIL_BACKEND == 'mailer.backend.DbBackend':\n        # We customize `mailer.send_html_mail` to enable CC and BCC\n        priority = mailer.get_priority(priority)\n        msg = make_message(\n            subject=subject,\n            body=message,\n            from_email=from_email,\n            to=recipients,\n            priority=priority,\n        )\n        msg.email = email\n        msg.save()\n    else:\n        email.send()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if URL is part of the current project s URLs.", "response": "def url_is_project(url, default='not_a_func'):\n    \"\"\"\n    Check if URL is part of the current project's URLs.\n\n    Args:\n        url (str): URL to check.\n        default (callable): used to filter out some URLs attached to function.\n\n    Returns:\n\n    \"\"\"\n    try:\n        u = resolve(url)\n        if u and u.func != default:\n            return True\n    except Resolver404:\n        static_url = settings.STATIC_URL\n        static_url_wd = static_url.lstrip('/')\n        if url.startswith(static_url):\n            url = url[len(static_url):]\n        elif url.startswith(static_url_wd):\n            url = url[len(static_url_wd):]\n        else:\n            return False\n        if finders.find(url):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef url_is(white_list):\n    def func(url):\n        prefixes = white_list.get('PREFIXES', ())\n        for prefix in prefixes:\n            if url.startswith(prefix):\n                return True\n        constants = white_list.get('CONSTANTS', ())\n        for exact_url in constants:\n            if url == exact_url:\n                return True\n        return False\n    return func", "response": "Function generator. Returns a function to check if a URL is..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving a collection of records.", "response": "def save_records(self, records):\n        '''\n        Save a collection of records\n        '''\n        for record in records:\n            if not isinstance(record, Record):\n                record = Record(*record)\n            self.save_record(*record)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_record(self, agent_id, t_step, key, value):\n        '''\n        Save a collection of records to the database.\n        Database writes are cached.\n        '''\n        value = self.convert(key, value)\n        self._tups.append(Record(agent_id=agent_id,\n                                 t_step=t_step,\n                                 key=key,\n                                 value=value))\n        if len(self._tups) > 100:\n            self.flush_cache()", "response": "Save a record to the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the serialized value for a given key.", "response": "def convert(self, key, value):\n        \"\"\"Get the serialized value for a given key.\"\"\"\n        if key not in self._dtypes:\n            self.read_types()\n            if key not in self._dtypes:\n                name = utils.name(value)\n                serializer = utils.serializer(name)\n                deserializer = utils.deserializer(name)\n                self._dtypes[key] = (name, serializer, deserializer)\n                with self.db:\n                    self.db.execute(\"replace into value_types (key, value_type) values (?, ?)\", (key, name))\n        return self._dtypes[key][1](value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recover(self, key, value):\n        if key not in self._dtypes:\n            self.read_types()\n        if key not in self._dtypes:\n            raise ValueError(\"Unknown datatype for {} and {}\".format(key, value))\n        return self._dtypes[key][2](value)", "response": "Get the deserialized value for a given key and the serialized version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flush_cache(self):\n        '''\n        Use a cache to save state changes to avoid opening a session for every change.\n        The cache will be flushed at the end of the simulation, and when history is accessed.\n        '''\n        logger.debug('Flushing cache {}'.format(self.db_path))\n        with self.db:\n            for rec in self._tups:\n                self.db.execute(\"replace into history(agent_id, t_step, key, value) values (?, ?, ?, ?)\", (rec.agent_id, rec.t_step, rec.key, rec.value))\n        self._tups = list()", "response": "Flushes the cache for all the entries in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef records():\n    import pkg_resources\n    import uuid\n    from dojson.contrib.marc21 import marc21\n    from dojson.contrib.marc21.utils import create_record, split_blob\n    from invenio_pidstore import current_pidstore\n    from invenio_records.api import Record\n\n    # pkg resources the demodata\n    data_path = pkg_resources.resource_filename(\n        'invenio_records', 'data/marc21/bibliographic.xml'\n    )\n    with open(data_path) as source:\n        indexer = RecordIndexer()\n        with db.session.begin_nested():\n            for index, data in enumerate(split_blob(source.read()), start=1):\n                # create uuid\n                rec_uuid = uuid.uuid4()\n                # do translate\n                record = marc21.do(create_record(data))\n                # create PID\n                current_pidstore.minters['recid'](\n                    rec_uuid, record\n                )\n                # create record\n                indexer.index(Record.create(record, id_=rec_uuid))\n        db.session.commit()", "response": "Load records from a MARC - 21 XML file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a single trial of the simulation.", "response": "def run_trial(self, trial_id = 0, until = None, return_env = True, **opts):\n        \"\"\"Run a single trial of the simulation\n\n        Parameters\n        ----------\n        trial_id : int\n        \"\"\"\n        # Set-up trial environment and graph\n        until=until or self.max_time\n        env=self.get_env(trial_id = trial_id, **opts)\n        # Set up agents on nodes\n        with utils.timer('Simulation {} trial {}'.format(self.name, trial_id)):\n            env.run(until)\n        if self.dump and not self.dry_run:\n            with utils.timer('Dumping simulation {} trial {}'.format(self.name, trial_id)):\n                env.dump(formats = self.dump)\n        if return_env:\n            return env"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches the ORCID public API and return a dictionary with the personal details of the person associated with the given ORCID", "response": "def search_orcid(orcid):\n    \"\"\"\n    Search the ORCID public API\n\n    Specfically, return a dictionary with the personal details\n    (name, etc.) of the person associated with the given ORCID\n\n    Args:\n        orcid (`str`): The ORCID to be searched\n\n    Returns:\n        `dict`: Dictionary with the JSON response from the API\n\n    Raises:\n        `~requests.HTTPError`: If the given ORCID cannot be found, an `~requests.HTTPError`\n            is raised with status code 404\n    \"\"\"\n    url = 'https://pub.orcid.org/v2.1/{orcid}/person'.format(orcid=orcid)\n    r = requests.get(url, headers=headers)\n    if r.status_code != 200:\n        r.raise_for_status()\n    return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield one date per day from starting date to ending date.", "response": "def daterange(start_date, end_date):\n    \"\"\"\n    Yield one date per day from starting date to ending date.\n\n    Args:\n        start_date (date): starting date.\n        end_date (date): ending date.\n\n    Yields:\n        date: a date for each day within the range.\n    \"\"\"\n    for n in range(int((end_date - start_date).days)):\n        yield start_date + timedelta(n)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef month_name_to_number(month, to_int=False):\n    number = {\n        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05',\n        'Jun': '06', 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10',\n        'Nov': '11', 'Dec': '12',\n    }.get(month)\n    return int(number) if to_int else number", "response": "Convert a month name to its number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread and parse ReSpecTh XML file metadata.", "response": "def get_file_metadata(root):\n    \"\"\"Read and parse ReSpecTh XML file metadata (file author, version, etc.)\n\n    Args:\n        root (`~xml.etree.ElementTree.Element`): Root of ReSpecTh XML file\n\n    Returns:\n        properties (`dict`): Dictionary with file metadata\n    \"\"\"\n    properties = {}\n\n    file_author = getattr(root.find('fileAuthor'), 'text', False)\n    # Test for missing attribute or empty string in the same statement\n    if not file_author:\n        raise MissingElementError('fileAuthor')\n    else:\n        properties['file-authors'] = [{'name': file_author}]\n\n    # Default version is 0 for the ChemKED file\n    properties['file-version'] = 0\n\n    # Default ChemKED version\n    properties['chemked-version'] = __version__\n\n    return properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_reference(root):\n    reference = {}\n    elem = root.find('bibliographyLink')\n    if elem is None:\n        raise MissingElementError('bibliographyLink')\n\n    # Try to get reference info via DOI, fall back on preferredKey if necessary.\n    ref_doi = elem.get('doi', None)\n    ref_key = elem.get('preferredKey', None)\n\n    if ref_doi is not None:\n        try:\n            ref = crossref_api.works(ids=ref_doi)['message']\n        except (HTTPError, habanero.RequestError, ConnectionError):\n            if ref_key is None:\n                raise KeywordError('DOI not found and preferredKey attribute not set')\n            else:\n                warn('Missing doi attribute in bibliographyLink or lookup failed. '\n                     'Setting \"detail\" key as a fallback; please update to the appropriate fields.'\n                     )\n                reference['detail'] = ref_key\n                if reference['detail'][-1] != '.':\n                    reference['detail'] += '.'\n        else:\n            if ref_key is not None:\n                warn('Using DOI to obtain reference information, rather than preferredKey.')\n            reference['doi'] = elem.attrib['doi']\n            # Now get elements of the reference data\n            # Assume that the reference returned by the DOI lookup always has a container-title\n            reference['journal'] = ref.get('container-title')[0]\n            ref_year = ref.get('published-print') or ref.get('published-online')\n            reference['year'] = int(ref_year['date-parts'][0][0])\n            reference['volume'] = int(ref.get('volume'))\n            reference['pages'] = ref.get('page')\n            reference['authors'] = []\n            for author in ref['author']:\n                auth = {}\n                auth['name'] = ' '.join([author['given'], author['family']])\n                # Add ORCID if available\n                orcid = author.get('ORCID')\n                if orcid:\n                    auth['ORCID'] = orcid.lstrip('http://orcid.org/')\n                reference['authors'].append(auth)\n\n    elif ref_key is not None:\n        warn('Missing doi attribute in bibliographyLink. '\n             'Setting \"detail\" key as a fallback; please update to the appropriate fields.'\n             )\n        reference['detail'] = ref_key\n        if reference['detail'][-1] != '.':\n            reference['detail'] += '.'\n    else:\n        # Need one of DOI or preferredKey\n        raise MissingAttributeError('preferredKey', 'bibliographyLink')\n\n    return reference", "response": "Read reference information from the root of ReSpecTh XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_experiment_kind(root):\n    properties = {}\n    if root.find('experimentType').text == 'Ignition delay measurement':\n        properties['experiment-type'] = 'ignition delay'\n    else:\n        raise NotImplementedError(root.find('experimentType').text + ' not (yet) supported')\n\n    properties['apparatus'] = {'kind': '', 'institution': '', 'facility': ''}\n    kind = getattr(root.find('apparatus/kind'), 'text', False)\n    # Test for missing attribute or empty string\n    if not kind:\n        raise MissingElementError('apparatus/kind')\n    elif kind in ['shock tube', 'rapid compression machine']:\n        properties['apparatus']['kind'] = kind\n    else:\n        raise NotImplementedError(kind + ' experiment not (yet) supported')\n\n    return properties", "response": "Read common properties from root of ReSpecTh XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads common properties from the root of ReSpecTh XML file.", "response": "def get_common_properties(root):\n    \"\"\"Read common properties from root of ReSpecTh XML file.\n\n    Args:\n        root (`~xml.etree.ElementTree.Element`): Root of ReSpecTh XML file\n\n    Returns:\n        properties (`dict`): Dictionary with common properties\n    \"\"\"\n    properties = {}\n\n    for elem in root.iterfind('commonProperties/property'):\n        name = elem.attrib['name']\n\n        if name == 'initial composition':\n            properties['composition'] = {'species': [], 'kind': None}\n\n            for child in elem.iter('component'):\n                spec = {}\n                spec['species-name'] = child.find('speciesLink').attrib['preferredKey']\n                units = child.find('amount').attrib['units']\n\n                # use InChI for unique species identifier (if present)\n                try:\n                    spec['InChI'] = child.find('speciesLink').attrib['InChI']\n                except KeyError:\n                    # TODO: add InChI validator/search\n                    warn('Missing InChI for species ' + spec['species-name'])\n                    pass\n\n                # If mole or mass fraction, just set value\n                if units in ['mole fraction', 'mass fraction', 'mole percent']:\n                    spec['amount'] = [float(child.find('amount').text)]\n                elif units == 'percent':\n                    # assume this means mole percent\n                    warn('Assuming percent in composition means mole percent')\n                    spec['amount'] = [float(child.find('amount').text)]\n                    units = 'mole percent'\n                elif units == 'ppm':\n                    # assume molar ppm, convert to mole fraction\n                    warn('Assuming molar ppm in composition and converting to mole fraction')\n                    spec['amount'] = [float(child.find('amount').text) * 1.e-6]\n                    units = 'mole fraction'\n                elif units == 'ppb':\n                    # assume molar ppb, convert to mole fraction\n                    warn('Assuming molar ppb in composition and converting to mole fraction')\n                    spec['amount'] = [float(child.find('amount').text) * 1.e-9]\n                    units = 'mole fraction'\n                else:\n                    raise KeywordError('Composition units need to be one of: mole fraction, '\n                                       'mass fraction, mole percent, percent, ppm, or ppb.'\n                                       )\n\n                properties['composition']['species'].append(spec)\n\n                # check consistency of composition type\n                if properties['composition']['kind'] is None:\n                    properties['composition']['kind'] = units\n                elif properties['composition']['kind'] != units:\n                    raise KeywordError('composition units ' + units +\n                                       ' not consistent with ' +\n                                       properties['composition']['kind']\n                                       )\n\n        elif name in datagroup_properties:\n            field = name.replace(' ', '-')\n            units = elem.attrib['units']\n            if units == 'Torr':\n                units = 'torr'\n            quantity = 1.0 * unit_registry(units)\n            try:\n                quantity.to(property_units[field])\n            except pint.DimensionalityError:\n                raise KeywordError('units incompatible for property ' + name)\n\n            properties[field] = [' '.join([elem.find('value').text, units])]\n\n        else:\n            raise KeywordError('Property ' + name + ' not supported as common property')\n\n    return properties"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget ignition type and target information from a ReSpecTh XML file.", "response": "def get_ignition_type(root):\n    \"\"\"Gets ignition type and target.\n\n    Args:\n        root (`~xml.etree.ElementTree.Element`): Root of ReSpecTh XML file\n\n    Returns:\n        properties (`dict`): Dictionary with ignition type/target information\n    \"\"\"\n    properties = {}\n    elem = root.find('ignitionType')\n\n    if elem is None:\n        raise MissingElementError('ignitionType')\n    elem = elem.attrib\n\n    if 'target' in elem:\n        ign_target = elem['target'].rstrip(';').upper()\n    else:\n        raise MissingAttributeError('target', 'ignitionType')\n\n    if 'type' in elem:\n        ign_type = elem['type']\n        if ign_type == 'baseline max intercept from d/dt':\n            ign_type = 'd/dt max extrapolated'\n    else:\n        raise MissingAttributeError('type', 'ignitionType')\n\n    # ReSpecTh allows multiple ignition targets\n    if len(ign_target.split(';')) > 1:\n        raise NotImplementedError('Multiple ignition targets not supported.')\n\n    # Acceptable ignition targets include pressure, temperature, and species\n    # concentrations\n    if ign_target == 'OHEX':\n        ign_target = 'OH*'\n    elif ign_target == 'CHEX':\n        ign_target = 'CH*'\n    elif ign_target == 'P':\n        ign_target = 'pressure'\n    elif ign_target == 'T':\n        ign_target = 'temperature'\n\n    if ign_target not in ['pressure', 'temperature', 'OH', 'OH*', 'CH*', 'CH']:\n        raise KeywordError(ign_target + ' not valid ignition target')\n\n    if ign_type not in ['max', 'd/dt max', '1/2 max', 'min', 'd/dt max extrapolated']:\n        raise KeywordError(ign_type + ' not valid ignition type')\n\n    properties['type'] = ign_type\n    properties['target'] = ign_target\n\n    return properties"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_datapoints(root):\n    # Shock tube experiment will have one data group, while RCM may have one\n    # or two (one for ignition delay, one for volume-history)\n    dataGroups = root.findall('dataGroup')\n    if not dataGroups:\n        raise MissingElementError('dataGroup')\n\n    # all situations will have main experimental data in first dataGroup\n    dataGroup = dataGroups[0]\n    property_id = {}\n    unit_id = {}\n    species_id = {}\n    # get properties of dataGroup\n    for prop in dataGroup.findall('property'):\n        unit_id[prop.attrib['id']] = prop.attrib['units']\n        temp_prop = prop.attrib['name']\n        if temp_prop not in datagroup_properties + ['composition']:\n            raise KeyError(temp_prop + ' not valid dataPoint property')\n        property_id[prop.attrib['id']] = temp_prop\n\n        if temp_prop == 'composition':\n            spec = {'species-name': prop.find('speciesLink').attrib['preferredKey']}\n            # use InChI for unique species identifier (if present)\n            try:\n                spec['InChI'] = prop.find('speciesLink').attrib['InChI']\n            except KeyError:\n                # TODO: add InChI validator/search\n                warn('Missing InChI for species ' + spec['species-name'])\n                pass\n            species_id[prop.attrib['id']] = spec\n\n    if not property_id:\n        raise MissingElementError('property')\n\n    # now get data points\n    datapoints = []\n    for dp in dataGroup.findall('dataPoint'):\n        datapoint = {}\n        if 'composition' in property_id.values():\n            datapoint['composition'] = {'species': [], 'kind': None}\n\n        for val in dp:\n            # handle \"regular\" properties differently than composition\n            if property_id.get(val.tag) in datagroup_properties:\n                units = unit_id[val.tag]\n                if units == 'Torr':\n                    units = 'torr'\n                datapoint[property_id[val.tag].replace(' ', '-')] = [val.text + ' ' + units]\n            elif property_id.get(val.tag) == 'composition':\n                spec = {}\n                spec['species-name'] = species_id[val.tag]['species-name']\n                spec['InChI'] = species_id[val.tag].get('InChI')\n\n                units = unit_id[val.tag]\n                # If mole or mass fraction, just set value\n                if units in ['mole fraction', 'mass fraction', 'mole percent']:\n                    spec['amount'] = [float(val.text)]\n                elif units == 'percent':\n                    # assume this means mole percent\n                    warn('Assuming percent in composition means mole percent')\n                    spec['amount'] = [float(val.text)]\n                    units = 'mole percent'\n                elif units == 'ppm':\n                    # assume molar ppm, convert to mole fraction\n                    warn('Assuming molar ppm in composition and converting to mole fraction')\n                    spec['amount'] = [float(val.text) * 1.e-6]\n                    units = 'mole fraction'\n                elif units == 'ppb':\n                    # assume molar ppb, convert to mole fraction\n                    warn('Assuming molar ppb in composition and converting to mole fraction')\n                    spec['amount'] = [float(val.text) * 1.e-9]\n                    units = 'mole fraction'\n                else:\n                    raise KeywordError('composition units need to be one of: mole fraction, '\n                                       'mass fraction, mole percent, percent, ppm, or ppb.'\n                                       )\n\n                # check consistency of composition type\n                if datapoint['composition']['kind'] is None:\n                    datapoint['composition']['kind'] = units\n                elif datapoint['composition']['kind'] != units:\n                    raise KeywordError(\n                        'composition units ' + units +\n                        ' not consistent with ' + datapoint['composition']['kind']\n                        )\n\n                datapoint['composition']['species'].append(spec)\n            else:\n                raise KeywordError('value missing from properties: ' + val.tag)\n\n        datapoints.append(datapoint)\n\n    if len(datapoints) == 0:\n        raise MissingElementError('dataPoint')\n\n    # ReSpecTh files can have other dataGroups with pressure, volume, or temperature histories\n    if len(dataGroups) > 1:\n        datapoints[0]['time-histories'] = []\n        for dataGroup in dataGroups[1:]:\n            time_tag = None\n            quant_tags = []\n            quant_dicts = []\n            quant_types = []\n            for prop in dataGroup.findall('property'):\n                if prop.attrib['name'] == 'time':\n                    time_dict = {'units': prop.attrib['units'], 'column': 0}\n                    time_tag = prop.attrib['id']\n                elif prop.attrib['name'] in ['volume', 'temperature', 'pressure']:\n                    quant_types.append(prop.attrib['name'])\n                    quant_dicts.append({'units': prop.attrib['units'], 'column': 1})\n                    quant_tags.append(prop.attrib['id'])\n                else:\n                    raise KeywordError('Only volume, temperature, pressure, and time are allowed '\n                                       'in a time-history dataGroup.')\n\n            if time_tag is None or len(quant_tags) == 0:\n                raise KeywordError('Both time and quantity properties required for time-history.')\n\n            time_histories = [\n                {'time': time_dict, 'quantity': q, 'type': t, 'values': []}\n                for (q, t) in zip(quant_dicts, quant_types)\n            ]\n            # collect volume-time history\n            for dp in dataGroup.findall('dataPoint'):\n                time = None\n                quants = {}\n                for val in dp:\n                    if val.tag == time_tag:\n                        time = float(val.text)\n                    elif val.tag in quant_tags:\n                        quant = float(val.text)\n                        tag_idx = quant_tags.index(val.tag)\n                        quant_type = quant_types[tag_idx]\n                        quants[quant_type] = quant\n                    else:\n                        raise KeywordError('Value tag {} not found in dataGroup tags: '\n                                           '{}'.format(val.tag, quant_tags))\n                if time is None or len(quants) == 0:\n                    raise KeywordError('Both time and quantity values required in each '\n                                       'time-history dataPoint.')\n                for t in time_histories:\n                    t['values'].append([time, quants[t['type']]])\n\n            datapoints[0]['time-histories'].extend(time_histories)\n\n    return datapoints", "response": "Parse datapoints with ignition delay from file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReSpecTh_to_ChemKED(filename_xml, file_author='', file_author_orcid='', *, validate=False):\n    # get all information from XML file\n    tree = etree.parse(filename_xml)\n    root = tree.getroot()\n\n    # get file metadata\n    properties = get_file_metadata(root)\n\n    # get reference info\n    properties['reference'] = get_reference(root)\n    # Save name of original data filename\n    properties['reference']['detail'] = (properties['reference'].get('detail', '') +\n                                         'Converted from ReSpecTh XML file ' +\n                                         os.path.basename(filename_xml)\n                                         )\n\n    # Ensure ignition delay, and get which kind of experiment\n    properties.update(get_experiment_kind(root))\n\n    # Get properties shared across the file\n    properties['common-properties'] = get_common_properties(root)\n\n    # Determine definition of ignition delay\n    properties['common-properties']['ignition-type'] = get_ignition_type(root)\n\n    # Now parse ignition delay datapoints\n    properties['datapoints'] = get_datapoints(root)\n\n    # Ensure inclusion of pressure rise or volume history matches apparatus.\n    has_pres_rise = ('pressure-rise' in properties['common-properties'] or\n                     any([True for dp in properties['datapoints'] if 'pressure-rise' in dp])\n                     )\n    if has_pres_rise and properties['apparatus']['kind'] == 'rapid compression machine':\n        raise KeywordError('Pressure rise cannot be defined for RCM.')\n\n    has_vol_hist = any(\n        [t.get('type') == 'volume' for dp in properties['datapoints']\n         for t in dp.get('time-histories', [{}])]\n    )\n    if has_vol_hist and properties['apparatus']['kind'] == 'shock tube':\n        raise KeywordError('Volume history cannot be defined for shock tube.')\n\n    # add any additional file authors\n    if file_author_orcid and not file_author:\n        raise KeywordError('If file_author_orcid is specified, file_author must be as well')\n\n    if file_author:\n        temp_author = {'name': file_author}\n        if file_author_orcid:\n            temp_author['ORCID'] = file_author_orcid\n        properties['file-authors'].append(temp_author)\n\n    # Now go through datapoints and apply common properties\n    for idx in range(len(properties['datapoints'])):\n        for prop in properties['common-properties']:\n            properties['datapoints'][idx][prop] = properties['common-properties'][prop]\n\n    if validate:\n        chemked.ChemKED(dict_input=properties)\n\n    return properties", "response": "Convert a ReSpecTh XML file to ChemKED - compliant dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef respth2ck(argv=None):\n    parser = ArgumentParser(\n        description='Convert a ReSpecTh XML file to a ChemKED YAML file.'\n        )\n    parser.add_argument('-i', '--input',\n                        type=str,\n                        required=True,\n                        help='Input filename (e.g., \"file1.yaml\")'\n                        )\n    parser.add_argument('-o', '--output',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='Output filename (e.g., \"file1.xml\")'\n                        )\n    parser.add_argument('-fa', '--file-author',\n                        dest='file_author',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='File author name to override original'\n                        )\n    parser.add_argument('-fo', '--file-author-orcid',\n                        dest='file_author_orcid',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='File author ORCID'\n                        )\n\n    args = parser.parse_args(argv)\n\n    filename_ck = args.output\n    filename_xml = args.input\n\n    properties = ReSpecTh_to_ChemKED(filename_xml, args.file_author, args.file_author_orcid,\n                                     validate=True)\n\n    # set output filename and path\n    if not filename_ck:\n        filename_ck = os.path.join(os.path.dirname(filename_xml),\n                                   os.path.splitext(os.path.basename(filename_xml))[0] + '.yaml'\n                                   )\n\n    with open(filename_ck, 'w') as outfile:\n        yaml.dump(properties, outfile, default_flow_style=False)\n    print('Converted to ' + filename_ck)", "response": "Command - line entry point for converting a ReSpecTh XML file to a ChemKED YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ck2respth(argv=None):\n    parser = ArgumentParser(\n        description='Convert a ChemKED YAML file to a ReSpecTh XML file.'\n        )\n    parser.add_argument('-i', '--input',\n                        type=str,\n                        required=True,\n                        help='Input filename (e.g., \"file1.xml\")'\n                        )\n    parser.add_argument('-o', '--output',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='Output filename (e.g., \"file1.yaml\")'\n                        )\n\n    args = parser.parse_args(argv)\n\n    c = chemked.ChemKED(yaml_file=args.input)\n    c.convert_to_ReSpecTh(args.output)", "response": "Command - line entry point for converting a ChemKED YAML file to a ReSpecTh XML file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(argv=None):\n    parser = ArgumentParser(\n        description='Convert between ReSpecTh XML file and ChemKED YAML file '\n                    'automatically based on file extension.'\n        )\n    parser.add_argument('-i', '--input',\n                        type=str,\n                        required=True,\n                        help='Input filename (e.g., \"file1.yaml\" or \"file2.xml\")'\n                        )\n    parser.add_argument('-o', '--output',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='Output filename (e.g., \"file1.xml\" or \"file2.yaml\")'\n                        )\n    parser.add_argument('-fa', '--file-author',\n                        dest='file_author',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='File author name to override original'\n                        )\n    parser.add_argument('-fo', '--file-author-orcid',\n                        dest='file_author_orcid',\n                        type=str,\n                        required=False,\n                        default='',\n                        help='File author ORCID'\n                        )\n\n    args = parser.parse_args(argv)\n\n    if os.path.splitext(args.input)[1] == '.xml' and os.path.splitext(args.output)[1] == '.yaml':\n        respth2ck(['-i', args.input, '-o', args.output, '-fa', args.file_author,\n                   '-fo', args.file_author_orcid])\n\n    elif os.path.splitext(args.input)[1] == '.yaml' and os.path.splitext(args.output)[1] == '.xml':\n        c = chemked.ChemKED(yaml_file=args.input)\n        c.convert_to_ReSpecTh(args.output)\n\n    elif os.path.splitext(args.input)[1] == '.xml' and os.path.splitext(args.output)[1] == '.xml':\n        raise KeywordError('Cannot convert .xml to .xml')\n\n    elif os.path.splitext(args.input)[1] == '.yaml' and os.path.splitext(args.output)[1] == '.yaml':\n        raise KeywordError('Cannot convert .yaml to .yaml')\n\n    else:\n        raise KeywordError('Input/output args need to be .xml/.yaml')", "response": "This function is used to convert between ReSpecTh and ChemKED files based on file extension."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd user details to the request. META.", "response": "def process_exception(self, request, exception):\n        \"\"\"\n        Add user details.\n        \"\"\"\n        if request.user and hasattr(request.user, 'email'):\n            request.META['USER'] = request.user.email"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_response(self, request, response):\n        if response.status_code == 404 and not settings.DEBUG:\n            domain = request.get_host()\n            path = request.get_full_path()\n            referer = force_text(\n                request.META.get('HTTP_REFERER', ''), errors='replace')\n\n            if not self.is_ignorable_request(request, path, domain, referer):\n                ua = request.META.get('HTTP_USER_AGENT', '<none>')\n                ip = request.META.get('REMOTE_ADDR', '<none>')\n\n                user = None\n                if request.user and hasattr(request.user, 'email'):\n                    user = request.user.email\n                content = (\n                    \"Referrer: %s\\n\"\n                    \"Requested URL: %s\\n\"\n                    \"User agent: %s\\n\"\n                    \"IP address: %s\\n\"\n                    \"User: %s\\n\"\n                ) % (referer, path, ua, ip, user)\n                if self.is_internal_request(domain, referer):\n                    internal = 'INTERNAL '\n                else:\n                    internal = ''\n                mail_managers(\n                    \"Broken %slink on %s\" % (\n                        internal,\n                        domain\n                    ),\n                    content,\n                    fail_silently=True)\n        return response", "response": "Send broken link emails for relevant 404 NOT FOUND responses."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_internal_request(self, domain, referer):\n        # Different subdomains are treated as different domains.\n        return bool(re.match(\"^https?://%s/\" % re.escape(domain), referer))", "response": "Returns True if the referer is the same domain as the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_ignorable_request(self, request, uri, domain, referer):\n        # '?' in referer is identified as search engine source\n        if (not referer or (not self.is_internal_request(\n                domain, referer) and '?' in referer)):\n            return True\n        return any(\n            pattern.search(uri) for pattern in settings.IGNORABLE_404_URLS)", "response": "Returns True if the given request shouldn t notify the site managers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a duration string representation into a list of DurationRepresentation objects", "response": "def parse(self, representation):\n        \"\"\"Parses a duration string representation\n\n\n        :param  representation: duration as a string, example: '1d' (day),\n                                '34minutes' (minutes), '485s' (seconds)...\n        :type   representation: string\n\n        :returns: the parsed duration representation\n        :rtype: DurationRepresentation\n        \"\"\"\n        elements = extract_tokens(representation)\n\n        try:\n            scales = [DurationRepresentation(float(p[0]), Scale(p[1])) for p in elements]\n        except ValueError:\n            raise ScaleFormatError(\"Malformed duration representation: {0}\".format(representation))\n\n        return scales"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting or create an entry using obtained information from an IP.", "response": "def get_or_create_from_ip(ip):\n        \"\"\"\n        Get or create an entry using obtained information from an IP.\n\n        Args:\n            ip (str): IP address xxx.xxx.xxx.xxx.\n\n        Returns:\n            ip_info: an instance of IPInfo.\n        \"\"\"\n        data = ip_api_handler.get(ip)\n        if data and any(v for v in data.values()):\n            if data.get('ip_address', None) is None or not data['ip_address']:\n                data['ip_address'] = ip\n            return IPInfo.objects.get_or_create(**data)\n        return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the IP info object for the current user.", "response": "def update_ip_info(self, since_days=10, save=False, force=False):\n        \"\"\"\n        Update the IP info.\n\n        Args:\n            since_days (int): if checked less than this number of days ago,\n                don't check again (default to 10 days).\n            save (bool): whether to save anyway or not.\n            force (bool): whether to update ip_info to last checked one.\n\n        Returns:\n            bool: check was run. IPInfo might not have been updated.\n        \"\"\"\n        # If ip already checked\n        try:\n            last_check = IPInfoCheck.objects.get(\n                ip_address=self.client_ip_address)\n\n            # If checked less than since_days ago, don't check again\n            since_last = datetime.date.today() - last_check.date\n            if since_last <= datetime.timedelta(days=since_days):\n                if not self.ip_info or (\n                        self.ip_info != last_check.ip_info and force):\n                    self.ip_info = last_check.ip_info\n                    self.save()\n                    return True\n                elif save:\n                    self.save()\n                return False\n\n            # Get or create ip_info object\n            ip_info, created = IPInfo.get_or_create_from_ip(\n                self.client_ip_address)\n\n            # Update check time\n            last_check.date = datetime.date.today()\n            last_check.save()\n\n            # Maybe data changed\n            if created:\n                last_check.ip_info = ip_info\n                self.ip_info = ip_info\n                self.save()\n                return True\n            elif save:\n                self.save()\n\n            return False\n\n        except IPInfoCheck.DoesNotExist:\n            # Else if ip never checked, check it and set ip_info\n            self.ip_info = IPInfoCheck.check_ip(self.client_ip_address)\n            self.save()\n\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start_daemon():\n        if RequestLog.daemon is None:\n            parser = get_nginx_parser()\n            RequestLog.daemon = RequestLog.ParseToDBThread(parser, daemon=True)\n        RequestLog.daemon.start()\n        return RequestLog.daemon", "response": "Start a daemon thread to continuously read log files and append lines in DB."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a ChemKED instance from a ReSpecTh file.", "response": "def from_respecth(cls, filename_xml, file_author='', file_author_orcid=''):\n        \"\"\"Construct a ChemKED instance directly from a ReSpecTh file.\n\n        Arguments:\n            filename_xml (`str`): Filename of the ReSpecTh-formatted XML file to be imported\n            file_author (`str`, optional): File author to be added to the list generated from the\n                XML file\n            file_author_orcid (`str`, optional): ORCID for the file author being added to the list\n                of file authors\n\n        Returns:\n            `ChemKED`: Instance of the `ChemKED` class containing the data in ``filename_xml``.\n\n        Examples:\n            >>> ck = ChemKED.from_respecth('respecth_file.xml')\n            >>> ck = ChemKED.from_respecth('respecth_file.xml', file_author='Bryan W. Weber')\n            >>> ck = ChemKED.from_respecth('respecth_file.xml', file_author='Bryan W. Weber',\n                                           file_author_orcid='0000-0000-0000-0000')\n        \"\"\"\n        properties = ReSpecTh_to_ChemKED(filename_xml, file_author, file_author_orcid,\n                                         validate=False)\n        return cls(dict_input=properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_yaml(self, properties):\n        validator = OurValidator(schema)\n        if not validator.validate(properties):\n            for key, value in validator.errors.items():\n                if any(['unallowed value' in v for v in value]):\n                    print(('{key} has an illegal value. Allowed values are {values} and are case '\n                           'sensitive.').format(key=key, values=schema[key]['allowed']))\n\n            raise ValueError(validator.errors)", "response": "Validate the YAML file for adherance to the ChemKED format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Pandas DataFrame of the datapoints in this instance.", "response": "def get_dataframe(self, output_columns=None):\n        \"\"\"Get a Pandas DataFrame of the datapoints in this instance.\n\n        Arguments:\n            output_columns (`list`, optional): List of strings specifying the columns to include\n                in the output DataFrame. The default is `None`, which outputs all of the\n                columns. Options include (not case sensitive):\n\n                    * ``Temperature``\n                    * ``Pressure``\n                    * ``Ignition Delay``\n                    * ``Composition``\n                    * ``Equivalence Ratio``\n                    * ``Reference``\n                    * ``Apparatus``\n                    * ``Experiment Type``\n                    * ``File Author``\n                    * ``File Version``\n                    * ``ChemKED Version``\n\n                In addition, specific fields from the ``Reference`` and ``Apparatus`` attributes can\n                be included by specifying the name after a colon. These options are:\n\n                    * ``Reference:Volume``\n                    * ``Reference:Journal``\n                    * ``Reference:DOI``\n                    * ``Reference:Authors``\n                    * ``Reference:Detail``\n                    * ``Reference:Year``\n                    * ``Reference:Pages``\n                    * ``Apparatus:Kind``\n                    * ``Apparatus:Facility``\n                    * ``Apparatus:Institution``\n\n                Only the first author is printed when ``Reference`` or ``Reference:Authors`` is\n                selected because the whole author list may be quite long.\n\n        Note:\n            If the Composition is selected as an output type, the composition specified in the\n            `DataPoint` is used. No attempt is made to convert to a consistent basis; mole fractions\n            will remain mole fractions, mass fractions will remain mass fractions, and mole percent\n            will remain mole percent. Therefore, it is possible to end up with more than one type of\n            composition specification in a given column. However, if the composition is included\n            in the resulting dataframe, the type of each composition will be specified by the \"Kind\"\n            field in each row.\n\n        Examples:\n            >>> df = ChemKED(yaml_file).get_dataframe()\n            >>> df = ChemKED(yaml_file).get_dataframe(['Temperature', 'Ignition Delay'])\n\n        Returns:\n            `~pandas.DataFrame`: Contains the information regarding each point in the ``datapoints``\n                attribute\n        \"\"\"\n        import pandas as pd\n\n        valid_labels = [a.replace('_', ' ') for a in self.__dict__\n                        if not (a.startswith('__') or a.startswith('_'))\n                        ]\n        valid_labels.remove('datapoints')\n        valid_labels.extend(\n            ['composition', 'ignition delay', 'temperature', 'pressure', 'equivalence ratio']\n        )\n        ref_index = valid_labels.index('reference')\n        valid_labels[ref_index:ref_index + 1] = ['reference:' + a for a in Reference._fields]\n        app_index = valid_labels.index('apparatus')\n        valid_labels[app_index:app_index + 1] = ['apparatus:' + a for a in Apparatus._fields]\n        species_list = list(set(chain(*[list(d.composition.keys()) for d in self.datapoints])))\n\n        if output_columns is None or len(output_columns) == 0:\n            col_labels = valid_labels\n            comp_index = col_labels.index('composition')\n            col_labels[comp_index:comp_index + 1] = species_list + ['Composition:Kind']\n        else:\n            output_columns = [a.lower() for a in output_columns]\n            col_labels = []\n            for col in output_columns:\n                if col in valid_labels or col in ['reference', 'apparatus']:\n                    col_labels.append(col)\n                else:\n                    raise ValueError('{} is not a valid output column choice'.format(col))\n\n            if 'composition' in col_labels:\n                comp_index = col_labels.index('composition')\n                col_labels[comp_index:comp_index + 1] = species_list + ['Composition:Kind']\n            if 'reference' in col_labels:\n                ref_index = col_labels.index('reference')\n                col_labels[ref_index:ref_index + 1] = ['reference:' + a for a in Reference._fields]\n            if 'apparatus' in col_labels:\n                app_index = col_labels.index('apparatus')\n                col_labels[app_index:app_index + 1] = ['apparatus:' + a for a in Apparatus._fields]\n\n        data = []\n        for d in self.datapoints:\n            row = []\n            d_species = list(d.composition.keys())\n            for col in col_labels:\n                if col in species_list:\n                    if col in d_species:\n                        row.append(d.composition[col].amount)\n                    else:\n                        row.append(Q_(0.0, 'dimensionless'))\n                elif 'reference' in col or 'apparatus' in col:\n                    split_col = col.split(':')\n                    if split_col[1] == 'authors':\n                        row.append(getattr(getattr(self, split_col[0]), split_col[1])[0]['name'])\n                    else:\n                        row.append(getattr(getattr(self, split_col[0]), split_col[1]))\n                elif col in ['temperature', 'pressure', 'ignition delay', 'equivalence ratio']:\n                    row.append(getattr(d, col.replace(' ', '_')))\n                elif col == 'file authors':\n                    row.append(getattr(self, col.replace(' ', '_'))[0]['name'])\n                elif col == 'Composition:Kind':\n                    row.append(d.composition_type)\n                else:\n                    row.append(getattr(self, col.replace(' ', '_')))\n            data.append(row)\n\n        col_labels = [a.title() for a in col_labels]\n        columns = pd.Index(col_labels)\n        return pd.DataFrame(data=data, columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_file(self, filename, *, overwrite=False):\n        # Ensure file isn't already present\n        if exists(filename) and not overwrite:\n            raise OSError(filename + ' already present. Specify \"overwrite=True\" '\n                          'to overwrite, or rename.'\n                          )\n\n        with open(filename, 'w') as yaml_file:\n            yaml.dump(self._properties, yaml_file)", "response": "Write the object to a new ChemKED file based on the properties."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a ChemKED record to ReSpecTh XML file.", "response": "def convert_to_ReSpecTh(self, filename):\n        \"\"\"Convert ChemKED record to ReSpecTh XML file.\n\n        This converter uses common information in a ChemKED file to generate a\n        ReSpecTh XML file. Note that some information may be lost, as ChemKED stores\n        some additional attributes.\n\n        Arguments:\n            filename (`str`): Filename for output ReSpecTh XML file.\n\n        Example:\n            >>> dataset = ChemKED(yaml_file)\n            >>> dataset.convert_to_ReSpecTh(xml_file)\n        \"\"\"\n        root = etree.Element('experiment')\n\n        file_author = etree.SubElement(root, 'fileAuthor')\n        file_author.text = self.file_authors[0]['name']\n\n        # right now ChemKED just uses an integer file version\n        file_version = etree.SubElement(root, 'fileVersion')\n        major_version = etree.SubElement(file_version, 'major')\n        major_version.text = str(self.file_version)\n        minor_version = etree.SubElement(file_version, 'minor')\n        minor_version.text = '0'\n\n        respecth_version = etree.SubElement(root, 'ReSpecThVersion')\n        major_version = etree.SubElement(respecth_version, 'major')\n        major_version.text = '1'\n        minor_version = etree.SubElement(respecth_version, 'minor')\n        minor_version.text = '0'\n\n        # Only ignition delay currently supported\n        exp = etree.SubElement(root, 'experimentType')\n        if self.experiment_type == 'ignition delay':\n            exp.text = 'Ignition delay measurement'\n        else:\n            raise NotImplementedError('Only ignition delay type supported for conversion.')\n\n        reference = etree.SubElement(root, 'bibliographyLink')\n        citation = ''\n        for author in self.reference.authors:\n            citation += author['name'] + ', '\n        citation += (self.reference.journal + ' (' + str(self.reference.year) + ') ' +\n                     str(self.reference.volume) + ':' + self.reference.pages + '. ' +\n                     self.reference.detail\n                     )\n        reference.set('preferredKey', citation)\n        reference.set('doi', self.reference.doi)\n\n        apparatus = etree.SubElement(root, 'apparatus')\n        kind = etree.SubElement(apparatus, 'kind')\n        kind.text = self.apparatus.kind\n\n        common_properties = etree.SubElement(root, 'commonProperties')\n        # ChemKED objects have no common properties once loaded. Check for properties\n        # among datapoints that tend to be common\n        common = []\n        composition = self.datapoints[0].composition\n\n        # Composition type *has* to be the same\n        composition_type = self.datapoints[0].composition_type\n        if not all(dp.composition_type == composition_type for dp in self.datapoints):\n            raise NotImplementedError('Error: ReSpecTh does not support varying composition '\n                                      'type among datapoints.'\n                                      )\n\n        if all([composition == dp.composition for dp in self.datapoints]):\n            # initial composition is common\n            common.append('composition')\n            prop = etree.SubElement(common_properties, 'property')\n            prop.set('name', 'initial composition')\n\n            for species_name, species in composition.items():\n                component = etree.SubElement(prop, 'component')\n                species_link = etree.SubElement(component, 'speciesLink')\n                species_link.set('preferredKey', species_name)\n                if species.InChI is not None:\n                    species_link.set('InChI', species.InChI)\n\n                amount = etree.SubElement(component, 'amount')\n                amount.set('units', composition_type)\n                amount.text = str(species.amount.magnitude)\n\n        # If multiple datapoints present, then find any common properties. If only\n        # one datapoint, then composition should be the only \"common\" property.\n        if len(self.datapoints) > 1:\n            for prop_name in datagroup_properties:\n                attribute = prop_name.replace(' ', '_')\n                quantities = [getattr(dp, attribute, False) for dp in self.datapoints]\n\n                # All quantities must have the property in question and all the\n                # values must be equal\n                if all(quantities) and quantities.count(quantities[0]) == len(quantities):\n                    common.append(prop_name)\n                    prop = etree.SubElement(common_properties, 'property')\n                    prop.set('description', '')\n                    prop.set('name', prop_name)\n                    prop.set('units', str(quantities[0].units))\n\n                    value = etree.SubElement(prop, 'value')\n                    value.text = str(quantities[0].magnitude)\n\n        # Ignition delay can't be common, unless only a single datapoint.\n\n        datagroup = etree.SubElement(root, 'dataGroup')\n        datagroup.set('id', 'dg1')\n        datagroup_link = etree.SubElement(datagroup, 'dataGroupLink')\n        datagroup_link.set('dataGroupID', '')\n        datagroup_link.set('dataPointID', '')\n\n        property_idx = {}\n        labels = {'temperature': 'T', 'pressure': 'P',\n                  'ignition delay': 'tau', 'pressure rise': 'dP/dt',\n                  }\n\n        for prop_name in datagroup_properties:\n            attribute = prop_name.replace(' ', '_')\n            # This can't be hasattr because properties are set to the value None\n            # if no value is specified in the file, so the attribute always exists\n            prop_indices = [i for i, dp in enumerate(self.datapoints)\n                            if getattr(dp, attribute) is not None\n                            ]\n            if prop_name in common or not prop_indices:\n                continue\n\n            prop = etree.SubElement(datagroup, 'property')\n            prop.set('description', '')\n            prop.set('name', prop_name)\n            units = str(getattr(self.datapoints[prop_indices[0]], attribute).units)\n            prop.set('units', units)\n            idx = 'x{}'.format(len(property_idx) + 1)\n            property_idx[idx] = {'name': prop_name, 'units': units}\n            prop.set('id', idx)\n            prop.set('label', labels[prop_name])\n\n        # Need to handle datapoints with possibly different species in the initial composition\n        if 'composition' not in common:\n            for dp in self.datapoints:\n                for species in dp.composition.values():\n                    # Only add new property for species not already considered\n                    has_spec = any([species.species_name in d.values()\n                                    for d in property_idx.values()\n                                    ])\n                    if not has_spec:\n                        prop = etree.SubElement(datagroup, 'property')\n                        prop.set('description', '')\n\n                        idx = 'x{}'.format(len(property_idx) + 1)\n                        property_idx[idx] = {'name': species.species_name}\n                        prop.set('id', idx)\n                        prop.set('label', '[' + species.species_name + ']')\n                        prop.set('name', 'composition')\n                        prop.set('units', self.datapoints[0].composition_type)\n\n                        species_link = etree.SubElement(prop, 'speciesLink')\n                        species_link.set('preferredKey', species.species_name)\n                        if species.InChI is not None:\n                            species_link.set('InChI', species.InChI)\n\n        for dp in self.datapoints:\n            datapoint = etree.SubElement(datagroup, 'dataPoint')\n            for idx, val in property_idx.items():\n                # handle regular properties a bit differently than composition\n                if val['name'] in datagroup_properties:\n                    value = etree.SubElement(datapoint, idx)\n                    quantity = getattr(dp, val['name'].replace(' ', '_')).to(val['units'])\n                    value.text = str(quantity.magnitude)\n                else:\n                    # composition\n                    for item in dp.composition.values():\n                        if item.species_name == val['name']:\n                            value = etree.SubElement(datapoint, idx)\n                            value.text = str(item.amount.magnitude)\n\n        # See https://stackoverflow.com/a/16097112 for the None.__ne__\n        history_types = ['volume_history', 'temperature_history', 'pressure_history',\n                         'piston_position_history', 'light_emission_history',\n                         'OH_emission_history', 'absorption_history']\n        time_histories = [getattr(dp, p) for dp in self.datapoints for p in history_types]\n        time_histories = list(filter(None.__ne__, time_histories))\n\n        if len(self.datapoints) > 1 and len(time_histories) > 1:\n            raise NotImplementedError('Error: ReSpecTh files do not support multiple datapoints '\n                                      'with a time history.')\n        elif len(time_histories) > 0:\n            for dg_idx, hist in enumerate(time_histories):\n                if hist.type not in ['volume', 'temperature', 'pressure']:\n                    warn('The time-history type {} is not supported by ReSpecTh for '\n                         'ignition delay experiments'.format(hist.type))\n                    continue\n\n                datagroup = etree.SubElement(root, 'dataGroup')\n                datagroup.set('id', 'dg{}'.format(dg_idx))\n                datagroup_link = etree.SubElement(datagroup, 'dataGroupLink')\n                datagroup_link.set('dataGroupID', '')\n                datagroup_link.set('dataPointID', '')\n\n                # Time history has two properties: time and quantity.\n                prop = etree.SubElement(datagroup, 'property')\n                prop.set('description', '')\n                prop.set('name', 'time')\n                prop.set('units', str(hist.time.units))\n                time_idx = 'x{}'.format(len(property_idx) + 1)\n                property_idx[time_idx] = {'name': 'time'}\n                prop.set('id', time_idx)\n                prop.set('label', 't')\n\n                prop = etree.SubElement(datagroup, 'property')\n                prop.set('description', '')\n                prop.set('name', hist.type)\n                prop.set('units', str(hist.quantity.units))\n                quant_idx = 'x{}'.format(len(property_idx) + 1)\n                property_idx[quant_idx] = {'name': hist.type}\n                prop.set('id', quant_idx)\n                prop.set('label', 'V')\n\n                for time, quantity in zip(hist.time, hist.quantity):\n                    datapoint = etree.SubElement(datagroup, 'dataPoint')\n                    value = etree.SubElement(datapoint, time_idx)\n                    value.text = str(time.magnitude)\n                    value = etree.SubElement(datapoint, quant_idx)\n                    value.text = str(quantity.magnitude)\n\n        ign_types = [getattr(dp, 'ignition_type', False) for dp in self.datapoints]\n        # All datapoints must have the same ignition target and type\n        if all(ign_types) and ign_types.count(ign_types[0]) == len(ign_types):\n            # In ReSpecTh files all datapoints must share ignition type\n            ignition = etree.SubElement(root, 'ignitionType')\n            if ign_types[0]['target'] in ['pressure', 'temperature']:\n                ignition.set('target', ign_types[0]['target'][0].upper())\n            else:\n                # options left are species\n                ignition.set('target', self.datapoints[0].ignition_type['target'])\n            if ign_types[0]['type'] == 'd/dt max extrapolated':\n                ignition.set('type', 'baseline max intercept from d/dt')\n            else:\n                ignition.set('type', self.datapoints[0].ignition_type['type'])\n        else:\n            raise NotImplementedError('Different ignition targets or types for multiple datapoints '\n                                      'are not supported in ReSpecTh.')\n\n        et = etree.ElementTree(root)\n        et.write(filename, encoding='utf-8', xml_declaration=True)\n\n        # now do a \"pretty\" rewrite\n        xml = minidom.parse(filename)\n        xml_string = xml.toprettyxml(indent='    ')\n        with open(filename, 'w') as f:\n            f.write(xml_string)\n\n        print('Converted to ' + filename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_quantity(self, properties):\n        quant = Q_(properties[0])\n        if len(properties) > 1:\n            unc = properties[1]\n            uncertainty = unc.get('uncertainty', False)\n            upper_uncertainty = unc.get('upper-uncertainty', False)\n            lower_uncertainty = unc.get('lower-uncertainty', False)\n            uncertainty_type = unc.get('uncertainty-type')\n            if uncertainty_type == 'relative':\n                if uncertainty:\n                    quant = quant.plus_minus(float(uncertainty), relative=True)\n                elif upper_uncertainty and lower_uncertainty:\n                    warn('Asymmetric uncertainties are not supported. The '\n                         'maximum of lower-uncertainty and upper-uncertainty '\n                         'has been used as the symmetric uncertainty.')\n                    uncertainty = max(float(upper_uncertainty), float(lower_uncertainty))\n                    quant = quant.plus_minus(uncertainty, relative=True)\n                else:\n                    raise ValueError('Either \"uncertainty\" or \"upper-uncertainty\" and '\n                                     '\"lower-uncertainty\" need to be specified.')\n            elif uncertainty_type == 'absolute':\n                if uncertainty:\n                    uncertainty = Q_(uncertainty)\n                    quant = quant.plus_minus(uncertainty.to(quant.units).magnitude)\n                elif upper_uncertainty and lower_uncertainty:\n                    warn('Asymmetric uncertainties are not supported. The '\n                         'maximum of lower-uncertainty and upper-uncertainty '\n                         'has been used as the symmetric uncertainty.')\n                    uncertainty = max(Q_(upper_uncertainty), Q_(lower_uncertainty))\n                    quant = quant.plus_minus(uncertainty.to(quant.units).magnitude)\n                else:\n                    raise ValueError('Either \"uncertainty\" or \"upper-uncertainty\" and '\n                                     '\"lower-uncertainty\" need to be specified.')\n            else:\n                raise ValueError('uncertainty-type must be one of \"absolute\" or \"relative\"')\n\n        return quant", "response": "Process the uncertainty information from a given quantity and return it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cantera_composition_string(self, species_conversion=None):\n        if self.composition_type in ['mole fraction', 'mass fraction']:\n            factor = 1.0\n        elif self.composition_type == 'mole percent':\n            factor = 100.0\n        else:\n            raise ValueError('Unknown composition type: {}'.format(self.composition_type))\n\n        if species_conversion is None:\n            comps = ['{!s}:{:.4e}'.format(c.species_name,\n                     c.amount.magnitude/factor) for c in self.composition.values()]\n        else:\n            comps = []\n            for c in self.composition.values():\n                amount = c.amount.magnitude/factor\n                idents = [getattr(c, s, False) for s in ['species_name', 'InChI', 'SMILES']]\n                present = [i in species_conversion for i in idents]\n                if not any(present):\n                    comps.append('{!s}:{:.4e}'.format(c.species_name, amount))\n                else:\n                    if len([i for i in present if i]) > 1:\n                        raise ValueError('More than one conversion present for species {}'.format(\n                                         c.species_name))\n\n                    ident = idents[present.index(True)]\n                    species_replacement_name = species_conversion.pop(ident)\n                    comps.append('{!s}:{:.4e}'.format(species_replacement_name, amount))\n\n            if len(species_conversion) > 0:\n                raise ValueError('Unknown species in conversion: {}'.format(species_conversion))\n\n        return ', '.join(comps)", "response": "Get the composition in a string suitable for input to Cantera."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the mole fractions in a string format suitable for input to Cantera.", "response": "def get_cantera_mole_fraction(self, species_conversion=None):\n        \"\"\"Get the mole fractions in a string format suitable for input to Cantera.\n\n        Arguments:\n            species_conversion (`dict`, optional): Mapping of species identifier to a\n                species name. This argument should be supplied when the name of the\n                species in the ChemKED YAML file does not match the name of the same\n                species in a chemical kinetic mechanism. The species identifier (the key\n                of the mapping) can be the name, InChI, or SMILES provided in the ChemKED\n                file, while the value associated with a key should be the desired name in\n                the Cantera format output string.\n\n        Returns:\n            `str`: String of mole fractions in the ``SPEC:AMT, SPEC:AMT`` format\n\n        Raises:\n            `ValueError`: If the composition type is ``'mass fraction'``, the conversion cannot\n                be done because no molecular weight information is known\n\n        Examples:\n            >>> dp = DataPoint(properties)\n            >>> dp.get_cantera_mole_fraction()\n            'H2:4.4400e-03, O2:5.5600e-03, Ar:9.9000e-01'\n            >>> species_conversion = {'H2': 'h2', 'O2': 'o2'}\n            >>> dp.get_cantera_mole_fraction(species_conversion)\n            'h2:4.4400e-03, o2:5.5600e-03, Ar:9.9000e-01'\n            >>> species_conversion = {'1S/H2/h1H': 'h2', '1S/O2/c1-2': 'o2'}\n            >>> dp.get_cantera_mole_fraction(species_conversion)\n            'h2:4.4400e-03, o2:5.5600e-03, Ar:9.9000e-01'\n        \"\"\"\n        if self.composition_type == 'mass fraction':\n            raise ValueError('Cannot get mole fractions from the given composition.\\n'\n                             '{}'.format(self.composition))\n        else:\n            return self.get_cantera_composition_string(species_conversion)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the mass fractions in a string format suitable for input to Cantera.", "response": "def get_cantera_mass_fraction(self, species_conversion=None):\n        \"\"\"Get the mass fractions in a string format suitable for input to Cantera.\n\n        Arguments:\n            species_conversion (`dict`, optional): Mapping of species identifier to a\n                species name. This argument should be supplied when the name of the\n                species in the ChemKED YAML file does not match the name of the same\n                species in a chemical kinetic mechanism. The species identifier (the key\n                of the mapping) can be the name, InChI, or SMILES provided in the ChemKED\n                file, while the value associated with a key should be the desired name in\n                the Cantera format output string.\n\n        Returns:\n            `str`: String of mass fractions in the ``SPEC:AMT, SPEC:AMT`` format\n\n        Raises:\n            `ValueError`: If the composition type is ``'mole fraction'`` or\n                ``'mole percent'``, the conversion cannot be done because no molecular\n                weight information is known\n\n        Examples:\n            >>> dp = DataPoint(properties)\n            >>> dp.get_cantera_mass_fraction()\n            'H2:2.2525e-04, O2:4.4775e-03, Ar:9.9530e-01'\n            >>> species_conversion = {'H2': 'h2', 'O2': 'o2'}\n            >>> dp.get_cantera_mass_fraction(species_conversion)\n            'h2:2.2525e-04, o2:4.4775e-03, Ar:9.9530e-01'\n            >>> species_conversion = {'1S/H2/h1H': 'h2', '1S/O2/c1-2': 'o2'}\n            >>> dp.get_cantera_mass_fraction(species_conversion)\n            'h2:2.2525e-04, o2:4.4775e-03, Ar:9.9530e-01'\n        \"\"\"\n        if self.composition_type in ['mole fraction', 'mole percent']:\n            raise ValueError('Cannot get mass fractions from the given composition.\\n'\n                             '{}'.format(self.composition)\n                             )\n        else:\n            return self.get_cantera_composition_string(species_conversion)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_username(identifier):\n    pattern = re.compile('.+@\\w+\\..+')\n    if pattern.match(identifier):\n        try:\n            user = User.objects.get(email=identifier)\n        except:\n            raise Http404\n        else:\n            return user.username\n    else:\n        return identifier", "response": "Checks if a string is an email adress or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a payload with no none values.", "response": "def _create_payload(self, symbols):\n        \"\"\" Creates a payload with no none values.\n\n        :param symbols: currency symbols to request specific exchange rates.\n        :type symbols: list or tuple\n        :return: a payload.\n        :rtype: dict\n        \"\"\"\n        payload = {'access_key': self.access_key}\n        if symbols is not None:\n            payload['symbols'] = ','.join(symbols)\n\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef historical_rates(self, date, symbols=None):\n        try:\n            if isinstance(date, datetime.date):\n                # Convert date to ISO 8601 format.\n                date = date.isoformat()\n\n            symbols = symbols or self.symbols\n            payload = self._create_payload(symbols)\n\n            url = BASE_URL + date\n\n            response = requests.get(url, params=payload)\n\n            response.raise_for_status()\n\n            return response.json()\n        except requests.exceptions.RequestException as ex:\n            raise FixerioException(str(ex))", "response": "Get historical rates for any day since a given date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a pip requirements file", "response": "def parse_requirements(filename):\n    \"\"\" load requirements from a pip requirements file \"\"\"\n    with open(filename, 'r') as f:\n        lineiter = list(line.strip() for line in f)\n    return [line for line in lineiter if line and not line.startswith(\"#\")]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_state(self):\n        '''\n        :DEPRECATED:\n        Periodically save the state of the environment and the agents.\n        '''\n        self._save_state()\n        while self.peek() != simpy.core.Infinity:\n            delay = max(self.peek() - self.now, self.interval)\n            utils.logger.debug('Step: {}'.format(self.now))\n            ev = self.event()\n            ev._ok = True\n            # Schedule the event with minimum priority so\n            # that it executes before all agents\n            self.schedule(ev, -999, delay)\n            yield ev\n            self._save_state()", "response": "Yields the state of the environment and agents."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the unique entries in the list l.", "response": "def distinct(l):\n    \"\"\"\n    Return a list where the duplicates have been removed.\n\n    Args:\n        l (list): the list to filter.\n\n    Returns:\n        list: the same list without duplicates.\n    \"\"\"\n    seen = set()\n    seen_add = seen.add\n    return (_ for _ in l if not (_ in seen or seen_add(_)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_format_modules(lang):\n    if check_for_language(lang):\n        format_locations = []\n        for path in CUSTOM_FORMAT_MODULE_PATHS:\n            format_locations.append(path + '.%s')\n        format_locations.append('django.conf.locale.%s')\n        locale = to_locale(lang)\n        locales = [locale]\n        if '_' in locale:\n            locales.append(locale.split('_')[0])\n        for location in format_locations:\n            for loc in locales:\n                try:\n                    yield import_module('.formats', location % loc)\n                except ImportError:\n                    pass", "response": "Iterates over all format modules in the given language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_format_modules(lang=None, reverse=False):\n    if lang is None:\n        lang = get_language()\n    modules = _format_modules_cache.setdefault(lang, list(\n        iter_format_modules(lang)))\n    if reverse:\n        return list(reversed(modules))\n    return modules", "response": "Returns a list of the format modules found in the given language."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_format(format_type, lang=None, use_l10n=None):\n    format_type = str_encode(format_type)\n    if use_l10n or (use_l10n is None and settings.USE_L10N):\n        if lang is None:\n            lang = get_language()\n        cache_key = (format_type, lang)\n        try:\n            cached = _format_cache[cache_key]\n            if cached is not None:\n                return cached\n            else:\n                # Return the general setting by default\n                return getattr(settings, format_type)\n        except KeyError:\n            for module in get_format_modules(lang):\n                try:\n                    val = getattr(module, format_type)\n                    for iso_input in ISO_INPUT_FORMATS.get(format_type, ()):\n                        if iso_input not in val:\n                            if isinstance(val, tuple):\n                                val = list(val)\n                            val.append(iso_input)\n                    _format_cache[cache_key] = val\n                    return val\n                except AttributeError:\n                    pass\n            _format_cache[cache_key] = None\n    return getattr(settings, format_type)", "response": "Returns the format for a specific format type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef word(self, word, url='https://api.shanbay.com/bdc/search/'):\n        params = {\n            'word': word\n        }\n        return self._request(url, params=params).json()", "response": "Search for a single word in Shanbay"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd word to a user s list", "response": "def add_word(self, word_id, url='https://api.shanbay.com/bdc/learning/'):\n        \"\"\"\u6dfb\u52a0\u5355\u8bcd\"\"\"\n        data = {\n            'id': word_id\n        }\n        return self._request(url, method='post', data=data).json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets examples for a given word", "response": "def examples(self, word_id, type=None,\n                 url='https://api.shanbay.com/bdc/example/'):\n        \"\"\"\u83b7\u53d6\u5355\u8bcd\u7684\u4f8b\u53e5\"\"\"\n        params = {\n            'vocabulary_id': word_id\n        }\n        if type is not None:\n            params['type'] = type\n        return self._request(url, params=params).json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an example to a user s list of words", "response": "def add_example(self, word_id, original, translation,\n                    url='https://api.shanbay.com/bdc/example/'):\n        \"\"\"\u521b\u5efa\u4f8b\u53e5\"\"\"\n        data = {\n            'vocabulary': word_id,\n            'original': original,\n            'translation': translation\n        }\n        return self._request(url, method='post', data=data).json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete an example from Shanbay", "response": "def delete_example(self, example_id,\n                       url='https://api.shanbay.com/bdc/example/{example_id}/'):\n        \"\"\"\u5220\u9664\u4f8b\u53e5\"\"\"\n        url = url.format(example_id=example_id)\n        return self._request(url, method='delete').json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef notes(self, word_id, url='https://api.shanbay.com/bdc/note/'):\n        params = {\n            'vocabulary_id': word_id\n        }\n        return self._request(url, params=params).json()", "response": "Get a list of notes for a given word"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_note(self, word_id, note,\n                 url='https://api.shanbay.com/bdc/note/'):\n        \"\"\"\u521b\u5efa\u7b14\u8bb0\"\"\"\n        data = {\n            'vocabulary': word_id,\n            'note': note\n        }\n        return self._request(url, method='post', data=data).json()", "response": "add a note to a user s list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_note(self, note_id,\n                    url='https://api.shanbay.com/bdc/note/{note_id}/'):\n        \"\"\"\u5220\u9664\u7b14\u8bb0\"\"\"\n        url = url.format(note_id=note_id)\n        return self._request(url, method='delete').json()", "response": "Delete a note from Shanbay"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, str_representation):\n        for scale in self.SCALES:\n            if str_representation in scale:\n                return scale\n        raise ScaleFormatError(\"Unsupported scale format: {0}\".format(str_representation))", "response": "Retrieves a scale representation from it s string representation"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a JSON response for the given context", "response": "def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a JSON response, transforming 'context' to make the payload.\n\n        \"\"\"\n        response_kwargs['content_type'] = 'application/json'\n        return self.response_class(\n            self.convert_context_to_json(context),\n            **response_kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasserts a provided string is a valid duration token representation", "response": "def valid_token(token):\n    \"\"\"Asserts a provided string is a valid duration token representation\n\n    :param  token: duration representation token\n    :type   token: string\n    \"\"\"\n    is_scale = False\n\n    # Check if the token represents a scale\n    # If it doesn't set a flag accordingly\n    try:\n        Scale(token)\n        is_scale = True\n    except ScaleFormatError:\n        pass\n\n    # If token either represents a numerical value, a\n    # separator token, or a scale, it is considered valid\n    if any([token.isdigit(), token in SEPARATOR_TOKENS, is_scale]):\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract tokens from a duration representation.", "response": "def extract_tokens(representation, separators=SEPARATOR_CHARACTERS):\n    \"\"\"Extracts durations tokens from a duration representation.\n\n    Parses the string representation incrementaly and raises\n    on first error met.\n\n    :param  representation: duration representation\n    :type   representation: string\n    \"\"\"\n    buff = \"\"\n    elements = []\n    last_index = 0\n    last_token = None\n\n    for index, c in enumerate(representation):\n        # if separator character is found, push\n        # the content of the buffer in the elements list\n        if c in separators:\n            if buff:\n                # If the last found token is invalid,\n                # raise and InvalidTokenError\n                if not valid_token(buff):\n                    raise InvalidTokenError(\n                        \"Duration representation {0} contains \"\n                        \"an invalid token: {1}\".format(representation, buff)\n                    )\n\n                # If buffer content is a separator word, for example\n                # \"and\", just ignore it\n                if not buff.strip() in SEPARATOR_TOKENS:\n                    elements.append(buff)\n\n            # Anyway, reset buffer and last token marker\n            # to their zero value\n            buff = \"\"\n            last_token = None\n        else:\n            token = compute_char_token(c)\n            if (token is not None and last_token is not None and token != last_token):\n                elements.append(buff)\n                buff = c\n            else:\n                buff += c\n\n            last_token = token\n\n    # push the content left in representation\n    # in the elements list\n    elements.append(buff)\n\n    return list(zip(elements[::2], elements[1::2]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_random_string(length=7, chars='ABCDEFGHJKMNPQRSTUVWXYZ23456789',\n                         repetitions=False):\n    \"\"\"\n    Returns a random string, based on the provided arguments.\n\n    It returns capital letters and numbers by default.\n    Ambiguous characters are left out, repetitions will be avoided.\n\n    \"\"\"\n    if repetitions:\n        return ''.join(random.choice(chars) for _ in range(length))\n    return ''.join(random.sample(chars, length))", "response": "Returns a random string based on the provided arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_member(fqn):\n    modulename, member_name = split_fqn(fqn)\n    module = __import__(modulename, globals(), locals(), member_name)\n    return getattr(module, member_name)", "response": "Loads and returns a class for a given fully qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_fqn(fqn):\n    if hasattr(fqn, '__call__'):\n        fqn_string = fqn()\n    else:\n        fqn_string = fqn\n    return fqn_string.rsplit('.', 1)", "response": "Returns the left and right part of the import."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef info(self):\n        html = self.request(self.team_url).text\n        soup = BeautifulSoup(html)\n        team_header = soup.find_all(class_='team-header')[0]\n\n        # \u6807\u9898\n        title = team_header.find_all(class_='title')[0].text.strip()\n        # \u7ec4\u957f\n        leader = team_header.find_all(class_='leader'\n                                      )[0].find_all('a')[0].text.strip()\n        # \u521b\u5efa\u65f6\u95f4\n        date_str = team_header.find_all(class_='date')[0].text.strip()\n        date_created = datetime.datetime.strptime(date_str, '%Y/%m/%d')\n        # \u6392\u540d\n        team_stat = soup.find_all(class_='team-stat')[0]\n        _str = team_stat.find_all(class_='rank')[0].text.strip()\n        rank = int(re.findall(r'\\d+$', _str)[0])\n        # \u6210\u5458\u6570\n        _str = team_stat.find_all(class_='size')[0].text.strip()\n        number, max_number = map(int, re.findall(r'(\\d+)/(\\d+)$', _str)[0])\n        # \u6253\u5361\u7387\n        _str = team_stat.find_all(class_='rate')[0].text.strip()\n        rate = float(re.findall(r'(\\d+\\.?(?:\\d+)?)%$', _str)[0])\n        # \u603b\u6210\u957f\u503c\n        _str = team_stat.find_all(class_='points')[0].text.strip()\n        points = int(re.findall(r'\\d+$', _str)[0])\n\n        return {\n            'title': title,\n            'leader': leader,\n            'date_created': date_created,\n            'rank': rank,\n            'number': number,\n            'max_number': max_number,\n            'rate': rate,\n            'points': points\n        }", "response": "Get info about the current nation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the limit of the current referral.", "response": "def update_limit(self, days, kind=2, condition='>='):\n        \"\"\"\u66f4\u65b0\u6210\u5458\u52a0\u5165\u6761\u4ef6\n\n        :rtype: bool\n        \"\"\"\n        url = 'http://www.shanbay.com/team/setqualification/%s' % self.team_id\n        data = {\n            'kind': kind,\n            'condition': condition,\n            'value': days,\n            'team': self.team_id,\n            'csrfmiddlewaretoken': self._request.cookies.get('csrftoken')\n        }\n        r = self.request(url, 'post', data=data)\n        return r.url == 'http://www.shanbay.com/referral/invite/?kind=team'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef members(self):\n        all_members = []\n        for page in range(1, self.max_page() + 1):\n            all_members.extend(self.single_page_members(page))\n        return all_members", "response": "get all members of the page"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of members from a single page.", "response": "def single_page_members(self, page_number=1):\n        \"\"\"\u83b7\u53d6\u5355\u4e2a\u9875\u9762\u5185\u7684\u5c0f\u7ec4\u6210\u5458\u4fe1\u606f\n\n        :param page_number: \u9875\u7801\n        :return: \u5305\u542b\u5c0f\u7ec4\u6210\u5458\u4fe1\u606f\u7684\u5217\u8868\n\n        \u8fd4\u56de\u503c\u793a\u4f8b: ::\n\n            [{\n                'id': 123,                  # member_id\n                'username': 'jim',          # username\n                'nickname': 'Jim',          # \u6635\u79f0\n                'role': u'\u5c0f\u7ec4\u957f',          # \u8eab\u4efd\n                'points': 1234,             # \u8d21\u732e\u6210\u957f\u503c\n                'days': 100,                # \u7ec4\u9f84\n                'rate': 99.9,               # \u6253\u5361\u7387\n                'checked_yesterday': True,  # \u6628\u5929\u662f\u5426\u6253\u5361\n                'checked': False,           # \u4eca\u5929\u662f\u5426\u6253\u5361\n            }, {\n                # ...\n            }]\n\n\n        \"\"\"\n        url = '%s?page=%s' % (self.dismiss_url, page_number)\n        html = self.request(url).text\n        soup = BeautifulSoup(html)\n        members_html = soup.find(id='members')\n        if not members_html:\n            return []\n\n        def get_tag_string(html, class_, tag='td', n=0):\n            \"\"\"\u83b7\u53d6\u5355\u4e2a tag \u7684\u6587\u672c\u6570\u636e\"\"\"\n            return html.find_all(tag, class_=class_)[n].get_text().strip()\n\n        members = []\n        # \u83b7\u53d6\u6210\u5458\u4fe1\u606f\n        for member_html in members_html.find_all('tr', class_='member'):\n            _id = member_html.attrs['data-id']\n            try:\n                user_url = member_html.find_all('td', class_='user'\n                                                )[0].find('a').attrs['href']\n                username = self.get_username('http://www.shanbay.com'\n                                             + user_url)\n            except Exception as e:\n                logger.exception(e)\n                username = ''\n            try:\n                nickname = get_tag_string(member_html, 'nickname', 'a')\n            except Exception as e:\n                logger.exception(e)\n                nickname = username\n            try:\n                role = member_html.find_all('td', class_='user'\n                                            )[0].find_all('span', class_='label'\n                                                          )[0].get_text().strip()\n            except IndexError:\n                role = ''\n            except Exception as e:\n                logger.exception(e)\n                role = ''\n\n            member = {\n                'id': int(_id),\n                'username': username,\n                # \u6635\u79f0\n                'nickname': nickname,\n                # \u8eab\u4efd\n                'role': role,\n                # \u8d21\u732e\u6210\u957f\u503c\n                'points': int(get_tag_string(member_html, 'points')),\n                # \u7ec4\u9f84\n                'days': int(get_tag_string(member_html, 'days')),\n                # \u6253\u5361\u7387\n                'rate': float(get_tag_string(member_html, 'rate'\n                                             ).split('%')[0]),\n                # \u6628\u5929\u662f\u5426\u6253\u5361\n                'checked_yesterday': get_tag_string(member_html, 'checked'\n                                                    ) != '\u672a\u6253\u5361',\n                # \u4eca\u5929\u662f\u5426\u6253\u5361\n                'checked': get_tag_string(member_html, 'checked',\n                                          n=1) != '\u672a\u6253\u5361',\n            }\n            members.append(member)\n        return members"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dismiss(self, member_ids):\n        url = 'http://www.shanbay.com/api/v1/team/member/'\n        data = {\n            'action': 'dispel',\n        }\n        if isinstance(member_ids, (list, tuple)):\n            data['ids'] = ','.join(map(str, member_ids))\n        else:\n            data['ids'] = member_ids\n        r = self.request(url, 'put', data=data)\n        try:\n            return r.json()['msg'] == \"SUCCESS\"\n        except Exception as e:\n            logger.exception(e)\n            return False", "response": "Dismiss a set of members from the shanbay."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new topic", "response": "def new_topic(self, title, content):\n        \"\"\"\u5c0f\u7ec4\u53d1\u8d34\n\n        :return: \u5e16\u5b50 id \u6216 ``None``\n        \"\"\"\n        data = {\n            'title': title,\n            'body': content,\n            'csrfmiddlewaretoken': self._request.cookies.get('csrftoken')\n        }\n        url = 'http://www.shanbay.com/api/v1/forum/%s/thread/' % self.forum_id()\n        r = self.request(url, 'post', data=data)\n        j = r.json()\n        if j['status_code'] == 0:\n            return j['data']['thread']['id']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reply_topic(self, topic_id, content):\n        data = {\n            'body': content,\n            'csrfmiddlewaretoken': self._request.cookies.get('csrftoken')\n        }\n        url = 'http://www.shanbay.com/api/v1/forum/thread/%s/post/' % topic_id\n        r = self.request(url, 'post', data=data)\n        j = r.json()\n        if j['status_code'] == 0:\n            return j['data']['thread']['id']", "response": "reply to a topic"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to the server.", "response": "def connect(self, origin=None):\n        \"\"\"\n        Connects to the server.\n\n        :param origin: (Optional) The origin.\n        \"\"\"\n        self.logger.debug('Establish connection...')\n\n        if self.connected:\n            self.logger.warning('Connection already established. Return...')\n            return\n\n        if origin is not None:\n            self.origin = origin\n\n        self.auto_reconnect = True\n\n        self.ws_thread = threading.Thread(\n            name=\"APIConnectionThread_{}\".format(uuid.uuid1()),\n            target=self._run_forever)\n        self.ws_thread.daemon = True\n        self.ws_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disconnect(self):\n        self.logger.debug('Close connection...')\n\n        self.auto_reconnect = False\n\n        if self.websocket is not None:\n            self.websocket.close()", "response": "Closes the connection to the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, data):\n        self.logger.debug('Send data: {}'.format(data))\n\n        if not self.connected:\n            self.logger.warning('Connection not established. Return...')\n            return\n\n        self.websocket.send(json.dumps(data))", "response": "Sends data to the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall aways when a message arrives.", "response": "def _on_message(self, socket, message):\n        \"\"\"\n        Called aways when a message arrives.\n        \"\"\"\n        data = json.loads(message)\n        message_type = None\n        identifier = None\n        subscription = None\n\n        if 'type' in data:\n            message_type = data['type']\n\n        if 'identifier' in data:\n            identifier = json.loads(data['identifier'])\n\n        if identifier is not None:\n            subscription = self.find_subscription(identifier)\n\n        if subscription is not None:\n            subscription.received(data)\n        elif message_type == 'welcome':\n            self.logger.debug('Welcome message received.')\n\n            for subscription in self.subscriptions.values():\n                if subscription.state == 'connection_pending':\n                    subscription.create()\n\n        elif message_type == 'ping':\n            if self.log_ping:\n                self.logger.debug('Ping received.')\n        else:\n            self.logger.warning('Message not supported. (Message: {})'.format(message))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the socket is closed.", "response": "def _on_close(self, socket):\n        \"\"\"\n        Called when the connection was closed.\n        \"\"\"\n        self.logger.debug('Connection closed.')\n\n        for subscription in self.subscriptions.values():\n            if subscription.state == 'subscribed':\n                subscription.state = 'connection_pending'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connected(self):\n        return self.websocket is not None and \\\n               self.websocket.sock is not None and \\\n               self.websocket.sock.connected", "response": "Returns True if the websocket is connected to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_subscription(self, identifier):\n        for subscription in self.subscriptions.values():\n            if subscription.identifier == identifier:\n                return subscription", "response": "Finds a subscription by it s identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self):\n        self.logger.debug('Create subscription on server...')\n\n        if not self.connection.connected:\n            self.state = 'connection_pending'\n            return\n\n        data = {\n            'command': 'subscribe',\n            'identifier': self._identifier_string()\n        }\n\n        self.connection.send(data)\n        self.state = 'pending'", "response": "Create a new subscription on the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the subscription from the server.", "response": "def remove(self):\n        \"\"\"\n        Removes the subscription.\n        \"\"\"\n        self.logger.debug('Remove subscription from server...')\n\n        data = {\n            'command': 'unsubscribe',\n            'identifier': self._identifier_string()\n        }\n\n        self.connection.send(data)\n        self.state = 'unsubscribed'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self, message):\n        self.logger.debug('Send message: {}'.format(message))\n\n        if self.state == 'pending' or self.state == 'connection_pending':\n            self.logger.info('Connection not established. Add message to queue.')\n            self.message_queue.append(message)\n            return\n        elif self.state == 'unsubscribed' or self.state == 'rejected':\n            self.logger.warning('Not subscribed! Message discarded.')\n            return\n\n        data = {\n            'command': 'message',\n            'identifier': self._identifier_string(),\n            'data': message.raw_message()\n        }\n\n        self.connection.send(data)", "response": "Sends a message to the server on the current channel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef received(self, data):\n        self.logger.debug('Data received: {}'.format(data))\n\n        message_type = None\n\n        if 'type' in data:\n            message_type = data['type']\n\n        if message_type == 'confirm_subscription':\n            self._subscribed()\n        elif message_type == 'reject_subscription':\n            self._rejected()\n        elif self.receive_callback is not None and 'message' in data:\n            self.receive_callback(data['message'])\n        else:\n            self.logger.warning('Message type unknown. ({})'.format(message_type))", "response": "Handle incoming data from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _subscribed(self):\n        self.logger.debug('Subscription confirmed.')\n        self.state = 'subscribed'\n        for message in self.message_queue:\n            self.send(message)", "response": "Called when the subscription was accepted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli_opts():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \"--homeassistant-config\",\n        type=str,\n        required=False,\n        dest=\"config\",\n        help=\"Create configuration section for home assistant\",)\n    parser.add_argument(\n        \"-f\",\n        \"--filter\",\n        type=str,\n        required=False,\n        dest=\"filter\",\n        help=\"Ignore events related with these devices\",)\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=str,\n        required=False,\n        dest=\"output\",\n        help=\"Send output to file\",)\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        action=\"store_true\",\n        dest=\"verbose\",\n        help=\"Verbose output\",)\n    parser.add_argument('device')\n\n    return parser.parse_args()", "response": "Handle the command line options"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        print(\"Entering monitoring mode, press CTRL-C to quit\")\n        serial = self._connection.serial\n\n        while True:\n            serial.write(b\"@R\")\n            length = int(serial.read(), 16)\n            data = serial.read(length * 2)\n            message = messages.parse(data)\n            if not (self._options.filter and\n                    message.entity and\n                    message.entity in self._devices):\n                logging.debug(\" \".join(message.bytes))\n            if not self._options.config or \\\n               message.entity is None or \\\n               message.entity in self._devices:\n                continue\n\n            print(\"New device found\")\n            ha_id = input(\"Enter home assistant unique ID: \")\n            name = input(\"Enter name: \")\n            self._add_device(scs_id=message.entity, ha_id=ha_id, name=name)", "response": "Monitor the bus for events and handle them"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a device to the list of known ones", "response": "def _add_device(self, scs_id, ha_id, name):\n        \"\"\" Add device to the list of known ones \"\"\"\n        if scs_id in self._devices:\n            return\n\n        self._devices[scs_id] = {\n            'name': name,\n            'ha_id': ha_id\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _home_assistant_config(self):\n        devices = {}\n        for scs_id, dev in self._devices.items():\n            devices[dev['ha_id']] = {\n                'name': dev['name'],\n                'scs_id': scs_id}\n\n        return {'devices': devices}", "response": "Creates home assistant configuration for the known devices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_filter(self, config):\n        path = pathlib.Path(config)\n        if not path.is_file():\n            return\n\n        with open(config, 'r') as conf:\n            devices = yaml.load(conf)['devices']\n            for ha_id, dev in devices.items():\n                self._devices[dev['scs_id']] = {\n                    ha_id: dev,\n                    'name': dev['name']}", "response": "Load the filter file and populate self. _devices accordingly"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the connection to the serial port and ensure no pending items are left.", "response": "def close(self):\n        \"\"\" Closes the connection to the serial port and ensure no pending\n        operatoin are left \"\"\"\n        self._serial.write(b\"@c\")\n        self._serial.read()\n        self._serial.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a value converting it to the proper type if validation_type exists.", "response": "def load(self, value):\n        \"\"\"Load a value, converting it to the proper type if validation_type exists.\"\"\"\n        if self.property_type is None:\n            return value\n        elif not isinstance(self.property_type, BaseType):\n            raise TypeError('property_type must be schematics BaseType')\n        else:\n            native_value = self.property_type.to_native(value)\n            self.property_type.validate(native_value)\n            return native_value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iter_config_props(cls):\n        props = inspect.getmembers(cls, lambda a: isinstance(a, ConfigProperty))\n        for attr_name, config_prop in props:\n            yield attr_name, config_prop", "response": "Iterate over all ConfigProperty attributes and yield them as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_property_keys(cls):\n        for attr_name, config_prop in cls._iter_config_props():\n            if config_prop.property_key is None:\n                config_prop.property_key = attr_name", "response": "Update the unspecified property_keys for each ConfigProperty in the class attr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting instance property to a value and add it varz if needed", "response": "def _set_instance_prop(self, attr_name, config_prop, value):\n        \"\"\"Set instance property to a value and add it varz if needed\"\"\"\n        setattr(self, attr_name, value)\n\n        # add to varz if it is not private\n        if not config_prop.exclude_from_varz:\n            self.varz[attr_name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load(self):\n        for attr_name, config_prop in self._iter_config_props():\n            found = False\n            for loader in self._loaders:\n                if loader.exists(config_prop.property_key):\n                    raw_value = loader.get(config_prop.property_key)\n                    converted_value = config_prop.load(raw_value)\n\n                    self._set_instance_prop(attr_name, config_prop, converted_value)\n                    found = True\n                    break\n\n            if not found:\n                if not config_prop.required or config_prop.default is not None:\n                    self._set_instance_prop(attr_name, config_prop, config_prop.default)\n                else:\n                    raise ValueError('Missing required ConfigProperty {}'.format(attr_name))", "response": "Load values for all ConfigProperty attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reload(self):\n        for loader in self._loaders:\n            loader.reload()\n\n        self.varz = {}  # reset varz\n        self._load()", "response": "Reload all ConfigProperty values from all loaded loaders."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all properties and values in a dictionary", "response": "def as_dict(self):\n        \"\"\"Return all properties and values in a dictionary (includes private properties)\"\"\"\n        return {config_name: getattr(self, config_name)\n                for config_name, _ in self._iter_config_props()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in_same_dir(as_file, target_file):\n    return os.path.abspath(os.path.join(os.path.dirname(as_file), target_file))", "response": "Return an absolute path to a target file that is located in the same directory as as_file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomparing a name in question separated into given and family.", "response": "def compare_name(given_name, family_name, question_name):\n    \"\"\"Compares a name in question to a specified name separated into given and family.\n\n    The name in question ``question_name`` can be of varying format, including\n    \"Kyle E. Niemeyer\", \"Kyle Niemeyer\", \"K. E. Niemeyer\", \"KE Niemeyer\", and\n    \"K Niemeyer\". Other possibilities include names with hyphens such as\n    \"Chih-Jen Sung\", \"C. J. Sung\", \"C-J Sung\".\n\n    Examples:\n        >>> compare_name('Kyle', 'Niemeyer', 'Kyle E Niemeyer')\n        True\n        >>> compare_name('Chih-Jen', 'Sung', 'C-J Sung')\n        True\n\n    Args:\n        given_name (`str`): Given (or first) name to be checked against.\n        family_name (`str`): Family (or last) name to be checked against.\n        question_name (`str`): The whole name in question.\n\n    Returns:\n        `bool`: The return value. True for successful comparison, False otherwise.\n    \"\"\"\n    # lowercase everything\n    given_name = given_name.lower()\n    family_name = family_name.lower()\n    question_name = question_name.lower()\n\n    # rearrange names given as \"last, first middle\"\n    if ',' in question_name:\n        name_split = question_name.split(',')\n        name_split.reverse()\n        question_name = ' '.join(name_split).strip()\n\n    # remove periods\n    question_name = question_name.replace('.', '')\n    given_name = given_name.replace('.', '')\n    family_name = family_name.replace('.', '')\n\n    # split names by , <space> - .\n    given_name = list(filter(None, re.split(r\"[, \\-.]+\", given_name)))\n    num_family_names = len(list(filter(None, re.split(\"[, .]+\", family_name))))\n\n    # split name in question by , <space> - .\n    name_split = list(filter(None, re.split(r\"[, \\-.]+\", question_name)))\n    first_name = [name_split[0]]\n    if len(name_split) > 2:\n        first_name += [n for n in name_split[1:-num_family_names]]\n\n    if len(first_name) > 1 and len(given_name) == len(first_name):\n        # both have same number of first and middle names/initials\n        for i in range(1, len(first_name)):\n            first_name[i] = first_name[i][0]\n            given_name[i] = given_name[i][0]\n    elif len(given_name) != len(first_name):\n        min_names = min(len(given_name), len(first_name))\n        first_name = first_name[:min_names]\n        given_name = given_name[:min_names]\n\n    # first initial\n    if len(first_name[0]) == 1 or len(given_name[0]) == 1:\n        given_name[0] = given_name[0][0]\n        first_name[0] = first_name[0][0]\n\n    # first and middle initials combined\n    if len(first_name[0]) > 1 or len(given_name[0]) > 1:\n        given_name[0] = given_name[0][0]\n        first_name[0] = name_split[0][0]\n\n    # Hyphenated last name may need to be reconnected\n    if num_family_names == 1 and '-' in family_name:\n        num_hyphen = family_name.count('-')\n        family_name_compare = '-'.join(name_split[-(num_hyphen + 1):])\n    else:\n        family_name_compare = ' '.join(name_split[-num_family_names:])\n\n    return given_name == first_name and family_name == family_name_compare"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that the temperature ranges given for thermo data are valid.", "response": "def _validate_isvalid_t_range(self, isvalid_t_range, field, values):\n        \"\"\"Checks that the temperature ranges given for thermo data are valid\n        Args:\n            isvalid_t_range (`bool`): flag from schema indicating T range is to be checked\n            field (`str`): T_range\n            values (`list`): List of temperature values indicating low, middle, and high ranges\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_t_range': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'list'}}\n        \"\"\"\n        if all([isinstance(v, (float, int)) for v in values]):\n            # If no units given, assume Kelvin\n            T_low = Q_(values[0], 'K')\n            T_mid = Q_(values[1], 'K')\n            T_hi = Q_(values[2], 'K')\n        elif all([isinstance(v, str) for v in values]):\n            T_low = Q_(values[0])\n            T_mid = Q_(values[1])\n            T_hi = Q_(values[2])\n        else:\n            self._error(field, 'The temperatures in the range must all be either with units or '\n                               'without units, they cannot be mixed')\n            return False\n\n        if min([T_low, T_mid, T_hi]) != T_low:\n            self._error(field, 'The first element of the T_range must be the lower limit')\n        if max([T_low, T_mid, T_hi]) != T_hi:\n            self._error(field, 'The last element of the T_range must be the upper limit')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_isvalid_unit(self, isvalid_unit, field, value):\n        quantity = 1.0 * units(value['units'])\n        try:\n            quantity.to(property_units[field])\n        except pint.DimensionalityError:\n            self._error(field, 'incompatible units; should be consistent '\n                        'with ' + property_units[field]\n                        )", "response": "Checks if the units of the file associated with this property are compatible with the Pint unit registry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_isvalid_history(self, isvalid_history, field, value):\n        # Check the type has appropriate units\n        history_type = value['type']\n        if history_type.endswith('emission'):\n            history_type = 'emission'\n        elif history_type.endswith('absorption'):\n            history_type = 'absorption'\n        quantity = 1.0*(units(value['quantity']['units']))\n        try:\n            quantity.to(property_units[history_type])\n        except pint.DimensionalityError:\n            self._error(field, 'incompatible units; should be consistent '\n                        'with ' + property_units[history_type])\n\n        # Check that time has appropriate units\n        time = 1.0*(units(value['time']['units']))\n        try:\n            time.to(property_units['time'])\n        except pint.DimensionalityError:\n            self._error(field, 'incompatible units; should be consistent '\n                        'with ' + property_units['time'])\n\n        # Check that the values have the right number of columns\n        n_cols = len(value['values'][0])\n        max_cols = max(value['time']['column'],\n                       value['quantity']['column'],\n                       value.get('uncertainty', {}).get('column', 0)) + 1\n        if n_cols > max_cols:\n            self._error(field, 'too many columns in the values')\n        elif n_cols < max_cols:\n            self._error(field, 'not enough columns in the values')", "response": "Checks that the given time history is properly formatted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_isvalid_quantity(self, isvalid_quantity, field, value):\n        quantity = Q_(value[0])\n        low_lim = 0.0 * units(property_units[field])\n\n        try:\n            if quantity <= low_lim:\n                self._error(\n                    field, 'value must be greater than 0.0 {}'.format(property_units[field]),\n                )\n        except pint.DimensionalityError:\n            self._error(field, 'incompatible units; should be consistent '\n                        'with ' + property_units[field]\n                        )", "response": "Checks for valid given value and appropriate units."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_isvalid_uncertainty(self, isvalid_uncertainty, field, value):\n        self._validate_isvalid_quantity(True, field, value)\n\n        # This len check is necessary for reasons that aren't quite clear to me\n        # Cerberus calls this validation method even when lists have only one element\n        # and should therefore be validated only by isvalid_quantity\n        if len(value) > 1 and value[1]['uncertainty-type'] != 'relative':\n            if value[1].get('uncertainty') is not None:\n                self._validate_isvalid_quantity(True, field, [value[1]['uncertainty']])\n\n            if value[1].get('upper-uncertainty') is not None:\n                self._validate_isvalid_quantity(True, field, [value[1]['upper-uncertainty']])\n\n            if value[1].get('lower-uncertainty') is not None:\n                self._validate_isvalid_quantity(True, field, [value[1]['lower-uncertainty']])", "response": "Checks for valid given value and appropriate units with uncertainty."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that the DOI is in the correct format.", "response": "def _validate_isvalid_reference(self, isvalid_reference, field, value):\n        \"\"\"Checks valid reference metadata using DOI (if present).\n\n        Args:\n            isvalid_reference (`bool`): flag from schema indicating reference to be checked.\n            field (`str`): 'reference'\n            value (`dict`): dictionary of reference metadata.\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_reference': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'dict'}}\n\n        \"\"\"\n        if 'doi' in value:\n            try:\n                ref = crossref_api.works(ids=value['doi'])['message']\n            except (HTTPError, habanero.RequestError):\n                self._error(field, 'DOI not found')\n                return\n            except ConnectionError:\n                warn('network not available, DOI not validated.')\n                return\n\n            # Assume that the reference returned by the DOI lookup always has a container-title\n            ref_container = ref.get('container-title')[0]\n            # TODO: Add other container types: value.get('journal') or value.get('report') or ...\n            # note that there's a type field in the ref that is journal-article, proceedings-article\n            container = value.get('journal')\n            if container is None or container != ref_container:\n                self._error(field, 'journal should be {}'.format(ref_container))\n\n            # Assume that the reference returned by DOI lookup always has a year\n            ref_year = ref.get('published-print') or ref.get('published-online')\n            ref_year = ref_year['date-parts'][0][0]\n            year = value.get('year')\n            if year is None or year != ref_year:\n                self._error(field, 'year should be {}'.format(ref_year))\n\n            # Volume number might not be in the reference\n            ref_volume = ref.get('volume')\n            volume = value.get('volume')\n            if ref_volume is None:\n                if volume is not None:\n                    self._error(field, 'Volume was specified in the YAML but is not present in the '\n                                'DOI reference.')\n            else:\n                if volume is None or int(volume) != int(ref_volume):\n                    self._error(field, 'volume should be {}'.format(ref_volume))\n\n            # Pages might not be in the reference\n            ref_pages = ref.get('page')\n            pages = value.get('pages')\n            if ref_pages is None:\n                if pages is not None:\n                    self._error(field, 'Pages were specified in the YAML but are not present in '\n                                'the DOI reference.')\n            else:\n                if pages is None or pages != ref_pages:\n                    self._error(field, 'pages should be {}'.format(ref_pages))\n\n            # check that all authors present\n            authors = value['authors'][:]\n            author_names = [a['name'] for a in authors]\n            for author in ref['author']:\n                # find using family name\n                author_match = next(\n                    (a for a in authors if\n                     compare_name(author['given'], author['family'], a['name'])\n                     ),\n                    None\n                    )\n                # error if missing author in given reference information\n                if author_match is None:\n                    self._error(field, 'Missing author: ' +\n                                ' '.join([author['given'], author['family']])\n                                )\n                else:\n                    author_names.remove(author_match['name'])\n\n                    # validate ORCID if given\n                    orcid = author.get('ORCID')\n                    if orcid:\n                        # Crossref may give ORCID as http://orcid.org/####-####-####-####\n                        # so need to strip the leading URL\n                        orcid = orcid[orcid.rfind('/') + 1:]\n\n                        if 'ORCID' in author_match:\n                            if author_match['ORCID'] != orcid:\n                                self._error(\n                                    field, author_match['name'] + ' ORCID does ' +\n                                    'not match that in reference. Reference: ' +\n                                    orcid + '. Given: ' + author_match['ORCID']\n                                    )\n                        else:\n                            # ORCID not given, suggest adding it\n                            warn('ORCID ' + orcid + ' missing for ' + author_match['name'])\n\n            # check for extra names given\n            if len(author_names) > 0:\n                self._error(field, 'Extra author(s) given: ' +\n                            ', '.join(author_names)\n                            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking for valid ORCID and checks if it matches the given ORCID.", "response": "def _validate_isvalid_orcid(self, isvalid_orcid, field, value):\n        \"\"\"Checks for valid ORCID if given.\n\n        Args:\n            isvalid_orcid (`bool`): flag from schema indicating ORCID to be checked.\n            field (`str`): 'author'\n            value (`dict`): dictionary of author metadata.\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_orcid': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'dict'}}\n\n        \"\"\"\n        if isvalid_orcid and 'ORCID' in value:\n            try:\n                res = search_orcid(value['ORCID'])\n            except ConnectionError:\n                warn('network not available, ORCID not validated.')\n                return\n            except HTTPError:\n                self._error(field, 'ORCID incorrect or invalid for ' +\n                            value['name']\n                            )\n                return\n\n            family_name = res['name']['family-name']['value']\n            given_name = res['name']['given-names']['value']\n            if not compare_name(given_name, family_name, value['name']):\n                self._error(field, 'Name and ORCID do not match. Name supplied: ' +\n                            value['name'] + '. Name associated with ORCID: ' +\n                            ' '.join([given_name, family_name])\n                            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the composition of the current object is valid.", "response": "def _validate_isvalid_composition(self, isvalid_composition, field, value):\n        \"\"\"Checks for valid specification of composition.\n\n        Args:\n            isvalid_composition (bool): flag from schema indicating\n                composition to be checked.\n            field (str): 'composition'\n            value (dict): dictionary of composition\n\n        The rule's arguments are validated against this schema:\n            {'isvalid_composition': {'type': 'bool'}, 'field': {'type': 'str'},\n             'value': {'type': 'dict'}}\n        \"\"\"\n        sum_amount = 0.0\n        if value['kind'] in ['mass fraction', 'mole fraction']:\n            low_lim = 0.0\n            up_lim = 1.0\n            total_amount = 1.0\n        elif value['kind'] in ['mole percent']:\n            low_lim = 0.0\n            up_lim = 100.0\n            total_amount = 100.0\n        else:\n            self._error(field, 'composition kind must be \"mole percent\", \"mass fraction\", or '\n                        '\"mole fraction\"')\n            return False\n\n        for sp in value['species']:\n            amount = sp['amount'][0]\n            sum_amount += amount\n\n            # Check that amount within bounds, based on kind specified\n            if amount < low_lim:\n                self._error(field, 'Species ' + sp['species-name'] + ' ' +\n                            value['kind'] + ' must be greater than {:.1f}'.format(low_lim)\n                            )\n            elif amount > up_lim:\n                self._error(field, 'Species ' + sp['species-name'] + ' ' +\n                            value['kind'] + ' must be less than {:.1f}'.format(up_lim)\n                            )\n\n        # Make sure mole/mass fraction sum to 1\n        if not np.isclose(total_amount, sum_amount):\n            self._error(field, 'Species ' + value['kind'] +\n                        's do not sum to {:.1f}: '.format(total_amount) +\n                        '{:f}'.format(sum_amount)\n                        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_csv(filename, keys=None, convert_types=False, **kwargs):\n    '''\n    Read a CSV in canonical form: ::\n\n        <agent_id, t_step, key, value, value_type>\n\n    '''\n    df = pd.read_csv(filename)\n    if convert_types:\n        df = convert_types_slow(df)\n    if keys:\n        df = df[df['key'].isin(keys)]\n    df = process_one(df)\n    return df", "response": "Read a CSV file in canonical form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_types_slow(df):\n    '''This is a slow operation.'''\n    dtypes = get_types(df)\n    for k, v in dtypes.items():\n        t = df[df['key']==k]\n        t['value'] = t['value'].astype(v)\n    df = df.apply(convert_row, axis=1)\n    return df", "response": "This is a slow operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits a dataframe in two dataframes one with the history of agents and the environment history and one with the agents and the environment history .", "response": "def split_df(df):\n    '''\n    Split a dataframe in two dataframes: one with the history of agents,\n    and one with the environment history\n    '''\n    envmask = (df['agent_id'] == 'env')\n    n_env = envmask.sum()\n    if n_env == len(df):\n        return df, None\n    elif n_env == 0:\n        return None, df\n    agents, env = [x for _, x in df.groupby(envmask)]\n    return env, agents"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process(df, **kwargs):\n    '''\n    Process a dataframe in canonical form ``(t_step, agent_id, key, value, value_type)`` into\n    two dataframes with a column per key: one with the history of the agents, and one for the\n    history of the environment.\n    '''\n    env, agents = split_df(df)\n    return process_one(env, **kwargs), process_one(agents, **kwargs)", "response": "Process a dataframe in canonical form into a sequence of two dataframes with a column per key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a dataframe in canonical form with a column per key.", "response": "def process_one(df, *keys, columns=['key', 'agent_id'], values='value',\n                fill=True, index=['t_step',],\n                aggfunc='first', **kwargs):\n    '''\n    Process a dataframe in canonical form ``(t_step, agent_id, key, value, value_type)`` into\n    a dataframe with a column per key\n    '''\n    if df is None:\n        return df\n    if keys:\n        df = df[df['key'].isin(keys)]\n\n    df = df.pivot_table(values=values, index=index, columns=columns,\n                        aggfunc=aggfunc, **kwargs)\n    if fill:\n        df = fillna(df)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_all(*args, **kwargs):\n    '''\n    Read all the trial data and plot the result of applying a function on them.\n    '''\n    dfs = do_all(*args, **kwargs)\n    ps = []\n    for line in dfs:\n        f, df, config = line\n        df.plot(title=config['name'])\n        ps.append(df)\n    return ps", "response": "Read all the trial data and plot the result of applying a function on them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a name that can be imported to serialize or deserialize an object", "response": "def name(value, known_modules=[]):\n    '''Return a name that can be imported, to serialize/deserialize an object'''\n    if value is None:\n        return 'None'\n    if not isinstance(value, type):  # Get the class name first\n        value = type(value)\n    tname = value.__name__\n    if hasattr(builtins, tname):\n        return tname\n    modname = value.__module__\n    if modname == '__main__':\n        return tname\n    if known_modules and modname in known_modules:\n        return tname\n    for kmod in known_modules:\n        if not kmod:\n            continue\n        module = importlib.import_module(kmod)\n        if hasattr(module, tname):\n            return tname\n    return '{}.{}'.format(modname, tname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a text representation of an object.", "response": "def serialize(v, known_modules=[]):\n    '''Get a text representation of an object.'''\n    tname = name(v, known_modules=known_modules)\n    func = serializer(tname)\n    return func(v), tname"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize(type_, value=None, **kwargs):\n    '''Get an object from a text representation'''\n    if not isinstance(type_, str):\n        return type_\n    des = deserializer(type_, **kwargs)\n    if value is None:\n        return des\n    return des(value)", "response": "Get an object from a text representation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef content(self):\n        if self._content is None:\n            self._content = self.parse_files()\n        return self._content", "response": "Return parsed data. Parse it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind files. returns the list of matching files.", "response": "def matching_files(self):\n        \"\"\"\n        Find files.\n\n        Returns:\n            list: the list of matching files.\n        \"\"\"\n        matching = []\n        matcher = self.file_path_regex\n        pieces = self.file_path_regex.pattern.split(sep)\n        partial_matchers = list(map(re.compile, (\n            sep.join(pieces[:i + 1]) for i in range(len(pieces)))))\n\n        for root, dirs, files in walk(self.top_dir, topdown=True):\n            for i in reversed(range(len(dirs))):\n                dirname = relpath(join(root, dirs[i]), self.top_dir)\n                dirlevel = dirname.count(sep)\n                if not partial_matchers[dirlevel].match(dirname):\n                    del dirs[i]\n\n            for filename in files:\n                if matcher.match(filename):\n                    matching.append(abspath(join(root, filename)))\n\n        return matching"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_files(self):\n        log_re = self.log_format_regex\n        log_lines = []\n        for log_file in self.matching_files():\n            with open(log_file) as f:\n                matches = re.finditer(log_re, f.read())\n                for match in matches:\n                    log_lines.append(match.groupdict())\n        return log_lines", "response": "Find the files and parse them."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the threshold values for a uniform distribution of the network agents.", "response": "def calculate_distribution(network_agents=None,\n                           agent_type=None):\n    '''\n    Calculate the threshold values (thresholds for a uniform distribution)\n    of an agent distribution given the weights of each agent type.\n\n    The input has this form: ::\n\n            [\n            {'agent_type': 'agent_type_1',\n                'weight': 0.2,\n                'state': {\n                    'id': 0\n                }\n            },\n            {'agent_type': 'agent_type_2',\n                'weight': 0.8,\n                'state': {\n                    'id': 1\n                }\n            }\n            ]\n\n    In this example, 20% of the nodes will be marked as type\n    'agent_type_1'.\n    '''\n    if network_agents:\n        network_agents = deepcopy(network_agents)\n    elif agent_type:\n        network_agents = [{'agent_type': agent_type}]\n    else:\n        raise ValueError('Specify a distribution or a default agent type')\n\n    # Calculate the thresholds\n    total = sum(x.get('weight', 1) for x in network_agents)\n    acc = 0\n    for v in network_agents:\n        if 'ids' in v:\n            v['threshold'] = STATIC_THRESHOLD\n            continue\n        upper = acc + (v.get('weight', 1)/total)\n        v['threshold'] = [acc, upper]\n        acc = upper\n    return network_agents"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_distribution(network_agents, known_modules=[]):\n    '''\n    When serializing an agent distribution, remove the thresholds, in order\n    to avoid cluttering the YAML definition file.\n    '''\n    d = deepcopy(list(network_agents))\n    for v in d:\n        if 'threshold' in v:\n            del v['threshold']\n        v['agent_type'] = serialize_type(v['agent_type'],\n                                         known_modules=known_modules)\n    return d", "response": "Serializes a network agent distribution into a YAML document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_states(states, topology):\n    '''Validate states to avoid ignoring states during initialization'''\n    states = states or []\n    if isinstance(states, dict):\n        for x in states:\n            assert x in topology.node\n    else:\n        assert len(states) <= len(topology)\n    return states", "response": "Validate states to avoid ignoring states during initialization"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _agent_from_distribution(distribution, value=-1, agent_id=None):\n    if value < 0:\n        value = random.random()\n    for d in sorted(distribution, key=lambda x: x['threshold']):\n        threshold = d['threshold']\n        # Check if the definition matches by id (first) or by threshold\n        if not ((agent_id is not None and threshold == STATIC_THRESHOLD and agent_id in d['ids']) or \\\n                (value >= threshold[0] and value < threshold[1])):\n            continue\n        state = {}\n        if 'state' in d:\n            state = deepcopy(d['state'])\n        return d['agent_type'], state\n\n    raise Exception('Distribution for value {} not found in: {}'.format(value, distribution))", "response": "Used in the initialization of agents given an agent distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ego_search(self, steps=1, center=False, node=None, **kwargs):\n        '''Get a list of nodes in the ego network of *node* of radius *steps*'''\n        node = as_node(node if node is not None else self)\n        G = self.subgraph(**kwargs)\n        return nx.ego_graph(G, node, center=center, radius=steps).nodes()", "response": "Get a list of nodes in the ego network of radius * steps*"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of nodes whose coordinates are closer than radius to node.", "response": "def geo_search(self, radius, node=None, center=False, **kwargs):\n        '''Get a list of nodes whose coordinates are closer than *radius* to *node*.'''\n        node = as_node(node if node is not None else self)\n\n        G = self.subgraph(**kwargs)\n\n        pos = nx.get_node_attributes(G, 'pos')\n        if not pos:\n            return []\n        nodes, coords = list(zip(*pos.items()))\n        kdtree = KDTree(coords)  # Cannot provide generator.\n        indices = kdtree.query_ball_point(pos[node], radius)\n        return [nodes[i] for i in indices if center or (nodes[i] != node)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_message(self, message):\n\n        msg = tornado.escape.json_decode(message)\n\n        if msg['type'] == 'config_file':\n\n            if self.application.verbose:\n                print(msg['data'])\n\n            self.config = list(yaml.load_all(msg['data']))\n\n            if len(self.config) > 1:\n                error = 'Please, provide only one configuration.'\n                if self.application.verbose:\n                    logger.error(error)\n                self.write_message({'type': 'error',\n                    'error': error})\n                return\n\n            self.config = self.config[0]\n            self.send_log('INFO.' + self.simulation_name,\n                          'Using config: {name}'.format(name=self.config['name']))\n\n            if 'visualization_params' in self.config:\n                self.write_message({'type': 'visualization_params',\n                    'data': self.config['visualization_params']})\n            self.name = self.config['name']\n            self.run_simulation()\n\n            settings = []\n            for key in self.config['environment_params']: \n                if type(self.config['environment_params'][key]) == float or type(self.config['environment_params'][key]) == int:\n                    if self.config['environment_params'][key] <= 1:\n                        setting_type = 'number'\n                    else:\n                        setting_type = 'great_number'\n                elif type(self.config['environment_params'][key]) == bool:\n                    setting_type = 'boolean'\n                else:\n                    setting_type = 'undefined'\n\n                settings.append({\n                    'label': key,\n                    'type': setting_type,\n                    'value': self.config['environment_params'][key]\n                })\n\n            self.write_message({'type': 'settings',\n                'data': settings})\n\n        elif msg['type'] == 'get_trial':\n            if self.application.verbose:\n                logger.info('Trial {} requested!'.format(msg['data']))\n            self.send_log('INFO.' + __name__, 'Trial {} requested!'.format(msg['data']))\n            self.write_message({'type': 'get_trial',\n                                'data': self.get_trial(int(msg['data']))})\n\n        elif msg['type'] == 'run_simulation':\n            if self.application.verbose:\n                logger.info('Running new simulation for {name}'.format(name=self.config['name']))\n            self.send_log('INFO.' + self.simulation_name, 'Running new simulation for {name}'.format(name=self.config['name']))\n            self.config['environment_params'] = msg['data']\n            self.run_simulation()\n\n        elif msg['type'] == 'download_gexf':\n            G = self.trials[ int(msg['data']) ].history_to_graph()\n            for node in G.nodes():\n                if 'pos' in G.node[node]:\n                    G.node[node]['viz'] = {\"position\": {\"x\": G.node[node]['pos'][0], \"y\": G.node[node]['pos'][1], \"z\": 0.0}}\n                    del (G.node[node]['pos'])\n            writer = nx.readwrite.gexf.GEXFWriter(version='1.2draft')\n            writer.add_graph(G)\n            self.write_message({'type': 'download_gexf',\n                'filename': self.config['name'] + '_trial_' + str(msg['data']),\n                'data': tostring(writer.xml).decode(writer.encoding) })\n\n        elif msg['type'] == 'download_json':\n            G = self.trials[ int(msg['data']) ].history_to_graph()\n            for node in G.nodes():\n                if 'pos' in G.node[node]:\n                    G.node[node]['viz'] = {\"position\": {\"x\": G.node[node]['pos'][0], \"y\": G.node[node]['pos'][1], \"z\": 0.0}}\n                    del (G.node[node]['pos'])\n            self.write_message({'type': 'download_json',\n                'filename': self.config['name'] + '_trial_' + str(msg['data']),\n                'data': nx.node_link_data(G) })\n\n        else:\n            if self.application.verbose:\n                logger.info('Unexpected message!')", "response": "Receives a message from the websocket parse and act accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets stats for status codes by date.", "response": "def status_codes_by_date_stats():\n    \"\"\"\n    Get stats for status codes by date.\n\n    Returns:\n        list: status codes + date grouped by type: 2xx, 3xx, 4xx, 5xx, attacks.\n    \"\"\"\n\n    def date_counter(queryset):\n        return dict(Counter(map(\n            lambda dt: ms_since_epoch(datetime.combine(\n                make_naive(dt), datetime.min.time())),\n            list(queryset.values_list('datetime', flat=True)))))\n\n    codes = {low: date_counter(\n        RequestLog.objects.filter(status_code__gte=low, status_code__lt=high))\n        for low, high in ((200, 300), (300, 400), (400, 500))}\n    codes[500] = date_counter(RequestLog.objects.filter(status_code__gte=500))\n    codes['attacks'] = date_counter(RequestLog.objects.filter(\n        status_code__in=(400, 444, 502)))\n\n    stats = {}\n    for code in (200, 300, 400, 500, 'attacks'):\n        for date, count in codes[code].items():\n            if stats.get(date, None) is None:\n                stats[date] = {200: 0, 300: 0, 400: 0, 500: 0, 'attacks': 0}\n            stats[date][code] += count\n\n    stats = sorted([(k, v) for k, v in stats.items()], key=lambda x: x[0])\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef most_visited_pages_stats():\n    stats = {'more_than_10': [], 'less_than_10': {}}\n\n    counter = Counter(list(RequestLog.objects.values_list('url', flat=True)))\n    most_visited_pages = counter.most_common()\n    bounds = (10000, 1000, 100, 10)\n    subsets = [[] for _ in bounds]\n\n    for u, c in most_visited_pages:\n        if url_is_ignored(u):\n            continue\n        if c >= bounds[0]:\n            subsets[0].append([u, c])\n        elif c < bounds[-1]:\n            subsets[-1].append([u, c])\n        else:\n            for i, bound in enumerate(bounds[:-1]):\n                if bound > c >= bounds[i+1]:\n                    subsets[i+1].append([u, c])\n                    break\n\n    stats['more_than_10'] = [\n        {'bound': bound, 'subset': subset}\n        for bound, subset in zip(bounds[:-1], subsets[:-1])]\n\n    for subset in subsets[:-1]:\n        for uc in subset:\n            if url_is_project(uc[0]):\n                if url_is_asset(uc[0]):\n                    uc.append(ASSET)\n                else:\n                    uc.append(PROJECT)\n            else:\n                if url_is_asset(uc[0]):\n                    uc.append(OLD_ASSET)\n                elif url_is_common_asset(uc[0]):\n                    uc.append(COMMON_ASSET)\n                elif url_is_old_project(uc[0]):\n                    uc.append(OLD_PROJECT)\n                elif url_is_false_negative(uc[0]):\n                    uc.append(FALSE_NEGATIVE)\n                else:\n                    uc.append(SUSPICIOUS)\n\n    occurrences = {name: {'distinct': 0, 'total': 0}\n                   for name in set(URL_TYPE.keys()) - {IGNORED}}\n\n    for u, c in subsets[-1]:\n        if url_is_project(u):\n            if url_is_asset(u):\n                occurrences[ASSET]['distinct'] += 1\n                occurrences[ASSET]['total'] += c\n            else:\n                occurrences[PROJECT]['distinct'] += 1\n                occurrences[PROJECT]['total'] += c\n        else:\n            if url_is_asset(u):\n                occurrences[OLD_ASSET]['distinct'] += 1\n                occurrences[OLD_ASSET]['total'] += c\n            elif url_is_common_asset(u):\n                occurrences[COMMON_ASSET]['distinct'] += 1\n                occurrences[COMMON_ASSET]['total'] += c\n            elif url_is_old_project(u):\n                occurrences[OLD_PROJECT]['distinct'] += 1\n                occurrences[OLD_PROJECT]['total'] += c\n            elif url_is_false_negative(u):\n                occurrences[FALSE_NEGATIVE]['distinct'] += 1\n                occurrences[FALSE_NEGATIVE]['total'] += c\n            else:\n                occurrences[SUSPICIOUS]['distinct'] += 1\n                occurrences[SUSPICIOUS]['total'] += c\n\n    stats['less_than_10'] = occurrences\n\n    return stats", "response": "Get stats for the most visited pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to enter a node in the agent.", "response": "def enter(self, pub_id, *nodes):\n        '''Agents will try to enter. The pub checks if it is possible'''\n        try:\n            pub = self['pubs'][pub_id]\n        except KeyError:\n            raise ValueError('Pub {} is not available'.format(pub_id))\n        if not pub['open'] or (pub['capacity'] < (len(nodes) + pub['occupancy'])):\n            return False\n        pub['occupancy'] += len(nodes)\n        for node in nodes:\n            node['pub'] = pub_id\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlooking for friends to drink with", "response": "def looking_for_friends(self):\n        '''Look for friends to drink with'''\n        self.info('I am looking for friends')\n        available_friends = list(self.get_agents(drunk=False,\n                                                 pub=None,\n                                                 state_id=self.looking_for_friends.id))\n        if not available_friends:\n            self.info('Life sucks and I\\'m alone!')\n            return self.at_home\n        befriended = self.try_friends(available_friends)\n        if befriended:\n            return self.looking_for_pub"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlook for a pub that accepts me and my friends", "response": "def looking_for_pub(self):\n        '''Look for a pub that accepts me and my friends'''\n        if self['pub'] != None:\n            return self.sober_in_pub\n        self.debug('I am looking for a pub')\n        group = list(self.get_neighboring_agents())\n        for pub in self.env.available_pubs():\n            self.debug('We\\'re trying to get into {}: total: {}'.format(pub, len(group)))\n            if self.env.enter(pub, self, *group):\n                self.info('We\\'re all {} getting in {}!'.format(len(group), pub))\n                return self.sober_in_pub"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to become friends with another agent.", "response": "def befriend(self, other_agent, force=False):\n        '''\n        Try to become friends with another agent. The chances of\n        success depend on both agents' openness.\n        '''\n        if force or self['openness'] > random():\n            self.env.add_edge(self, other_agent)\n            self.info('Made some friend {}'.format(other_agent))\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef try_friends(self, others):\n        ''' Look for random agents around me and try to befriend them'''\n        befriended = False\n        k = int(10*self['openness'])\n        shuffle(others)\n        for friend in islice(others, k):  # random.choice >= 3.7\n            if friend == self:\n                continue\n            if friend.befriend(self):\n                self.befriend(friend, force=True)\n                self.debug('Hooray! new friend: {}'.format(friend.id))\n                befriended = True\n            else:\n                self.debug('{} does not want to be friends'.format(friend.id))\n        return befriended", "response": "Look for random agents around me and try to befriend them"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the mean standard deviation min max quartile1 quartile2 quartile3 and max of a vector", "response": "def profile_distribution(data):\n    \"\"\"\n    Compute the mean, standard deviation, min, quartile1, quartile2, quartile3, and max of a vector\n\n    Parameters\n    ----------\n    data: array of real values\n\n    Returns\n    -------\n    features = dictionary containing the min, max, mean, and standard deviation\n    \"\"\"\n    if len(data) == 0:\n        return (data, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n    else:\n        ddof = 1 if len(data) > 1 else 0\n        dist_mean = np.mean(data)\n        dist_stdev = np.std(data, ddof=ddof)\n        dist_min, dist_quartile1, dist_quartile2, dist_quartile3, dist_max = np.percentile(data, [0,25,50,75,100])\n        dist_skew = skew(data)\n        dist_kurtosis = kurtosis(data)\n    return (data, dist_mean, dist_stdev, dist_skew, dist_kurtosis, dist_min, dist_quartile1, dist_quartile2, dist_quartile3, dist_max)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_native(self, value):\n        if isinstance(value, dict):\n            return value\n        elif isinstance(value, six.string_types):\n            native_value = json.loads(value)\n            if isinstance(native_value, dict):\n                return native_value\n            else:\n                raise ConversionError(u'Cannot load value as a dict: {}'.format(value))", "response": "Return the value as a dict raising error if conversion is not possible"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a value as a list converting items if necessary", "response": "def to_native(self, value):\n        \"\"\"Load a value as a list, converting items if necessary\"\"\"\n        if isinstance(value, six.string_types):\n            value_list = value.split(self.string_delim)\n        else:\n            value_list = value\n\n        to_native = self.member_type.to_native if self.member_type is not None else lambda x: x\n        return [to_native(item) for item in value_list]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating each member of the list", "response": "def validate_member_type(self, value):\n        \"\"\"Validate each member of the list, if member_type exists\"\"\"\n        if self.member_type:\n            for item in value:\n                self.member_type.validate(item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the length of value if min_length or max_length was specified", "response": "def validate_length(self, value):\n        \"\"\"Validate the length of value, if min_length or max_length was specified\"\"\"\n        list_len = len(value) if value else 0\n\n        if self.max_length is not None and list_len > self.max_length:\n            raise ValidationError(\n                u'List has {} values; max length is {}'.format(list_len, self.max_length))\n\n        if self.min_length is not None and list_len < self.min_length:\n            raise ValidationError(\n                u'List has {} values; min length is {}'.format(list_len, self.min_length))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_resource(self, value):\n\n        def do_backoff(*args, **kwargs):\n            \"\"\"Call self._test_connection with exponential backoff, for self._max_tries attempts\"\"\"\n            attempts = 0\n            while True:\n                try:\n                    self._test_connection(*args, **kwargs)\n                    break\n                except ValidationError:\n                    wait_secs = min(self._max_wait, 2 ** attempts)\n                    attempts += 1\n                    if attempts < self._max_tries:\n                        time.sleep(wait_secs)\n                    else:\n                        raise\n\n        do_backoff(value)", "response": "Validate the network resource with exponential backoff."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef server_date_utc(self):\n        date_str = self.request('http://www.shanbay.com', 'head'\n                                ).headers['date']\n        date_utc = datetime.datetime.strptime(date_str,\n                                              '%a, %d %b %Y %H:%M:%S GMT')\n        return date_utc", "response": "Get server s date in UTC"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of metafeatures computable by the Metafeatures class.", "response": "def list_metafeatures(cls, group=\"all\"):\n        \"\"\"\n        Returns a list of metafeatures computable by the Metafeatures class.\n        \"\"\"\n        # todo make group for intractable metafeatures for wide datasets or\n        # datasets with high cardinality categorical columns:\n        # PredPCA1, PredPCA2, PredPCA3, PredEigen1, PredEigen2, PredEigen3,\n        # PredDet, kNN1NErrRate, kNN1NKappa, LinearDiscriminantAnalysisKappa,\n        # LinearDiscriminantAnalysisErrRate\n        if group == \"all\":\n            return copy.deepcopy(cls.IDS)\n        elif group == \"landmarking\":\n            return list(filter(\n                lambda mf_id: \"ErrRate\" in mf_id or \"Kappa\" in mf_id, cls.IDS\n            ))\n        elif group == \"target_dependent\":\n            return list(filter(\n                cls._resource_is_target_dependent, cls.IDS\n            ))\n        else:\n            raise ValueError(f\"Unknown group {group}\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the metafeatures of the referenced base class for the given metafeatures.", "response": "def compute(\n        self, X: DataFrame, Y: Series=None,\n        column_types: Dict[str, str]=None, metafeature_ids: List=None,\n        exclude: List=None, sample_shape=None, seed=None, n_folds=2,\n        verbose=False, timeout=None\n    ) -> dict:\n        \"\"\"\n        Parameters\n        ----------\n        X: pandas.DataFrame, the dataset features\n        Y: pandas.Series, the dataset targets\n        column_types: Dict[str, str], dict from column name to column type as\n            \"NUMERIC\" or \"CATEGORICAL\" or \"TEXT\", must include Y column\n        metafeature_ids: list, the metafeatures to compute. default of None\n            indicates to compute all metafeatures\n        exclude: list, default None. The metafeatures to be excluded from computation.\n            Must be None if metafeature_ids is not None.\n        sample_shape: tuple, the shape of X after sampling (X,Y) uniformly.\n            Default is (None, None), indicate not to sample rows or columns.\n        seed: int, the seed used to generate pseudo-random numbers. when None\n            is given, a seed will be generated pseudo-randomly. this can be\n            used for reproducibility of metafeatures. a generated seed can be\n            accessed through the 'seed' property, after calling this method.\n        n_folds: int, the number of cross validation folds used by the\n            landmarking metafeatures. also affects the sample_shape validation\n        verbose: bool, default False. When True, prints the ID of each\n            metafeature right before it is about to be computed.\n        timeout: float, default None. If timeout is None, compute_metafeatures\n            will be run to completion. Otherwise, execution will halt after\n            approximately timeout seconds. Any metafeatures that have not been\n            computed will be labeled 'TIMEOUT'.\n\n        Returns\n        -------\n        A dictionary mapping the metafeature id to another dictionary containing\n        the `value` and `compute_time` (if requested) of the referencing\n        metafeature. The value is typically a number, but can be a string\n        indicating a reason why the value could not be computed.\n        \"\"\"\n        start_time = time.time()\n        self._validate_compute_arguments(\n            X, Y, column_types, metafeature_ids, exclude, sample_shape, seed,\n            n_folds, verbose\n        )\n        if timeout is None:\n            def check_time():\n                pass\n        else:\n            def check_time():\n                if time.time() - start_time > timeout:\n                    raise TimeoutError()\n        self._check_timeout = check_time\n\n        if column_types is None:\n            column_types = self._infer_column_types(X, Y)\n        if metafeature_ids is None:\n            metafeature_ids = self._get_metafeature_ids(exclude)\n            exclude = None\n        if sample_shape is None:\n            sample_shape = (None, None)\n        if seed is None:\n            seed = np.random.randint(np.iinfo(np.int32).max)\n        self._validate_compute_arguments(\n            X, Y, column_types, metafeature_ids, exclude, sample_shape, seed,\n            n_folds, verbose\n        )\n\n        self._init_resources(\n            X, Y, column_types, sample_shape, seed, n_folds\n        )\n\n        computed_metafeatures = {name: {self.VALUE_KEY: self.TIMEOUT, self.COMPUTE_TIME_KEY: 0}\n                                 for name in metafeature_ids}\n        try:\n            for metafeature_id in metafeature_ids:\n                self._check_timeout()\n                if verbose:\n                    print(metafeature_id)\n                if self._resource_is_target_dependent(metafeature_id) and (\n                    Y is None or column_types[Y.name] == self.NUMERIC\n                ):\n                    if Y is None:\n                        value = self.NO_TARGETS\n                    else:\n                        value = self.NUMERIC_TARGETS\n                    compute_time = None\n                else:\n                    value, compute_time = self._get_resource(metafeature_id)\n\n                computed_metafeatures[metafeature_id] = {\n                    self.VALUE_KEY: value,\n                    self.COMPUTE_TIME_KEY: compute_time\n                }\n        except TimeoutError:\n            pass\n\n        return computed_metafeatures"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstratifies uniform sampling of rows according to the classes in Y.", "response": "def _sample_rows(self, X, Y, sample_shape, seed):\n        \"\"\"\n        Stratified uniform sampling of rows, according to the classes in Y.\n        Ensures there are enough samples from each class in Y for cross\n        validation.\n        \"\"\"\n        if sample_shape[0] is None or X.shape[0] <= sample_shape[0]:\n            X_sample, Y_sample = X, Y\n        elif Y is None:\n            np.random.seed(seed)\n            row_indices = np.random.choice(\n                X.shape[0], size=sample_shape[0], replace=False\n            )\n            X_sample, Y_sample = X.iloc[row_indices], Y\n        else:\n            drop_size = X.shape[0] - sample_shape[0]\n            sample_size = sample_shape[0]\n            sss = StratifiedShuffleSplit(\n                n_splits=2, test_size=drop_size, train_size=sample_size, random_state=seed\n            )\n            row_indices, _ = next(sss.split(X, Y))\n            X_sample, Y_sample = X.iloc[row_indices], Y.iloc[row_indices]\n        return (X_sample, Y_sample)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new instance of a new key - value store using a token", "response": "def from_token(cls, url, path, token):\n        \"\"\"Constructor: use token authentication to read secrets from a Vault path\n\n        See https://www.vaultproject.io/docs/auth/token.html\n\n        Args:\n            url: Vault url\n            path: Vault path where secrets are stored\n            vault_token: token (must have access to vault path)\n        \"\"\"\n        source_dict = cls._fetch_secrets(url, path, token)\n        return cls(source_dict, url, path, token)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new object from a Vault AppRole", "response": "def from_app_role(cls, url, path, role_id, secret_id):\n        \"\"\"Constructor: use AppRole authentication to read secrets from a Vault path\n\n        See https://www.vaultproject.io/docs/auth/approle.html\n\n        Args:\n            url: Vault url\n            path: Vault path where secrets are stored\n            role_id: Vault RoleID\n            secret_id: Vault SecretID\n        \"\"\"\n        token = cls._fetch_app_role_token(url, role_id, secret_id)\n        source_dict = cls._fetch_secrets(url, path, token)\n        return cls(source_dict, url, path, token)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fetch_secrets(vault_url, path, token):\n        url = _url_joiner(vault_url, 'v1', path)\n        resp = requests.get(url, headers=VaultLoader._get_headers(token))\n        resp.raise_for_status()\n        data = resp.json()\n        if data.get('errors'):\n            raise VaultException(u'Error fetching Vault secrets from path {}: {}'\n                                 .format(path, data['errors']))\n        return data['data']", "response": "Fetch data from the vault path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches a Vault token using the RoleID and SecretID", "response": "def _fetch_app_role_token(vault_url, role_id, secret_id):\n        \"\"\"Get a Vault token, using the RoleID and SecretID\"\"\"\n        url = _url_joiner(vault_url, 'v1/auth/approle/login')\n        resp = requests.post(url, data={'role_id': role_id, 'secret_id': secret_id})\n        resp.raise_for_status()\n        data = resp.json()\n        if data.get('errors'):\n            raise VaultException(u'Error fetching Vault token: {}'.format(data['errors']))\n        return data['auth']['client_token']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreload the secrets from the vault path", "response": "def reload(self):\n        \"\"\"Reread secrets from the vault path\"\"\"\n        self._source = self._fetch_secrets(self._vault_url, self._path, self._token)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sorted_options(sort_options):\n    return [\n        {\n            'title': v['title'],\n            'value': ('-{0}'.format(k)\n                      if v.get('default_order', 'asc') == 'desc' else k),\n        }\n        for k, v in\n        sorted(sort_options.items(), key=lambda x: x[1].get('order', 0))\n    ]", "response": "Sort options for Invenio - Search - JS."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts html code into formatted plain text.", "response": "def html_to_plain_text(html):\n    \"\"\"Converts html code into formatted plain text.\"\"\"\n    # Use BeautifulSoup to normalize the html\n    soup = BeautifulSoup(html, \"html.parser\")\n    # Init the parser\n    parser = HTML2PlainParser()\n    parser.feed(str(soup.encode('utf-8')))\n    # Strip the end of the plain text\n    result = parser.text.rstrip()\n    # Add footnotes\n    if parser.links:\n        result += '\\n\\n'\n        for link in parser.links:\n            result += '[{}]: {}\\n'.format(link[0], link[1])\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_starttag(self, tag, attrs):\n        if (tag in self.newline_before_elements):\n            self.text += '\\n'\n        if (tag in self.stroke_before_elements and not\n                self.text.endswith(self.stroke_text)):\n            # Put a stroke in front of every relevant element, if there is some\n            # content between it and its predecessor\n            self.text += self.stroke_text\n        if tag == 'a':\n            # If it's a link, append it to the link list\n            for attr in attrs:\n                if attr[0] == 'href':\n                    self.links.append((len(self.links) + 1, attr[1]))", "response": "Handles every start tag like e. g. <p >."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_data(self, data):\n        # Only proceed with unignored elements\n        if self.lasttag not in self.ignored_elements:\n            # Remove any predefined linebreaks\n            text = data.replace('\\n', '')\n            # If there's some text left, proceed!\n            if text:\n                if self.lasttag == 'li':\n                    # Use a special prefix for list elements\n                    self.text += '  * '\n                self.text += text\n                if self.lasttag in self.newline_after_elements:\n                    # Add a linebreak at the end of the content\n                    self.text += '\\n'", "response": "Handles data between tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle every end tag like e. g. </p >.", "response": "def handle_endtag(self, tag):\n        \"\"\"Handles every end tag like e.g. </p>.\"\"\"\n        if tag in self.stroke_after_elements:\n            if self.text.endswith(self.stroke_text):\n                # Only add a stroke if there isn't already a stroke posted\n                # In this case, there was no content between the tags, so\n                # remove the starting stroke\n                self.text = self.text[:-len(self.stroke_text)]\n            else:\n                # If there's no linebreak before the stroke, add one!\n                if not self.text.endswith('\\n'):\n                    self.text += '\\n'\n                self.text += self.stroke_text\n        if tag == 'a':\n            # If it's a link, add a footnote\n            self.text += '[{}]'.format(len(self.links))\n        elif tag == 'br' and self.text and not self.text.endswith('\\n'):\n            # If it's a break, check if there's no break at the end of the\n            # content. If there's none, add one!\n            self.text += '\\n'\n        # Reset the lasttag, otherwise this parse can geht confused, if the\n        # next element is not wrapped in a new tag.\n        if tag == self.lasttag:\n            self.lasttag = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mygenerator(n=5, n_edges=5):\n    '''\n    Just a simple generator that creates a network with n nodes and\n    n_edges edges. Edges are assigned randomly, only avoiding self loops.\n    '''\n    G = nx.Graph()\n\n    for i in range(n):\n        G.add_node(i)\n    \n    for i in range(n_edges):\n        nodes = list(G.nodes)\n        n_in = choice(nodes)\n        nodes.remove(n_in)  # Avoid loops\n        n_out = choice(nodes)\n        G.add_edge(n_in, n_out)\n    return G", "response": "A simple generator that creates a network with n nodes and n_edges edges."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _import(self, datadict):\n        self.GUID = datadict.get(\"GUID\", uuid.uuid1())\n        self.FileName = datadict.get(\"FileName\", \"\")\n        self.Name = datadict.get(\"Name\", \"\")\n        self.WorkingDirectory = datadict.get(\"WorkingDirectory\", \"\")\n        self.OutputPath = datadict.get(\"OutputPath\", \"\")\n        self.RootNamespace = datadict.get(\"RootNamespace\", \"\")\n        self.ProjectHome = datadict.get(\"ProjectHome\", \"\")\n        self.StartupFile = datadict.get(\"StartupFile\", \"\")\n        self.CompileFiles = datadict.get(\"CompileFiles\", [])\n        self.ContentFiles = datadict.get(\"ContentFiles\", [])\n        self.Directories = datadict.get(\"Directories\", [])\n        self.DirectoryInFilter = datadict.get(\"DirectoryInFilter\", [])\n        self.DirectoryExFilter = datadict.get(\"DirectoryExFilter\", [])\n        self.CompileInFilter = datadict.get(\"CompileInFilter\", [])\n        self.CompileExFilter = datadict.get(\"CompileExFilter\", [])\n        self.ContentInFilter = datadict.get(\"ContentInFilter\", [])\n        self.ContentExFilter = datadict.get(\"ContentExFilter\", [])\n        self.VSVersion = datadict.get(\"VSVersion\", None)", "response": "Internal method to import instance variables data from a dictionary containing variables values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new instance of a VSGProject from a section.", "response": "def from_section(cls, config, section, **kwargs):\n        \"\"\"\n        Creates a :class:`~vsgen.project.VSGProject` from a :class:`~configparser.ConfigParser` section.\n\n        :param ConfigParser config:   A :class:`~configparser.ConfigParser` instance.\n        :param str          section:  A :class:`~configparser.ConfigParser` section key.\n        :param              kwargs:   List of additional keyworded arguments to be passed into the :class:`~vsgen.project.VSGProject`.\n        :return:                      A valid :class:`~vsgen.project.VSGProject` instance if succesful; None otherwise.\n        \"\"\"\n        p = cls(**kwargs)\n\n        p.Name = config.get(section, 'name', fallback=p.Name)\n        p.FileName = config.getfile(section, 'filename', fallback=p.FileName)\n        p.SearchPath = config.getdirs(section, 'search_path', fallback=p.SearchPath)\n        p.OutputPath = config.getdir(section, 'output_path', fallback=p.OutputPath)\n        p.WorkingDirectory = config.getdir(section, 'working_directory', fallback=p.WorkingDirectory)\n        p.RootNamespace = config.get(section, 'root_namespace', fallback=p.RootNamespace)\n        p.ProjectHome = config.getdir(section, 'project_home', fallback=p.ProjectHome)\n        p.StartupFile = config.getfile(section, 'startup_file', fallback=p.StartupFile)\n        p.CompileFiles = config.getlist(section, 'compile_files', fallback=p.CompileFiles)\n        p.ContentFiles = config.getlist(section, 'content_files', fallback=p.ContentFiles)\n        p.CompileInFilter = config.getlist(section, 'compile_in_filter', fallback=p.CompileInFilter)\n        p.CompileExFilter = config.getlist(section, 'compile_ex_filter', fallback=p.CompileExFilter)\n        p.ContentInFilter = config.getlist(section, 'content_in_filter', fallback=p.ContentInFilter)\n        p.ContentExFilter = config.getlist(section, 'content_ex_filter', fallback=p.ContentExFilter)\n        p.DirectoryInFilter = config.getlist(section, 'directory_in_filter', fallback=p.DirectoryInFilter)\n        p.DirectoryExFilter = config.getlist(section, 'directory_ex_filter', fallback=p.DirectoryExFilter)\n\n        root_path = config.get(section, 'root_path', fallback=\"\")\n        p.insert_files(root_path)\n\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ProjectHomeRelative(self):\n        return os.path.relpath(self.ProjectHome, os.path.dirname(self.FileName))", "response": "Returns the ProjectHome relative to the FileName directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef StartupFileRelative(self):\n        return os.path.relpath(self.StartupFile, self.ProjectHome) if self.StartupFile else self.StartupFile", "response": "Returns the StartupFile relative to the ProjectHome directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a generator iterating over the content files in the current directory.", "response": "def ContentFilesRelative(self):\n        \"\"\"\n        Returns a generator iterating over the each file in :attr:`ContentFiles` relative to :attr:`ProjectHome` directory.\n        \"\"\"\n        return (os.path.relpath(path, self.ProjectHome) for path in sorted(self.ContentFiles, key=self.lower))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CompileFilesRelative(self):\n        return (os.path.relpath(path, self.ProjectHome) for path in sorted(self.CompileFiles, key=self.lower))", "response": "Returns a generator iterating over the files in CompileFiles relative to ProjectHome directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DirectoriesRelative(self):\n        # Acquire all directories\n        directories = itertools.chain(self.Directories, (os.path.dirname(f) for f in itertools.chain(self.ContentFiles, self.CompileFiles)))\n        directories = set(os.path.relpath(d, self.ProjectHome) for d in directories)\n\n        # We need separate entries for parent directories of directories in the list\n        for path in set(directories):\n            subpath = os.path.dirname(path)\n            while subpath:\n                directories.add(subpath)\n                subpath = os.path.dirname(subpath)\n\n        return sorted(directories)", "response": "Returns an iterator over the directories referenced by the project relative to the ProjectHome directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_files(self, rootpath, directoryInFilter=None, directoryExFilter=None, compileInFilter=None, compileExFilter=None, contentInFilter=None, contentExFilter=None):\n        # Overrides\n        directoryInFilter = self.DirectoryInFilter if directoryInFilter is None else directoryInFilter\n        directoryExFilter = self.DirectoryExFilter if directoryExFilter is None else directoryExFilter\n        compileInFilter = self.CompileInFilter if compileInFilter is None else compileInFilter\n        compileExFilter = self.CompileExFilter if compileExFilter is None else compileExFilter\n        contentInFilter = self.ContentInFilter if contentInFilter is None else contentInFilter\n        contentExFilter = self.ContentExFilter if contentExFilter is None else contentExFilter\n\n        def filter(text, filters, explicit):\n            \"\"\"\n            Convience filter function\n\n            :param text text: The target text.\n            :param list filters: The collection of fnmatch expressions\n            :param bool explicit: Flag denoting an the empty filter collection return match failure.\n            \"\"\"\n            if explicit:\n                return any(fnmatch.fnmatch(text, f) for f in filters)\n            return not filters or any(fnmatch.fnmatch(text, f) for f in filters)\n\n        for root, dirnames, filenames in os.walk(rootpath):\n\n            searchdir = os.path.normpath(os.path.normcase(root))\n\n            # If the root dir matches an excluded directory, stop any further searches\n            if filter(searchdir, directoryExFilter, True):\n                dirnames[:] = []\n            elif filter(searchdir, directoryInFilter, False):\n                for filepath in [os.path.join(root, filename) for filename in filenames]:\n                    if filter(filepath, compileInFilter, False) and not filter(filepath, compileExFilter, True):\n                        self.CompileFiles.append(filepath)\n                    elif filter(filepath, contentInFilter, False) and not filter(filepath, contentExFilter, True):\n                        self.ContentFiles.append(filepath)", "response": "Inserts files in the current directory by recursive traversing the rootpath and inserting them according the addition filter parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_caveat(condition, root_key, third_party_info, key, ns):\n    '''Encrypt a third-party caveat.\n\n    The third_party_info key holds information about the\n    third party we're encrypting the caveat for; the key is the\n    public/private key pair of the party that's adding the caveat.\n\n    The caveat will be encoded according to the version information\n    found in third_party_info.\n\n    @param condition string\n    @param root_key bytes\n    @param third_party_info object\n    @param key nacl key\n    @param ns not used yet\n    @return bytes\n    '''\n    if third_party_info.version == VERSION_1:\n        return _encode_caveat_v1(condition, root_key,\n                                 third_party_info.public_key, key)\n    if (third_party_info.version == VERSION_2 or\n            third_party_info.version == VERSION_3):\n        return _encode_caveat_v2_v3(third_party_info.version, condition,\n                                    root_key, third_party_info.public_key,\n                                    key, ns)\n    raise NotImplementedError('only bakery v1, v2, v3 supported')", "response": "Encode a third - party caveat."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _encode_caveat_v1(condition, root_key, third_party_pub_key, key):\n    '''Create a JSON-encoded third-party caveat.\n\n    The third_party_pub_key key represents the PublicKey of the third party\n    we're encrypting the caveat for; the key is the public/private key pair of\n    the party that's adding the caveat.\n\n    @param condition string\n    @param root_key bytes\n    @param third_party_pub_key (PublicKey)\n    @param key (PrivateKey)\n    @return a base64 encoded bytes\n    '''\n    plain_data = json.dumps({\n        'RootKey': base64.b64encode(root_key).decode('ascii'),\n        'Condition': condition\n    })\n    box = nacl.public.Box(key.key, third_party_pub_key.key)\n\n    encrypted = box.encrypt(six.b(plain_data))\n    nonce = encrypted[0:nacl.public.Box.NONCE_SIZE]\n    encrypted = encrypted[nacl.public.Box.NONCE_SIZE:]\n    return base64.b64encode(six.b(json.dumps({\n        'ThirdPartyPublicKey': str(third_party_pub_key),\n        'FirstPartyPublicKey': str(key.public_key),\n        'Nonce': base64.b64encode(nonce).decode('ascii'),\n        'Id': base64.b64encode(encrypted).decode('ascii')\n    })))", "response": "Create a JSON - encoded third - party caveat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _encode_caveat_v2_v3(version, condition, root_key, third_party_pub_key,\n                         key, ns):\n    '''Create a version 2 or version 3 third-party caveat.\n\n    The format has the following packed binary fields (note\n    that all fields up to and including the nonce are the same\n    as the v2 format):\n\n        version 2 or 3 [1 byte]\n        first 4 bytes of third-party Curve25519 public key [4 bytes]\n        first-party Curve25519 public key [32 bytes]\n        nonce [24 bytes]\n        encrypted secret part [rest of message]\n\n    The encrypted part encrypts the following fields\n    with box.Seal:\n\n        version 2 or 3 [1 byte]\n        length of root key [n: uvarint]\n        root key [n bytes]\n        length of encoded namespace [n: uvarint] (Version 3 only)\n        encoded namespace [n bytes] (Version 3 only)\n        condition [rest of encrypted part]\n    '''\n    ns_data = bytearray()\n    if version >= VERSION_3:\n        ns_data = ns.serialize_text()\n    data = bytearray()\n    data.append(version)\n    data.extend(third_party_pub_key.serialize(raw=True)[:_PUBLIC_KEY_PREFIX_LEN])\n    data.extend(key.public_key.serialize(raw=True)[:])\n    secret = _encode_secret_part_v2_v3(version, condition, root_key, ns_data)\n    box = nacl.public.Box(key.key, third_party_pub_key.key)\n    encrypted = box.encrypt(secret)\n    nonce = encrypted[0:nacl.public.Box.NONCE_SIZE]\n    encrypted = encrypted[nacl.public.Box.NONCE_SIZE:]\n    data.extend(nonce[:])\n    data.extend(encrypted)\n    return bytes(data)", "response": "Encode a version 2 or version 3 third - party caveat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencode a version 2 or version 3 secret part of the third party caveat.", "response": "def _encode_secret_part_v2_v3(version, condition, root_key, ns):\n    '''Creates a version 2 or version 3 secret part of the third party\n    caveat. The returned data is not encrypted.\n\n    The format has the following packed binary fields:\n    version 2 or 3 [1 byte]\n    root key length [n: uvarint]\n    root key [n bytes]\n    namespace length [n: uvarint] (v3 only)\n    namespace [n bytes] (v3 only)\n    predicate [rest of message]\n    '''\n    data = bytearray()\n    data.append(version)\n    encode_uvarint(len(root_key), data)\n    data.extend(root_key)\n    if version >= VERSION_3:\n        encode_uvarint(len(ns), data)\n        data.extend(ns)\n    data.extend(condition.encode('utf-8'))\n    return bytes(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode a third party caveat by decrypting the encrypted part using key.", "response": "def decode_caveat(key, caveat):\n    '''Decode caveat by decrypting the encrypted part using key.\n\n    @param key the nacl private key to decode.\n    @param caveat bytes.\n    @return ThirdPartyCaveatInfo\n    '''\n    if len(caveat) == 0:\n        raise VerificationError('empty third party caveat')\n\n    first = caveat[:1]\n    if first == b'e':\n        # 'e' will be the first byte if the caveatid is a base64\n        # encoded JSON object.\n        return _decode_caveat_v1(key, caveat)\n    first_as_int = six.byte2int(first)\n    if (first_as_int == VERSION_2 or\n            first_as_int == VERSION_3):\n        if (len(caveat) < _VERSION3_CAVEAT_MIN_LEN\n                and first_as_int == VERSION_3):\n            # If it has the version 3 caveat tag and it's too short, it's\n            # almost certainly an id, not an encrypted payload.\n            raise VerificationError(\n                'caveat id payload not provided for caveat id {}'.format(\n                    caveat))\n        return _decode_caveat_v2_v3(first_as_int, key, caveat)\n    raise VerificationError('unknown version for caveat')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding a base64 encoded JSON string.", "response": "def _decode_caveat_v1(key, caveat):\n    '''Decode a base64 encoded JSON id.\n\n    @param key the nacl private key to decode.\n    @param caveat a base64 encoded JSON string.\n    '''\n\n    data = base64.b64decode(caveat).decode('utf-8')\n    wrapper = json.loads(data)\n    tp_public_key = nacl.public.PublicKey(\n        base64.b64decode(wrapper['ThirdPartyPublicKey']))\n    if key.public_key.key != tp_public_key:\n        raise Exception('public key mismatch')  # TODO\n\n    if wrapper.get('FirstPartyPublicKey', None) is None:\n        raise Exception('target service public key not specified')\n\n    # The encrypted string is base64 encoded in the JSON representation.\n    secret = base64.b64decode(wrapper.get('Id'))\n    nonce = base64.b64decode(wrapper.get('Nonce'))\n\n    fp_public_key = nacl.public.PublicKey(base64.b64decode(\n        wrapper.get('FirstPartyPublicKey')))\n\n    box = nacl.public.Box(key.key, fp_public_key)\n    c = box.decrypt(secret, nonce)\n    record = json.loads(c.decode('utf-8'))\n    fp_key = nacl.public.PublicKey(\n        base64.b64decode(wrapper.get('FirstPartyPublicKey')))\n    return ThirdPartyCaveatInfo(\n        condition=record.get('Condition'),\n        first_party_public_key=PublicKey(fp_key),\n        third_party_key_pair=key,\n        root_key=base64.b64decode(record.get('RootKey')),\n        caveat=caveat,\n        id=None,\n        version=VERSION_1,\n        namespace=legacy_namespace()\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _decode_caveat_v2_v3(version, key, caveat):\n    '''Decodes a version 2 or version 3 caveat.\n    '''\n    if (len(caveat) < 1 + _PUBLIC_KEY_PREFIX_LEN +\n            _KEY_LEN + nacl.public.Box.NONCE_SIZE + 16):\n        raise VerificationError('caveat id too short')\n    original_caveat = caveat\n    caveat = caveat[1:]  # skip version (already checked)\n\n    pk_prefix = caveat[:_PUBLIC_KEY_PREFIX_LEN]\n    caveat = caveat[_PUBLIC_KEY_PREFIX_LEN:]\n    if key.public_key.serialize(raw=True)[:_PUBLIC_KEY_PREFIX_LEN] != pk_prefix:\n        raise VerificationError('public key mismatch')\n\n    first_party_pub = caveat[:_KEY_LEN]\n    caveat = caveat[_KEY_LEN:]\n    nonce = caveat[:nacl.public.Box.NONCE_SIZE]\n    caveat = caveat[nacl.public.Box.NONCE_SIZE:]\n    fp_public_key = nacl.public.PublicKey(first_party_pub)\n    box = nacl.public.Box(key.key, fp_public_key)\n    data = box.decrypt(caveat, nonce)\n    root_key, condition, ns = _decode_secret_part_v2_v3(version, data)\n    return ThirdPartyCaveatInfo(\n        condition=condition.decode('utf-8'),\n        first_party_public_key=PublicKey(fp_public_key),\n        third_party_key_pair=key,\n        root_key=root_key,\n        caveat=original_caveat,\n        version=version,\n        id=None,\n        namespace=ns\n    )", "response": "Decodes a version 2 or version 3 caveat."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes integer into variable - length format into data.", "response": "def encode_uvarint(n, data):\n    '''encodes integer into variable-length format into data.'''\n    if n < 0:\n        raise ValueError('only support positive integer')\n    while True:\n        this_byte = n & 127\n        n >>= 7\n        if n == 0:\n            data.append(this_byte)\n            break\n        data.append(this_byte | 128)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_uvarint(data):\n    '''Decode a variable-length integer.\n\n    Reads a sequence of unsigned integer byte and decodes them into an integer\n    in variable-length format and returns it and the length read.\n    '''\n    n = 0\n    shift = 0\n    length = 0\n    for b in data:\n        if not isinstance(b, int):\n            b = six.byte2int(b)\n        n |= (b & 0x7f) << shift\n        length += 1\n        if (b & 0x80) == 0:\n            break\n        shift += 7\n    return n, length", "response": "Decode a variable - length integer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding type dictionary for user - defined type converters.", "response": "def build_type_dict(converters):\n    \"\"\"\n    Builds type dictionary for user-defined type converters,\n    used by :mod:`parse` module.\n    This requires that each type converter has a \"name\" attribute.\n\n    :param converters: List of type converters (parse_types)\n    :return: Type converter dictionary\n    \"\"\"\n    more_types = {}\n    for converter in converters:\n        assert callable(converter)\n        more_types[converter.name] = converter\n    return more_types"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a type converter for a list of items.", "response": "def make_list(cls, item_converter=None, listsep=','):\n        \"\"\"\n        Create a type converter for a list of items (many := 1..*).\n        The parser accepts anything and the converter needs to fail on errors.\n\n        :param item_converter:  Type converter for an item.\n        :param listsep:  List separator to use (as string).\n        :return: Type converter function object for the list.\n        \"\"\"\n        if not item_converter:\n            item_converter = parse_anything\n        return cls.with_cardinality(Cardinality.many, item_converter,\n                                pattern=cls.anything_pattern, listsep=listsep)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a type converter function for an enumeration or text - to - value mapping.", "response": "def make_enum(enum_mappings):\n        \"\"\"\n        Creates a type converter for an enumeration or text-to-value mapping.\n\n        :param enum_mappings: Defines enumeration names and values.\n        :return: Type converter function object for the enum/mapping.\n        \"\"\"\n        if (inspect.isclass(enum_mappings) and\n            issubclass(enum_mappings, enum.Enum)):\n            enum_class = enum_mappings\n            enum_mappings = enum_class.__members__\n\n        def convert_enum(text):\n            if text not in convert_enum.mappings:\n                text = text.lower()     # REQUIRED-BY: parse re.IGNORECASE\n            return convert_enum.mappings[text]    #< text.lower() ???\n        convert_enum.pattern = r\"|\".join(enum_mappings.keys())\n        convert_enum.mappings = enum_mappings\n        return convert_enum"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_choice(cls, choices, transform=None, strict=None):\n        # -- NOTE: Parser uses re.IGNORECASE flag\n        #    => transform may enforce case.\n        choices = cls._normalize_choices(choices, transform)\n        if strict is None:\n            strict = cls.default_strict\n\n        def convert_choice(text):\n            if transform:\n                text = transform(text)\n            if strict and not (text in convert_choice.choices):\n                values = \", \".join(convert_choice.choices)\n                raise ValueError(\"%s not in: %s\" % (text, values))\n            return text\n        convert_choice.pattern = r\"|\".join(choices)\n        convert_choice.choices = choices\n        return convert_choice", "response": "Creates a type converter function to select one from a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_choice2(cls, choices, transform=None, strict=None):\n        choices = cls._normalize_choices(choices, transform)\n        if strict is None:\n            strict = cls.default_strict\n\n        def convert_choice2(text):\n            if transform:\n                text = transform(text)\n            if strict and not (text in convert_choice2.choices):\n                values = \", \".join(convert_choice2.choices)\n                raise ValueError(\"%s not in: %s\" % (text, values))\n            index = convert_choice2.choices.index(text)\n            return index, text\n        convert_choice2.pattern = r\"|\".join(choices)\n        convert_choice2.choices = choices\n        return convert_choice2", "response": "Creates a type converter function to select one item from a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a type converter function object for a number of type converters.", "response": "def make_variant(cls, converters, re_opts=None, compiled=False, strict=True):\n        \"\"\"\n        Creates a type converter for a number of type converter alternatives.\n        The first matching type converter is used.\n\n        REQUIRES: type_converter.pattern attribute\n\n        :param converters: List of type converters as alternatives.\n        :param re_opts:  Regular expression options zu use (=default_re_opts).\n        :param compiled: Use compiled regexp matcher, if true (=False).\n        :param strict:   Enable assertion checks.\n        :return: Type converter function object.\n\n        .. note::\n\n            Works only with named fields in :class:`parse.Parser`.\n            Parser needs group_index delta for unnamed/fixed fields.\n            This is not supported for user-defined types.\n            Otherwise, you need to use :class:`parse_type.parse.Parser`\n            (patched version of the :mod:`parse` module).\n        \"\"\"\n        # -- NOTE: Uses double-dispatch with regex pattern rematch because\n        #          match is not passed through to primary type converter.\n        assert converters, \"REQUIRE: Non-empty list.\"\n        if len(converters) == 1:\n            return converters[0]\n        if re_opts is None:\n            re_opts = cls.default_re_opts\n\n        pattern = r\")|(\".join([tc.pattern for tc in converters])\n        pattern = r\"(\"+ pattern + \")\"\n        group_count = len(converters)\n        for converter in converters:\n            group_count += pattern_group_count(converter.pattern)\n\n        if compiled:\n            convert_variant = cls.__create_convert_variant_compiled(converters,\n                                                                re_opts, strict)\n        else:\n            convert_variant = cls.__create_convert_variant(re_opts, strict)\n        convert_variant.pattern = pattern\n        convert_variant.converters = tuple(converters)\n        # OLD: convert_variant.group_count = group_count\n        convert_variant.regex_group_count = group_count\n        return convert_variant"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncarry out a conversion and returns the converted quantity and its new units.", "response": "def parseUnits(self, inp):\n        \"\"\"Carries out a conversion (represented as a string) and returns the\n        result as a human-readable string.\n\n        Args:\n            inp (str): Text representing a unit conversion, which should\n                include a magnitude, a description of the initial units,\n                and a description of the target units to which the quantity\n                should be converted.\n\n        Returns:\n            A quantities object representing the converted quantity and its new\n            units.\n        \"\"\"\n        quantity = self.convert(inp)\n        units = ' '.join(str(quantity.units).split(' ')[1:])\n        return NumberService.parseMagnitude(quantity.item()) + \" \" + units"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef isValidUnit(self, w):\n        bad = set(['point', 'a'])\n        if w in bad:\n            return False\n\n        try:\n            pq.Quantity(0.0, w)\n            return True\n        except:\n            return w == '/'", "response": "Checks if a string represents a valid quantities unit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting all the valid units from an inp string and returns a list of strings each entry in which is a valid quantities unit.", "response": "def extractUnits(self, inp):\n        \"\"\"Collects all the valid units from an inp string. Works by\n        appending consecutive words from the string and cross-referncing\n        them with a set of valid units.\n\n        Args:\n            inp (str): Some text which hopefully contains descriptions\n                of different units.\n\n        Returns:\n            A list of strings, each entry in which is a valid quantities\n            unit.\n        \"\"\"\n        inp = self._preprocess(inp)\n\n        units = []\n        description = \"\"\n        for w in inp.split(' '):\n            if self.isValidUnit(w) or w == '/':\n                if description:\n                    description += \" \"\n                description += w\n            else:\n                if description:\n                    units.append(description)\n                description = \"\"\n\n        if description:\n            units.append(description)\n        return units"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert(self, inp):\n        inp = self._preprocess(inp)\n\n        n = NumberService().longestNumber(inp)\n        units = self.extractUnits(inp)\n\n        # Convert to quantity object, attempt conversion\n        quantity = pq.Quantity(float(n), units[0])\n        quantity.units = units[1]\n\n        return quantity", "response": "Converts a string representation of some quantity of units into a\n            quantity object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef allow(self, ctx, acls):\n        '''Allow access to any ACL members that was equal to the user name.\n\n        That is, some user u is considered a member of group u and no other.\n        '''\n        for acl in acls:\n            if self._identity == acl:\n                return True\n        return False", "response": "Allow access to any ACL members that were equal to the user name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexpand a list of paths into a list of resources or collections.", "response": "def expand_paths(paths=None, predicate=None, filters=None, parent_uuid=None):\n    \"\"\"Return an unique list of resources or collections from a list of paths.\n    Supports fq_name and wilcards resolution.\n\n    >>> expand_paths(['virtual-network',\n                      'floating-ip/2a0a54b4-a420-485e-8372-42f70a627ec9'])\n    [Collection('virtual-network'),\n     Resource('floating-ip', uuid='2a0a54b4-a420-485e-8372-42f70a627ec9')]\n\n    :param paths: list of paths relative to the current path\n                  that may contain wildcards (*, ?) or fq_names\n    :type paths: [str]\n    :param predicate: function to filter found resources\n    :type predicate: f(resource) -> bool\n    :param filters: list of filters for Collections\n    :type filters: [(name, value), ...]\n    :rtype: [Resource or Collection]\n    :raises BadPath: path cannot be resolved\n    \"\"\"\n    if not paths:\n        paths = [Context().shell.current_path]\n    else:\n        paths = [Context().shell.current_path / res for res in paths]\n\n    # use a dict to have unique paths\n    # but keep them ordered\n    result = OrderedDict()\n    for res in parallel_map(_path_to_resources, paths,\n                            kwargs={'predicate': predicate,\n                                    'filters': filters,\n                                    'parent_uuid': parent_uuid},\n                            workers=50):\n        for r in res:\n            result[r.path] = r\n\n    resources = list(result.values())\n    if not resources:\n        raise NotFound()\n    return resources"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a Jinja2 template to text.", "response": "def render(self, template, filename, context={}, filters={}):\n        \"\"\"\n        Renders a Jinja2 template to text.\n        \"\"\"\n        filename = os.path.normpath(filename)\n        path, file = os.path.split(filename)\n        try:\n            os.makedirs(path)\n        except OSError as exception:\n            if exception.errno != errno.EEXIST:\n                raise\n\n        path, file = os.path.split(template)\n        loader = jinja2.FileSystemLoader(path)\n        env = jinja2.Environment(loader=loader, trim_blocks=True, lstrip_blocks=True)\n        env.filters.update(filters)\n        template = env.get_template(file)\n        text = template.render(context)\n        with open(filename, 'wt') as f:\n            f.write(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interact(self, ctx, location, ir_err):\n        '''Implement Interactor.interact by opening the browser window\n        and waiting for the discharge token'''\n        p = ir_err.interaction_method(self.kind(), WebBrowserInteractionInfo)\n        if not location.endswith('/'):\n            location += '/'\n        visit_url = urljoin(location, p.visit_url)\n        wait_token_url = urljoin(location, p.wait_token_url)\n        self._open_web_browser(visit_url)\n        return self._wait_for_token(ctx, wait_token_url)", "response": "Implement Interactor. interact by opening the browser window\n        and waiting for the discharge token."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wait_for_token(self, ctx, wait_token_url):\n        ''' Returns a token from a the wait token URL\n        @param wait_token_url URL to wait for (string)\n        :return DischargeToken\n        '''\n        resp = requests.get(wait_token_url)\n        if resp.status_code != 200:\n            raise InteractionError('cannot get {}'.format(wait_token_url))\n        json_resp = resp.json()\n        kind = json_resp.get('kind')\n        if kind is None:\n            raise InteractionError(\n                'cannot get kind token from {}'.format(wait_token_url))\n        token_val = json_resp.get('token')\n        if token_val is None:\n            token_val = json_resp.get('token64')\n            if token_val is None:\n                raise InteractionError(\n                    'cannot get token from {}'.format(wait_token_url))\n            token_val = base64.b64decode(token_val)\n        return DischargeToken(kind=kind, value=token_val)", "response": "Returns a DischargeToken from a wait token URL"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_dict(cls, info_dict):\n        '''Create a new instance of WebBrowserInteractionInfo, as expected\n        by the Error.interaction_method method.\n        @param info_dict The deserialized JSON object\n        @return a new WebBrowserInteractionInfo object.\n        '''\n        return WebBrowserInteractionInfo(\n            visit_url=info_dict.get('VisitURL'),\n            wait_token_url=info_dict.get('WaitTokenURL'))", "response": "Create a new instance of WebBrowserInteractionInfo as expected\n        by the Error. interaction_method method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all the System objects known to the cluster.", "response": "def get(self):\n        \"\"\"\n        Returns a `list` of all the `System` objects to the cluster.  Updates every time - no caching.\n        :return: a `list` of all the `System` objects known to the cluster.\n        :rtype: list\n        \"\"\"\n        self.conn.connection._check_login()\n        response = self.conn.connection._do_get(\"{}/{}\".format(self.conn.connection._api_url, \"types/System/instances\")).json()\n        all_system_objects = []\n        for system_object in response:\n            all_system_objects.append(self.conn.System.from_dict(system_object))\n        return all_system_objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the name of the SDS object for the specified name.", "response": "def set_sds_name(self, name, sdsObj):\n        \"\"\"\n        Set name for SDS\n        :param name: Name of SDS\n        :param sdsObj: ScaleIO SDS object\n        :return: POST request response\n        :rtype: Requests POST response object\n        \"\"\"\n        # TODO:\n        # Check if object parameters are the correct type, otherwise throw error\n        # UNSURE IF THIS IS CORRECT WAY TO SET SDS NAME\n        self.conn.connection._check_login()\n        sdsNameDict = {'sdsName': name}\n        response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self.conn.connection._api_url, \"instances/Sds::\", sdcObj.id, 'action/setSdsName'), json=sdsNameDict)    \n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters SDS with MDM", "response": "def registerSds(self, sdsObj, **kwargs):\n        \"\"\"\n        Register SDS with MDM/SIO Cluster\n        :param sdsObj: ScaleIO SDS object\n        :return: POST request response\n        :rtype: Requests POST response object\n        \"\"\"\n        # Register existing SDS running SDS binary (need to be installed manually but not added to MDM)\n        # \n        self.conn.connection._check_login()    \n\n        response = self.conn.connection._do_post(\"{}/{}\".format(self.conn.connection._api_url, \"types/Sds/instances\"), json=sdsObj.__to_dict__())\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting list of SDS objects attached to a specific ScaleIO Faultset.", "response": "def get_sds_in_faultset(self, faultSetObj):\n        \"\"\"\n        Get list of SDS objects attached to a specific ScaleIO Faultset\n        :param faultSetObj: ScaleIO Faultset object\n        :rtype: list of SDS in specified Faultset\n        \"\"\"\n        self.conn.connection._check_login()\n        response = self.conn.connection._do_get(\"{}/{}{}/{}\".format(self.conn.connection._api_url, 'types/FaultSet::', faultSetObj.id, 'relationships/Sds')).json()\n        all_sds = []\n        for sds in response:\n            all_sds.append(\n                SIO_SDS.from_dict(sds)\n            )\n        return all_sds"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets ScaleIO SDS object by its name.", "response": "def get_sds_by_name(self,name):\n        \"\"\"\n        Get ScaleIO SDS object by its name\n        :param name: Name of SDS\n        :return: ScaleIO SDS object\n        :raise KeyError: No SDS with specified name found\n        :rtype: SDS object\n        \"\"\"\n        for sds in self.sds:\n            if sds.name == name:\n                return sds\n        raise KeyError(\"SDS of that name not found\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets ScaleIO SDS object by its ip address", "response": "def get_sds_by_ip(self,ip):\n        \"\"\"\n        Get ScaleIO SDS object by its ip address\n        :param name: IP address of SDS\n        :return: ScaleIO SDS object\n        :raise KeyError: No SDS with specified ip found\n        :rtype: SDS object\n        \"\"\"\n        if self.conn.is_ip_addr(ip):\n            for sds in self.sds:\n                for sdsIp in sds.ipList:\n                    if sdsIp == ip:\n                        return sds\n            raise KeyError(\"SDS of that name not found\")\n        else:\n            raise ValueError(\"Malformed IP address - get_sds_by_ip()\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_sds_by_id(self,id):\n        for sds in self.sds:\n            if sds.id == id:\n                return sds\n        raise KeyError(\"SDS with that ID not found\")", "response": "Get ScaleIO SDS object by its id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting a new value for a given configuration parameter.", "response": "def set(self, name, value, overwrite=False):\n        \"\"\"\n        Sets a new value for a given configuration parameter.\n\n        If it already exists, an Exception is thrown.\n        To overwrite an existing value, set overwrite to True.\n\n        :param name: Unique name of the parameter\n        :param value: Value of the configuration parameter\n        :param overwrite: If true, an existing parameter of *name* gets overwritten without warning or exception.\n        :type overwrite: boolean\n        \"\"\"\n        if hasattr(self, name):\n            if overwrite:\n                setattr(self, name, value)\n            else:\n                self._log.warning(\"Configuration parameter %s exists and overwrite not allowed\" % name)\n                raise Exception(\"Configuration parameter %s exists and overwrite not allowed\" % name)\n        else:\n            setattr(self, name, value)\n        return getattr(self, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates missing types for fields with a CardinalityField part.", "response": "def create_missing_types(cls, schema, type_dict, type_builder=None):\n        \"\"\"Creates missing types for fields with a CardinalityField part.\n        It is assumed that the primary type converter for cardinality=1\n        is registered in the type dictionary.\n\n        :param schema:  Parse schema (or format) for parser (as string).\n        :param type_dict:  Type dictionary with type converters.\n        :param type_builder: Type builder to use for missing types.\n        :return: Type dictionary with missing types. Empty, if none.\n        :raises: MissingTypeError,\n                if a primary type converter with cardinality=1 is missing.\n        \"\"\"\n        if not type_builder:\n            type_builder = cls.type_builder\n\n        missing = cls.extract_missing_special_type_names(schema, type_dict)\n        return type_builder.create_type_variants(missing, type_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_missing_special_type_names(schema, type_dict):\n        for name in FieldParser.extract_types(schema):\n            if CardinalityField.matches_type(name) and (name not in type_dict):\n                    yield name", "response": "Extract the type names for fields with CardinalityField part."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks an allow or deny caveat.", "response": "def _check_operations(ctx, need_ops, arg):\n    ''' Checks an allow or a deny caveat. The need_ops parameter specifies\n    whether we require all the operations in the caveat to be declared in\n    the context.\n    '''\n    ctx_ops = ctx.get(OP_KEY, [])\n    if len(ctx_ops) == 0:\n        if need_ops:\n            f = arg.split()\n            if len(f) == 0:\n                return 'no operations allowed'\n            return '{} not allowed'.format(f[0])\n        return None\n\n    fields = arg.split()\n    for op in ctx_ops:\n        err = _check_op(op, need_ops, fields)\n        if err is not None:\n            return err\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the caveat against all registered caveat conditions.", "response": "def check_first_party_caveat(self, ctx, cav):\n        ''' Checks the caveat against all registered caveat conditions.\n        :return: error message string if any or None\n        '''\n        try:\n            cond, arg = parse_caveat(cav)\n        except ValueError as ex:\n            # If we can't parse it, perhaps it's in some other format,\n            # return a not-recognised error.\n            return 'cannot parse caveat \"{}\": {}'.format(cav, ex.args[0])\n        checker = self._checkers.get(cond)\n        if checker is None:\n            return 'caveat \"{}\" not satisfied: caveat not recognized'.format(\n                cav)\n        err = checker.check(ctx, cond, arg)\n        if err is not None:\n            return 'caveat \"{}\" not satisfied: {}'.format(cav, err)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of CheckerInfo objects sorted by namespace and then name", "response": "def info(self):\n        ''' Returns information on all the registered checkers.\n\n        Sorted by namespace and then name\n        :returns a list of CheckerInfo\n        '''\n        return sorted(self._checkers.values(), key=lambda x: (x.ns, x.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters the given condition in the given namespace uri with the given check function.", "response": "def register(self, cond, uri, check):\n        ''' Registers the given condition(string) in the given namespace\n        uri (string) to be checked with the given check function.\n        The check function checks a caveat by passing an auth context, a cond\n        parameter(string) that holds the caveat condition including any\n        namespace prefix and an arg parameter(string) that hold any additional\n        caveat argument text. It will return any error as string otherwise\n        None.\n\n        It will raise a ValueError if the namespace is not registered or\n        if the condition has already been registered.\n        '''\n        if check is None:\n            raise RegisterError(\n                'no check function registered for namespace {} when '\n                'registering condition {}'.format(uri, cond))\n\n        prefix = self._namespace.resolve(uri)\n        if prefix is None:\n            raise RegisterError('no prefix registered for namespace {} when '\n                                'registering condition {}'.format(uri, cond))\n\n        if prefix == '' and cond.find(':') >= 0:\n            raise RegisterError(\n                'caveat condition {} in namespace {} contains a colon but its'\n                ' prefix is empty'.format(cond, uri))\n\n        full_cond = condition_with_prefix(prefix, cond)\n        info = self._checkers.get(full_cond)\n        if info is not None:\n            raise RegisterError(\n                'checker for {} (namespace {}) already registered in '\n                'namespace {}'.format(full_cond, uri, info.ns))\n        self._checkers[full_cond] = CheckerInfo(\n            check=check,\n            ns=uri,\n            name=cond,\n            prefix=prefix)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_std(self):\n        ''' Registers all the standard checkers in the given checker.\n\n        If not present already, the standard checkers schema (STD_NAMESPACE) is\n        added to the checker's namespace with an empty prefix.\n        '''\n        self._namespace.register(STD_NAMESPACE, '')\n        for cond in _ALL_CHECKERS:\n            self.register(cond, STD_NAMESPACE, _ALL_CHECKERS[cond])", "response": "Registers all the standard checkers in the given checker."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authorize(self, ctx, identity, ops):\n        '''Implements Authorizer.authorize by calling f with the given identity\n        for each operation.\n        '''\n        allowed = []\n        caveats = []\n        for op in ops:\n            ok, fcaveats = self._f(ctx, identity, op)\n            allowed.append(ok)\n            if fcaveats is not None:\n                caveats.extend(fcaveats)\n        return allowed, caveats", "response": "Implements Authorizer. authorize by calling f with the given identity\n        for each operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements Authorizer. authorize by calling identity. allow to determine whether the identity is a member of the ACLs associated with the given operations.", "response": "def authorize(self, ctx, identity, ops):\n        '''Implements Authorizer.authorize by calling identity.allow to\n        determine whether the identity is a member of the ACLs associated with\n        the given operations.\n        '''\n        if len(ops) == 0:\n            # Anyone is allowed to do nothing.\n            return [], []\n        allowed = [False] * len(ops)\n        has_allow = isinstance(identity, ACLIdentity)\n        for i, op in enumerate(ops):\n            acl = self._get_acl(ctx, op)\n            if has_allow:\n                allowed[i] = identity.allow(ctx, acl)\n            else:\n                allowed[i] = self._allow_public and EVERYONE in acl\n        return allowed, []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_relevant(self, action, subject):\n        return self.matches_action(action) and self.matches_subject(subject)", "response": "Returns True if the action and subject match the conditions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that a given HAL id is a valid one.", "response": "def is_valid(hal_id):\n    \"\"\"\n    Check that a given HAL id is a valid one.\n\n    :param hal_id: The HAL id to be checked.\n    :returns: Boolean indicating whether the HAL id is valid or not.\n\n    >>> is_valid(\"hal-01258754, version 1\")\n    True\n\n    >>> is_valid(\"hal-01258754\")\n    True\n\n    >>> is_valid(\"hal-01258754v2\")\n    True\n\n    >>> is_valid(\"foobar\")\n    False\n    \"\"\"\n    match = REGEX.match(hal_id)\n    return (match is not None) and (match.group(0) == hal_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_from_text(text):\n    return tools.remove_duplicates([i[0]\n                                    for i in REGEX.findall(text) if i != ''])", "response": "Extract HAL ids from a text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getsolution(self, config, section, **kwargs):\n        if section not in config:\n            raise ValueError('Section [{}] not found in [{}]'.format(section, ', '.join(config.sections())))\n\n        s = VSGSolution(**kwargs)\n\n        s.Name = config.get(section, 'name', fallback=s.Name)\n        s.FileName = os.path.normpath(config.get(section, 'filename', fallback=s.FileName))\n        s.VSVersion = config.getfloat(section, 'visual_studio_version', fallback=s.VSVersion)\n        if not s.VSVersion:\n            raise ValueError('Solution section [%s] requires a value for Visual Studio Version (visual_studio_version)' % section)\n\n        project_sections = config.getlist(section, 'projects', fallback=[])\n        for project_section in project_sections:\n            project = self._getproject(config, project_section, VSVersion=s.VSVersion)\n            s.Projects.append(project)\n\n        return s", "response": "Creates a VSG solution from a configparser instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a VSG project from a configparser instance.", "response": "def _getproject(self, config, section, **kwargs):\n        \"\"\"\n        Creates a VSG project from a configparser instance.\n\n        :param object config: The instance of the configparser class\n        :param str section: The section name to read.\n        :param kwargs:  List of additional keyworded arguments to be passed into the VSGProject.\n        :return: A valid VSGProject instance if succesful; None otherwise.\n        \"\"\"\n        if section not in config:\n            raise ValueError('Section [{}] not found in [{}]'.format(section, ', '.join(config.sections())))\n\n        type = config.get(section, 'type', fallback=None)\n        if not type:\n            raise ValueError('Section [{}] mandatory option \"{}\" not found'.format(section, \"type\"))\n\n        project_class = entrypoint('vsgen.projects', type)\n        return project_class.from_section(config, section, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an instance of the class VSGSuite from a file.", "response": "def from_file(cls, filename):\n        \"\"\"\n        Creates an VSGSuite instance from a filename.\n\n        :param str filename:  The fully qualified path to the VSG configuration file.\n        \"\"\"\n        # Read the configuration file\n        config = VSGConfigParser()\n        if filename not in config.read([filename]):\n            raise ValueError('Could not read VSG configuration file %s.' % filename)\n\n        # set the root\n        root = config.get('vsgen', 'root')\n        root = os.path.normpath(os.path.join(os.path.dirname(filename), root))\n        config.set('vsgen', 'root', root)\n\n        return VSGSuite(config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a parser for the VSGSuite classes.", "response": "def make_parser(cls, **kwargs):\n        \"\"\"\n        Creates a :class:`~argparse.ArgumentParser` instances to work with VSGSuite classes.\n\n        :param kwargs:  List of additional keyworded arguments to be passed into the :class:`~argparse.ArgumentParser`.\n        :return:  A :class:`~argparse.ArgumentParser` instance.\n        \"\"\"\n        # Build a parent parser\n        parser = argparse.ArgumentParser(**kwargs)\n\n        # Add multiple sub-commands:\n        subparsers = parser.add_subparsers(help='Available commands.', dest='suite_commands')\n\n        # 'Generate' command\n        file_parser = subparsers.add_parser('generate', help='Generates solutions and projects based on one or more configuration files.')\n        file_parser.add_argument('configuration_filenames', metavar='file', nargs='+', help='The configuration file that contains the [vsgen.*] sections contains the vsgen input.')\n\n        # 'Auto' command\n        auto_parser = subparsers.add_parser('auto', help='Automatically generates a solution and project collection from vsgen preset and a single directory.')\n\n        # Build a subparser for each type of project\n        suite_parsers = auto_parser.add_subparsers(help='Available Project Types.', dest='suite_type')\n        for ek, ev in entrypoints('vsgen.suites').items():\n            suite_parser = ev.make_parser(add_help=False)\n            suite_parsers.add_parser(ek, help='Automatically generates a solution and \"{}\" project from a single directory.'.format(ek), parents=[suite_parser])\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate one or more VSGSuite instances from command line arguments.", "response": "def from_args(cls, **kwargs):\n        \"\"\"\n        Generates one or more VSGSuite instances from command line arguments.\n\n        :param kwargs:  List of additional keyworded arguments to be passed into the VSGSuite defined in the :meth:`~VSGSuite.make_parser` method.\n        \"\"\"\n        # Create a VSGSuite for each filename on the command line.\n        if kwargs.get('suite_commands', None) == 'generate':\n            filenames = kwargs.pop('configuration_filenames', [])\n            return [cls.from_file(f) for f in filenames]\n\n        # Create a VSGSuit from the target directory and override commands\n        if kwargs.get('suite_commands', None) == 'auto':\n            type = kwargs.get('suite_type', None)\n            return [cls.from_directory('', type, **kwargs)]\n\n        # Create nothing.\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_directory(cls, directory, type, **kwargs):\n        # Resolve the suite class from the type\n        suite_class = entrypoint('vsgen.suites', type)\n\n        # Merge the default and any additional, maybe override, params.\n        params = {\n            'root': os.path.abspath(directory),\n            'name': os.path.basename(os.path.abspath(directory))\n        }\n        params.update({k: v for k, v in kwargs.items() if v is not None})\n        return suite_class(**params)", "response": "Creates an instance of the class specified by the type and the directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the configuration to disk.", "response": "def write(self, parallel=True):\n        \"\"\"\n        Writes the configuration to disk.\n        \"\"\"\n        # Write the Solution files\n        solutions = sorted(self._solutions, key=lambda x: x.Name)\n        with VSGWriteCommand('Writing VSG Solution', solutions, parallel) as command:\n            command.execute()\n\n        # Write the Projects files\n        projects = set(sorted((p for s in solutions for p in s.Projects), key=lambda x: x.Name))\n        with VSGWriteCommand('Writing VSG Projects', projects, parallel) as command:\n            command.execute()\n\n        # Register the registerables\n        registerables = set(sorted((p for s in solutions for p in s.Projects), key=lambda x: x.Name))\n        with VSGRegisterCommand('Registering Project Registerables', registerables) as command:\n            command.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a plaintext representation of a bibitem.", "response": "def bibitem_as_plaintext(bibitem):\n    \"\"\"\n    Return a plaintext representation of a bibitem from the ``.bbl`` file.\n\n    .. note::\n\n        This plaintext representation can be super ugly, contain URLs and so \\\n        on.\n\n    .. note::\n\n        You need to have ``delatex`` installed system-wide, or to build it in \\\n                this repo, according to the ``README.md`` before using this \\\n                function.\n\n    :param bibitem: The text content of the bibitem.\n    :returns: A cleaned plaintext citation from the bibitem.\n    \"\"\"\n    try:\n        output = subprocess.check_output([\"delatex\",\n                                          \"-s\"],\n                                         input=bibitem.encode(\"utf-8\"))\n    except FileNotFoundError:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        output = subprocess.check_output([\"%s/../external/opendetex/delatex\" %\n                                          (script_dir,),\n                                          \"-s\"],\n                                         input=bibitem.encode(\"utf-8\"))\n    output = output.decode(\"utf-8\")\n    output = tools.clean_whitespaces(output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plaintext_citations(bbl):\n    # Handle path or content\n    if os.path.isfile(bbl):\n        with open(bbl, 'r') as fh:\n            bbl_content = fh.read()\n    else:\n        bbl_content = bbl\n    # Get a list of bibitems, taking the first item out as it is *before* the\n    # first \\bibitem\n    bibitems = BIBITEMS_REGEX.split(bbl_content)[1:]\n    # Delete the text after the \\end{thebibliography}\n    bibitems = [ENDTHEBIBLIOGRAPHY_REGEX.sub(\"\", i).strip() for i in bibitems]\n    # Clean every bibitem to have plaintext\n    cleaned_bbl = [bibitem_as_plaintext(bibitem) for bibitem in bibitems]\n    return cleaned_bbl", "response": "Parse a. bbl file to get a list of plaintext citations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a ProtetionDomain object by its name", "response": "def get_pd_by_name(self, name):\n        \"\"\"\n        Get ScaleIO ProtectionDomain object by its name\n        :param name: Name of ProtectionDomain\n        :return: ScaleIO ProtectionDomain object\n        :raise KeyError: No ProtetionDomain with specified name found\n        :rtype: ProtectionDomain object\n        \"\"\"\n        for pd in self.conn.protection_domains:\n            if pd.name == name:\n                return pd\n        raise KeyError(\"Protection Domain NAME \" + name + \" not found\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_pd_by_id(self, id):\n        for pd in self.conn.protection_domains:\n            if pd.id == id:\n                return pd\n        raise KeyError(\"Protection Domain with ID \" + id + \" not found\")", "response": "Get a ProtectionDomain object by its id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_potection_domain(self, pdObj):\n        self.conn.connection._check_login()\n        response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self.conn.connection._api_url, \"instances/ProtectionDomain::\", pdObj.id, 'action/removeProtectionDomain'))\n        return response", "response": "Delete a potential domain from the Protection Domain"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_type(cls, type_name):\n        if cls.matches_type(type_name):\n            basename = type_name[:-1]\n            cardinality = cls.from_char_map[type_name[-1]]\n        else:\n            # -- ASSUME: Cardinality.one\n            cardinality = Cardinality.one\n            basename = type_name\n        return (basename, cardinality)", "response": "Split a type name with CardinalityField suffix into its parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_type(cls, basename, cardinality):\n        if cardinality is Cardinality.one:\n            # -- POSTCONDITION: assert not cls.make_type(type_name)\n            return basename\n        # -- NORMAL CASE: type with CardinalityField suffix.\n        type_name = \"%s%s\" % (basename, cls.to_char_map[cardinality])\n        # -- POSTCONDITION: assert cls.make_type(type_name)\n        return type_name", "response": "Build a new type name according to CardinalityField naming scheme."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a type variant for a specific type.", "response": "def create_type_variant(cls, type_name, type_converter):\n        \"\"\"\n        Create type variants for types with a cardinality field.\n        The new type converters are based on the type converter with\n        cardinality=1.\n\n        .. code-block:: python\n\n            import parse\n\n            @parse.with_pattern(r'\\d+')\n            def parse_number(text):\n                return int(text)\n\n            new_type = CardinalityFieldTypeBuilder.create_type_variant(\n                                    \"Number+\", parse_number)\n            new_type = CardinalityFieldTypeBuilder.create_type_variant(\n                                    \"Number+\", dict(Number=parse_number))\n\n        :param type_name:  Type name with cardinality field suffix.\n        :param type_converter:  Type converter or type dictionary.\n        :return: Type converter variant (function).\n        :raises: ValueError, if type_name does not end with CardinalityField\n        :raises: MissingTypeError, if type_converter is missing in type_dict\n        \"\"\"\n        assert isinstance(type_name, six.string_types)\n        if not CardinalityField.matches_type(type_name):\n            message = \"type_name='%s' has no CardinalityField\" % type_name\n            raise ValueError(message)\n\n        primary_name, cardinality = CardinalityField.split_type(type_name)\n        if isinstance(type_converter, dict):\n            type_dict = type_converter\n            type_converter = type_dict.get(primary_name, None)\n            if not type_converter:\n                raise MissingTypeError(primary_name)\n\n        assert callable(type_converter)\n        type_variant = TypeBuilder.with_cardinality(cardinality,\n                                    type_converter, listsep=cls.listsep)\n        type_variant.name = type_name\n        return type_variant"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate type variants for types with a cardinality field suffix.", "response": "def create_type_variants(cls, type_names, type_dict):\n        \"\"\"\n        Create type variants for types with a cardinality field.\n        The new type converters are based on the type converter with\n        cardinality=1.\n\n        .. code-block:: python\n\n            # -- USE: parse_number() type converter function.\n            new_types = CardinalityFieldTypeBuilder.create_type_variants(\n                            [\"Number?\", \"Number+\"], dict(Number=parse_number))\n\n        :param type_names: List of type names with cardinality field suffix.\n        :param type_dict:  Type dictionary with named type converters.\n        :return: Type dictionary with type converter variants.\n        \"\"\"\n        type_variant_dict = {}\n        for type_name in type_names:\n            type_variant = cls.create_type_variant(type_name, type_dict)\n            type_variant_dict[type_name] = type_variant\n        return type_variant_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates missing type variants for types with cardinality field suffix.", "response": "def create_missing_type_variants(cls, type_names, type_dict):\n        \"\"\"\n        Create missing type variants for types with a cardinality field.\n\n        :param type_names: List of type names with cardinality field suffix.\n        :param type_dict:  Type dictionary with named type converters.\n        :return: Type dictionary with missing type converter variants.\n        \"\"\"\n        missing_type_names = [ name for name in type_names\n                               if name not in type_dict ]\n        return cls.create_type_variants(missing_type_names, type_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef system(self):\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/System/instances\")).json()\n        all_system_objects = []\n        for system_object in response:\n            all_system_objects.append(SIO_System.from_dict(system_object))\n        return all_system_objects", "response": "Returns a list of all the System objects known to the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all the System objects known to the cluster. Updates every time - no caching.", "response": "def storage_pools(self):\n        \"\"\"\n        Returns a `list` of all the `System` objects to the cluster.  Updates every time - no caching.\n        :return: a `list` of all the `System` objects known to the cluster.\n        :rtype: list\n        \"\"\"\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/StoragePool/instances\")).json() \n        all_storage_pools = []\n        for storage_pool_object in response:\n            all_storage_pools.append(SIO_Storage_Pool.from_dict(storage_pool_object))\n        return all_storage_pools"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all the SDC known to the cluster. Updates every time - no caching.", "response": "def sdc(self):\n        \"\"\"\n        Returns a `list` of all the `ScaleIO_SDC` known to the cluster.  Updates every time - no caching.\n        :return: a `list` of all the `ScaleIO_SDC` known to the cluster.\n        :rtype: list\n        \"\"\"\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/Sdc/instances\")).json()       \n        all_sdc = []\n        for sdc in response:\n            all_sdc.append(\n                SIO_SDC.from_dict(sdc)\n            )\n        return all_sdc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sds(self):\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url,\"types/Sds/instances\")).json()\n        all_sds = []\n        for sds in response:\n            all_sds.append(\n                SIO_SDS.from_dict(sds)\n            )\n        return all_sds", "response": "Returns a list of all the SIO_SDS known to the cluster. Updates every time - no caching."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef volumes(self):\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/Volume/instances\")).json()\n        all_volumes = []\n        for volume in response:\n            all_volumes.append(\n                SIO_Volume.from_dict(volume)\n            )\n        return all_volumes", "response": "Returns a list of all the SIO_Volume objects known to the cluster. Updates every time - no caching."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the Volumes of type Snapshot. Updates every time - no caching.", "response": "def snapshots(self):\n        \"\"\"\n        Get all Volumes of type Snapshot.  Updates every time - no caching.\n        :return: a `list` of all the `ScaleIO_Volume` that have a are of type Snapshot.\n        :rtype: list\n        \"\"\"\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/Volume/instances\")).json()\n        all_volumes_snapshot = []\n        for volume in response:\n            if volume['volumeType'] == 'Snapshot':\n                all_volumes_snapshot.append(\n                    Volume.from_dict(volume)\n            )\n        return all_volumes_snapshot"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all the Protection Domains in this API", "response": "def protection_domains(self):\n        \"\"\"\n        :rtype: list of Protection Domains\n        \"\"\"\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/ProtectionDomain/instances\")).json()\n        all_pds = []\n        for pd in response:\n            all_pds.append(\n                SIO_Protection_Domain.from_dict(pd)\n            )\n        return all_pds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all fault sets in the system", "response": "def fault_sets(self):\n        \"\"\"\n        You can only create and configure Fault Sets before adding SDSs to the system, and configuring them incorrectly\n        may prevent the creation of volumes. An SDS can only be added to a Fault Set during the creation of the SDS.\n        :rtype: list of Faultset objects\n        \"\"\"\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/FaultSet/instances\")).json()\n        all_faultsets = []\n        for fs in response:\n            all_faultsets.append(\n                SIO_Fault_Set.from_dict(fs)\n            )\n        return all_faultsets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vtrees(self):\n        self.connection._check_login()\n        response = self.connection._do_get(\"{}/{}\".format(self.connection._api_url, \"types/VTree/instances\")).json()\n        all_vtrees = []\n        for vtree in response:\n            all_vtrees.append(\n                SIO_Vtree.from_dict(vtree)\n            )\n        return all_vtrees", "response": "Get list of VTrees from ScaleIO cluster"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_ip_addr(self, ipstr):\n        ipstr_chunks = ipstr.split('.')\n        if len(ipstr_chunks) != 4:\n            return False\n        for ipstr_chunk in ipstr_chunks:\n            if not ipstr_chunk.isdigit():\n                return False\n            ipno_part = int(ipstr_chunk)\n            if ipno_part < 0 or ipno_part > 255:\n                return False\n        return True", "response": "Helper method to verify if string is an IP addr?"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put_ops(self, key, time, ops):\n        ''' Put an ops only if not already there, otherwise it's a no op.\n        '''\n        if self._store.get(key) is None:\n            self._store[key] = ops", "response": "Put an ops only if not already there."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ops(self, key):\n        ''' Returns ops from the key if found otherwise raises a KeyError.\n        '''\n        ops = self._store.get(key)\n        if ops is None:\n            raise KeyError(\n                'cannot get operations for {}'.format(key))\n        return ops", "response": "Returns the list of operations for the given key if found otherwise raises a KeyError."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_local_location(loc):\n    '''Parse a local caveat location as generated by LocalThirdPartyCaveat.\n\n    This is of the form:\n\n        local <version> <pubkey>\n\n    where <version> is the bakery version of the client that we're\n    adding the local caveat for.\n\n    It returns None if the location does not represent a local\n    caveat location.\n    @return a ThirdPartyInfo.\n    '''\n    if not (loc.startswith('local ')):\n        return None\n    v = VERSION_1\n    fields = loc.split()\n    fields = fields[1:]  # Skip 'local'\n    if len(fields) == 2:\n        try:\n            v = int(fields[0])\n        except ValueError:\n            return None\n        fields = fields[1:]\n    if len(fields) == 1:\n        key = PublicKey.deserialize(fields[0])\n        return ThirdPartyInfo(public_key=key, version=v)\n    return None", "response": "Parse a local caveat location as generated by LocalThirdPartyCaveat."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_caveat(self, cav, key=None, loc=None):\n        '''Add a caveat to the macaroon.\n\n        It encrypts it using the given key pair\n        and by looking up the location using the given locator.\n        As a special case, if the caveat's Location field has the prefix\n        \"local \" the caveat is added as a client self-discharge caveat using\n        the public key base64-encoded in the rest of the location. In this\n        case, the Condition field must be empty. The resulting third-party\n        caveat will encode the condition \"true\" encrypted with that public\n        key.\n\n        @param cav the checkers.Caveat to be added.\n        @param key the public key to encrypt third party caveat.\n        @param loc locator to find information on third parties when adding\n        third party caveats. It is expected to have a third_party_info method\n        that will be called with a location string and should return a\n        ThirdPartyInfo instance holding the requested information.\n        '''\n        if cav.location is None:\n            self._macaroon.add_first_party_caveat(\n                self.namespace.resolve_caveat(cav).condition)\n            return\n        if key is None:\n            raise ValueError(\n                'no private key to encrypt third party caveat')\n        local_info = _parse_local_location(cav.location)\n        if local_info is not None:\n            info = local_info\n            if cav.condition is not '':\n                raise ValueError(\n                    'cannot specify caveat condition in '\n                    'local third-party caveat')\n            cav = checkers.Caveat(location='local', condition='true')\n        else:\n            if loc is None:\n                raise ValueError(\n                    'no locator when adding third party caveat')\n            info = loc.third_party_info(cav.location)\n\n        root_key = os.urandom(24)\n\n        # Use the least supported version to encode the caveat.\n        if self._version < info.version:\n            info = ThirdPartyInfo(\n                version=self._version,\n                public_key=info.public_key,\n            )\n\n        caveat_info = encode_caveat(\n            cav.condition, root_key, info, key, self._namespace)\n        if info.version < VERSION_3:\n            # We're encoding for an earlier client or third party which does\n            # not understand bundled caveat info, so use the encoded\n            # caveat information as the caveat id.\n            id = caveat_info\n        else:\n            id = self._new_caveat_id(self._caveat_id_prefix)\n            self._caveat_data[id] = caveat_info\n\n        self._macaroon.add_third_party_caveat(cav.location, root_key, id)", "response": "Add a caveat to the macaroon."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an array of caveats to the macaroon.", "response": "def add_caveats(self, cavs, key, loc):\n        '''Add an array of caveats to the macaroon.\n\n        This method does not mutate the current object.\n        @param cavs arrary of caveats.\n        @param key the PublicKey to encrypt third party caveat.\n        @param loc locator to find the location object that has a method\n        third_party_info.\n        '''\n        if cavs is None:\n            return\n        for cav in cavs:\n            self.add_caveat(cav, key, loc)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        '''Return a dict representation of the macaroon data in JSON format.\n        @return a dict\n        '''\n        if self.version < VERSION_3:\n            if len(self._caveat_data) > 0:\n                raise ValueError('cannot serialize pre-version3 macaroon with '\n                                 'external caveat data')\n            return json.loads(self._macaroon.serialize(\n                json_serializer.JsonSerializer()))\n        serialized = {\n            'm': json.loads(self._macaroon.serialize(\n                json_serializer.JsonSerializer())),\n            'v': self._version,\n        }\n        if self._namespace is not None:\n            serialized['ns'] = self._namespace.serialize_text().decode('utf-8')\n        caveat_data = {}\n        for id in self._caveat_data:\n            key = base64.b64encode(id).decode('utf-8')\n            value = base64.b64encode(self._caveat_data[id]).decode('utf-8')\n            caveat_data[key] = value\n        if len(caveat_data) > 0:\n            serialized['cdata'] = caveat_data\n        return serialized", "response": "Return a dict representation of the macaroon data in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a macaroon obtained from the given dictionary as deserialized from JSON.", "response": "def from_dict(cls, json_dict):\n        '''Return a macaroon obtained from the given dictionary as\n        deserialized from JSON.\n        @param json_dict The deserialized JSON object.\n        '''\n        json_macaroon = json_dict.get('m')\n        if json_macaroon is None:\n            # Try the v1 format if we don't have a macaroon field.\n            m = pymacaroons.Macaroon.deserialize(\n                json.dumps(json_dict), json_serializer.JsonSerializer())\n            macaroon = Macaroon(root_key=None, id=None,\n                                namespace=legacy_namespace(),\n                                version=_bakery_version(m.version))\n            macaroon._macaroon = m\n            return macaroon\n\n        version = json_dict.get('v', None)\n        if version is None:\n            raise ValueError('no version specified')\n        if (version < VERSION_3 or\n                version > LATEST_VERSION):\n            raise ValueError('unknown bakery version {}'.format(version))\n        m = pymacaroons.Macaroon.deserialize(json.dumps(json_macaroon),\n                                             json_serializer.JsonSerializer())\n        if m.version != macaroon_version(version):\n            raise ValueError(\n                'underlying macaroon has inconsistent version; '\n                'got {} want {}'.format(m.version, macaroon_version(version)))\n        namespace = checkers.deserialize_namespace(json_dict.get('ns'))\n        cdata = json_dict.get('cdata', {})\n        caveat_data = {}\n        for id64 in cdata:\n            id = b64decode(id64)\n            data = b64decode(cdata[id64])\n            caveat_data[id] = data\n        macaroon = Macaroon(root_key=None, id=None,\n                            namespace=namespace,\n                            version=version)\n        macaroon._caveat_data = caveat_data\n        macaroon._macaroon = m\n        return macaroon"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a macaroon deserialized from a string", "response": "def deserialize_json(cls, serialized_json):\n        '''Return a macaroon deserialized from a string\n        @param serialized_json The string to decode {str}\n        @return {Macaroon}\n        '''\n        serialized = json.loads(serialized_json)\n        return Macaroon.from_dict(serialized)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _new_caveat_id(self, base):\n        '''Return a third party caveat id\n\n        This does not duplicate any third party caveat ids already inside\n        macaroon. If base is non-empty, it is used as the id prefix.\n\n        @param base bytes\n        @return bytes\n        '''\n        id = bytearray()\n        if len(base) > 0:\n            id.extend(base)\n        else:\n            # Add a version byte to the caveat id. Technically\n            # this is unnecessary as the caveat-decoding logic\n            # that looks at versions should never see this id,\n            # but if the caveat payload isn't provided with the\n            # payload, having this version gives a strong indication\n            # that the payload has been omitted so we can produce\n            # a better error for the user.\n            id.append(VERSION_3)\n\n        # Iterate through integers looking for one that isn't already used,\n        # starting from n so that if everyone is using this same algorithm,\n        # we'll only perform one iteration.\n        i = len(self._caveat_data)\n        caveats = self._macaroon.caveats\n        while True:\n            # We append a varint to the end of the id and assume that\n            # any client that's created the id that we're using as a base\n            # is using similar conventions - in the worst case they might\n            # end up with a duplicate third party caveat id and thus create\n            # a macaroon that cannot be discharged.\n            temp = id[:]\n            encode_uvarint(i, temp)\n            found = False\n            for cav in caveats:\n                if (cav.verification_key_id is not None\n                        and cav.caveat_id == temp):\n                    found = True\n                    break\n            if not found:\n                return bytes(temp)\n            i += 1", "response": "Return a third party caveat id This does not duplicate any third party caveat ids already inside the macaroon."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\n        ''' Returns a copy of the macaroon. Note that the the new\n        macaroon's namespace still points to the same underlying Namespace -\n        copying the macaroon does not make a copy of the namespace.\n        :return a Macaroon\n        '''\n        m1 = Macaroon(None, None, version=self._version,\n                      namespace=self._namespace)\n        m1._macaroon = self._macaroon.copy()\n        m1._caveat_data = self._caveat_data.copy()\n        return m1", "response": "Returns a copy of the macaroon."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the discharge hook function.", "response": "def _prepare_discharge_hook(req, client):\n    ''' Return the hook function (called when the response is received.)\n\n    This allows us to intercept the response and do any necessary\n    macaroon discharge before returning.\n    '''\n    class Retry:\n        # Define a local class so that we can use its class variable as\n        # mutable state accessed by the closures below.\n        count = 0\n\n    def hook(response, *args, **kwargs):\n        ''' Requests hooks system, this is the hook for the response.\n        '''\n        status_code = response.status_code\n\n        if status_code != 407 and status_code != 401:\n            return response\n        if (status_code == 401 and response.headers.get('WWW-Authenticate') !=\n                'Macaroon'):\n            return response\n\n        if response.headers.get('Content-Type') != 'application/json':\n            return response\n        errorJSON = response.json()\n        if errorJSON.get('Code') != ERR_DISCHARGE_REQUIRED:\n            return response\n        error = Error.from_dict(errorJSON)\n        Retry.count += 1\n        if Retry.count >= MAX_DISCHARGE_RETRIES:\n            raise BakeryException('too many ({}) discharge requests'.format(\n                Retry.count)\n            )\n        client.handle_error(error, req.url)\n        req.headers.pop('Cookie', None)\n        req.prepare_cookies(client.cookies)\n        req.headers[BAKERY_PROTOCOL_HEADER] = \\\n            str(bakery.LATEST_VERSION)\n        with requests.Session() as s:\n            return s.send(req)\n    return hook"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_macaroons(headers_or_request):\n    ''' Returns an array of any macaroons found in the given slice of cookies.\n    If the argument implements a get_header method, that will be used\n    instead of the get method to retrieve headers.\n    @param headers_or_request: dict of headers or a\n    urllib.request.Request-like object.\n    @return: A list of list of mpy macaroons\n    '''\n    def get_header(key, default=None):\n        try:\n            return headers_or_request.get_header(key, default)\n        except AttributeError:\n            return headers_or_request.get(key, default)\n\n    mss = []\n\n    def add_macaroon(data):\n        try:\n            data = utils.b64decode(data)\n            data_as_objs = json.loads(data.decode('utf-8'))\n        except ValueError:\n            return\n        ms = [utils.macaroon_from_dict(x) for x in data_as_objs]\n        mss.append(ms)\n\n    cookie_header = get_header('Cookie')\n    if cookie_header is not None:\n        cs = SimpleCookie()\n        # The cookie might be a unicode object, so convert it\n        # to ASCII. This may cause an exception under Python 2.\n        # TODO is that a problem?\n        cs.load(str(cookie_header))\n        for c in cs:\n            if c.startswith('macaroon-'):\n                add_macaroon(cs[c].value)\n    # Python doesn't make it easy to have multiple values for a\n    # key, so split the header instead, which is necessary\n    # for HTTP1.1 compatibility anyway (see RFC 7230, section 3.2.2)\n    macaroon_header = get_header('Macaroons')\n    if macaroon_header is not None:\n        for h in macaroon_header.split(','):\n            add_macaroon(h)\n    return mss", "response": "Returns an array of any macaroons found in the given slice of cookies."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a field to the serialized dictionary.", "response": "def _add_json_binary_field(b, serialized, field):\n    '''' Set the given field to the given val (bytes) in the serialized\n    dictionary.\n    If the value isn't valid utf-8, we base64 encode it and use field+\"64\"\n    as the field name.\n    '''\n    try:\n        val = b.decode('utf-8')\n        serialized[field] = val\n    except UnicodeDecodeError:\n        val = base64.b64encode(b).decode('utf-8')\n        serialized[field + '64'] = val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a macaroon from a legacy wait endpoint.", "response": "def _wait_for_macaroon(wait_url):\n    ''' Returns a macaroon from a legacy wait endpoint.\n    '''\n    headers = {\n        BAKERY_PROTOCOL_HEADER: str(bakery.LATEST_VERSION)\n    }\n    resp = requests.get(url=wait_url, headers=headers)\n    if resp.status_code != 200:\n        raise InteractionError('cannot get {}'.format(wait_url))\n\n    return bakery.Macaroon.from_dict(resp.json().get('Macaroon'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying a URL as found in an ErrInteractionRequired VisitURL field to find available interaction methods.", "response": "def _legacy_get_interaction_methods(u):\n    ''' Queries a URL as found in an ErrInteractionRequired VisitURL field to\n    find available interaction methods.\n    It does this by sending a GET request to the URL with the Accept\n    header set to \"application/json\" and parsing the resulting\n    response as a dict.\n    '''\n    headers = {\n        BAKERY_PROTOCOL_HEADER: str(bakery.LATEST_VERSION),\n        'Accept': 'application/json'\n    }\n    resp = requests.get(url=u, headers=headers)\n    method_urls = {}\n    if resp.status_code == 200:\n        json_resp = resp.json()\n        for m in json_resp:\n            method_urls[m] = urljoin(u, json_resp[m])\n\n    if method_urls.get('interactive') is None:\n        # There's no \"interactive\" method returned, but we know\n        # the server does actually support it, because all dischargers\n        # are required to, so fill it in with the original URL.\n        method_urls['interactive'] = u\n    return method_urls"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(self, method, url, **kwargs):\n        '''Use the requests library to make a request.\n        Using this method is like doing:\n\n            requests.request(method, url, auth=client.auth())\n        '''\n        # TODO should we raise an exception if auth or cookies are explicitly\n        # mentioned in kwargs?\n        kwargs['auth'] = self.auth()\n        kwargs['cookies'] = self.cookies\n        return requests.request(method=method, url=url, **kwargs)", "response": "Use the requests library to make a request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to resolve the given error which should be a response to the given URL. If the error is a response then the error will be a response . If the error is an ERR_DISCHARGE_REQUIREDException then the exception will be raised.", "response": "def handle_error(self, error, url):\n        '''Try to resolve the given error, which should be a response\n        to the given URL, by discharging any macaroon contained in\n        it. That is, if error.code is ERR_DISCHARGE_REQUIRED\n        then it will try to discharge err.info.macaroon. If the discharge\n        succeeds, the discharged macaroon will be saved to the client's cookie\n        jar, otherwise an exception will be raised.\n        '''\n        if error.info is None or error.info.macaroon is None:\n            raise BakeryException('unable to read info in discharge error '\n                                  'response')\n\n        discharges = bakery.discharge_all(\n            error.info.macaroon,\n            self.acquire_discharge,\n            self.key,\n        )\n        macaroons = '[' + ','.join(map(utils.macaroon_to_json_string,\n                                       discharges)) + ']'\n        all_macaroons = base64.urlsafe_b64encode(utils.to_bytes(macaroons))\n\n        full_path = urljoin(url, error.info.macaroon_path)\n        if error.info.cookie_name_suffix is not None:\n            name = 'macaroon-' + error.info.cookie_name_suffix\n        else:\n            name = 'macaroon-auth'\n        expires = checkers.macaroons_expiry_time(checkers.Namespace(), discharges)\n        self.cookies.set_cookie(utils.cookie(\n            name=name,\n            value=all_macaroons.decode('ascii'),\n            url=full_path,\n            expires=expires,\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests a discharge macaroon from the caveat location as an HTTP URL.", "response": "def acquire_discharge(self, cav, payload):\n        ''' Request a discharge macaroon from the caveat location\n        as an HTTP URL.\n        @param cav Third party {pymacaroons.Caveat} to be discharged.\n        @param payload External caveat data {bytes}.\n        @return The acquired macaroon {macaroonbakery.Macaroon}\n        '''\n        resp = self._acquire_discharge_with_token(cav, payload, None)\n        # TODO Fabrice what is the other http response possible ??\n        if resp.status_code == 200:\n            return bakery.Macaroon.from_dict(resp.json().get('Macaroon'))\n        cause = Error.from_dict(resp.json())\n        if cause.code != ERR_INTERACTION_REQUIRED:\n            raise DischargeError(cause.message)\n        if cause.info is None:\n            raise DischargeError(\n                'interaction-required response with no info: {}'.format(\n                    resp.json())\n            )\n        loc = cav.location\n        if not loc.endswith('/'):\n            loc = loc + '/'\n        token, m = self._interact(loc, cause, payload)\n        if m is not None:\n            # We've acquired the macaroon directly via legacy interaction.\n            return m\n        # Try to acquire the discharge again, but this time with\n        # the token acquired by the interaction method.\n        resp = self._acquire_discharge_with_token(cav, payload, token)\n        if resp.status_code == 200:\n            return bakery.Macaroon.from_dict(resp.json().get('Macaroon'))\n        else:\n            raise DischargeError(\n                'discharge failed with code {}'.format(resp.status_code))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a DischargeToken and a bakery. Macaroon.", "response": "def _interact(self, location, error_info, payload):\n        '''Gathers a macaroon by directing the user to interact with a\n        web page. The error_info argument holds the interaction-required\n        error response.\n        @return DischargeToken, bakery.Macaroon\n        '''\n        if (self._interaction_methods is None or\n                len(self._interaction_methods) == 0):\n            raise InteractionError('interaction required but not possible')\n        # TODO(rogpeppe) make the robust against a wider range of error info.\n        if error_info.info.interaction_methods is None and \\\n                error_info.info.visit_url is not None:\n            # It's an old-style error; deal with it differently.\n            return None, self._legacy_interact(location, error_info)\n        for interactor in self._interaction_methods:\n            found = error_info.info.interaction_methods.get(interactor.kind())\n            if found is None:\n                continue\n            try:\n                token = interactor.interact(self, location, error_info)\n            except InteractionMethodNotFound:\n                continue\n            if token is None:\n                raise InteractionError('interaction method returned an empty '\n                                       'token')\n            return token, None\n\n        raise InteractionError('no supported interaction method')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef random_secret_exponent(curve_order):\n    # run a rejection sampling algorithm to ensure the random int is less\n    # than the curve order\n    while True:\n        # generate a random 256 bit hex string\n        random_hex = hexlify(dev_urandom_entropy(32))\n        random_int = int(random_hex, 16)\n        if random_int >= 1 and random_int < curve_order:\n            break\n    return random_int", "response": "Generates a random secret exponent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dict2bibtex(data):\n    bibtex = '@' + data['ENTRYTYPE'] + '{' + data['ID'] + \",\\n\"\n\n    for field in [i for i in sorted(data) if i not in ['ENTRYTYPE', 'ID']]:\n        bibtex += \"\\t\" + field + \"={\" + data[field] + \"},\\n\"\n    bibtex += \"}\\n\\n\"\n    return bibtex", "response": "Convert a dictionary representing a BibTeX entry into a BibTeX string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite a BibTeX file.", "response": "def write(filename, data):\n    \"\"\"\n    Create a new BibTeX file.\n\n    :param filename: The name of the BibTeX file to write.\n    :param data: A ``bibtexparser.BibDatabase`` object.\n    \"\"\"\n    with open(filename, 'w') as fh:\n        fh.write(bibdatabase2bibtex(data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nedits an entry in a BibTeX file.", "response": "def edit(filename, identifier, data):\n    \"\"\"\n    Update an entry in a BibTeX file.\n\n    :param filename: The name of the BibTeX file to edit.\n    :param identifier: The id of the entry to update, in the BibTeX file.\n    :param data: A dict associating fields and updated values. Fields present \\\n            in the BibTeX file but not in this dict will be kept as is.\n    \"\"\"\n    # Get current bibtex\n    with open(filename, 'r') as fh:\n        bibtex = bibtexparser.load(fh)\n\n    # Update it\n    # TODO: Not working\n    bibtex.entries_dict[identifier] = data.entries[0]\n\n    # Write the resulting BibTeX\n    write(filename, bibtex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an entry in a BibTeX file.", "response": "def delete(filename, identifier):\n    \"\"\"\n    Delete an entry in a BibTeX file.\n\n    :param filename: The name of the BibTeX file to edit.\n    :param identifier: The id of the entry to delete, in the BibTeX file.\n    \"\"\"\n    # Get current bibtex\n    with open(filename, 'r') as fh:\n        bibtex = bibtexparser.load(fh)\n\n    # Delete the bibtex entry\n    # TODO: Not working\n    try:\n        del bibtex.entries_dict[identifier]\n    except KeyError:\n        pass\n\n    # Write the resulting BibTeX\n    write(filename, bibtex)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all entries from a BibTeX file.", "response": "def get(filename, ignore_fields=None):\n    \"\"\"\n    Get all entries from a BibTeX file.\n\n    :param filename: The name of the BibTeX file.\n    :param ignore_fields: An optional list of fields to strip from the BibTeX \\\n            file.\n\n    :returns: A ``bibtexparser.BibDatabase`` object representing the fetched \\\n            entries.\n    \"\"\"\n    # Handle default argument\n    if ignore_fields is None:\n        ignore_fields = []\n\n    # Open bibtex file\n    with open(filename, 'r') as fh:\n        bibtex = bibtexparser.load(fh)\n\n    # Clean the entries if necessary\n    bibtex.entries = [{k: entry[k]\n                       for k in entry if k not in ignore_fields}\n                      for entry in bibtex.entries]\n\n    return bibtex"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an entry from a BibTeX file.", "response": "def get_entry_by_filter(filename, filter_function, ignore_fields=None):\n    \"\"\"\n    Get an entry from a BibTeX file.\n\n    .. note ::\n\n        Returns the first matching entry.\n\n    :param filename: The name of the BibTeX file.\n    :param filter_function: A function returning ``True`` or ``False`` \\\n            whether the entry should be included or not.\n    :param ignore_fields: An optional list of fields to strip from the BibTeX \\\n            file.\n\n    :returns: A ``bibtexparser.BibDatabase`` object representing the \\\n            first matching entry. ``None`` if entry was not found.\n    \"\"\"\n    # Handle default argument\n    if ignore_fields is None:\n        ignore_fields = []\n\n    # Open bibtex file\n    with open(filename, 'r') as fh:\n        bibtex = bibtexparser.load(fh)\n\n    matching_entry = None\n    try:\n        # Try to fetch the matching entry dict\n        for entry in bibtex.entries:\n            if filter_function(entry):\n                matching_entry = entry\n    except KeyError:\n        # If none found, return None\n        return None\n\n    if matching_entry is None:\n        return None\n\n    # Clean the entry dict if necessary\n    matching_entry = {k: matching_entry[k]\n                      for k in matching_entry if k not in ignore_fields}\n\n    bib_db = bibtexparser.bibdatabase.BibDatabase()\n    bib_db.entries = [matching_entry]\n    return bib_db"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an entry from a BibTeX file.", "response": "def get_entry(filename, identifier, ignore_fields=None):\n    \"\"\"\n    Get an entry from a BibTeX file.\n\n    :param filename: The name of the BibTeX file.\n    :param identifier: An id of the entry to fetch, in the BibTeX file.\n    :param ignore_fields: An optional list of fields to strip from the BibTeX \\\n            file.\n\n    :returns: A ``bibtexparser.BibDatabase`` object representing the \\\n            fetched entry. ``None`` if entry was not found.\n    \"\"\"\n    # Handle default argument\n    if ignore_fields is None:\n        ignore_fields = []\n\n    return get_entry_by_filter(filename,\n                               lambda x: x[\"ID\"] == identifier,\n                               ignore_fields)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_filename(data,\n                mask=DEFAULT_PAPERS_FILENAME_MASK,\n                extra_formatters=None):\n    \"\"\"\n    Convert a bibtex entry to a formatted filename according to a given mask.\n\n    .. note ::\n\n        Available formatters out of the box are:\n            - ``journal``\n            - ``title``\n            - ``year``\n            - ``first`` for the first author\n            - ``last`` for the last author\n            - ``authors`` for the list of authors\n            - ``arxiv_version`` (discarded if no arXiv version in the BibTeX)\n\n        Filename is slugified after applying the masks.\n\n    :param data: A ``bibtexparser.BibDatabase`` object representing a \\\n            BibTeX entry, as the one from ``bibtexparser`` output.\n    :param mask: A Python format string.\n    :param extra_formatters: A dict of format string (in the mask) and \\\n            associated lambdas to perform the formatting.\n\n    :returns: A formatted filename.\n    \"\"\"\n    # Handle default argument\n    if extra_formatters is None:\n        extra_formatters = {}\n\n    entry = data.entries[0]\n    authors = re.split(' and ', entry['author'])\n\n    formatters = {\n        \"journal\": \"\",\n        \"title\": \"\",\n        \"year\": \"\",\n        \"first\": \"\",\n        \"last\": \"\",\n        \"authors\": \"\",\n        \"arxiv_version\": \"\"\n    }\n\n    formatters[\"journal\"] = entry.get(\"journal\", \"\")\n    formatters[\"title\"] = entry.get(\"title\", \"\")\n    formatters[\"year\"] = entry.get(\"year\", \"\")\n\n    formatters[\"first\"] = authors[0].split(',')[0].strip()\n    formatters[\"last\"] = authors[-1].split(',')[0].strip()\n    formatters[\"authors\"] = \", \".join([i.split(',')[0].strip()\n                                       for i in authors])\n\n    for extra_formatter in extra_formatters:\n        formatters[extra_formatter] = extra_formatters[extra_formatter](entry)\n\n    arxiv_version = \"\"\n    if \"eprint\" in entry:\n        arxiv_version = '-' + entry['eprint'][entry['eprint'].rfind('v'):]\n    formatters[\"arxiv_version\"] = arxiv_version\n\n    return tools.slugify(mask.format(**formatters))", "response": "Convert a bibtex entry to a formatted filename according to a given mask."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a constant - width integer from a file - like object.", "response": "async def load_uint(reader, width):\n    \"\"\"\n    Constant-width integer serialization\n    :param reader:\n    :param width:\n    :return:\n    \"\"\"\n    buffer = _UINT_BUFFER\n    result = 0\n    shift = 0\n    for _ in range(width):\n        await reader.areadinto(buffer)\n        result += buffer[0] << shift\n        shift += 8\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_uvarint_b(buffer):\n    result = 0\n    idx = 0\n    byte = 0x80\n    while byte & 0x80:\n        byte = buffer[idx]\n        result += (byte & 0x7F) << (7 * idx)\n        idx += 1\n    return result", "response": "Variable int deserialization synchronous from buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing n as variable size integer to the provided buffer.", "response": "def dump_uvarint_b_into(n, buffer, offset=0):\n    \"\"\"\n    Serializes n as variable size integer to the provided buffer.\n    Buffer has to ha\n    :param n:\n    :param buffer:\n    :param offset:\n    :return:\n    \"\"\"\n    shifted = True\n    while shifted:\n        shifted = n >> 7\n        buffer[offset] = (n & 0x7F) | (0x80 if shifted else 0x00)\n        offset += 1\n        n = shifted\n    return buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads fixed size integer from the buffer.", "response": "def load_uint_b(buffer, width):\n    \"\"\"\n    Loads fixed size integer from the buffer\n    :param buffer:\n    :return:\n    \"\"\"\n    result = 0\n    for idx in range(width):\n        result += buffer[idx] << (8 * idx)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize fixed size integer into a buffer.", "response": "def dump_uint_b_into(n, width, buffer, offset=0):\n    \"\"\"\n    Serializes fixed size integer to the buffer\n    :param n:\n    :param width:\n    :return:\n    \"\"\"\n    for idx in range(width):\n        buffer[idx + offset] = n & 0xff\n        n >>= 8\n    return buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bind_name(self, name):\n        if self.name:\n            raise errors.Error('Already bound \"{0}\" with name \"{1}\" could not '\n                               'be rebound'.format(self, self.name))\n        self.name = name\n        self.storage_name = ''.join(('_', self.name))\n        return self", "response": "Bind field to its name in model class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbinds field to model class.", "response": "def bind_model_cls(self, model_cls):\n        \"\"\"Bind field to model class.\"\"\"\n        if self.model_cls:\n            raise errors.Error('\"{0}\" has been already bound to \"{1}\" and '\n                               'could not be rebound to \"{2}\"'.format(\n                                   self, self.model_cls, model_cls))\n        self.model_cls = model_cls\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value(self, model, default=None):\n        if default is not None:\n            default = self._converter(default)\n\n        value = getattr(model, self.storage_name)\n        return value if value is not None else default", "response": "Return field s value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_value(self, model, value):\n        if value is None and self.required:\n            raise AttributeError(\"This field is required.\")\n\n        if value is not None:\n            value = self._converter(value)\n\n        setattr(model, self.storage_name, value)", "response": "Set field s value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_model_instance(model_cls, data):\n        if not isinstance(data, (model_cls, dict)):\n            raise TypeError('{0} is not valid type, instance of '\n                            '{1} or dict required'.format(data, model_cls))\n        return model_cls(**data) if isinstance(data, dict) else data", "response": "Convert dict into object of class model_cls."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts raw input value of the field.", "response": "def _converter(self, value):\n        \"\"\"Convert raw input value of the field.\"\"\"\n        if not isinstance(value, datetime.date):\n            raise TypeError('{0} is not valid date'.format(value))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _converter(self, value):\n        if type(value) is not self.related_model_cls.Collection:\n            value = self.related_model_cls.Collection([\n                self._get_model_instance(self.related_model_cls, item)\n                for item in value])\n        return value", "response": "Convert raw input value of the field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns built - in type representation of Collection.", "response": "def get_builtin_type(self, model):\n        \"\"\"Return built-in type representation of Collection.\n\n        :param DomainModel model:\n        :rtype list:\n        \"\"\"\n        return [item.get_data() if isinstance(item, self.related_model_cls)\n                else item for item in self.get_value(model)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(text):\n    ret = Docstring()\n    if not text:\n        return ret\n\n    text = inspect.cleandoc(text)\n    match = re.search('^:', text, flags=re.M)\n    if match:\n        desc_chunk = text[:match.start()]\n        meta_chunk = text[match.start():]\n    else:\n        desc_chunk = text\n        meta_chunk = ''\n\n    parts = desc_chunk.split('\\n', 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or ''\n        ret.blank_after_short_description = long_desc_chunk.startswith('\\n')\n        ret.blank_after_long_description = long_desc_chunk.endswith('\\n\\n')\n        ret.long_description = long_desc_chunk.strip() or None\n\n    for match in re.finditer(\n            r'(^:.*?)(?=^:|\\Z)', meta_chunk, flags=re.S | re.M\n    ):\n        chunk = match.group(0)\n        if not chunk:\n            continue\n        try:\n            args_chunk, desc_chunk = chunk.lstrip(':').split(':', 1)\n        except ValueError:\n            raise ParseError(\n                'Error parsing meta information near \"{}\".'.format(chunk)\n            )\n        args = args_chunk.split()\n        desc = desc_chunk.strip()\n        if '\\n' in desc:\n            first_line, rest = desc.split('\\n', 1)\n            desc = first_line + '\\n' + inspect.cleandoc(rest)\n        ret.meta.append(DocstringMeta(args, description=desc, type=None))\n\n    return ret", "response": "Parse the docstring into its components."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies DocstringMeta from another instance.", "response": "def from_meta(cls, meta, meta_all=None):\n        \"\"\"Copy DocstringMeta from another instance.\"\"\"\n        if len(meta.args) == 2:\n            name = meta.args[1]\n            meta_type = None\n            for x in meta_all:\n                if x.args[1] == name and x.args[0] == 'type':\n                    meta_type = x.description\n                    break\n\n            return cls(args=meta.args, description=meta.description, type=meta_type)\n        else:\n            return cls(args=meta.args, description=meta.description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arg_name(self):\n        if len(self.args) > 2:\n            return self.args[2]\n        elif len(self.args) > 1:\n            return self.args[1]\n        return None", "response": "Return argument name associated with given param."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef params(self):\n        return [\n            DocstringParam.from_meta(meta, self.meta)\n            for meta in self.meta\n            if meta.args[0] in {\n                'param', 'parameter', 'arg', 'argument', 'key', 'keyword'\n            }\n        ]", "response": "Return list of DocstringParam."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef raises(self):\n        return [\n            DocstringRaises.from_meta(meta)\n            for meta in self.meta\n            if meta.args[0] in {'raises', 'raise', 'except', 'exception'}\n        ]", "response": "Return list of DocstringRaises."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a single object or dict of objects from a given object dictionary.", "response": "def gw_get(object_dict, name=None, plugin=None):\n    \"\"\"\n    Getter function to retrieve objects from a given object dictionary.\n\n    Used mainly to provide get() inside patterns.\n\n    :param object_dict: objects, which must have 'name' and 'plugin' as attribute\n    :type object_dict: dictionary\n    :param name: name of the object\n    :type name: str\n    :param plugin: plugin name, which registers the object\n    :return: None, single object or dict of objects\n    \"\"\"\n    if plugin is not None:\n        if name is None:\n            object_list = {}\n            for key in object_dict.keys():\n                if object_dict[key].plugin == plugin:\n                    object_list[key] = object_dict[key]\n            return object_list\n        else:\n            if name in object_dict.keys():\n                if object_dict[name].plugin == plugin:\n                    return object_dict[name]\n                else:\n                    return None\n            else:\n                return None\n    else:\n        if name is None:\n            return object_dict\n        else:\n            if name in object_dict.keys():\n                return object_dict[name]\n            else:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a discharge request from the macaroon server.", "response": "def discharge(ctx, content, key, locator, checker):\n    '''Handles a discharge request as received by the /discharge\n    endpoint.\n    @param ctx The context passed to the checker {checkers.AuthContext}\n    @param content URL and form parameters {dict}\n    @param locator Locator used to add third party caveats returned by\n    the checker {macaroonbakery.ThirdPartyLocator}\n    @param checker {macaroonbakery.ThirdPartyCaveatChecker} Used to check third\n    party caveats.\n    @return The discharge macaroon {macaroonbakery.Macaroon}\n    '''\n    id = content.get('id')\n    if id is not None:\n        id = id.encode('utf-8')\n    else:\n        id = content.get('id64')\n        if id is not None:\n            id = utils.b64decode(id)\n\n    caveat = content.get('caveat64')\n    if caveat is not None:\n        caveat = utils.b64decode(caveat)\n\n    return bakery.discharge(\n        ctx,\n        id=id,\n        caveat=caveat,\n        key=key,\n        checker=checker,\n        locator=locator,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef http_error_handler(f):\n\n    def hrefs_to_resources(hrefs):\n        for href in hrefs.replace(',', '').split():\n            type, uuid = href.split('/')[-2:]\n            yield Resource(type, uuid=uuid)\n\n    def hrefs_list_to_resources(hrefs_list):\n        for href in eval(hrefs_list):\n            type, uuid = href.split('/')[-2:]\n            yield Resource(type, uuid=uuid)\n\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        try:\n            return f(self, *args, **kwargs)\n        except HttpError as e:\n            if e.http_status == 404:\n                # remove previously created resource\n                # from the cache\n                self.emit('deleted', self)\n                if isinstance(self, Resource):\n                    raise ResourceNotFound(resource=self)\n                elif isinstance(self, Collection):\n                    raise CollectionNotFound(collection=self)\n            elif e.http_status == 409:\n                # contrail 3.2\n                matches = re.match(r'^Delete when children still present: (\\[[^]]*\\])', e.message)\n                if matches:\n                    raise ChildrenExists(\n                        resources=list(hrefs_list_to_resources(matches.group(1))))\n                matches = re.match(r'^Delete when resource still referred: (\\[[^]]*\\])', e.message)\n                if matches:\n                    raise BackRefsExists(\n                        resources=list(hrefs_list_to_resources(matches.group(1))))\n                # contrail 2.21\n                matches = re.match(r'^Children (.*) still exist$', e.message)\n                if matches:\n                    raise ChildrenExists(\n                        resources=list(hrefs_to_resources(matches.group(1))))\n                matches = re.match(r'^Back-References from (.*) still exist$', e.message)\n                if matches:\n                    raise BackRefsExists(\n                        resources=list(hrefs_to_resources(matches.group(1))))\n            raise\n    return wrapper", "response": "Handle 404 errors returned by the API server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef href(self):\n        url = self.session.base_url + str(self.path)\n        if self.path.is_collection and not self.path.is_root:\n            return url + 's'\n        return url", "response": "Return the URL of the resource in the base URL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter(self, field_name, field_value):\n        self.filters.append((field_name, field_value))\n        return self", "response": "Add a permanent filter on the collection\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch(self, recursive=1, fields=None, detail=None,\n              filters=None, parent_uuid=None, back_refs_uuid=None):\n        \"\"\"\n        Fetch collection from API server\n\n        :param recursive: level of recursion\n        :type recursive: int\n        :param fields: fetch only listed fields.\n                       contrail 3.0 required\n        :type fields: [str]\n        :param detail: fetch all fields\n        :type detail: bool\n        :param filters: list of filters\n        :type filters: [(name, value), ...]\n        :param parent_uuid: filter by parent_uuid\n        :type parent_uuid: v4UUID str or list of v4UUID str\n        :param back_refs_uuid: filter by back_refs_uuid\n        :type back_refs_uuid: v4UUID str or list of v4UUID str\n\n        :rtype: Collection\n        \"\"\"\n\n        params = self._format_fetch_params(fields=fields, detail=detail, filters=filters,\n                                           parent_uuid=parent_uuid, back_refs_uuid=back_refs_uuid)\n        data = self.session.get_json(self.href, **params)\n\n        if not self.type:\n            self.data = [Collection(col[\"link\"][\"name\"],\n                                    fetch=recursive - 1 > 0,\n                                    recursive=recursive - 1,\n                                    fields=self._fetch_fields(fields),\n                                    detail=detail or self.detail,\n                                    filters=self._fetch_filters(filters),\n                                    parent_uuid=self._fetch_parent_uuid(parent_uuid),\n                                    back_refs_uuid=self._fetch_back_refs_uuid(back_refs_uuid))\n                         for col in data['links']\n                         if col[\"link\"][\"rel\"] == \"collection\"]\n        else:\n            # when detail=False, res == {resource_attrs}\n            # when detail=True, res == {'type': {resource_attrs}}\n            self.data = [Resource(self.type,\n                                  fetch=recursive - 1 > 0,\n                                  recursive=recursive - 1,\n                                  **res.get(self.type, res))\n                         for res_type, res_list in data.items()\n                         for res in res_list]\n\n        return self", "response": "Fetch all the related resources from API server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the resource exists.", "response": "def check(self):\n        \"\"\"Check that the resource exists.\n\n        :raises ResourceNotFound: if the resource doesn't exists\n        \"\"\"\n        if self.fq_name:\n            self['uuid'] = self._check_fq_name(self.fq_name)\n        elif self.uuid:\n            self['fq_name'] = self._check_uuid(self.uuid)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fq_name(self):\n        return self.get('fq_name', self.get('to', super(Resource, self).fq_name))", "response": "Return the FQDN of the resource\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn parent resource :rtype: Resource :raises ResourceNotFound: parent resource doesn't exists :raises ResourceMissing: parent resource is not defined", "response": "def parent(self):\n        \"\"\"Return parent resource\n\n        :rtype: Resource\n        :raises ResourceNotFound: parent resource doesn't exists\n        :raises ResourceMissing: parent resource is not defined\n        \"\"\"\n        try:\n            return Resource(self['parent_type'], uuid=self['parent_uuid'], check=True)\n        except KeyError:\n            raise ResourceMissing('%s has no parent resource' % self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parent(self, resource):\n        resource.check()\n        self['parent_type'] = resource.type\n        self['parent_uuid'] = resource.uuid", "response": "Set parent resource\n\n        :param resource: parent resource\n        :type resource: Resource\n\n        :raises ResourceNotFound: resource not found on the API"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn creation date of the resource in the API.", "response": "def created(self):\n        \"\"\"Return creation date\n\n        :rtype: datetime\n        :raises ResourceNotFound: resource not found on the API\n        \"\"\"\n        if 'id_perms' not in self:\n            self.fetch()\n        created = self['id_perms']['created']\n        return datetime.strptime(created, '%Y-%m-%dT%H:%M:%S.%f')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the resource to the API server.", "response": "def save(self):\n        \"\"\"Save the resource to the API server\n\n        If the resource doesn't have a uuid the resource will be created.\n        If uuid is present the resource is updated.\n\n        :rtype: Resource\n        \"\"\"\n        if self.path.is_collection:\n            self.session.post_json(self.href,\n                                   {self.type: dict(self.data)},\n                                   cls=ResourceEncoder)\n        else:\n            self.session.put_json(self.href,\n                                  {self.type: dict(self.data)},\n                                  cls=ResourceEncoder)\n        return self.fetch(exclude_children=True, exclude_back_refs=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        res = self.session.delete(self.href)\n        self.emit('deleted', self)\n        return res", "response": "Delete resource from the API server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(self, recursive=1, exclude_children=False, exclude_back_refs=False):\n        if not self.path.is_resource and not self.path.is_uuid:\n            self.check()\n        params = {}\n        # even if the param is False the API will exclude resources\n        if exclude_children:\n            params['exclude_children'] = True\n        if exclude_back_refs:\n            params['exclude_back_refs'] = True\n        data = self.session.get_json(self.href, **params)[self.type]\n        self.from_dict(data)\n        return self", "response": "Fetch the resource from the API server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(self, data, recursive=1):\n        # Find other linked resources\n        data = self._encode_resource(data, recursive=recursive)\n        self.data = data", "response": "Populate the resource from a python dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_ref(self, ref):\n        self.session.remove_ref(self, ref)\n        return self.fetch()", "response": "Remove reference from self to ref\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_ref(self, ref, attr=None):\n        ref_attr = '%s_refs' % ref.type.replace('-', '_')\n        ref = {\n            'to': ref.fq_name,\n            'uuid': ref.uuid,\n        }\n        if ref_attr in self:\n            self[ref_attr].append(ref)\n        else:\n            self[ref_attr] = [ref]\n        return self", "response": "Set the reference to a resource\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_ref(self, ref, attr=None):\n        self.session.add_ref(self, ref, attr)\n        return self.fetch()", "response": "Add a reference to the resource\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd reference from back_ref to self", "response": "def add_back_ref(self, back_ref, attr=None):\n        \"\"\"Add reference from back_ref to self\n\n        :param back_ref: back_ref to add\n        :type back_ref: Resource\n\n        :rtype: Resource\n        \"\"\"\n        back_ref.add_ref(self, attr)\n        return self.fetch()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _search(self, trie, strings, limit=None):\n        results = [trie.has_keys_with_prefix(s) for s in strings]\n        if not any(results):\n            return []\n        for result, s in zip(results, strings):\n            if result is True:\n                return trie.values(s)[:limit]", "response": "Search in cache\n\n        :param strings: list of strings to get from the cache\n        :type strings: str list\n        :param limit: limit search results\n        :type limit: int\n\n        :rtype: [Resource | Collection]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a new signal.", "response": "def register(self, signal, plugin, description=\"\"):\n        \"\"\"\n        Registers a new signal.\n\n        :param signal: Unique name of the signal\n        :param plugin: Plugin, which registers the new signal\n        :param description: Description of the reason or use case, why this signal is needed.\n                            Used for documentation.\n        \"\"\"\n        if signal in self.signals.keys():\n            raise Exception(\"Signal %s was already registered by %s\" % (signal, self.signals[signal].plugin.name))\n\n        self.signals[signal] = Signal(signal, plugin, self._namespace, description)\n        self.__log.debug(\"Signal %s registered by %s\" % (signal, plugin.name))\n        return self.signals[signal]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self, receiver, signal, function, plugin, description=\"\", sender=None):\n        if receiver in self.receivers.keys():\n            raise Exception(\"Receiver %s was already registered by %s\" % (receiver,\n                                                                          self.receivers[receiver].plugin.name))\n        self.receivers[receiver] = Receiver(receiver, signal, function, plugin, self._namespace, description, sender)\n        self.__log.debug(\"Receiver %s registered for signal %s\" % (receiver, signal))\n        return self.receivers[receiver]", "response": "Connect a receiver to a signal"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disconnect(self, receiver):\n        if receiver not in self.receivers.keys():\n            raise Exception(\"No receiver %s was registered\" % receiver)\n        self.receivers[receiver].disconnect()\n        del(self.receivers[receiver])\n        self.__log.debug(\"Receiver %s disconnected\" % receiver)", "response": "Disconnect a receiver from a signal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a signal to the given plugin.", "response": "def send(self, signal, plugin, **kwargs):\n        \"\"\"\n        Sends a signal for the given plugin.\n\n        :param signal: Name of the signal\n        :type signal: str\n        :param plugin: Plugin object, under which the signals where registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if signal not in self.signals.keys():\n            raise UnknownSignal(\"Unknown signal %s\" % signal)\n        self.__log.debug(\"Sending signal %s for %s\" % (signal, plugin.name))\n        rv = self.signals[signal].send(plugin, **kwargs)\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, signal=None, plugin=None):\n        if plugin is not None:\n            if signal is None:\n                signals_list = {}\n                for key in self.signals.keys():\n                    if self.signals[key].plugin == plugin:\n                        signals_list[key] = self.signals[key]\n                return signals_list\n            else:\n                if signal in self.signals.keys():\n                    if self.signals[signal].plugin == plugin:\n                        return self.signals[signal]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if signal is None:\n                return self.signals\n            else:\n                if signal in self.signals.keys():\n                    return self.signals[signal]\n                else:\n                    return None", "response": "Get one or more signals."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_receiver(self, receiver=None, plugin=None):\n        if plugin is not None:\n            if receiver is None:\n                receiver_list = {}\n                for key in self.receivers.keys():\n                    if self.receivers[key].plugin == plugin:\n                        receiver_list[key] = self.receivers[key]\n                return receiver_list\n            else:\n                if receiver in self.receivers.keys():\n                    if self.receivers[receiver].plugin == plugin:\n                        return self.receivers[receiver]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if receiver is None:\n                return self.receivers\n            else:\n                if receiver in self.receivers.keys():\n                    return self.receivers[receiver]\n                else:\n                    return None", "response": "Get one or more receivers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the listener with incoming and outgoing queues.", "response": "def start(inqueue, outqueue=None):\r\n    \"\"\"Starts the listener with incoming and outgoing queues.\"\"\"\r\n    conf.init(), db.init(conf.DbPath)\r\n    Listener(inqueue, outqueue).run()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles Windows key events.", "response": "def _handle_windows(self, event):\r\n        \"\"\"Windows key event handler.\"\"\"\r\n        vkey = self._keyname(event.GetKey())\r\n        if event.Message in self.KEYS_UP + self.KEYS_DOWN:\r\n            if vkey in self.MODIFIERNAMES:\r\n                self._realmodifiers[vkey] = event.Message in self.KEYS_DOWN\r\n                self._modifiers[self.MODIFIERNAMES[vkey]] = self._realmodifiers[vkey]\r\n        if event.Message not in self.KEYS_DOWN:\r\n            return True\r\n\r\n        is_altgr = False\r\n        if (vkey, event.IsExtended()) in self.NUMPAD_SPECIALS:\r\n            key = vkey = \"Numpad-\" + vkey\r\n        elif not event.Ascii or vkey.startswith(\"Numpad\"):\r\n            key = vkey\r\n        else:\r\n            is_altgr = event.Ascii in self.ALT_GRS\r\n            key = self._keyname(unichr(event.Ascii))\r\n\r\n        if DEBUG: print(\"Adding key %s (real %s)\" % (key.encode(\"utf-8\"), vkey.encode(\"utf-8\")))\r\n        self._output(type=\"keys\", key=key, realkey=vkey)\r\n\r\n        if vkey not in self.MODIFIERNAMES and not is_altgr:\r\n            modifier = \"-\".join(k for k in [\"Ctrl\", \"Alt\", \"Shift\", \"Win\"]\r\n                                if self._modifiers[k])\r\n            if modifier and modifier != \"Shift\": # Shift-X is not a combo\r\n                if self._modifiers[\"Ctrl\"] and event.Ascii:\r\n                    key = self._keyname(unichr(event.KeyID))\r\n                realmodifier = \"-\".join(k for k, v in self._realmodifiers.items() if v)\r\n                realkey = \"%s-%s\" % (realmodifier, key)\r\n                key = \"%s-%s\" % (modifier, key)\r\n                if DEBUG: print(\"Adding combo %s (real %s)\" % (key.encode(\"utf-8\"), realkey.encode(\"utf-8\")))\r\n                self._output(type=\"combos\", key=key, realkey=realkey)\r\n\r\n        if DEBUG:\r\n            print(\"CHARACTER: %r\" % key)\r\n            print('GetKey: {0}'.format(event.GetKey()))  # Name of the virtual keycode, str\r\n            print('IsAlt: {0}'.format(event.IsAlt()))  # Was the alt key depressed?, bool\r\n            print('IsExtended: {0}'.format(event.IsExtended()))  # Is this an extended key?, bool\r\n            print('IsInjected: {0}'.format(event.IsInjected()))  # Was this event generated programmatically?, bool\r\n            print('IsTransition: {0}'.format(event.IsTransition()))  #Is this a transition from up to down or vice versa?, bool\r\n            print('ASCII: {0}'.format(event.Ascii))  # ASCII value, if one exists, str\r\n            print('KeyID: {0}'.format(event.KeyID))  # Virtual key code, int\r\n            print('ScanCode: {0}'.format(event.ScanCode))  # Scan code, int\r\n            print('Message: {0}'.format(event.Message))  # Name of the virtual keycode, str\r\n            print()\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_mac(self, keycode):\r\n        key = self._keyname(unichr(keycode))\r\n        self._output(type=\"keys\", key=key, realkey=key)", "response": "Handle mac key events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nactivating GwDocumentsInfo by registering commands and documents", "response": "def activate(self):\n        \"\"\"\n        Activates GwDocumentsInfo by registering:\n\n        * 2 commands (doc, doc_list)\n        * 1 document (documents_overview)\n        \"\"\"\n        self.commands.register(\"doc_list\", \"List all documents\", self._list_documents)\n        self.commands.register(\"doc\", \"Shows the documentation\", self._show_documentation)\n        self.commands.register(\"doc_write\", \"Stores documents as files \", self._store_documentation,\n                               params=[Argument((\"path\",),\n                                                required=True),\n                                       Option((\"--html\", \"-h\"),\n                                              required=False,\n                                              help=\"Will output html instead of rst\",\n                                              default=False,\n                                              is_flag=True),\n                                       Option((\"--overwrite\", \"-o\"),\n                                              required=False,\n                                              help=\"Will overwrite existing files\",\n                                              default=False,\n                                              is_flag=True),\n                                       Option((\"--quiet\", \"-q\"),\n                                              required=False,\n                                              help=\"Will suppress any user interaction\",\n                                              default=False,\n                                              is_flag=True)\n                                       ])\n\n        self.documents.register(name=\"documents_overview\",\n                                content=documents_content,\n                                description=\"Gives an overview about all registered documents\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _store_documentation(self, path, html, overwrite, quiet):\n\n        echo(\"Storing groundwork application documents\\n\")\n        echo(\"Application: %s\" % self.app.name)\n        echo(\"Number of documents: %s\\n\" % len(self.app.documents.get()))\n\n        if not os.path.isabs(path):\n            path = os.path.abspath(path)\n\n        if not os.path.isdir(path):\n            echo(\"Path %s is not a directory!\" % path)\n            sys.exit(1)\n\n        if not os.path.exists(path):\n            echo(\"Path %s does not exist\" % path)\n            sys.exit(1)\n\n        for dirpath, dirnames, files in os.walk(path):\n            if files:\n                echo(\"Path %s is not empty!\\n\" % path)\n                if not overwrite:\n                    sys.exit(1)\n\n        documents = []\n        for key, document in self.app.documents.get().items():\n            file_extension = \".html\" if html else \".rst\"\n\n            # lowers the name, removes all whitespaces and adds the file extension\n            file_name_parts = key.lower().split()\n            file_name = \"\".join(file_name_parts)\n            file_name += file_extension\n            documents.append((file_name, document))\n\n        echo(\"Going to write to following files:\")\n        for document in documents:\n            echo(\"  %s\" % document[0])\n\n        echo(\"\\nTarget directory: %s\" % path)\n        answer = None\n        while answer not in [\"N\", \"Y\"] and not quiet:\n            answer = prompt(\"Shall we go on? [Y]es, [N]o: \").upper()\n\n        if answer == \"N\":\n            sys.exit(0)\n\n        for document in documents:\n            try:\n                with open(os.path.join(path, document[0]), \"w\") as doc_file:\n                    doc_rendered = Environment().from_string(document[1].content).render(app=self.app,\n                                                                                         plugin=document[1].plugin)\n                    if html:\n                        output = publish_parts(doc_rendered, writer_name=\"html\")['whole']\n                    else:\n                        output = doc_rendered\n\n                    doc_file.write(output)\n            except Exception as e:\n                echo(\"%s error occurred: %s\" % (document[0], e))\n            else:\n                echo(\"%s stored.\" % document[0])", "response": "Stores all documents on the file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _show_documentation(self):\n        documents = []\n        for key, document in self.app.documents.get().items():\n            if key != \"main\":\n                documents.append((key, document))\n        documents = sorted(documents, key=lambda x: x[0])\n        main = self.app.documents.get(\"main\")\n        if main is not None:\n            documents.insert(0, (main.name, main))\n\n        user_answer = \"\"\n        index = 0\n        while user_answer != \"X\":\n            if index < 0:\n                index = 0\n            if index > len(documents) - 1:\n                index = len(documents) - 1\n            document = documents[index][1]\n\n            os.system('cls' if os.name == 'nt' else 'clear')\n            echo(Environment().from_string(document.content).render(app=self.app, plugin=document.plugin))\n\n            source = \"This document is registered by '%s' under the name '%s'\" % (document.plugin.name, document.name)\n            echo(\"-\" * len(source))\n            echo(source)\n            echo(\"-\" * len(source))\n            commands = \"Actions: \"\n            if index < len(documents) - 1:\n                commands += \"[N]ext, \"\n            if index > 0:\n                commands += \"[P]revious, \"\n            commands += \"E[x]it\"\n            echo(commands)\n\n            if index < len(documents) - 1:\n                default = \"N\"\n            elif index > 0:\n                default = \"P\"\n            else:\n                default = \"X\"\n            user_answer = prompt(\"Select your action\", default=default).upper()\n\n            if user_answer == \"N\":\n                index += 1\n            elif user_answer == \"P\":\n                index -= 1", "response": "Show all documents of the current groundwork app in the console."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes several cleanup tasks as part of the cleanup.", "response": "def execute_cleanup_tasks(ctx, cleanup_tasks, dry_run=False):\n    \"\"\"Execute several cleanup tasks as part of the cleanup.\n\n    REQUIRES: ``clean(ctx, dry_run=False)`` signature in cleanup tasks.\n\n    :param ctx:             Context object for the tasks.\n    :param cleanup_tasks:   Collection of cleanup tasks (as Collection).\n    :param dry_run:         Indicates dry-run mode (bool)\n    \"\"\"\n    # pylint: disable=redefined-outer-name\n    executor = Executor(cleanup_tasks, ctx.config)\n    for cleanup_task in cleanup_tasks.tasks:\n        print(\"CLEANUP TASK: %s\" % cleanup_task)\n        executor.execute((cleanup_task, dict(dry_run=dry_run)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove directories (and their contents) recursively. Skips removal if directories does not exist. :param patterns: Directory name patterns, like \"**/tmp*\" (as list). :param dry_run: Dry-run mode indicator (as bool). :param workdir: Current work directory (default=\".\")", "response": "def cleanup_dirs(patterns, dry_run=False, workdir=\".\"):\n    \"\"\"Remove directories (and their contents) recursively.\n    Skips removal if directories does not exist.\n\n    :param patterns:    Directory name patterns, like \"**/tmp*\" (as list).\n    :param dry_run:     Dry-run mode indicator (as bool).\n    :param workdir:     Current work directory (default=\".\")\n    \"\"\"\n    current_dir = Path(workdir)\n    python_basedir = Path(Path(sys.executable).dirname()).joinpath(\"..\").abspath()\n    warn2_counter = 0\n    for dir_pattern in patterns:\n        for directory in path_glob(dir_pattern, current_dir):\n            directory2 = directory.abspath()\n            if sys.executable.startswith(directory2):\n                # pylint: disable=line-too-long\n                print(\"SKIP-SUICIDE: '%s' contains current python executable\" % directory)\n                continue\n            elif directory2.startswith(python_basedir):\n                # -- PROTECT CURRENTLY USED VIRTUAL ENVIRONMENT:\n                if warn2_counter <= 4:\n                    print(\"SKIP-SUICIDE: '%s'\" % directory)\n                warn2_counter += 1\n                continue\n\n            if dry_run:\n                print(\"RMTREE: %s (dry-run)\" % directory)\n            else:\n                print(\"RMTREE: %s\" % directory)\n                directory.rmtree_p()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_signature_size(msg):\n    if isinstance(msg, (TxinGen, TxinToScript, TxinToScriptHash)):\n        return 0\n    elif isinstance(msg, TxinToKey):\n        return len(msg.key_offsets)\n    else:\n        raise ValueError('Unknown tx in')", "response": "Returns a signature size for the input\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def serialize_rctsig_base(self, ar, inputs, outputs):\n        await self._msg_field(ar, idx=0)\n        if self.type == RctType.Null:\n            return\n        if self.type != RctType.Full and self.type != RctType.FullBulletproof and \\\n                self.type != RctType.Simple and self.type != RctType.SimpleBulletproof:\n            raise ValueError('Unknown type')\n\n        await self._msg_field(ar, idx=1)\n        if self.type == RctType.Simple:\n            await ar.tag('pseudoOuts')\n            await ar.begin_array()\n            await ar.prepare_container(inputs, eref(self, 'pseudoOuts'), KeyV)\n            if ar.writing and len(self.pseudoOuts) != inputs:\n                raise ValueError('pseudoOuts size mismatch')\n\n            for i in range(inputs):\n                await ar.field(eref(self.pseudoOuts, i), KeyV.ELEM_TYPE)\n            await ar.end_array()\n\n        await ar.tag('ecdhInfo')\n        await ar.begin_array()\n        await ar.prepare_container(outputs, eref(self, 'ecdhInfo'), EcdhTuple)\n        if ar.writing and len(self.ecdhInfo) != outputs:\n            raise ValueError('EcdhInfo size mismatch')\n\n        for i in range(outputs):\n            if self.type == RctType.Bulletproof2:\n                am8 = [self.ecdhInfo[i].amount[0:8] if ar.writing else bytearray(0)]\n                await ar.field(eref(am8, 0), Hash8)\n                if not ar.writing:\n                    x.set_elem(eref(self.ecdhInfo[i], 'amount'), am8[0] + bytearray(24))\n                    x.set_elem(eref(self.ecdhInfo[i], 'mask'), bytearray(32))\n            else:\n                await ar.field(eref(self.ecdhInfo, i), EcdhInfo.ELEM_TYPE)\n        await ar.end_array()\n\n        await ar.tag('outPk')\n        await ar.begin_array()\n        await ar.prepare_container((outputs), eref(self, 'outPk'), CtKey)\n        if ar.writing and len(self.outPk) != outputs:\n            raise ValueError('outPk size mismatch')\n\n        for i in range(outputs):\n            await ar.field(eref(self.outPk[i], 'mask'), ECKey)\n        await ar.end_array()", "response": "Custom serialization of the RCTSIG base."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def serialize_rctsig_prunable(self, ar, type, inputs, outputs, mixin):\n        if type == RctType.Null:\n            return True\n\n        if type != RctType.Full and type != RctType.Bulletproof and \\\n                type != RctType.Simple and type != RctType.Bulletproof2:\n            raise ValueError('Unknown type')\n\n        if is_rct_bp(type):\n            await ar.tag('bp')\n            await ar.begin_array()\n            bps = [0]\n            if ar.writing:\n                bps[0] = len(self.bulletproofs)\n\n            if type == RctType.Bulletproof2:\n                await ar.field(elem=eref(bps, 0), elem_type=x.UVarintType)\n            else:\n                await ar.field(elem=eref(bps, 0), elem_type=x.UInt32)\n\n            await ar.prepare_container(bps[0], eref(self, 'bulletproofs'), elem_type=Bulletproof)\n\n            for i in range(bps[0]):\n                await ar.field(elem=eref(self.bulletproofs, i), elem_type=Bulletproof)\n            await ar.end_array()\n\n        else:\n            await ar.tag('rangeSigs')\n            await ar.begin_array()\n            await ar.prepare_container(outputs, eref(self, 'rangeSigs'), elem_type=RangeSig)\n            if len(self.rangeSigs) != outputs:\n                raise ValueError('rangeSigs size mismatch')\n\n            for i in range(len(self.rangeSigs)):\n                await ar.field(elem=eref(self.rangeSigs, i), elem_type=RangeSig)\n            await ar.end_array()\n\n        await ar.tag('MGs')\n        await ar.begin_array()\n\n        # We keep a byte for size of MGs, because we don't know whether this is\n        # a simple or full rct signature, and it's starting to annoy the hell out of me\n        is_full = type == RctType.Full\n        mg_elements = inputs if not is_full else 1\n        await ar.prepare_container(mg_elements, eref(self, 'MGs'), elem_type=MgSig)\n        if len(self.MGs) != mg_elements:\n            raise ValueError('MGs size mismatch')\n\n        for i in range(mg_elements):\n            # We save the MGs contents directly, because we want it to save its\n            # arrays and matrices without the size prefixes, and the load can't\n            # know what size to expect if it's not in the data\n            await ar.begin_object()\n            await ar.tag('ss')\n            await ar.begin_array()\n\n            await ar.prepare_container(mixin + 1, eref(self.MGs[i], 'ss'), elem_type=KeyM)\n            if ar.writing and len(self.MGs[i].ss) != mixin + 1:\n                raise ValueError('MGs size mismatch')\n\n            for j in range(mixin + 1):\n                await ar.begin_array()\n                mg_ss2_elements = 1 + (1 if not is_full else inputs)\n                await ar.prepare_container(mg_ss2_elements, eref(self.MGs[i].ss, j), elem_type=KeyM.ELEM_TYPE)\n\n                if ar.writing and len(self.MGs[i].ss[j]) != mg_ss2_elements:\n                    raise ValueError('MGs size mismatch 2')\n\n                for k in range(mg_ss2_elements):\n                    await ar.field(eref(self.MGs[i].ss[j], k), elem_type=KeyV.ELEM_TYPE)\n                await ar.end_array()\n\n            await ar.tag('cc')\n            await ar.field(eref(self.MGs[i], 'cc'), elem_type=ECKey)\n            await ar.end_object()\n        await ar.end_array()\n\n        if type in (RctType.Bulletproof, RctType.Bulletproof2):\n            await ar.begin_array()\n            await ar.prepare_container(inputs, eref(self, 'pseudoOuts'), elem_type=KeyV)\n            if ar.writing and len(self.pseudoOuts) != inputs:\n                raise ValueError('pseudoOuts size mismatch')\n\n            for i in range(inputs):\n                await ar.field(eref(self.pseudoOuts, i), elem_type=KeyV.ELEM_TYPE)\n            await ar.end_array()", "response": "Serialize rct sig\n        :param ar:\n        :type ar: x.Archive\n        :param type:\n        :param inputs:\n        :param outputs:\n        :param mixin:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing the transaction :param ar: :type ar: x.Archive :return:", "response": "async def serialize_archive(self, ar, version=None):\n        \"\"\"\n        Serialize the transaction\n        :param ar:\n        :type ar: x.Archive\n        :return:\n        \"\"\"\n        # Transaction prefix serialization first.\n        await ar.message(self, TransactionPrefix)\n\n        if self.version == 1:\n            await ar.tag('signatures')\n            await ar.begin_array()\n            await ar.prepare_container(len(self.vin), eref(self, 'signatures'), elem_type=SignatureArray)\n            signatures_not_expected = len(self.signatures) == 0\n            if not signatures_not_expected and len(self.vin) != len(self.signatures):\n                raise ValueError('Signature size mismatch')\n\n            for i in range(len(self.vin)):\n                sig_size = get_signature_size(self.vin[i])\n                if signatures_not_expected:\n                    if 0 == sig_size:\n                        continue\n                    else:\n                        raise ValueError('Unexpected sig')\n\n                await ar.prepare_container(sig_size, eref(self.signatures, i), elem_type=SignatureArray)\n                if sig_size != len(self.signatures[i]):\n                    raise ValueError('Unexpected sig size')\n\n                for j in range(sig_size):\n                    await ar.field(eref(self.signatures[i], j), Signature)\n\n        else:\n            await ar.tag('rct_signatures')\n            if len(self.vin) == 0:\n                return\n\n            await ar.begin_object()\n            await ar.prepare_message(eref(self, 'rct_signatures'), RctSig)\n            await self.rct_signatures.serialize_rctsig_base(ar, len(self.vin), len(self.vout))\n            await ar.end_object()\n\n            if self.rct_signatures.type != RctType.Null:\n                mixin_size = len(self.vin[0].key_offsets) - 1 if len(self.vin) > 0 and isinstance(self.vin[0], TxinToKey) else 0\n                await ar.tag('rctsig_prunable')\n                await ar.begin_object()\n                await ar.prepare_message(eref(self.rct_signatures, 'p'), RctSigPrunable)\n                await self.rct_signatures.p.serialize_rctsig_prunable(ar, self.rct_signatures.type,\n                                                                      len(self.vin), len(self.vout),\n                                                                      mixin_size)\n                await ar.end_object()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_storage_pool_by_name(self, name):\n        for storage_pool in self.conn.storage_pools:\n            if storage_pool.name == name:\n                return storage_pool\n        raise KeyError(\"Storage pool of that name not found\")", "response": "Get ScaleIO StoragePool object by its name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_storage_pool_by_id(self, id):\n        for storage_pool in self.conn.storage_pools:\n            if storage_pool.id == id:\n                return storage_pool\n        raise KeyError(\"Storage Pool with that ID not found\")", "response": "Get a StoragePool object by its id"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the Entry Point for a given section.", "response": "def entrypoints(section):\n    \"\"\"\n    Returns the Entry Point for a given Entry Point section.\n\n    :param str section: The section name in the entry point collection\n    :returns:  A dictionary of (Name, Class) pairs stored in the entry point collection.\n    \"\"\"\n    return {ep.name: ep.load() for ep in pkg_resources.iter_entry_points(section)}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the entry point object given a section and option pair.", "response": "def entrypoint(section, option):\n    \"\"\"\n    Returns the the entry point object given a section, option pair.\n\n    :param str section: The section name in the entry point collection\n    :param str option: The option name in the entry point collection\n    :return:  The entry point object if available.\n    \"\"\"\n    try:\n        return entrypoints(section)[option]\n    except KeyError:\n        raise KeyError('Cannot resolve type \"{}\" to a recognised vsgen \"{}\" type.'.format(option, section))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef infer_declared(ms, namespace=None):\n    '''Retrieves any declared information from the given macaroons and returns\n    it as a key-value map.\n    Information is declared with a first party caveat as created by\n    declared_caveat.\n\n    If there are two caveats that declare the same key with different values,\n    the information is omitted from the map. When the caveats are later\n    checked, this will cause the check to fail.\n    namespace is the Namespace used to retrieve the prefix associated to the\n    uri, if None it will use the STD_NAMESPACE only.\n    '''\n    conditions = []\n    for m in ms:\n        for cav in m.caveats:\n            if cav.location is None or cav.location == '':\n                conditions.append(cav.caveat_id_bytes.decode('utf-8'))\n    return infer_declared_from_conditions(conditions, namespace)", "response": "Retrieves any declared information from the given macaroons and returns a key - value map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlike infer_declared except that it is passed a set of first party caveat conditions as a list of string rather than a set of macaroons.", "response": "def infer_declared_from_conditions(conds, namespace=None):\n    ''' like infer_declared except that it is passed a set of first party\n    caveat conditions as a list of string rather than a set of macaroons.\n    '''\n    conflicts = []\n    # If we can't resolve that standard namespace, then we'll look for\n    # just bare \"declared\" caveats which will work OK for legacy\n    # macaroons with no namespace.\n    if namespace is None:\n        namespace = Namespace()\n    prefix = namespace.resolve(STD_NAMESPACE)\n    if prefix is None:\n        prefix = ''\n    declared_cond = prefix + COND_DECLARED\n\n    info = {}\n    for cond in conds:\n        try:\n            name, rest = parse_caveat(cond)\n        except ValueError:\n            name, rest = '', ''\n        if name != declared_cond:\n            continue\n        parts = rest.split(' ', 1)\n        if len(parts) != 2:\n            continue\n        key, val = parts[0], parts[1]\n        old_val = info.get(key)\n        if old_val is not None and old_val != val:\n            conflicts.append(key)\n            continue\n        info[key] = val\n    for key in set(conflicts):\n        del info[key]\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unescape_json_str(st):\n    c = 0\n    ln = len(st)\n    escape_chmap = {\n        b'b': b'\\b',\n        b'f': b'\\f',\n        b'n': b'\\n',\n        b'r': b'\\r',\n        b't': b'\\t',\n        b'\\\\': b'\\\\',\n        b'\"': b'\\\"',\n        b'/': b'\\/'\n    }\n\n    ret = []\n\n    def at(i):\n        return st[i:i+1]\n\n    while c < ln:\n        if at(c) == b'\\\\':\n            if at(c+1) == b'u':\n                ret.append(bytes([int(st[c+2:c+6], 16)]))\n                # ret.append(st[c:c+6].decode('unicode_escape').encode('utf8'))\n                c += 6\n\n            else:\n                ret.append(escape_chmap[at(c+1)])\n                c += 2\n\n        else:\n            ret.append(at(c))\n            c += 1\n\n    df = (b''.join(ret))\n    return df", "response": "Unescape Monero json encoded string\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef escape_string_json(st):\n    ret = []\n    c = 0\n    ln = len(st)\n\n    escape_chmap = {\n        b'\\b': b'b',\n        b'\\f': b'f',\n        b'\\n': b'n',\n        b'\\r': b'r',\n        b'\\t': b't',\n        b'\\\\': b'\\\\',\n        b'\\\"': b'\"',\n        b'\\/': b'/'\n    }\n\n    while c < ln:\n        ch = st[c:c+1]\n        if ch in escape_chmap:\n            ret.append(b'\\\\' + escape_chmap[ch])\n        elif ord(ch) < 0x20:\n            ret.append(b'\\\\u%04X' % ord(ch))\n        else:\n            ret.append(ch)\n        c += 1\n    return b''.join(ret)", "response": "Escapes the string for the base64 - encoded unicode object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pre_activate_injection(self):\n        # Let's be sure that this plugins class is registered and available on application level under\n        # application.plugins.classes. This allows to reuse this class for *new* plugins.\n        if not self.app.plugins.classes.exist(self.__class__.__name__):\n            self.app.plugins.classes.register([self.__class__])\n\n        self._load_needed_plugins()\n\n        self.app.signals.send(\"plugin_activate_pre\", self)", "response": "Injects functions before the activation routine of child classes gets called\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninjects functions after the activation routine of child classes got called", "response": "def _post_activate_injection(self):\n        \"\"\"\n        Injects functions after the activation routine of child classes got called\n        :return: None\n        \"\"\"\n        self.active = True\n        self.app.signals.send(\"plugin_activate_post\", self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling by the plugin when the deactivation routine of child classes got called.", "response": "def _post_deactivate_injection(self):\n        \"\"\"\n        Injects functions after the deactivation routine of child classes got called\n        :return: None\n        \"\"\"\n        # Lets be sure that active is really set to false.\n        self.active = False\n        self.app.signals.send(\"plugin_deactivate_post\", self)\n        # After all receivers are handled. We start to clean up signals and receivers of this plugin\n        # Attention: This signal clean must not be called via a signal (like in other patterns),\n        # because the call order of receivers is not clear and a signal/receiver clean up would prohibit the call\n        # of all \"later\" receivers.\n        self.signals.deactivate_plugin_signals()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if this plugins need other plugins to work and tries to activate them if they are not.", "response": "def _load_needed_plugins(self):\n        \"\"\"\n        Checks if this plugins needs other plugins to work and tries to activate them\n        :return: True, if all needed plugins are or got activated. Otherwise False\n        \"\"\"\n        global plugin_recursive_store\n        if \"plugin_recursive_store\" not in globals():\n            plugin_recursive_store = []\n\n        if self.name in plugin_recursive_store:\n            self.log.warning(\"Plugin dependency loop detected: %s already checked and dependencies got activated\" %\n                             self.name)\n            if self.app.strict:\n                raise PluginDependencyLoop(\"Plugin dependency loop detected: %s already checked and dependencies \"\n                                           \"got activated\" % self.name)\n            return False\n        else:\n            plugin_recursive_store.append(self.name)\n\n        if not hasattr(self, \"needed_plugins\"):\n            pass\n        elif not isinstance(self.needed_plugins, tuple) and not isinstance(self.needed_plugins, list):\n            raise TypeError(\"needed_plugins must be a tuple or a list\")\n        elif len(self.needed_plugins) > 0:\n            try:\n                for needed_plugin in self.needed_plugins:\n                    if not isinstance(needed_plugin, str):\n                        raise TypeError(\"Plugin name must be a string, got %s\" % type(needed_plugin).__name__)\n                    # Check, if a plugin with this name got already activated\n                    plugin = self.app.plugins.get(needed_plugin)\n                    if plugin is not None and not plugin.active:\n                        plugin.activate()\n                    # If not, check if a plugin_class with this name is available and activate it\n                    plugin_class = self.app.plugins.classes.get(needed_plugin)\n                    if plugin_class is not None:\n                        plugin_class(self.app, needed_plugin)\n            except Exception:\n                plugin_recursive_store.remove(self.name)\n                return False\n\n        plugin_recursive_store.remove(self.name)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(self, signal, description):\n        return self.__app.signals.register(signal, self._plugin, description)", "response": "Registers a new signal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self, receiver, signal, function, description, sender=None):\n        return self.__app.signals.connect(receiver, signal, function, self._plugin, description, sender)", "response": "Connect a receiver to a signal"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, signal, **kwargs):\n        return self.__app.signals.send(signal, plugin=self._plugin, **kwargs)", "response": "Sends a signal to the given plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a single signal or a dictionary of signals for this plugin.", "response": "def get(self, signal=None):\n        \"\"\"\n        Returns a single signal or a dictionary of signals for this plugin.\n        \"\"\"\n        return self.__app.signals.get(signal, self._plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a single receiver or a dictionary of receivers for this plugin.", "response": "def get_receiver(self, receiver=None):\n        \"\"\"\n        Returns a single receiver or a dictionary of receivers for this plugin.\n        \"\"\"\n        return self.__app.signals.get_receiver(receiver, self._plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_model_cls(attributes):\n        model_cls = attributes.get('__model_cls__')\n        if model_cls is None:\n            raise AttributeError(\"Attribute __model_cls__ is required.\")\n\n        if not issubclass(model_cls, models.DomainModel):\n            raise TypeError(\"Attribute __model_cls__ must be subclass of \"\n                            \"DomainModel.\")", "response": "Check __model_cls__ attribute.\n\n        :type attributes: dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn tuple with prepared __include__ and __exclude__ attributes.", "response": "def get_prepared_include_exclude(attributes):\n        \"\"\"Return tuple with prepared __include__ and __exclude__ attributes.\n\n        :type attributes: dict\n        :rtype: tuple\n        \"\"\"\n        attrs = dict()\n        for attr in ('__include__', '__exclude__'):\n            attrs[attr] = tuple([item.name for item in\n                                 attributes.get(attr, tuple())])\n        return attrs['__include__'], attrs['__exclude__']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking include and exclude attributes.", "response": "def check_include_exclude(attributes):\n        \"\"\"Check __include__ and __exclude__ attributes.\n\n        :type attributes: dict\n        \"\"\"\n        include = attributes.get('__include__', tuple())\n        exclude = attributes.get('__exclude__', tuple())\n\n        if not isinstance(include, tuple):\n            raise TypeError(\"Attribute __include__ must be a tuple.\")\n\n        if not isinstance(exclude, tuple):\n            raise TypeError(\"Attribute __exclude__ must be a tuple.\")\n\n        if all((not include, not exclude)):\n            return None\n\n        if all((include, exclude)):\n            raise AttributeError(\"Usage of __include__ and __exclude__ \"\n                                 \"at the same time is prohibited.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn tuple of names of defined properties.", "response": "def get_properties(attributes):\n        \"\"\"Return tuple of names of defined properties.\n\n        :type attributes: dict\n        :rtype: list\n        \"\"\"\n        return [key for key, value in six.iteritems(attributes)\n                if isinstance(value, property)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether intersections exist.", "response": "def check_properties(mcs, attributes):\n        \"\"\"Check whether intersections exist.\n\n        :type attributes: dict\n        \"\"\"\n        include, exclude = mcs.get_prepared_include_exclude(attributes)\n        properties = mcs.get_properties(attributes)\n        intersections = list(\n            set(properties).intersection(include if include else exclude))\n        if not intersections:\n            return None\n\n        attr_name = '__include__' if include else '__exclude__'\n\n        raise AttributeError(\n            \"It is not allowed to mention already defined properties: \"\n            \"{0} in {1} attributes.\".format(\", \".join(intersections),\n                                            attr_name))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self, config_files):\n        config = Config()\n\n        for config_file in config_files:\n            if not os.path.isabs(config_file):\n                config_file = os.path.join(os.getcwd(), config_file)\n\n            self.log.debug(\"Loading configuration from %s\" % config_file)\n            d = types.ModuleType('config')\n            d.__file__ = config_file\n            try:\n                with open(config_file) as current_config_file:\n                    exec(compile(current_config_file.read(), config_file, 'exec'), d.__dict__)\n            except IOError as e:\n                e.strerror = 'Unable to load configuration file (%s)' % e.strerror\n                raise\n            for key in dir(d):\n                if key.isupper():\n                    if key not in self.invalid_parameters:\n                        setattr(config, key, getattr(d, key))\n                    else:\n                        raise InvalidParameter(\"%s is not allowed as name for a configuration parameter\" % key)\n        return config", "response": "Loads a configuration from a list of all the configuration files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_deleted(self, event):\n        key = 'filesystem:file_deleted'\n        data = {\n            'filepath': event.src_path,\n            'is_directory': event.is_directory,\n            'dirpath': os.path.dirname(event.src_path)\n        }\n\n        bmsg = BroadcastMessage(key=key, data=data)\n        BroadcastManager.broadcast(bmsg)", "response": "Event Handler when a file is deleted"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a datetime. datetime object return a string representing this date / time formatted according to this dateformat.", "response": "def format(self, date):\n        \"\"\"\n        Given a datetime.datetime object, return a string representing this date/time,\n        formatted according to this dateformat.\n        \"\"\"\n        context = {'date': date}\n        for handler in self.format_chain:\n            handler(self, date, context)\n        return eval(self.format_code, globals(), context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload agent authentication information from the specified content string as read from an agents file.", "response": "def read_auth_info(agent_file_content):\n    '''Loads agent authentication information from the\n    specified content string, as read from an agents file.\n    The returned information is suitable for passing as an argument\n    to the AgentInteractor constructor.\n    @param agent_file_content The agent file content (str)\n    @return AuthInfo The authentication information\n    @raises AgentFileFormatError when the file format is bad.\n    '''\n    try:\n        data = json.loads(agent_file_content)\n        return AuthInfo(\n            key=bakery.PrivateKey.deserialize(data['key']['private']),\n            agents=list(\n                Agent(url=a['url'], username=a['username'])\n                for a in data.get('agents', [])\n            ),\n        )\n    except (\n        KeyError,\n        ValueError,\n        TypeError,\n    ) as e:\n        raise AgentFileFormatError('invalid agent file', e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interact(self, client, location, interaction_required_err):\n        '''Implement Interactor.interact by obtaining obtaining\n        a macaroon from the discharger, discharging it with the\n        local private key using the discharged macaroon as\n        a discharge token'''\n        p = interaction_required_err.interaction_method('agent',\n                                                        InteractionInfo)\n        if p.login_url is None or p.login_url == '':\n            raise httpbakery.InteractionError(\n                'no login-url field found in agent interaction method')\n        agent = self._find_agent(location)\n        if not location.endswith('/'):\n            location += '/'\n        login_url = urljoin(location, p.login_url)\n        resp = requests.get(\n            login_url, params={\n                'username': agent.username,\n                'public-key': str(self._auth_info.key.public_key)},\n            auth=client.auth())\n        if resp.status_code != 200:\n            raise httpbakery.InteractionError(\n                'cannot acquire agent macaroon: {} {}'.format(\n                    resp.status_code, resp.text)\n            )\n        m = resp.json().get('macaroon')\n        if m is None:\n            raise httpbakery.InteractionError('no macaroon in response')\n        m = bakery.Macaroon.from_dict(m)\n        ms = bakery.discharge_all(m, None, self._auth_info.key)\n        b = bytearray()\n        for m in ms:\n            b.extend(utils.b64decode(m.serialize()))\n        return httpbakery.DischargeToken(kind='agent', value=bytes(b))", "response": "Implement Interactor. interact by obtaining the acquired macaroon from the discharger using the discharged macaroon as\n a discharge token using the discharged macaroon as\n a discharge token"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_agent(self, location):\n        ''' Finds an appropriate agent entry for the given location.\n        :return Agent\n        '''\n        for a in self._auth_info.agents:\n            # Don't worry about trailing slashes\n            if a.url.rstrip('/') == location.rstrip('/'):\n                return a\n        raise httpbakery.InteractionMethodNotFound(\n            'cannot find username for discharge location {}'.format(location))", "response": "Find an appropriate agent entry for the given location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef legacy_interact(self, client, location, visit_url):\n        '''Implement LegacyInteractor.legacy_interact by obtaining\n        the discharge macaroon using the client's private key\n        '''\n        agent = self._find_agent(location)\n        # Shallow-copy the client so that we don't unexpectedly side-effect\n        # it by changing the key. Another possibility might be to\n        # set up agent authentication differently, in such a way that\n        # we're sure that client.key is the same as self._auth_info.key.\n        client = copy.copy(client)\n        client.key = self._auth_info.key\n        resp = client.request(\n            method='POST',\n            url=visit_url,\n            json={\n                'username': agent.username,\n                'public_key': str(self._auth_info.key.public_key),\n            },\n        )\n        if resp.status_code != 200:\n            raise httpbakery.InteractionError(\n                'cannot acquire agent macaroon from {}: {} (response body: {!r})'.format(visit_url, resp.status_code, resp.text))\n        if not resp.json().get('agent_login', False):\n            raise httpbakery.InteractionError('agent login failed')", "response": "Implement LegacyInteractor. legacy_interact by obtaining\n        the discharge macaroon using the client s private key and the agent s public key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef macaroons_expiry_time(ns, ms):\n    ''' Returns the minimum time of any time-before caveats found in the given\n    macaroons or None if no such caveats were found.\n    :param ns: a Namespace, used to resolve caveats.\n    :param ms: a list of pymacaroons.Macaroon\n    :return: datetime.DateTime or None.\n    '''\n    t = None\n    for m in ms:\n        et = expiry_time(ns, m.caveats)\n        if et is not None and (t is None or et < t):\n            t = et\n    return t", "response": "Returns the minimum time of any time - before caveats found in the given macaroons."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef expiry_time(ns, cavs):\n    ''' Returns the minimum time of any time-before caveats found\n    in the given list or None if no such caveats were found.\n\n    The ns parameter is\n    :param ns: used to determine the standard namespace prefix - if\n    the standard namespace is not found, the empty prefix is assumed.\n    :param cavs: a list of pymacaroons.Caveat\n    :return: datetime.DateTime or None.\n    '''\n    prefix = ns.resolve(STD_NAMESPACE)\n    time_before_cond = condition_with_prefix(\n        prefix, COND_TIME_BEFORE)\n    t = None\n    for cav in cavs:\n        if not cav.first_party():\n            continue\n        cav = cav.caveat_id_bytes.decode('utf-8')\n        name, rest = parse_caveat(cav)\n        if name != time_before_cond:\n            continue\n        try:\n            et = pyrfc3339.parse(rest, utc=True).replace(tzinfo=None)\n            if t is None or et < t:\n                t = et\n        except ValueError:\n            continue\n    return t", "response": "Returns the minimum time of any time - before caveats found in the given list or None if no such caveats were found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the server.", "response": "def connect(self, url):\n        \"\"\"Connect to the server.\n        :param str url: server URL.\n        \"\"\"\n\n        headers = httputil.HTTPHeaders({'Content-Type': APPLICATION_JSON})\n        request = httpclient.HTTPRequest(url=url,\n                                         connect_timeout=self.connect_timeout,\n                                         request_timeout=self.request_timeout,\n                                         headers=headers)\n        ws = websocket_connect(url)\n        ws.add_done_callback(self._connect_callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to the server.", "response": "def send(self, data):\n        \"\"\"Send message to the server\n        :param str data: message.\n        \"\"\"\n        if not self._ws_connection:\n            raise RuntimeError('Web socket connection is closed.')\n\n        self._ws_connection.write_message(json.dumps(data))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_all(text, replace_dict):\n    for i, j in replace_dict.items():\n        text = text.replace(i, j)\n    return text", "response": "Replace multiple strings in a text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_or_apply(function, param):\n    try:\n        if isinstance(param, list):\n            return [next(iter(function(i))) for i in param]\n        else:\n            return next(iter(function(param)))\n    except StopIteration:\n        return None", "response": "Maps the function on param or applies it depending on param \\\n            is a list or an item."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef batch(iterable, size):\n    item = iter(iterable)\n    while True:\n        batch_iterator = islice(item, size)\n        try:\n            yield chain([next(batch_iterator)], batch_iterator)\n        except StopIteration:\n            return", "response": "Returns a list of items from an iterable in batches of the given size at a time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a slug for the given string.", "response": "def slugify(value):\n    \"\"\"\n    Normalizes string, converts to lowercase, removes non-alpha characters,\n    and converts spaces to hyphens to have nice filenames.\n\n    From Django's \"django/template/defaultfilters.py\".\n\n    >>> slugify(\"El ping\u00fcino Wenceslao hizo kil\u00f3metros bajo exhaustiva lluvia y fr\u00edo, a\u00f1oraba a su querido cachorro. ortez ce vieux whisky au juge blond qui fume sur son \u00eele int\u00e9rieure, \u00e0 \u0393\u03b1\u03b6\u03ad\u03b5\u03c2 \u03ba\u03b1\u1f76 \u03bc\u03c5\u03c1\u03c4\u03b9\u1f72\u03c2 \u03b4\u1f72\u03bd \u03b8\u1f70 \u03b2\u03c1\u1ff6 \u03c0\u03b9\u1f70 \u03c3\u03c4\u1f78 \u03c7\u03c1\u03c5\u03c3\u03b1\u03c6\u1f76 \u03be\u03ad\u03c6\u03c9\u03c4\u03bf \u3044\u308d\u306f\u306b\u307b\u3078\u3068\u3061\u308a\u306c\u308b\u3092 Pchn\u0105\u0107 w t\u0119 \u0142\u00f3d\u017a je\u017ca lub o\u015bm skrzy\u0144 fig \u0e01\u0e27\u0e48\u0e32\u0e1a\u0e23\u0e23\u0e14\u0e32\u0e1d\u0e39\u0e07\u0e2a\u0e31\u0e15\u0e27\u0e4c\u0e40\u0e14\u0e23\u0e31\u0e08\u0e09\u0e32\u0e19\")\n    'El_pinguino_Wenceslao_hizo_kilometros_bajo_exhaustiva_lluvia_y_frio_anoraba_a_su_querido_cachorro_ortez_ce_vieux_whisky_au_juge_blond_qui_fume_sur_son_ile_interieure_a_Pchnac_w_te_odz_jeza_lub_osm_skrzyn_fig'\n    \"\"\"\n    try:\n        unicode_type = unicode\n    except NameError:\n        unicode_type = str\n    if not isinstance(value, unicode_type):\n        value = unicode_type(value)\n    value = (unicodedata.normalize('NFKD', value).\n             encode('ascii', 'ignore').decode('ascii'))\n    value = unicode_type(_SLUGIFY_STRIP_RE.sub('', value).strip())\n    return _SLUGIFY_HYPHENATE_RE.sub('_', value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the citations of a given preprint in plain text.", "response": "def get_plaintext_citations(arxiv_id):\n    \"\"\"\n    Get the citations of a given preprint, in plain text.\n\n    .. note::\n\n        Bulk download of sources from arXiv is not permitted by their API. \\\n                You should have a look at http://arxiv.org/help/bulk_data_s3.\n\n    :param arxiv_id: The arXiv id (e.g. ``1401.2910`` or ``1401.2910v1``) in \\\n            a canonical form.\n    :returns:  A list of cleaned plaintext citations.\n    \"\"\"\n    plaintext_citations = []\n    # Get the list of bbl files for this preprint\n    bbl_files = arxiv.get_bbl(arxiv_id)\n    for bbl_file in bbl_files:\n        # Fetch the cited DOIs for each of the bbl files\n        plaintext_citations.extend(bbl.get_plaintext_citations(bbl_file))\n    return plaintext_citations"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the cited DOIs of the papers cited in a. bbl file.", "response": "def get_cited_dois(arxiv_id):\n    \"\"\"\n    Get the DOIs of the papers cited in a .bbl file.\n\n    .. note::\n\n        Bulk download of sources from arXiv is not permitted by their API. \\\n                You should have a look at http://arxiv.org/help/bulk_data_s3.\n\n    :param arxiv_id: The arXiv id (e.g. ``1401.2910`` or ``1401.2910v1``) in \\\n            a canonical form.\n    :returns: A dict of cleaned plaintext citations and their associated DOI.\n    \"\"\"\n    dois = {}\n    # Get the list of bbl files for this preprint\n    bbl_files = arxiv.get_bbl(arxiv_id)\n    for bbl_file in bbl_files:\n        # Fetch the cited DOIs for each of the bbl files\n        dois.update(bbl.get_cited_dois(bbl_file))\n    return dois"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_subcommand_kwargs(mgr, name, namespace):\n    subcmd = mgr.get(name)\n    subcmd_kwargs = {}\n    for opt in list(subcmd.args.values()) + list(subcmd.options.values()):\n        if hasattr(namespace, opt.dest):\n            subcmd_kwargs[opt.dest] = getattr(namespace, opt.dest)\n    return (subcmd, subcmd_kwargs)", "response": "Get the kwargs for a given subcommand from global parsed\n    arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a plaintext file to get a list of cleaned plaintext citations.", "response": "def get_plaintext_citations(file):\n    \"\"\"\n    Parse a plaintext file to get a clean list of plaintext citations. The \\\n            file should have one citation per line.\n\n    :param file: Either the path to the plaintext file or the content of a \\\n            plaintext file.\n    :returns:  A list of cleaned plaintext citations.\n    \"\"\"\n    # Handle path or content\n    if os.path.isfile(file):\n        with open(file, 'r') as fh:\n            content = fh.readlines()\n    else:\n        content = file.splitlines()\n    # Clean every line to have plaintext\n    cleaned_citations = [tools.clean_whitespaces(line) for line in content]\n    return cleaned_citations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the cited DOIs of the papers cited in a plaintext file.", "response": "def get_cited_dois(file):\n    \"\"\"\n    Get the DOIs of the papers cited in a plaintext file. The file should \\\n            have one citation per line.\n\n    .. note::\n\n        This function is also used as a backend tool by most of the others \\\n        citations processors, to factorize the code.\n\n    :param file: Either the path to the plaintext file or the content of a \\\n            plaintext file. It can also be a parsed list of plaintext \\\n            citations and, in this case, no preprocessing is done.\n    :returns: A dict of cleaned plaintext citations and their associated DOI.\n    \"\"\"\n    # If file is not a pre-processed list of plaintext citations\n    if not isinstance(file, list):\n        # It is either a path to a plaintext file or the content of a plaintext\n        # file, we need some pre-processing to get a list of citations.\n        plaintext_citations = get_plaintext_citations(file)\n    else:\n        # Else, we passed a list of plaintext citations.\n        plaintext_citations = file\n    dois = {}\n    crossref_queue = []\n\n    # Try to get the DOI directly from the citation\n    for citation in plaintext_citations[:]:\n        # Some citations already contain a DOI so try to match it directly\n        matched_dois = doi.extract_from_text(citation)\n        if len(matched_dois) > 0:\n            # Add the DOI and go on\n            dois[citation] = next(iter(matched_dois))\n            continue\n        # Same thing for arXiv id\n        matched_arxiv = arxiv.extract_from_text(citation)\n        if len(matched_arxiv) > 0:\n            # Add the associated DOI and go on\n            dois[citation] = arxiv.to_doi(next(iter(matched_arxiv)))\n            continue\n        # If no match found, stack it for next step\n        # Note to remove URLs in the citation as the plaintext citations can\n        # contain URLs and they are bad for the CrossRef API.\n        crossref_queue.append(tools.remove_urls(citation))\n\n    # Do batch with remaining papers, to prevent from the timeout of CrossRef\n    for batch in tools.batch(crossref_queue, CROSSREF_MAX_BATCH_SIZE):\n        batch = [i for i in batch]\n        try:\n            # Fetch results from CrossRef\n            request = requests.post(CROSSREF_LINKS_API_URL, json=batch)\n            for result in request.json()[\"results\"]:\n                # Try to get a DOI\n                try:\n                    dois[result[\"text\"]] = result[\"doi\"]\n                except KeyError:\n                    # Or set it to None\n                    dois[result[\"text\"]] = None\n        except (RequestException, ValueError, KeyError):\n            # If an exception occurred, set all the DOIs to None for the\n            # current batch\n            for i in batch:\n                dois[i] = None\n    return dois"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the name of the SDC object for the current set of attributes.", "response": "def set_sdc_name(self, name, sdcObj):\n        \"\"\"\n        Set name for SDC\n        :param name: Name of SDC\n        :param sdcObj: ScaleIO SDC object\n        :return: POST request response\n        :rtype: Requests POST response object\n        \"\"\"\n        # TODO:\n        # Check if object parameters are the correct ones, otherwise throw error\n        self.conn.connection._check_login()\n        sdcNameDict = {'sdcName': name}\n        response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self.conn.connection._api_url, \"instances/Sdc::\", sdcObj.id, 'action/setSdcName'), json=sdcNameDict)    \n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sdc_by_name(self, name):\n        for sdc in self.sdc:\n            if sdc.name == name:\n                return sdc\n        raise KeyError(\"SDC of that name not found\")", "response": "Get ScaleIO SDC object by its name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sdc_by_id(self, id):\n        for sdc in self.sdc:\n            if sdc.id == id:\n                return sdc\n        raise KeyError(\"SDC with that ID not found\")", "response": "Get ScaleIO SDC object by its id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting ScaleIO SDC object by its GUID", "response": "def get_sdc_by_guid(self, guid):\n        \"\"\"\n        Get ScaleIO SDC object by its id\n        :param name: guid of SDC\n        :return: ScaleIO SDC object\n        :raise KeyError: No SDC with specified id found\n        :rtype: SDC object\n        \"\"\"\n        for sdc in self.sdc:\n            if sdc.guid == guid:\n                return sdc\n        raise KeyError(\"SDC with that GUID not found\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sdc_by_ip(self, ip):\n        if self.conn.is_ip_addr(ip):\n            for sdc in self.sdc:\n                if sdc.sdcIp == ip:\n                    return sdc\n            raise KeyError(\"SDS of that name not found\")\n        else:\n            raise ValueError(\"Malformed IP address - get_sdc_by_ip()\")", "response": "Get ScaleIO SDC object by its IP address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a given string is a valid ISBN.", "response": "def is_valid(isbn_id):\n    \"\"\"\n    Check that a given string is a valid ISBN.\n\n    :param isbn_id: the isbn to be checked.\n    :returns: boolean indicating whether the isbn is valid or not.\n\n    >>> is_valid(\"978-3-16-148410-0\")\n    True\n\n    >>> is_valid(\"9783161484100\")\n    True\n\n    >>> is_valid(\"9783161484100aa\")\n    False\n\n    >>> is_valid(\"abcd\")\n    False\n\n    >>> is_valid(\"0136091814\")\n    True\n\n    >>> is_valid(\"0136091812\")\n    False\n\n    >>> is_valid(\"9780136091817\")\n    False\n\n    >>> is_valid(\"123456789X\")\n    True\n    \"\"\"\n    return (\n        (not isbnlib.notisbn(isbn_id)) and (\n            isbnlib.get_canonical_isbn(isbn_id) == isbn_id or\n            isbnlib.mask(isbnlib.get_canonical_isbn(isbn_id)) == isbn_id)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts ISBNs from a text.", "response": "def extract_from_text(text):\n    \"\"\"\n    Extract ISBNs from a text.\n\n    :param text: Some text.\n    :returns: A list of canonical ISBNs found in the text.\n\n    >>> extract_from_text(\"978-3-16-148410-0 9783161484100 9783161484100aa abcd 0136091814 0136091812 9780136091817 123456789X\")\n    ['9783161484100', '9783161484100', '9783161484100', '0136091814', '123456789X']\n    \"\"\"\n    isbns = [isbnlib.get_canonical_isbn(isbn)\n             for isbn in isbnlib.get_isbnlike(text)]\n    return [i for i in isbns if i is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_bibtex(isbn_identifier):\n    # Try to find the BibTeX using associated DOIs\n    bibtex = doi.get_bibtex(to_doi(isbn_identifier))\n    if bibtex is None:\n        # In some cases, there are no DOIs for a given ISBN. In this case, try\n        # to fetch bibtex directly from the ISBN, using a combination of\n        # Google Books and worldcat.org results.\n        bibtex = isbnlib.registry.bibformatters['bibtex'](\n            isbnlib.meta(isbn_identifier, 'default'))\n    return bibtex", "response": "Get a BibTeX string for the given ISBN."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning options already used in the command line", "response": "def used_options(self):\n        \"\"\"Return options already used in the\n        command line\n\n        rtype: command.Option generator\n        \"\"\"\n        for option_str in filter(lambda c: c.startswith('-'), self.words):\n            for option in list(self.cmd.options.values()):\n                if option_str in option.option_strings:\n                    yield option"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a generator of all available command. Option objects given the current cmd line", "response": "def available_options(self):\n        \"\"\"Return options that can be used given\n        the current cmd line\n\n        rtype: command.Option generator\n        \"\"\"\n        for option in list(self.cmd.options.values()):\n            if (option.is_multiple or\n                    option not in list(self.used_options)):\n                yield option"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef used_args(self):\n        # get all arguments values from the command line\n        values = []\n        for idx, c in enumerate(self.words[1:]):\n            if c.startswith('-'):\n                continue\n            option_str = self.words[1:][idx - 1]\n            option = self.get_option(option_str)\n            if option is None or not option.need_value:\n                values.append((c, c == self.document.get_word_before_cursor(WORD=True)))\n        logger.debug(\"Found args values %s\" % values)\n        # consume values\n        for arg in self.cmd.args.values():\n            if not values:\n                raise StopIteration\n            if arg.is_multiple:\n                values = []\n                yield arg\n            elif type(arg.nargs) is int:\n                for _ in range(arg.nargs):\n                    value = values.pop(0)\n                    # not the current argument\n                    if value[1] is False:\n                        yield arg\n                    if not values:\n                        raise StopIteration", "response": "Return the args already used in the command line\n        rtype : command. Arg generator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the available args given the current cmd line rtype : command. Arg generator", "response": "def available_args(self):\n        \"\"\"Return args that can be used given\n        the current cmd line\n\n        rtype: command.Arg generator\n        \"\"\"\n        used = list(self.used_args)\n        logger.debug('Found used args: %s' % used)\n        for arg in list(self.cmd.args.values()):\n            if (arg.is_multiple or\n                    arg not in used):\n                yield arg\n            elif (type(arg.nargs) is int and\n                    arg.nargs > 1 and\n                    not arg.nargs == used.count(arg)):\n                yield arg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_elem_ref(elem_ref):\n    return (\n        elem_ref\n        and isinstance(elem_ref, tuple)\n        and len(elem_ref) == 3\n        and (elem_ref[0] == ElemRefObj or elem_ref[0] == ElemRefArr)\n    )", "response": "Returns true if the elem_ref is an element reference\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the element with the given elem_ref is present in the base element list.", "response": "def has_elem(elem_ref):\n    \"\"\"\n    Has element?\n    :param elem_ref:\n    :return:\n    \"\"\"\n    if not is_elem_ref(elem_ref):\n        return False\n    elif elem_ref[0] == ElemRefObj:\n        return hasattr(elem_ref[1], elem_ref[2])\n    elif elem_ref[0] == ElemRefArr:\n        return elem_ref[2] in elem_ref[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_elem(elem_ref, default=None):\n    if not is_elem_ref(elem_ref):\n        return elem_ref\n    elif elem_ref[0] == ElemRefObj:\n        return getattr(elem_ref[1], elem_ref[2], default)\n    elif elem_ref[0] == ElemRefArr:\n        return elem_ref[1][elem_ref[2]]", "response": "Gets the element referenced by elem_ref or returns the elem_ref directly if it s not a reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the element referenced by the elem_ref. Returns the elem.", "response": "def set_elem(elem_ref, elem):\n    \"\"\"\n    Sets element referenced by the elem_ref. Returns the elem.\n\n    :param elem_ref:\n    :param elem:\n    :return:\n    \"\"\"\n    if elem_ref is None or elem_ref == elem or not is_elem_ref(elem_ref):\n        return elem\n\n    elif elem_ref[0] == ElemRefObj:\n        setattr(elem_ref[1], elem_ref[2], elem)\n        return elem\n\n    elif elem_ref[0] == ElemRefArr:\n        elem_ref[1][elem_ref[2]] = elem\n        return elem"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning element reference :param obj: :param key: :param is_assoc: :return:", "response": "def eref(obj, key, is_assoc=None):\n    \"\"\"\n    Returns element reference\n    :param obj:\n    :param key:\n    :param is_assoc:\n    :return:\n    \"\"\"\n    if obj is None:\n        return None\n    if isinstance(key, int) or (is_assoc is not None and is_assoc):\n        return ElemRefArr, get_elem(obj), key\n    else:\n        return ElemRefObj, get_elem(obj), key"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrevising wording to match canonical and expected forms.", "response": "def _preprocess(inp):\n        \"\"\"Revise wording to match canonical and expected forms.\"\"\"\n        inp = re.sub(r'(\\b)a(\\b)', r'\\g<1>one\\g<2>', inp)\n        inp = re.sub(r'to the (.*) power', r'to \\g<1>', inp)\n        inp = re.sub(r'to the (.*?)(\\b)', r'to \\g<1>\\g<2>', inp)\n        inp = re.sub(r'log of', r'log', inp)\n        inp = re.sub(r'(square )?root( of)?', r'sqrt', inp)\n        inp = re.sub(r'squared', r'to two', inp)\n        inp = re.sub(r'cubed', r'to three', inp)\n        inp = re.sub(r'divided?( by)?', r'divide', inp)\n        inp = re.sub(r'(\\b)over(\\b)', r'\\g<1>divide\\g<2>', inp)\n        inp = re.sub(r'(\\b)EE(\\b)', r'\\g<1>e\\g<2>', inp)\n        inp = re.sub(r'(\\b)E(\\b)', r'\\g<1>e\\g<2>', inp)\n        inp = re.sub(r'(\\b)pie(\\b)', r'\\g<1>pi\\g<2>', inp)\n        inp = re.sub(r'(\\b)PI(\\b)', r'\\g<1>pi\\g<2>', inp)\n\n        def findImplicitMultiplications(inp):\n            \"\"\"Replace omitted 'times' references.\"\"\"\n\n            def findConstantMultiplications(inp):\n                split = inp.split(' ')\n                revision = \"\"\n\n                converter = NumberService()\n                for i, w in enumerate(split):\n                    if i > 0 and w in MathService.__constants__:\n                        if converter.isValid(split[i - 1]):\n                            revision += \" times\"\n                    if not revision:\n                        revision = w\n                    else:\n                        revision += \" \" + w\n\n                return revision\n\n            def findUnaryMultiplications(inp):\n                split = inp.split(' ')\n                revision = \"\"\n\n                for i, w in enumerate(split):\n                    if i > 0 and w in MathService.__unaryOperators__:\n                        last_op = split[i - 1]\n\n                        binary = last_op in MathService.__binaryOperators__\n                        unary = last_op in MathService.__unaryOperators__\n\n                        if last_op and not (binary or unary):\n                            revision += \" times\"\n                    if not revision:\n                        revision = w\n                    else:\n                        revision += \" \" + w\n\n                return revision\n\n            return findUnaryMultiplications(findConstantMultiplications(inp))\n\n        return findImplicitMultiplications(inp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates a final value given a set of numbers and symbols.", "response": "def _calculate(numbers, symbols):\n        \"\"\"Calculates a final value given a set of numbers and symbols.\"\"\"\n        if len(numbers) is 1:\n            return numbers[0]\n\n        precedence = [[pow], [mul, div], [add, sub]]\n\n        # Find most important operation\n        for op_group in precedence:\n            for i, op in enumerate(symbols):\n                if op in op_group:\n                    # Apply operation\n                    a = numbers[i]\n                    b = numbers[i + 1]\n                    result = MathService._applyBinary(a, b, op)\n                    new_numbers = numbers[:i] + [result] + numbers[i + 2:]\n                    new_symbols = symbols[:i] + symbols[i + 1:]\n\n                    return MathService._calculate(new_numbers, new_symbols)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseEquation(self, inp):\n        inp = MathService._preprocess(inp)\n        split = inp.split(' ')\n\n        # Recursive call on unary operators\n        for i, w in enumerate(split):\n            if w in self.__unaryOperators__:\n                op = self.__unaryOperators__[w]\n\n                # Split equation into halves\n                eq1 = ' '.join(split[:i])\n                eq2 = ' '.join(split[i + 1:])\n\n                # Calculate second half\n                result = MathService._applyUnary(self.parseEquation(eq2), op)\n\n                return self.parseEquation(eq1 + \" \" + str(result))\n\n        def extractNumbersAndSymbols(inp):\n            numbers = []\n            symbols = []\n\n            # Divide into values (numbers), operators (symbols)\n            next_number = \"\"\n            for w in inp.split(' '):\n                if w in self.__binaryOperators__:\n                    symbols.append(self.__binaryOperators__[w])\n\n                    if next_number:\n                        numbers.append(next_number)\n                        next_number = \"\"\n\n                else:\n                    if next_number:\n                        next_number += \" \"\n                    next_number += w\n\n            if next_number:\n                numbers.append(next_number)\n\n            # Cast numbers from words to integers\n            def convert(n):\n                if n in self.__constants__:\n                    return self.__constants__[n]\n\n                converter = NumberService()\n                return converter.parse(n)\n\n            numbers = [convert(n) for n in numbers]\n\n            return numbers, symbols\n\n        numbers, symbols = extractNumbersAndSymbols(inp)\n\n        return MathService._calculate(numbers, symbols)", "response": "Solves the equation specified by the input string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, command, description, function, params=[]):\n        return self.app.commands.register(command, description, function, params, self.plugin)", "response": "Registers a new command for a plugin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a single command or dict of commands which can be filtered by name.", "response": "def get(self, name=None):\n        \"\"\"\n        Returns commands, which can be filtered by name.\n\n        :param name: name of the command\n        :type name: str\n        :return: None, single command or dict of commands\n        \"\"\"\n        return self.app.commands.get(name, self.plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, name=None, plugin=None):\n        if plugin is not None:\n            if name is None:\n                command_list = {}\n                for key in self._commands.keys():\n                    if self._commands[key].plugin == plugin:\n                        command_list[key] = self._commands[key]\n                return command_list\n            else:\n                if name in self._commands.keys():\n                    if self._commands[name].plugin == plugin:\n                        return self._commands[name]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if name is None:\n                return self._commands\n            else:\n                if name in self._commands.keys():\n                    return self._commands[name]\n                else:\n                    return None", "response": "Returns commands which can be filtered by name or plugin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self, command, description, function, params=[], plugin=None):\n        if command in self._commands.keys():\n            raise CommandExistException(\"Command %s already registered by %s\" % (command,\n                                                                                 self._commands[command].plugin.name))\n\n        new_command = Command(command, description, params, function, plugin)\n        self._commands[command] = new_command\n        self._click_root_command.add_command(new_command.click_command)\n        self.log.debug(\"Command registered: %s\" % command)\n        return new_command", "response": "Registers a new command in the command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregister(self, command):\n        if command not in self._commands.keys():\n            self.log.warning(\"Can not unregister command %s\" % command)\n        else:\n            # Click does not have any kind of a function to unregister/remove/deactivate already added commands.\n            # So we need to delete the related objects manually from the click internal commands dictionary for\n            # our root command.\n            del(self._click_root_command.commands[command])\n            # Finally lets delete the command from our internal dictionary too.\n            del(self._commands[command])\n            self.log.debug(\"Command %s got unregistered\" % command)", "response": "Unregisters an existing command from the click internal commands dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rcpt(self, recip, options=[]):\n        optionlist = ''\n        if options and self.does_esmtp:\n            optionlist = ' ' + ' '.join(options)\n        code, msg = yield self.docmd(b\"rcpt\", (\"TO:%s%s\" % (smtplib.quoteaddr(recip), optionlist)).encode('ascii'))\n        return (code, msg)", "response": "SMTP 'rcpt' command -- indicates 1 recipient for this mail."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data(self, msg):\n\n        (code, repl) = yield self.docmd(b\"data\")\n\n        if code != 354:\n            raise smtplib.SMTPDataError(code, repl)\n        else:\n            if isinstance(msg, str):\n                msg = smtplib._fix_eols(msg).encode('ascii')\n            q = smtplib._quote_periods(msg)\n            if q[-2:] != CRLF:\n                q = q + CRLF\n            q = q + b\".\" + CRLF\n            #self.send(q)\n            yield self.send(q)\n            (code, msg) = yield self.getreply()\n            return (code, msg)", "response": "SMTP DATA command. Sends a message to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a declared caveat asserting that the given key is set to the given value.", "response": "def declared_caveat(key, value):\n    '''Returns a \"declared\" caveat asserting that the given key is\n    set to the given value.\n\n    If a macaroon has exactly one first party caveat asserting the value of a\n    particular key, then infer_declared will be able to infer the value, and\n    then the check will allow the declared value if it has the value\n    specified here.\n\n    If the key is empty or contains a space, it will return an error caveat.\n    '''\n    if key.find(' ') >= 0 or key == '':\n        return error_caveat('invalid caveat \\'declared\\' key \"{}\"'.format(key))\n    return _first_party(COND_DECLARED, key + ' ' + value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _operation_caveat(cond, ops):\n    ''' Helper for allow_caveat and deny_caveat.\n\n    It checks that all operation names are valid before creating the caveat.\n    '''\n    for op in ops:\n        if op.find(' ') != -1:\n            return error_caveat('invalid operation name \"{}\"'.format(op))\n    return _first_party(cond, ' '.join(ops))", "response": "Helper function for allow_caveat and deny_caveat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a caveat that specifies that the time that it is checked before t.", "response": "def time_before_caveat(t):\n    '''Return a caveat that specifies that the time that it is checked at\n    should be before t.\n    :param t is a a UTC date in - use datetime.utcnow, not datetime.now\n    '''\n\n    return _first_party(COND_TIME_BEFORE,\n                        pyrfc3339.generate(t, accept_naive=True,\n                                           microseconds=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a caveat into an identifier identifying the checker that should be used and the argument to the checker.", "response": "def parse_caveat(cav):\n    ''' Parses a caveat into an identifier, identifying the checker that should\n    be used, and the argument to the checker (the rest of the string).\n\n    The identifier is taken from all the characters before the first\n    space character.\n    :return two string, identifier and arg\n    '''\n    if cav == '':\n        raise ValueError('empty caveat')\n    try:\n        i = cav.index(' ')\n    except ValueError:\n        return cav, ''\n    if i == 0:\n        raise ValueError('caveat starts with space character')\n    return cav[0:i], cav[i + 1:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning s as a bytes type using utf - 8 encoding if necessary.", "response": "def to_bytes(s):\n    '''Return s as a bytes type, using utf-8 encoding if necessary.\n    @param s string or bytes\n    @return bytes\n    '''\n    if isinstance(s, six.binary_type):\n        return s\n    if isinstance(s, six.string_types):\n        return s.encode('utf-8')\n    raise TypeError('want string or bytes, got {}', type(s))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef b64decode(s):\n    '''Base64 decodes a base64-encoded string in URL-safe\n    or normal format, with or without padding.\n    The argument may be string or bytes.\n\n    @param s bytes decode\n    @return bytes decoded\n    @raises ValueError on failure\n    '''\n    # add padding if necessary.\n    s = to_bytes(s)\n    if not s.endswith(b'='):\n        s = s + b'=' * (-len(s) % 4)\n    try:\n        if '_' or '-' in s:\n            return base64.urlsafe_b64decode(s)\n        else:\n            return base64.b64decode(s)\n    except (TypeError, binascii.Error) as e:\n        raise ValueError(str(e))", "response": "Base64 decodes a base64 - encoded string in URL - safe\n    or normal format with or without padding."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new Cookie using a slightly more efficient API than that provided by six. moves. http_cookiejar", "response": "def cookie(\n        url,\n        name,\n        value,\n        expires=None):\n    '''Return a new Cookie using a slightly more\n    friendly API than that provided by six.moves.http_cookiejar\n\n    @param name The cookie name {str}\n    @param value The cookie value {str}\n    @param url The URL path of the cookie {str}\n    @param expires The expiry time of the cookie {datetime}. If provided,\n        it must be a naive timestamp in UTC.\n    '''\n    u = urlparse(url)\n    domain = u.hostname\n    if '.' not in domain and not _is_ip_addr(domain):\n        domain += \".local\"\n    port = str(u.port) if u.port is not None else None\n    secure = u.scheme == 'https'\n    if expires is not None:\n        if expires.tzinfo is not None:\n            raise ValueError('Cookie expiration must be a naive datetime')\n        expires = (expires - datetime(1970, 1, 1)).total_seconds()\n    return http_cookiejar.Cookie(\n        version=0,\n        name=name,\n        value=value,\n        port=port,\n        port_specified=port is not None,\n        domain=domain,\n        domain_specified=True,\n        domain_initial_dot=False,\n        path=u.path,\n        path_specified=True,\n        secure=secure,\n        expires=expires,\n        discard=False,\n        comment=None,\n        comment_url=None,\n        rest=None,\n        rfc2109=False,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging-in to the ScaleIO IM.", "response": "def _login(self):\n        \"\"\"\n        LOGIN CAN ONLY BE DONE BY POSTING TO A HTTP FORM.\n        A COOKIE IS THEN USED FOR INTERACTING WITH THE API\n        \"\"\"\n        self.logger.debug(\"Logging into \" + \"{}/{}\".format(self._im_api_url, \"j_spring_security_check\"))\n        self._im_session.headers.update({'Content-Type':'application/x-www-form-urlencoded', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.99 Safari/537.36'})\n        #self._im_session.mount('https://', TLS1Adapter())\n        #self._im_verify_ssl = False\n        self.j_username = self._username\n        self.j_password = self._password\n        requests.packages.urllib3.disable_warnings() # Disable unverified connection warning.\n        payload = {'j_username': self.j_username, 'j_password': self.j_password, 'submit':'Login'}\n        \n        # login to ScaleIO IM\n        r = self._im_session.post(\n            \"{}/{}\".format(self._im_api_url,\"j_spring_security_check\"),\n            verify=self._im_verify_ssl,\n            #headers = {'Content-Type':'application/x-www-form-urlencoded', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.99 Safari/537.36'},\n            data=payload)\n        self.logger.debug(\"Login POST response: \" + \"{}\".format(r.text))\n\n        self._im_logged_in = True\n        \n        \"\"\"\n        ADD CODE:\n        Check if this is IM have existing configuration. If so populate ScaleIO_configurtion_object\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the state of the idle cluster to newstate.", "response": "def set_abort_pending(self, newstate):\n        \"\"\"\n        Method to set Abort state if something goes wrong during provisioning\n        Method also used to finish provisioning process when all is completed\n        Method: POST\n        \"\"\"\n        self.logger.debug(\"set_abort_pending(\" + \"{})\".format(newstate))\n        # NOT TO BE USED\n        #default_minimal_cluster_config = '{\"installationId\":null,\"mdmIPs\":[\"192.168.102.12\",\"192.168.102.13\"],\"mdmPassword\":\"Scaleio123\",\"liaPassword\":\"Scaleio123\",\"licenseKey\":null,\"primaryMdm\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.12\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"managementIPs\":null,\"mdmIPs\":[\"192.168.102.12\"]},\"secondaryMdm\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.13\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"managementIPs\":null,\"mdmIPs\":[\"192.168.102.13\"]},\"tb\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.11\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"tbIPs\":[\"192.168.102.11\"]},\"sdsList\":[{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.11\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.102.11]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.102.11\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/home/vagrant/scaleio1\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.12\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.102.12]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.102.12\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/home/vagrant/scaleio1\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.13\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.102.13]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.102.13\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/home/vagrant/scaleio1\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072}],\"sdcList\":[{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.11\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.12\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.13\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null}],\"callHomeConfiguration\":null,\"remoteSyslogConfiguration\":null}'\n        r1 = self._im_session.post(\n            \"{}/{}\".format(self._im_api_url,\"types/Command/instances/actions/abortPending\"),\n            headers={'Content-type':'application/json','Version':'1.0'}, \n            verify=self._im_verify_ssl,\n            data = newstate,\n            stream=True\n        )\n        if not r1.ok:\n            # Something went wrong\n            self.logger.error(\"Error set_abort_pending(\" +\"{})\".format(newstate))\n\n        #print \"Response after set_abort_pending()\"\n        # RESPONSE NEED TO BE WRAPPED IN try/catch. Cannot assume JSON is returned.\n        #print r1.text\n        #pprint (json.loads(r1.text))\n        return r1.text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push_cached_cluster_configuration(self, mdmPassword, liaPassword, noUpload = False, noInstall= False, noConfigure = False):\n        self.logger.debug(\"push_cached_cluster_configuration(\" + \"{},{},{},{},{}\".format(mdmPassword, liaPassword, noUpload, noInstall, noConfigure))\n        config_params = {'noUpload': noUpload, 'noInstall': noInstall, 'noConfigure':noConfigure}\n        #print \"Push cached ScaleIO cluster configuration to IM\"\n        self._cluster_config_cached.setMdmPassword(mdmPassword)\n        self._cluster_config_cached.setLiaPassword(liaPassword)\n        self.logger.debug(\"Push JSON data:\")\n        self.logger.debug(\"{}\".format(self._cluster_config_cached.to_JSON()))\n\n        ####### FINISH METOD - CAN ONLY PUSH - USE CACHE\n        # SDS configured to use /home/scaleio1\n        #default_minimal_cluster_config = '{\"installationId\":null,\"mdmIPs\":[\"192.168.102.12\",\"192.168.102.13\"],\"mdmPassword\":\"Scaleio123\",\"liaPassword\":\"Scaleio123\",\"licenseKey\":null,\"primaryMdm\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.12\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"managementIPs\":null,\"mdmIPs\":[\"192.168.102.12\"]},\"secondaryMdm\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.13\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"managementIPs\":null,\"mdmIPs\":[\"192.168.102.13\"]},\"tb\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.11\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"tbIPs\":[\"192.168.102.11\"]},\"sdsList\":[{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.11\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.102.11]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.102.11\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/home/vagrant/scaleio1\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.12\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.102.12]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.102.12\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/home/vagrant/scaleio1\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.13\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.102.13]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.102.13\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/home/vagrant/scaleio1\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072}],\"sdcList\":[{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.11\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.12\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.102.13\"],\"domain\":null,\"userName\":\"root\",\"password\":\"vagrant\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null}],\"callHomeConfiguration\":null,\"remoteSyslogConfiguration\":null}'\n        \n        # Generated with scelio_object.py - Progammatically generated JSON using a set of classes that represent different ScaleIO components\n        default_minimal_cluster_config = '{\"licenseKey\": null, \"mdmPassword\": \"Scaleio123\", \"mdmIPs\": [\"192.168.102.12\", \"192.168.102.13\"], \"sdsList\": [{\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.11\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"protectionDomain\": \"default\", \"nodeInfo\": null, \"sdsName\": \"SDS_192.168.102.11\", \"sdcOnlyIPs\": [], \"optimized\": false, \"devices\": [{\"devicePath\": \"/home/vagrant/scaleio1\", \"storagePool\": null, \"deviceName\": null}], \"faultSet\": null, \"port\": \"7072\", \"sdsOnlyIPs\": [], \"allIPs\": [\"192.168.102.11\"]}, {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.12\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"protectionDomain\": \"default\", \"nodeInfo\": null, \"sdsName\": \"SDS_192.168.102.12\", \"sdcOnlyIPs\": [], \"optimized\": false, \"devices\": [{\"devicePath\": \"/home/vagrant/scaleio1\", \"storagePool\": null, \"deviceName\": null}], \"faultSet\": null, \"port\": \"7072\", \"sdsOnlyIPs\": [], \"allIPs\": [\"192.168.102.12\"]}, {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.13\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"protectionDomain\": \"default\", \"nodeInfo\": null, \"sdsName\": \"SDS_192.168.102.13\", \"sdcOnlyIPs\": [], \"optimized\": false, \"devices\": [{\"devicePath\": \"/home/vagrant/scaleio1\", \"storagePool\": null, \"deviceName\": null}], \"faultSet\": null, \"port\": \"7072\", \"sdsOnlyIPs\": [], \"allIPs\": [\"192.168.102.13\"]}], \"liaPassword\": \"Scaleio123\", \"primaryMdm\": {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.12\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"nodeInfo\": null, \"managementIPs\": [], \"mdmIPs\": [\"192.168.102.12\"]}, \"callHomeConfiguration\": null, \"installationId\": null, \"secondaryMdm\": {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.13\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"nodeInfo\": null, \"managementIPs\": [], \"mdmIPs\": [\"192.168.102.13\"]}, \"sdcList\": [{\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.11\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"nodeInfo\": null, \"splitterRpaIp\": null}, {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.12\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"nodeInfo\": null, \"splitterRpaIp\": null}, {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.13\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"nodeInfo\": null, \"splitterRpaIp\": null}], \"tb\": {\"node\": {\"userName\": \"root\", \"domain\": null, \"nodeName\": null, \"nodeIPs\": [\"192.168.102.11\"], \"liaPassword\": null, \"ostype\": \"linux\", \"password\": \"vagrant\"}, \"nodeInfo\": null, \"tbIPs\": [\"192.168.102.11\"]}, \"remoteSyslogConfiguration\": null}'        \n        #\n        #default_minimal_cluster_config = '{\"installationId\":null,\"mdmIPs\":[\"192.168.100.51\",\"192.168.100.52\"],\"mdmPassword\":\"Password1!\",\"liaPassword\":\"Password1!\",\"licenseKey\":null,\"primaryMdm\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.51\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"managementIPs\":null,\"mdmIPs\":[\"192.168.100.51\"]},\"secondaryMdm\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.52\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"managementIPs\":null,\"mdmIPs\":[\"192.168.100.52\"]},\"tb\":{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.53\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"tbIPs\":[\"192.168.100.53\"]},\"sdsList\":[{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.51\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.100.51]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.100.51\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/dev/sdb\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.52\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.100.52]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.100.52\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/dev/sdb\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.53\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"sdsName\":\"SDS_[192.168.100.53]\",\"protectionDomain\":\"default\",\"faultSet\":null,\"allIPs\":[\"192.168.100.53\"],\"sdsOnlyIPs\":null,\"sdcOnlyIPs\":null,\"devices\":[{\"devicePath\":\"/dev/sdb\",\"storagePool\":null,\"deviceName\":null}],\"optimized\":false,\"port\":7072}],\"sdcList\":[{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.51\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.52\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null},{\"node\":{\"ostype\":\"linux\",\"nodeName\":null,\"nodeIPs\":[\"192.168.100.53\"],\"domain\":null,\"userName\":\"root\",\"password\":\"password\",\"liaPassword\":null},\"nodeInfo\":null,\"splitterRpaIp\":null}],\"callHomeConfiguration\":null,\"remoteSyslogConfiguration\":null}'\n        \n        #print \"JSON DUMP OF INSTALL CONFIG:\"\n        #pprint (json.loads(default_minimal_cluster_config))\n        \n        r1 = self._im_session.post(\n            \"{}/{}\".format(self._im_api_url,\"types/Installation/instances/\"),\n            headers={'Content-type':'application/json','Version':'1.0'},\n            params = config_params, \n            verify=self._im_verify_ssl,\n            #json=json.loads(self._cluster_config_cached.to_JSON()),\n            json = json.loads(default_minimal_cluster_config),\n            stream=True\n        )\n        if not r1.ok:\n            # Something went wrong\n            self.logger.error(\"Error push_cached_cluster_configuration()\")\n        \n        #print \"Response after push_cached_cluster_configuration()\"\n        \n        # RESPONSE NEED TO BE WRAPPED IN tey/catch. Can?t assume JSON is returned.\n        self.logger.debug(\"HTTP Response:\")\n        self.logger.debug(\"{}\".format(r1.text))\n        return r1.text", "response": "Push the current configuration to the IM"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_minimal_scaleio_cluster(self, mdmPassword, liaPassword):\n        \"\"\"\n        self.read_cluster_config_from_disk(\"minimal-cluster.json\")\n        #self._cluster_config_cached.setMdmPassword(setMdmPassword)\n        #self._cluster_config_cached.setLiaPassword(setLiaPassword)\n        self.push_cached_cluster_configuration(setMdmPassword, setLiaPassword)\n        \"\"\"\n        \n        ###########################\n        # Create a ScaleIO System #\n        ###########################\n        # Flow:\n        # Create Nodes\n        # Create basic info. mdmPass, liaPass and some others\n        # Construct MDM and TB and basic info\n        # Create list of SDS\n        # Create list of SDC\n        \n        \n        ###################\n        # Construct nodes #\n        ###################\n        nodeUsername = 'root'\n        nodePassword = 'password'\n        #node1 = ScaleIO_Node_Object(None, None, ['192.168.102.11'], None, 'linux', nodePassword, nodeUsername)\n        #node2 = ScaleIO_Node_Object(None, None, ['192.168.102.12'], None, 'linux', nodePassword, nodeUsername)\n        #node3 = ScaleIO_Node_Object(None, None, ['192.168.102.13'], None, 'linux', nodePassword, nodeUsername)\n        node1 = ScaleIO_Node_Object(None, None, ['192.168.100.101'], None, 'linux', nodePassword, nodeUsername)\n        node2 = ScaleIO_Node_Object(None, None, ['192.168.100.102'], None, 'linux', nodePassword, nodeUsername)\n        node3 = ScaleIO_Node_Object(None, None, ['192.168.100.103'], None, 'linux', nodePassword, nodeUsername)\n        print \"Node Object:\"\n        pprint (node1.to_JSON())\n        pprint (node2.to_JSON())\n        pprint (node2.to_JSON())\n        print \"\"\n            \n        ##########################################\n        # Construct basic info for System_Object #\n        ##########################################\n        mdmIPs = ['192.168.100.101','192.168.100.102']\n        sdcList = []\n        sdsList = []\n        #mdmPassword = 'Scaleio123'\n        #liaPassword = 'Scaleio123'\n        licenseKey = None\n        installationId = None\n     \n        ########################################\n        # Create MDMs and TB for System_Object #\n        ########################################\n        primaryMdm = Mdm_Object(json.loads(node2.to_JSON()), None, None, node2.nodeIPs) # WHY ISNT ManagementIPs pupulated???? Its not in a working config either. mdmIPs need to be populated though\n        secondaryMdm = Mdm_Object(json.loads(node3.to_JSON()), None, None, node3.nodeIPs)\n        tb = Tb_Object(json.loads(node1.to_JSON()), None, node1.nodeIPs)\n        callHomeConfiguration = None # {'callHomeConfiguration':'None'}\n        remoteSyslogConfiguration = None # {'remoteSysogConfiguration':'None'}\n        \n        ################################################################\n        #Create SDS objects - To be added to SDS list in System_Object #\n        ################################################################\n        sds1 = Sds_Object(json.loads(node1.to_JSON()), None, 'SDS_' + str(node1.nodeIPs[0]), 'default', None, node1.nodeIPs, None, None, None, False, '7072')\n        sds1.addDevice(\"/dev/sdb\", None, None)\n        sds2 = Sds_Object(json.loads(node2.to_JSON()), None, 'SDS_' + str(node2.nodeIPs[0]), 'default', None, node2.nodeIPs, None, None, None, False, '7072')\n        sds2.addDevice(\"/dev/sdb\", None, None)\n        sds3 = Sds_Object(json.loads(node3.to_JSON()), None, 'SDS_' + str(node3.nodeIPs[0]), 'default', None, node3.nodeIPs, None, None, None, False, '7072')\n        sds3.addDevice(\"/dev/sdb\", None, None)\n        sdsList.append(json.loads(sds1.to_JSON()))\n        sdsList.append(json.loads(sds2.to_JSON()))\n        sdsList.append(json.loads(sds3.to_JSON()))\n        print \"sdsList:\"\n        pprint (sdsList)\n    \n        #############################################################\n        # Create SDC objects - To be added as list to System_Object #\n        #############################################################\n        \"\"\"\n        node=None,\n        nodeInfo=None,\n        splitterRpaIp=None\n        \"\"\"\n        sdc1 = Sdc_Object(json.loads(node1.to_JSON()), None, None)\n        sdc2 = Sdc_Object(json.loads(node2.to_JSON()), None, None)\n        sdc3 = Sdc_Object(json.loads(node3.to_JSON()), None, None)\n        \n        sdcList.append(json.loads(sdc1.to_JSON()))\n        sdcList.append(json.loads(sdc2.to_JSON()))\n        sdcList.append(json.loads(sdc3.to_JSON()))\n        \n        ######################################################\n        # Construct a complete ScaleIO cluster configuration #\n        ######################################################\n        sioobj = ScaleIO_System_Object(installationId,\n                                       mdmIPs,\n                                       mdmPassword,\n                                       liaPassword,\n                                       licenseKey,\n                                       json.loads(primaryMdm.to_JSON()),\n                                       json.loads(secondaryMdm.to_JSON()),\n                                       json.loads(tb.to_JSON()),\n                                       sdsList,\n                                       sdcList,\n                                       callHomeConfiguration,\n                                       remoteSyslogConfiguration\n                                       )\n    \n        # Export sioobj to JSON (should upload clean in IM)\n        \n\n        ###########################################################################\n        # Push System_Object JSON - To be used by IM to install ScaleIO on nodes #\n        ###########################################################################\n        #pprint (sioobj.to_JSON())\n        self._cluster_config_cached = sioobj.to_JSON() # PUSH CONFIGURATION INTO CONFIGURATION CACHE\n        self._cache_contains_uncommitted= False # New config pushed into cache - Nothing oncommitted\n        self.push_cluster_configuration(self._cluster_config_cached)", "response": "This method creates a minimal ScaleIO cluster with 2xMDM 1xTB 3x SDS and 3x SDS with 2xTB 3x SDS with 2xTB 3x MDM 1xTB 3x SDS with 2xTB 3x SDS with 2xTB 3x SDS with 2xTB 3x MDM 1xTB 3x SDS"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_cluster_configuration(self, scaleioobj, noUpload = False, noInstall= False, noConfigure = False):\n        self.logger.debug(\"push_cluster_configuration(\" + \"{},{},{},{})\".format(scaleioobj, noUpload, noInstall, noConfigure))\n        #print \"JSON DUMP OF CLUSTER CONFIG:\"\n        #pprint (json.loads(scaleioobj))\n        config_params = {'noUpload': noUpload, 'noInstall': noInstall, 'noConfigure':noConfigure}\n\n        r1 = self._im_session.post(\n            \"{}/{}\".format(self._im_api_url,\"types/Installation/instances/\"),\n            headers={'Content-type':'application/json','Version':'1.0'},\n            params = config_params, \n            verify=self._im_verify_ssl,\n            #json=json.loads(self._cluster_config_cached.to_JSON()),\n            json = json.loads(scaleioobj),\n            stream=True\n        )\n        if not r1.ok:\n            # Something went wrong\n            self.logger.error(\"Error push_cluster_configuration() - \" + \"Errorcode: {}\".format(r1.status_code))\n        \n        #print \"Response after push_cluster_configuration()\"\n        \n        # RESPONSE NEED TO BE WRAPPED IN try/catch. Cannot assume JSON is returned.\n        #print r1.text\n        #pprint (json.loads(r1.text))\n        return r1.text", "response": "Method push cluster configuration to IM"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupload all the files in the specified directory to the IM.", "response": "def uploadPackages(self, directory):        \n        \"\"\"\n        Not working. Am not able ot figure out how to upload. IT return status 200OK with this code but do not store the files.\n        In tomcat.log (IM) there?s a complaint about character encoding whn uploading file. Not sure how to rectiy it in requests post call though\n        \"\"\"\n        files_to_upload_dict = {}\n        files_to_upload_list = [ f for f in listdir(directory) if isfile(join(directory,f)) ]\n        self.logger.debug(\"uploadPackages(\" + \"{})\".format(directory))\n        #print \"Files to upload:\"\n        for index in range(len(files_to_upload_list)):\n            self.logger.info(files_to_upload_list[index])\n            self.uploadFileToIM (directory, files_to_upload_list[index], files_to_upload_list[index])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uploadFileToIM (self, directory, filename, title):\n        self.logger.debug(\"uploadFileToIM(\" + \"{},{},{})\".format(directory, filename, title))\n        parameters = {'data-filename-placement':'inside',\n                      'title':str(filename),\n                      'filename':str(filename),\n                      'type':'file',\n                      'name':'files',\n                      'id':'fileToUpload',\n                      'multiple':''\n                      }\n        file_dict = {'files':(str(filename), open(directory + filename, 'rb'), 'application/x-rpm')}\n        m = MultipartEncoder(fields=file_dict)\n        \n        temp_username = self._username\n        temp_password = self._password\n        temp_im_api_url = self._im_api_url\n        temp_im_session = requests.Session()\n        temp_im_session.mount('https://', TLS1Adapter())\n        temp_im_verify_ssl = self._im_verify_ssl\n\n        resp = temp_im_session.post(\n            \"{}/{}\".format(temp_im_api_url,\"types/InstallationPackage/instances/uploadPackage\"),\n            auth=HTTPBasicAuth(temp_username, temp_password),\n            #headers = m.content_type,\n            files = file_dict,\n            verify = False,\n            data = parameters\n            )\n        self.logger.info(\"Uploaded: \" + \"{}\".format(filename))\n        self.logger.debug(\"HTTP Response: \" + \"{}\".format(resp.status_code))", "response": "Uploads a file to an IM and returns the ID of the newly uploaded file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uploadCsvConfiguration(self, conf_filename):\n        parameters = {'selectInstallOrExtend':'install', #'install' or 'extend'\n                      'name':'file',\n                      'id':'fileToUpload',\n                      'filename':'config.csv'\n                      }\n        file_dict = {'file':('config.csv', open(conf_filename, 'rb'), 'text/csv')}\n        \"\"\"\n        files = {'file': ('report.csv', 'some,data,to,send\\nanother,row,to,send\\n')}\n        \"\"\"\n        \n        temp_username = self._username\n        temp_password = self._password\n        temp_im_api_url = self._im_api_url\n        temp_im_session = requests.Session()\n        #self._im_session.headers.update({'Accept': 'application/json', 'Version': '1.0'}) # Accept only json\n        temp_im_session.mount('https://', TLS1Adapter())\n        temp_im_verify_ssl = self._im_verify_ssl\n\n\n        resp = temp_im_session.post(\n        #resp = self._do_post(\n            \"{}/{}\".format(temp_im_api_url,\"types/Configuration/instances/actions/parseFromCSV\"),\n            auth=HTTPBasicAuth('admin', 'Password1!'),\n            #headers = m.content_type,\n            files = file_dict,\n            verify = False,\n            data = parameters\n            )", "response": "This method uploads a CSV file to IM."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def dump_varint(writer, val):\n    if val <= 63:\n        return await dump_varint_t(writer, PortableRawSizeMark.BYTE, val)\n    elif val <= 16383:\n        return await dump_varint_t(writer, PortableRawSizeMark.WORD, val)\n    elif val <= 1073741823:\n        return await dump_varint_t(writer, PortableRawSizeMark.DWORD, val)\n    else:\n        if val > 4611686018427387903:\n            raise ValueError('Int too big')\n        return await dump_varint_t(writer, PortableRawSizeMark.INT64, val)", "response": "Binary dump of the variable size integer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping a binary string to the writer.", "response": "async def dump_string(writer, val):\n    \"\"\"\n    Binary string dump\n\n    :param writer:\n    :param val:\n    :return:\n    \"\"\"\n    await dump_varint(writer, len(val))\n    await writer.awrite(val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def load_string(reader):\n    ivalue = await load_varint(reader)\n    fvalue = bytearray(ivalue)\n    await reader.areadinto(fvalue)\n    return bytes(fvalue)", "response": "Loads a string from binary stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def dump_blob(writer, elem, elem_type, params=None):\n    elem_is_blob = isinstance(elem, x.BlobType)\n    data = bytes(getattr(elem, x.BlobType.DATA_ATTR) if elem_is_blob else elem)\n    await dump_varint(writer, len(elem))\n    await writer.awrite(data)", "response": "Dumps blob to a binary stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload blob from reader to the element. Returns the loaded blob.", "response": "async def load_blob(reader, elem_type, params=None, elem=None):\n    \"\"\"\n    Loads blob from reader to the element. Returns the loaded blob.\n\n    :param reader:\n    :param elem_type:\n    :param params:\n    :param elem:\n    :return:\n    \"\"\"\n    ivalue = await load_varint(reader)\n    fvalue = bytearray(ivalue)\n    await reader.areadinto(fvalue)\n\n    if elem is None:\n        return fvalue  # array by default\n\n    elif isinstance(elem, x.BlobType):\n        setattr(elem, elem_type.DATA_ATTR, fvalue)\n        return elem\n\n    else:\n        elem.extend(fvalue)\n\n    return elem"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def root(self):\n        if self.writing:\n            await x.dump_uint(self.iobj, PortableStorageConsts.SIGNATUREA, 4)\n            await x.dump_uint(self.iobj, PortableStorageConsts.SIGNATUREB, 4)\n            await x.dump_uint(self.iobj, PortableStorageConsts.FORMAT_VER, 1)\n\n        else:\n            sig_a = await x.load_uint(self.iobj, 4)\n            sig_b = await x.load_uint(self.iobj, 4)\n            ver = await x.load_uint(self.iobj, 1)\n\n            if sig_a != PortableStorageConsts.SIGNATUREA:\n                raise ValueError('Signature A error')\n            if sig_b != PortableStorageConsts.SIGNATUREB:\n                raise ValueError('Signature A error')\n            if ver != PortableStorageConsts.FORMAT_VER:\n                raise ValueError('Unsupported version')", "response": "Get the root level of the at least one element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a section in the file.", "response": "async def section(self, sec=None):\n        \"\"\"\n        Section / dict serialization\n        :return:\n        \"\"\"\n        if self.writing:\n            await dump_varint(self.iobj, len(sec))\n            for key in sec:\n                await self.section_name(key)\n                await self.storage_entry(sec[key])\n\n        else:\n            sec = {} if sec is None else sec\n\n            count = await load_varint(self.iobj)\n            for idx in range(count):\n                sec_name = await self.section_name()\n                val = await self.storage_entry()\n                sec[sec_name] = val\n\n            return sec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the section name.", "response": "async def section_name(self, sec_name=None):\n        \"\"\"\n        Section name\n        :param sec_name:\n        :return:\n        \"\"\"\n        if self.writing:\n            fvalue = sec_name.encode('ascii')\n            await x.dump_uint(self.iobj, len(fvalue), 1)\n            await self.iobj.awrite(bytearray(fvalue))\n\n        else:\n            ivalue = await x.load_uint(self.iobj, 1)\n            fvalue = bytearray(ivalue)\n            await self.iobj.areadinto(fvalue)\n            return bytes(fvalue).decode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def uvarint(self, elem):\n        if self.writing:\n            return await dump_varint(self.iobj, elem)\n        else:\n            return await load_varint(self.iobj)", "response": "Uvarint untouched\n        :param elem:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread an integer from the cache or writes it to the cache if writing is True.", "response": "async def uint(self, elem, elem_type, params=None):\n        \"\"\"\n        Integer types\n        :param elem:\n        :param elem_type:\n        :param params:\n        :return:\n        \"\"\"\n        if self.writing:\n            return await x.dump_uint(self.iobj, elem, elem_type.WIDTH)\n        else:\n            return await x.load_uint(self.iobj, elem_type.WIDTH)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def unicode_type(self, elem):\n        if self.writing:\n            return await x.dump_unicode(self.iobj, elem)\n        else:\n            return await x.load_unicode(self.iobj)", "response": "Unicode type\n        :param elem:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def blob(self, elem=None, elem_type=None, params=None):\n        elem_type = elem_type if elem_type else elem.__class__\n        if hasattr(elem_type, 'blob_serialize'):\n            elem = elem_type() if elem is None else elem\n            return await elem.blob_serialize(self, elem=elem, elem_type=elem_type, params=params)\n\n        if self.writing:\n            return await x.dump_blob(self.iobj, elem=elem, elem_type=elem_type, params=params)\n        else:\n            return await x.load_blob(self.iobj, elem_type=elem_type, params=params, elem=elem)", "response": "Load and dump a blob from the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading or dump a container.", "response": "async def container(self, container=None, container_type=None, params=None):\n        \"\"\"\n        Loads/dumps container\n        :return:\n        \"\"\"\n        if hasattr(container_type, 'blob_serialize'):\n            container = container_type() if container is None else container\n            return await container.blob_serialize(self, elem=container, elem_type=container_type, params=params)\n\n        # Container entry version + container\n        if self.writing:\n            return await self.container_dump(container, container_type, params)\n        else:\n            return await self.container_load(container_type, params=params, container=container)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the size of the element after blob serialization.", "response": "async def get_element_size(self, elem_type, elem=None, params=None):\n        \"\"\"\n        Determines element size after blob serialization.\n        Can be quite tricky for complicated structures - another object required to implement sizeof()\n\n        :param elem_type:\n        :param elem:\n        :param params:\n        :return:\n        \"\"\"\n        if hasattr(elem_type, 'blob_size'):\n            elem = elem_type() if elem is None else elem\n            return await elem.blob_size(self)\n\n        if issubclass(elem_type, x.UVarintType):\n            raise helpers.ArchiveException('Unknown size for varint')\n\n        elif issubclass(elem_type, x.IntType):\n            return elem_type.WIDTH\n\n        elif issubclass(elem_type, x.BlobType):\n            if elem is not None:\n                return len(elem)\n            if not elem_type.FIX_SIZE:\n                raise helpers.ArchiveException('Unknown size for blob')\n            return elem_type.SIZE\n\n        elif issubclass(elem_type, x.UnicodeType):\n            raise helpers.ArchiveException('Unknown size for string')\n\n        elif issubclass(elem_type, x.VariantType):\n            raise helpers.ArchiveException('Unknown size for variant')\n\n        elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n            celem_type = x.container_elem_type(elem_type, params)\n            if elem is not None:\n                return len(elem) * await self.get_element_size(elem_type=celem_type, elem=elem[0] if len(elem) > 0 else None)\n            if not elem_type.FIX_SIZE:\n                raise helpers.ArchiveException('Unknown size for container')\n            return elem_type.SIZE * await self.get_element_size(elem_type=celem_type)\n\n        elif issubclass(elem_type, x.TupleType):  # tuple ~ simple list\n            acc = 0\n            for t in elem_type.f_specs():\n                acc += await self.get_element_size(t)\n            return acc\n\n        elif issubclass(elem_type, x.MessageType):\n            acc = 0\n            for t in elem_type.f_specs():\n                acc += await self.get_element_size(t[1], params=t[2:])\n            return acc\n\n        else:\n            raise TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def container_load(self, container_type, params=None, container=None, obj=None):\n        elem_type = x.container_elem_type(container_type, params)\n        elem_size = await self.get_element_size(elem_type=elem_type, params=params)\n\n        # If container is of fixed size we know the size to load from the input.\n        # Otherwise we have to read to the end\n        data_left = len(self.iobj.buffer)\n        c_len = container_type.SIZE\n        if not container_type.FIX_SIZE:\n            if data_left == 0:\n                return None\n            if data_left % elem_size != 0:\n                raise helpers.ArchiveException('Container size mod elem size not 0')\n            c_len = data_left // elem_size\n\n        res = container if container else []\n        for i in range(c_len):\n            try:\n                self.tracker.push_index(i)\n                fvalue = await self._load_field(elem_type,\n                                                params[1:] if params else None,\n                                                x.eref(res, i) if container else None)\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if not container:\n                res.append(fvalue)\n        return res", "response": "Loads the container of elements from the reader. Supports the container ref. Returns loaded container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload and dump a tuple.", "response": "async def tuple(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Loads/dumps tuple\n        :return:\n        \"\"\"\n        if hasattr(elem_type, 'blob_serialize'):\n            container = elem_type() if elem is None else elem\n            return await container.blob_serialize(self, elem=elem, elem_type=elem_type, params=params)\n\n        if self.writing:\n            return await self.dump_tuple(elem, elem_type, params)\n        else:\n            return await self.load_tuple(elem_type, params=params, elem=elem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads and dump a single variant from the cache.", "response": "async def variant(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Loads/dumps variant type\n        :param elem:\n        :param elem_type:\n        :param params:\n        :param obj:\n        :return:\n        \"\"\"\n        elem_type = elem_type if elem_type else elem.__class__\n\n        if hasattr(elem_type, 'blob_serialize'):\n            elem = elem_type() if elem is None else elem\n            return await elem.bob_serialize(self, elem=elem, elem_type=elem_type, params=params)\n\n        if self.writing:\n            return await self.dump_variant(elem=elem,\n                                           elem_type=elem_type if elem_type else elem.__class__, params=params)\n        else:\n            return await self.load_variant(elem_type=elem_type if elem_type else elem.__class__,\n                                           params=params, elem=elem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads and dumps a message.", "response": "async def message(self, msg, msg_type=None):\n        \"\"\"\n        Loads/dumps message\n        :param msg:\n        :param msg_type:\n        :param obj:\n        :return:\n        \"\"\"\n        elem_type = msg_type if msg_type is not None else msg.__class__\n\n        if hasattr(elem_type, 'blob_serialize'):\n            msg = elem_type() if msg is None else msg\n            return await msg.blob_serialize(self)\n\n        fields = elem_type.f_specs()\n        for field in fields:\n            await self.message_field(msg=msg, field=field)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping and loads a message field.", "response": "async def message_field(self, msg, field, fvalue=None, obj=None):\n        \"\"\"\n        Dumps/Loads message field\n        :param msg:\n        :param field:\n        :param fvalue: explicit value for dump\n        :param obj:\n        :return:\n        \"\"\"\n        fname, ftype, params = field[0], field[1], field[2:]\n        try:\n            self.tracker.push_field(fname)\n            if self.writing:\n                fvalue = getattr(msg, fname, None) if fvalue is None else fvalue\n                await self._dump_field(fvalue, ftype, params)\n\n            else:\n                await self._load_field(ftype, params, x.eref(msg, fname))\n\n            self.tracker.pop()\n\n        except Exception as e:\n            raise helpers.ArchiveException(e, tracker=self.tracker) from e"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def message_fields(self, msg, fields, obj=None):\n        for field in fields:\n            await self.message_field(msg, field, obj)\n        return msg", "response": "Load and dump individual message fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def field(self, elem=None, elem_type=None, params=None):\n        elem_type = elem_type if elem_type else elem.__class__\n        fvalue = None\n\n        src = elem\n        if issubclass(elem_type, x.UVarintType):\n            fvalue = await self.uvarint(x.get_elem(src))\n\n        elif issubclass(elem_type, x.IntType):\n            fvalue = await self.uint(elem=x.get_elem(src), elem_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.BlobType):\n            fvalue = await self.blob(elem=x.get_elem(src), elem_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.UnicodeType):\n            fvalue = await self.unicode_type(x.get_elem(src))\n\n        elif issubclass(elem_type, x.VariantType):\n            fvalue = await self.variant(elem=x.get_elem(src), elem_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n            fvalue = await self.container(container=x.get_elem(src), container_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.TupleType):  # tuple ~ simple list\n            fvalue = await self.tuple(elem=x.get_elem(src), elem_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.MessageType):\n            fvalue = await self.message(x.get_elem(src), msg_type=elem_type)\n\n        else:\n            raise TypeError\n\n        return fvalue if self.writing else x.set_elem(elem, fvalue)", "response": "Get the archive field."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the blob of the object.", "response": "async def blobize(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Main blobbing\n        :param elem:\n        :param elem_type:\n        :param params:\n        :return:\n        \"\"\"\n        if self.writing:\n            await self.field(elem=elem, elem_type=elem_type, params=params)\n            return bytes(self.iobj.buffer)\n        else:\n            return await self.field(elem=elem, elem_type=elem_type, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value of an integer attribute.", "response": "async def uint(self, elem, elem_type, params=None):\n        \"\"\"\n        Integer types\n        :param elem:\n        :param elem_type:\n        :param params:\n        :return:\n        \"\"\"\n        if self.writing:\n            return IntegerModel(elem, elem_type.WIDTH) if self.modelize else elem\n        else:\n            return elem.val if isinstance(elem, IModel) else elem"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload and dumps a blob.", "response": "async def blob(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Loads/dumps blob\n        :return:\n        \"\"\"\n        elem_type = elem_type if elem_type else elem.__class__\n        if hasattr(elem_type, 'kv_serialize'):\n            elem = elem_type() if elem is None else elem\n            return await elem.kv_serialize(self, elem=elem, elem_type=elem_type, params=params)\n\n        if self.writing:\n            elem_is_blob = isinstance(elem, x.BlobType)\n            data = getattr(elem, x.BlobType.DATA_ATTR) if elem_is_blob else elem\n            if data is None:\n                return NoSetSentinel()\n            if len(data) == 0:\n                return b''\n\n            fval = Modeler.to_bytes(data)\n            if self.hexlify:\n                return binascii.hexlify(fval).decode('ascii')\n            else:\n                return fval\n\n        else:\n            if elem is None:\n                return NoSetSentinel()\n            if self.hexlify:\n                return bytes(binascii.unhexlify(elem))\n            else:\n                return bytes(elem)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload or dump a container.", "response": "async def container(self, container=None, container_type=None, params=None, obj=None):\n        \"\"\"\n        Loads/dumps container\n        :return:\n        \"\"\"\n        if hasattr(container_type, 'kv_serialize'):\n            container = container_type() if container is None else container\n            return await container.kv_serialize(self, elem=container, elem_type=container_type, params=params, obj=obj)\n\n        # Container entry version + container\n        if self.writing:\n            return await self.container_dump(container, container_type, params, obj=obj)\n        else:\n            return await self.container_load(container_type, params=params, container=container, obj=obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping a container of elements to the writer.", "response": "async def container_dump(self, container, container_type, params=None, obj=None):\n        \"\"\"\n        Dumps container of elements to the writer.\n\n        :param container:\n        :param container_type:\n        :param params:\n        :param obj:\n        :return:\n        \"\"\"\n        elem_type = x.container_elem_type(container_type, params)\n        obj = [] if not x.has_elem(obj) else x.get_elem(obj)\n\n        # todo: pod container, just concat blobs / serialized content together. loading = size / elem size...\n        if container is None:  # todo: reconsider\n            return NoSetSentinel()  # if not self.modelize else ArrayModel(obj, xmr_type_to_type(elem_type))\n\n        for idx, elem in enumerate(container):\n            try:\n                self.tracker.push_index(idx)\n                fvalue = await self._dump_field(elem, elem_type, params[1:] if params else None)\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if not isinstance(fvalue, NoSetSentinel):\n                obj.append(fvalue)\n\n        return obj if not self.modelize else ArrayModel(obj, xmr_type_to_type(elem_type))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def container_load(self, container_type, params=None, container=None, obj=None):\n        if isinstance(obj, IModel):\n            obj = obj.val\n\n        if obj is None:\n            return NoSetSentinel()\n\n        c_len = len(obj)\n        elem_type = params[0] if params else None\n        if elem_type is None:\n            elem_type = container_type.ELEM_TYPE\n\n        res = container if container else []\n        for i in range(c_len):\n            try:\n                self.tracker.push_index(i)\n                fvalue = await self._load_field(elem_type,\n                                                params[1:] if params else None,\n                                                x.eref(res, i) if container else None, obj=obj[i])\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if not container and not isinstance(fvalue, NoSetSentinel):\n                res.append(fvalue)\n\n        return res", "response": "Loads a container of elements from the reader. Supports the container ref. Returns loaded container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def tuple(self, elem=None, elem_type=None, params=None, obj=None):\n        if hasattr(elem_type, 'kv_serialize'):\n            container = elem_type() if elem is None else elem\n            return await container.kv_serialize(self, elem=elem, elem_type=elem_type, params=params, obj=obj)\n\n        # TODO: if modeled return as 0=>, 1=>, ...\n        if self.writing:\n            return await self.dump_tuple(elem, elem_type, params, obj=obj)\n        else:\n            return await self.load_tuple(elem_type, params=params, elem=elem, obj=obj)", "response": "Load and dump a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump a tuple of elements to the writer.", "response": "async def dump_tuple(self, elem, elem_type, params=None, obj=None):\n        \"\"\"\n        Dumps tuple of elements to the writer.\n\n        :param elem:\n        :param elem_type:\n        :param params:\n        :param obj:\n        :return:\n        \"\"\"\n        if len(elem) != len(elem_type.f_specs()):\n            raise ValueError('Fixed size tuple has not defined size: %s' % len(elem_type.f_specs()))\n\n        elem_fields = params[0] if params else None\n        if elem_fields is None:\n            elem_fields = elem_type.f_specs()\n\n        obj = [] if obj is None else x.get_elem(obj)\n        for idx, elem in enumerate(elem):\n            try:\n                self.tracker.push_index(idx)\n                fvalue = await self._dump_field(elem, elem_fields[idx], params[1:] if params else None)\n                obj.append(fvalue)\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def load_tuple(self, elem_type, params=None, elem=None, obj=None):\n        if obj is None:\n            return None\n\n        elem_fields = params[0] if params else None\n        if elem_fields is None:\n            elem_fields = elem_type.f_specs()\n\n        c_len = len(obj)\n        if len(elem_fields) != c_len:\n            raise ValueError('Size mismatch')\n\n        res = elem if elem else []\n        for i in range(len(elem_fields)):\n            try:\n                self.tracker.push_index(i)\n                fvalue = await self._load_field(params[1:] if params else None,\n                                                x.eref(res, i) if elem else None,\n                                                obj=obj[i])\n                self.tracker.pop()\n\n                if not elem:\n                    res.append(fvalue)\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n        return res", "response": "Loads a tuple of elements from the reader. Supports the tuple ref."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def variant(self, elem=None, elem_type=None, params=None, obj=None):\n        elem_type = elem_type if elem_type else elem.__class__\n\n        if hasattr(elem_type, 'kv_serialize'):\n            elem = elem_type() if elem is None else elem\n            return await elem.kv_serialize(self, elem=elem, elem_type=elem_type, params=params, obj=obj)\n\n        if self.writing:\n            return await self.dump_variant(elem=elem,\n                                           elem_type=elem_type if elem_type else elem.__class__, params=params, obj=obj)\n        else:\n            return await self.load_variant(elem_type=elem_type if elem_type else elem.__class__,\n                                           params=params, elem=elem, obj=obj)", "response": "Load or dump a single Variant from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def dump_variant(self, elem, elem_type=None, params=None, obj=None):\n        fvalue = None\n        if isinstance(elem, x.VariantType) or elem_type.WRAPS_VALUE:\n            try:\n                self.tracker.push_variant(elem.variant_elem_type)\n                fvalue = {\n                    elem.variant_elem: await self._dump_field(getattr(elem, elem.variant_elem), elem.variant_elem_type, obj=obj)\n                }\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n        else:\n            try:\n                fdef = elem_type.find_fdef(elem_type.f_specs(), elem)\n                self.tracker.push_variant(fdef[1])\n                fvalue = {\n                    fdef[0]: await self._dump_field(elem, fdef[1], obj=obj)\n                }\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n        return fvalue", "response": "Dumps a single variant to the writer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a single variant from the reader.", "response": "async def load_variant(self, elem_type, params=None, elem=None, wrapped=None, obj=None):\n        \"\"\"\n        Loads variant type from the reader.\n        Supports both wrapped and raw variant.\n\n        :param elem_type:\n        :param params:\n        :param elem:\n        :param wrapped:\n        :param obj:\n        :return:\n        \"\"\"\n        is_wrapped = elem_type.WRAPS_VALUE if wrapped is None else wrapped\n\n        if is_wrapped:\n            elem = elem_type() if elem is None else elem\n\n        fname = list(obj.keys())[0]\n        for field in elem_type.f_specs():\n            if field[0] != fname:\n                continue\n\n            try:\n                self.tracker.push_variant(field[1])\n                fvalue = await self._load_field(field[1], field[2:], elem if not is_wrapped else None, obj=obj[fname])\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if is_wrapped:\n                elem.set_variant(field[0], fvalue)\n\n            return elem if is_wrapped else fvalue\n        raise ValueError('Unknown tag: %s' % fname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads and dumps a message.", "response": "async def message(self, msg, msg_type=None, obj=None):\n        \"\"\"\n        Loads/dumps message\n        :param msg:\n        :param msg_type:\n        :param obj:\n        :return:\n        \"\"\"\n        elem_type = msg_type if msg_type is not None else msg.__class__\n        obj = collections.OrderedDict() if not x.has_elem(obj) else x.get_elem(obj)\n\n        if hasattr(elem_type, 'kv_serialize'):\n            msg = elem_type() if msg is None else msg\n            return await msg.kv_serialize(self, obj=obj)\n\n        fields = elem_type.f_specs()\n        for field in fields:\n            await self.message_field(msg=msg, field=field, obj=obj)\n\n        return obj if self.writing else msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the archive field.", "response": "async def field(self, elem=None, elem_type=None, params=None, obj=None):\n        \"\"\"\n        Archive field\n        :param elem:\n        :param elem_type:\n        :param params:\n        :param obj:\n        :return:\n        \"\"\"\n        elem_type = elem_type if elem_type else elem.__class__\n        fvalue = None\n\n        src = elem if self.writing else obj\n        dst = obj if self.writing else elem\n\n        # TODO: optional elem, default value for deserialization...\n\n        # Blob wrapper. Underlying structure should be serialized as blob.\n        if x.is_type(elem_type, BlobFieldWrapper):\n            blobber = Blobber(self.writing, data=x.get_elem(src) if not self.writing else None)\n            fvalue = await blobber.blobize(elem=x.get_elem(src), elem_type=elem_type.ftype, params=params)\n            fvalue = NoSetSentinel() if fvalue is None or len(fvalue) == 0 else fvalue\n\n        elif issubclass(elem_type, x.UVarintType):\n            fvalue = await self.uvarint(x.get_elem(src))\n\n        elif issubclass(elem_type, x.IntType):\n            fvalue = await self.uint(elem=x.get_elem(src), elem_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.BlobType):\n            fvalue = await self.blob(elem=x.get_elem(src), elem_type=elem_type, params=params)\n\n        elif issubclass(elem_type, x.UnicodeType):\n            fvalue = await self.unicode_type(x.get_elem(src))\n\n        elif issubclass(elem_type, x.VariantType):\n            fvalue = await self.variant(elem=x.get_elem(src), elem_type=elem_type, params=params, obj=dst)\n\n        elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n            fvalue = await self.container(container=x.get_elem(src), container_type=elem_type, params=params, obj=dst)\n\n        elif issubclass(elem_type, x.TupleType):  # tuple ~ simple list\n            fvalue = await self.tuple(elem=x.get_elem(src), elem_type=elem_type, params=params, obj=dst)\n\n        elif issubclass(elem_type, x.MessageType):\n            fvalue = await self.message(x.get_elem(src), msg_type=elem_type, obj=dst)\n\n        else:\n            raise TypeError\n\n        return x.set_elem(dst, fvalue) if not isinstance(fvalue, NoSetSentinel) else fvalue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_valid_volsize(self,volsize):\n        \n        if type(volsize) is int:\n            size_temp = divmod(volsize, 8192)\n            if size_temp[1] > 0: # If not on 8GB boundary\n                return int((1 + size_temp[0]) * 8192) # Always round to next 8GB increment\n        else:\n            return int(volsize)", "response": "Checks if the given size is a valid ScaleIO Volume size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_volume(self, volObj, removeMode='ONLY_ME', **kwargs):\n        if kwargs:\n            for key, value in kwargs.iteritems():\n                if key =='autoUnmap' and value ==True:\n                    # Find all mapped SDS to this volObj\n                    # Call unmap for all of them\n                    if self.get_volume_all_sdcs_mapped(volObj):\n                        try:\n                            self.conn.cluster.unmap_volume_from_sdc(volObj, enableMapAllSdcs=False)\n                        except:\n                            raise RuntimeError(\"delete_volume() - enableMapAllSdcs error\")\n                    else: # All SDS not enabled so loop through all mapped SDCs of volume and remove one by one                        \n                        for sdc in self.get_sdc_for_volume(volObj):\n                            try:\n                                self.unmap_volume_from_sdc(volObj, self.get_sdc_by_id(sdc['sdcId']))\n                            except:\n                                raise RuntimeError(\"delete_volume() - unmap_volume_from_sdc() error\")\n        # TODO:\n        # Check if object parameters are the correct ones, otherwise throw error\n        self.conn.connection._check_login()\n        deleteVolumeDict = {'removeMode': removeMode}\n        try:\n            response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self.conn.connection._api_url, \"instances/Volume::\", volObj.id, 'action/removeVolume'), json=deleteVolumeDict)\n        except:\n            raise RuntimeError(\"delete_volume() - Communication error with ScaleIO Gateway\")\n        return response", "response": "Delete a volume from the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmap a Volume to a ScaleIO SDC", "response": "def map_volume_to_sdc(self, volumeObj, sdcObj=None, allowMultipleMappings=False, **kwargs):\n        \"\"\"\n        Map a Volume to SDC\n        :param volumeObj: ScaleIO Volume object\n        :param sdcObj: ScaleIO SDC object\n        :param allowMultipleMappings: True to allow more than one SDC to be mapped to volume\n        :return: POST request response\n        :rtype: Requests POST response object\n        \"\"\"\n        self.conn.connection._check_login()\n        if kwargs:\n            for key, value in kwargs.iteritems():\n                if key == 'enableMapAllSdcs':\n                    if value == True:\n                        mapVolumeToSdcDict = {'allSdcs': 'True'}\n        else:\n            mapVolumeToSdcDict = {'sdcId': sdcObj.id, 'allowMultipleMappings': str(allowMultipleMappings).upper()}\n        response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self._api_url, \"instances/Volume::\", volumeObj.id, 'action/addMappedSdc'), json=mapVolumeToSdcDict)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting ScaleIO Volume object by its ID", "response": "def get_volume_by_id(self, id):\n        \"\"\"\n        Get ScaleIO Volume object by its ID\n        :param name: ID of volume\n        :return: ScaleIO Volume object\n        :raise KeyError: No Volume with specified ID found\n        :rtype: ScaleIO Volume object\n        \"\"\"\n        for vol in self.conn.volumes:\n            if vol.id == id:\n                return vol\n        raise KeyError(\"Volume with ID \" + id + \" not found\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of ScaleIO Volume objects attached to a VTree.", "response": "def get_volumes_for_vtree(self, vtreeObj):\n        \"\"\"\n        :param vtreeObj: VTree object\n            Protection Domain Object\n        :return: list of Volumes attached to VTree\n        :rtype: ScaleIO Volume object\n        \"\"\"\n        self.conn.connection._check_login()\n        all_volumes = []\n        response = self._do_get(\"{}/{}{}/{}\".format(self.conn.connection._api_url, 'instances/VTree::', vtreeObj.id, 'relationships/Volume')).json()\n        for vtree_volume in response:\n            all_volumes.append(\n                Volume.from_dict(vtree_volume)\n            )\n        return all_volumes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget ScaleIO Volume object by its Name", "response": "def get_volume_by_name(self, name):\n        \"\"\"\n        Get ScaleIO Volume object by its Name\n        :param name: Name of volume\n        :return: ScaleIO Volume object\n        :raise KeyError: No Volume with specified name found\n        :rtype: ScaleIO Volume object\n        \"\"\"\n        for vol in self.conn.volumes:\n            if vol.name == name:\n                return vol\n        raise KeyError(\"Volume with NAME \" + name + \" not found\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate snapshot for list of volumes", "response": "def create_snapshot(self, systemId, snapshotSpecificationObject):\n        \"\"\"\n        Create snapshot for list of volumes\n        :param systemID: Cluster ID \n        :param snapshotSpecificationObject: Of class SnapshotSpecification\n        :rtype: SnapshotGroupId\n        \"\"\"\n        self.conn.connection._check_login()\n        #try:\n        response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self.conn.connection._api_url, \"instances/System::\", systemId, 'action/snapshotVolumes'), json=snapshotSpecificationObject.__to_dict__())\n        #except:\n        #    raise RuntimeError(\"create_snapshot_by_system_id() - Error communicating with ScaleIO gateway\")\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget list of SDC objects mapped to a specific volume", "response": "def get_sdc_for_volume(self, volObj):\n        \"\"\"\n        Get list of SDC mapped to a specific volume\n        :param volObj: ScaleIO volume object\n        :return: List of ScaleIO SDC objects (empty list if no mapping exist)\n        :rtype: SDC object\n        \"\"\"\n        sdcList = []\n        if volObj.mapped_sdcs is not None:\n            for sdc in volObj.mapped_sdcs:\n                sdcList.append(sdc)\n        if len(sdcList) == 0:\n            self.conn.logger.debug(\"No SDCs mapped to volume: %s-(%s)\" % (volObj.name, volObj.id))\n            return []\n        # returning an empty list is\n        # valid for snapshots or volumes.\n        return sdcList"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_index_for(package, index_dir, verbose=True):\n    index_template = \"\"\"\\\n<html>\n<head><title>{title}</title></head>\n<body>\n<h1>{title}</h1>\n<ul>\n{packages}\n</ul>\n</body>\n</html>\n\"\"\"\n    item_template = '<li><a href=\"{1}\">{0}</a></li>'\n    index_filename = os.path.join(index_dir, \"index.html\")\n    if not os.path.isdir(index_dir):\n        os.makedirs(index_dir)\n\n    parts = []\n    for pkg_filename in package.files:\n        pkg_name = os.path.basename(pkg_filename)\n        if pkg_name == \"index.html\":\n            # -- ROOT-INDEX:\n            pkg_name = os.path.basename(os.path.dirname(pkg_filename))\n        else:\n            pkg_name = package.splitext(pkg_name)\n        pkg_relpath_to = os.path.relpath(pkg_filename, index_dir)\n        parts.append(item_template.format(pkg_name, pkg_relpath_to))\n\n    if not parts:\n        print(\"OOPS: Package %s has no files\" % package.name)\n        return\n\n    if verbose:\n        root_index = not Package.isa(package.files[0])\n        if root_index:\n            info = \"with %d package(s)\" % len(package.files)\n        else:\n            package_versions = sorted(set(package.versions))\n            info = \", \".join(reversed(package_versions))\n        message = \"%-30s  %s\" % (package.name, info)\n        print(message)\n\n    with open(index_filename, \"w\") as f:\n        packages = \"\\n\".join(parts)\n        text = index_template.format(title=package.name, packages=packages)\n        f.write(text.strip())\n        f.close()", "response": "Create an index. html file for one package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_package_index(download_dir):\n    if not os.path.isdir(download_dir):\n        raise ValueError(\"No such directory: %r\" % download_dir)\n\n    pkg_rootdir = os.path.join(download_dir, \"simple\")\n    if os.path.isdir(pkg_rootdir):\n        shutil.rmtree(pkg_rootdir, ignore_errors=True)\n    os.mkdir(pkg_rootdir)\n\n    # -- STEP: Collect all packages.\n    package_map = {}\n    packages = []\n    for filename in sorted(os.listdir(download_dir)):\n        if not Package.isa(filename):\n            continue\n        pkg_filepath = os.path.join(download_dir, filename)\n        package_name = Package.get_pkgname(pkg_filepath)\n        package = package_map.get(package_name, None)\n        if not package:\n            # -- NEW PACKAGE DETECTED: Store/register package.\n            package = Package(pkg_filepath)\n            package_map[package.name] = package\n            packages.append(package)\n        else:\n            # -- SAME PACKAGE: Collect other variant/version.\n            package.files.append(pkg_filepath)\n\n    # -- STEP: Make local PYTHON PACKAGE INDEX.\n    root_package = Package(None, \"Python Package Index\")\n    root_package.files = [ os.path.join(pkg_rootdir, pkg.name, \"index.html\")\n                           for pkg in packages ]\n    make_index_for(root_package, pkg_rootdir)\n    for package in packages:\n        index_dir = os.path.join(pkg_rootdir, package.name)\n        make_index_for(package, index_dir)", "response": "Create a pypi server like file structure below download directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a value from other types if necessary.", "response": "def _convert_to_list(self, value, delimiters):\n        \"\"\"\n        Return a list value translating from other types if necessary.\n\n        :param str value:  The value to convert.\n        \"\"\"\n        if not value:\n            return []\n        if delimiters:\n            return [l.strip() for l in value.split(delimiters)]\n        return [l.strip() for l in value.split()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getlist(self, section, option, raw=False, vars=None, fallback=[], delimiters=','):\n        v = self.get(section, option, raw=raw, vars=vars, fallback=fallback)\n        return self._convert_to_list(v, delimiters=delimiters)", "response": "A convenience method which coerces the option in the specified section to a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getdir(self, section, option, raw=False, vars=None, fallback=\"\", validate=False):\n        v = self.get(section, option, raw=raw, vars=vars, fallback=fallback)\n        v = self._convert_to_path(v)\n        return v if not validate or os.path.isdir(v) else fallback", "response": "A convenience method which coerces the option in the specified section to a directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding ~configparser. ConfigParser. set by auto formatting byte strings into unicode strings.", "response": "def set(self, section, option, value=None):\n        \"\"\"\n        Extends :meth:`~configparser.ConfigParser.set` by auto formatting byte strings into unicode strings.\n        \"\"\"\n        if isinstance(section, bytes):\n            section = section.decode('utf8')\n\n        if isinstance(option, bytes):\n            option = option.decode('utf8')\n\n        if isinstance(value, bytes):\n            value = value.decode('utf8')\n\n        return super(VSGConfigParser, self).set(section, option, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the configuration with the values from the given kwargs.", "response": "def update(self, **kwargs):\n        \"\"\"\n        Extends :meth:`~configparser.ConfigParser.set` by auto formatting byte strings into unicode strings.\n        \"\"\"\n        # Override the template values with the override values.\n        for s in config.sections():\n            for o in config.options(s):\n                override = kwargs.pop(o, None)\n                if override:\n                    config.set(s, o, override)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, name, content, description=None):\n        return self.__app.documents.register(name, content, self._plugin, description)", "response": "Register a new document."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a new document.", "response": "def register(self, name, content, plugin, description=None):\n        \"\"\"\n        Registers a new document.\n\n        .. warning: You can not use any relative links inside a given document.\n                    For instance, sphinx's toctree, image, figure or include statements do not work.\n\n        :param content: Content of the document\n        :type content: str\n        :param name: Unique name of the document for documentation purposes.\n        :param plugin: Plugin object, under which the documents where registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if name in self.documents.keys():\n            raise DocumentExistsException(\"Document %s was already registered by %s\" %\n                                          (name, self.documents[name].plugin.name))\n\n        self.documents[name] = Document(name, content, plugin, description)\n        self.__log.debug(\"Document %s registered by %s\" % (name, plugin.name))\n        return self.documents[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregister(self, document):\n        if document not in self.documents.keys():\n            self.log.warning(\"Can not unregister document %s\" % document)\n        else:\n            del (self.documents[document])\n            self.__log.debug(\"Document %s got unregistered\" % document)", "response": "Unregisters an existing document so that it is no longer available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting one or more documents.", "response": "def get(self, document=None, plugin=None):\n        \"\"\"\n        Get one or more documents.\n\n        :param document: Name of the document\n        :type document: str\n        :param plugin: Plugin object, under which the document was registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if document is None:\n                documents_list = {}\n                for key in self.documents.keys():\n                    if self.documents[key].plugin == plugin:\n                        documents_list[key] = self.documents[key]\n                return documents_list\n            else:\n                if document in self.documents.keys():\n                    if self.documents[document].plugin == plugin:\n                        return self.documents[document]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if document is None:\n                return self.documents\n            else:\n                if document in self.documents.keys():\n                    return self.documents[document]\n                else:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitialises given plugins but does not activate them.", "response": "def initialise_by_names(self, plugins=None):\n        \"\"\"\n        Initialises given plugins, but does not activate them.\n\n        This is needed to import and configure libraries, which are imported by used patterns, like GwFlask.\n\n        After this action, all needed python modules are imported and configured.\n        Also the groundwork application object is ready and contains functions and objects, which were added\n        by patterns, like app.commands from GwCommandsPattern.\n\n        The class of a given plugin must already be registered in the :class:`.PluginClassManager`.\n\n        :param plugins: List of plugin names\n        :type plugins: list of strings\n        \"\"\"\n\n        if plugins is None:\n            plugins = []\n\n        self._log.debug(\"Plugins Initialisation started\")\n        if not isinstance(plugins, list):\n            raise AttributeError(\"plugins must be a list, not %s\" % type(plugins))\n\n        self._log.debug(\"Plugins to initialise: %s\" % \", \".join(plugins))\n        plugin_initialised = []\n        for plugin_name in plugins:\n            if not isinstance(plugin_name, str):\n                raise AttributeError(\"plugin name must be a str, not %s\" % type(plugin_name))\n\n            plugin_class = self.classes.get(plugin_name)\n            self.initialise(plugin_class.clazz, plugin_name)\n            plugin_initialised.append(plugin_name)\n\n        self._log.info(\"Plugins initialised: %s\" % \", \".join(plugin_initialised))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate(self, plugins=[]):\n        self._log.debug(\"Plugins Activation started\")\n\n        if not isinstance(plugins, list):\n            raise AttributeError(\"plugins must be a list, not %s\" % type(plugins))\n\n        self._log.debug(\"Plugins to activate: %s\" % \", \".join(plugins))\n\n        plugins_activated = []\n        for plugin_name in plugins:\n            if not isinstance(plugin_name, str):\n                raise AttributeError(\"plugin name must be a str, not %s\" % type(plugin_name))\n\n            if plugin_name not in self._plugins.keys() and plugin_name in self.classes._classes.keys():\n                self._log.debug(\"Initialisation needed before activation.\")\n                try:\n                    self.initialise_by_names([plugin_name])\n                except Exception as e:\n                    self._log.error(\"Couldn't initialise plugin %s. Reason %s\" % (plugin_name, e))\n                    if self._app.strict:\n                        error = \"Couldn't initialise plugin %s\" % plugin_name\n                        if sys.version_info[0] < 3:\n                            error += \"Reason: %s\" % e\n                        raise_from(Exception(error), e)\n                    else:\n                        continue\n            if plugin_name in self._plugins.keys():\n                self._log.debug(\"Activating plugin %s\" % plugin_name)\n                if not self._plugins[plugin_name].active:\n                    try:\n                        self._plugins[plugin_name].activate()\n                    except Exception as e:\n                        raise_from(\n                            PluginNotActivatableException(\"Plugin %s could not be activated: %s\" % (plugin_name,\n                                                                                                    e)), e)\n                    else:\n                        self._log.debug(\"Plugin %s activated\" % plugin_name)\n                        plugins_activated.append(plugin_name)\n                else:\n                    self._log.warning(\"Plugin %s got already activated.\" % plugin_name)\n                    if self._app.strict:\n                        raise PluginNotInitialisableException()\n\n        self._log.info(\"Plugins activated: %s\" % \", \".join(plugins_activated))", "response": "Activates given plugins.\n\n        This calls mainly plugin.activate() and plugins register needed resources like commands, signals or\n        documents.\n\n        If given plugins have not been initialised, this is also done via :func:`_load`.\n\n        :param plugins: List of plugin names\n        :type plugins: list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeactivating given plugins. A given plugin must be activated, otherwise it is ignored and no action takes place (no signals are fired, no deactivate functions are called.) A deactivated plugin is still loaded and initialised and can be reactivated by calling :func:`activate` again. It is also still registered in the :class:`.PluginManager` and can be requested via :func:`get`. :param plugins: List of plugin names :type plugins: list of strings", "response": "def deactivate(self, plugins=[]):\n        \"\"\"\n        Deactivates given plugins.\n\n        A given plugin must be activated, otherwise it is ignored and no action takes place (no signals are fired,\n        no deactivate functions are called.)\n\n        A deactivated plugin is still loaded and initialised and can be reactivated by calling :func:`activate` again.\n        It is also still registered in the :class:`.PluginManager` and can be requested via :func:`get`.\n\n        :param plugins: List of plugin names\n        :type plugins: list of strings\n        \"\"\"\n        self._log.debug(\"Plugins Deactivation started\")\n\n        if not isinstance(plugins, list):\n            raise AttributeError(\"plugins must be a list, not %s\" % type(plugins))\n\n        self._log.debug(\"Plugins to deactivate: %s\" % \", \".join(plugins))\n\n        plugins_deactivated = []\n        for plugin_name in plugins:\n            if not isinstance(plugin_name, str):\n                raise AttributeError(\"plugin name must be a str, not %s\" % type(plugin_name))\n\n            if plugin_name not in self._plugins.keys():\n                self._log.info(\"Unknown activated plugin %s\" % plugin_name)\n                continue\n            else:\n                self._log.debug(\"Deactivating plugin %s\" % plugin_name)\n                if not self._plugins[plugin_name].active:\n                    self._log.warning(\"Plugin %s seems to be already deactivated\" % plugin_name)\n                else:\n                    try:\n                        self._plugins[plugin_name].deactivate()\n                    except Exception as e:\n                        raise_from(\n                            PluginNotDeactivatableException(\"Plugin %s could not be deactivated\" % plugin_name), e)\n                    else:\n                        self._log.debug(\"Plugin %s deactivated\" % plugin_name)\n                        plugins_deactivated.append(plugin_name)\n\n        self._log.info(\"Plugins deactivated: %s\" % \", \".join(plugins_deactivated))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, name=None):\n        if name is None:\n            return self._plugins\n        else:\n            if name not in self._plugins.keys():\n                return None\n            else:\n                return self._plugins[name]", "response": "Returns the single or dictionary of plugins with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_active(self, name):\n        if name in self._plugins.keys():\n            return self._plugins[\"name\"].active\n        return None", "response": "Returns True if plugin exists and is active."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_plugins_by_entry_points(self):\n        # Let's find and register every plugin, which is in sys.path and has defined a entry_point 'groundwork.plugin'\n        # in it's setup.py\n        entry_points = []\n        classes = {}\n        for entry_point in iter_entry_points(group='groundwork.plugin', name=None):\n            entry_points.append(entry_point)\n\n        for entry_point in entry_points:\n            try:\n                entry_point_object = entry_point.load()\n            except Exception as e:\n                # We should not throw an exception now, because a package/entry_point can be outdated, using an old\n                # api from groundwork, tries to import unavailable packages, what ever...\n                # We just do not make it available. That's all we can do.\n                self._log.debug(\"Couldn't load entry_point %s. Reason: %s\" % (entry_point.name, e))\n                continue\n\n            if not issubclass(entry_point_object, GwBasePattern):\n                self._log.warning(\"entry_point  %s is not a subclass of groundworkPlugin\" % entry_point.name)\n                continue\n            plugin_name = entry_point_object.__name__\n\n            plugin_class = self.register_class(entry_point_object, plugin_name,\n                                               entrypoint_name=entry_point.name,\n                                               distribution_path=entry_point.dist.location,\n                                               distribution_key=entry_point.dist.key,\n                                               distribution_version=entry_point.dist.version)\n\n            classes[plugin_name] = plugin_class\n            # classes[plugin_name] = {\n            #     \"name\": plugin_name,\n            #     \"entry_point\": entry_point.name,\n            #     \"path\": entry_point.dist.location,\n            #     \"class\": entry_point_object,\n            #     \"distribution\": {\n            #         \"key\": entry_point.dist.key,\n            #         \"version\": entry_point.dist.version\n            #     },\n            # }\n            self._log.debug(\"Found plugin: %s at entry_point %s of package %s (%s)\" % (plugin_name, entry_point.name,\n                                                                                       entry_point.dist.key,\n                                                                                       entry_point.dist.version))\n        return classes", "response": "Get all the plugins from entry_points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self, classes=[]):\n        if not isinstance(classes, list):\n            raise AttributeError(\"plugins must be a list, not %s.\" % type(classes))\n\n        plugin_registered = []\n\n        for plugin_class in classes:\n            plugin_name = plugin_class.__name__\n            self.register_class(plugin_class, plugin_name)\n            self._log.debug(\"Plugin %s registered\" % plugin_name)\n            plugin_registered.append(plugin_name)\n\n        self._log.info(\"Plugins registered: %s\" % \", \".join(plugin_registered))", "response": "Registers new plugins.\n\n        The registration only creates a new entry for a plugin inside the _classes dictionary.\n        It does not activate or even initialise the plugin.\n\n        A plugin must be a class, which inherits directly or indirectly from GwBasePattern.\n\n        :param classes: List of plugin classes\n        :type classes: list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the plugin class object with the given name or the complete plugin dictionary if no name is given.", "response": "def get(self, name=None):\n        \"\"\"\n        Returns the plugin class object with the given name.\n        Or if a name is not given, the complete plugin dictionary is returned.\n\n        :param name: Name of a plugin\n        :return: None, single plugin or dictionary of plugins\n        \"\"\"\n        if name is None:\n            return self._classes\n        else:\n            if name not in self._classes.keys():\n                return None\n            else:\n                return self._classes[name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize path to unicode", "response": "def _(path):\n    \"\"\"\n    Normalize path to unicode\n    :param path: path\n    :return: normalize path\n\n    >>> _(None)\n    u''\n    >>> _(u(\"test1\"))\n    u'test1'\n    >>> _(\"test2\")\n    u'test2'\n    \"\"\"\n    if path is None:\n        return u(\"\")\n    if not PY3:\n        if type(path) == unicode:\n            return path\n        try:\n            return _decode_utf8(path)\n        except UnicodeDecodeError:\n            pass\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remote(href):\n    href = _(href)\n    href = os.path.join(u(\"/\"), href)\n    if os.sep == \"\\\\\":\n        href = href.replace(\"\\\\\", \"/\")\n    return href", "response": "Normalize remote href\n    :param href: remote path\n    :return: normalize href\n\n    >>> remote(\"/test/hello.txt\")\n    u'/test/hello.txt'\n    >>> remote(\"test/hello.txt\")\n    u'/test/hello.txt'\n    >>> remote(\"test\\hello.txt\")\n    u'/test/hello.txt'\n    >>> remote(None)\n    u'/'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting common headers for the current user and password", "response": "def getHeaders(self):\n        \"\"\"\n        Get common headers\n        :return:\n        \"\"\"\n        basicauth = base64.encodestring(b(self.user + ':' + self.password)).strip()\n        return {\n            \"Depth\": \"1\",\n            \"Authorization\": 'Basic ' + _decode_utf8(basicauth),\n            \"Accept\": \"*/*\"\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, href):\n        for iTry in range(TRYINGS):\n            logger.info(u(\"list(%s): %s\") % (iTry, href))\n            folders = None\n            files = None\n            try:\n                href = os.path.join(u(\"/\"), _(href))\n                conn = self.getConnection()\n                conn.request(\"PROPFIND\", _encode_utf8(href), u(\"\"), self.getHeaders())\n                response = conn.getresponse()\n                checkResponse(response)\n                data = response.read()\n                if data == b('list: folder was not found'):\n                    return folders, files\n                elif data == b('You are not authorized to see this!'):\n                    return folders, files\n                else:\n                    try:\n                        dom = xml.dom.minidom.parseString(data)\n                        responces = dom.getElementsByTagNameNS(\"DAV:\", \"response\")\n                        folders = {}\n                        files = {}\n                        for dom in responces:\n                            response = RemoteObject(dom, self, href)\n                            if response.href != href:\n                                if response.isFolder():\n                                    folders[response.href] = response\n                                else:\n                                    files[response.href] = response\n                    except xml.parsers.expat.ExpatError:\n                        e = sys.exc_info()[1]\n                        logger.exception(e)\n                return folders, files\n            except ConnectionException:\n                raise\n            except Exception:\n                e = sys.exc_info()[1]\n                logger.exception(e)\n            return folders, files", "response": "list of files and directories at remote server"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync(self, localpath, href, exclude=None, block=True):\n        logger.info(u(\"sync: %s %s\") % (localpath, href))\n        try:\n            localpath = _(localpath)\n            href = remote(href)\n            localRoot, localFolders, localFiles = next(os.walk(localpath))\n            remoteFolders, remoteFiles = self.list(href)\n            if remoteFiles is None or remoteFolders is None:\n                remoteFiles = {}\n                remoteFolders = {}\n                self.mkdir(href)\n\n            def norm(folder):\n                path = os.path.join(href, _(folder))\n                if path[len(path) - 1] != os.path.sep:\n                    path += u(\"/\")\n                return path\n\n            foldersToCreate = filter(\n                lambda folderPath: folderPath not in remoteFolders,\n                map(norm, localFolders)\n            )\n            apply_async(\"mkdir\", lambda path: self.mkdir(path), foldersToCreate, self.limit)\n\n            filesToSync = filter(\n                lambda lFile: os.path.join(href, _(lFile)) not in remoteFiles,\n                localFiles\n            )\n            fileArgs = [(os.path.join(localpath, f), os.path.join(href, f))\n                        for f in filesToSync]\n            apply_async(\"upload\", lambda s, t: self.upload(s, t), fileArgs, self.limit)\n\n            for folder in localFolders:\n                localFolderPath = os.path.join(localpath, folder)\n                remoteFolderPath = os.path.join(href, folder)\n                if exclude:\n                    bSync = exclude(localFolderPath, remoteFolderPath)\n                else:\n                    bSync = True\n                if bSync:\n                    apply_async(\n                        \"sync\",\n                        lambda localpath, href: self.sync(localpath, href, exclude, False),\n                        [(localFolderPath, remoteFolderPath), ]\n                    )\n        except ConnectionException:\n            raise\n        except Exception:\n            e = sys.exc_info()[1]\n            logger.exception(e)\n        if block:\n            qWork.join()", "response": "Sync local and remote folders"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate remote folder :param href: remote path :return: response", "response": "def mkdir(self, href):\n        \"\"\"\n        create remote folder\n        :param href: remote path\n        :return: response\n        \"\"\"\n        for iTry in range(TRYINGS):\n            logger.info(u(\"mkdir(%s): %s\") % (iTry, href))\n            try:\n                href = remote(href)\n                con = self.getConnection()\n                con.request(\"MKCOL\", _encode_utf8(href), \"\", self.getHeaders())\n                response = con.getresponse()\n                checkResponse(response)\n                return response.read()\n            except ConnectionException:\n                raise\n            except Exception:\n                e = sys.exc_info()[1]\n                logger.exception(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef downloadTo(self, href, localpath):\n        for iTry in range(TRYINGS):\n            logger.info(u(\"downloadTo(%s): %s %s\") % (iTry, href, localpath))\n            try:\n                href = remote(href)\n                localpath = _(localpath)\n\n                conn = self.getConnection()\n                conn.request(\"GET\", _encode_utf8(href), \"\", self.getHeaders())\n                response = conn.getresponse()\n                checkResponse(response)\n                f = None\n                try:\n                    while True:\n                        data = _decode_utf8(response.read(1024))\n                        if not data:\n                            break\n                        if data == u('resource not found'):\n                            return False\n                        if not f:\n                            f = open(localpath, \"w\")\n                        f.write(data)\n                finally:\n                    if f:\n                        f.close()\n                return True\n            except ConnectionException:\n                raise\n            except Exception:\n                e = sys.exc_info()[1]\n                logger.exception(e)", "response": "Download file to localstorage"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a file from localpath to remote server and returns the ID of the file that was uploaded.", "response": "def upload(self, localpath, href):\n        \"\"\"\n        Upload file from localpath to remote server\n        :param localpath: local path\n        :param href: remote path\n        :return: response\n        \"\"\"\n        localpath = _(localpath)\n        href = remote(href)\n        if not os.path.exists(localpath):\n            logger.info(u(\"ERROR: localfile: %s not found\") % localpath)\n            return\n        if os.path.islink(localpath):\n            return self.upload(os.path.abspath(os.path.realpath(localpath)), href)\n            # 3 tryings to upload file\n        for iTry in range(TRYINGS):\n            try:\n                logger.info(u(\"upload: %s %s\") % (localpath, href))\n                length = os.path.getsize(localpath)\n\n                if PY3:\n                    _open = open(_encode_utf8(localpath), \"r\", encoding='latin-1')\n                else:\n                    _open = open(_encode_utf8(localpath), \"r\")\n                with _open as f:\n                    return self.write(f, href, length=length)\n            except ConnectionException:\n                raise\n            except Exception:\n                e = sys.exc_info()[1]\n                logger.exception(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the. sln file to disk.", "response": "def write(self):\n        \"\"\"\n        Writes the ``.sln`` file to disk.\n        \"\"\"\n        filters = {\n            'MSGUID': lambda x: ('{%s}' % x).upper(),\n            'relslnfile': lambda x: os.path.relpath(x, os.path.dirname(self.FileName))\n        }\n        context = {\n            'sln': self\n        }\n        return self.render(self.__jinja_template__, self.FileName, context, filters)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef preprocess_data(self, div=1, downsample=0, sum_norm=None,\n                        include_genes=None, exclude_genes=None,\n                        include_cells=None, exclude_cells=None,\n                        norm='log', min_expression=1, thresh=0.01,\n                        filter_genes=True):\n        \"\"\"Log-normalizes and filters the expression data.\n\n        Parameters\n        ----------\n\n        div : float, optional, default 1\n            The factor by which the gene expression will be divided prior to\n            log normalization.\n\n        downsample : float, optional, default 0\n            The factor by which to randomly downsample the data. If 0, the\n            data will not be downsampled.\n\n        sum_norm : str or float, optional, default None\n            If a float, the total number of transcripts in each cell will be\n            normalized to this value prior to normalization and filtering.\n            Otherwise, nothing happens. If 'cell_median', each cell is\n            normalized to have the median total read count per cell. If\n            'gene_median', each gene is normalized to have the median total\n            read count per gene.\n\n        norm : str, optional, default 'log'\n            If 'log', log-normalizes the expression data. If 'ftt', applies the\n            Freeman-Tukey variance-stabilization transformation. If\n            'multinomial', applies the Pearson-residual transformation (this is\n            experimental and should only be used for raw, un-normalized UMI\n            datasets). If None, the data is not normalized.\n\n        include_genes : array-like of string, optional, default None\n            A vector of gene names or indices that specifies the genes to keep.\n            All other genes will be filtered out. Gene names are case-\n            sensitive.\n\n        exclude_genes : array-like of string, optional, default None\n            A vector of gene names or indices that specifies the genes to\n            exclude. These genes will be filtered out. Gene names are case-\n            sensitive.\n\n        include_cells : array-like of string, optional, default None\n            A vector of cell names that specifies the cells to keep.\n            All other cells will be filtered out. Cell names are\n            case-sensitive.\n\n        exclude_cells : array-like of string, optional, default None\n            A vector of cell names that specifies the cells to exclude.\n            Thses cells will be filtered out. Cell names are\n            case-sensitive.\n\n        min_expression : float, optional, default 1\n            The threshold above which a gene is considered\n            expressed. Gene expression values less than 'min_expression' are\n            set to zero.\n\n        thresh : float, optional, default 0.2\n            Keep genes expressed in greater than 'thresh'*100 % of cells and\n            less than (1-'thresh')*100 % of cells, where a gene is considered\n            expressed if its expression value exceeds 'min_expression'.\n\n        filter_genes : bool, optional, default True\n            Setting this to False turns off filtering operations aside from\n            removing genes with zero expression across all cells. Genes passed\n            in exclude_genes or not passed in include_genes will still be\n            filtered.\n\n        \"\"\"\n        # load data\n        try:\n            D= self.adata_raw.X\n            self.adata = self.adata_raw.copy()\n            \n        except AttributeError:\n            print('No data loaded')\n        \n        # filter cells\n        cell_names = np.array(list(self.adata_raw.obs_names))\n        idx_cells = np.arange(D.shape[0])\n        if(include_cells is not None):\n            include_cells = np.array(list(include_cells))\n            idx2 = np.where(np.in1d(cell_names, include_cells))[0]\n            idx_cells = np.array(list(set(idx2) & set(idx_cells)))\n\n        if(exclude_cells is not None):\n            exclude_cells = np.array(list(exclude_cells))\n            idx4 = np.where(np.in1d(cell_names, exclude_cells,\n                                    invert=True))[0]\n            idx_cells = np.array(list(set(idx4) & set(idx_cells)))\n\n        if downsample > 0:\n            numcells = int(D.shape[0] / downsample)\n            rand_ind = np.random.choice(np.arange(D.shape[0]),\n                                        size=numcells, replace=False)\n            idx_cells = np.array(list(set(rand_ind) & set(idx_cells)))\n        else:\n            numcells = D.shape[0]\n\n        mask_cells = np.zeros(D.shape[0], dtype='bool')\n        mask_cells[idx_cells] = True\n        \n        self.adata = self.adata_raw[mask_cells,:].copy()\n        D = self.adata.X\n        if isinstance(D,np.ndarray):\n            D=sp.csr_matrix(D,dtype='float32')\n        else:\n            D=D.astype('float32')\n            D.sort_indices()\n        \n        if(D.getformat() == 'csc'):\n            D=D.tocsr();\n        \n        # sum-normalize\n        if (sum_norm == 'cell_median' and norm != 'multinomial'):\n            s = D.sum(1).A.flatten()\n            sum_norm = np.median(s)\n            D = D.multiply(1 / s[:,None] * sum_norm).tocsr()\n        elif (sum_norm == 'gene_median' and norm != 'multinomial'):\n            s = D.sum(0).A.flatten()\n            sum_norm = np.median(s)\n            s[s==0]=1\n            D = D.multiply(1 / s[None,:] * sum_norm).tocsr()\n\n        elif sum_norm is not None and norm != 'multinomial':\n            D = D.multiply(1 / D.sum(1).A.flatten()[:,\n                    None] * sum_norm).tocsr()\n        \n        # normalize\n        self.adata.X = D\n        if norm is None:\n            D.data[:] = (D.data / div)\n            \n        elif(norm.lower() == 'log'):\n            D.data[:] = np.log2(D.data / div + 1)\n            \n        elif(norm.lower() == 'ftt'):\n            D.data[:] = np.sqrt(D.data/div) + np.sqrt(D.data/div+1)\n            \n        elif norm.lower() == 'multinomial':\n            ni = D.sum(1).A.flatten() #cells\n            pj = (D.sum(0) / D.sum()).A.flatten() #genes\n            col = D.indices\n            row=[]\n            for i in range(D.shape[0]):\n                row.append(i*np.ones(D.indptr[i+1]-D.indptr[i]))                \n            row = np.concatenate(row).astype('int32')            \n            mu = sp.coo_matrix((ni[row]*pj[col], (row,col))).tocsr()\n            mu2 = mu.copy()            \n            mu2.data[:]=mu2.data**2\n            mu2 = mu2.multiply(1/ni[:,None])  \n            mu.data[:] = (D.data - mu.data) / np.sqrt(mu.data - mu2.data)\n         \n            self.adata.X = mu\n            if sum_norm is None:\n                sum_norm = np.median(ni)\n            D = D.multiply(1 / ni[:,None] * sum_norm).tocsr()            \n            D.data[:] = np.log2(D.data / div + 1)\n\n        else:\n            D.data[:] = (D.data / div)\n\n        # zero-out low-expressed genes      \n        idx = np.where(D.data <= min_expression)[0]\n        D.data[idx] = 0\n        \n        # filter genes\n        gene_names = np.array(list(self.adata.var_names))\n        idx_genes = np.arange(D.shape[1])            \n        if(include_genes is not None):\n            include_genes = np.array(list(include_genes))\n            idx = np.where(np.in1d(gene_names, include_genes))[0]\n            idx_genes = np.array(list(set(idx) & set(idx_genes)))\n\n        if(exclude_genes is not None):\n            exclude_genes = np.array(list(exclude_genes))\n            idx3 = np.where(np.in1d(gene_names, exclude_genes,\n                                    invert=True))[0]\n            idx_genes = np.array(list(set(idx3) & set(idx_genes)))\n        \n        if(filter_genes):                \n            a, ct = np.unique(D.indices, return_counts=True)\n            c = np.zeros(D.shape[1])\n            c[a] = ct\n\n            keep = np.where(np.logical_and(c / D.shape[0] > thresh,\n                                           c / D.shape[0] <= 1 - thresh))[0]\n\n            idx_genes = np.array(list(set(keep) & set(idx_genes)))\n        \n        \n        mask_genes = np.zeros(D.shape[1], dtype='bool')\n        mask_genes[idx_genes] = True\n\n        self.adata.X = self.adata.X.multiply(mask_genes[None, :]).tocsr()\n        self.adata.X.eliminate_zeros()\n        self.adata.var['mask_genes']=mask_genes\n        \n        if norm == 'multinomial':\n            self.adata.layers['X_disp'] = D.multiply(mask_genes[None, :]).tocsr()\n            self.adata.layers['X_disp'].eliminate_zeros()\n        else:\n            self.adata.layers['X_disp'] = self.adata.X", "response": "Preprocess the data for the UMI - related data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_data(self, filename, transpose=True,\n                  save_sparse_file='h5ad', sep=',', **kwargs):\n        \"\"\"Loads the specified data file. The file can be a table of\n        read counts (i.e. '.csv' or '.txt'), with genes as rows and cells\n        as columns by default. The file can also be a pickle file (output from\n        'save_sparse_data') or an h5ad file (output from 'save_anndata').\n\n        This function that loads the file specified by 'filename'.\n\n        Parameters\n        ----------\n        filename - string\n            The path to the tabular raw expression counts file.\n\n        sep - string, optional, default ','\n            The delimeter used to read the input data table. By default\n            assumes the input table is delimited by commas.\n\n        save_sparse_file - str, optional, default 'h5ad'\n            If 'h5ad', writes the SAM 'adata_raw' object to a h5ad file\n            (the native AnnData file format) to the same folder as the original\n            data for faster loading in the future. If 'p', pickles the sparse\n            data structure, cell names, and gene names in the same folder as\n            the original data for faster loading in the future.\n\n        transpose - bool, optional, default True\n            By default, assumes file is (genes x cells). Set this to False if\n            the file has dimensions (cells x genes).\n\n\n        \"\"\"\n        if filename.split('.')[-1] == 'p':\n            raw_data, all_cell_names, all_gene_names = (\n                pickle.load(open(filename, 'rb')))\n\n            if(transpose):                \n                raw_data = raw_data.T\n                if raw_data.getformat()=='csc':\n                    print(\"Converting sparse matrix to csr format...\")\n                    raw_data=raw_data.tocsr()\n            \n            save_sparse_file = None\n        elif filename.split('.')[-1] != 'h5ad':\n            df = pd.read_csv(filename, sep=sep, index_col=0)\n            if(transpose):\n                dataset = df.T\n            else:\n                dataset = df\n\n            raw_data = sp.csr_matrix(dataset.values)\n            all_cell_names = np.array(list(dataset.index.values))\n            all_gene_names = np.array(list(dataset.columns.values))\n\n        if filename.split('.')[-1] != 'h5ad':\n            self.adata_raw = AnnData(X=raw_data, obs={'obs_names': all_cell_names},\n                                     var={'var_names': all_gene_names})\n            \n            if(np.unique(all_gene_names).size != all_gene_names.size):\n                self.adata_raw.var_names_make_unique()\n            if(np.unique(all_cell_names).size != all_cell_names.size):\n                self.adata_raw.obs_names_make_unique()\n            \n            self.adata = self.adata_raw.copy()\n            self.adata.layers['X_disp'] = raw_data\n\n        else:\n            self.adata_raw = anndata.read_h5ad(filename, **kwargs)\n            self.adata = self.adata_raw.copy()\n            if 'X_disp' not in list(self.adata.layers.keys()):\n                self.adata.layers['X_disp'] = self.adata.X\n            save_sparse_file = None\n                \n        if(save_sparse_file == 'p'):\n            new_sparse_file = '.'.join(filename.split('/')[-1].split('.')[:-1])\n            path = filename[:filename.find(filename.split('/')[-1])]\n            self.save_sparse_data(path + new_sparse_file + '_sparse.p')\n        elif(save_sparse_file == 'h5ad'):\n            new_sparse_file = '.'.join(filename.split('/')[-1].split('.')[:-1])\n            path = filename[:filename.find(filename.split('/')[-1])]\n            self.save_anndata(path + new_sparse_file + '_SAM.h5ad')", "response": "Loads the specified data file into the internal data structures."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the raw data in a pickle file.", "response": "def save_sparse_data(self, fname):\n        \"\"\"Saves the tuple (raw_data,all_cell_names,all_gene_names) in a\n        Pickle file.\n\n        Parameters\n        ----------\n        fname - string\n            The filename of the output file.\n\n        \"\"\"\n        data = self.adata_raw.X.T\n        if data.getformat()=='csr':\n            data=data.tocsc()\n\n        cell_names = np.array(list(self.adata_raw.obs_names))\n        gene_names = np.array(list(self.adata_raw.var_names))\n        \n        pickle.dump((data, cell_names, gene_names), open(fname, 'wb'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave an anndata to a. h5ad file.", "response": "def save_anndata(self, fname, data = 'adata_raw', **kwargs):\n        \"\"\"Saves `adata_raw` to a .h5ad file (AnnData's native file format).\n\n        Parameters\n        ----------\n        fname - string\n            The filename of the output file.\n\n        \"\"\"\n        x = self.__dict__[data]\n        x.write_h5ad(fname, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_annotations(self, aname, sep=','):\n        ann = pd.read_csv(aname)\n\n        cell_names = np.array(list(self.adata.obs_names))\n        all_cell_names = np.array(list(self.adata_raw.obs_names))\n\n        if(ann.shape[1] > 1):\n            ann = pd.read_csv(aname, index_col=0, sep=sep)\n            if(ann.shape[0] != all_cell_names.size):\n                ann = pd.read_csv(aname, index_col=0, header=None, sep=sep)\n        else:\n            if(ann.shape[0] != all_cell_names.size):\n                ann = pd.read_csv(aname, header=None, sep=sep)\n        ann.index = np.array(list(ann.index.astype('<U100')))\n        ann1 = np.array(list(ann.T[cell_names].T.values.flatten()))\n        ann2 = np.array(list(ann.values.flatten()))\n\n        self.adata_raw.obs['annotations'] = pd.Categorical(ann2)\n        self.adata.obs['annotations'] = pd.Categorical(ann1)", "response": "Loads the cell annoations specified by the aname path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the spatial dispersion factors for each gene in the set of outlier genes.", "response": "def dispersion_ranking_NN(self, nnm, num_norm_avg=50):\n        \"\"\"Computes the spatial dispersion factors for each gene.\n\n        Parameters\n        ----------\n        nnm - scipy.sparse, float\n            Square cell-to-cell nearest-neighbor matrix.\n\n        num_norm_avg - int, optional, default 50\n            The top 'num_norm_avg' dispersions are averaged to determine the\n            normalization factor when calculating the weights. This ensures\n            that outlier genes do not significantly skew the weight\n            distribution.\n\n        Returns:\n        -------\n        indices - ndarray, int\n            The indices corresponding to the gene weights sorted in decreasing\n            order.\n\n        weights - ndarray, float\n            The vector of gene weights.\n        \"\"\"\n\n        self.knn_avg(nnm)\n        D_avg = self.adata.layers['X_knn_avg']\n\n        mu, var = sf.mean_variance_axis(D_avg, axis=0)\n\n        dispersions = np.zeros(var.size)\n        dispersions[mu > 0] = var[mu > 0] / mu[mu > 0]\n\n        self.adata.var['spatial_dispersions'] = dispersions.copy()\n\n        ma = np.sort(dispersions)[-num_norm_avg:].mean()\n        dispersions[dispersions >= ma] = ma\n\n        weights = ((dispersions / dispersions.max())**0.5).flatten()\n\n        self.adata.var['weights'] = weights\n\n        return weights"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_regression_PCs(self, genes=None, npcs=None, plot=False):\n        from sklearn.decomposition import PCA\n\n        if npcs is None:\n            npcs = self.adata.X.shape[0]\n\n        pca = PCA(n_components=npcs)\n        pc = pca.fit_transform(self.adata.X.toarray())\n\n        self.regression_pca = pca\n        self.regression_pcs = pc\n\n        gene_names = np.array(list(self.adata.var_names))\n        if(genes is not None):\n            idx = np.where(np.in1d(gene_names, genes))[0]\n            sx = pca.components_[:, idx]\n            x = np.abs(sx).mean(1)\n\n            if plot:\n                plt.figure()\n                plt.plot(x)\n\n            return x\n        else:\n            return", "response": "Calculates the regression of the gene IDs in genes to each other."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef regress_genes(self, PCs):\n\n        ind = [PCs]\n        ind = np.array(ind).flatten()\n        try:\n            y = self.adata.X.toarray() - self.regression_pcs[:, ind].dot(\n                self.regression_pca.components_[ind, :] * self.adata.var[\n                                                            'weights'].values)\n        except BaseException:\n            y = self.adata.X.toarray() - self.regression_pcs[:, ind].dot(\n                self.regression_pca.components_[ind, :])\n\n        self.adata.X = sp.csr_matrix(y)", "response": "Regress out the principal components in PCs from the filtered sequence data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the Self-Assembling Manifold algorithm. Parameters ---------- k - int, optional, default 20 The number of nearest neighbors to identify for each cell. distance : string, optional, default 'correlation' The distance metric to use when constructing cell distance matrices. Can be any of the distance metrics supported by sklearn's 'pdist'. max_iter - int, optional, default 10 The maximum number of iterations SAM will run. stopping_condition - float, optional, default 5e-3 The stopping condition threshold for the RMSE between gene weights in adjacent iterations. verbose - bool, optional, default True If True, the iteration number and error between gene weights in adjacent iterations will be displayed. projection - str, optional, default 'umap' If 'tsne', generates a t-SNE embedding. If 'umap', generates a UMAP embedding. Otherwise, no embedding will be generated. preprocessing - str, optional, default 'Normalizer' If 'Normalizer', use sklearn.preprocessing.Normalizer, which normalizes expression data prior to PCA such that each cell has unit L2 norm. If 'StandardScaler', use sklearn.preprocessing.StandardScaler, which normalizes expression data prior to PCA such that each gene has zero mean and unit variance. Otherwise, do not normalize the expression data. We recommend using 'StandardScaler' for large datasets and 'Normalizer' otherwise. num_norm_avg - int, optional, default 50 The top 'num_norm_avg' dispersions are averaged to determine the normalization factor when calculating the weights. This prevents genes with large spatial dispersions from skewing the distribution of weights. proj_kwargs - dict, optional, default {} A dictionary of keyword arguments to pass to the projection functions.", "response": "def run(self,\n            max_iter=10,\n            verbose=True,\n            projection='umap',\n            stopping_condition=5e-3,\n            num_norm_avg=50,\n            k=20,\n            distance='correlation',\n            preprocessing='Normalizer',\n            proj_kwargs={}):\n        \"\"\"Runs the Self-Assembling Manifold algorithm.\n\n        Parameters\n        ----------\n        k - int, optional, default 20\n            The number of nearest neighbors to identify for each cell.\n\n        distance : string, optional, default 'correlation'\n            The distance metric to use when constructing cell distance\n            matrices. Can be any of the distance metrics supported by\n            sklearn's 'pdist'.\n\n        max_iter - int, optional, default 10\n            The maximum number of iterations SAM will run.\n\n        stopping_condition - float, optional, default 5e-3\n            The stopping condition threshold for the RMSE between gene weights\n            in adjacent iterations.\n\n        verbose - bool, optional, default True\n            If True, the iteration number and error between gene weights in\n            adjacent iterations will be displayed.\n\n        projection - str, optional, default 'umap'\n            If 'tsne', generates a t-SNE embedding. If 'umap', generates a UMAP\n            embedding. Otherwise, no embedding will be generated.\n\n        preprocessing - str, optional, default 'Normalizer'\n            If 'Normalizer', use sklearn.preprocessing.Normalizer, which\n            normalizes expression data prior to PCA such that each cell has\n            unit L2 norm. If 'StandardScaler', use\n            sklearn.preprocessing.StandardScaler, which normalizes expression\n            data prior to PCA such that each gene has zero mean and unit\n            variance. Otherwise, do not normalize the expression data. We\n            recommend using 'StandardScaler' for large datasets and\n            'Normalizer' otherwise.\n\n        num_norm_avg - int, optional, default 50\n            The top 'num_norm_avg' dispersions are averaged to determine the\n            normalization factor when calculating the weights. This prevents\n            genes with large spatial dispersions from skewing the distribution\n            of weights.\n            \n        proj_kwargs - dict, optional, default {}\n            A dictionary of keyword arguments to pass to the projection\n            functions.\n        \"\"\"\n\n        self.distance = distance\n        D = self.adata.X\n        self.k = k\n        if(self.k < 5):\n            self.k = 5\n        elif(self.k > 100):\n            self.k = 100\n\n        if(self.k > D.shape[0] - 1):\n            self.k = D.shape[0] - 2\n\n        numcells = D.shape[0]\n\n        n_genes = 8000\n        if numcells > 3000 and n_genes > 3000:\n            n_genes = 3000\n        elif numcells > 2000 and n_genes > 4500:\n            n_genes = 4500\n        elif numcells > 1000 and n_genes > 6000:\n            n_genes = 6000\n        elif n_genes > 8000:\n            n_genes = 8000\n\n        npcs = None\n        if npcs is None and numcells > 3000:\n            npcs = 150\n        elif npcs is None and numcells > 2000:\n            npcs = 250\n        elif npcs is None and numcells > 1000:\n            npcs = 350\n        elif npcs is None:\n            npcs = 500\n\n        tinit = time.time()\n\n        edm = sp.coo_matrix((numcells, numcells), dtype='i').tolil()\n        nums = np.arange(edm.shape[1])\n        RINDS = np.random.randint(\n            0, numcells, (self.k - 1) * numcells).reshape((numcells, \n                                                                 (self.k - 1)))\n        RINDS = np.hstack((nums[:, None], RINDS))\n\n        edm[np.tile(np.arange(RINDS.shape[0])[:, None],\n                    (1, RINDS.shape[1])).flatten(), RINDS.flatten()] = 1\n        edm = edm.tocsr()\n\n        print('RUNNING SAM')\n\n        W = self.dispersion_ranking_NN(\n            edm, num_norm_avg=1)\n\n        old = np.zeros(W.size)\n        new = W\n\n        i = 0\n        err = ((new - old)**2).mean()**0.5\n\n        if max_iter < 5:\n            max_iter = 5\n\n        nnas = num_norm_avg\n        self.Ns=[edm]\n        self.Ws = [W]\n        while (i < max_iter and err > stopping_condition):\n\n            conv = err\n            if(verbose):\n                print('Iteration: ' + str(i) + ', Convergence: ' + str(conv))\n\n            i += 1\n            old = new\n\n            W, wPCA_data, EDM, = self.calculate_nnm(\n                D, W, n_genes, preprocessing, npcs, numcells, nnas)\n            new = W\n            err = ((new - old)**2).mean()**0.5\n            \n            self.Ns.append(EDM)\n            self.Ws.append(W)\n\n        W, wPCA_data, EDM, = self.calculate_nnm(\n                D, W, n_genes, preprocessing, npcs, numcells, nnas)\n        self.Ns.append(EDM)\n        \n        all_gene_names = np.array(list(self.adata.var_names))\n        indices = np.argsort(-W)\n        ranked_genes = all_gene_names[indices]\n\n        self.corr_bin_genes(number_of_features=1000)\n\n        self.adata.uns['ranked_genes'] = ranked_genes\n\n        self.adata.obsm['X_pca'] = wPCA_data\n\n        self.adata.uns['neighbors'] = {}\n        self.adata.uns['neighbors']['connectivities'] = EDM\n\n        if(projection == 'tsne'):\n            print('Computing the t-SNE embedding...')\n            self.run_tsne(**proj_kwargs)\n        elif(projection == 'umap'):\n            print('Computing the UMAP embedding...')\n            self.run_umap(**proj_kwargs)\n        elif(projection == 'diff_umap'):\n            print('Computing the diffusion UMAP embedding...')\n            self.run_diff_umap(**proj_kwargs)\n            \n        elapsed = time.time() - tinit\n        if verbose:\n            print('Elapsed time: ' + str(elapsed) + ' seconds')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_correlated_groups(self, group=None, n_genes=5, **kwargs):\n        geneID_groups = self.adata.uns['gene_groups']\n        if(group is None):\n            for i in range(len(geneID_groups)):\n                self.show_gene_expression(geneID_groups[i][0], **kwargs)\n        else:\n            for i in range(n_genes):\n                self.show_gene_expression(geneID_groups[group][i], **kwargs)", "response": "Plots orthogonal expression patterns within a specific correlated group of genes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_correlated_genes(\n            self,\n            name,\n            n_genes=5,\n            number_of_features=1000,\n            **kwargs):\n        \"\"\"Plots gene expression patterns correlated with the input gene.\n\n        Parameters\n        ----------\n        name - string\n            The name of the gene with respect to which correlated gene\n            expression patterns will be displayed.\n\n        n_genes - int, optional, default 5\n            The number of top ranked correlated genes to display.\n\n        **kwargs -\n            All keyword arguments in 'show_gene_expression' and 'scatter'\n            are eligible.\n        \"\"\"\n        all_gene_names = np.array(list(self.adata.var_names))\n        if((all_gene_names == name).sum() == 0):\n            print(\n                \"Gene not found in the filtered dataset. Note that genes \"\n                \"are case sensitive.\")\n            return\n        sds = self.corr_bin_genes(\n            input_gene=name,\n            number_of_features=number_of_features)\n        if (n_genes + 1 > sds.size):\n            x = sds.size\n        else:\n            x = n_genes + 1\n\n        for i in range(1, x):\n            self.show_gene_expression(sds[i], **kwargs)\n        return sds[1:]", "response": "Plots the top ranked expression patterns of the given gene."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef corr_bin_genes(self, number_of_features=None, input_gene=None):\n\n        weights = self.adata.var['spatial_dispersions'].values\n        all_gene_names = np.array(list(self.adata.var_names))\n        D_avg = self.adata.layers['X_knn_avg']\n\n        idx2 = np.argsort(-weights)[:weights[weights > 0].size]\n\n        if(number_of_features is None or number_of_features > idx2.size):\n            number_of_features = idx2.size\n\n        if number_of_features > 1000:\n            number_of_features = 1000\n\n        if(input_gene is not None):\n            input_gene = np.where(all_gene_names == input_gene)[0]\n            if(input_gene.size == 0):\n                print(\n                    \"Gene note found in the filtered dataset. Note \"\n                    \"that genes are case sensitive.\")\n                return\n            seeds = [np.array([input_gene])]\n            pw_corr = np.corrcoef(\n                D_avg[:, idx2[:number_of_features]].T.toarray())\n            for i in range(1, number_of_features):\n                flag = False\n                maxd = np.mean(pw_corr[i, :][pw_corr[i, :] > 0])\n                maxi = 0\n                for j in range(len(seeds)):\n                    if(pw_corr[np.where(idx2 == seeds[j][0])[0], i]\n                       > maxd):\n                        maxd = pw_corr[np.where(idx2 == seeds[j][0])[0], i]\n                        maxi = j\n                        flag = True\n                if(not flag):\n                    seeds.append(np.array([idx2[i]]))\n                else:\n                    seeds[maxi] = np.append(seeds[maxi], idx2[i])\n\n            geneID_groups = []\n            for i in range(len(seeds)):\n                geneID_groups.append(all_gene_names[seeds[i]])\n\n            return geneID_groups[0]\n        else:\n            seeds = [np.array([idx2[0]])]\n            pw_corr = np.corrcoef(\n                D_avg[:, idx2[:number_of_features]].T.toarray())\n            for i in range(1, number_of_features):\n                flag = False\n                maxd = np.mean(pw_corr[i, :][pw_corr[i, :] > 0])\n                maxi = 0\n                for j in range(len(seeds)):\n                    if(pw_corr[np.where(idx2 == seeds[j][0])[0], i]\n                       > maxd):\n                        maxd = pw_corr[np.where(idx2 == seeds[j][0])[0], i]\n                        maxi = j\n                        flag = True\n                if(not flag):\n                    seeds.append(np.array([idx2[i]]))\n                else:\n                    seeds[maxi] = np.append(seeds[maxi], idx2[i])\n\n            geneID_groups = []\n            for i in range(len(seeds)):\n                geneID_groups.append(\n                    all_gene_names[seeds[i]])\n\n            self.adata.uns['gene_groups'] = geneID_groups\n            return geneID_groups", "response": "This method is used to bin the genes in the SAM manifold."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_tsne(self, X=None, metric='correlation', **kwargs):\n        if(X is not None):\n            dt = man.TSNE(metric=metric, **kwargs).fit_transform(X)\n            return dt\n\n        else:\n            dt = man.TSNE(metric=self.distance,\n                          **kwargs).fit_transform(self.adata.obsm['X_pca'])\n            tsne2d = dt\n            self.adata.obsm['X_tsne'] = tsne2d", "response": "Wrapper for sklearn s t - SNE implementation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_umap(self, X=None, metric=None, **kwargs):\n\n        import umap as umap\n\n        if metric is None:\n            metric = self.distance\n\n        if(X is not None):\n            umap_obj = umap.UMAP(metric=metric, **kwargs)\n            dt = umap_obj.fit_transform(X)\n            return dt\n\n        else:\n            umap_obj = umap.UMAP(metric=metric, **kwargs)\n            umap2d = umap_obj.fit_transform(self.adata.obsm['X_pca'])\n            self.adata.obsm['X_umap'] = umap2d", "response": "Wrapper for umap - learn.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_diff_umap(self,use_rep='X_pca', metric='euclidean', n_comps=15,\n                      method='gauss', **kwargs):\n        \"\"\"\n        Experimental -- running UMAP on the diffusion components        \n        \"\"\"             \n        import scanpy.api as sc\n        sc.pp.neighbors(self.adata,use_rep=use_rep,n_neighbors=self.k,\n                                       metric=self.distance,method=method)\n        sc.tl.diffmap(self.adata, n_comps=n_comps)\n        \n        sc.pp.neighbors(self.adata,use_rep='X_diffmap',n_neighbors=self.k,\n                                       metric='euclidean',method=method)\n                \n        if 'X_umap' in self.adata.obsm.keys():\n                self.adata.obsm['X_umap_sam'] = self.adata.obsm['X_umap']\n                \n        sc.tl.umap(self.adata,min_dist=0.1,copy=False)", "response": "Run UMAP on the diffusion components of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying a scatter plot of the current state of the key - value entry in the current state of the object.", "response": "def scatter(self, projection=None, c=None, cmap='rainbow', linewidth=0.0,\n                edgecolor='k', axes=None, colorbar=True, s=10, **kwargs):\n        \"\"\"Display a scatter plot.\n\n        Displays a scatter plot using the SAM projection or another input\n        projection with or without annotations.\n\n        Parameters\n        ----------\n\n        projection - ndarray of floats, optional, default None\n            An N x 2 matrix, where N is the number of data points. If None,\n            use an existing SAM projection (default t-SNE). Can take on values\n            'umap' or 'tsne' to specify either the SAM UMAP embedding or\n            SAM t-SNE embedding.\n\n        c - ndarray or str, optional, default None\n            Colors for each cell in the scatter plot. Can be a vector of\n            floats or strings for cell annotations. Can also be a key\n            for sam.adata.obs (i.e. 'louvain_clusters').\n\n        axes - matplotlib axis, optional, default None\n            Plot output to the specified, existing axes. If None, create new\n            figure window.\n\n        cmap - string, optional, default 'rainbow'\n            The colormap to use for the input color values.\n\n        colorbar - bool, optional default True\n            If True, display a colorbar indicating which values / annotations\n            correspond to which color in the scatter plot.\n\n        Keyword arguments -\n            All other keyword arguments that can be passed into\n            matplotlib.pyplot.scatter can be used.\n        \"\"\"\n\n        if (not PLOTTING):\n            print(\"matplotlib not installed!\")\n        else:\n            if(isinstance(projection, str)):\n                try:\n                    dt = self.adata.obsm[projection]\n                except KeyError:\n                    print('Please create a projection first using run_umap or'\n                          'run_tsne')\n\n            elif(projection is None):\n                try:\n                    dt = self.adata.obsm['X_umap']\n                except KeyError:\n                    try:\n                        dt = self.adata.obsm['X_tsne']\n                    except KeyError:\n                        print(\"Please create either a t-SNE or UMAP projection\"\n                              \"first.\")\n                        return\n            else:\n                dt = projection\n\n            if(axes is None):\n                plt.figure()\n                axes = plt.gca()\n\n            if(c is None):\n                plt.scatter(dt[:, 0], dt[:, 1], s=s,\n                            linewidth=linewidth, edgecolor=edgecolor, **kwargs)\n            else:\n\n                if isinstance(c, str):\n                    try:\n                        c = self.adata.obs[c].get_values()\n                    except KeyError:\n                        0  # do nothing\n\n                if((isinstance(c[0], str) or isinstance(c[0], np.str_)) and\n                   (isinstance(c, np.ndarray) or isinstance(c, list))):\n                    i = ut.convert_annotations(c)\n                    ui, ai = np.unique(i, return_index=True)\n                    cax = axes.scatter(dt[:,0], dt[:,1], c=i, cmap=cmap, s=s,\n                                       linewidth=linewidth,\n                                       edgecolor=edgecolor,\n                                       **kwargs)\n\n                    if(colorbar):\n                        cbar = plt.colorbar(cax, ax=axes, ticks=ui)\n                        cbar.ax.set_yticklabels(c[ai])\n                else:\n                    if not (isinstance(c, np.ndarray) or isinstance(c, list)):\n                        colorbar = False\n                    i = c\n\n                    cax = axes.scatter(dt[:,0], dt[:,1], c=i, cmap=cmap, s=s,\n                                       linewidth=linewidth,\n                                       edgecolor=edgecolor,\n                                       **kwargs)\n\n                    if(colorbar):\n                        plt.colorbar(cax, ax=axes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_gene_expression(self, gene, avg=True, axes=None, **kwargs):\n\n        all_gene_names = np.array(list(self.adata.var_names))\n        cell_names = np.array(list(self.adata.obs_names))\n        all_cell_names = np.array(list(self.adata_raw.obs_names))\n\n        idx = np.where(all_gene_names == gene)[0]\n        name = gene\n        if(idx.size == 0):\n            print(\n                \"Gene note found in the filtered dataset. Note that genes \"\n                \"are case sensitive.\")\n            return\n\n        if(avg):\n            a = self.adata.layers['X_knn_avg'][:, idx].toarray().flatten()\n\n            if a.sum() == 0:\n                a = np.log2(self.adata_raw.X[np.in1d(\n                    all_cell_names, cell_names), :][:,\n                                                idx].toarray().flatten() + 1)\n        else:\n            a = np.log2(self.adata_raw.X[np.in1d(\n                all_cell_names, cell_names), :][:,\n                                                idx].toarray().flatten() + 1)\n\n        if axes is None:\n            plt.figure()\n            axes = plt.gca()\n\n        self.scatter(c=a, axes=axes, **kwargs)\n        axes.set_title(name)", "response": "Displays a scatter plot of a particular gene s expression pattern."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef louvain_clustering(self, X=None, res=1, method='modularity'):\n\n        if X is None:\n            X = self.adata.uns['neighbors']['connectivities']\n            save = True\n        else:\n            if not sp.isspmatrix_csr(X):\n                X = sp.csr_matrix(X)\n            save = False\n\n        import igraph as ig\n        import louvain\n\n        adjacency = sparse_knn(X.dot(X.T) / self.k, self.k).tocsr()\n        sources, targets = adjacency.nonzero()\n        weights = adjacency[sources, targets]\n        if isinstance(weights, np.matrix):\n            weights = weights.A1\n        g = ig.Graph(directed=True)\n        g.add_vertices(adjacency.shape[0])\n        g.add_edges(list(zip(sources, targets)))\n        try:\n            g.es['weight'] = weights\n        except BaseException:\n            pass\n\n        if method == 'significance':\n            cl = louvain.find_partition(g, louvain.SignificanceVertexPartition)\n        else:\n            cl = louvain.find_partition(\n                g,\n                louvain.RBConfigurationVertexPartition,\n                resolution_parameter=res)\n\n        if save:\n            self.adata.obs['louvain_clusters'] = pd.Categorical(np.array(cl.membership))\n        else:\n            return np.array(cl.membership)", "response": "Runs Louvain clustering on the vtraag X."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming k - means clustering on the clusteres of the specified number of clusters.", "response": "def kmeans_clustering(self, numc, X=None, npcs=15):\n        \"\"\"Performs k-means clustering.\n\n        Parameters\n        ----------\n        numc - int\n            Number of clusters\n\n        npcs - int, optional, default 15\n            Number of principal components to use as inpute for k-means\n            clustering.\n\n        \"\"\"\n\n        from sklearn.cluster import KMeans\n        if X is None:\n            D_sub = self.adata.uns['X_processed']\n            X = (\n                D_sub -\n                D_sub.mean(0)).dot(\n                self.adata.uns['pca_obj'].components_[\n                    :npcs,\n                    :].T)\n            save = True\n        else:\n            save = False\n\n        cl = KMeans(n_clusters=numc).fit_predict(Normalizer().fit_transform(X))\n\n        if save:\n            self.adata.obs['kmeans_clusters'] = pd.Categorical(cl)\n        else:\n            return cl"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identify_marker_genes_rf(self, labels=None, clusters=None,\n                                 n_genes=4000):\n        \"\"\"\n        Ranks marker genes for each cluster using a random forest\n        classification approach.\n\n        Parameters\n        ----------\n\n        labels - numpy.array or str, optional, default None\n            Cluster labels to use for marker gene identification. If None,\n            assumes that one of SAM's clustering algorithms has been run. Can\n            be a string (i.e. 'louvain_clusters', 'kmeans_clusters', etc) to\n            specify specific cluster labels in adata.obs.\n            \n        clusters - int or array-like, default None\n            A number or vector corresponding to the specific cluster ID(s)\n            for which marker genes will be calculated. If None, marker genes\n            will be computed for all clusters.\n\n        n_genes - int, optional, default 4000\n            By default, trains the classifier on the top 4000 SAM-weighted\n            genes.\n\n        \"\"\"\n        if(labels is None):\n            try:\n                keys = np.array(list(self.adata.obs_keys()))\n                lbls = self.adata.obs[ut.search_string(\n                    keys, '_clusters')[0][0]].get_values()\n            except KeyError:\n                print(\"Please generate cluster labels first or set the \"\n                      \"'labels' keyword argument.\")\n                return\n        elif isinstance(labels, str):\n            lbls = self.adata.obs[labels].get_values().flatten()\n        else:\n            lbls = labels\n\n        from sklearn.ensemble import RandomForestClassifier\n\n        markers = {}\n        if clusters == None:\n            lblsu = np.unique(lbls)\n        else:\n            lblsu = np.unique(clusters)\n\n        indices = np.argsort(-self.adata.var['weights'].values)\n        X = self.adata.layers['X_disp'][:, indices[:n_genes]].toarray()\n        for K in range(lblsu.size):\n            print(K)\n            y = np.zeros(lbls.size)\n\n            y[lbls == lblsu[K]] = 1\n\n            clf = RandomForestClassifier(n_estimators=100, max_depth=None,\n                                         random_state=0)\n\n            clf.fit(X, y)\n\n            idx = np.argsort(-clf.feature_importances_)\n\n            markers[lblsu[K]] = self.adata.uns['ranked_genes'][idx]\n        \n        if clusters is None:\n            self.adata.uns['marker_genes_rf'] = markers\n\n        return markers", "response": "This function uses a random forest classification approach to identify marker genes for each cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrank marker genes for each cluster using a SAM-weighted expression-ratio approach (works quite well). Parameters ---------- labels - numpy.array or str, optional, default None Cluster labels to use for marker gene identification. If None, assumes that one of SAM's clustering algorithms has been run. Can be a string (i.e. 'louvain_clusters', 'kmeans_clusters', etc) to specify specific cluster labels in adata.obs.", "response": "def identify_marker_genes_ratio(self, labels=None):\n        \"\"\"\n        Ranks marker genes for each cluster using a SAM-weighted\n        expression-ratio approach (works quite well). \n\n        Parameters\n        ----------\n\n        labels - numpy.array or str, optional, default None\n            Cluster labels to use for marker gene identification. If None,\n            assumes that one of SAM's clustering algorithms has been run. Can\n            be a string (i.e. 'louvain_clusters', 'kmeans_clusters', etc) to\n            specify specific cluster labels in adata.obs.\n\n        \"\"\"\n        if(labels is None):\n            try:\n                keys = np.array(list(self.adata.obs_keys()))\n                lbls = self.adata.obs[ut.search_string(\n                    keys, '_clusters')[0][0]].get_values()\n            except KeyError:\n                print(\"Please generate cluster labels first or set the \"\n                      \"'labels' keyword argument.\")\n                return\n        elif isinstance(labels, str):\n            lbls = self.adata.obs[labels].get_values().flatten()\n        else:\n            lbls = labels\n\n        all_gene_names = np.array(list(self.adata.var_names))\n\n        markers={}\n\n        s = np.array(self.adata.layers['X_disp'].sum(0)).flatten()\n        lblsu=np.unique(lbls)\n        for i in lblsu:\n            d = np.array(self.adata.layers['X_disp']\n                         [lbls == i, :].sum(0)).flatten()\n            rat = np.zeros(d.size)\n            rat[s > 0] = d[s > 0]**2 / s[s > 0] * \\\n                self.adata.var['weights'].values[s > 0]\n            x = np.argsort(-rat)\n            markers[i] = all_gene_names[x[:]]\n\n        self.adata.uns['marker_genes_ratio'] = markers\n\n        return markers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef identify_marker_genes_corr(self, labels=None, n_genes=4000):\n        if(labels is None):\n            try:\n                keys = np.array(list(self.adata.obs_keys()))\n                lbls = self.adata.obs[ut.search_string(\n                    keys, '_clusters')[0][0]].get_values()\n            except KeyError:\n                print(\"Please generate cluster labels first or set the \"\n                      \"'labels' keyword argument.\")\n                return\n        elif isinstance(labels, str):\n            lbls = self.adata.obs[labels].get_values().flatten()\n        else:\n            lbls = labels\n\n\n        w=self.adata.var['weights'].values\n        s = StandardScaler()\n        idxg = np.argsort(-w)[:n_genes]\n        y1=s.fit_transform(self.adata.layers['X_disp'][:,idxg].A)*w[idxg]\n        \n        all_gene_names = np.array(list(self.adata.var_names))[idxg]\n\n        markers = {}\n        lblsu=np.unique(lbls)\n        for i in lblsu:\n            Gcells = np.array(list(self.adata.obs_names[lbls==i]))\n            z1 = y1[np.in1d(self.adata.obs_names,Gcells),:]\n            m1 = (z1 - z1.mean(1)[:,None])/z1.std(1)[:,None]            \n            ref = z1.mean(0)\n            ref = (ref-ref.mean())/ref.std()\n            g2 = (m1*ref).mean(0)    \n            markers[i] = all_gene_names[np.argsort(-g2)]\n            \n\n        self.adata.uns['marker_genes_corr'] = markers\n        return markers", "response": "Identify marker genes based on their respective magnitudes in the cluster - specific reference expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, action=None, subject=None, **conditions):\n        self.add_rule(Rule(True, action, subject, **conditions))", "response": "Add a new entry to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addnot(self, action=None, subject=None, **conditions):\n        self.add_rule(Rule(False, action, subject, **conditions))", "response": "Add a new not rule to the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef can(self, action, subject, **conditions):\n        for rule in self.relevant_rules_for_match(action, subject):\n            if rule.matches_conditions(action, subject, **conditions):\n                return rule.base_behavior\n        return False", "response": "Check if the user has permission to perform a given action on an object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relevant_rules_for_match(self, action, subject):\n        matches = []\n        for rule in self.rules:\n            rule.expanded_actions = self.expand_actions(rule.actions)\n            if rule.is_relevant(action, subject):\n                matches.append(rule)\n\n        return self.optimize(matches[::-1])", "response": "retrive match action and subject"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\naccept an array of actions and returns an array of actions which match", "response": "def expand_actions(self, actions):\n        \"\"\"\n        Accepts an array of actions and returns an array of actions which match\n        \"\"\"\n        r = []\n        for action in actions:\n            r.append(action)\n            if action in self.aliased_actions:\n                r.extend(self.aliased_actions[action])\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef alias_action(self, *args, **kwargs):\n        to = kwargs.pop('to', None)\n        if not to:\n            return\n        error_message = (\"You can't specify target ({}) as alias \"\n                         \"because it is real action name\".format(to)\n                         )\n        if to in list(itertools.chain(*self.aliased_actions.values())):\n            raise Exception(error_message)\n\n        self.aliased_actions.setdefault(to, []).extend(args)", "response": "Alias one or more actions into another one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(table, cols=\"*\", where=(), group=\"\", order=(), limit=(), **kwargs):\r\n    return select(table, cols, where, group, order, limit, **kwargs).fetchall()", "response": "Convenience wrapper for database SELECT and fetch all."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetchone(table, cols=\"*\", where=(), group=\"\", order=(), limit=(), **kwargs):\r\n    return select(table, cols, where, group, order, limit, **kwargs).fetchone()", "response": "Convenience wrapper for database SELECT and fetch one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(table, values=(), **kwargs):\r\n    values = dict(values, **kwargs).items()\r\n    sql, args = makeSQL(\"INSERT\", table, values=values)\r\n    return execute(sql, args).lastrowid", "response": "Convenience wrapper for database INSERT."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(table, values, where=(), **kwargs):\r\n    where = dict(where, **kwargs).items()\r\n    sql, args = makeSQL(\"UPDATE\", table, values=values, where=where)\r\n    return execute(sql, args).rowcount", "response": "Convenience wrapper for database UPDATE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(table, where=(), **kwargs):\r\n    where = dict(where, **kwargs).items()\r\n    sql, args = makeSQL(\"DELETE\", table, where=where)\r\n    return execute(sql, args).rowcount", "response": "Convenience wrapper for database DELETE."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a cursor to the database.", "response": "def make_cursor(path, init_statements=(), _connectioncache={}):\r\n    \"\"\"Returns a cursor to the database, making new connection if not cached.\"\"\"\r\n    connection = _connectioncache.get(path)\r\n    if not connection:\r\n        is_new = not os.path.exists(path) or not os.path.getsize(path)\r\n        try: is_new and os.makedirs(os.path.dirname(path))\r\n        except OSError: pass\r\n        connection = sqlite3.connect(path, isolation_level=None,\r\n            check_same_thread=False, detect_types=sqlite3.PARSE_DECLTYPES)\r\n        for x in init_statements or (): connection.execute(x)\r\n        try: is_new and \":memory:\" not in path.lower() and os.chmod(path, 0707)\r\n        except OSError: pass\r\n        connection.row_factory = lambda cur, row: dict(sqlite3.Row(cur, row))\r\n        _connectioncache[path] = connection\r\n    return connection.cursor()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makeSQL(action, table, cols=\"*\", where=(), group=\"\", order=(), limit=(), values=()):\r\n    cols  =    cols if isinstance(cols,  basestring) else \", \".join(cols)\r\n    group =   group if isinstance(group, basestring) else \", \".join(group)\r\n    order = [order] if isinstance(order, basestring) else order\r\n    limit = [limit] if isinstance(limit, (basestring, int)) else limit\r\n    sql = \"SELECT %s FROM %s\" % (cols, table) if \"SELECT\" == action else \"\"\r\n    sql = \"DELETE FROM %s\"    % (table)       if \"DELETE\" == action else sql\r\n    sql = \"INSERT INTO %s\"    % (table)       if \"INSERT\" == action else sql\r\n    sql = \"UPDATE %s\"         % (table)       if \"UPDATE\" == action else sql\r\n    args = {}\r\n    if \"INSERT\" == action:\r\n        args.update(values)\r\n        cols, vals = (\", \".join(x + k for k, v in values) for x in (\"\", \":\"))\r\n        sql += \" (%s) VALUES (%s)\" % (cols, vals)\r\n    if \"UPDATE\" == action:\r\n        sql += \" SET \"\r\n        for i, (col, val) in enumerate(values):\r\n            sql += (\", \" if i else \"\") + \"%s = :%sU%s\" % (col, col, i)\r\n            args[\"%sU%s\" % (col, i)] = val\r\n    if where:\r\n        sql += \" WHERE \"\r\n        for i, (col, val) in enumerate(where):\r\n            key = \"%sW%s\" % (re.sub(\"\\\\W\", \"_\", col), i)\r\n            dbval = val[1] if isinstance(val, (list, tuple)) else val\r\n            args[key] = dbval\r\n            op = \"IS\" if dbval == val else val[0]\r\n            op = \"=\" if dbval is not None and \"IS\" == op else op\r\n            sql += (\" AND \" if i else \"\") + \"%s %s :%s\" % (col, op, key)\r\n    if group:\r\n        sql += \" GROUP BY \" + group\r\n    if order:\r\n        sql += \" ORDER BY \"\r\n        for i, col in enumerate(order):\r\n            name = col[0] if isinstance(col, (list, tuple)) else col\r\n            direction = \"\" if name == col else \" \" + col[1]\r\n            sql += (\", \" if i else \"\") + name + direction\r\n    if limit:\r\n        sql += \" LIMIT %s\" % (\", \".join(map(str, limit)))\r\n    return sql, args", "response": "Returns a sql statement string and parameter dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef continue_prompt(message=\"\"):\n    answer = False\n    message = message + \"\\n'Yes' or 'No' to continue: \"\n    while answer not in ('Yes', 'No'):\n        answer = prompt(message, eventloop=eventloop())\n        if answer == \"Yes\":\n            answer = True\n            break\n        if answer == \"No\":\n            answer = False\n            break\n    return answer", "response": "Prompt the user to continue or not\n    Returns True when the user type Yes or False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef printo(msg, encoding=None, errors='replace', std_type='stdout'):\n    std = getattr(sys, std_type, sys.stdout)\n    if encoding is None:\n        try:\n            encoding = std.encoding\n        except AttributeError:\n            encoding = None\n    # Fallback to ascii if no encoding is found\n    if encoding is None:\n        encoding = 'ascii'\n    # https://docs.python.org/3/library/sys.html#sys.stdout\n    # write in the binary buffer directly in python3\n    if hasattr(std, 'buffer'):\n        std = std.buffer\n    std.write(msg.encode(encoding, errors=errors))\n    std.write(b'\\n')\n    std.flush()", "response": "Write msg to stdout."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_table(rows, sep='  '):\n    max_col_length = [0] * 100\n    # calculate max length for each col\n    for row in rows:\n        for index, (col, length) in enumerate(zip(row, max_col_length)):\n            if len(text_type(col)) > length:\n                max_col_length[index] = len(text_type(col))\n    formated_rows = []\n    for row in rows:\n        format_str = sep.join([\n            '{:<%s}' % l if i < (len(row) - 1) else '{}'\n            for i, (c, l) in enumerate(zip(row, max_col_length))\n        ])\n        formated_rows.append(format_str.format(*row))\n    return '\\n'.join(formated_rows)", "response": "Format the table of the n - grams."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting a python tree structure into a single object.", "response": "def format_tree(tree):\n    \"\"\"Format a python tree structure\n\n    Given the python tree::\n\n        tree = {\n            'node': ['ROOT', 'This is the root of the tree'],\n            'childs': [{\n                'node': 'A1',\n                'childs': [{\n                    'node': 'B1',\n                    'childs': [{\n                        'node': 'C1'\n                    }]\n                },\n                {\n                    'node': 'B2'\n                }]\n            },\n            {\n                'node': 'A2',\n                'childs': [{\n                    'node': 'B3',\n                    'childs': [{\n                        'node': ['C2', 'This is a leaf']\n                    },\n                    {\n                        'node': 'C3'\n                    }]\n                }]\n            },\n            {\n                'node': ['A3', 'This is a node'],\n                'childs': [{\n                    'node': 'B2'\n                }]\n            }]\n        }\n\n    `format_tree` will return::\n\n        ROOT            This is the root of the tree\n        \u251c\u2500\u2500 A1\n        \u2502   \u251c\u2500\u2500 B1\n        \u2502   \u2502   \u2514\u2500\u2500 C1\n        \u2502   \u2514\u2500\u2500 B2\n        \u251c\u2500\u2500 A2\n        \u2502   \u2514\u2500\u2500 B3\n        \u2502       \u251c\u2500\u2500 C2  This is a leaf\n        \u2502       \u2514\u2500\u2500 C3\n        \u2514\u2500\u2500 A3          This is a node\n            \u2514\u2500\u2500 B2\n\n    \"\"\"\n\n    def _traverse_tree(tree, parents=None):\n        tree['parents'] = parents\n        childs = tree.get('childs', [])\n        nb_childs = len(childs)\n        for index, child in enumerate(childs):\n            child_parents = list(parents) + [index == nb_childs - 1]\n            tree['childs'][index] = _traverse_tree(\n                tree['childs'][index],\n                parents=child_parents)\n        return tree\n\n    tree = _traverse_tree(tree, parents=[])\n\n    def _get_rows_data(tree, rows):\n        prefix = ''\n        for p in tree['parents'][:-1]:\n            if p is False:\n                prefix += '\u2502   '\n            else:\n                prefix += '    '\n        if not tree['parents']:\n            pass\n        elif tree['parents'][-1] is True:\n            prefix += '\u2514\u2500\u2500 '\n        else:\n            prefix += '\u251c\u2500\u2500 '\n        if isinstance(tree['node'], string_types):\n            tree['node'] = [tree['node']]\n        rows.append([prefix + tree['node'][0]] + tree['node'][1:])\n        for child in tree.get('childs', []):\n            rows = _get_rows_data(child, rows)\n        return rows\n\n    rows = _get_rows_data(tree, [])\n    return format_table(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping a function over a list of elements", "response": "def parallel_map(func, iterable, args=None, kwargs=None, workers=None):\n    \"\"\"Map func on a list using gevent greenlets.\n\n    :param func: function applied on iterable elements\n    :type func: function\n    :param iterable: elements to map the function over\n    :type iterable: iterable\n    :param args: arguments of func\n    :type args: tuple\n    :param kwargs: keyword arguments of func\n    :type kwargs: dict\n    :param workers: limit the number of greenlets\n                    running in parrallel\n    :type workers: int\n    \"\"\"\n    if args is None:\n        args = ()\n    if kwargs is None:\n        kwargs = {}\n    if workers is not None:\n        pool = Pool(workers)\n    else:\n        pool = Group()\n    iterable = [pool.spawn(func, i, *args, **kwargs) for i in iterable]\n    pool.join(raise_error=True)\n    for idx, i in enumerate(iterable):\n        i_type = type(i.get())\n        i_value = i.get()\n        if issubclass(i_type, BaseException):\n            raise i_value\n        iterable[idx] = i_value\n    return iterable"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseFloat(self, words):\n        def pointFloat(words):\n            m = re.search(r'(.*) point (.*)', words)\n            if m:\n                whole = m.group(1)\n                frac = m.group(2)\n                total = 0.0\n                coeff = 0.10\n                for digit in frac.split(' '):\n                    total += coeff * self.parse(digit)\n                    coeff /= 10.0\n\n                return self.parseInt(whole) + total\n            return None\n\n        def fractionFloat(words):\n            m = re.search(r'(.*) and (.*)', words)\n            if m:\n                whole = self.parseInt(m.group(1))\n                frac = m.group(2)\n\n                # Replace plurals\n                frac = re.sub(r'(\\w+)s(\\b)', '\\g<1>\\g<2>', frac)\n\n                # Convert 'a' to 'one' (e.g., 'a third' to 'one third')\n                frac = re.sub(r'(\\b)a(\\b)', '\\g<1>one\\g<2>', frac)\n\n                split = frac.split(' ')\n\n                # Split fraction into num (regular integer), denom (ordinal)\n                num = split[:1]\n                denom = split[1:]\n\n                while denom:\n                    try:\n                        # Test for valid num, denom\n                        num_value = self.parse(' '.join(num))\n                        denom_value = self.parse(' '.join(denom))\n                        return whole + float(num_value) / denom_value\n                    except:\n                        # Add another word to num\n                        num += denom[:1]\n                        denom = denom[1:]\n            return None\n\n        # Extract \"one point two five\"-type float\n        result = pointFloat(words)\n        if result:\n            return result\n\n        # Extract \"one and a quarter\"-type float\n        result = fractionFloat(words)\n        if result:\n            return result\n\n        # Parse as integer\n        return self.parseInt(words)", "response": "Convert a floating - point number described in words to a double."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the words to the integer representation of the words.", "response": "def parseInt(self, words):\n        \"\"\"Parses words to the integer they describe.\n\n        Args:\n            words (str): Description of the integer.\n\n        Returns:\n            An integer representation of the words.\n        \"\"\"\n        # Remove 'and', case-sensitivity\n        words = words.replace(\" and \", \" \").lower()\n        # 'a' -> 'one'\n        words = re.sub(r'(\\b)a(\\b)', '\\g<1>one\\g<2>', words)\n\n        def textToNumber(s):\n            \"\"\"\n            Converts raw number string to an integer.\n            Based on text2num.py by Greg Hewill.\n            \"\"\"\n            a = re.split(r\"[\\s-]+\", s)\n            n = 0\n            g = 0\n            for w in a:\n                x = NumberService.__small__.get(w, None)\n                if x is not None:\n                    g += x\n                elif w == \"hundred\":\n                    g *= 100\n                else:\n                    x = NumberService.__magnitude__.get(w, None)\n                    if x is not None:\n                        n += g * x\n                        g = 0\n                    else:\n                        raise NumberService.NumberException(\n                            \"Unknown number: \" + w)\n            return n + g\n\n        return textToNumber(words)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseMagnitude(m):\n        m = NumberService().parse(m)\n\n        def toDecimalPrecision(n, k):\n            return float(\"%.*f\" % (k, round(n, k)))\n\n        # Cast to two digits of precision\n        digits = 2\n        magnitude = toDecimalPrecision(m, digits)\n\n        # If value is really small, keep going\n        while not magnitude:\n            digits += 1\n            magnitude = toDecimalPrecision(m, digits)\n\n        # If item is less than one, go one beyond 'necessary' number of digits\n        if m < 1.0:\n            magnitude = toDecimalPrecision(m, digits + 1)\n\n        # Ignore decimal accuracy if irrelevant\n        if int(magnitude) == magnitude:\n            magnitude = int(magnitude)\n\n        # Adjust for scientific notation\n        magString = str(magnitude)\n        magString = re.sub(r'(\\d)e-(\\d+)',\n                           '\\g<1> times ten to the negative \\g<2>', magString)\n        magString = re.sub(r'(\\d)e\\+(\\d+)',\n                           '\\g<1> times ten to the \\g<2>', magString)\n        magString = re.sub(r'-(\\d+)', 'negative \\g<1>', magString)\n        magString = re.sub(r'\\b0(\\d+)', '\\g<1>', magString)\n        return magString", "response": "Parses a number m into a human - ready string representation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef longestNumber(self, inp):\n        split = inp.split(' ')\n\n        # Assume just a single number\n        numStart = None\n        numEnd = None\n        for i, w in enumerate(split):\n            if self.isValid(w):\n                if numStart is None:\n                    numStart = i\n                numEnd = i\n            else:\n                # Check for ordinal, which would signify end\n                w = re.sub(r'(\\w+)s(\\b)', '\\g<1>\\g<2>', w)\n                if w in self.__ordinals__:\n                    if self.isValid(' '.join(split[numStart:i + 1])):\n                        numEnd = i\n                        break\n        description = ' '.join(split[numStart:numEnd + 1])\n        return self.parse(description)", "response": "Extracts the longest valid numerical description from a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing the private part of the key in a base64 format by default.", "response": "def serialize(self, raw=False):\n        '''Encode the private part of the key in a base64 format by default,\n        but when raw is True it will return hex encoded bytes.\n        @return: bytes\n        '''\n        if raw:\n            return self._key.encode()\n        return self._key.encode(nacl.encoding.Base64Encoder)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a PublicKey from a base64 encoded bytes.", "response": "def deserialize(cls, serialized):\n        ''' Create a PublicKey from a base64 encoded bytes.\n        :return: a PublicKey\n        '''\n        return PublicKey(\n            nacl.public.PublicKey(serialized,\n                                  encoder=nacl.encoding.Base64Encoder))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a response content and headers that can be used to set a discharge macaroon.", "response": "def discharge_required_response(macaroon, path, cookie_suffix_name,\n                                message=None):\n    ''' Get response content and headers from a discharge macaroons error.\n\n    @param macaroon may hold a macaroon that, when discharged, may\n    allow access to a service.\n    @param path holds the URL path to be associated with the macaroon.\n    The macaroon is potentially valid for all URLs under the given path.\n    @param cookie_suffix_name holds the desired cookie name suffix to be\n    associated with the macaroon. The actual name used will be\n    (\"macaroon-\" + CookieName). Clients may ignore this field -\n    older clients will always use (\"macaroon-\" + macaroon.signature() in hex)\n    @return content(bytes) and the headers to set on the response(dict).\n    '''\n    if message is None:\n        message = 'discharge required'\n    content = json.dumps(\n        {\n            'Code': 'macaroon discharge required',\n            'Message': message,\n            'Info': {\n                'Macaroon': macaroon.to_dict(),\n                'MacaroonPath': path,\n                'CookieNameSuffix': cookie_suffix_name\n            },\n        }\n    ).encode('utf-8')\n    return content, {\n        'WWW-Authenticate': 'Macaroon',\n        'Content-Type': 'application/json'\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the bakery protocol version from a client request headers.", "response": "def request_version(req_headers):\n    ''' Determines the bakery protocol version from a client request.\n    If the protocol cannot be determined, or is invalid, the original version\n    of the protocol is used. If a later version is found, the latest known\n    version is used, which is OK because versions are backwardly compatible.\n\n    @param req_headers: the request headers as a dict.\n    @return: bakery protocol version (for example macaroonbakery.VERSION_1)\n    '''\n    vs = req_headers.get(BAKERY_PROTOCOL_HEADER)\n    if vs is None:\n        # No header - use backward compatibility mode.\n        return bakery.VERSION_1\n    try:\n        x = int(vs)\n    except ValueError:\n        # Badly formed header - use backward compatibility mode.\n        return bakery.VERSION_1\n    if x > bakery.LATEST_VERSION:\n        # Later version than we know about - use the\n        # latest version that we can.\n        return bakery.LATEST_VERSION\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an error from a JSON - deserialized object holding the serialized error.", "response": "def from_dict(cls, serialized):\n        '''Create an error from a JSON-deserialized object\n        @param serialized the object holding the serialized error {dict}\n        '''\n        # Some servers return lower case field names for message and code.\n        # The Go client is tolerant of this, so be similarly tolerant here.\n        def field(name):\n            return serialized.get(name) or serialized.get(name.lower())\n        return Error(\n            code=field('Code'),\n            message=field('Message'),\n            info=ErrorInfo.from_dict(field('Info')),\n            version=bakery.LATEST_VERSION,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether the error is an InteractionRequired error with the given name and JSON - serializes the method - specific data into x by calling its from_dict method with the deserialized JSON object.", "response": "def interaction_method(self, kind, x):\n        ''' Checks whether the error is an InteractionRequired error\n        that implements the method with the given name, and JSON-unmarshals the\n        method-specific data into x by calling its from_dict method\n        with the deserialized JSON object.\n        @param kind The interaction method kind (string).\n        @param x A class with a class method from_dict that returns a new\n        instance of the interaction info for the given kind.\n        @return The result of x.from_dict.\n        '''\n        if self.info is None or self.code != ERR_INTERACTION_REQUIRED:\n            raise InteractionError(\n                'not an interaction-required error (code {})'.format(\n                    self.code)\n            )\n        entry = self.info.interaction_methods.get(kind)\n        if entry is None:\n            raise InteractionMethodNotFound(\n                'interaction method {} not found'.format(kind)\n            )\n        return x.from_dict(entry)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new ErrorInfo object from a JSON deserialized object.", "response": "def from_dict(cls, serialized):\n        '''Create a new ErrorInfo object from a JSON deserialized\n        dictionary\n        @param serialized The JSON object {dict}\n        @return ErrorInfo object\n        '''\n        if serialized is None:\n            return None\n        macaroon = serialized.get('Macaroon')\n        if macaroon is not None:\n            macaroon = bakery.Macaroon.from_dict(macaroon)\n        path = serialized.get('MacaroonPath')\n        cookie_name_suffix = serialized.get('CookieNameSuffix')\n        visit_url = serialized.get('VisitURL')\n        wait_url = serialized.get('WaitURL')\n        interaction_methods = serialized.get('InteractionMethods')\n        return ErrorInfo(macaroon=macaroon, macaroon_path=path,\n                         cookie_name_suffix=cookie_name_suffix,\n                         visit_url=visit_url, wait_url=wait_url,\n                         interaction_methods=interaction_methods)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def dump_blob(elem, elem_type=None):\n    elem_is_blob = isinstance(elem, x.BlobType)\n    data = getattr(elem, x.BlobType.DATA_ATTR) if elem_is_blob else elem\n    if data is None or len(data) == 0:\n        return b''\n    if isinstance(data, (bytes, bytearray, list)):\n        return base64.b16encode(bytes(data))\n    else:\n        raise ValueError('Unknown blob type')", "response": "Dumps blob message.\n    Supports both blob and raw value.\n\n    :param writer:\n    :param elem:\n    :param elem_type:\n    :param params:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def dump_container(obj, container, container_type, params=None, field_archiver=None):\n    field_archiver = field_archiver if field_archiver else dump_field\n    elem_type = params[0] if params else None\n    if elem_type is None:\n        elem_type = container_type.ELEM_TYPE\n\n    obj = [] if obj is None else get_elem(obj)\n    if container is None:\n        return None\n    for elem in container:\n        fvalue = await field_archiver(None, elem, elem_type, params[1:] if params else None)\n        obj.append(fvalue)\n    return obj", "response": "Serializes a container as popo\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def load_container(obj, container_type, params=None, container=None, field_archiver=None):\n    field_archiver = field_archiver if field_archiver else load_field\n    if obj is None:\n        return None\n\n    c_len = len(obj)\n    elem_type = params[0] if params else None\n    if elem_type is None:\n        elem_type = container_type.ELEM_TYPE\n\n    res = container if container else []\n    for i in range(c_len):\n        fvalue = await field_archiver(obj[i], elem_type,\n                                      params[1:] if params else None,\n                                      eref(res, i) if container else None)\n        if not container:\n            res.append(fvalue)\n    return res", "response": "Load a container of elements from the object representation. Supports the container ref."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a message field to the object.", "response": "async def dump_message_field(obj, msg, field, field_archiver=None):\n    \"\"\"\n    Dumps a message field to the object. Field is defined by the message field specification.\n\n    :param obj:\n    :param msg:\n    :param field:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    fname, ftype, params = field[0], field[1], field[2:]\n    fvalue = getattr(msg, fname, None)\n    field_archiver = field_archiver if field_archiver else dump_field\n    return await field_archiver(eref(obj, fname, True), fvalue, ftype, params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload message field from the object.", "response": "async def load_message_field(obj, msg, field, field_archiver=None):\n    \"\"\"\n    Loads message field from the object. Field is defined by the message field specification.\n    Returns loaded value, supports field reference.\n\n    :param reader:\n    :param msg:\n    :param field:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    fname, ftype, params = field[0], field[1], field[2:]\n    field_archiver = field_archiver if field_archiver else load_field\n    await field_archiver(obj[fname], ftype, params, eref(msg, fname))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def dump_message(obj, msg, field_archiver=None):\n    mtype = msg.__class__\n    fields = mtype.f_specs()\n\n    obj = collections.OrderedDict() if obj is None else get_elem(obj)\n    for field in fields:\n        await dump_message_field(obj, msg=msg, field=field, field_archiver=field_archiver)\n    return obj", "response": "Dumps message to the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a message from the given object.", "response": "async def load_message(obj, msg_type, msg=None, field_archiver=None):\n    \"\"\"\n    Loads message if the given type from the object.\n    Supports reading directly to existing message.\n\n    :param obj:\n    :param msg_type:\n    :param msg:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    msg = msg_type() if msg is None else msg\n\n    fields = msg_type.f_specs() if msg_type else msg.__class__.f_specs()\n    for field in fields:\n        await load_message_field(obj, msg, field, field_archiver=field_archiver)\n\n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform a popo object representation.", "response": "async def dump_variant(obj, elem, elem_type=None, params=None, field_archiver=None):\n    \"\"\"\n    Transform variant to the popo object representation.\n\n    :param obj:\n    :param elem:\n    :param elem_type:\n    :param params:\n    :param field_archiver:\n    :return:\n    \"\"\"\n    field_archiver = field_archiver if field_archiver else dump_field\n    if isinstance(elem, x.VariantType) or elem_type.WRAPS_VALUE:\n        return {\n            elem.variant_elem: await field_archiver(None, getattr(elem, elem.variant_elem), elem.variant_elem_type)\n        }\n\n    else:\n        fdef = elem_type.find_fdef(elem_type.f_specs(), elem)\n        return {\n            fdef[0]: await field_archiver(None, elem, fdef[1])\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def load_variant(obj, elem, elem_type=None, params=None, field_archiver=None, wrapped=None):\n    field_archiver = field_archiver if field_archiver else load_field\n    is_wrapped = elem_type.WRAPS_VALUE if wrapped is None else wrapped\n\n    if is_wrapped:\n        elem = elem_type() if elem is None else elem\n\n    fname = list(obj.keys())[0]\n    for field in elem_type.f_specs():\n        if field[0] != fname:\n            continue\n\n        fvalue = await field_archiver(obj[fname], field[1], field[2:], elem if not is_wrapped else None)\n        if is_wrapped:\n            elem.set_variant(field[0], fvalue)\n\n        return elem if is_wrapped else fvalue\n    raise ValueError('Unknown tag: %s' % fname)", "response": "Load a single element from the obj representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping generic field to the popo object representation according to the element specification.", "response": "async def dump_field(obj, elem, elem_type, params=None):\n    \"\"\"\n    Dumps generic field to the popo object representation, according to the element specification.\n    General multiplexer.\n\n    :param obj:\n    :param elem:\n    :param elem_type:\n    :param params:\n    :return:\n    \"\"\"\n    if isinstance(elem, (int, bool)) or issubclass(elem_type, x.UVarintType) or issubclass(elem_type, x.IntType):\n        return set_elem(obj, elem)\n\n    elif issubclass(elem_type, x.BlobType) or isinstance(obj, bytes) or isinstance(obj, bytearray):\n        return set_elem(obj, await dump_blob(elem))\n\n    elif issubclass(elem_type, x.UnicodeType) or isinstance(elem, str):\n        return set_elem(obj, elem)\n\n    elif issubclass(elem_type, x.VariantType):\n        return set_elem(obj, await dump_variant(None, elem, elem_type, params))\n\n    elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n        return set_elem(obj, await dump_container(None, elem, elem_type, params))\n\n    elif issubclass(elem_type, x.MessageType):\n        return set_elem(obj, await dump_message(None, elem))\n\n    else:\n        raise TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a single field from the reader based on the field type specification.", "response": "async def load_field(obj, elem_type, params=None, elem=None):\n    \"\"\"\n    Loads a field from the reader, based on the field type specification. Demultiplexer.\n\n    :param obj:\n    :param elem_type:\n    :param params:\n    :param elem:\n    :return:\n    \"\"\"\n    if issubclass(elem_type, x.UVarintType) or issubclass(elem_type, x.IntType) or isinstance(obj, (int, bool)):\n        return set_elem(elem, obj)\n\n    elif issubclass(elem_type, x.BlobType):\n        fvalue = await load_blob(obj, elem_type)\n        return set_elem(elem, fvalue)\n\n    elif issubclass(elem_type, x.UnicodeType) or isinstance(elem, str):\n        return set_elem(elem, obj)\n\n    elif issubclass(elem_type, x.VariantType):\n        fvalue = await load_variant(obj, elem=get_elem(elem), elem_type=elem_type, params=params)\n        return set_elem(elem, fvalue)\n\n    elif issubclass(elem_type, x.ContainerType):  # container ~ simple list\n        fvalue = await load_container(obj, elem_type, params=params, container=get_elem(elem))\n        return set_elem(elem, fvalue)\n\n    elif issubclass(elem_type, x.MessageType):\n        fvalue = await load_message(obj, msg_type=elem_type, msg=get_elem(elem))\n        return set_elem(elem, fvalue)\n\n    else:\n        raise TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextends the given validator with the Seep layer.", "response": "def extend(validator_cls):\n    \"\"\"\n    Extend the given :class:`jsonschema.IValidator` with the Seep layer.\n\n    \"\"\"\n\n    Validator = jsonschema.validators.extend(\n        validator_cls, {\n            \"properties\": _properties_with_defaults(validator_cls),\n        }\n    )\n\n    class Blueprinter(Validator):\n        def instantiate(self, data):\n            self.validate(data)\n            return data\n\n    return Blueprinter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(argv=None):\n    from vsgen import VSGSuite\n    from vsgen import VSGLogger\n\n    # Special case to use the sys.argv when main called without a list.\n    if argv is None:\n        argv = sys.argv\n\n    # Initialize the application logger\n    pylogger = VSGLogger()\n\n    # Construct a command line parser and parse the command line\n    args = VSGSuite.make_parser(description='Executes the vsgen package as an application.').parse_args(argv[1:])\n    for s in VSGSuite.from_args(**vars(args)):\n        s.write(False)\n    return 0", "response": "Entry point of the script."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares model fields attribute.", "response": "def prepare_fields_attribute(attribute_name, attributes, class_name):\n        \"\"\"Prepare model fields attribute.\"\"\"\n        attribute = attributes.get(attribute_name)\n        if not attribute:\n            attribute = tuple()\n        elif isinstance(attribute, std_collections.Iterable):\n            attribute = tuple(attribute)\n        else:\n            raise errors.Error('{0}.{1} is supposed to be a list of {2}, '\n                               'instead {3} given', class_name, attribute_name,\n                               fields.Field, attribute)\n        return attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bind_fields_to_model_cls(cls, model_fields):\n        return dict(\n            (field.name, field.bind_model_cls(cls)) for field in model_fields)", "response": "Bind fields to model class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbind collection to model s class.", "response": "def bind_collection_to_model_cls(cls):\n        \"\"\"Bind collection to model's class.\n\n        If collection was not specialized in process of model's declaration,\n        subclass of collection will be created.\n        \"\"\"\n        cls.Collection = type('{0}.Collection'.format(cls.__name__),\n                              (cls.Collection,),\n                              {'value_type': cls})\n        cls.Collection.__module__ = cls.__module__"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbumping version of the current project.", "response": "def bump_version(ctx, new_version, version_part=None, dry_run=False):\n    \"\"\"Bump version (to prepare a new release).\"\"\"\n    version_part = version_part or \"minor\"\n    if dry_run:\n        ctx = DryRunContext(ctx)\n    ctx.run(\"bumpversion --new-version={} {}\".format(new_version,\n                                                      version_part))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds packages for this release.", "response": "def build_packages(ctx, hide=False):\n    \"\"\"Build packages for this release.\"\"\"\n    print(\"build_packages:\")\n    ctx.run(\"python setup.py sdist bdist_wheel\", echo=True, hide=hide)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the release: bump version, build packages, ...", "response": "def prepare(ctx, new_version=None, version_part=None, hide=True,\n            dry_run=False):\n    \"\"\"Prepare the release: bump version, build packages, ...\"\"\"\n    if new_version is not None:\n        bump_version(ctx, new_version, version_part=version_part,\n                     dry_run=dry_run)\n    build_packages(ctx, hide=hide)\n    packages = ensure_packages_exist(ctx, check_only=True)\n    print_packages(packages)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering release packages in artifact - store or repository.", "response": "def register_packages(ctx, repo=None, dry_run=False):\n    \"\"\"Register release (packages) in artifact-store/repository.\"\"\"\n    original_ctx = ctx\n    if repo is None:\n        repo = ctx.project.repo or \"pypi\"\n    if dry_run:\n        ctx = DryRunContext(ctx)\n\n    packages = ensure_packages_exist(original_ctx)\n    print_packages(packages)\n    for artifact in packages:\n        ctx.run(\"twine register --repository={repo} {artifact}\".format(\n                artifact=artifact, repo=repo))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, name, function, description=None):\n        return self.__app.threads.register(name, function, self._plugin, description)", "response": "Register a new thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new thread with the given name.", "response": "def register(self, name, function, plugin, description=None):\n        \"\"\"\n        Registers a new document.\n\n        .. warning: You can not use any relative links inside a given document.\n                    For instance, sphinx's toctree, image, figure or include statements do not work.\n\n        :param function: Function, which gets called for the new thread\n        :type function: function\n        :param name: Unique name of the thread for documentation purposes.\n        :param plugin: Plugin object, under which the threads where registered\n        :type plugin: GwBasePattern\n        :param description: Short description of the thread\n        \"\"\"\n        if name in self.threads.keys():\n            raise ThreadExistsException(\"Thread %s was already registered by %s\" %\n                                        (name, self.threads[name].plugin.name))\n\n        self.threads[name] = Thread(name, function, plugin, description)\n        self.__log.debug(\"Thread %s registered by %s\" % (name, plugin.name))\n        return self.threads[name]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting one or more threads.", "response": "def get(self, thread=None, plugin=None):\n        \"\"\"\n        Get one or more threads.\n\n        :param thread: Name of the thread\n        :type thread: str\n        :param plugin: Plugin object, under which the thread was registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if thread is None:\n                threads_list = {}\n                for key in self.threads.keys():\n                    if self.threads[key].plugin == plugin:\n                        threads_list[key] = self.threads[key]\n                return threads_list\n            else:\n                if thread in self.threads.keys():\n                    if self.threads[thread].plugin == plugin:\n                        return self.threads[thread]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if thread is None:\n                return self.threads\n            else:\n                if thread in self.threads.keys():\n                    return self.threads[thread]\n                else:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and fill the schema from a directory which contains xsd files. It calls fill_schema_from_xsd_file for each xsd file found.", "response": "def create_schema_from_xsd_directory(directory, version):\n    \"\"\"Create and fill the schema from a directory which contains xsd\n    files. It calls fill_schema_from_xsd_file for each xsd file\n    found.\n\n    \"\"\"\n    schema = Schema(version)\n    for f in _get_xsd_from_directory(directory):\n        logger.info(\"Loading schema %s\" % f)\n        fill_schema_from_xsd_file(f, schema)\n    return schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the P4 env vars using set p4", "response": "def __getVariables(self):\n        \"\"\"Parses the P4 env vars using 'set p4'\"\"\"\n        try:\n            startupinfo = None\n            if os.name == 'nt':\n                startupinfo = subprocess.STARTUPINFO()\n                startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n            output = subprocess.check_output(['p4', 'set'], startupinfo=startupinfo)\n            if six.PY3:\n                output = str(output, 'utf8')\n        except subprocess.CalledProcessError as err:\n            LOGGER.error(err)\n            return\n\n        p4vars = {}\n        for line in output.splitlines():\n            if not line:\n                continue\n            try:\n                k, v = line.split('=', 1)\n            except ValueError:\n                continue\n            p4vars[k.strip()] = v.strip().split(' (')[0]\n            if p4vars[k.strip()].startswith('(config'):\n                del p4vars[k.strip()]\n\n        self._port = self._port or os.getenv('P4PORT', p4vars.get('P4PORT'))\n        self._user = self._user or os.getenv('P4USER', p4vars.get('P4USER'))\n        self._client = self._client or os.getenv('P4CLIENT', p4vars.get('P4CLIENT'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef client(self):\n        if isinstance(self._client, six.string_types):\n            self._client = Client(self._client, self)\n\n        return self._client", "response": "The client used in perforce queries"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a p4 command and returns a list of dictionary objects.", "response": "def run(self, cmd, stdin=None, marshal_output=True, **kwargs):\n        \"\"\"Runs a p4 command and returns a list of dictionary objects\n\n        :param cmd: Command to run\n        :type cmd: list\n        :param stdin: Standard Input to send to the process\n        :type stdin: str\n        :param marshal_output: Whether or not to marshal the output from the command\n        :type marshal_output: bool\n        :param kwargs: Passes any other keyword arguments to subprocess\n        :raises: :class:`.error.CommandError`\n        :returns: list, records of results\n        \"\"\"\n        records = []\n        args = [self._executable, \"-u\", self._user, \"-p\", self._port]\n\n        if self._client:\n            args += [\"-c\", str(self._client)]\n\n        if marshal_output:\n            args.append('-G')\n\n        if isinstance(cmd, six.string_types):\n            raise ValueError('String commands are not supported, please use a list')\n\n        args += cmd\n\n        command = ' '.join(args)\n\n        startupinfo = None\n        if os.name == 'nt':\n            startupinfo = subprocess.STARTUPINFO()\n            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n\n        proc = subprocess.Popen(\n            args,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            startupinfo=startupinfo,\n            **kwargs\n        )\n\n        if stdin:\n            proc.stdin.write(six.b(stdin))\n\n        if marshal_output:\n            try:\n                while True:\n                    record = marshal.load(proc.stdout)\n                    if record.get(b'code', '') == b'error' and record[b'severity'] >= self._level:\n                        proc.stdin.close()\n                        proc.stdout.close()\n                        raise errors.CommandError(record[b'data'], record, command)\n                    if isinstance(record, dict):\n                        if six.PY2:\n                            records.append(record)\n                        else:\n                            records.append({str(k, 'utf8'): str(v) if isinstance(v, int) else str(v, 'utf8', errors='ignore') for k, v in record.items()})\n            except EOFError:\n                pass\n\n            stdout, stderr = proc.communicate()\n        else:\n            records, stderr = proc.communicate()\n\n        if stderr:\n            raise errors.CommandError(stderr, command)\n\n        return records"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ls(self, files, silent=True, exclude_deleted=False):\n        try:\n            cmd = ['fstat']\n            if exclude_deleted:\n                cmd += ['-F', '^headAction=delete ^headAction=move/delete']\n\n            cmd += files\n\n            results = self.run(cmd)\n        except errors.CommandError as err:\n            if silent:\n                results = []\n            elif \"is not under client's root\" in str(err):\n                raise errors.RevisionError(err.args[0])\n            else:\n                raise\n\n        return [Revision(r, self) for r in results if r.get('code') != 'error']", "response": "List files in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting or creates a Changelist object with a description", "response": "def findChangelist(self, description=None):\n        \"\"\"Gets or creates a Changelist object with a description\n\n        :param description: The description to set or lookup\n        :type description: str\n        :returns: :class:`.Changelist`\n        \"\"\"\n        if description is None:\n            change = Default(self)\n        else:\n            if isinstance(description, six.integer_types):\n                change = Changelist(description, self)\n            else:\n                pending = self.run(['changes', '-l', '-s', 'pending', '-c', str(self._client), '-u', self._user])\n                for cl in pending:\n                    if cl['desc'].strip() == description.strip():\n                        LOGGER.debug('Changelist found: {}'.format(cl['change']))\n                        change = Changelist(int(cl['change']), self)\n                        break\n                else:\n                    LOGGER.debug('No changelist found, creating one')\n                    change = Changelist.create(description, self)\n                    change.client = self._client\n                    change.save()\n\n        return change"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, filename, change=None):\n        try:\n            if not self.canAdd(filename):\n                raise errors.RevisionError('File is not under client path')\n\n            if change is None:\n                self.run(['add', filename])\n            else:\n                self.run(['add', '-c', str(change.change), filename])\n\n            data = self.run(['fstat', filename])[0]\n        except errors.CommandError as err:\n            LOGGER.debug(err)\n            raise errors.RevisionError('File is not under client path')\n\n        rev = Revision(data, self)\n\n        if isinstance(change, Changelist):\n            change.append(rev)\n\n        return rev", "response": "Adds a new file to a changelist."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if a filename can be added to the current client s depot under the current client s depot under the current client s depot.", "response": "def canAdd(self, filename):\n        \"\"\"Determines if a filename can be added to the depot under the current client\n\n        :param filename: File path to add\n        :type filename: str\n        \"\"\"\n        try:\n            result = self.run(['add', '-n', '-t', 'text', filename])[0]\n        except errors.CommandError as err:\n            LOGGER.debug(err)\n            return False\n\n        if result.get('code') not in ('error', 'info'):\n            return True\n\n        LOGGER.warn('Unable to add {}: {}'.format(filename, result['data']))\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self):\n        if not self._dirty:\n            return\n\n        fields = []\n        formdata = dict(self._p4dict)\n        del formdata['code']\n        for key, value in six.iteritems(formdata):\n            match = re.search('\\d$', key)\n            if match:\n                value = '\\t{}'.format(value)\n                key = key[:match.start()]\n\n            value = value.replace('\\n', '\\n\\t')\n            fields.append('{}:  {}'.format(key, value))\n        form = '\\n'.join(fields)\n        self._connection.run([self.COMMAND, '-i'], stdin=form, marshal_output=False)\n        self._dirty = False", "response": "Saves the state of the changelist"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the depot to get the current status of the changelist", "response": "def query(self, files=True):\n        \"\"\"Queries the depot to get the current status of the changelist\"\"\"\n        if self._change:\n            cl = str(self._change)\n            self._p4dict = {camel_case(k): v for k, v in six.iteritems(self._connection.run(['change', '-o', cl])[0])}\n\n        if files:\n            self._files = []\n            if self._p4dict.get('status') == 'pending' or self._change == 0:\n                change = self._change or 'default'\n                data = self._connection.run(['opened', '-c', str(change)])\n                self._files = [Revision(r, self._connection) for r in data]\n            else:\n                data = self._connection.run(['describe', str(self._change)])[0]\n                depotfiles = []\n                for k, v in six.iteritems(data):\n                    if k.startswith('depotFile'):\n                        depotfiles.append(v)\n                self._files = self._connection.ls(depotfiles)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a revision to this changelist and checks it out if needed", "response": "def append(self, rev):\n        \"\"\"Adds a :py:class:Revision to this changelist and adds or checks it out if needed\n\n        :param rev: Revision to add\n        :type rev: :class:`.Revision`\n        \"\"\"\n        if not isinstance(rev, Revision):\n            results = self._connection.ls(rev)\n            if not results:\n                self._connection.add(rev, self)\n                return\n\n            rev = results[0]\n\n        if not rev in self:\n            if rev.isMapped:\n                rev.edit(self)\n\n            self._files.append(rev)\n            rev.changelist = self\n\n            self._dirty = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a revision from the changelist.", "response": "def remove(self, rev, permanent=False):\n        \"\"\"Removes a revision from this changelist\n\n        :param rev: Revision to remove\n        :type rev: :class:`.Revision`\n        :param permanent: Whether or not we need to set the changelist to default\n        :type permanent: bool\n        \"\"\"\n        if not isinstance(rev, Revision):\n            raise TypeError('argument needs to be an instance of Revision')\n\n        if rev not in self:\n            raise ValueError('{} not in changelist'.format(rev))\n\n        self._files.remove(rev)\n        if not permanent:\n            rev.changelist = self._connection.default"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revert(self, unchanged_only=False):\n        if self._reverted:\n            raise errors.ChangelistError('This changelist has been reverted')\n\n        change = self._change\n        if self._change == 0:\n            change = 'default'\n\n        cmd = ['revert', '-c', str(change)]\n\n        if unchanged_only:\n            cmd.append('-a')\n\n        files = [f.depotFile for f in self._files]\n        if files:\n            cmd += files\n            self._connection.run(cmd)\n\n        self._files = []\n        self._reverted = True", "response": "Revert all files in this changelist to the original state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self):\n        self._connection.run(['change', '-i'], stdin=format(self), marshal_output=False)\n        self._dirty = False", "response": "Saves the state of the changelist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit(self):\n        if self._dirty:\n            self.save()\n\n        self._connection.run(['submit', '-c', str(self._change)], marshal_output=False)", "response": "Submits a chagelist to the depot"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self):\n        try:\n            self.revert()\n        except errors.ChangelistError:\n            pass\n\n        self._connection.run(['change', '-d', str(self._change)])", "response": "Delete all files in this changelist then deletes the changelist from perforce"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new changelist with the given description", "response": "def create(description='<Created by Python>', connection=None):\n        \"\"\"Creates a new changelist\n\n        :param connection: Connection to use to create the changelist\n        :type connection: :class:`.Connection`\n        :param description: Description for new changelist\n        :type description: str\n        :returns: :class:`.Changelist`\n        \"\"\"\n        connection = connection or Connection()\n        description = description.replace('\\n', '\\n\\t')\n        form = NEW_FORMAT.format(client=str(connection.client), description=description)\n        result = connection.run(['change', '-i'], stdin=form, marshal_output=False)\n\n        return Changelist(int(result.split()[1]), connection)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the state of the changelist", "response": "def save(self):\n        \"\"\"Saves the state of the changelist\"\"\"\n        files = [f.depotFile for f in self._files]\n        cmd = ['reopen', '-c', 'default']\n        self._connection.run(cmd + files)\n        self._dirty = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun an fstat for this file and repopulates the data", "response": "def query(self):\n        \"\"\"Runs an fstat for this file and repopulates the data\"\"\"\n\n        self._p4dict = self._connection.run(['fstat', '-m', '1', self._p4dict['depotFile']])[0]\n        self._head = HeadRevision(self._p4dict)\n\n        self._filename = self.depotFile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck out the file and updates the changelist", "response": "def edit(self, changelist=0):\n        \"\"\"Checks out the file\n\n        :param changelist: Optional changelist to checkout the file into\n        :type changelist: :class:`.Changelist`\n        \"\"\"\n        command = 'reopen' if self.action in ('add', 'edit') else 'edit'\n        if int(changelist):\n            self._connection.run([command, '-c', str(changelist.change), self.depotFile])\n        else:\n            self._connection.run([command, self.depotFile])\n\n        self.query()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(self, lock=True, changelist=0):\n\n        cmd = 'lock' if lock else 'unlock'\n        if changelist:\n            self._connection.run([cmd, '-c', changelist, self.depotFile])\n        else:\n            self._connection.run([cmd, self.depotFile])\n\n        self.query()", "response": "Locks or unlocks the file in the changelist"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync(self, force=False, safe=True, revision=0, changelist=0):\n        cmd = ['sync']\n        if force:\n            cmd.append('-f')\n\n        if safe:\n            cmd.append('-s')\n\n        if revision:\n            cmd.append('{}#{}'.format(self.depotFile, revision))\n        elif changelist:\n            cmd.append('{}@{}'.format(self.depotFile, changelist))\n        else:\n            cmd.append(self.depotFile)\n\n        self._connection.run(cmd)\n\n        self.query()", "response": "Syncs the current revision with the current file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreverts any file changes", "response": "def revert(self, unchanged=False):\n        \"\"\"Reverts any file changes\n\n        :param unchanged: Only revert if the file is unchanged\n        :type unchanged: bool\n        \"\"\"\n        cmd = ['revert']\n        if unchanged:\n            cmd.append('-a')\n\n        wasadd = self.action == 'add'\n\n        cmd.append(self.depotFile)\n\n        self._connection.run(cmd)\n\n        if 'movedFile' in self._p4dict:\n            self._p4dict['depotFile'] = self._p4dict['movedFile']\n\n        if not wasadd:\n            self.query()\n\n        if self._changelist:\n            self._changelist.remove(self, permanent=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shelve(self, changelist=None):\n        if changelist is None and self.changelist.description == 'default':\n            raise errors.ShelveError('Unabled to shelve files in the default changelist')\n\n        cmd = ['shelve']\n        if changelist:\n            cmd += ['-c', str(changelist)]\n\n        cmd.append(self.depotFile)\n\n        self._connection.run(cmd)\n\n        self.query()", "response": "Shelves the file if it is in a changelist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move(self, dest, changelist=0, force=False):\n        cmd = ['move']\n        if force:\n            cmd.append('-f')\n\n        if changelist:\n            cmd += ['-c', str(changelist)]\n\n        if not self.isEdit:\n            self.edit(changelist)\n\n        cmd += [self.depotFile, dest]\n        self._connection.run(cmd)\n        self._p4dict['depotFile'] = dest\n\n        self.query()", "response": "Renames the file to dest and moves it to changelist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, changelist=0):\n        cmd = ['delete']\n\n        if changelist:\n            cmd += ['-c', str(changelist)]\n\n        cmd.append(self.depotFile)\n        self._connection.run(cmd)\n\n        self.query()", "response": "Marks the file for deletion"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revision(self):\n        rev = self._p4dict.get('haveRev', -1)\n        if rev == 'none':\n            rev = 0\n        return int(rev)", "response": "Return the revision number of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef changelist(self):\n        if self._changelist:\n            return self._changelist\n\n        if self._p4dict['change'] == 'default':\n            return Default(connection=self._connection)\n        else:\n            return Changelist(str(self._p4dict['change']), self._connection)", "response": "Which Changelist is this revision in"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stream(self):\n        stream = self._p4dict.get('stream')\n        if stream:\n            return Stream(stream, self._connection)", "response": "Which stream the client is under"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def load_uvarint(reader):\n    buffer = _UVARINT_BUFFER\n    await reader.areadinto(buffer)\n    size = buffer[0]\n    if size == 0:\n        return 0\n\n    negative = size < 0\n    size = -size if negative else size\n    result = 0\n    shift = 0\n\n    if size > 8:\n        raise ValueError('Varint size too big: %s' % size)\n\n    # TODO: endianity, rev bytes if needed\n    for _ in range(size):\n        await reader.areadinto(buffer)\n        result += buffer[0] << shift\n        shift += 8\n    return result if not negative else -result", "response": "Load Monero portable_binary_archive boost integer serialization\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping n Monero portable_binary_archive boost integer serialization.", "response": "async def dump_uvarint(writer, n):\n    \"\"\"\n    Monero portable_binary_archive boost integer serialization\n    :param writer:\n    :param n:\n    :return:\n    \"\"\"\n    buffer = _UVARINT_BUFFER\n    if n == 0:\n        buffer[0] = 0\n        return await writer.awrite(buffer)\n\n    negative = n < 0\n    ll = -n if negative else n\n\n    size = 0\n    while ll != 0:\n        ll >>= 8\n        size += 1\n\n    buffer[0] = size\n    await writer.awrite(buffer)\n\n    ll = -n if negative else n\n\n    # TODO: endianity, rev bytes if needed\n    for _ in range(size):\n        buffer[0] = ll & 0xff\n        await writer.awrite(buffer)\n        ll >>= 8"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines if a type is in the database.", "response": "def type_in_db(self, tp, params):\n        \"\"\"\n        Determines if type is in the database\n        :param tp:\n        :return:\n        \"\"\"\n        tw = TypeWrapper(tp, params)\n        return self.version_db.is_versioned(tw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_version(self, tp, params):\n        tw = TypeWrapper(tp, params)\n        if not tw.is_versioned():\n            # self.registry.set_tr()\n            return TypeWrapper.ELEMENTARY_RES\n\n        # If not in the DB, load from archive at current position\n        if not self.version_db.is_versioned(tw):\n            tr = await load_uvarint(self.iobj)\n            ver = await load_uvarint(self.iobj)\n            self.version_db.set_version(tw, tr, ver)\n\n        else:\n            tr, ver = self.version_db.get_version(tw)\n\n        obj_id = None if tr == 0 else await load_uvarint(self.iobj)\n        self.registry.set_tr(obj_id)\n        return ver", "response": "Loads version from the stream or version database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def set_version(self, tp, params, version=None, elem=None):\n        self.registry.set_tr(None)\n        tw = TypeWrapper(tp, params)\n        if not tw.is_versioned():\n            return TypeWrapper.ELEMENTARY_RES\n\n        # If not in the DB, store to the archive at the current position\n        if not self.version_db.is_versioned(tw):\n            if version is None:\n                version = self._cur_version(tw, elem)\n\n            await dump_uvarint(self.iobj, 0)\n            await dump_uvarint(self.iobj, version)\n            self.version_db.set_version(tw, 0, version)\n\n        return self.version_db.get_version(tw)[1]", "response": "Sets the version of the current object to the given version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def version(self, tp, params, version=None, elem=None):\n        if self.writing:\n            return await self.set_version(tp, params, version, elem)\n        else:\n            return await self.get_version(tp, params)", "response": "This method is used to set or get the version of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def uvarint(self, elem):\n        if self.writing:\n            return await dump_uvarint(self.iobj, elem)\n        else:\n            return await load_uvarint(self.iobj)", "response": "Uvarint\n        :param elem:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the uvarint value of a tag.", "response": "async def uint(self, elem, elem_type, params=None):\n        \"\"\"\n        Integer types\n        :param elem:\n        :param elem_type:\n        :param params:\n        :return:\n        \"\"\"\n        one_b_type = x.is_type(elem_type, (x.Int8, x.UInt8))\n        if self.writing:\n            return (await x.dump_uint(self.iobj, elem, 1)) if one_b_type else (await dump_uvarint(self.iobj, elem))\n        else:\n            return (await x.load_uint(self.iobj, 1)) if one_b_type else (await load_uvarint(self.iobj))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn unicode type of the element.", "response": "async def unicode_type(self, elem):\n        \"\"\"\n        Unicode type\n        :param elem:\n        :return:\n        \"\"\"\n        if self.writing:\n            await dump_uvarint(self.iobj, len(elem))\n            await self.iobj.awrite(bytes(elem, 'utf8'))\n\n        else:\n            ivalue = await load_uvarint(self.iobj)\n            if ivalue == 0:\n                return ''\n\n            fvalue = bytearray(ivalue)\n            await self.iobj.areadinto(fvalue)\n            return str(fvalue, 'utf8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads and dump a blob.", "response": "async def blob(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Loads/dumps blob\n        :return:\n        \"\"\"\n        elem_type = elem_type if elem_type else elem.__class__\n        version = await self.version(elem_type, params, elem=elem)\n\n        if self.is_tracked():\n            return self.get_tracked()\n\n        if hasattr(elem_type, 'boost_serialize'):\n            elem = elem_type() if elem is None else elem\n            self.pop_track()\n            return await elem.boost_serialize(self, elem=elem, elem_type=elem_type, params=params, version=version)\n\n        if self.writing:\n            self.pop_track()\n            return await self.blob_dump(elem=elem, elem_type=elem_type, params=params)\n\n        else:\n            obj = await self.blob_load(elem_type=elem_type, params=params, elem=elem)\n            return self.track_obj(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def blob_dump(self, elem, elem_type, params=None):\n        elem_is_blob = isinstance(elem, x.BlobType)\n        elem_params = elem if elem_is_blob or elem_type is None else elem_type\n        data = getattr(elem, x.BlobType.DATA_ATTR) if elem_is_blob else elem\n\n        if len(data) != elem_params.SIZE:\n            raise ValueError('Fixed size blob has not defined size: %s, path %s' % (elem_params.SIZE, self.tracker))\n\n        await dump_uvarint(self.iobj, len(elem))\n        await self.iobj.awrite(data)", "response": "Dumps blob message to the writer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the blob from reader to the element. Returns the loaded blob.", "response": "async def blob_load(self, elem_type, params=None, elem=None):\n        \"\"\"\n        Loads blob from reader to the element. Returns the loaded blob.\n\n        :param reader:\n        :param elem_type:\n        :param params:\n        :param elem:\n        :return:\n        \"\"\"\n        ivalue = await load_uvarint(self.iobj)\n        fvalue = bytearray(ivalue)\n        await self.iobj.areadinto(fvalue)\n\n        if elem is None:\n            return fvalue  # array by default\n\n        elif isinstance(elem, x.BlobType):\n            setattr(elem, elem_type.DATA_ATTR, fvalue)\n            return elem\n\n        else:\n            elem.extend(fvalue)\n\n        return elem"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def container(self, container=None, container_type=None, params=None):\n        # Container versioning is a bit tricky, primitive type containers are not versioned.\n        elem_type = x.container_elem_type(container_type, params)\n        raw_container = container_is_raw(container_type, params)\n        elem_elementary = TypeWrapper.is_elementary_type(elem_type)\n        is_versioned = not elem_elementary and not raw_container\n        version = None\n\n        if is_versioned:\n            version = await self.version(container_type, params, elem=container)\n            if self.is_tracked():\n                return self.get_tracked()\n\n        if hasattr(container_type, 'boost_serialize'):\n            container = container_type() if container is None else container\n            self.pop_track(is_versioned)\n            return await container.boost_serialize(self, elem=container, elem_type=container_type, params=params, version=version)\n\n        # Container entry version + container\n        if self.writing:\n            self.pop_track(is_versioned)\n            return await self.container_dump(container, container_type, params)\n        else:\n            obj = await self.container_load(container_type, params=params, container=container)\n            return self.track_obj(obj, is_versioned)", "response": "Load and dump a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets size of a container.", "response": "async def container_size(self, container_len=None, container_type=None, params=None):\n        \"\"\"\n        Container size\n        :param container_len:\n        :param container_type:\n        :param params:\n        :return:\n        \"\"\"\n        if hasattr(container_type, 'boost_serialize'):\n            raise ValueError('not supported')\n\n        if self.writing:\n            await dump_uvarint(self.iobj, container_len)\n            if not container_is_raw(container_type, params):\n                c_elem = x.container_elem_type(container_type, params)\n                c_ver = TypeWrapper(c_elem)\n                await dump_uvarint(self.iobj, self._cur_version(c_ver))  # element version\n\n            if container_type.FIX_SIZE and container_len != container_type.SIZE:\n                raise ValueError('Fixed size container has not defined size: %s' % container_type.SIZE)\n\n        else:\n            raise ValueError('Not supported')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def container_val(self, elem, container_type, params=None):\n        if hasattr(container_type, 'boost_serialize'):\n            raise ValueError('not supported')\n\n        if self.writing:\n            elem_type = params[0] if params else None\n            if elem_type is None:\n                elem_type = container_type.ELEM_TYPE\n\n            await self.dump_field(elem, elem_type, params[1:] if params else None)\n\n        else:\n            raise ValueError('Not supported')", "response": "Get the value of a single element in a container."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def container_dump(self, container, container_type, params=None):\n        await self.container_size(len(container), container_type, params)\n\n        elem_type = x.container_elem_type(container_type, params)\n        for idx, elem in enumerate(container):\n            try:\n                self.tracker.push_index(idx)\n                await self._dump_field(elem, elem_type, params[1:] if params else None)\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e", "response": "Dumps a container of elements to the writer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the container of elements from the reader. Supports the container ref. Returns loaded container.", "response": "async def container_load(self, container_type, params=None, container=None):\n        \"\"\"\n        Loads container of elements from the reader. Supports the container ref.\n        Returns loaded container.\n\n        :param container_type:\n        :param params:\n        :param container:\n        :param field_archiver:\n        :return:\n        \"\"\"\n        raw_container = container_is_raw(container_type, params)\n        c_len = await load_uvarint(self.iobj)\n        elem_ver = await load_uvarint(self.iobj) if not raw_container else 0\n\n        # if container and c_len != len(container):\n        #     raise ValueError('Size mismatch')\n\n        elem_type = x.container_elem_type(container_type, params)\n        res = container if container else []\n        for i in range(c_len):\n            try:\n                self.tracker.push_index(i)\n                fvalue = await self._load_field(elem_type,\n                                                params[1:] if params else None,\n                                                x.eref(res, i) if container else None)\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if not container:\n                res.append(fvalue)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def tuple(self, elem=None, elem_type=None, params=None):\n        version = await self.version(elem_type, params, elem=elem)\n        if self.is_tracked():\n            return self.get_tracked()\n\n        if hasattr(elem_type, 'boost_serialize'):\n            container = elem_type() if elem is None else elem\n            self.pop_track()\n            return await container.boost_serialize(self, elem=elem, elem_type=elem_type, params=params, version=version)\n\n        if self.writing:\n            self.pop_track()\n            return await self.dump_tuple(elem, elem_type, params)\n        else:\n            obj = await self.load_tuple(elem_type, params=params, elem=elem)\n            return self.track_obj(obj)", "response": "Load a tuple from the cache or dump it if writing is True."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump a tuple of elements to the writer.", "response": "async def dump_tuple(self, elem, elem_type, params=None):\n        \"\"\"\n        Dumps tuple of elements to the writer.\n\n        :param elem:\n        :param elem_type:\n        :param params:\n        :return:\n        \"\"\"\n        if len(elem) != len(elem_type.f_specs()):\n            raise ValueError('Fixed size tuple has not defined size: %s' % len(elem_type.f_specs()))\n\n        elem_fields = params[0] if params else None\n        if elem_fields is None:\n            elem_fields = elem_type.f_specs()\n        for idx, elem in enumerate(elem):\n            try:\n                self.tracker.push_index(idx)\n                await self._dump_field(elem, elem_fields[idx], params[1:] if params else None)\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def variant(self, elem=None, elem_type=None, params=None):\n        elem_type = elem_type if elem_type else elem.__class__\n        version = await self.version(elem_type, params, elem=elem)\n\n        if self.is_tracked():\n            return self.get_tracked()\n\n        if hasattr(elem_type, 'boost_serialize'):\n            elem = elem_type() if elem is None else elem\n            self.pop_track()\n            return await elem.boost_serialize(self, elem=elem, elem_type=elem_type, params=params, version=version)\n\n        if self.writing:\n            self.pop_track()\n            return await self.dump_variant(elem=elem,\n                                           elem_type=elem_type if elem_type else elem.__class__, params=params)\n        else:\n            obj = await self.load_variant(elem_type=elem_type if elem_type else elem.__class__,\n                                          params=params, elem=elem)\n            return self.track_obj(obj)", "response": "Loads and dumps a single variant from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def dump_variant(self, elem, elem_type=None, params=None):\n        if isinstance(elem, x.VariantType) or elem_type.WRAPS_VALUE:\n            await dump_uvarint(self.iobj, elem.variant_elem_type.VARIANT_CODE)\n            await self._dump_field(getattr(elem, elem.variant_elem), elem.variant_elem_type)\n\n        else:\n            fdef = elem_type.find_fdef(elem_type.f_specs(), elem)\n            vcode = fdef[1].BOOST_VARIANT_CODE if hasattr(fdef[1], 'BOOST_VARIANT_CODE') else fdef[1].VARIANT_CODE\n            await dump_uvarint(self.iobj, vcode)\n            await self._dump_field(elem, fdef[1])", "response": "Dumps the contents of the specified variant to the writer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a single variant from the reader.", "response": "async def load_variant(self, elem_type, params=None, elem=None, wrapped=None):\n        \"\"\"\n        Loads variant type from the reader.\n        Supports both wrapped and raw variant.\n\n        :param reader:\n        :param elem_type:\n        :param params:\n        :param elem:\n        :param wrapped:\n        :return:\n        \"\"\"\n        is_wrapped = (isinstance(elem, x.VariantType) or elem_type.WRAPS_VALUE) if wrapped is None else wrapped\n        if is_wrapped:\n            elem = elem_type() if elem is None else elem\n\n        tag = await load_uvarint(self.iobj)\n        for field in elem_type.f_specs():\n            ftype = field[1]\n            vcode = ftype.BOOST_VARIANT_CODE if hasattr(ftype, 'BOOST_VARIANT_CODE') else ftype.VARIANT_CODE\n            if vcode != tag:\n                continue\n\n            fvalue = await self._load_field(ftype, field[2:], elem if not is_wrapped else None)\n            if is_wrapped:\n                elem.set_variant(field[0], fvalue)\n            return elem if is_wrapped else fvalue\n\n        raise ValueError('Unknown tag: %s, path: %s' % (tag, self.tracker))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def root(self):\n        if self.writing:\n            await self.iobj.awrite(binascii.unhexlify(b'011673657269616c697a6174696f6e3a3a617263686976650000'))\n\n        else:\n            hdr = bytearray(2)\n            await self.iobj.areadinto(hdr)\n            if hdr != bytearray(b'\\x01\\x16'):\n                raise ValueError('Unsupported header')\n\n            hdr = bytearray(22)\n            await self.iobj.areadinto(hdr)\n            if hdr != bytearray(b'serialization::archive'):\n                raise ValueError('Unrecognized magic header')\n\n            tra = await load_uvarint(self.iobj)\n            ver = await load_uvarint(self.iobj)\n            if tra != 0:\n                raise ValueError('Tracking not supported')", "response": "Load the root level of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nroot - level message. First entry in the archive.", "response": "async def root_message(self, msg, msg_type=None):\n        \"\"\"\n        Root-level message. First entry in the archive.\n        Archive headers processing\n\n        :return:\n        \"\"\"\n        await self.root()\n        await self.message(msg, msg_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def message(self, msg, msg_type=None, use_version=None):\n        elem_type = msg_type if msg_type is not None else msg.__class__\n        version = await self.version(elem_type, None, elem=msg) if use_version is None else use_version\n\n        if self.is_tracked():\n            return self.get_tracked()\n\n        if hasattr(elem_type, 'boost_serialize'):\n            msg = elem_type() if msg is None else msg\n            self.pop_track(use_version is None)\n            return await msg.boost_serialize(self, version=version)\n\n        if self.writing:\n            self.pop_track(use_version is None)\n            return await self.dump_message(msg, msg_type=msg_type)\n        else:\n            obj = await self.load_message(msg_type, msg=msg)\n            return self.track_obj(obj, use_version is None)", "response": "Load a message from the database and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload and dump individual message fields.", "response": "async def message_fields(self, msg, fields):\n        \"\"\"\n        Load/dump individual message fields\n        :param msg:\n        :param fields:\n        :param field_archiver:\n        :return:\n        \"\"\"\n        for field in fields:\n            try:\n                self.tracker.push_field(field[0])\n                await self.message_field(msg, field)\n                self.tracker.pop()\n\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps a message to the writer.", "response": "async def dump_message(self, msg, msg_type=None):\n        \"\"\"\n        Dumps message to the writer.\n\n        :param msg:\n        :param msg_type:\n        :return:\n        \"\"\"\n        mtype = msg.__class__ if msg_type is None else msg_type\n        fields = mtype.f_specs()\n        for field in fields:\n            await self.message_field(msg=msg, field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a message of the given type from the reader.", "response": "async def load_message(self, msg_type, msg=None):\n        \"\"\"\n        Loads message if the given type from the reader.\n        Supports reading directly to existing message.\n\n        :param msg_type:\n        :param msg:\n        :return:\n        \"\"\"\n        msg = msg_type() if msg is None else msg\n        fields = msg_type.f_specs() if msg_type else msg.__class__.f_specs()\n        for field in fields:\n            await self.message_field(msg, field)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects next resource in the list of resources.", "response": "def _get_next_resource(self, resource, next_resource_name, selectors):\n        \"\"\"\n        :param resource: Resource (not necessary fetched)\n        :param next_resource_name: string\n        :rtype: (resource_type, resource_path)\n        \"\"\"\n        # don't fetch twice\n        if 'id_perms' not in resource:\n            resource.fetch()\n\n        res = None\n        for res_list in (getattr(resource.refs, next_resource_name),\n                         getattr(resource.back_refs, next_resource_name),\n                         getattr(resource.children, next_resource_name)):\n            res = self._select_next_resource(res_list, selectors)\n            if res is not None:\n                break\n\n        if res is None:\n            raise CommandError(\"Resource '%s' is not linked to resource type '%s'\" %\n                               (self.current_path(resource), next_resource_name))\n\n        return (res.type, res)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef contrail_error_handler(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        try:\n            return f(*args, **kwargs)\n        except HttpError as e:\n            # Replace message by details to provide a\n            # meaningful message\n            if e.details:\n                e.message, e.details = e.details, e.message\n                e.args = (\"%s (HTTP %s)\" % (e.message, e.http_status),)\n            raise\n    return wrapper", "response": "Handle HTTP errors returned by the API server\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize a new session to Contrail API server", "response": "def make(self, host=\"localhost\", port=8082, protocol=\"http\", base_uri=\"\", os_auth_type=\"http\", **kwargs):\n        \"\"\"Initialize a session to Contrail API server\n\n        :param os_auth_type: auth plugin to use:\n            - http: basic HTTP authentification\n            - v2password: keystone v2 auth\n            - v3password: keystone v3 auth\n        :type os_auth_type: str\n        \"\"\"\n        loader = loading.base.get_plugin_loader(os_auth_type)\n        plugin_options = {opt.dest: kwargs.pop(\"os_%s\" % opt.dest)\n                          for opt in loader.get_options()\n                          if 'os_%s' % opt.dest in kwargs}\n        plugin = loader.load_from_options(**plugin_options)\n        return self.load_from_argparse_arguments(Namespace(**kwargs),\n                                                 host=host,\n                                                 port=port,\n                                                 protocol=protocol,\n                                                 base_uri=base_uri,\n                                                 auth=plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nposts data to the api - server", "response": "def post_json(self, url, data, cls=None, **kwargs):\n        \"\"\"\n        POST data to the api-server\n\n        :param url: resource location (eg: \"/type/uuid\")\n        :type url: str\n        :param cls: JSONEncoder class\n        :type cls: JSONEncoder\n        \"\"\"\n        kwargs['data'] = to_json(data, cls=cls)\n        kwargs['headers'] = self.default_headers\n        return self.post(url, **kwargs).json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_json(self, url, data, cls=None, **kwargs):\n        kwargs['data'] = to_json(data, cls=cls)\n        kwargs['headers'] = self.default_headers\n        return self.put(url, **kwargs).json()", "response": "PUT data to the api - server"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fqname_to_id(self, fq_name, type):\n        data = {\n            \"type\": type,\n            \"fq_name\": list(fq_name)\n        }\n        return self.post_json(self.make_url(\"/fqname-to-id\"), data)[\"uuid\"]", "response": "Return uuid for fq_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef id_to_fqname(self, uuid, type=None):\n        data = {\n            \"uuid\": uuid\n        }\n        result = self.post_json(self.make_url(\"/id-to-fqname\"), data)\n        result['fq_name'] = FQName(result['fq_name'])\n        if type is not None and not result['type'].replace('_', '-') == type:\n            raise HttpError('uuid %s not found for type %s' % (uuid, type), http_status=404)\n        return result", "response": "Return fq_name and type for uuid"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for a key in the key - value store.", "response": "def search_kv_store(self, key):\n        \"\"\"Search for a key in the key-value store.\n        :param key: string\n        :rtype: string\n        \"\"\"\n        data = {\n            'operation': 'RETRIEVE',\n            'key': key\n        }\n        return self.post_json(self.make_url(\"/useragent-kv\"), data)['value']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_kv_store(self, key, value):\n        data = {\n            'operation': 'STORE',\n            'key': key,\n            'value': value\n        }\n        return self.post(self.make_url(\"/useragent-kv\"), data=to_json(data),\n                         headers=self.default_headers).text", "response": "Add a key - value store entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a key - value store entry.", "response": "def remove_kv_store(self, key):\n        \"\"\"Remove a key-value store entry.\n\n        :param key: string\n        \"\"\"\n        data = {\n            'operation': 'DELETE',\n            'key': key\n        }\n        return self.post(self.make_url(\"/useragent-kv\"), data=to_json(data),\n                         headers=self.default_headers).text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef canonical_ops(ops):\n    ''' Returns the given operations array sorted with duplicates removed.\n\n    @param ops checker.Ops\n    @return: checker.Ops\n    '''\n    new_ops = sorted(set(ops), key=lambda x: (x.entity, x.action))\n    return new_ops", "response": "Returns the given operations array sorted with duplicates removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _macaroon_id_ops(ops):\n    '''Return operations suitable for serializing as part of a MacaroonId.\n\n    It assumes that ops has been canonicalized and that there's at least\n    one operation.\n    '''\n    id_ops = []\n    for entity, entity_ops in itertools.groupby(ops, lambda x: x.entity):\n        actions = map(lambda x: x.action, entity_ops)\n        id_ops.append(id_pb2.Op(entity=entity, actions=actions))\n    return id_ops", "response": "Return operations suitable for serializing as part of a MacaroonId."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a macaroon with the given version from the oven and associates it with the given operations and attaches the given caveats.", "response": "def macaroon(self, version, expiry, caveats, ops):\n        ''' Takes a macaroon with the given version from the oven,\n        associates it with the given operations and attaches the given caveats.\n        There must be at least one operation specified.\n        The macaroon will expire at the given time - a time_before first party\n        caveat will be added with that time.\n\n        @return: a new Macaroon object.\n        '''\n        if len(ops) == 0:\n            raise ValueError('cannot mint a macaroon associated '\n                             'with no operations')\n\n        ops = canonical_ops(ops)\n        root_key, storage_id = self.root_keystore_for_ops(ops).root_key()\n\n        id = self._new_macaroon_id(storage_id, expiry, ops)\n\n        id_bytes = six.int2byte(LATEST_VERSION) + \\\n            id.SerializeToString()\n\n        if macaroon_version(version) < MACAROON_V2:\n            # The old macaroon format required valid text for the macaroon id,\n            # so base64-encode it.\n            id_bytes = raw_urlsafe_b64encode(id_bytes)\n\n        m = Macaroon(\n            root_key,\n            id_bytes,\n            self.location,\n            version,\n            self.namespace,\n        )\n        m.add_caveat(checkers.time_before_caveat(expiry), self.key,\n                     self.locator)\n        m.add_caveats(caveats, self.key, self.locator)\n        return m"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ops_entity(self, ops):\n        ''' Returns a new multi-op entity name string that represents\n        all the given operations and caveats. It returns the same value\n        regardless of the ordering of the operations. It assumes that the\n        operations have been canonicalized and that there's at least one\n        operation.\n\n        :param ops:\n        :return: string that represents all the given operations and caveats.\n        '''\n        # Hash the operations, removing duplicates as we go.\n        hash_entity = hashlib.sha256()\n        for op in ops:\n            hash_entity.update('{}\\n{}\\n'.format(\n                op.action, op.entity).encode())\n        hash_encoded = base64.urlsafe_b64encode(hash_entity.digest())\n        return 'multi-' + hash_encoded.decode('utf-8').rstrip('=')", "response": "Returns a new multi - op entity name string that represents all the given operations and caveats."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef macaroon_ops(self, macaroons):\n        ''' This method makes the oven satisfy the MacaroonOpStore protocol\n        required by the Checker class.\n\n        For macaroons minted with previous bakery versions, it always\n        returns a single LoginOp operation.\n\n        :param macaroons:\n        :return:\n        '''\n        if len(macaroons) == 0:\n            raise ValueError('no macaroons provided')\n\n        storage_id, ops = _decode_macaroon_id(macaroons[0].identifier_bytes)\n        root_key = self.root_keystore_for_ops(ops).get(storage_id)\n        if root_key is None:\n            raise VerificationError(\n                'macaroon key not found in storage')\n        v = Verifier()\n        conditions = []\n\n        def validator(condition):\n            # Verify the macaroon's signature only. Don't check any of the\n            # caveats yet but save them so that we can return them.\n            conditions.append(condition)\n            return True\n        v.satisfy_general(validator)\n        try:\n            v.verify(macaroons[0], root_key, macaroons[1:])\n        except Exception as exc:\n            # Unfortunately pymacaroons doesn't control\n            # the set of exceptions that can be raised here.\n            # Possible candidates are:\n            # pymacaroons.exceptions.MacaroonUnmetCaveatException\n            # pymacaroons.exceptions.MacaroonInvalidSignatureException\n            # ValueError\n            # nacl.exceptions.CryptoError\n            #\n            # There may be others too, so just catch everything.\n            raise six.raise_from(\n                VerificationError('verification failed: {}'.format(str(exc))),\n                exc,\n            )\n\n        if (self.ops_store is not None\n            and len(ops) == 1\n                and ops[0].entity.startswith('multi-')):\n            # It's a multi-op entity, so retrieve the actual operations\n            # it's associated with.\n            ops = self.ops_store.get_ops(ops[0].entity)\n\n        return ops, conditions", "response": "This method returns a list of LoginOp objects for the given macaroon."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append(self, value):\n        return super(Collection, self).append(\n            self._ensure_value_is_valid(value))", "response": "Add an item to the end of the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextending the list by appending all the items in the given list.", "response": "def extend(self, iterable):\n        \"\"\"Extend the list by appending all the items in the given list.\"\"\"\n        return super(Collection, self).extend(\n            self._ensure_iterable_is_valid(iterable))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, index, value):\n        return super(Collection, self).insert(\n            index, self._ensure_value_is_valid(value))", "response": "Insert an item at a given position."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ensure_value_is_valid(self, value):\n        if not isinstance(value, self.__class__.value_type):\n            raise TypeError('{0} is not valid collection value, instance '\n                            'of {1} required'.format(\n                                value, self.__class__.value_type))\n        return value", "response": "Ensure that value is a valid collection s value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef container_elem_type(container_type, params):\n    elem_type = params[0] if params else None\n    if elem_type is None:\n        elem_type = container_type.ELEM_TYPE\n    return elem_type", "response": "Returns container element type based on container type and parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gen_elem_array(size, elem_type=None):\n    if elem_type is None or not callable(elem_type):\n        return [elem_type] * size\n    if is_type(elem_type, ContainerType):\n\n        def elem_type():\n            return []\n\n    res = []\n    for _ in range(size):\n        res.append(elem_type())\n    return res", "response": "Generates element array of given size and initializes with given type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that a given DOI is a valid canonical DOI.", "response": "def is_valid(doi):\n    \"\"\"\n    Check that a given DOI is a valid canonical DOI.\n\n    :param doi: The DOI to be checked.\n    :returns: Boolean indicating whether the DOI is valid or not.\n\n    >>> is_valid('10.1209/0295-5075/111/40005')\n    True\n\n    >>> is_valid('10.1016.12.31/nature.S0735-1097(98)2000/12/31/34:7-7')\n    True\n\n    >>> is_valid('10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S')\n    True\n\n    >>> is_valid('10.1007/978-3-642-28108-2_19')\n    True\n\n    >>> is_valid('10.1007.10/978-3-642-28108-2_19')\n    True\n\n    >>> is_valid('10.1016/S0735-1097(98)00347-7')\n    True\n\n    >>> is_valid('10.1579/0044-7447(2006)35\\[89:RDUICP\\]2.0.CO;2')\n    True\n\n    >>> is_valid('<geo coords=\"10.4515260,51.1656910\"></geo>')\n    False\n    \"\"\"\n    match = REGEX.match(doi)\n    return (match is not None) and (match.group(0) == doi)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_url(dois):\n    if isinstance(dois, list):\n        return [DX_URL.format(doi=doi) for doi in dois]\n    else:\n        return DX_URL.format(doi=dois)", "response": "Converts a list of DOIs to a list of URLs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_oa_version(doi):\n    try:\n        request = requests.get(\"%s%s\" % (DISSEMIN_API, doi))\n        request.raise_for_status()\n        result = request.json()\n        assert result[\"status\"] == \"ok\"\n        return result[\"paper\"][\"pdf_url\"]\n    except (AssertionError, ValueError, KeyError, RequestException):\n        return None", "response": "Get an OA version for a given DOI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_oa_policy(doi):\n    try:\n        request = requests.get(\"%s%s\" % (DISSEMIN_API, doi))\n        request.raise_for_status()\n        result = request.json()\n        assert result[\"status\"] == \"ok\"\n        return ([i\n                 for i in result[\"paper\"][\"publications\"]\n                 if i[\"doi\"] == doi][0])[\"policy\"]\n    except (AssertionError, ValueError,\n            KeyError, RequestException, IndexError):\n        return None", "response": "Get the OA policy for a given DOI."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_linked_version(doi):\n    try:\n        request = requests.head(to_url(doi))\n        return request.headers.get(\"location\")\n    except RequestException:\n        return None", "response": "Get the original link behind the DOI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bibtex(doi):\n    try:\n        request = requests.get(to_url(doi),\n                               headers={\"accept\": \"application/x-bibtex\"})\n        request.raise_for_status()\n        assert request.headers.get(\"content-type\") == \"application/x-bibtex\"\n        return request.text\n    except (RequestException, AssertionError):\n        return None", "response": "Get a BibTeX entry for a given DOI."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures the logging module with a given dictionary.", "response": "def _configure_logging(self, logger_dict=None):\n        \"\"\"\n        Configures the logging module with a given dictionary, which in most cases was loaded from a configuration\n        file.\n\n        If no dictionary is provided, it falls back to a default configuration.\n\n        See `Python docs\n        <https://docs.python.org/3.5/library/logging.config.html#logging.config.dictConfig>`_ for more information.\n\n        :param logger_dict: dictionary for logger.\n        \"\"\"\n        self.log.debug(\"Configure logging\")\n\n        # Let's be sure, that for our log no handlers are registered anymore\n        for handler in self.log.handlers:\n            self.log.removeHandler(handler)\n        if logger_dict is None:\n            self.log.debug(\"No logger dictionary defined. Doing default logger configuration\")\n            formatter = logging.Formatter(\"%(name)s - %(asctime)s - [%(levelname)s] - %(module)s - %(message)s\")\n            stream_handler = logging.StreamHandler(sys.stdout)\n            stream_handler.setLevel(logging.WARNING)\n            stream_handler.setFormatter(formatter)\n            self.log.addHandler(stream_handler)\n            self.log.setLevel(logging.WARNING)\n        else:\n            self.log.debug(\"Logger dictionary defined. Loading dictConfig for logging\")\n            logging.config.dictConfig(logger_dict)\n            self.log.debug(\"dictConfig loaded\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def dump_blob(writer, elem, elem_type, params=None):\n    elem_is_blob = isinstance(elem, BlobType)\n    elem_params = elem if elem_is_blob or elem_type is None else elem_type\n    data = bytes(getattr(elem, BlobType.DATA_ATTR) if elem_is_blob else elem)\n\n    if not elem_params.FIX_SIZE:\n        await dump_uvarint(writer, len(elem))\n    elif len(data) != elem_params.SIZE:\n        raise ValueError('Fixed size blob has not defined size: %s' % elem_params.SIZE)\n    await writer.awrite(data)", "response": "Dumps blob message to the writer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload blob from reader to the element. Returns the loaded blob.", "response": "async def load_blob(reader, elem_type, params=None, elem=None):\n    \"\"\"\n    Loads blob from reader to the element. Returns the loaded blob.\n\n    :param reader:\n    :param elem_type:\n    :param params:\n    :param elem:\n    :return:\n    \"\"\"\n    ivalue = elem_type.SIZE if elem_type.FIX_SIZE else await load_uvarint(reader)\n    fvalue = bytearray(ivalue)\n    await reader.areadinto(fvalue)\n\n    if elem is None:\n        return fvalue  # array by default\n\n    elif isinstance(elem, BlobType):\n        setattr(elem, elem_type.DATA_ATTR, fvalue)\n        return elem\n\n    else:\n        elem.extend(fvalue)\n\n    return elem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping a string as UTF8 encoded string as a naked XML element.", "response": "async def dump_unicode(writer, elem):\n    \"\"\"\n    Dumps string as UTF8 encoded string\n    :param writer:\n    :param elem:\n    :return:\n    \"\"\"\n    await dump_uvarint(writer, len(elem))\n    await writer.awrite(bytes(elem, 'utf8'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def load_unicode(reader):\n    ivalue = await load_uvarint(reader)\n    fvalue = bytearray(ivalue)\n    await reader.areadinto(fvalue)\n    return str(fvalue, 'utf8')", "response": "Loads UTF8 string from a reader."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def prepare_container(self, size, container, elem_type=None):\n        if not self.writing:\n            if container is None:\n                return gen_elem_array(size, elem_type)\n\n            fvalue = get_elem(container)\n            if fvalue is None:\n                fvalue = []\n            fvalue += gen_elem_array(max(0, size - len(fvalue)), elem_type)\n            set_elem(container, fvalue)\n            return fvalue", "response": "Prepares the container for serialization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading or dump a blob of the current object.", "response": "async def blob(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Loads/dumps blob\n        :return:\n        \"\"\"\n        elem_type = elem_type if elem_type else elem.__class__\n        if hasattr(elem_type, \"serialize_archive\"):\n            elem = elem_type() if elem is None else elem\n            return await elem.serialize_archive(\n                self, elem=elem, elem_type=elem_type, params=params\n            )\n\n        if self.writing:\n            return await dump_blob(\n                self.iobj, elem=elem, elem_type=elem_type, params=params\n            )\n        else:\n            return await load_blob(\n                self.iobj, elem_type=elem_type, params=params, elem=elem\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def container(self, container=None, container_type=None, params=None):\n        if hasattr(container_type, \"serialize_archive\"):\n            container = container_type() if container is None else container\n            return await container.serialize_archive(\n                self, elem=container, elem_type=container_type, params=params\n            )\n\n        if self.writing:\n            return await self._dump_container(\n                self.iobj, container, container_type, params\n            )\n        else:\n            return await self._load_container(\n                self.iobj, container_type, params=params, container=container\n            )", "response": "Load or dump a container."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the size of the container.", "response": "async def container_size(\n            self, container_len=None, container_type=None, params=None\n    ):\n        \"\"\"\n        Container size\n        :param container_len:\n        :param container_type:\n        :param params:\n        :return:\n        \"\"\"\n        if hasattr(container_type, \"serialize_archive\"):\n            raise ValueError(\"not supported\")\n\n        if self.writing:\n            return await self._dump_container_size(\n                self.iobj, container_len, container_type, params\n            )\n        else:\n            raise ValueError(\"Not supported\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def container_val(self, elem, container_type, params=None):\n        if hasattr(container_type, \"serialize_archive\"):\n            raise ValueError(\"not supported\")\n        if self.writing:\n            return await self._dump_container_val(\n                self.iobj, elem, container_type, params\n            )\n        else:\n            raise ValueError(\"Not supported\")", "response": "Get the value of a single element in a container."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads or dump a tuple.", "response": "async def tuple(self, elem=None, elem_type=None, params=None):\n        \"\"\"\n        Loads/dumps tuple\n        :return:\n        \"\"\"\n        if hasattr(elem_type, \"serialize_archive\"):\n            container = elem_type() if elem is None else elem\n            return await container.serialize_archive(\n                self, elem=elem, elem_type=elem_type, params=params\n            )\n\n        if self.writing:\n            return await self._dump_tuple(self.iobj, elem, elem_type, params)\n        else:\n            return await self._load_tuple(\n                self.iobj, elem_type, params=params, elem=elem\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def variant(self, elem=None, elem_type=None, params=None, wrapped=None):\n        elem_type = elem_type if elem_type else elem.__class__\n        if hasattr(elem_type, \"serialize_archive\"):\n            elem = elem_type() if elem is None else elem\n            return await elem.serialize_archive(\n                self, elem=elem, elem_type=elem_type, params=params\n            )\n\n        if self.writing:\n            return await self._dump_variant(\n                self.iobj,\n                elem=elem,\n                elem_type=elem_type if elem_type else elem.__class__,\n                params=params,\n            )\n        else:\n            return await self._load_variant(\n                self.iobj,\n                elem_type=elem_type if elem_type else elem.__class__,\n                params=params,\n                elem=elem,\n                wrapped=wrapped,\n            )", "response": "Load or dump a single variant from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload and dumps a message.", "response": "async def message(self, msg, msg_type=None, use_version=None):\n        \"\"\"\n        Loads/dumps message\n        :param msg:\n        :param msg_type:\n        :param use_version:\n        :return:\n        \"\"\"\n        elem_type = msg_type if msg_type is not None else msg.__class__\n        msg = elem_type() if msg is None else msg\n        if hasattr(elem_type, \"serialize_archive\"):\n            version = await self.version(elem_type, None, elem=msg) if use_version is None else use_version\n            return await msg.serialize_archive(self, version=version)\n\n        mtype = msg.__class__ if msg_type is None else msg_type\n        fields = mtype.f_specs()\n        if hasattr(mtype, \"serialize_archive\"):\n            raise ValueError(\"Cannot directly load, has to use archive with %s\" % mtype)\n\n        await self.message_fields(msg, fields)\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump or loads a message field.", "response": "async def message_field(self, msg, field, fvalue=None):\n        \"\"\"\n        Dumps/Loads message field\n        :param msg:\n        :param field:\n        :param fvalue: explicit value for dump\n        :return:\n        \"\"\"\n        fname, ftype, params = field[0], field[1], field[2:]\n        try:\n            self.tracker.push_field(fname)\n            if self.writing:\n                await self._dump_message_field(self.iobj, msg, field, fvalue=fvalue)\n            else:\n                await self._load_message_field(self.iobj, msg, field)\n            self.tracker.pop()\n\n        except Exception as e:\n            raise helpers.ArchiveException(e, tracker=self.tracker) from e"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def field(self, elem=None, elem_type=None, params=None):\n        elem_type = elem_type if elem_type else elem.__class__\n        fvalue = None\n\n        etype = self._get_type(elem_type)\n        if self._is_type(etype, UVarintType):\n            fvalue = await self.uvarint(get_elem(elem))\n\n        elif self._is_type(etype, IntType):\n            fvalue = await self.uint(\n                elem=get_elem(elem), elem_type=elem_type, params=params\n            )\n\n        elif self._is_type(etype, BlobType):\n            fvalue = await self.blob(\n                elem=get_elem(elem), elem_type=elem_type, params=params\n            )\n\n        elif self._is_type(etype, UnicodeType):\n            fvalue = await self.unicode_type(get_elem(elem))\n\n        elif self._is_type(etype, VariantType):\n            fvalue = await self.variant(\n                elem=get_elem(elem), elem_type=elem_type, params=params\n            )\n\n        elif self._is_type(etype, ContainerType):  # container ~ simple list\n            fvalue = await self.container(\n                container=get_elem(elem), container_type=elem_type, params=params\n            )\n\n        elif self._is_type(etype, TupleType):  # tuple ~ simple list\n            fvalue = await self.tuple(\n                elem=get_elem(elem), elem_type=elem_type, params=params\n            )\n\n        elif self._is_type(etype, MessageType):\n            fvalue = await self.message(get_elem(elem), msg_type=elem_type)\n\n        else:\n            raise TypeError(\n                \"unknown type: %s %s %s\" % (elem_type, type(elem_type), elem)\n            )\n\n        return fvalue if self.writing else set_elem(elem, fvalue)", "response": "Get the archive field."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _dump_container_size(\n            self, writer, container_len, container_type, params=None\n    ):\n        \"\"\"\n        Dumps container size - per element streaming\n        :param writer:\n        :param container_len:\n        :param container_type:\n        :param params:\n        :return:\n        \"\"\"\n        if not container_type or not container_type.FIX_SIZE:\n            await dump_uvarint(writer, container_len)\n        elif container_len != container_type.SIZE:\n            raise ValueError(\n                \"Fixed size container has not defined size: %s\" % container_type.SIZE\n            )", "response": "Dumps the size of the container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump a single container value.", "response": "async def _dump_container_val(self, writer, elem, container_type, params=None):\n        \"\"\"\n        Single elem dump\n        :param writer:\n        :param elem:\n        :param container_type:\n        :param params:\n        :return:\n        \"\"\"\n        elem_type = container_elem_type(container_type, params)\n        await self.dump_field(writer, elem, elem_type, params[1:] if params else None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping the container of elements to the writer.", "response": "async def _dump_container(self, writer, container, container_type, params=None):\n        \"\"\"\n        Dumps container of elements to the writer.\n\n        :param writer:\n        :param container:\n        :param container_type:\n        :param params:\n        :return:\n        \"\"\"\n        await self._dump_container_size(writer, len(container), container_type)\n\n        elem_type = container_elem_type(container_type, params)\n\n        for idx, elem in enumerate(container):\n            try:\n                self.tracker.push_index(idx)\n                await self.dump_field(\n                    writer, elem, elem_type, params[1:] if params else None\n                )\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the container of elements from the reader. Supports the container ref. Returns loaded container.", "response": "async def _load_container(\n            self, reader, container_type, params=None, container=None\n    ):\n        \"\"\"\n        Loads container of elements from the reader. Supports the container ref.\n        Returns loaded container.\n\n        :param reader:\n        :param container_type:\n        :param params:\n        :param container:\n        :return:\n        \"\"\"\n\n        c_len = (\n            container_type.SIZE\n            if container_type.FIX_SIZE\n            else await load_uvarint(reader)\n        )\n        if container and get_elem(container) and c_len != len(container):\n            raise ValueError(\"Size mismatch\")\n\n        elem_type = container_elem_type(container_type, params)\n        res = container if container else []\n        for i in range(c_len):\n            try:\n                self.tracker.push_index(i)\n                fvalue = await self.load_field(\n                    reader,\n                    elem_type,\n                    params[1:] if params else None,\n                    eref(res, i) if container else None,\n                )\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if not container:\n                res.append(fvalue)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump a tuple of elements to the writer.", "response": "async def _dump_tuple(self, writer, elem, elem_type, params=None):\n        \"\"\"\n        Dumps tuple of elements to the writer.\n\n        :param writer:\n        :param elem:\n        :param elem_type:\n        :param params:\n        :return:\n        \"\"\"\n        if len(elem) != len(elem_type.f_specs()):\n            raise ValueError(\n                \"Fixed size tuple has not defined size: %s\" % len(elem_type.f_specs())\n            )\n        await dump_uvarint(writer, len(elem))\n\n        elem_fields = params[0] if params else None\n        if elem_fields is None:\n            elem_fields = elem_type.f_specs()\n        for idx, elem in enumerate(elem):\n            try:\n                self.tracker.push_index(idx)\n                await self.dump_field(\n                    writer, elem, elem_fields[idx], params[1:] if params else None\n                )\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def _load_tuple(self, reader, elem_type, params=None, elem=None):\n\n        c_len = await load_uvarint(reader)\n        if elem and c_len != len(elem):\n            raise ValueError(\"Size mismatch\")\n        if c_len != len(elem_type.f_specs()):\n            raise ValueError(\"Tuple size mismatch\")\n\n        elem_fields = params[0] if params else None\n        if elem_fields is None:\n            elem_fields = elem_type.f_specs()\n\n        res = elem if elem else []\n        for i in range(c_len):\n            try:\n                self.tracker.push_index(i)\n                fvalue = await self.load_field(\n                    reader,\n                    elem_fields[i],\n                    params[1:] if params else None,\n                    eref(res, i) if elem else None,\n                )\n                self.tracker.pop()\n            except Exception as e:\n                raise helpers.ArchiveException(e, tracker=self.tracker) from e\n\n            if not elem:\n                res.append(fvalue)\n        return res", "response": "Loads a tuple of elements from the reader. Supports the tuple ref."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a message field to the writer.", "response": "async def _dump_message_field(self, writer, msg, field, fvalue=None):\n        \"\"\"\n        Dumps a message field to the writer. Field is defined by the message field specification.\n\n        :param writer:\n        :param msg:\n        :param field:\n        :param fvalue:\n        :return:\n        \"\"\"\n        fname, ftype, params = field[0], field[1], field[2:]\n        fvalue = getattr(msg, fname, None) if fvalue is None else fvalue\n        await self.dump_field(writer, fvalue, ftype, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _load_message_field(self, reader, msg, field):\n        fname, ftype, params = field[0], field[1], field[2:]\n        await self.load_field(reader, ftype, params, eref(msg, fname))", "response": "Loads a message field from the reader."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _dump_variant(self, writer, elem, elem_type=None, params=None):\n        if isinstance(elem, VariantType) or elem_type.WRAPS_VALUE:\n            await dump_uint(writer, elem.variant_elem_type.VARIANT_CODE, 1)\n            await self.dump_field(\n                writer, getattr(elem, elem.variant_elem), elem.variant_elem_type\n            )\n\n        else:\n            fdef = find_variant_fdef(elem_type, elem)\n            await dump_uint(writer, fdef[1].VARIANT_CODE, 1)\n            await self.dump_field(writer, elem, fdef[1])", "response": "Dumps the contents of the specified variant to the writer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a single variant from the reader.", "response": "async def _load_variant(\n            self, reader, elem_type, params=None, elem=None, wrapped=None\n    ):\n        \"\"\"\n        Loads variant type from the reader.\n        Supports both wrapped and raw variant.\n\n        :param reader:\n        :param elem_type:\n        :param params:\n        :param elem:\n        :param wrapped:\n        :return:\n        \"\"\"\n        is_wrapped = (\n            (isinstance(elem, VariantType) or elem_type.WRAPS_VALUE)\n            if wrapped is None\n            else wrapped\n        )\n        if is_wrapped:\n            elem = elem_type() if elem is None else elem\n\n        tag = await load_uint(reader, 1)\n        for field in elem_type.f_specs():\n            ftype = field[1]\n            if ftype.VARIANT_CODE == tag:\n                fvalue = await self.load_field(\n                    reader, ftype, field[2:], elem if not is_wrapped else None\n                )\n                if is_wrapped:\n                    elem.set_variant(field[0], fvalue)\n                return elem if is_wrapped else fvalue\n        raise ValueError(\"Unknown tag: %s\" % tag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self, message):\n        self._start = time.clock()\n        VSGLogger.info(\"{0:<20} - Started\".format(message))", "response": "Starts timer with the message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self, message):\n        self._stop = time.clock()\n        VSGLogger.info(\"{0:<20} - Finished [{1}s]\".format(message, self.pprint(self._stop - self._start)))", "response": "Stop timer with the message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pprint(self, seconds):\n        return (\"%d:%02d:%02d.%03d\", reduce(lambda ll, b: divmod(ll[0], b) + ll[1:], [(seconds * 1000,), 1000, 60, 60]))", "response": "Pretty Prints seconds as Hours : Minutes. MilliSeconds\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch for a valid identifier in a given file.", "response": "def find_identifiers(src):\n    \"\"\"\n    Search for a valid identifier (DOI, ISBN, arXiv, HAL) in a given file.\n\n    .. note::\n\n        This function returns the first matching identifier, that is the most\n        likely to be relevant for this file. However, it may fail and return an\n        identifier taken from the references or another paper.\n\n    .. note::\n\n        You will need to have ``pdftotext`` and/or ``djvutxt`` installed \\\n                system-wide before processing files with this function.\n\n\n    :params src: Path to the file to scan.\n\n    :returns: a tuple (type, identifier) or ``(None, None)`` if not found or \\\n            an error occurred.\n    \"\"\"\n    if src.endswith(\".pdf\"):\n        totext = subprocess.Popen([\"pdftotext\", src, \"-\"],\n                                  stdout=subprocess.PIPE,\n                                  stderr=subprocess.PIPE,\n                                  bufsize=1)\n    elif src.endswith(\".djvu\"):\n        totext = subprocess.Popen([\"djvutxt\", src],\n                                  stdout=subprocess.PIPE,\n                                  stderr=subprocess.PIPE,\n                                  bufsize=1)\n    else:\n        return (None, None)\n\n    while totext.poll() is None:\n        extract_full = ' '.join([i.decode(\"utf-8\").strip()\n                                 for i in totext.stdout.readlines()])\n        # Loop over all the valid identifier types\n        for identifier in __valid_identifiers__:\n            # Dynamically call the ``extract_from_text`` method for the\n            # associated module.\n            module = sys.modules.get(\"libbmc.%s\" % (identifier,), None)\n            if module is None:\n                continue\n            found_id = getattr(module, \"extract_from_text\")(extract_full)\n            if found_id:\n                totext.terminate()\n                # found_id is a list of found IDs\n                return (identifier, found_id[0])\n    return (None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bibtex(identifier):\n    identifier_type, identifier_id = identifier\n    if identifier_type not in __valid_identifiers__:\n        return None\n\n    # Dynamically call the ``get_bibtex`` method from the associated module.\n    module = sys.modules.get(\"libbmc.%s\" % (identifier_type,), None)\n    if module is None:\n        return None\n    return getattr(module, \"get_bibtex\")(identifier_id)", "response": "Try to fetch a BiBTeX string from a found identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize(self,*args,**kwargs):\n        super(JSONHandler,self).initialize(*args,**kwargs)\n        content_type = self.request.headers.get('Content-Type', '')\n        if 'application/json' in content_type.lower():\n            self._parse_json_body_arguments()", "response": "Initialize the JSON handler."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_plaintext_citations(bibtex):\n    parser = BibTexParser()\n    parser.customization = convert_to_unicode\n    # Load the BibTeX\n    if os.path.isfile(bibtex):\n        with open(bibtex) as fh:\n            bib_database = bibtexparser.load(fh, parser=parser)\n    else:\n        bib_database = bibtexparser.loads(bibtex, parser=parser)\n    # Convert bibentries to plaintext\n    bibentries = [bibentry_as_plaintext(bibentry)\n                  for bibentry in bib_database.entries]\n    # Return them\n    return bibentries", "response": "Parse a BibTeX file to get a list of plaintext citations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads INI configuration into this module s attributes.", "response": "def init(filename=ConfigPath):\r\n    \"\"\"Loads INI configuration into this module's attributes.\"\"\"\r\n    section, parts = \"DEFAULT\", filename.rsplit(\":\", 1)\r\n    if len(parts) > 1 and os.path.isfile(parts[0]): filename, section = parts\r\n    if not os.path.isfile(filename): return\r\n\r\n    vardict, parser = globals(), configparser.RawConfigParser()\r\n    parser.optionxform = str # Force case-sensitivity on names\r\n    try:\r\n        def parse_value(raw):\r\n            try: return json.loads(raw) # Try to interpret as JSON\r\n            except ValueError: return raw # JSON failed, fall back to raw\r\n        txt = open(filename).read() # Add DEFAULT section if none present\r\n        if not re.search(\"\\\\[\\\\w+\\\\]\", txt): txt = \"[DEFAULT]\\n\" + txt\r\n        parser.readfp(StringIO.StringIO(txt), filename)\r\n        for k, v in parser.items(section): vardict[k] = parse_value(v)\r\n    except Exception:\r\n        logging.warn(\"Error reading config from %s.\", filename, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave this module s changed attributes to INI configuration.", "response": "def save(filename=ConfigPath):\r\n    \"\"\"Saves this module's changed attributes to INI configuration.\"\"\"\r\n    default_values = defaults()\r\n    parser = configparser.RawConfigParser()\r\n    parser.optionxform = str # Force case-sensitivity on names\r\n    try:\r\n        save_types = basestring, int, float, tuple, list, dict, type(None)\r\n        for k, v in sorted(globals().items()):\r\n            if not isinstance(v, save_types) or k.startswith(\"_\") \\\r\n            or default_values.get(k, parser) == v: continue # for k, v\r\n            try: parser.set(\"DEFAULT\", k, json.dumps(v))\r\n            except Exception: pass\r\n        if parser.defaults():\r\n            with open(filename, \"wb\") as f:\r\n                f.write(\"# %s %s configuration written on %s.\\n\" % (Title, Version,\r\n                        datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\r\n                parser.write(f)\r\n        else: # Nothing to write: delete configuration file\r\n            try: os.unlink(filename)\r\n            except Exception: pass\r\n    except Exception:\r\n        logging.warn(\"Error writing config to %s.\", filename, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a once - assembled dict of this module s storable attributes.", "response": "def defaults(values={}):\r\n    \"\"\"Returns a once-assembled dict of this module's storable attributes.\"\"\"\r\n    if values: return values\r\n    save_types = basestring, int, float, tuple, list, dict, type(None)\r\n    for k, v in globals().items():\r\n        if isinstance(v, save_types) and not k.startswith(\"_\"): values[k] = v\r\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix_pdf(pdf_file, destination):\n    tmp = tempfile.NamedTemporaryFile()\n    with open(tmp.name, 'wb') as output:\n        with open(pdf_file, \"rb\") as fh:\n            for line in fh:\n                output.write(line)\n                if b'%%EOF' in line:\n                    break\n    shutil.copy(tmp.name, destination)", "response": "Fix malformed PDF files when data are present after '%%EOF'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy filename to a tempfile, write pages to filename except the teared one. ..note :: Adapted from sciunto's code, https://github.com/sciunto/tear-pages :param filename: PDF filepath :param teared_pages: Numbers of the pages to tear. Default to first page \\ only.", "response": "def tearpage_backend(filename, teared_pages=None):\n    \"\"\"\n    Copy filename to a tempfile, write pages to filename except the teared one.\n\n    ..note ::\n\n        Adapted from sciunto's code, https://github.com/sciunto/tear-pages\n\n    :param filename: PDF filepath\n    :param teared_pages: Numbers of the pages to tear. Default to first page \\\n            only.\n    \"\"\"\n    # Handle default argument\n    if teared_pages is None:\n        teared_pages = [0]\n\n    # Copy the pdf to a tmp file\n    with tempfile.NamedTemporaryFile() as tmp:\n        # Copy the input file to tmp\n        shutil.copy(filename, tmp.name)\n\n        # Read the copied pdf\n        # TODO: Use with syntax\n        try:\n            input_file = PdfFileReader(open(tmp.name, 'rb'))\n        except PdfReadError:\n            fix_pdf(filename, tmp.name)\n            input_file = PdfFileReader(open(tmp.name, 'rb'))\n        # Seek for the number of pages\n        num_pages = input_file.getNumPages()\n\n        # Write pages excepted the first one\n        output_file = PdfFileWriter()\n        for i in range(num_pages):\n            if i in teared_pages:\n                continue\n            output_file.addPage(input_file.getPage(i))\n\n        tmp.close()\n        outputStream = open(filename, \"wb\")\n        output_file.write(outputStream)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tearpage_needed(bibtex):\n    for publisher in BAD_JOURNALS:\n        if publisher in bibtex.get(\"journal\", \"\").lower():\n            # Bad journal is found, add pages to tear\n            return BAD_JOURNALS[publisher]\n\n    # If no bad journals are found, return an empty list\n    return []", "response": "Check whether a given paper needs some pages to be teared or not."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntear pages of the file if needed.", "response": "def tearpage(filename, bibtex=None, force=None):\n    \"\"\"\n    Tear some pages of the file if needed.\n\n    :params filename: Path to the file to handle.\n    :params bibtex: BibTeX dict associated to this file, as the one given by \\\n            ``bibtexparser``. (Mandatory if force is not specified)\n    :params force: If a list of integers, force the tearing of the \\\n            specified pages. (Optional)\n    :returns: A boolean indicating whether the file has been teared or not. \\\n            Side effect is tearing the necessary pages from the file.\n    \"\"\"\n    # Fetch pages to tear\n    pages_to_tear = []\n    if force is not None:\n        pages_to_tear = force\n    elif bibtex is not None:\n        pages_to_tear = tearpage_needed(bibtex)\n\n    if len(pages_to_tear) > 0:\n        # If tearing is needed, do it and return True\n        tearpage_backend(filename, teared_pages=pages_to_tear)\n        return True\n\n    # Else, simply return False\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(*args, **kwargs):\n    global __CONNECTION\n    if __CONNECTION is None:\n        __CONNECTION = Connection(*args, **kwargs)\n\n    return __CONNECTION", "response": "Creates or returns a singleton : class :. Connection object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks out a file into the default changelist", "response": "def edit(filename, connection=None):\n    \"\"\"Checks out a file into the default changelist\n\n    :param filename: File to check out\n    :type filename: str\n    :param connection: Connection object to use\n    :type connection: :py:class:`Connection`\n    \"\"\"\n    c = connection or connect()\n    rev = c.ls(filename)\n    if rev:\n        rev[0].edit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync(filename, connection=None):\n    c = connection or connect()\n    rev = c.ls(filename)\n    if rev:\n        rev[0].sync()", "response": "Syncs a file containing a node s metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nediting or Adds a filename ensuring the file is in perforce and editable", "response": "def open(filename, connection=None):\n    \"\"\"Edits or Adds a filename ensuring the file is in perforce and editable\n\n    :param filename: File to check out\n    :type filename: str\n    :param connection: Connection object to use\n    :type connection: :py:class:`Connection`\n    \"\"\"\n    c = connection or connect()\n    res = c.ls(filename)\n    if res and res[0].revision:\n        res[0].edit()\n    else:\n        c.add(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the name of the FaultSet for this object", "response": "def set_faultset_name(self, name, fsObj):\n        \"\"\"\n        Set name for Faultset\n        :param name: Name of Faultset\n        :param fsObj: ScaleIO FS object\n        :return: POST request response\n        :rtype: Requests POST response object\n        \"\"\"\n        # Set name of FaultSet\n        self.conn.connection._check_login()\n        faultSetNameDict = {'Name': name}\n        # This one is the most logical name comparing to other methods.\n        response = self.conn.connection._do_post(\"{}/{}{}/{}\".format(self.conn.connection._api_url, \"types/FaultSet::\", fsObj.id, 'instances/action/setFaultSetName'), json=faultSetNameSdcDict)    \n\n        # This is how its documented in REST API Chapter\n        #response = self._do_post(\"{}/{}{}/{}\".format(self._api_url, \"types/FaultSet::\", fsObj.id, 'instances/action/setFaultSetName'), json=faultsetNameSdcDict)    \n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_valid(arxiv_id):\n    match = REGEX.match(arxiv_id)\n    return  (match is not None) and (match.group(0) == arxiv_id)", "response": "Checks that a given arXiv ID is a valid arXiv ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a BibTeX entry for a given arXiv ID.", "response": "def get_bibtex(arxiv_id):\n    \"\"\"\n    Get a BibTeX entry for a given arXiv ID.\n\n    .. note::\n\n        Using awesome https://pypi.python.org/pypi/arxiv2bib/ module.\n\n    :param arxiv_id: The canonical arXiv id to get BibTeX from.\n    :returns: A BibTeX string or ``None``.\n\n    >>> get_bibtex('1506.06690')\n    \"@article{1506.06690v2,\\\\nAuthor        = {Lucas Verney and Lev Pitaevskii and Sandro Stringari},\\\\nTitle         = {Hybridization of first and second sound in a weakly-interacting Bose gas},\\\\nEprint        = {1506.06690v2},\\\\nDOI           = {10.1209/0295-5075/111/40005},\\\\nArchivePrefix = {arXiv},\\\\nPrimaryClass  = {cond-mat.quant-gas},\\\\nAbstract      = {Using Landau's theory of two-fluid hydrodynamics we investigate the sound\\\\nmodes propagating in a uniform weakly-interacting superfluid Bose gas for\\\\nvalues of temperature, up to the critical point. In order to evaluate the\\\\nrelevant thermodynamic functions needed to solve the hydrodynamic equations,\\\\nincluding the temperature dependence of the superfluid density, we use\\\\nBogoliubov theory at low temperatures and the results of a perturbative\\\\napproach based on Beliaev diagrammatic technique at higher temperatures.\\\\nSpecial focus is given on the hybridization phenomenon between first and second\\\\nsound which occurs at low temperatures of the order of the interaction energy\\\\nand we discuss explicitly the behavior of the two sound velocities near the\\\\nhybridization point.},\\\\nYear          = {2015},\\\\nMonth         = {Jun},\\\\nUrl           = {http://arxiv.org/abs/1506.06690v2},\\\\nFile          = {1506.06690v2.pdf}\\\\n}\"\n\n    >>> get_bibtex('1506.06690v1')\n    \"@article{1506.06690v1,\\\\nAuthor        = {Lucas Verney and Lev Pitaevskii and Sandro Stringari},\\\\nTitle         = {Hybridization of first and second sound in a weakly-interacting Bose gas},\\\\nEprint        = {1506.06690v1},\\\\nDOI           = {10.1209/0295-5075/111/40005},\\\\nArchivePrefix = {arXiv},\\\\nPrimaryClass  = {cond-mat.quant-gas},\\\\nAbstract      = {Using Landau's theory of two-fluid hydrodynamics we investigate the sound\\\\nmodes propagating in a uniform weakly-interacting superfluid Bose gas for\\\\nvalues of temperature, up to the critical point. In order to evaluate the\\\\nrelevant thermodynamic functions needed to solve the hydrodynamic equations,\\\\nincluding the temperature dependence of the superfluid density, we use\\\\nBogoliubov theory at low temperatures and the results of a perturbative\\\\napproach based on Beliaev diagrammatic technique at higher temperatures.\\\\nSpecial focus is given on the hybridization phenomenon between first and second\\\\nsound which occurs at low temperatures of the order of the interaction energy\\\\nand we discuss explicitly the behavior of the two sound velocities near the\\\\nhybridization point.},\\\\nYear          = {2015},\\\\nMonth         = {Jun},\\\\nUrl           = {http://arxiv.org/abs/1506.06690v1},\\\\nFile          = {1506.06690v1.pdf}\\\\n}\"\n    \"\"\"\n    # Fetch bibtex using arxiv2bib module\n    try:\n        bibtex = arxiv2bib.arxiv2bib([arxiv_id])\n    except HTTPError:\n        bibtex = []\n\n    for bib in bibtex:\n        if isinstance(bib, arxiv2bib.ReferenceErrorInfo):\n            continue\n        else:\n            # Return fetched bibtex\n            return bib.bibtex()\n    # An error occurred, return None\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_from_text(text):\n    # Remove the leading \"arxiv:\".\n    return tools.remove_duplicates([re.sub(\"arxiv:\", \"\", i[0],\n                                           flags=re.IGNORECASE)\n                                    for i in REGEX.findall(text) if i[0] != ''])", "response": "Extract arXiv IDs from a text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a list of ARXIV IDs to a list of URLs.", "response": "def to_url(arxiv_ids):\n    \"\"\"\n    Convert a list of canonical DOIs to a list of DOIs URLs.\n\n    :param dois: List of canonical DOIs.\n    :returns: A list of DOIs URLs.\n\n    >>> to_url('1506.06690')\n    'http://arxiv.org/abs/1506.06690'\n\n    >>> to_url('1506.06690v1')\n    'http://arxiv.org/abs/1506.06690v1'\n    \"\"\"\n    if isinstance(arxiv_ids, list):\n        return [ARXIV_URL.format(arxiv_id=arxiv_id) for arxiv_id in arxiv_ids]\n    else:\n        return ARXIV_URL.format(arxiv_id=arxiv_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_doi(doi):\n    try:\n        request = requests.get(\"http://export.arxiv.org/api/query\",\n                               params={\n                                   \"search_query\": \"doi:%s\" % (doi,),\n                                   \"max_results\": 1\n                               })\n        request.raise_for_status()\n    except RequestException:\n        return None\n    root = xml.etree.ElementTree.fromstring(request.content)\n    for entry in root.iter(\"{http://www.w3.org/2005/Atom}entry\"):\n        arxiv_id = entry.find(\"{http://www.w3.org/2005/Atom}id\").text\n        # arxiv_id is an arXiv full URL. We only want the id which is the last\n        # URL component.\n        return arxiv_id.split(\"/\")[-1]\n    return None", "response": "Get the arXiv eprint id for a given DOI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading sources on arXiv for a given preprint.", "response": "def get_sources(arxiv_id):\n    \"\"\"\n    Download sources on arXiv for a given preprint.\n\n    .. note::\n\n        Bulk download of sources from arXiv is not permitted by their API. \\\n                You should have a look at http://arxiv.org/help/bulk_data_s3.\n\n    :param eprint: The arXiv id (e.g. ``1401.2910`` or ``1401.2910v1``) in a \\\n            canonical form.\n    :returns: A ``TarFile`` object of the sources of the arXiv preprint or \\\n            ``None``.\n    \"\"\"\n    try:\n        request = requests.get(ARXIV_EPRINT_URL.format(arxiv_id=arxiv_id))\n        request.raise_for_status()\n        file_object = io.BytesIO(request.content)\n        return tarfile.open(fileobj=file_object)\n    except (RequestException, AssertionError, tarfile.TarError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bbl(arxiv_id):\n    tar_file = get_sources(arxiv_id)\n    bbl_files = [i for i in tar_file.getmembers() if i.name.endswith(\".bbl\")]\n    bbl_files = [tar_file.extractfile(member).read().decode(tarfile.ENCODING)\n                 for member in bbl_files]\n    return bbl_files", "response": "Get the. bbl files of a given preprint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extractDates(inp, tz=None, now=None):\n    service = DateService(tz=tz, now=now)\n    return service.extractDates(inp)", "response": "This method extracts semantic date information from an input string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting all day - related information from an input string.", "response": "def extractDays(self, inp):\n        \"\"\"Extracts all day-related information from an input string.\n        Ignores any information related to the specific time-of-day.\n\n        Args:\n            inp (str): Input string to be parsed.\n\n        Returns:\n            A list of datetime objects containing the extracted date from the\n            input snippet, or an empty list if none found.\n        \"\"\"\n        inp = self._preprocess(inp)\n\n        def extractDayOfWeek(dayMatch):\n            if dayMatch.group(5) in self.__daysOfWeek__:\n                return self.__daysOfWeek__.index(dayMatch.group(5))\n            elif dayMatch.group(6) in self.__daysOfWeek__:\n                return self.__daysOfWeek__.index(dayMatch.group(6))\n\n        def extractMonth(dayMatch):\n            if dayMatch.group(7) in self.__months__:\n                return self.__months__.index(dayMatch.group(7)) + 1\n            elif dayMatch.group(7) in self.__shortMonths__:\n                return self.__shortMonths__.index(dayMatch.group(7)) + 1\n\n        def extractDay(dayMatch):\n            combined = dayMatch.group(8) + dayMatch.group(9)\n            if combined in self.__dateDescriptors__:\n                return self.__dateDescriptors__[combined]\n            elif dayMatch.group(8) in self.__dateDescriptors__:\n                return self.__dateDescriptors__[dayMatch.group(8)]\n            elif int(dayMatch.group(8)) in self.__dateDescriptors__.values():\n                return int(dayMatch.group(8))\n\n        def extractDaysFrom(dayMatch):\n            if not dayMatch.group(1):\n                return 0\n\n            def numericalPrefix(dayMatch):\n                # Grab 'three' of 'three weeks from'\n                prefix = inp.split(dayMatch.group(1))[0].strip().split(' ')\n                prefix.reverse()\n                prefix = list(filter(lambda s: s != 'and', prefix))\n\n                # Generate best guess number\n                service = NumberService()\n                num = prefix[0]\n                if service.isValid(num):\n                    for n in prefix[1:]:\n                        inc = n + \" \" + num\n                        if service.isValid(inc):\n                            num = inc\n                        else:\n                            break\n                    return service.parse(num)\n                return 1\n\n            factor = numericalPrefix(dayMatch)\n\n            if dayMatch.group(2) == 'week':\n                return factor * 7\n            elif dayMatch.group(2) == 'day':\n                return factor * 1\n\n        def handleMatch(dayMatch):\n            def safe(exp):\n                \"\"\"For safe evaluation of regex groups\"\"\"\n                try:\n                    return exp()\n                except:\n                    return False\n\n            days_from = safe(lambda: extractDaysFrom(dayMatch))\n            today = safe(lambda: dayMatch.group(3) in self.__todayMatches__)\n            tomorrow = safe(lambda: dayMatch.group(3)\n                            in self.__tomorrowMatches__)\n            next_week = safe(lambda: dayMatch.group(4) == 'next')\n            day_of_week = safe(lambda: extractDayOfWeek(dayMatch))\n            month = safe(lambda: extractMonth(dayMatch))\n            day = safe(lambda: extractDay(dayMatch))\n\n            # Convert extracted terms to datetime object\n            if not dayMatch:\n                return None\n            elif today:\n                d = self.now\n            elif tomorrow:\n                d = self.now + datetime.timedelta(days=1)\n            elif type(day_of_week) == int:\n                current_day_of_week = self.now.weekday()\n                num_days_away = (day_of_week - current_day_of_week) % 7\n\n                if next_week:\n                    num_days_away += 7\n\n                d = self.now + \\\n                    datetime.timedelta(days=num_days_away)\n            elif month and day:\n                d = datetime.datetime(\n                    self.now.year, month, day,\n                    self.now.hour, self.now.minute)\n\n            if days_from:\n                d += datetime.timedelta(days=days_from)\n\n            return d\n\n        matches = self._dayRegex.finditer(inp)\n        return [handleMatch(dayMatch) for dayMatch in matches]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extractTimes(self, inp):\n        def handleMatch(time):\n            relative = False\n\n            if not time:\n                return None\n\n            # Default times: 8am, 12pm, 7pm\n            elif time.group(1) == 'morning':\n                h = 8\n                m = 0\n            elif time.group(1) == 'afternoon':\n                h = 12\n                m = 0\n            elif time.group(1) == 'evening':\n                h = 19\n                m = 0\n            elif time.group(4) and time.group(5):\n                h, m = 0, 0\n\n                # Extract hours difference\n                converter = NumberService()\n                try:\n                    diff = converter.parse(time.group(4))\n                except:\n                    return None\n\n                if time.group(5) == 'hours':\n                    h += diff\n                else:\n                    m += diff\n\n                # Extract minutes difference\n                if time.group(6):\n                    converter = NumberService()\n                    try:\n                        diff = converter.parse(time.group(7))\n                    except:\n                        return None\n\n                    if time.group(8) == 'hours':\n                        h += diff\n                    else:\n                        m += diff\n\n                relative = True\n            else:\n                # Convert from \"HH:MM pm\" format\n                t = time.group(2)\n                h, m = int(t.split(':')[0]) % 12, int(t.split(':')[1])\n\n                try:\n                    if time.group(3) == 'pm':\n                        h += 12\n                except IndexError:\n                    pass\n\n            if relative:\n                return self.now + datetime.timedelta(hours=h, minutes=m)\n            else:\n                return datetime.datetime(\n                    self.now.year, self.now.month, self.now.day, h, m\n                )\n\n        inp = self._preprocess(inp)\n        return [handleMatch(time) for time in self._timeRegex.finditer(inp)]", "response": "Extracts time - related information from an input string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extractDates(self, inp):\n        def merge(param):\n            day, time = param\n            if not (day or time):\n                return None\n\n            if not day:\n                return time\n            if not time:\n                return day\n\n            return datetime.datetime(\n                day.year, day.month, day.day, time.hour, time.minute\n            )\n\n        days = self.extractDays(inp)\n        times = self.extractTimes(inp)\n        return map(merge, zip_longest(days, times, fillvalue=None))", "response": "Extract semantic date information from an input string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the first date found in the input string or None if not found.", "response": "def extractDate(self, inp):\n        \"\"\"Returns the first date found in the input string, or None if not\n        found.\"\"\"\n        dates = self.extractDates(inp)\n        for date in dates:\n            return date\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a datetime object representing a day into a human - ready string that can be read spoken aloud etc.", "response": "def convertDay(self, day, prefix=\"\", weekday=False):\n        \"\"\"Convert a datetime object representing a day into a human-ready\n        string that can be read, spoken aloud, etc.\n\n        Args:\n            day (datetime.date): A datetime object to be converted into text.\n            prefix (str): An optional argument that prefixes the converted\n                string. For example, if prefix=\"in\", you'd receive \"in two\n                days\", rather than \"two days\", while the method would still\n                return \"tomorrow\" (rather than \"in tomorrow\").\n            weekday (bool): An optional argument that returns \"Monday, Oct. 1\"\n                if True, rather than \"Oct. 1\".\n\n        Returns:\n            A string representation of the input day, ignoring any time-related\n            information.\n        \"\"\"\n        def sameDay(d1, d2):\n            d = d1.day == d2.day\n            m = d1.month == d2.month\n            y = d1.year == d2.year\n            return d and m and y\n\n        tom = self.now + datetime.timedelta(days=1)\n\n        if sameDay(day, self.now):\n            return \"today\"\n        elif sameDay(day, tom):\n            return \"tomorrow\"\n\n        if weekday:\n            dayString = day.strftime(\"%A, %B %d\")\n        else:\n            dayString = day.strftime(\"%B %d\")\n\n        # Ex) Remove '0' from 'August 03'\n        if not int(dayString[-2]):\n            dayString = dayString[:-2] + dayString[-1]\n\n        return prefix + \" \" + dayString"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convertTime(self, time):\n        # if ':00', ignore reporting minutes\n        m_format = \"\"\n        if time.minute:\n            m_format = \":%M\"\n\n        timeString = time.strftime(\"%I\" + m_format + \" %p\")\n\n        # if '07:30', cast to '7:30'\n        if not int(timeString[0]):\n            timeString = timeString[1:]\n\n        return timeString", "response": "Convert a datetime object representing a time into a human - ready string that can be read spoken aloud etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convertDate(self, date, prefix=\"\", weekday=False):\n        dayString = self.convertDay(\n            date, prefix=prefix, weekday=weekday)\n        timeString = self.convertTime(date)\n        return dayString + \" at \" + timeString", "response": "Converts a datetime object representing into a human - ready ISO - 8601 date string that can be read spoken aloud etc. In effect runs\n        both convertDay and convertTime on the input and returns a human - ready ISO - 8601 date string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _move(self):\n        newpath = self.action['newpath']\n        try:\n            self.fs.move(self.fp,newpath)\n        except OSError:\n            raise tornado.web.HTTPError(400)\n        return newpath", "response": "Called during a PUT request where the action specifies\n        a move operation. Returns the new path of the new file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls during a PUT request where the action specifies a copy operation. Returns the copy path of the new file.", "response": "def _copy(self):\n        \"\"\"\n        Called during a PUT request where the action specifies\n        a copy operation. Returns resource URI of the new file.\n        \"\"\"\n        copypath = self.action['copypath']\n        try:\n            self.fs.copy(self.fp,copypath)\n        except OSError:\n            raise tornado.web.HTTPError(400)\n        return copypath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _rename(self):\n        newname = self.action['newname']\n        try:\n            newpath = self.fs.rename(self.fp,newname)\n        except OSError:\n            raise tornado.web.HTTPError(400)\n        return newpath", "response": "Called during a PUT request where the action specifies\n        a rename operation. Returns the new file URI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget details for the filesystem including configured volumes.", "response": "def get(self):\n        \"\"\"\n        Return details for the filesystem, including configured volumes.\n        \"\"\"\n        res = self.fs.get_filesystem_details()\n        res = res.to_dict()\n        self.write(res)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproviding move copy and rename functionality.", "response": "def put(self):\n        \"\"\"\n        Provides move, copy, and rename functionality. An action must be\n        specified when calling this method.\n        \"\"\"\n        self.fp = self.get_body_argument('filepath')\n        self.action = self.get_body_argument('action')\n\n        try:\n            ptype = self.fs.get_type_from_path(self.fp)\n        except OSError:\n            raise tornado.web.HTTPError(404)\n        if ptype == 'directory':\n            self.handler_name = 'filesystem:directories-details'\n        else:\n            self.handler_name = 'filesystem:files-details'\n\n        if self.action['action'] == 'move':\n            newpath = self._move()\n            self.write({'filepath':newpath})\n        elif self.action['action'] == 'copy':\n            newpath = self._copy()\n            self.write({'filepath':newpath})\n        elif self.action['action'] == 'rename':\n            newpath = self._rename()\n            self.write({'filepath':newpath})\n        else:\n            raise tornado.web.HTTPError(400)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when the client is listening and the HTTP request is made.", "response": "def post(self, *args):\n        \"\"\"\n        Start a new filewatcher at the specified path.\n        \"\"\"\n        filepath = self.get_body_argument('filepath')\n        if not self.fs.exists(filepath):\n            raise tornado.web.HTTPError(404)\n\n        Filewatcher.add_directory_to_watch(filepath)\n        self.write({'msg':'Watcher added for {}'.format(filepath)})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, filepath):\n        Filewatcher.remove_directory_to_watch(filepath)\n        self.write({'msg':'Watcher deleted for {}'.format(filepath)})", "response": "Stop and delete the specified filewatcher."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, filepath):\n        try:\n            res = self.fs.get_file_details(filepath)\n            res = res.to_dict()\n            self.write(res)\n        except OSError:\n            raise tornado.web.HTTPError(404)", "response": "Get details for the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put(self, filepath):\n        action = self.get_body_argument('action')\n\n        if action['action'] == 'update_group':\n            newgrp = action['group']\n            try:\n                self.fs.update_group(filepath,newgrp)\n                self.write({'msg':'Updated group for {}'.format(filepath)})\n            except OSError:\n                raise tornado.web.HTTPError(404)\n        elif action['action'] == 'update_permissions':\n            newperms = action['permissions']\n            try:\n                self.fs.update_permissions(filepath,newperms)\n                self.write({'msg':'Updated permissions for {}'.format(filepath)})\n            except OSError:\n                raise tornado.web.HTTPError(404)\n        else:\n            raise tornado.web.HTTPError(400)", "response": "Change the group or permissions of the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, filepath):\n        try:\n            self.fs.delete(filepath)\n            self.write({'msg':'File deleted at {}'.format(filepath)})\n        except OSError:\n            raise tornado.web.HTTPError(404)", "response": "Delete the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget directory details for the specified file.", "response": "def get(self, filepath):\n        \"\"\"\n        Get directory details for the specified file. If contents is\n        set to True (default) then the directory contents will be sent\n        along with the directory details. If dir_size is set to True\n        (default=False) then du -hs will be run against subdirectories\n        for accurate content sizes.\n        \"\"\"\n        contents = self.get_argument('contents', False)\n        if contents == u'true':\n            contents = True\n        else:\n            contents = False\n        dir_sizes = self.get_argument('dir_sizes', False)\n        if dir_sizes == u'true':\n            dir_sizes = True\n        else:\n            dir_sizes = False\n\n        try:\n            res = self.fs.get_directory_details(filepath,contents=contents,dir_sizes=dir_sizes)\n            res = res.to_dict()\n            self.write(res)\n        except OSError:\n            raise tornado.web.HTTPError(404)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new directory at the specified path.", "response": "def post(self):\n        \"\"\"\n        Create a new directory at the specified path.\n        \"\"\"\n        filepath = self.get_body_argument('filepath')\n\n        try:\n            self.fs.create_directory(filepath)\n            encoded_filepath = tornado.escape.url_escape(filepath,plus=True)\n            resource_uri = self.reverse_url('filesystem:directories-details', encoded_filepath)\n            self.write({'uri':resource_uri})\n        except OSError:\n            raise tornado.web.HTTPError(404)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, filepath):\n        exists = self.fs.exists(filepath)\n        if exists:\n            mime = magic.Magic(mime=True)\n            mime_type = mime.from_file(filepath)\n            if mime_type in self.unsupported_types:\n                self.set_status(204)\n                return\n            else:\n                contents = self.fs.read_file(filepath)\n            self.write({'filepath':filepath,'contents': contents})\n        else:\n            raise tornado.web.HTTPError(404)", "response": "Get the contents of the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the contents of the given file to the specified file.", "response": "def post(self, filepath):\n        \"\"\"\n        Write the given contents to the specified file. This is not\n        an append, all file contents will be replaced by the contents\n        given.\n        \"\"\"\n        try:\n            content = self.get_body_argument('content')\n            self.fs.write_file(filepath, content)\n            self.write({'msg': 'Updated file at {}'.format(filepath)})\n        except OSError:\n            raise tornado.web.HTTPError(404)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the content of the requested resource which is located at the given absolute path.", "response": "def get_content(self, start=None, end=None):\n        \"\"\"\n        Retrieve the content of the requested resource which is located\n        at the given absolute path.\n        This method should either return a byte string or an iterator\n        of byte strings.  The latter is preferred for large files\n        as it helps reduce memory fragmentation.\n        \"\"\"\n        with open(self.filepath, \"rb\") as file:\n            if start is not None:\n                file.seek(start)\n            if end is not None:\n                remaining = end - (start or 0)\n            else:\n                remaining = None\n            while True:\n                chunk_size = 64 * 1024\n                if remaining is not None and remaining < chunk_size:\n                    chunk_size = remaining\n                chunk = file.read(chunk_size)\n                if chunk:\n                    if remaining is not None:\n                        remaining -= len(chunk)\n                    yield chunk\n                else:\n                    if remaining is not None:\n                        assert remaining == 0\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_headers(self):\n        self.set_header(\"Accept-Ranges\", \"bytes\")\n\n        content_type = self.get_content_type()\n        if content_type:\n            self.set_header(\"Content-Type\", content_type)", "response": "Sets the content headers on the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the content type of the file.", "response": "def get_content_type(self):\n        \"\"\"\n        Returns the ``Content-Type`` header to be used for this request.\n        \"\"\"\n        mime_type, encoding = mimetypes.guess_type(self.filepath)\n        if encoding == \"gzip\":\n            return \"application/gzip\"\n        elif encoding is not None:\n            return \"application/octet-stream\"\n        elif mime_type is not None:\n            return mime_type\n        # if mime_type not detected, use application/octet-stream\n        else:\n            return \"application/octet-stream\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a new shared object.", "response": "def register(self, name, description, obj):\n        \"\"\"\n        Registers a new shared object.\n\n        :param name: Unique name for shared object\n        :type name: str\n        :param description: Description of shared object\n        :type description: str\n        :param obj: The object, which shall be shared\n        :type obj: any type\n        \"\"\"\n        return self.app.shared_objects.register(name, description, obj, self.plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, name=None):\n        return self.app.shared_objects.get(name, self.plugin)", "response": "Get a specific shared object from the application level."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns requested shared objects.", "response": "def get(self, name=None, plugin=None):\n        \"\"\"\n        Returns requested shared objects.\n\n        :param name: Name of a request shared object\n        :type name: str or None\n        :param plugin: Plugin, which has registered the requested shared object\n        :type plugin: GwBasePattern instance or None\n        \"\"\"\n        if plugin is not None:\n            if name is None:\n                shared_objects_list = {}\n                for key in self._shared_objects.keys():\n                    if self._shared_objects[key].plugin == plugin:\n                        shared_objects_list[key] = self._shared_objects[key]\n                return shared_objects_list\n            else:\n                if name in self._shared_objects.keys():\n                    if self._shared_objects[name].plugin == plugin:\n                        return self._shared_objects[name]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if name is None:\n                return self._shared_objects\n            else:\n                if name in self._shared_objects.keys():\n                    return self._shared_objects[name]\n                else:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a new shared object.", "response": "def register(self, name, description, obj, plugin):\n        \"\"\"\n        Registers a new shared object.\n\n        :param name: Unique name for shared object\n        :type name: str\n        :param description: Description of shared object\n        :type description: str\n        :param obj: The object, which shall be shared\n        :type obj: any type\n        :param plugin: Plugin, which registers the new shared object\n        \"\"\"\n        if name in self._shared_objects.keys():\n            raise SharedObjectExistException(\"Shared Object %s already registered by %s\"\n                                             % (name, self._shared_objects[name].plugin.name))\n\n        new_shared_object = SharedObject(name, description, obj, plugin)\n        self._shared_objects[name] = new_shared_object\n        self.log.debug(\"Shared object registered: %s\" % name)\n        return new_shared_object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_signals(self):\n        print(\"Signal list\")\n        print(\"***********\\n\")\n        for key, signal in self.app.signals.signals.items():\n            print(\"%s (%s)\\n  %s\\n\" % (signal.name, signal.plugin.name, signal.description))", "response": "Prints a list of all registered signals. Including description and plugin name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a list of all registered receivers. Including signal plugin name and description.", "response": "def list_receivers(self):\n        \"\"\"\n        Prints a list of all registered receivers. Including signal, plugin name and description.\n        \"\"\"\n        print(\"Receiver list\")\n        print(\"*************\\n\")\n        for key, receiver in self.app.signals.receivers.items():\n            print(\"%s <-- %s (%s):\\n  %s\\n\" % (receiver.name,\n                                               receiver.signal,\n                                               receiver.plugin.name,\n                                               receiver.description))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_elementary_type(elem_type):\n        if not oh.is_type(elem_type, bt.XmrType):\n            return False\n        if oh.is_type(elem_type, (bt.UVarintType, bt.IntType, mt.UnicodeType)):\n            return True\n        return False", "response": "Returns True if the type is elementary - not versioned\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef command_copytree(args):\n    for srcdir in args.srcdirs:\n        basename = os.path.basename(srcdir)\n        destdir2 = os.path.normpath(os.path.join(args.destdir, basename))\n        if os.path.exists(destdir2):\n            shutil.rmtree(destdir2)\n        sys.stdout.write(\"copytree: %s => %s\\n\" % (srcdir, destdir2))\n        shutil.copytree(srcdir, destdir2)\n    return 0", "response": "Copy one or more source directories below a destination directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command_copy(args):\n    sources = args.sources\n    destpath = args.destpath\n    source_files = []\n    for file_ in sources:\n        if \"*\" in file_:\n            selected = glob(file_)\n            source_files.extend(selected)\n        elif os.path.isfile(file_):\n            source_files.append(file_)\n\n    if destpath.endswith(\"/\") or os.path.isdir(destpath) or len(sources) > 1:\n        # -- DESTDIR-MODE: Last argument is a directory.\n        destdir = destpath\n    else:\n        # -- DESTFILE-MODE: Copy (and rename) one file.\n        assert len(source_files) == 1\n        destdir = os.path.dirname(destpath)\n\n    # -- WORK-HORSE: Copy one or more files to destpath.\n    if not os.path.isdir(destdir):\n        sys.stdout.write(\"copy: Create dir %s\\n\" % destdir)\n        os.makedirs(destdir)\n    for source in source_files:\n        destname = os.path.join(destdir, os.path.basename(source))\n        sys.stdout.write(\"copy: %s => %s\\n\" % (source, destname))\n        shutil.copy(source, destname)\n    return 0", "response": "Copy one or more source files to a destpath."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a non - existing directory.", "response": "def command_mkdir(args):\n    \"\"\"\n    Create a non-existing directory (or more ...).\n    If the directory exists, the step is skipped.\n    Similar to the UNIX command: 'mkdir -p dir'\n    \"\"\"\n    errors = 0\n    for directory in args.dirs:\n        if os.path.exists(directory):\n            if not os.path.isdir(directory):\n                # -- SANITY CHECK: directory exists, but as file...\n                sys.stdout.write(\"mkdir: %s\\n\" % directory)\n                sys.stdout.write(\"ERROR: Exists already, but as file...\\n\")\n                errors += 1\n        else:\n            # -- NORMAL CASE: Directory does not exits yet.\n            assert not os.path.isdir(directory)\n            sys.stdout.write(\"mkdir: %s\\n\" % directory)\n            os.makedirs(directory)\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef command_py2to3(args):\n    from lib2to3.main import main\n    sys.exit(main(\"lib2to3.fixes\", args=args.sources))", "response": "Python 2 to 3 conversion tool."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncommands util with subcommands for tox environments.", "response": "def toxcmd_main(args=None):\n    \"\"\"Command util with subcommands for tox environments.\"\"\"\n    usage = \"USAGE: %(prog)s [OPTIONS] COMMAND args...\"\n    if args is None:\n        args = sys.argv[1:]\n\n    # -- STEP: Build command-line parser.\n    parser = argparse.ArgumentParser(description=inspect.getdoc(toxcmd_main),\n                                     formatter_class=FORMATTER_CLASS)\n    common_parser = parser.add_argument_group(\"Common options\")\n    common_parser.add_argument(\"--version\", action=\"version\", version=VERSION)\n    subparsers = parser.add_subparsers(help=\"commands\")\n    for command in discover_commands():\n        command_parser = subparsers.add_parser(command.name,\n                                               usage=command.usage,\n                                               description=command.description,\n                                               help=command.short_description,\n                                               formatter_class=FORMATTER_CLASS)\n        command_parser.set_defaults(func=command)\n        command.setup_parser(command_parser)\n        command.parser = command_parser\n\n    # -- STEP: Process command-line and run command.\n    options = parser.parse_args(args)\n    command_function = options.func\n    return command_function(options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndischarging all third party caveats in the given macaroon.", "response": "def discharge_all(m, get_discharge, local_key=None):\n    '''Gathers discharge macaroons for all the third party caveats in m\n    (and any subsequent caveats required by those) using get_discharge to\n    acquire each discharge macaroon.\n    The local_key parameter may optionally hold the key of the client, in\n    which case it will be used to discharge any third party caveats with the\n    special location \"local\". In this case, the caveat itself must be \"true\".\n    This can be used be a server to ask a client to prove ownership of the\n    private key.\n    It returns a list of macaroon with m as the first element, followed by all\n    the discharge macaroons.\n    All the discharge macaroons will be bound to the primary macaroon.\n\n    The get_discharge function is passed a context (AuthContext),\n    the caveat(pymacaroons.Caveat) to be discharged and encrypted_caveat (bytes) will be\n    passed the external caveat payload found in m, if any.\n    It should return a bakery.Macaroon object holding the discharge\n    macaroon for the third party caveat.\n    '''\n    primary = m.macaroon\n    discharges = [primary]\n\n    # cav holds the macaroon caveat that needs discharge.\n    # encrypted_caveat (bytes) holds encrypted caveat if it was held\n    # externally.\n    _NeedCaveat = namedtuple('_NeedCaveat', 'cav encrypted_caveat')\n    need = []\n\n    def add_caveats(m):\n        for cav in m.macaroon.caveats:\n            if cav.location is None or cav.location == '':\n                continue\n            encrypted_caveat = m.caveat_data.get(cav.caveat_id, None)\n            need.append(\n                _NeedCaveat(cav=cav,\n                            encrypted_caveat=encrypted_caveat))\n    add_caveats(m)\n    while len(need) > 0:\n        cav = need[0]\n        need = need[1:]\n        if cav.cav.location == 'local':\n            if local_key is None:\n                raise ThirdPartyCaveatCheckFailed(\n                    'found local third party caveat but no private key provided',\n                )\n            # TODO use a small caveat id.\n            dm = discharge(ctx=emptyContext,\n                           key=local_key,\n                           checker=_LocalDischargeChecker(),\n                           caveat=cav.encrypted_caveat,\n                           id=cav.cav.caveat_id_bytes,\n                           locator=_EmptyLocator())\n        else:\n            dm = get_discharge(cav.cav, cav.encrypted_caveat)\n        # It doesn't matter that we're invalidating dm here because we're\n        # about to throw it away.\n        discharge_m = dm.macaroon\n        m = primary.prepare_for_request(discharge_m)\n        discharges.append(m)\n        add_caveats(dm)\n    return discharges"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndischarge a third party caveat.", "response": "def discharge(ctx, id, caveat, key, checker, locator):\n    ''' Creates a macaroon to discharge a third party caveat.\n\n    The given parameters specify the caveat and how it should be checked.\n    The condition implicit in the caveat is checked for validity using checker.\n    If it is valid, a new macaroon is returned which discharges the caveat.\n    The macaroon is created with a version derived from the version that was\n    used to encode the id.\n\n    :param id: (bytes) holds the id to give to the discharge macaroon.\n    If Caveat is empty, then the id also holds the encrypted third party\n    caveat.\n    :param caveat: (bytes) holds the encrypted third party caveat.\n    If this is None, id will be used.\n    :param key: holds the key to use to decrypt the third party caveat\n    information and to encrypt any additional third party caveats returned by\n    the caveat checker.\n    :param checker: used to check the third party caveat, and may also return\n    further caveats to be added to the discharge macaroon.\n    :param locator: used to information on third parties referred to by third\n    party caveats returned by the Checker.\n    '''\n    caveat_id_prefix = []\n    if caveat is None:\n        # The caveat information is encoded in the id itself.\n        caveat = id\n    else:\n        # We've been given an explicit id, so when extra third party\n        # caveats are added, use that id as the prefix\n        # for any more ids.\n        caveat_id_prefix = id\n    cav_info = decode_caveat(key, caveat)\n    cav_info = ThirdPartyCaveatInfo(\n        condition=cav_info.condition,\n        first_party_public_key=cav_info.first_party_public_key,\n        third_party_key_pair=cav_info.third_party_key_pair,\n        root_key=cav_info.root_key,\n        caveat=cav_info.caveat,\n        version=cav_info.version,\n        id=id,\n        namespace=cav_info.namespace\n    )\n    # Note that we don't check the error - we allow the\n    # third party checker to see even caveats that we can't\n    # understand.\n    try:\n        cond, arg = checkers.parse_caveat(cav_info.condition)\n    except ValueError as exc:\n        raise VerificationError(exc.args[0])\n\n    if cond == checkers.COND_NEED_DECLARED:\n        cav_info = cav_info._replace(condition=arg)\n        caveats = _check_need_declared(ctx, cav_info, checker)\n    else:\n        caveats = checker.check_third_party_caveat(ctx, cav_info)\n\n    # Note that the discharge macaroon does not need to\n    # be stored persistently. Indeed, it would be a problem if\n    # we did, because then the macaroon could potentially be used\n    # for normal authorization with the third party.\n    m = Macaroon(\n        cav_info.root_key,\n        id,\n        '',\n        cav_info.version,\n        cav_info.namespace,\n    )\n    m._caveat_id_prefix = caveat_id_prefix\n    if caveats is not None:\n        for cav in caveats:\n            m.add_caveat(cav, key, locator)\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a third - party caveat that is added to a macaroon with the given PublicKey.", "response": "def local_third_party_caveat(key, version):\n    ''' Returns a third-party caveat that, when added to a macaroon with\n    add_caveat, results in a caveat with the location \"local\", encrypted with\n    the given PublicKey.\n    This can be automatically discharged by discharge_all passing a local key.\n    '''\n    if version >= VERSION_2:\n        loc = 'local {} {}'.format(version, key)\n    else:\n        loc = 'local {}'.format(key)\n    return checkers.Caveat(location=loc, condition='')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deserialize_namespace(data):\n    ''' Deserialize a Namespace object.\n\n    :param data: bytes or str\n    :return: namespace\n    '''\n    if isinstance(data, bytes):\n        data = data.decode('utf-8')\n    kvs = data.split()\n    uri_to_prefix = {}\n    for kv in kvs:\n        i = kv.rfind(':')\n        if i == -1:\n            raise ValueError('no colon in namespace '\n                             'field {}'.format(repr(kv)))\n        uri, prefix = kv[0:i], kv[i + 1:]\n        if not is_valid_schema_uri(uri):\n            # Currently this can't happen because the only invalid URIs\n            # are those which contain a space\n            raise ValueError(\n                'invalid URI {} in namespace '\n                'field {}'.format(repr(uri), repr(kv)))\n        if not is_valid_prefix(prefix):\n            raise ValueError(\n                'invalid prefix {} in namespace field'\n                ' {}'.format(repr(prefix), repr(kv)))\n        if uri in uri_to_prefix:\n            raise ValueError(\n                'duplicate URI {} in '\n                'namespace {}'.format(repr(uri), repr(data)))\n        uri_to_prefix[uri] = prefix\n    return Namespace(uri_to_prefix)", "response": "Deserialize a Namespace object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a serialized form of the Namepace.", "response": "def serialize_text(self):\n        '''Returns a serialized form of the Namepace.\n\n        All the elements in the namespace are sorted by\n        URI, joined to the associated prefix with a colon and\n        separated with spaces.\n        :return: bytes\n        '''\n        if self._uri_to_prefix is None or len(self._uri_to_prefix) == 0:\n            return b''\n        od = collections.OrderedDict(sorted(self._uri_to_prefix.items()))\n        data = []\n        for uri in od:\n            data.append(uri + ':' + od[uri])\n        return ' '.join(data).encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering the given URI and associates it with the given prefix.", "response": "def register(self, uri, prefix):\n        '''Registers the given URI and associates it with the given prefix.\n\n        If the URI has already been registered, this is a no-op.\n\n        :param uri: string\n        :param prefix: string\n        '''\n        if not is_valid_schema_uri(uri):\n            raise KeyError(\n                'cannot register invalid URI {} (prefix {})'.format(\n                    uri, prefix))\n        if not is_valid_prefix(prefix):\n            raise ValueError(\n                'cannot register invalid prefix %q for URI %q'.format(\n                    prefix, uri))\n        if self._uri_to_prefix.get(uri) is None:\n            self._uri_to_prefix[uri] = prefix"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving the given caveat by using resolve to map from its schema namespace to the appropriate prefix.", "response": "def resolve_caveat(self, cav):\n        ''' Resolves the given caveat(string) by using resolve to map from its\n        schema namespace to the appropriate prefix.\n        If there is no registered prefix for the namespace, it returns an error\n        caveat.\n        If cav.namespace is empty or cav.location is non-empty, it returns cav\n        unchanged.\n\n        It does not mutate ns and may be called concurrently with other\n        non-mutating Namespace methods.\n        :return: Caveat object\n        '''\n        # TODO: If a namespace isn't registered, try to resolve it by\n        # resolving it to the latest compatible version that is\n        # registered.\n        if cav.namespace == '' or cav.location != '':\n            return cav\n\n        prefix = self.resolve(cav.namespace)\n        if prefix is None:\n            err_cav = error_caveat(\n                'caveat {} in unregistered namespace {}'.format(\n                    cav.condition, cav.namespace))\n            if err_cav.namespace != cav.namespace:\n                prefix = self.resolve(err_cav.namespace)\n                if prefix is None:\n                    prefix = ''\n            cav = err_cav\n        if prefix != '':\n            cav.condition = condition_with_prefix(prefix, cav.condition)\n        cav.namespace = ''\n        return cav"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef with_value(self, key, val):\n        ''' Return a copy of the AuthContext object with the given key and\n        value added.\n        '''\n        new_dict = dict(self._dict)\n        new_dict[key] = val\n        return AuthContext(new_dict)", "response": "Return a copy of the AuthContext object with the given key and val added."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves figures to a single file.", "response": "def save_figures(filename, fig_IDs=None, **kwargs):\n    \"\"\"\n    Save figures.\n    \n    Parameters\n    ----------\n    filename - str\n        Name of output file\n        \n    fig_IDs - int, numpy.array, list, optional, default None\n        A list of open figure IDs or a figure ID that will be saved to a\n        pdf/png file respectively.\n    \n    **kwargs - \n        Extra keyword arguments passed into 'matplotlib.pyplot.savefig'.\n        \n    \"\"\"\n    import matplotlib.pyplot as plt\n    if(fig_IDs is not None):\n        if(type(fig_IDs) is list):\n            savetype = 'pdf'\n        else:\n            savetype = 'png'\n    else:\n        savetype = 'pdf'\n\n    if(savetype == 'pdf'):\n        from matplotlib.backends.backend_pdf import PdfPages\n\n        if(len(filename.split('.')) == 1):\n            filename = filename + '.pdf'\n        else:\n            filename = '.'.join(filename.split('.')[:-1])+'.pdf'\n\n        pdf = PdfPages(filename)\n\n        if fig_IDs is None:\n            figs = [plt.figure(n) for n in plt.get_fignums()]\n        else:\n            figs = [plt.figure(n) for n in fig_IDs]\n\n        for fig in figs:\n            fig.savefig(pdf, format='pdf', **kwargs)\n        pdf.close()\n    elif(savetype == 'png'):\n        plt.figure(fig_IDs).savefig(filename, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a regular expression pattern for a data type with the specified cardinality.", "response": "def make_pattern(self, pattern, listsep=','):\n        \"\"\"Make pattern for a data type with the specified cardinality.\n\n        .. code-block:: python\n\n            yes_no_pattern = r\"yes|no\"\n            many_yes_no = Cardinality.one_or_more.make_pattern(yes_no_pattern)\n\n        :param pattern:  Regular expression for type (as string).\n        :param listsep:  List separator for multiple items (as string, optional)\n        :return: Regular expression pattern for type with cardinality.\n        \"\"\"\n        if self is Cardinality.one:\n            return pattern\n        elif self is Cardinality.zero_or_one:\n            return self.schema % pattern\n        else:\n            return self.schema % (pattern, listsep, pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_group_count(self, pattern):\n        group_count = self.group_count\n        pattern_repeated = 1\n        if self.is_many():\n            pattern_repeated = 2\n        return group_count + pattern_repeated * pattern_group_count(pattern)", "response": "Compute the number of regexp match groups when the pattern is provided\n        to the : func:`Cardinality. make_pattern()` method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a type converter for the specified cardinality.", "response": "def with_cardinality(cls, cardinality, converter, pattern=None,\n                         listsep=','):\n        \"\"\"Creates a type converter for the specified cardinality\n        by using the type converter for T.\n\n        :param cardinality: Cardinality to use (0..1, 0..*, 1..*).\n        :param converter: Type converter (function) for data type T.\n        :param pattern:  Regexp pattern for an item (=converter.pattern).\n        :return: type-converter for optional<T> (T or None).\n        \"\"\"\n        if cardinality is Cardinality.one:\n            return converter\n        # -- NORMAL-CASE\n        builder_func = getattr(cls, \"with_%s\" % cardinality.name)\n        if cardinality is Cardinality.zero_or_one:\n            return builder_func(converter, pattern)\n        else:\n            # -- MANY CASE: 0..*, 1..*\n            return builder_func(converter, pattern, listsep=listsep)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a type converter for a T with 0.. 1 times by using the type converter function for one item of T.", "response": "def with_zero_or_one(cls, converter, pattern=None):\n        \"\"\"Creates a type converter for a T with 0..1 times\n        by using the type converter for one item of T.\n\n        :param converter: Type converter (function) for data type T.\n        :param pattern:  Regexp pattern for an item (=converter.pattern).\n        :return: type-converter for optional<T> (T or None).\n        \"\"\"\n        cardinality = Cardinality.zero_or_one\n        if not pattern:\n            pattern = getattr(converter, \"pattern\", cls.default_pattern)\n        optional_pattern = cardinality.make_pattern(pattern)\n        group_count = cardinality.compute_group_count(pattern)\n\n        def convert_optional(text, m=None):\n            if text:\n                text = text.strip()\n            if not text:\n                return None\n            return converter(text)\n        convert_optional.pattern = optional_pattern\n        # OLD: convert_optional.group_count = group_count\n        convert_optional.regex_group_count = group_count\n        return convert_optional"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a type converter function for a list of items with 0.. N items.", "response": "def with_zero_or_more(cls, converter, pattern=None, listsep=\",\"):\n        \"\"\"Creates a type converter function for a list<T> with 0..N items\n        by using the type converter for one item of T.\n\n        :param converter: Type converter (function) for data type T.\n        :param pattern:  Regexp pattern for an item (=converter.pattern).\n        :param listsep:  Optional list separator between items (default: ',')\n        :return: type-converter for list<T>\n        \"\"\"\n        cardinality = Cardinality.zero_or_more\n        if not pattern:\n            pattern  = getattr(converter, \"pattern\", cls.default_pattern)\n        many0_pattern = cardinality.make_pattern(pattern, listsep)\n        group_count = cardinality.compute_group_count(pattern)\n\n        def convert_list0(text, m=None):\n            if text:\n                text = text.strip()\n            if not text:\n                return []\n            return [converter(part.strip()) for part in text.split(listsep)]\n        convert_list0.pattern = many0_pattern\n        # OLD convert_list0.group_count = group_count\n        convert_list0.regex_group_count = group_count\n        return convert_list0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a type converter function for a list of items with 1.. N items.", "response": "def with_one_or_more(cls, converter, pattern=None, listsep=\",\"):\n        \"\"\"Creates a type converter function for a list<T> with 1..N items\n        by using the type converter for one item of T.\n\n        :param converter: Type converter (function) for data type T.\n        :param pattern:  Regexp pattern for an item (=converter.pattern).\n        :param listsep:  Optional list separator between items (default: ',')\n        :return: Type converter for list<T>\n        \"\"\"\n        cardinality = Cardinality.one_or_more\n        if not pattern:\n            pattern = getattr(converter, \"pattern\", cls.default_pattern)\n        many_pattern = cardinality.make_pattern(pattern, listsep)\n        group_count = cardinality.compute_group_count(pattern)\n\n        def convert_list(text, m=None):\n            return [converter(part.strip()) for part in text.split(listsep)]\n        convert_list.pattern = many_pattern\n        # OLD: convert_list.group_count = group_count\n        convert_list.regex_group_count = group_count\n        return convert_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef with_many(cls, converter, pattern=None, listsep=','):\n        return cls.with_one_or_more(converter, pattern, listsep)", "response": "Alias for with_one_or_more method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef with_many0(cls, converter, pattern=None, listsep=','):\n        return cls.with_zero_or_more(converter, pattern, listsep)", "response": "Alias for with_zero_or_more method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompare objects with __slots__ defined", "response": "def eq_obj_slots(l, r):\n    \"\"\"\n    Compares objects with __slots__ defined\n    :param l:\n    :param r:\n    :return:\n    \"\"\"\n    for f in l.__slots__:\n        if getattr(l, f, None) != getattr(r, f, None):\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompare object contents, supports slots :param l: :param r: :return:", "response": "def eq_obj_contents(l, r):\n    \"\"\"\n    Compares object contents, supports slots\n    :param l:\n    :param r:\n    :return:\n    \"\"\"\n    if l.__class__ is not r.__class__:\n        return False\n    if hasattr(l, \"__slots__\"):\n        return eq_obj_slots(l, r)\n    else:\n        return l.__dict__ == r.__dict__"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a dictionary for o with __slots__ defined", "response": "def slot_obj_dict(o):\n    \"\"\"\n    Builds dict for o with __slots__ defined\n    :param o:\n    :return:\n    \"\"\"\n    d = {}\n    for f in o.__slots__:\n        d[f] = getattr(o, f, None)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_type(x, types, full=False):\n    types = types if isinstance(types, tuple) else (types,)\n    ins = isinstance(x, types)\n    sub = False\n    try:\n        sub = issubclass(x, types)\n    except Exception:\n        pass\n    res = ins or sub\n    return res if not full else (res, ins)", "response": "Returns True if x is of type in types tuple\n    Returns False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stats_keyboard(events, table):\r\n    if len(events) < 2: return [], []\r\n    deltas, prev_dt = [], None\r\n    sessions, session = [], None\r\n    UNBROKEN_DELTA = datetime.timedelta(seconds=conf.KeyboardSessionMaxDelta)\r\n    blank = collections.defaultdict(lambda: collections.defaultdict(int))\r\n    collated = [blank.copy()] # [{dt, keys: {key: count}}]\r\n    for e in events:\r\n        if prev_dt:\r\n            if (prev_dt.second != e[\"dt\"].second\r\n            or prev_dt.minute != e[\"dt\"].minute or prev_dt.hour != e[\"dt\"].hour):\r\n                collated.append(blank.copy())\r\n            delta = e[\"dt\"] - prev_dt\r\n            deltas.append(delta)\r\n            if delta > UNBROKEN_DELTA:\r\n                session = None\r\n            else:\r\n                if not session:\r\n                    session = []\r\n                    sessions.append(session)\r\n                session.append(delta)\r\n        collated[-1][\"dt\"] = e[\"dt\"]\r\n        collated[-1][\"keys\"][e[\"realkey\"]] += 1\r\n        prev_dt = e[\"dt\"]\r\n    longest_session = max(sessions + [[datetime.timedelta()]], key=lambda x: sum(x, datetime.timedelta()))\r\n    stats = [\r\n        (\"Average interval between combos\",\r\n         sum(deltas, datetime.timedelta()) / len(deltas)),\r\n    ] if \"combos\" == table else [\r\n        (\"Keys per hour\",\r\n         int(3600 * len(events) / timedelta_seconds(events[-1][\"dt\"] - events[0][\"dt\"]))),\r\n        (\"Average interval between keys\",\r\n         sum(deltas, datetime.timedelta()) / len(deltas)),\r\n        (\"Typing sessions (key interval < %ss)\" % UNBROKEN_DELTA.seconds,\r\n         len(sessions)),\r\n        (\"Average keys in session\",\r\n         sum(len(x) + 1 for x in sessions) / len(sessions)),\r\n        (\"Average session duration\", sum((sum(x, datetime.timedelta())\r\n         for x in sessions), datetime.timedelta()) / len(sessions)),\r\n        (\"Longest session duration\",\r\n         sum(longest_session, datetime.timedelta())),\r\n        (\"Keys in longest session\",\r\n         len(longest_session) + 1),\r\n        (\"Most keys in session\",\r\n         max(len(x) + 1 for x in sessions)),\r\n    ]\r\n    return stats, collated", "response": "Return statistics and collated events for keyboard events."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stats_mouse(events, table):\r\n    if not events: return [], [], []\r\n    distance, last, deltas = 0, None, []\r\n    HS = conf.MouseHeatmapSize\r\n    SC = dict((\"xy\"[i], conf.DefaultScreenSize[i] / float(HS[i])) for i in [0, 1])\r\n    xymap = collections.defaultdict(int)\r\n    sizes = db.fetch(\"screen_sizes\", order=(\"dt\",))\r\n    sizeidx, sizelen = -1, len(sizes) # Scale by desktop size at event time\r\n    for e in events:\r\n        if last:\r\n            deltas.append(e[\"dt\"] - last[\"dt\"])\r\n            distance += math.sqrt(sum(abs(e[k] - last[k])**2 for k in \"xy\"))\r\n        last = dict(e) # Copy, as we modify coordinates\r\n        if sizeidx < 0: # Find latest size from before event\r\n            for i, size in reversed(list(enumerate(sizes))):\r\n                if e[\"dt\"] >= size[\"dt\"]:\r\n                    SC = dict((k, size[k] / float(HS[\"y\" == k])) for k in \"xy\")\r\n                    sizeidx = i\r\n                    break # for i, size\r\n        else: # Find next size from before event\r\n            while sizeidx < sizelen - 2 and e[\"dt\"] >= sizes[sizeidx + 1][\"dt\"]:\r\n                sizeidx += 1\r\n            if sizeidx < sizelen - 1 and e[\"dt\"] >= sizes[sizeidx][\"dt\"]:\r\n                SC = dict((k, sizes[sizeidx][k] / float(HS[\"y\" == k])) for k in \"xy\")\r\n        e[\"x\"], e[\"y\"] = tuple(min(int(e[k] / SC[k]), HS[\"y\" == k]) for k in \"xy\")\r\n        xymap[(e[\"x\"], e[\"y\"])] += 1\r\n\r\n    stats, positions = [], [dict(x=x, y=y, count=v) for (x, y), v in xymap.items()]\r\n    if \"moves\" == table:\r\n        px = re.sub(r\"(\\d)(?=(\\d{3})+(?!\\d))\", r\"\\1,\", \"%d\" % math.ceil(distance))\r\n        seconds = timedelta_seconds(events[-1][\"dt\"] - events[0][\"dt\"])\r\n        stats = [(\"Total distance\", \"%s pixels \" % px),\r\n                 (\"\", \"%.1f meters (if pixel is %smm)\" %\r\n                  (distance * conf.PixelLength, conf.PixelLength * 1000)),\r\n                 (\"Average speed\", \"%.1f pixels per second\" % (distance / (seconds or 1))),\r\n                 (\"\", \"%.4f meters per second\" %\r\n                  (distance * conf.PixelLength / (seconds or 1))), ]\r\n    elif \"scrolls\" == table:\r\n        counts = collections.Counter(e[\"wheel\"] for e in events)\r\n        stats = [(\"Scrolls per hour\", \r\n                  int(len(events) / (timedelta_seconds(events[-1][\"dt\"] - events[0][\"dt\"]) / 3600 or 1))),\r\n                 (\"Average interval\", sum(deltas, datetime.timedelta()) / (len(deltas) or 1)),\r\n                 (\"Scrolls down\", counts[-1]),\r\n                 (\"Scrolls up\", counts[1]), ]\r\n    elif \"clicks\" == table:\r\n        counts = collections.Counter(e[\"button\"] for e in events)\r\n        NAMES = {1: \"Left\", 2: \"Right\", 3: \"Middle\"}\r\n        stats = [(\"Clicks per hour\", \r\n                  int(len(events) / (timedelta_seconds(events[-1][\"dt\"] - events[0][\"dt\"]) / 3600 or 1))),\r\n                 (\"Average interval between clicks\",\r\n                  sum(deltas, datetime.timedelta()) / (len(deltas) or 1)),\r\n                 (\"Average distance between clicks\",\r\n                  \"%.1f pixels\" % (distance / (len(events) or 1))), ]\r\n        for k, v in sorted(counts.items()):\r\n            stats += [(\"%s button clicks\" % NAMES.get(k, \"%s.\" % k), v)]\r\n    return stats, positions, events", "response": "Returns statistics positions and rescaled events for mouse events."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the total timedelta duration in seconds.", "response": "def timedelta_seconds(timedelta):\r\n    \"\"\"Returns the total timedelta duration in seconds.\"\"\"\r\n    return (timedelta.total_seconds() if hasattr(timedelta, \"total_seconds\")\r\n            else timedelta.days * 24 * 3600 + timedelta.seconds +\r\n                 timedelta.microseconds / 1000000.)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init():\r\n    global app\r\n    if app: return app\r\n    conf.init(), db.init(conf.DbPath, conf.DbStatements)\r\n\r\n    bottle.TEMPLATE_PATH.insert(0, conf.TemplatePath)\r\n    app = bottle.default_app()\r\n    bottle.BaseTemplate.defaults.update(get_url=app.get_url)\r\n    return app", "response": "Initialize configuration and web application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the web server.", "response": "def start():\r\n    \"\"\"Starts the web server.\"\"\"\r\n    global app\r\n    bottle.run(app, host=conf.WebHost, port=conf.WebPort,\r\n               debug=conf.WebAutoReload, reloader=conf.WebAutoReload,\r\n               quiet=conf.WebQuiet)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the download of an URL using the current proxy currently set in socks.", "response": "def _download_helper(url):\n    \"\"\"\n    Handle the download of an URL, using the proxy currently set in \\\n            :mod:`socks`.\n\n    :param url: The URL to download.\n    :returns: A tuple of the raw content of the downloaded data and its \\\n            associated content-type. Returns None if it was \\\n            unable to download the document.\n    \"\"\"\n    # Try to fetch the URL using the current proxy\n    try:\n        request = urllib.request.urlopen(url)\n        try:\n            size = int(dict(request.info())['content-length'].strip())\n        except KeyError:\n            try:\n                size = int(dict(request.info())['Content-Length'].strip())\n            except KeyError:\n                size = 0\n        # Download the document\n        doc = b\"\"\n        doc_size = 0\n        while True:\n            buf = request.read(1024)\n            if buf:\n                doc += buf\n                doc_size += len(buf)\n                if size != 0:\n                    # Write progress bar on stdout\n                    done = int(50 * doc_size / size)\n                    sys.stdout.write(\"\\r[%s%s]\" %\n                                     ('='*done, ' '*(50-done)))\n                    sys.stdout.write(\" \"+str(int(float(done)/52*100))+\"%\")\n                    sys.stdout.flush()\n            else:\n                break\n        # Fetch content type\n        contenttype = None\n        contenttype_req = None\n        try:\n            contenttype_req = dict(request.info())['content-type']\n        except KeyError:\n            try:\n                contenttype_req = dict(request.info())['Content-Type']\n            except KeyError:\n                return None\n        if 'pdf' in contenttype_req:\n            contenttype = 'pdf'\n        elif 'djvu' in contenttype_req:\n            contenttype = 'djvu'\n\n        # Check content type and status code are ok\n        if request.getcode() != 200 or contenttype is None:\n            # Else, try with the next available proxy\n            return None\n\n        # Return a tuple of the downloaded content and the content-type\n        return (doc, contenttype)\n    # If an exception occurred, continue with next available proxy\n    except (urllib.error.URLError, socket.error, ValueError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a PDF or DJVU document from a URL.", "response": "def download(url, proxies=None):\n    \"\"\"\n    Download a PDF or DJVU document from a url, eventually using proxies.\n\n    :params url: The URL to the PDF/DJVU document to fetch.\n    :params proxies: An optional list of proxies to use. Proxies will be \\\n            used sequentially. Proxies should be a list of proxy strings. \\\n            Do not forget to include ``\"\"`` (empty string) in the list if \\\n            you want to try direct fetching without any proxy.\n\n    :returns: A tuple of the raw content of the downloaded data and its \\\n            associated content-type. Returns ``(None, None)`` if it was \\\n            unable to download the document.\n\n    >>> download(\"http://arxiv.org/pdf/1312.4006.pdf\") # doctest: +SKIP\n    \"\"\"\n    # Handle default argument\n    if proxies is None:\n        proxies = [\"\"]\n\n    # Loop over all available connections\n    for proxy in proxies:\n        # Handle no proxy case\n        if proxy == \"\":\n            socket.socket = DEFAULT_SOCKET\n        # Handle SOCKS proxy\n        elif proxy.startswith('socks'):\n            if proxy[5] == '4':\n                proxy_type = socks.SOCKS4\n            else:\n                proxy_type = socks.SOCKS5\n            proxy = proxy[proxy.find('://') + 3:]\n            try:\n                proxy, port = proxy.split(':')\n            except ValueError:\n                port = None\n            socks.set_default_proxy(proxy_type, proxy, port)\n            socket.socket = socks.socksocket\n        # Handle generic HTTP proxy\n        else:\n            try:\n                proxy, port = proxy.split(':')\n            except ValueError:\n                port = None\n            socks.set_default_proxy(socks.HTTP, proxy, port)\n            socket.socket = socks.socksocket\n\n        downloaded = _download_helper(url)\n        if downloaded is not None:\n            return downloaded\n\n    # In case of running out of proxies, return (None, None)\n    return (None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_format(format_spec):\n        fill = ''\n        align = ''\n        zero = ''\n        width = format_spec.width\n        if format_spec.align:\n            align = format_spec.align[0]\n            if format_spec.fill:\n                fill = format_spec.fill[0]\n        if format_spec.zero:\n            zero = '0'\n\n        precision_part = \"\"\n        if format_spec.precision:\n            precision_part = \".%s\" % format_spec.precision\n\n        # -- FORMAT-SPEC: [[fill]align][0][width][.precision][type]\n        return \"%s%s%s%s%s%s\" % (fill, align, zero, width,\n                                 precision_part, format_spec.type)", "response": "Builds a format string from a format specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_format_spec(cls, format):\n        # -- BASED-ON: parse.extract_format()\n        # pylint: disable=redefined-builtin, unsubscriptable-object\n        if not format:\n            raise ValueError(\"INVALID-FORMAT: %s (empty-string)\" % format)\n\n        orig_format = format\n        fill = align = None\n        if format[0] in cls.ALIGN_CHARS:\n            align = format[0]\n            format = format[1:]\n        elif len(format) > 1 and format[1] in cls.ALIGN_CHARS:\n            fill = format[0]\n            align = format[1]\n            format = format[2:]\n\n        zero = False\n        if format and format[0] == '0':\n            zero = True\n            format = format[1:]\n\n        width = ''\n        while format:\n            if not format[0].isdigit():\n                break\n            width += format[0]\n            format = format[1:]\n\n        precision = None\n        if format.startswith('.'):\n            # Precision isn't needed but we need to capture it so that\n            # the ValueError isn't raised.\n            format = format[1:]  # drop the '.'\n            precision = ''\n            while format:\n                if not format[0].isdigit():\n                    break\n                precision += format[0]\n                format = format[1:]\n\n        # the rest is the type, if present\n        type = format\n        if not type:\n            raise ValueError(\"INVALID-FORMAT: %s (without type)\" % orig_format)\n        return FormatSpec(type, width, zero, align, fill, precision)", "response": "Extract the format spec from a format string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract fields in a parse expression schema.", "response": "def extract_fields(cls, schema):\n        \"\"\"Extract fields in a parse expression schema.\n\n        :param schema: Parse expression schema/format to use (as string).\n        :return: Generator for fields in schema (as Field objects).\n        \"\"\"\n        # -- BASED-ON: parse.Parser._generate_expression()\n        for part in parse.PARSE_RE.split(schema):\n            if not part or part == '{{' or part == '}}':\n                continue\n            elif part[0] == '{':\n                # this will be a braces-delimited field to handle\n                yield cls.parse(part)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts types ( names ) for typed fields with format part.", "response": "def extract_types(cls, schema):\n        \"\"\"Extract types (names) for typed fields (with format/type part).\n\n        :param schema: Parser schema/format to use.\n        :return: Generator for type names (as string).\n        \"\"\"\n        for field in cls.extract_fields(schema):\n            if field.has_format:\n                yield field.format_spec.type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a handler. :param handler: A handler object.", "response": "def _registerHandler(self, handler):\n        \"\"\"\n        Registers a handler.\n\n        :param handler:  A handler object.\n        \"\"\"\n        self._logger.addHandler(handler)\n        self._handlers.append(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unregisterHandler(self, handler, shutdown=True):\n        if handler in self._handlers:\n            self._handlers.remove(handler)\n            self._logger.removeHandler(handler)\n            if shutdown:\n                try:\n                    handler.close()\n                except KeyError:\n                    # Depending on the Python version, it's possible for this call\n                    # to fail most likely because some logging module objects get\n                    # garbage collected before the VSGLogger object is.\n                    pass", "response": "Unregisters the given handler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getLogger(cls, name=None):\n        return logging.getLogger(\"{0}.{1}\".format(cls.BASENAME, name) if name else cls.BASENAME)", "response": "Returns the Python native logger object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef debug(cls, name, message, *args):\n        cls.getLogger(name).debug(message, *args)", "response": "Convenience function to log a message at the DEBUG level."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef warning(cls, name, message, *args):\n        cls.getLogger(name).warning(message, *args)", "response": "Convenience function to log a message at the WARNING level."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exception(cls, name, message, *args):\n        cls.getLogger(name).exception(message, *args)", "response": "Convenience method to log a message at the ERROR level with additonal exception information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef allow(self, ctx, ops):\n        ''' Checks that the authorizer's request is authorized to\n        perform all the given operations. Note that allow does not check\n        first party caveats - if there is more than one macaroon that may\n        authorize the request, it will choose the first one that does\n        regardless.\n\n        If all the operations are allowed, an AuthInfo is returned holding\n        details of the decision and any first party caveats that must be\n        checked before actually executing any operation.\n\n        If operations include LOGIN_OP, the request should contain an\n        authentication macaroon proving the client's identity. Once an\n        authentication macaroon is chosen, it will be used for all other\n        authorization requests.\n\n        If an operation was not allowed, an exception will be raised which may\n        be:\n\n        - DischargeRequiredError holding the operations that remain to\n        be authorized in order to allow authorization to proceed\n        - PermissionDenied when no operations can be authorized and there's\n        no third party to discharge macaroons for.\n\n        @param ctx AuthContext\n        @param ops an array of Op\n        :return: an AuthInfo object.\n        '''\n        auth_info, _ = self.allow_any(ctx, ops)\n        return auth_info", "response": "Checks that the authorizer s request is authorized to perform all the given operations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike allow except that it will authorize all of the operations as many of the necessary operations as possible without requiring any to be authorized.", "response": "def allow_any(self, ctx, ops):\n        ''' like allow except that it will authorize as many of the\n        operations as possible without requiring any to be authorized. If all\n        the operations succeeded, the array will be nil.\n\n        If any the operations failed, the returned error will be the same\n        that allow would return and each element in the returned slice will\n        hold whether its respective operation was allowed.\n\n        If all the operations succeeded, the returned slice will be None.\n\n        The returned AuthInfo will always be non-None.\n\n        The LOGIN_OP operation is treated specially - it is always required if\n        present in ops.\n        @param ctx AuthContext\n        @param ops an array of Op\n        :return: an AuthInfo object and the auth used as an array of int.\n        '''\n        authed, used = self._allow_any(ctx, ops)\n        return self._new_auth_info(used), authed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef allow_capability(self, ctx, ops):\n        '''Checks that the user is allowed to perform all the\n        given operations. If not, a discharge error will be raised.\n        If allow_capability succeeds, it returns a list of first party caveat\n        conditions that must be applied to any macaroon granting capability\n        to execute the operations. Those caveat conditions will not\n        include any declarations contained in login macaroons - the\n        caller must be careful not to mint a macaroon associated\n        with the LOGIN_OP operation unless they add the expected\n        declaration caveat too - in general, clients should not create\n        capabilities that grant LOGIN_OP rights.\n\n        The operations must include at least one non-LOGIN_OP operation.\n        '''\n        nops = 0\n        for op in ops:\n            if op != LOGIN_OP:\n                nops += 1\n        if nops == 0:\n            raise ValueError('no non-login operations required in capability')\n\n        _, used = self._allow_any(ctx, ops)\n        squasher = _CaveatSquasher()\n        for i, is_used in enumerate(used):\n            if not is_used:\n                continue\n            for cond in self._conditions[i]:\n                squasher.add(cond)\n        return squasher.final()", "response": "Checks that the user is allowed to perform all the given operations. Returns a list of first party caveat entries that must be used to perform all the operations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeactivate all recipes of the current plugin and unregisters all recipes of the current plugin.", "response": "def __deactivate_recipes(self, plugin, *args, **kwargs):\n        \"\"\"\n        Deactivates/unregisters all recipes of the current plugin, if this plugin gets deactivated.\n        \"\"\"\n        recipes = self.get()\n        for recipe in recipes.keys():\n            self.unregister(recipe)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a new recipe in the context of the current plugin.", "response": "def register(self, name, path, description, final_words=None):\n        \"\"\"\n        Registers a new recipe in the context of the current plugin.\n\n        :param name: Name of the recipe\n        :param path: Absolute path of the recipe folder\n        :param description: A meaningful description of the recipe\n        :param final_words: A string, which gets printed after the recipe was build.\n        \"\"\"\n        return self.__app.recipes.register(name, path, self._plugin, description, final_words)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of all recipes which are registered by the current plugin. If no name is provided all recipes are returned.", "response": "def get(self, name=None):\n        \"\"\"\n        Gets a list of all recipes, which are registered by the current plugin.\n        If a name is provided, only the requested recipe is returned or None.\n\n        :param: name: Name of the recipe\n        \"\"\"\n        return self.__app.recipes.get(name, self._plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a recipe :param recipe: Name of the recipe to build.", "response": "def build(self, recipe):\n        \"\"\"\n        Builds a recipe\n\n        :param recipe: Name of the recipe to build.\n        \"\"\"\n        return self.__app.recipes.build(recipe, self._plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, name, path, plugin, description=None, final_words=None):\n        if name in self.recipes.keys():\n            raise RecipeExistsException(\"Recipe %s was already registered by %s\" %\n                                        (name, self.recipes[\"name\"].plugin.name))\n\n        self.recipes[name] = Recipe(name, path, plugin, description, final_words)\n        self.__log.debug(\"Recipe %s registered by %s\" % (name, plugin.name))\n        return self.recipes[name]", "response": "Registers a new recipe."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget one or more recipes.", "response": "def get(self, recipe=None, plugin=None):\n        \"\"\"\n        Get one or more recipes.\n\n        :param recipe: Name of the recipe\n        :type recipe: str\n        :param plugin: Plugin object, under which the recipe was registered\n        :type plugin: GwBasePattern\n        \"\"\"\n        if plugin is not None:\n            if recipe is None:\n                recipes_list = {}\n                for key in self.recipes.keys():\n                    if self.recipes[key].plugin == plugin:\n                        recipes_list[key] = self.recipes[key]\n                return recipes_list\n            else:\n                if recipe in self.recipes.keys():\n                    if self.recipes[recipe].plugin == plugin:\n                        return self.recipes[recipe]\n                    else:\n                        return None\n                else:\n                    return None\n        else:\n            if recipe is None:\n                return self.recipes\n            else:\n                if recipe in self.recipes.keys():\n                    return self.recipes[recipe]\n                else:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build(self, recipe, plugin=None):\n        if recipe not in self.recipes.keys():\n            raise RecipeMissingException(\"Recipe %s unknown.\" % recipe)\n\n        recipe_obj = self.recipes[recipe]\n\n        if plugin is not None:\n            if recipe_obj.plugin != plugin:\n                raise RecipeWrongPluginException(\"The requested recipe does not belong to the given plugin. Use\"\n                                                 \"the app object, to retrieve the requested recipe: \"\n                                                 \"my_app.recipes.get(%s)\" % recipe)\n\n        recipe_obj.build()", "response": "Execute a recipe and creates new folder and files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build(self, output_dir=None, **kwargs):\n        if output_dir is None:\n            output_dir = os.getcwd()\n\n        target = cookiecutter(self.path, output_dir=output_dir, **kwargs)\n\n        if self.final_words is not None and len(self.final_words) > 0:\n            print(\"\")\n            print(self.final_words)\n        return target", "response": "Builds the recipe and creates needed folders and files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cermine(pdf_file, force_api=False, override_local=None):\n    try:\n        # Check if we want to load the local JAR from a specific path\n        local = override_local\n        # Else, try to stat the JAR file at the expected local path\n        if (local is None) and (not force_api):\n            if os.path.isfile(os.path.join(SCRIPT_DIR,\n                                           \"../external/cermine.jar\")):\n                local = os.path.join(SCRIPT_DIR,\n                                     \"../external/cermine.jar\")\n\n        # If we want to force the API use, or we could not get a local JAR\n        if force_api or (local is None):\n            print(\"Using API\")\n            with open(pdf_file, \"rb\") as fh:\n                # Query the API\n                request = requests.post(\n                    CERMINE_BASE_URL + \"extract.do\",\n                    headers={\"Content-Type\": \"application/binary\"},\n                    files={\"file\": fh}\n                )\n                return request.text\n        # Else, use the local JAR file\n        else:\n            return subprocess.check_output([\n                \"java\",\n                \"-cp\", local,\n                \"pl.edu.icm.cermine.PdfNLMContentExtractor\",\n                \"-path\", pdf_file]).decode(\"utf-8\")\n    except (RequestException,\n            subprocess.CalledProcessError,\n            FileNotFoundError):\n        # In case of any error, return None\n        return None", "response": "This function returns the raw output of the CERMINE API for the given PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cermine_dois(pdf_file, force_api=False, override_local=None):\n    # TODO:\n    #    * Do not convert to plain text, but use the extra metadata from\n    #      CERMINE\n    # Call CERMINE on the PDF file\n    cermine_output = cermine(pdf_file, force_api, override_local)\n    # Parse the resulting XML\n    root = ET.fromstring(cermine_output)\n    plaintext_references = [\n        # Remove extra whitespaces\n        tools.clean_whitespaces(\n            # Convert XML element to string, discarding any leading \"[n]\"\n            ET.tostring(e, method=\"text\").decode(\"utf-8\").replace(e.text, \"\"))\n        for e in root.iter(\"mixed-citation\")]\n    # Call the plaintext methods to fetch DOIs\n    return plaintext.get_cited_dois(plaintext_references)", "response": "This function will cermine the DOIs of a PDF file and return a dictionary of cleaned plaintext citations and their associated DOIs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning Grobid on a given folder and extract the related files.", "response": "def grobid(pdf_folder, grobid_home=None, grobid_jar=None):\n    \"\"\"\n    Run `Grobid <https://github.com/kermitt2/grobid>`_ on a given folder to \\\n            extract references.\n\n    .. note::\n\n        Before using this function, you have to download and build Grobid on \\\n                your system. See \\\n                `<https://grobid.readthedocs.org/en/latest/Install-Grobid/>`_ \\\n                for more infos on this. You need Java to be in your ``$PATH``.\n\n    :param pdf_folder: Folder containing the PDF files to handle.\n    :param grobid_home: Path to the grobid-home directory.\n    :param grobid_jar: Path to the built Grobid JAR file.\n    :returns: ``True``, or ``False`` if an error occurred.\n    \"\"\"\n    # TODO: Should be using https://github.com/kermitt2/grobid-example and\n    # BibTeX backend.\n    if grobid_home is None or grobid_jar is None:\n        # User should pass the correct paths\n        return False\n\n    try:\n        subprocess.call([\"java\",\n                         \"-jar\", grobid_jar,\n                         # Avoid OutOfMemoryException\n                         \"-Xmx1024m\",\n                         \"-gH\", grobid_home,\n                         \"-gP\", os.path.join(grobid_home,\n                                             \"config/grobid.properties\"),\n                         \"-dIn\", pdf_folder,\n                         \"-exe\", \"processReferences\"])\n        return True\n    except subprocess.CalledProcessError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting DOIs of references using \\ pdfextract.", "response": "def pdfextract_dois(pdf_file):\n    \"\"\"\n    Extract DOIs of references using \\\n            `pdfextract <https://github.com/CrossRef/pdfextract>`_.\n\n    .. note::\n\n        See ``libbmc.citations.pdf.pdfextract`` function as this one is just \\\n                a wrapper around it.\n        See ``libbmc.citations.plaintext.get_cited_dois`` as well for the \\\n                returned value, as it is ultimately called by this function.\n\n    :param pdf_file: Path to the PDF file to handle.\n    :returns: A dict of cleaned plaintext citations and their associated DOI.\n    \"\"\"\n    # Call pdf-extract on the PDF file\n    references = pdfextract(pdf_file)\n    # Parse the resulting XML\n    root = ET.fromstring(references)\n    plaintext_references = [e.text for e in root.iter(\"reference\")]\n    # Call the plaintext methods to fetch DOIs\n    return plaintext.get_cited_dois(plaintext_references)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_all(self, silent='NO'):\n        all_params = []\n        all_params.append(dict(name='phone', val=self.transport))\n        all_params.append(dict(name='username', val=self.username))\n        all_params.append(dict(name='user', val=self.user))\n        all_params.append(dict(name='hostname', val=self.hostname))\n        all_params.append(dict(name='host', val=self.host))\n        all_params.append(dict(name='cpu_pct', val=self.host_cpu_pct))\n        all_params.append(dict(name='num_proc', val=self.host_num_processes))\n        all_params.append(dict(name='mem_avail', val=self.host_mem_available))\n        all_params.append(dict(name='mem_total', val=self.host_mem_total))\n        if silent != 'NO':\n            for a in all_params:\n                print(a['name'].ljust(14) + '= ' + a['val'])\n    \n        return all_params", "response": "Prints all attributes and returns them as a dictionary \n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summarise(self):\n        res = ''\n        if self.user == 'Developer': \n            if self.host == 'Home PC':\n                res += 'At Home'\n            else:\n                res += 'Away from PC'\n        elif self.user == 'User' and self.host == 'Home PC':\n            res += 'Remote desktop into home PC'\n        res += '\\n'\n        res += self.transport\n        return res", "response": "returns a human readable summary of the contexts \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_host(self):\n        import socket\n        host_name = socket.gethostname()\n        for h in hosts:\n            if h['name'] == host_name:\n                return h['type'], h['name']\n        return dict(type='Unknown', name=host_name)", "response": "returns the host computer running this program \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions STUB - TODO The intention is to get data from the mobile in the format: gps_lat = 137.000 gps_lng = 100.000 moving = True | False move_dist_10_sc = 0 move_dist_2_mn = 4 move_dist_10_mn = 4 move_dist_2_hr = 4 screen_saver = True | False on_charge = True | False", "response": "def inspect_phone(self, gps_lat_long = [137.0000,100.0000], moving = False, move_dist_2_mn = 4, on_charge = True, screen_saver = False):\n        \"\"\"\n        FUNCTION STUB - TODO\n        The intention is to get data from the mobile in the format:\n            gps_lat         = 137.000\n            gps_lng         = 100.000\n            moving          = True | False\n            move_dist_10_sc = 0\n            move_dist_2_mn  = 4\n            move_dist_10_mn = 4\n            move_dist_2_hr  = 4\n            screen_saver    = True | False\n            on_charge       = True | False\n        \"\"\"\n        \n        \n        self.phone_gps_lat = gps_lat_long[0]\n        self.phone_gps_lng = gps_lat_long[1]\n        self.phone_moving = moving\n        self.phone_move_dist_2_mn = move_dist_2_mn\n        self.phone_on_charge = on_charge\n        self.screen_saver = screen_saver\n        #-------------------------------\n        phone_status = ''\n        if self.phone_on_charge is True:\n            phone_status += 'Phone is charging'\n            if self.phone_moving is True:\n                phone_status += ', driving in Car'\n            else:\n                phone_status += ', sitting still'\n        else:\n            if self.screen_saver is False:\n                phone_status += 'Phone is being used'\n            else:\n                phone_status += 'Phone is off'\n            if self.phone_moving is True:\n                if self.phone_move_dist_2_mn < 5:\n                    phone_status += ', going for Walk'\n                elif  self.phone_move_dist_2_mn > 500:\n                    phone_status += ', flying on Plane'\n                else:    \n                    phone_status += ', riding on public transport'\n        return phone_status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_host_usage(self):\n        import psutil\n        process_names = [proc.name for proc in psutil.process_iter()]\n        cpu_pct = psutil.cpu_percent(interval=1)\n        mem = psutil.virtual_memory()\n        return str(cpu_pct), str(len(process_names)), str(mem.available), str(mem.total)", "response": "get details of CPU RAM usage of this PC \n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprovide schema for shell configuration.", "response": "def schema():\n        \"\"\"Provide schema for shell configuration.\"\"\"\n        return Schema({\n            'script': And(Or(type(' '), type(u' ')), len),\n            Optional('title', default=''): str,\n            Optional('model', default={}): {Optional(And(str, len)): object},\n            Optional('env', default={}): {Optional(And(str, len)): And(str, len)},\n            Optional('item', default=None): object,\n            Optional('dry_run', default=False): bool,\n            Optional('debug', default=False): bool,\n            Optional('strict', default=False): bool,\n            Optional('variables', default={}): {\n                Optional(And(Or(type(' '), type(u' ')), len, Regex(r'([a-zA-Z][_a-zA-Z]*)'))):\n                    Or(type(' '), type(u' '))\n            },\n            Optional('temporary_scripts_path', default=''): Or(type(''), type(u'')),\n            Optional('internal', default=False): bool\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transform_to_attrs(self, response):\n        response_dict = self._desiarialize_response(response)\n        self.__dict__.update(response_dict)", "response": "Sets the key - value pairs in the given dict as\n        attributes of this result object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmodify the given dict into a flat dict consisting of only key - value pairs.", "response": "def _flatten_dict(self, dict_):\n        \"\"\"Modifies the given dict into a flat dict consisting of only\n        key/value pairs.\n        \"\"\"\n        flattened_dict = {}\n        for (key, value) in dict_.iteritems():\n            if isinstance(value, dict):\n                flattened_dict.update(self._flatten_dict(value))\n            else:\n                flattened_dict[key] = value\n        return flattened_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an object Project which matches name", "response": "def get_by_name(self, name):\n        \"\"\" returns an object Project which matches name \"\"\"\n        for p in self.project_list:\n            if p.nme == name:\n                return p\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a source to the list of data sources used in projects.", "response": "def add_source(self, name, location, schedule='Daily', op=''):\n        \"\"\"\n        handles the data sources used in projects, mainly as an \n        abstract to call the data sources in /lib and /dataTools\n        \"\"\"\n        if op == '':\n            op = name + '.log'\n        self.data_sources.append([name, location, schedule, op])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_tasks(self):\n        for t in self.tasks:\n            print('RUNNING ' + str(t.task_id) + ' = ' + t.name)\n            t.execute()\n            if t.success != '__IGNORE__RESULT__':\n                print(t)\n                print('TASK RESULT :', t.result, ' but success = ' , t.success )\n                if t.result != t.success:\n                    #raise Exception('Project execution failed at task ' + str(t.task_id) + ' = ' + t.name)\n                    print('ABORTING TASK EXECUTION SEQUENCE'  + str(t.task_id) + ' = ' + t.name)\n                    break", "response": "execute on all tasks IFF prior task is successful"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a report showing all project details", "response": "def build_report(self, op_file, tpe='md'):\n        \"\"\"\n        create a report showing all project details\n        \"\"\"\n        if tpe == 'md':\n            res = self.get_report_md()\n        elif tpe == 'rst':\n            res = self.get_report_rst()\n        elif tpe == 'html':\n            res = self.get_report_html()\n        else:\n            res = 'Unknown report type passed to project.build_report'\n        \n        with open(op_file, 'w') as f:\n            f.write(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a RST report", "response": "def get_report_rst(self):\n        \"\"\"\n        formats the project into a report in RST format\n        \"\"\"\n        res = ''\n        res += '-----------------------------------\\n' \n        res += self.nme  + '\\n'\n        res += '-----------------------------------\\n\\n'\n        res += self.desc + '\\n'\n        res += self.fldr + '\\n\\n'\n        res += '.. contents:: \\n\\n\\n'\n\n        res += 'Overview\\n' + '===========================================\\n\\n'\n        res += 'This document contains details on the project ' + self.nme + '\\n\\n'\n        \n        for d in self.details:\n            res += ' - ' + d[0] + ' = ' + d[1] + '\\n\\n'\n            \n        \n        res += '\\nTABLES\\n' + '===========================================\\n\\n'\n        \n        for t in self.datatables:\n            res +=  t.name + '\\n'\n            res += '-------------------------\\n\\n'\n            res += t.format_rst() + '\\n\\n'\n        \n        \n        \n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_report_html(self):\n        res = '<h2>Project:' + self.nme  + '</h2>'\n        res += '<p>' + self.desc + '</p>'\n        res += '<p>' + self.fldr + '</p>'\n        \n        res += '<BR><h3>TABLES</h3>'\n        \n        for t in self.datatables:\n            res += '<b>' + t.name + '<b><BR>'\n            res += '<p>' + str(t) + '</p>'\n        return res", "response": "returns the html report for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_param(self, param_key, param_val):\n        self.params.append([param_key, param_val])\n        if param_key == '__success_test':\n            self.success = param_val", "response": "Adds a parameter to the list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self):\n        func_params = []\n        exec_str = self.func.__name__ + '(' \n        for p in self.params:\n            if p[0][0:2] != '__':   # ignore custom param names\n                exec_str += p[0] + '=\"' + self._force_str(p[1]) + '\", '\n                func_params.append(p[1])\n        exec_str = exec_str[:-2]\n        exec_str += ')  # task' + str(self.task_id) + ': ' + self.name\n        \n        \n        self.result = self.func(*func_params)\n        print(exec_str + ' loaded ', self.result)", "response": "Executes all automatic tasks in order of task id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads all annotations from the specified file.", "response": "def read_annotations(path_or_file, separator='\\t', reset=True):\n    \"\"\"\n    Read all annotations from the specified file.\n    \n    >>> annotations = read_annotations(path_or_file, separator)\n    >>> colnames = annotations['Column Name']\n    >>> types = annotations['Type']\n    >>> annot_row = annotations['Annot. row name']\n\n    :param path_or_file: Path or file-like object\n    :param separator: Column separator\n    :param reset: Reset the file after reading. Useful for file-like, no-op for paths.\n    :returns: Ordered dictionary of annotations.\n    \"\"\"\n    annotations = OrderedDict({})\n    with PathOrFile(path_or_file, 'r', reset=reset) as f:\n        annotations['Column Name'] = f.readline().strip().split(separator)\n        for line in f:\n            if line.startswith('#!{'):\n                tokens = line.strip().split(separator)\n                _name, first_value = tokens[0].split('}')\n                name = _name.replace('#!{', '')\n                values = [first_value] + tokens[1:]\n                if name == 'Type':\n                    colnames = annotations['Column Name']\n                    annotations['dtype'] = {colnames[i]: perseus_to_dtype[x] for i, x in enumerate(values) if x in perseus_to_dtype}\n                    annotations['converters'] = {colnames[i]: converters[x] for i, x in enumerate(values) if x in converters}\n                annotations[name] = values\n    return annotations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef annotation_rows(prefix, annotations):\n    ncol = len(annotations['Column Name'])\n    return {name.replace(prefix, '', 1) : values + [''] * (ncol - len(values))\n            for name, values in annotations.items() if name.startswith(prefix)}", "response": "Helper function to extract N and C rows from annotations and pad their values with the specified prefix"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_column_index(annotations):\n    _column_index = OrderedDict({'Column Name' : annotations['Column Name']})\n    categorical_rows = annotation_rows('C:', annotations)\n    _column_index.update(categorical_rows)\n    numerical_rows = {name: [float(x) if x != '' else float('NaN') for x in values]\n            for name, values in annotation_rows('N:', annotations).items()} # to floats\n    _column_index.update(numerical_rows)\n    column_index = pd.MultiIndex.from_tuples(list(zip(*_column_index.values())), names=list(_column_index.keys()))\n    if len(column_index.names) == 1:\n        # flatten single-level index\n        name = column_index.names[0]\n        column_index = column_index.get_level_values(name)\n    return column_index", "response": "Create a pd. MultiIndex using the column names and any categorical rows."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_perseus(path_or_file, **kwargs):\n    annotations = read_annotations(path_or_file, separator)\n    column_index = create_column_index(annotations)\n    if 'usecols' in kwargs:\n\t    usecols = kwargs['usecols']\n\t    if type(usecols[0]) is str:\n\t\t    usecols = sorted([list(column_index).index(x) for x in usecols])\n\t    column_index = column_index[usecols]\n    kwargs['dtype'] = dict(kwargs.get('dtype', {}), **annotations.get('dtype', {}))\n    kwargs['converters'] = dict(kwargs.get('converters', {}), **annotations.get('converters', {}))\n    df = pd.read_csv(path_or_file, sep=separator, comment='#', **kwargs)\n    df.columns = column_index\n    return df", "response": "Read a Perseus - formatted matrix into a pd. DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_perseus(df, path_or_file, main_columns=None,\n        separator=separator,\n        convert_bool_to_category=True,\n        numerical_annotation_rows = set([])):\n    \"\"\"\n    Save pd.DataFrame to Perseus text format.\n\n    :param df: pd.DataFrame.\n    :param path_or_file: File name or file-like object.\n    :param main_columns: Main columns. Will be infered if set to None. All numeric columns up-until the first non-numeric column are considered main columns.\n    :param separator: For separating fields, default='\\t'.\n    :param covert_bool_to_category: Convert bool columns of True/False to category columns '+'/'', default=True.\n    :param numerical_annotation_rows: Set of column names to be interpreted as numerical annotation rows, default=set([]).\n    \"\"\"\n    _df = df.copy()\n    if not _df.columns.name:\n        _df.columns.name = 'Column Name'\n    column_names = _df.columns.get_level_values('Column Name')\n    annotations = {}\n    main_columns = _infer_main_columns(_df) if main_columns is None else main_columns\n    annotations['Type'] = ['E' if column_names[i] in main_columns else dtype_to_perseus(dtype)\n            for i, dtype in enumerate(_df.dtypes)]\n    # detect multi-numeric columns\n    for i, column in enumerate(_df.columns):\n        valid_values = [value for value in _df[column] if value is not None]\n        if len(valid_values) > 0 and all(type(value) is list for value in valid_values):\n            annotations['Type'][i] = 'M'\n            _df[column] = _df[column].apply(lambda xs: ';'.join(str(x) for x in xs))\n    if convert_bool_to_category:\n        for i, column in enumerate(_df.columns):\n            if _df.dtypes[i] is np.dtype('bool'):\n                values = _df[column].values\n                _df[column][values] = '+'\n                _df[column][~values] = ''\n    annotation_row_names = set(_df.columns.names) - {'Column Name'}\n    for name in annotation_row_names:\n        annotation_type = 'N' if name in numerical_annotation_rows else 'C'\n        annotations['{}:{}'.format(annotation_type, name)] = _df.columns.get_level_values(name)\n    with PathOrFile(path_or_file, 'w') as f:\n        f.write(separator.join(column_names) + '\\n')\n        for name, values in annotations.items():\n            f.write('#!{{{name}}}{values}\\n'.format(name=name, values=separator.join([str(x) for x in values])))\n        _df.to_csv(f, header=None, index=False, sep=separator)", "response": "Save a pd. DataFrame to Perseus text format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninfer the main columns of a single column.", "response": "def _infer_main_columns(df, index_level='Column Name', numeric_dtypes=_numeric_dtypes):\n    \"\"\"\n    All numeric columns up-until the first non-numeric column are considered main columns.\n    :param df: The pd.DataFrame\n    :param index_level: Name of the index level of the column names. Default 'Column Name'\n    :param numeric_dtypes: Set of numpy.dtype containing all numeric types. Default int/float.\n    :returns: The names of the infered main columns\n    \"\"\"\n    columns = df.columns.get_level_values(index_level)\n    main_columns = []\n    for i,dtype in enumerate(df.dtypes):\n        if dtype in numeric_dtypes:\n            main_columns.append(columns[i])\n        else:\n            break\n    return main_columns"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_page(search_text):\n    lst = search_aikif(search_text)\n    txt = '<table class=\"as-table as-table-zebra as-table-horizontal\">'\n    for result in lst:\n        txt += '<TR><TD>' + result + '</TD></TR>'\n    txt += '</TABLE>\\n\\n'\n    return txt", "response": "formats the entire search result in a table output\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_aikif(txt, formatHTML=True):\n    results = []\n    num_found = 0\n    import aikif.lib.cls_filelist as mod_fl\n    my_files = mod_fl.FileList([aikif_folder ], ['*.*'], ['*.pyc'])\n    files = my_files.get_list()\n    for f in files:\n        try:\n            num_found = 0\n            with open(f, 'r') as cur:\n                line_num = 0\n                for line in cur:\n                    line_num += 1\n                    if txt in line:\n                        num_found += 1\n                        if formatHTML is True:\n                            results.append(format_result(line, line_num, txt))\n                        else:\n                            results.append([f, line, line_num, txt])\n            if num_found > 0:\n                if formatHTML is True:\n                    results.append('<h3>' + f + ' = ' + str(num_found) + ' results</h3>')\n                else:    \n                    print(f + ' = ' + str(num_found) + '')\n        except Exception:\n            results.append('problem with file ' + f)\n    if len(results) == 0:\n        results.append(\"No results\")\n    return results", "response": "search for text in AIKIF"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting the result of a search", "response": "def format_result(line, line_num, txt):\n    \"\"\" highlight the search result \"\"\"\n    \n    return '&nbsp;&nbsp;' + str(line_num) + ': ' + line.replace(txt, '<span style=\"background-color: #FFFF00\">' + txt + '</span>')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the best world to make people happy", "response": "def solve(self, max_worlds=10000, silent=False):\n        \"\"\"\n        find the best world to make people happy\n        \"\"\"\n        self.num_worlds = 0\n        num_unhappy = 0\n        for tax_rate in range(self.tax_range[0],self.tax_range[1]):\n            for equity in range(self.equity_range[0],self.equity_range[1]):\n                for tradition in range(self.tradition_range[0],self.tradition_range[1]):\n                    self.num_worlds += 1\n                    if self.num_worlds > max_worlds:\n                        break\n                    w = World(str(self.num_worlds).zfill(6), [5000, tax_rate/10, tradition/10, equity/10])\n                    world_happiness = 0\n                    num_unhappy = 0\n                    for person in self.all_people:\n                        wh = Happiness(person, w)\n                        world_happiness += wh.rating\n                        if wh.rating < 0:\n                            num_unhappy += 1\n                    if world_happiness > self.net_happiness:\n                        self.net_happiness = world_happiness\n                        self.unhappy_people = num_unhappy\n                        if not silent:\n                            print('found better world - ' + w.nme + ' = ' + str(world_happiness) + ' - total unhappy_people = ' + str(self.unhappy_people))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_details(self):\n        res = str(self)\n        res += '\\nDETAILS\\n'\n        for f in self.factors:\n            res += str(f)\n\n        return res", "response": "show details of happiness parameters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate(self):\n        self.rating = 0\n        for f in self.factors:\n            self._update_pref(f.min, f.max, self.world.tax_rate)", "response": "Calculates the estimated happiness of a person in a world."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_pref(self, lmin, lmax, cur):\n        rate_of_change_positive = 10\n        rate_of_change_negative = 2\n        add_positive = 10\n        add_negative = 2\n        if lmin == lmax:\n            self.rating -= int(abs(lmin - cur)*100) / 10\n        else:\n            if lmin <= cur:\n                self.rating += (int(abs(lmin - cur)*rate_of_change_positive)) + add_positive\n            else:\n                self.rating -= (int(abs(lmin - cur)*rate_of_change_negative)) + add_negative\n            if lmax >= cur:\n                self.rating += (int(abs(lmax - cur)*rate_of_change_positive)) + add_positive\n            else:\n                self.rating -= (int(abs(lmax - cur)*rate_of_change_negative)) + add_negative", "response": "Update the self. rating based on the parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_value_to_text(self, text):\n\n        if self.nme in text:\n\n            res = 0.8\n        else:\n            res = 0.2\n\n        return self.nme + ' = ' + str(res) + ' match against ' + text", "response": "This function is used to match the value of a attribute to a text."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a list to html using table formatting", "response": "def list2html(lst):\n    \"\"\" \n    convert a list to html using table formatting \n    \"\"\"\n    txt = '<TABLE width=100% border=0>'\n    for l in lst:\n        txt += '<TR>\\n'\n        if type(l) is str:\n            txt+= '<TD>' + l + '</TD>\\n'\n        elif type(l) is list:\n            txt+= '<TD>'\n            for i in l:\n                txt += i + ', '\n            txt+= '</TD>'\n        else:\n            txt+= '<TD>' + str(l) + '</TD>\\n'\n        txt += '</TR>\\n'\n    txt += '</TABLE><BR>\\n'\n    return txt"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a list of files and returns as a list", "response": "def GetFileList(rootPaths, lstXtn, shortNameOnly='Y'):\n    \"\"\" \n    builds a list of files and returns as a list \n    \"\"\"\n    numFiles = 0    \n    opFileList = []\n    if type(rootPaths) == str:\n        rootPaths = [rootPaths]\n    for rootPath in rootPaths:\n        for root, dirs, files in os.walk(rootPath):\n            #print('found ' + str(len(dirs)) + ' directories')\n            for basename in files:\n                for xtn in lstXtn:\n                    if fnmatch.fnmatch(basename, xtn):\n                        filename = os.path.join(root, basename)\n                        numFiles = numFiles + 1\n                        if shortNameOnly == 'Y':\n                            opFileList.append( os.path.basename(filename))\n                        else:\n                            opFileList.append(filename)\n                        \n    return sorted(opFileList)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the html for an edit form", "response": "def build_edit_form(title, id, cols, return_page):\n    \"\"\" \n    returns the html for a simple edit form \n    \"\"\"\n    txt = '<H3>' + title + '<H3>'\n    txt += '<form action=\"' + return_page + '\" method=\"POST\">\\n' # return_page = /agents\n    txt += '  updating id:' + str(id) + '\\n<BR>'\n    txt += '  <input type=\"hidden\" name=\"rec_id\" readonly value=\"' + str(id) + '\"> '\n    txt += '  <TABLE width=80% valign=top border=1>'\n    \n    for col_num, col in enumerate(cols):\n        txt += '  <TR>\\n'\n        txt += '    <TD><div id=\"form_label\">' + col + '</div></TD>\\n'\n        txt += '    <TD><div id=\"form_input\"><input type=\"text\" name=\"col_' + str(col_num) + '\"></div></TD>\\n'\n        txt += '  </TR>\\n'\n    txt += '  <TR><TD></TD>\\n'\n    txt += '  <TD>\\n'\n    txt += '    <input type=\"submit\" name=\"update-form\" value=\"Save Changes\">\\n'\n    txt += '    <input type=\"submit\" name=\"delete-form\" value=\"Delete\">\\n'\n    txt += '    <input type=\"submit\" name=\"add-form\" value=\"Add\">\\n'\n    txt += '  </TD></TR></TABLE>'\n    txt += '</form>\\n'\n    return txt"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the html to display a listbox", "response": "def build_html_listbox(lst, nme):\n    \"\"\"\n    returns the html to display a listbox\n    \"\"\"\n    res = '<select name=\"' + nme + '\" multiple=\"multiple\">\\n'\n    for l in lst:\n        res += '    <option>' + str(l) + '</option>\\n'\n    res += '</select>\\n'\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_data_list(lst):\n    txt = '<H3>' + List + '<H3><UL>'\n    for i in lst:\n        txt += '<LI>' + i + '</LI>'\n        \n    txt += '<UL>'\n    return txt", "response": "returns the html with supplied list as a HTML listbox \n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filelist2html(lst, fldr, hasHeader='N'):\n    txt = '<TABLE width=100% border=0>'\n    numRows = 1\n    if lst:\n        for l in lst:\n            if hasHeader == 'Y':\n                if numRows == 1:\n                    td_begin = '<TH>'\n                    td_end = '</TH>'\n                else:\n                    td_begin = '<TD>'\n                    td_end = '</TD>'\n            else:\n                td_begin = '<TD>'\n                td_end = '</TD>'\n            numRows += 1\n            txt += '<TR>'\n            if type(l) is str:\n                txt += td_begin + link_file(l, fldr) + td_end\n            elif type(l) is list:\n                txt += td_begin\n                for i in l:\n                    txt+= link_file(i, fldr) + '; '\n                txt += td_end\n            else:\n                txt += td_begin + str(l) + td_end\n            txt += '</TR>\\n'\n    txt += '</TABLE><BR>\\n'\n    return txt", "response": "formats a standard filelist to htmk using table formats \n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef link_file(f, fldr):\n    fname = os.path.join(fldr,f)\n    if os.path.isfile(fname):\n        return '<a href=\"/aikif/data/core/' + f + '\">' + f + '</a>'\n    else:\n        return f", "response": "creates a html link for a file using folder fldr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_to_htmlrow(d):\n    res = \"<TR>\\n\"\n    for k, v in d.items():\n        if type(v) == str:\n            res = res + '<TD><p>' + k + ':</p></TD><TD><p>' + v + '</p></TD>'\n        else:\n            res = res + '<TD><p>' + k + ':</p></TD><TD><p>' + str(v) + '</p></TD>'\n    res += '</TR>\\n'\n    return res", "response": "converts a dictionary to a HTML table row"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_csv_to_html_table(csvFile, hasHeader='N'):\n    txt = '<table class=\"as-table as-table-zebra as-table-horizontal\">'\n    with open(csvFile, \"r\") as f:  # \n        numRows = 1\n        for row in f:\n            if hasHeader == 'Y':\n                if numRows == 1:\n                    td_begin = '<TH>'\n                    td_end = '</TH>'\n                else:\n                    td_begin = '<TD>'\n                    td_end = '</TD>'\n            else:\n                td_begin = '<TD>'\n                td_end = '</TD>'\n            cols = row.split(',')\n            numRows += 1\n\n            txt += \"<TR>\"\n            for col in cols:\n                txt += td_begin\n                try:\n                    colString = col\n                except Exception:\n                    colString = '<font color=red>Error decoding column data</font>'\n                txt += colString.strip('\"')\t\n                txt += td_end\n            txt += \"</TR>\\n\"\n        txt += \"</TABLE>\\n\\n\"\n    return txt", "response": "reads a CSV file and converts it to HTML"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_csv_to_html_list(csvFile):\n    txt = ''\n    with open(csvFile) as csv_file:\n        for row in csv.reader(csv_file, delimiter=','):\n            txt += '<div id=\"table_row\">'\n            for col in row:\n                txt += \" \"\n                try:\n                    txt += col\n                except Exception:\n                    txt += 'Error'\n                txt += \" \"\n            txt += \"</div>\\n\"\n    return txt", "response": "reads a CSV file and converts it to a HTML List\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the world to the given grd.", "response": "def set_world(self, grd, start_y_x, y_x):\n        \"\"\"\n        tell the agent to move to location y,x \n        Why is there another grd object in the agent? Because \n        this is NOT the main grid, rather a copy for the agent\n        to overwrite with planning routes, etc.\n        The real grid is initialised in World.__init__() class\n        \"\"\"\n        self.grd = grd\n        self.start_y = start_y_x[0]\n        self.start_x = start_y_x[1]\n        self.current_y = start_y_x[0]\n        self.current_x = start_y_x[1]\n        self.target_y = y_x[0]\n        self.target_x = y_x[1]\n        self.backtrack = [0,0]   # set only if blocked and agent needs to go back\n        self.prefer_x = 0        # set only if backtracked as preferred direction x\n        self.prefer_y = 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_your_job(self):\n        y,x = self.get_intended_direction()  # first find out where we should go\n        if self.target_x == self.current_x and self.target_y == self.current_y:\n            #print(self.name + \" : TARGET ACQUIRED\")\n            if len(self.results) == 0:\n                self.results.append(\"TARGET ACQUIRED\")\n                self.lg_mv(2, self.name + \": TARGET ACQUIRED\" )\n            \n            return\n        \n        self.num_steps += 1   \n        # first try is to move on the x axis in a simple greedy search\n        accessible = ['\\\\', '-', '|', '/', '.']\n        \n        # randomly move in Y direction instead of X if all paths clear\n        if y != 0 and x != 0 and self.backtrack == [0,0]:\n            if random.randint(1,10) > 6:\n                if self.grd.get_tile(self.current_y + y, self.current_x) in accessible:\n                    self.current_y += y\n                    self.lg_mv(3, self.name + \": randomly moving Y axis \" + str(self.num_steps)  )\n                    return\n        if x == 1:\n            if self.grd.get_tile(self.current_y, self.current_x + 1) in accessible:\n                self.current_x += 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving West\" )\n                return\n        elif x == -1:\n            if self.grd.get_tile(self.current_y, self.current_x - 1) in accessible:\n                self.current_x -= 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving East\" )\n                return\n        elif y == 1:\n            if self.grd.get_tile(self.current_y + 1, self.current_x) in accessible:\n                self.current_y += 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving South\" )\n                return\n        elif y == -1:\n            if self.grd.get_tile(self.current_y - 1, self.current_x) in accessible:\n                self.current_y -= 1\n                self.lg_mv(3, self.name + \": move# \" + str(self.num_steps) + \" - moving North\")\n                return\n        \n        self.grd.set_tile(self.start_y, self.start_x, 'A')\n        self.grd.save(os.path.join(os.getcwd(), 'agent.txt'))", "response": "This function is called by the explore agent to move to the target while avoiding blockages on the grid. It is also called by the explore agent to avoid blockages on the grid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap for debugging print and log methods", "response": "def lg_mv(self, log_lvl, txt):\n        \"\"\"\n        wrapper for debugging print and log methods\n        \"\"\"\n        if log_lvl <= self.LOG_LEVEL:\n            print(txt + str(self.current_y) + \",\" + str(self.current_x))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Y X value showing which direction the agent should move in order to get to the target ArcGIS agent should move in order to get to the target ArcGIS agent should move in order to get to the target ArcGIS agent", "response": "def get_intended_direction(self):\n        \"\"\"\n        returns a Y,X value showing which direction the\n        agent should move in order to get to the target\n        \"\"\"\n        x = 0\n        y = 0\n        if self.target_x == self.current_x and self.target_y == self.current_y:\n            return y,x  # target already acquired\n        if self.target_y > self.current_y:\n            y = 1\n        elif self.target_y < self.current_y:\n            y = -1\n        if self.target_x > self.current_x:\n            x = 1\n        elif self.target_x < self.current_x:\n            x = -1\n        return y,x"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear_surroundings(self):\n        cells_to_clear = self.grd.eight_neighbors(self.current_y, self.current_x)\n        for cell in cells_to_clear:\n            self.grd.set_tile(cell[0], cell[1], ' ')", "response": "Clears the cells immediately around the grid of the agent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_status(self):\n        txt = 'Agent Status:\\n'\n        print(txt)\n        txt += \"start_x  = \" + str(self.start_x) + \"\\n\"\n        txt += \"start_y  = \" + str(self.start_y) + \"\\n\"\n        txt += \"target_x = \" + str(self.target_x) + \"\\n\"\n        txt += \"target_y = \" + str(self.target_y) + \"\\n\"\n        txt += \"current_x = \" + str(self.current_x) + \"\\n\"\n        txt += \"current_y = \" + str(self.current_y) + \"\\n\"\n       \n        \n        print(self.grd)\n        return txt", "response": "shows the status of the agent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_audio_metadata(fname):\n    from mutagenx.easyid3 import EasyID3\n    audio = EasyID3(fname)\n    audio_dict = {}\n    \n    try:\n        artist = audio[\"artist\"]\n    except KeyError:\n        artist = ''\n        \n    try:    \n        title = audio[\"title\"]\n    except KeyError:\n        print(\"Cant get title\")\n        \n    try:\n        album = audio[\"album\"]\n    except KeyError:\n        album = ''\n        \n    \n    audio_dict['album'] = album\n    audio_dict['title'] = title\n    audio_dict['artist'] = artist\n    \n    return audio_dict", "response": "returns a dictionary of audio metadata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the metadata from an MP3 file", "response": "def get_audio_metadata_old(fname):\n    \"\"\" retrieve the metadata from an MP3 file \"\"\"\n    audio_dict = {}\n    print(\"IDv2 tag info for %s:\" % fname)\n    try:\n        audio = mutagenx.id3.ID3(fname, translate=False)\n    except StandardError as err:\n        print(\"ERROR = \" + str(err))\n    #else:\n        #print(audio.pprint().encode(\"utf-8\", \"replace\"))\n        #for frame in audio.values():\n        #    print(repr(frame))\n    \n    try:\n        audio_dict[\"title\"] = audio[\"title\"]\n    except KeyError:\n        print(\"No title\")\n        \n    try:\n        audio_dict[\"artist\"] = audio[\"artist\"] # tags['TPE1'] \n    except KeyError:\n        print(\"No artist\")\n        \n    try:\n        audio_dict[\"album\"] = audio[\"album\"]\n    except KeyError:\n        print(\"No album\")\n        \n    try:\n        audio_dict[\"length\"] = audio[\"length\"]\n    except KeyError:\n        print(\"No length\")\n        \n    #pprint.pprint(audio.tags)\n        \n    return audio_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the cytoscape version of the current node", "response": "def checkCytoscapeVersion(host=cytoscape_host,port=cytoscape_port):\n    \"\"\"\n    Checks cytoscape version\n    \n    :param host: cytoscape host address, default=cytoscape_host\n    :param port: cytoscape port, default=1234\n    \n    :returns: cytoscape and api version\n    \"\"\"\n    \n    URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/version/\"\n    r = requests.get(url = URL)\n    r=json.loads(r.content)\n    for k in r.keys():\n        print(k, r[k])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTableColumns(table, columns, namespace = \"default\", network = \"current\", host=cytoscape_host,port=cytoscape_port,verbose=False):\n    \n    \n    if type(network) != int:\n        network=cytoscape(\"network\", \"get attribute\",\\\n                      {\"network\":network,\\\n                       \"namespace\":namespace,\\\n                       \"columnList\":\"SUID\"},host=host,port=port)\n        network=network[0][\"SUID\"]\n\n    \n    df=pd.DataFrame()\n    def target(column):\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/networks/\"+str(network)+\"/tables/\"+namespace+table+\"/columns/\"+column  \n        if verbose:\n            print(\"'\"+URL+\"'\")\n            sys.stdout.flush()\n        response = urllib2.urlopen(URL)\n        response = response.read()\n        colA=json.loads(response)\n\n        col=pd.DataFrame()    \n        colHeader=colA[\"name\"]\n        colValues=colA[\"values\"]\n        col[colHeader]=colValues\n        return col\n    \n    ncols=[\"name\"]\n    for c in columns:\n        ncols.append(c.replace(\" \",\"%20\") )\n    for c in ncols:\n        try:\n            col=target(c)\n            df=pd.concat([df,col],axis=1)\n        except:\n            print(\"Could not find \"+c)\n            sys.stdout.flush()        \n\n    df.index=df[\"name\"].tolist()\n    df=df.drop([\"name\"],axis=1)\n    \n    return df", "response": "Gets tables from cytoscape and returns a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the data from a pandas dataframe into a single node or network.", "response": "def loadTableData(df, df_key='index',table=\"node\", \\\n                   table_key_column = \"name\",\n                   network=\"current\",\\\n                   namespace=\"default\",\\\n                   host=cytoscape_host,port=cytoscape_port,verbose=False):\n\n    \"\"\"\n    Loads tables into cytoscape\n    \n    :param df: a pandas dataframe to load\n    :param df_key: key column in df, default=\"index\"\n    :param table: target table, default=\"node\"\n    :param table_key_column: table key column, default=\"name\"\n    :param network: a network name or id, default=\"current\"\n    :param host: cytoscape host address, default=cytoscape_host\n    :param port: cytoscape port, default=1234\n    :param verbose: print more information\n\n    :returns: output of put request\n    \"\"\"\n    \n    \n    \n    if type(network) != int:\n        networkID=cytoscape(\"network\", \"get attribute\",\\\n                      {\"network\":network,\\\n                       \"namespace\":namespace,\\\n                       \"columnList\":\"SUID\"},host=host,port=port)\n        networkname=cytoscape(\"network\", \"get attribute\",\\\n                      {\"network\":network,\\\n                       \"namespace\":namespace,\\\n                       \"columnList\":\"name\"},host=host,port=port)\n        \n        network=networkID[0][\"SUID\"]\n        networkname=networkname[0][\"name\"]\n        \n    tmp=df.copy()\n    if df_key!=\"index\":\n        tmp.index=tmp[df_key].tolist()\n        tmp=tmp.drop([df_key],axis=1)\n            \n    tablen=networkname+\" default node\"\n    \n    data=[]\n\n \n    for c in tmp.columns.tolist():\n        tmpcol=tmp[[c]].dropna()\n        for r in tmpcol.index.tolist():\n            check=tmpcol[tmpcol.index.isin([r])]\n            \n            cell={}\n            cell[str(table_key_column)]=str(r) # {\"name\":\"p53\"}\n            if len(check) == 1:\n                val=tmpcol.loc[r,c]\n            \n                if type(val) != str:\n                    val=float(val)\n            else:\n                print(check)\n                val=\"\"\n            cell[str(c)]=val\n            data.append(cell)\n    \n    \n    upload={\"key\":table_key_column,\"dataKey\":table_key_column,\\\n            \"data\":data}\n    \n    \n    URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/networks/\"+str(network)+\"/tables/\"+namespace+table  \n    if verbose:\n        print(\"'\"+URL+\"'\")\n        sys.stdout.flush()\n    r = requests.put(url = URL, json = upload)\n    if verbose:\n        print(r)\n    CheckResponse(r)\n    res=r.content\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_style(title,defaults=None,mappings=None,host=cytoscape_host,port=cytoscape_port,verbose=False):\n\n    if defaults: \n        defaults_=[]    \n        for d in defaults:\n            if d:\n                defaults_.append(d)\n        defaults=defaults_\n\n    if mappings:\n        mappings_=[]\n        for m in mappings:\n            if m:\n                mappings_.append(m)\n        mappings=mappings_\n\n\n    URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/styles/\"+str(title)\n    if verbose:\n        print(URL)\n        sys.stdout.flush()\n\n    response = urllib2.urlopen(URL)    \n    response = response.read()\n    response = json.loads(response)\n    \n    olddefaults=response[\"defaults\"]\n    oldmappings=response[\"mappings\"]\n\n    if mappings:\n        mappings_visual_properties=[ m[\"visualProperty\"] for m in mappings ]\n        newmappings=[ m for m in oldmappings if m[\"visualProperty\"] not in mappings_visual_properties ]\n        for m in mappings:\n            newmappings.append(m)\n    else:\n        newmappings=oldmappings\n\n    if defaults:\n        defaults_visual_properties=[ m[\"visualProperty\"] for m in defaults ]\n        newdefaults=[ m for m in olddefaults if m[\"visualProperty\"] not in defaults_visual_properties ]\n        for m in defaults:\n            newdefaults.append(m)\n    else:\n        newdefaults=olddefaults\n        \n    r=requests.delete(URL)\n    CheckResponse(r)    \n\n    URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/styles\"\n    PARAMS={\"title\":title,\\\n           \"defaults\":newdefaults,\\\n           \"mappings\":newmappings}\n    r = requests.post(url = URL, json = PARAMS)\n    CheckResponse(r)", "response": "Updates a single visual style."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_styles(title,defaults=None,mappings=None,host=cytoscape_host,port=cytoscape_port):\n    \n    if defaults:\n        defaults_=[]\n        for d in defaults:\n            if d:\n                defaults_.append(d)\n        defaults=defaults_\n\n    if mappings:\n        mappings_=[]\n        for m in mappings:\n            if m:\n                mappings_.append(m)\n        mappings=mappings_\n\n    try:\n        update_style(title,defaults=defaults,mappings=mappings,host=host,port=port)\n        print(\"Existing style was updated.\")\n        sys.stdout.flush()\n    except:\n        print(\"Creating new style.\")\n        sys.stdout.flush()\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/styles\"\n        PARAMS={\"title\":title,\\\n               \"defaults\":defaults,\\\n               \"mappings\":mappings}\n        r = requests.post(url = URL, json = PARAMS)\n        CheckResponse(r)", "response": "Creates a new visual style and returns the new style."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mapVisualProperty(visualProperty,mappingType,mappingColumn,\\\n                      lower=None,center=None,upper=None,\\\n                      discrete=None,\\\n                      network=\"current\",table=\"node\",\\\n                      namespace=\"default\",host=cytoscape_host,\\\n                      port=cytoscape_port, verbose=False):\n    \"\"\"\"\n    Generates a dictionary for a given visual property\n    \n    :param visualProperty: visualProperty\n    :param mappingType: mappingType\n    :param mappingColumn: mappingColumn\n    :param lower: for \"continuous\" mappings a list of the form [value,rgb_string]\n    :param center: for \"continuous\" mappings a list of the form [value,rgb_string]\n    :param upper: for \"continuous\" mappings a list of the form [value,rgb_string]\n    :param discrete: for discrete mappings, a list of lists of the form [ list_of_keys, list_of_values ]\n    :param network: a network name or id, default=\"current\"\n    :param host: cytoscape host address, default=cytoscape_host\n    :param port: cytoscape port, default=1234\n    \n    :retunrs: a dictionary for the respective visual property\n\n    \"\"\"\n    if type(network) != int:\n        networkID=cytoscape(\"network\", \"get attribute\",\\\n                      {\"network\":network,\\\n                       \"namespace\":namespace,\\\n                       \"columnList\":\"SUID\"},host=host,port=port)\n        networkname=cytoscape(\"network\", \"get attribute\",\\\n                      {\"network\":network,\\\n                       \"namespace\":namespace,\\\n                       \"columnList\":\"name\"},host=host,port=port)\n        \n        network=networkID[0][\"SUID\"]\n        networkname=networkname[0][\"name\"]\n\n        URL=\"http://\"+str(host)+\":\"+str(port)+\"/v1/networks/\"+str(network)+\"/tables/\"+namespace+table+\"/columns/\"\n        if verbose:\n            print(URL)\n            sys.stdout.flush()\n        response = urllib2.urlopen(URL)\n        response = response.read()\n        response = json.loads(response)\n\n    mappingColumnType=None\n    for r in response:\n        if r[\"name\"]==mappingColumn:\n            mappingColumnType=r[\"type\"]\n            break\n    if not mappingColumnType:\n        print(\"For mappingType: \"+mappingType+\" it was not possible to find a  mappingColumnType.\")\n        sys.stdout.flush()\n    \n        \n    PARAMS={\"mappingType\" : mappingType,\\\n            \"mappingColumn\" : mappingColumn,\n            \"mappingColumnType\" : mappingColumnType,\n            \"visualProperty\" : visualProperty}\n    if mappingType == \"continuous\":\n        PARAMS[\"points\"]=[{\"value\" : lower[0],\\\n                           \"lesser\" : lower[1],\\\n                           \"equal\" : lower[1],\\\n                           \"greater\" : lower[1]},\\\n                          {\"value\" : center[0],\n                           \"lesser\" : center[1],\n                           \"equal\" : center[1],\n                           \"greater\" : center[1] },\\\n                          {\"value\" : upper[0],\\\n                           \"lesser\" : upper[1],\\\n                           \"equal\" : upper[1],\\\n                           \"greater\" : upper[1]}]\n        \n    if discrete:\n        PARAMS[\"map\"]=[]\n        for k,v in zip(discrete[0],discrete[1]):\n            PARAMS[\"map\"].append({ \"key\":k,\"value\":v})\n    \n    if not mappingColumnType:\n        res=None\n    else:\n        res=PARAMS    \n\n    return res", "response": "This function maps a given visual property to a set of properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef result(filetype=\"PNG\",saveas=None, host=cytoscape_host,port=cytoscape_port):\n    sleep(1)\n\n    def MAKETMP():\n        (fd, tmp_file) = tempfile.mkstemp()\n        tmp_file=\"/tmp/\"+tmp_file.split(\"/\")[-1]\n        return tmp_file\n    \n    outfile=MAKETMP()\n    \n    extensions={\"PNG\":\".png\",\"PDF\":\".pdf\",\"CYS\":\".cys\",\"CYJS\":\".cyjs\"}\n    ext=extensions[filetype]\n    \n    response=cytoscape(\"view\",\"fit content\",host=host,port=port)\n    response=cytoscape(\"view\", \"export\" , \\\n                       {\"options\":filetype,\\\n                        \"OutputFile\":outfile},\\\n                      host=host,port=port)\n    if host!='localhost':\n        ssh = paramiko.SSHClient()\n        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        ssh.connect(host)\n        ftp_client=ssh.open_sftp()\n        ftp_client.get(outfile+ext,outfile+ext)\n        ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(\"rm \"+outfile+ext )\n        \n    img = WImage(filename=outfile+ext)\n    if saveas:\n        copyfile(outfile+ext,saveas)\n    os.remove(outfile+ext)\n    return img", "response": "Checks the current network."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots tables from aDiff/cuffdiff into cytoscape using String protein queries. Uses top changed genes as well as first neighbours and difusion fo generate subnetworks. :param df: df as outputed by aDiff for differential gene expression :param aging_genes: ENS gene ids to be labeled with a diagonal :param species: species for string app query. eg. \"caenorhabditis elegans\", \"drosophila melanogaster\", \"mus musculus\", \"homo sapiens\" :param limit: limit for string app query. Number of extra genes to recover. If None, limit=N(query_genes)*.25 :param cuttoff: confidence cuttoff for sting app query. Default=0.4 :param taxon: taxon id for string app query. For the species shown above, taxon id will be automatically identified :param cytoscape_host: host address for cytoscape :param cytoscape_port: cytoscape port :param target: target destination for saving files without prefix. eg. \"/beegfs/group_bit/home/JBoucas/test/N2_vs_daf2\" :returns: nothing", "response": "def aDiffCytoscape(df,aging_genes,target,species=\"caenorhabditis elegans\",limit=None, cutoff=0.4,\\\n                  taxon=None,host=cytoscape_host,port=cytoscape_port):\n    \"\"\"\n    Plots tables from aDiff/cuffdiff into cytoscape using String protein queries. \n    Uses top changed genes as well as first neighbours and difusion fo generate subnetworks. \n    \n    :param df: df as outputed by aDiff for differential gene expression\n    :param aging_genes: ENS gene ids to be labeled with a diagonal\n    :param species: species for string app query. eg. \"caenorhabditis elegans\", \"drosophila melanogaster\", \"mus musculus\", \"homo sapiens\"\n    :param limit: limit for string app query. Number of extra genes to recover. If None, limit=N(query_genes)*.25\n    :param cuttoff: confidence cuttoff for sting app query. Default=0.4\n    :param taxon: taxon id for string app query. For the species shown above, taxon id will be automatically identified\n    :param cytoscape_host: host address for cytoscape\n    :param cytoscape_port: cytoscape port\n    :param target: target destination for saving files without prefix. eg. \"/beegfs/group_bit/home/JBoucas/test/N2_vs_daf2\"\n\n    :returns: nothing\n    \n    \"\"\"\n\n    ##### TEMPORARY FIX - STRING APP NOT ACCEPTING QUERIES ABOVE 2000 GENES ####\n    df=df.sort_values(by=[\"q_value\"],ascending=True)\n    df.reset_index(inplace=True, drop=True)\n    tmp=df[:1999]\n    df=tmp.copy()\n    ##### END OF TEMPORARY FIX #####\n\n    query_genes=df[\"ensembl_gene_id\"].tolist()\n    df[\"NormInt\"]=df[\"value_1\"]*df[\"value_2\"]\n    df[\"NormInt\"]=df[\"NormInt\"].apply(lambda x: np.log10(np.sqrt(x)) )\n\n    if not limit:\n        limit=int(len(query_genes)*.25)\n\n    # Annotate aging evindence\n    def CheckEvidence(x,aging_genes=aging_genes):\n        if x in aging_genes:\n            res=\"aging_gene\"\n        else:\n            res=\"no\"\n        return res\n    df[\"evidence\"]=df[\"ensembl_gene_id\"].apply(lambda x:CheckEvidence(x) )\n\n    # fix infinit values\n    def FixInfs(x):\n        if str(x) in [\"-inf\",\"inf\"]:\n            res=np.nan\n        else:\n            res=x\n            return res\n    df[\"NormInt\"]=df[\"NormInt\"].apply( lambda x:  FixInfs(x) )\n    df[\"log2(fold_change)\"]=df[\"log2(fold_change)\"].apply( lambda x:  FixInfs(x) )\n        \n    taxons={\"caenorhabditis elegans\":\"6239\",\"drosophila melanogaster\":\"7227\",\\\n       \"mus musculus\":\"10090\",\"homo sapiens\":\"9606\"}\n    if not taxon: \n        taxon=taxons[species]\n\n\n    # destroy any existing network still present in cytoscape\n    response=cytoscape(\"network\", \"list\",\\\n                       host=host, port=port)\n    if \"networks\" in response.keys():\n        response=response[\"networks\"]\n        #print response\n        if len(response) > 0:\n            for r in response:\n                rr=cytoscape(\"network\", \"destroy\",{\"network\":\"SUID:\"+str(r)},\\\n                             host=host, port=port)\n    \n    # String protein query\n    query_genes=[ str(s) for s in query_genes ]\n\n    response=cytoscape(\"string\", \"protein query\",\\\n                      {\"query\":\",\".join(query_genes),\\\n                       \"cutoff\":str(cutoff),\\\n                       \"species\":species,\\\n                       \"limit\":str(limit),\\\n                       \"taxonID\":taxon},\\\n                       host=host, port=port)\n\n    print(\"giving some time to cytoscape..\")\n    sys.stdout.flush()\n    sleep(10)\n\n    # apply new layout\n    response=cytoscape(\"layout\", \"force-directed\",\\\n                      {\"defaultSpringCoefficient\":\".000004\",\\\n                       \"defaultSpringLength\":\"5\"},\\\n                       host=host, port=port)\n    \n    # redefine defaults for node visualization\n    response=loadTableData(df[[\"ensembl_gene_id\",\"log2(fold_change)\",\"NormInt\",\"evidence\"]].dropna(),\\\n                       df_key=\"ensembl_gene_id\",table_key_column=\"query term\",\\\n                      host=host, port=port)\n    defaults_dic={\"NODE_SHAPE\":\"ellipse\",\\\n               \"NODE_SIZE\":60,\\\n               \"NODE_FILL_COLOR\":\"#AAAAAA\",\\\n               \"EDGE_TRANSPARENCY\":120}\n    defaults_list=simple_defaults(defaults_dic)\n\n    # apply mappings - blue / white / red - from -4 to +4 log2FC\n    NODE_LABEL=mapVisualProperty(\"NODE_LABEL\",\"passthrough\",\"display name\",host=host, port=port)\n\n    create_styles(\"dataStyle\",defaults_list,[NODE_LABEL],host=host, port=port)\n    response=cytoscape(\"vizmap\", \"apply\", {\"styles\":\"dataStyle\"},host=host, port=port)\n    cmap = matplotlib.cm.get_cmap(\"bwr\")\n    norm = matplotlib.colors.Normalize(vmin=-4, vmax=4)\n    min_color=matplotlib.colors.rgb2hex(cmap(norm(-4)))\n    center_color=matplotlib.colors.rgb2hex(cmap(norm(0)))\n    max_color=matplotlib.colors.rgb2hex(cmap(norm(4)))  \n\n    NODE_FILL_COLOR=mapVisualProperty('NODE_FILL_COLOR','continuous','log2(fold_change)',\\\n                         lower=[-4,min_color],center=[0.0,center_color],upper=[4,max_color],\\\n                                     host=host, port=port)\n    \n    # apply diamond shape and increase node size to nodes with aging evidence\n    NODE_SHAPE=mapVisualProperty('NODE_SHAPE','discrete','evidence',discrete=[ [\"aging_gene\",\"no\"], [\"DIAMOND\", \"ellipse\"] ],\\\n                                host=host, port=port)\n    NODE_SIZE=mapVisualProperty('NODE_SIZE','discrete','evidence',discrete=[ [\"aging_gene\",\"no\"], [\"100.0\",\"60.0\"] ],\\\n                               host=host, port=port)\n    update_style(\"dataStyle\",mappings=[NODE_SIZE,NODE_SHAPE,NODE_FILL_COLOR],\\\n                host=host, port=port)\n    response=cytoscape(\"vizmap\", \"apply\", {\"styles\":\"dataStyle\"},\\\n                      host=host, port=port)\n    \n    # apply mappings - reds - to Normalized expression (as in MA plots) to border color and border size\n    NormIntDf = getTableColumns('node',['NormInt'],host=host, port=port)\n    if 'NormInt' in NormIntDf.columns.tolist():\n        min_NormInt = min(NormIntDf.dropna()['NormInt'].tolist())\n        max_NormInt = max(NormIntDf.dropna()['NormInt'].tolist())\n        cent_NormInt = np.mean([min_NormInt,max_NormInt])\n\n        cmap = matplotlib.cm.get_cmap(\"Reds\")\n        norm = matplotlib.colors.Normalize(vmin=min_NormInt, vmax=max_NormInt)\n        min_color=matplotlib.colors.rgb2hex(cmap(norm(np.mean([min_NormInt,max_NormInt]))))\n        center_color=matplotlib.colors.rgb2hex(cmap(norm(cent_NormInt)))\n        max_color=matplotlib.colors.rgb2hex(cmap(norm(max_NormInt)))  \n\n        NODE_BORDER_PAINT=mapVisualProperty('NODE_BORDER_PAINT','continuous','NormInt',\\\n                             lower=[min_NormInt,min_color],center=[np.mean([min_NormInt,max_NormInt]),center_color],upper=[max_NormInt,max_color],\\\n                                           host=host, port=port)\n        update_style(\"dataStyle\",mappings=[NODE_BORDER_PAINT],\\\n                    host=host, port=port)\n        response=cytoscape(\"vizmap\", \"apply\", {\"styles\":\"dataStyle\"},\\\n                          host=host, port=port)\n\n        NODE_BORDER_WIDTH=mapVisualProperty('NODE_BORDER_WIDTH','continuous','NormInt',\\\n                          lower=[min_NormInt,2],center=[np.mean([min_NormInt,max_NormInt]),4],upper=[max_NormInt,8],\\\n                                           host=host, port=port)\n        update_style(\"dataStyle\",mappings=[NODE_BORDER_WIDTH],\\\n                    host=host, port=port)\n        response=cytoscape(\"vizmap\", \"apply\", {\"styles\":\"dataStyle\"},\\\n                          host=host, port=port)\n\n        response=cytoscape(\"network\",\"rename\",\\\n                           {\"name\":'main String network'},\\\n                          host=host, port=port)\n    \n    # create network with edges only\n    response=cytoscape(\"network\",\"select\",\\\n                   {\"edgeList\":\"all\",\\\n                   \"extendEdges\":\"true\"},\\\n                  host=host, port=port)\n    \n    response=cytoscape(\"network\",\"create\",\\\n                   {\"source\":\"current\",\\\n                    \"nodeList\":\"selected\"},\\\n                  host=host, port=port)\n    \n    response=cytoscape(\"network\",\"rename\",\\\n                       {\"name\":'main String network (edges only)'},\\\n                      host=host, port=port)\n    \n    # top 10 changed genes > first neighbours\n\n    response=cytoscape(\"network\",\"set current\",\n                       {\"network\":\"main String network (edges only)\"},\\\n                      host=host, port=port)\n    log2fcDf = getTableColumns('node',['log2(fold_change)'],host=host, port=port)\n    if 'log2(fold_change)' in log2fcDf.columns.tolist():\n        log2fcDf['log2(fold_change)']=log2fcDf['log2(fold_change)'].apply(lambda x: abs(x))\n        log2fcDf=log2fcDf.sort_values(by=['log2(fold_change)'],ascending=False)\n        top_nodes=log2fcDf.index.tolist()[:int(len(log2fcDf)*.10)]\n        response=cytoscape(\"network\",\"select\",\n                           {\"nodeList\":\"name:\"+\",\".join(top_nodes)},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"select\",\n                           {\"firstNeighbors\":\"\",\\\n                            \"direction\":\"any\",\\\n                            \"network\":\"current\"},\\\n                           host=host, port=port)\n        response=cytoscape(\"network\",\"create\",\n                           {\"source\":\"current\",\\\n                            \"nodeList\":\"selected\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"select\",\n                           {\"edgeList\":\"all\",\\\n                           \"extendEdges\":\"true\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"delete\",\n                           {\"nodeList\":\"unselected\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                          host=host,port=port)\n        response=cytoscape(\"layout\", \"force-directed\",\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"rename\",\\\n                           {\"name\":'top '+str(int(len(log2fcDf)*.10))+' changed firstNeighbors'},\\\n                          host=host, port=port)\n    \n        #top 10 changed genes difusion\n        response=cytoscape(\"network\",\"set current\",\n                           {\"network\":\"main String network (edges only)\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"select\",\n                           {\"nodeList\":\"name:\"+\",\".join(top_nodes)},\\\n                          host=host, port=port)\n        response=cytoscape(\"diffusion\",\"diffuse\",host=host, port=port)\n        response=cytoscape(\"network\",\"create\",\n                           {\"source\":\"current\",\\\n                          \"nodeList\":\"selected\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"select\",\n                           {\"edgeList\":\"all\",\\\n                           \"extendEdges\":\"true\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"delete\",\n                           {\"nodeList\":\"unselected\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                          host=host, port=port)\n        response=cytoscape(\"layout\", \"force-directed\",host=host, port=port)\n        response=cytoscape(\"network\",\"rename\",\\\n                           {\"name\":'top '+str(int(len(log2fcDf)*.10))+' changed diffusion'},\\\n                          host=host, port=port)\n    \n    def MAKETMP():\n        (fd, f) = tempfile.mkstemp()\n        f=\"/tmp/\"+f.split(\"/\")[-1]\n        return f\n\n\n    cys=MAKETMP()\n    cyjs=MAKETMP()\n    main_png=MAKETMP()\n    main_pdf=MAKETMP()\n    edg_png=MAKETMP()\n    edg_pdf=MAKETMP()\n    neig_png=MAKETMP()\n    neig_pdf=MAKETMP()\n    dif_png=MAKETMP()\n    dif_pdf=MAKETMP()\n    \n    response=cytoscape(\"session\", \"save as\" , \\\n                   {\"file\":cys},\\\n                 host=host, port=port)\n\n    response=cytoscape(\"network\", \"export\" , \\\n                       {\"options\":'CYJS',\\\n                        \"OutputFile\":cyjs},\\\n                      host=host, port=port)\n\n    response=cytoscape(\"network\",\"set current\",\n                       {\"network\":\"main String network\"},\\\n                      host=host, port=port)\n    response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                      host=host, port=port)\n    sleep(5)\n    response=cytoscape(\"view\", \"export\" , \\\n                       {\"options\":\"PNG\",\\\n                        \"OutputFile\":main_png},\\\n                      host=host, port=port)\n\n    response=cytoscape(\"view\", \"export\" , \\\n                       {\"options\":\"PDF\",\\\n                        \"OutputFile\":main_pdf},\\\n                      host=host, port=port)\n\n    \n    response=cytoscape(\"network\",\"set current\",\n                   {\"network\":\"main String network (edges only)\"},\\\n                  host=host, port=port)\n    response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                      host=host, port=port)\n    sleep(5)\n    response=cytoscape(\"view\", \"export\" , \\\n                       {\"options\":\"PNG\",\\\n                        \"OutputFile\":edg_png},\\\n                      host=host, port=port)\n\n    response=cytoscape(\"view\", \"export\" , \\\n                       {\"options\":\"PDF\",\\\n                        \"OutputFile\":edg_pdf},\\\n                      host=host, port=port)\n    \n\n    try:\n        response=cytoscape(\"network\",\"set current\",\n                           {\"network\":'top '+str(int(len(log2fcDf)*.10))+' changed firstNeighbors'},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                          host=host, port=port)\n        sleep(5)\n\n        response=cytoscape(\"view\", \"export\" , \\\n                           {\"options\":\"PNG\",\\\n                            \"OutputFile\":neig_png},\\\n                          host=host, port=port)\n\n        response=cytoscape(\"view\", \"export\" , \\\n                           {\"options\":\"PDF\",\\\n                            \"OutputFile\":neig_pdf},\\\n                          host=host, port=port)\n    except:\n        print(\"No \"+\"changed firstNeighbors\")\n        sys.stdout.flush()\n\n    try:\n        response=cytoscape(\"network\",\"set current\",\n                           {\"network\":'top '+str(int(len(log2fcDf)*.10))+' changed diffusion'},\\\n                          host=host, port=port)\n        response=cytoscape(\"network\",\"deselect\",{\"edgeList\":\"all\", \"nodeList\":\"all\"},\\\n                          host=host, port=port)\n        sleep(5)\n\n        response=cytoscape(\"view\", \"export\" , \\\n                           {\"options\":\"PNG\",\\\n                            \"OutputFile\":dif_png},\\\n                          host=host, port=port)\n\n        response=cytoscape(\"view\", \"export\" , \\\n                           {\"options\":\"PDF\",\\\n                            \"OutputFile\":dif_pdf},\\\n                          host=host, port=port)\n    except:\n        print(\"No \"+\"changed diffusion\")\n        sys.stdout.flush()    \n\n    ssh = paramiko.SSHClient()\n    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    ssh.connect(host)\n\n    ftp_client=ssh.open_sftp()\n\n    for f, extension, local in zip([cys,cyjs,main_png,main_pdf,edg_png,edg_pdf,neig_png,neig_pdf,dif_png,dif_pdf],\\\n                                    [\".cys\",\".cyjs\",\".png\",\".pdf\",\".png\",\".pdf\",\".png\",\".pdf\",\".png\",\".pdf\" ],\\\n                                    [target+\".cys\",target+\".cyjs\",target+\".main.png\",target+\".main.pdf\",\\\n                                    target+\".main.edges.png\",target+\".main.edges.pdf\",\\\n                                    target+\".topFirstNeighbors.png\",target+\".topFirstNeighbors.pdf\",\\\n                                    target+\".topDiffusion.png\",target+\".topDiffusion.pdf\"]):\n        try:\n            ftp_client.get(f+extension,local)\n            ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(\"rm \"+f+extension )\n        except:\n            print(\"No \"+local)\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_columns(sequence):\n    columns = {}\n\n    for row in sequence:\n        for key in row.keys():\n            if key not in columns:\n                columns[key] = len(key)\n\n            value_length = len(str(row[key]))\n            if value_length > columns[key]:\n                columns[key] = value_length\n\n    return columns", "response": "Calculates the maximum column widths for all tables in the resource tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_row_format(columns, keys=None):\n    row_format = ''\n    if keys is None:\n        keys = columns.keys()\n    else:\n        keys = [key for key in keys if key in columns]\n\n    for key in keys:\n        if len(row_format) > 0:\n            row_format += \"|\"\n        row_format += \"%%(%s)-%ds\" % (key, columns[key])\n\n    return '|' + row_format + '|'", "response": "Calculate row format for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting a sequence as ascii table to stdout.", "response": "def pprint(sequence, keys=None):\n    \"\"\"\n    Print sequence as ascii table to stdout.\n\n    Args:\n        sequence (list or tuple): a sequence with a dictionary each entry.\n        keys (list): optional list of keys to order columns as well as to filter for them.\n    \"\"\"\n    if len(sequence) > 0:\n        columns = calculate_columns(sequence)\n        row_format = calculate_row_format(columns, keys)\n        header = row_format % dict([(key, key.title()) for key in columns])\n        separator = row_format % dict([(key, '-' * columns[key]) for key in columns])\n\n        print(separator)\n        print(header)\n        print(separator)\n\n        for row in sequence:\n            print(row_format % row)\n\n        print(separator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef matrix_worker(data):\n    matrix = data['matrix']\n    Logger.get_logger(__name__ + '.worker').info(\n        \"Processing pipeline for matrix entry '%s'\", matrix['name'])\n\n    env = matrix['env'].copy()\n    env.update({'PIPELINE_MATRIX': matrix['name']})\n\n    pipeline = Pipeline(model=data['model'], env=env, options=data['options'])\n    pipeline.hooks = data['hooks']\n    return pipeline.process(data['pipeline'])", "response": "This function runs the pipeline in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if matrix entry can be processed.", "response": "def can_process_matrix(entry, matrix_tags):\n        \"\"\"\n        Check given matrix tags to be in the given list of matric tags.\n\n        Args:\n            entry (dict): matrix item (in yaml).\n            matrix_tags (list): represents --matrix-tags defined by user in command line.\n        Returns:\n            bool: True when matrix entry can be processed.\n        \"\"\"\n        if len(matrix_tags) == 0:\n            return True\n\n        count = 0\n        if 'tags' in entry:\n            for tag in matrix_tags:\n                if tag in entry['tags']:\n                    count += 1\n\n        return count > 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the pipeline in order of the matrix.", "response": "def run_matrix_ordered(self, process_data):\n        \"\"\"\n        Running pipelines one after the other.\n\n        Returns\n            dict: with two fields: success True/False and captured output (list of str).\n        \"\"\"\n        output = []\n        for entry in self.matrix:\n            env = entry['env'].copy()\n            env.update({'PIPELINE_MATRIX': entry['name']})\n\n            if Matrix.can_process_matrix(entry, process_data.options.matrix_tags):\n                self.logger.info(\"Processing pipeline for matrix entry '%s'\", entry['name'])\n                pipeline = Pipeline(model=process_data.model, env=env,\n                                    options=process_data.options)\n                pipeline.hooks = process_data.hooks\n                result = pipeline.process(process_data.pipeline)\n                output += result['output']\n                if not result['success']:\n                    return {'success': False, 'output': output}\n        return {'success': True, 'output': output}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning pipelines in parallel.", "response": "def run_matrix_in_parallel(self, process_data):\n        \"\"\"Running pipelines in parallel.\"\"\"\n        worker_data = [{'matrix': entry, 'pipeline': process_data.pipeline,\n                        'model': process_data.model, 'options': process_data.options,\n                        'hooks': process_data.hooks} for entry in self.matrix\n                       if Matrix.can_process_matrix(entry, process_data.options.matrix_tags)]\n        output = []\n        success = True\n        with closing(multiprocessing.Pool(multiprocessing.cpu_count())) as pool:\n            for result in pool.map(matrix_worker, worker_data):\n                output += result['output']\n                if not result['success']:\n                    success = False\n        return {'success': success, 'output': output}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(self, process_data):\n        if self.parallel and not process_data.options.dry_run:\n            return self.run_matrix_in_parallel(process_data)\n        return self.run_matrix_ordered(process_data)", "response": "Process the pipeline per matrix item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _sqlfile_to_statements(sql):\n    statements = (sqlparse.format(stmt, strip_comments=True).strip() for stmt in sqlparse.split(sql))\n    return [stmt for stmt in statements if stmt]", "response": "Takes a SQL string containing 0 or more statements and returns a \n    list of individual statements as strings. Comments and empty statements are ignored."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_migration_name(self, name, suffix):\n        return os.path.join(self.dir,\n                            'm{datestr}_{name}.{suffix}'.format(\n                                datestr=datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S'),\n                                name=name.replace(' ', '_'),\n                                suffix=suffix))", "response": "Generate a migration name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call_migrate(self, module, connection_param):\n        args = [connection_param]\n        spec = inspect.getargspec(module.migrate)\n        if len(spec.args) == 2:\n            args.append(self.db_config)\n        return module.migrate(*args)", "response": "Subclasses should call this method instead of module. migrate directly to support db_config optional argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _identify_datatype(self, input_data):\n        if isinstance(input_data, (int, float)) :\n            self.data_type = 'number'\n        elif isinstance(input_data, (list)): #, set\n            self.data_type = 'list'\n        elif isinstance(input_data, dict):\n            self.data_type = 'dict'\n        elif type(input_data) is str:\n            if self.input_data[0:4] == 'http':\n                self.data_type = 'url'\n            elif os.path.exists(input_data):\n                self.data_type = 'file'\n            else:\n                self.data_type = 'str'\n                \n        lg.record_result('_identify_datatype', self.name + ' is ' + self.data_type)", "response": "Identify the data type of the object based on the input data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a standard data object based on CSV file", "response": "def _create_from_csv(self):\n        \"\"\"\n        create a standard data object based on CSV file\n        \"\"\"\n       \n        import aikif.dataTools.cls_datatable as cl\n        fle = cl.DataTable(self.input_data, ',')\n        fle.load_to_array()\n        self.content['data'] = fle.arr\n        \n        \n        lg.record_process('_create_from_csv', 'read ' + self._calc_size_stats() + ' from ' + self.input_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a standard data object based on CSV file", "response": "def _create_from_owl(self):\n        \"\"\"\n        create a standard data object based on CSV file\n        \"\"\"\n        self.content['data'] = 'TODO - read OWL from ' + self.input_data\n        \n        lg.record_process('_create_from_owl', 'read ' + self._calc_size_stats() + ' from ' + self.input_data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_from_url(self):\n        import aikif.toolbox.network_tools as mod_net\n        mod_net.download_file_no_logon(self.input_data, 'temp_file.htm')\n        with open('temp_file.htm', 'r') as f:\n            self.content['data'] = f.read()\n        lg.record_process('_create_from_url', 'read ' + self._calc_size_stats() + ' from ' + self.input_data)", "response": "create a standard data object based on CSV file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calc_size_stats(self):\n        self.total_records = 0\n        self.total_length = 0\n        self.total_nodes = 0\n        if type(self.content['data']) is dict:\n            self.total_length += len(str(self.content['data']))\n            self.total_records += 1\n            self.total_nodes = sum(len(x) for x in self.content['data'].values())\n                               \n        elif hasattr(self.content['data'], '__iter__') and type(self.content['data']) is not str:\n            self._get_size_recursive(self.content['data'])\n        else:\n            self.total_records += 1\n            self.total_length += len(str(self.content['data']))\n            \n        return str(self.total_records) + ' records [or ' +  str(self.total_nodes) + ' nodes], taking ' + str(self.total_length) + ' bytes'", "response": "Calculate the size in bytes and num records of the content ArcGIS object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a readable version string from version_info tuple components.", "response": "def _make_version(major, minor, micro, releaselevel, serial):\n    \"\"\"Create a readable version string from version_info tuple components.\"\"\"\n    assert releaselevel in ['alpha', 'beta', 'candidate', 'final']\n    version = \"%d.%d\" % (major, minor)\n    if micro:\n        version += \".%d\" % (micro,)\n    if releaselevel != 'final':\n        short = {'alpha': 'a', 'beta': 'b', 'candidate': 'rc'}[releaselevel]\n        version += \"%s%d\" % (short, serial)\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_url(major, minor, micro, releaselevel, serial):\n    url = \"https://django-pagination-bootstrap.readthedocs.io\"\n    if releaselevel != 'final':\n        # For pre-releases, use a version-specific URL.\n        url += \"/en/\" + _make_version(major, minor, micro, releaselevel, serial)\n    return url", "response": "Make the URL people should start at for this version of coverage. py."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of unique paths in the file list", "response": "def get_list_of_paths(self):\r\n        \"\"\"\r\n        return a list of unique paths in the file list\r\n        \"\"\"\r\n        all_paths = []\r\n        for p in self.fl_metadata:\r\n            try:\r\n                all_paths.append(p['path'])\r\n            except:\r\n                try:\r\n                    print('cls_filelist - no key path, ignoring folder ' + str(p))\r\n                except:\r\n                    print('cls_filelist - no key path, ignoring odd character folder')\r\n\r\n        return list(set(all_paths))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_file_list(self, lstPaths, lstXtn, lstExcluded, VERBOSE = False):\r\n        if VERBOSE:\r\n            print(\"Generating list of Files...\")\r\n            print(\"Paths = \", lstPaths)\r\n            print(\"Xtns  = \", lstXtn)\r\n            print(\"exclude = \", lstExcluded)\r\n        numFiles = 0\r\n        self.filelist = []\r\n        self.fl_metadata = []\r\n        for rootPath in lstPaths:\r\n            if VERBOSE:\r\n                print(rootPath)\r\n            for root, dirs, files in os.walk(rootPath):\r\n                if VERBOSE:\r\n                    print(dirs)\r\n                for basename in files:\r\n                    for xtn in lstXtn:\r\n                        if fnmatch.fnmatch(basename, xtn):\r\n                            filename = os.path.join(root, basename)\r\n                            includeThisFile = \"Y\"\r\n                            if len(lstExcluded) > 0:\r\n                                for exclude in lstExcluded:\r\n                                    if filename.find(exclude) != -1:\r\n                                        includeThisFile = \"N\"\r\n                            if includeThisFile == \"Y\":\r\n                                numFiles = numFiles + 1\r\n                                self.filelist.append(filename)\r\n                                self.add_file_metadata(filename)    # not sure why there is a 2nd list, but there is.\r\n\r\n        if VERBOSE:\r\n            print(\"Found \", numFiles, \" files\")\r\n        return self.filelist", "response": "Builds a list of files and returns as a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the file metadata to the list of files that have been added to the list of files that have been added to the list of files that have been added to the list of files that have been added to the list of files that have been added to the list of files that have been added to the list.", "response": "def add_file_metadata(self, fname):\r\n        \"\"\"\r\n        collects the files metadata - note that this will fail\r\n        with strange errors if network connection drops out to\r\n        shared folder, but it is better to stop the program\r\n        rather than do a try except otherwise you will get an\r\n        incomplete set of files.\r\n        \"\"\"\r\n\r\n        file_dict = {}\r\n        file_dict[\"fullfilename\"] = fname\r\n        try:\r\n            file_dict[\"name\"] = os.path.basename(fname)\r\n            file_dict[\"date\"] = self.GetDateAsString(fname)\r\n            file_dict[\"size\"] = os.path.getsize(fname)\r\n            file_dict[\"path\"] = os.path.dirname(fname)\r\n        except IOError:\r\n            print('Error getting metadata for file')\r\n\r\n        self.fl_metadata.append(file_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_file_details_in_line(self, fname, col_headers):\r\n        line = ''\r\n        try:\r\n            sze = os.path.getsize(fname)\r\n        except Exception as ex:\r\n            return 'no file'\r\n        for fld in col_headers:\r\n            if fld == \"fullfilename\":\r\n                line = line + fname\r\n            if fld == \"name\":\r\n                line = line + '{:<30}'.format(os.path.basename(fname)) + ' '\r\n            if fld == \"date\":\r\n                line = line + self.GetDateAsString(fname) + ' '\r\n            if fld == \"size\":\r\n                line = line + '{:,}'.format(os.path.getsize(fname)) + ' '\r\n            if fld == \"path\":\r\n                line = line + os.path.dirname(fname) + ' '\r\n        #line += '\\n'\r\n        return line", "response": "Print the details of a file in a nice format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint details of a file as a csv file", "response": "def print_file_details_as_csv(self, fname, col_headers):\r\n        \"\"\" saves as csv format \"\"\"\r\n        line = ''\r\n        qu = '\"'\r\n        d = ','\r\n        for fld in col_headers:\r\n            if fld == \"fullfilename\":\r\n                line = line + qu + fname + qu + d\r\n            if fld == \"name\":\r\n                line = line + qu + os.path.basename(fname) + qu + d\r\n            if fld == \"date\":\r\n                line = line + qu + self.GetDateAsString(fname) + qu + d\r\n            if fld == \"size\":\r\n                line = line + qu + self.get_size_as_string(fname) + qu + d\r\n            if fld == \"path\":\r\n                try:\r\n                    line = line + qu + os.path.dirname(fname) + qu + d\r\n                except IOError:\r\n                    line = line + qu + 'ERROR_PATH' + qu + d\r\n\r\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_filelist(self, opFile, opFormat, delim=',', qu='\"'):\r\n\r\n        op_folder = os.path.dirname(opFile)\r\n        if op_folder is not None:   # short filename passed\r\n            if not os.path.exists(op_folder):\r\n                os.makedirs(op_folder)\r\n\r\n\r\n        with open(opFile,'w') as fout:\r\n            fout.write(\"fullFilename\" + delim)\r\n            for colHeading in opFormat:\r\n                fout.write(colHeading + delim)\r\n            fout.write('\\n')\r\n            for f in self.filelist:\r\n                line = qu + f + qu + delim\r\n                try:\r\n                    for fld in opFormat:\r\n                        if fld == \"name\":\r\n                            line = line + qu + os.path.basename(f) + qu + delim\r\n                        if fld == \"date\":\r\n                            line = line + qu + self.GetDateAsString(f) + qu + delim\r\n                        if fld == \"size\":\r\n                            line = line + qu + str(os.path.getsize(f)) + qu + delim\r\n                        if fld == \"path\":\r\n                            line = line + qu + os.path.dirname(f) + qu + delim\r\n                except IOError:\r\n                    line += '\\n'   # no metadata\r\n                try:\r\n                    fout.write (str(line.encode('ascii', 'ignore').decode('utf-8')))\r\n                    fout.write ('\\n')\r\n                except IOError:\r\n                    #print(\"Cant print line - cls_filelist line 304\")\r\n                    pass", "response": "Saves a list of files and meta data on them to a text file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login(self, schema, username, password):\n        self.schema = schema\n        self.username = username\n        self.password = password\n        self.connection = schema", "response": "login to the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntyping a collection of genes returning the most likely gene version in the collection with it s genotype", "response": "def type(self, sequence_coverage_collection,\n             min_gene_percent_covg_threshold=99):\n        \"\"\"Types a collection of genes returning the most likely gene version\n            in the collection with it's genotype\"\"\"\n        best_versions = self.get_best_version(\n            sequence_coverage_collection.values(),\n            min_gene_percent_covg_threshold)\n        return [self.presence_typer.type(best_version)\n                for best_version in best_versions]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_all_python_programs(self):\n        self.tot_lines = 0\n        self.tot_bytes = 0\n        self.tot_files = 0\n        self.tot_loc = 0\n        self.lstPrograms = []\n        fl = mod_fl.FileList([self.fldr], ['*.py'], [\"__pycache__\", \"/venv/\", \"/venv2/\", \".git\"])\n        for fip in fl.get_list():\n            if '__init__.py' not in fip:\n                self.add(fip, 'TODO - add comment')\n                f = mod_file.TextFile(fip)\n                self.tot_lines += f.count_lines_in_file()\n                self.tot_loc += f.count_lines_of_code()\n                self.tot_bytes += f.size\n                self.tot_files += 1\n \n        print('All Python Program Statistics')\n        print('Files = ', self.tot_files, ' Bytes = ', self.tot_bytes, ' Lines = ', self.tot_lines, ' Lines of Code = ', self.tot_loc)", "response": "collects a filelist of all. py programs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef comment(self, nme, desc):\n        \n        if nme != '':\n            program_exists = False\n            for i in self.lstPrograms:\n                print(i)\n                if nme in i[0]:\n                    i[1] = desc\n                    program_exists = True\n            \n            if program_exists is False: # not there?\n                self.lstPrograms.append([nme,desc + ' - <I>FILE DOESNT EXIST</I>'])\n            \n            self.lg.record_process('adding description to - ' + nme)", "response": "Adds a comment to the existing program in the list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the list of items to AIKIF core and optionally to local file fname", "response": "def save(self, fname=''):\n        \"\"\"\n        Save the list of items to AIKIF core and optionally to local file fname\n        \"\"\"\n        if fname != '':\n            with open(fname, 'w') as f:\n                for i in self.lstPrograms:\n                    f.write(self.get_file_info_line(i, ','))\n\n        \n        # save to standard AIKIF structure\n        \n        filemap = mod_filemap.FileMap([], [])\n        #location_fileList = filemap.get_full_filename(filemap.find_type('LOCATION'), filemap.find_ontology('FILE-PROGRAM')[0])     \n        object_fileList = filemap.get_full_filename(filemap.find_type('OBJECT'), filemap.find_ontology('FILE-PROGRAM')[0])      \n        print('object_fileList = ' + object_fileList + '\\n')\n        if os.path.exists(object_fileList):\n            os.remove(object_fileList)\n        self.lstPrograms.sort()\n\n        try:\n            with open(object_fileList, 'a') as f:\n                f.write('\\n'.join([i[0] for i in self.lstPrograms]))\n        except Exception as ex:\n            print('ERROR = cant write to object_filelist ' , object_fileList, str(ex))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_file_info_line(self, fname, delim):\n        txt = ''\n        f = mod_file.File(fname[0])\n        txt += '\"' + f.fullname + '\"' + delim \n        txt += '\"' + f.name + '\"' + delim \n        txt += '\"' + f.path + '\"' + delim\n        txt += '\"' + f.GetDateAsString(f.date_modified)[2:10] + '\"' + delim\n        txt += '\"' + str(f.size) + '\"' + delim\n        return txt  + '\\n'", "response": "returns a string that contains the file info"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a string of the file info in web format", "response": "def get_file_info_web(self, fname, delim='<BR>\\n'):\n        \"\"\"\n        gathers info on a python program in list and formats as string\n        \"\"\"\n        txt = ''\n        f = mod_file.File(fname[0])\n        txt += '<sup>' + f.name + '</sup>'  + delim \n        txt += '<sup>' + fname[1] + '</sup>' + delim\n        txt += '<sub><sup><span white-space:nowrap;>' + f.GetDateAsString(f.date_modified)[2:10] + '</span></sup></sub>' + delim\n        txt += '<sup><sup>' + str(f.size) + '</sup></sup>' + delim\n        return txt  + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects the details on the program size date list of functions generates a Markdown file for documentation", "response": "def collect_program_info(self, fname):\n        \"\"\"\n        gets details on the program, size, date, list of functions\n        and produces a Markdown file for documentation\n        \"\"\"\n        md = '#AIKIF Technical details\\n'\n        md += 'Autogenerated list of programs with comments and progress\\n'\n        md += '\\nFilename | Comment | Date | Size\\n'\n        md += '--- | --- | --- | ---\\n'\n        for i in self.lstPrograms:\n            md += self.get_file_info_line(i, ' | ')\n        \n        # save the details an Markdown file \n        with open(fname, 'w') as f:\n            f.write(md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DAVIDenrich(database, categories, user, ids, ids_bg = None, name = '', name_bg = '', verbose = False, p = 0.1, n = 2):\n    # Modified from https://david.ncifcrf.gov/content.jsp?file=WS.html\n    # by courtesy of HuangYi @ 20110424\n\n    \"\"\"\n    Queries the DAVID database for an enrichment analysis\n    Check https://david.ncifcrf.gov/content.jsp?file=DAVID_API.html for database == \"type\" tag and categories ==  \"annot\" tag.\n\n    :param database: A string for the database to query, e.g. 'WORMBASE_GENE_ID'\n    :param categories: A comma separated string with databases\n    :param user: A user ID registered at DAVID for querying\n    :param ids: A list with identifiers\n    :param name: A string with the name for the query set\n    :param ids_bg: A list with the background identifiers to enrich against,\n      'None' for whole set\n    :param name_bg: A string with the name for the background set\n    :param p: Maximum p value for enrichment of a term\n    :param n: Minimum number of genes within a term\n\n    :returns: None if no ids match the queried database, or a pandas data frame with results\n    \"\"\"\n    print('now')\n    ids = ','.join([str(i) for i in ids])\n    use_bg = 0\n    if ids_bg is not None:\n      ids_bg = ','.join([str(i) for i in ids_bg])\n    ssl._create_default_https_context = ssl._create_unverified_context\n    url = 'https://david.ncifcrf.gov/webservice/services/DAVIDWebService?wsdl'\n    client = sudsclient(url)\n    client.wsdl.services[0].setlocation('https://david.ncifcrf.gov/webservice/services/DAVIDWebService.DAVIDWebServiceHttpSoap11Endpoint/')\n    client_auth = client.service.authenticate(user)\n    if verbose:\n      print('User Authentication:', client_auth)\n      sys.stdout.flush()\n    size = client.service.addList(ids, database, name, 0) #| inputListIds,idType,listName,listType)\n    if verbose:\n      print('Mapping rate of ids: ', str(size))\n      sys.stdout.flush()\n    if not float(size) > float(0):\n      return None\n    if ids_bg is not None:\n      size_bg = client.service.addList(ids_bg, database, name_bg, 1)\n      if verbose:\n        print('Mapping rate of background ids: ', str(size_bg))\n        sys.stdout.flush()\n    client_categories = client.service.setCategories(categories)\n    if verbose:\n      print('Categories used: ', client_categories)\n      sys.stdout.flush()\n    client_report = client.service.getChartReport(p, n)\n    size_report = len(client_report)\n    if verbose:\n      print('Records reported: ', str(size_report))\n      sys.stdout.flush()\n\n    if size_report > 0:\n        df = []\n        for r in client_report:\n            d = dict(r)\n            line = []\n            for f in david_fields:\n                line.append(str(d[f]).encode('ascii','ignore'))\n            df.append(line)\n        df = pd.DataFrame(df)\n        df.columns=david_fields\n        for col in david_fields:\n            df[col] = df[col].apply(lambda x: x.decode())\n    else:\n        df=None\n\n    return df", "response": "Query the DAVID database for an enrichment analysis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a DAVIDenrich output it converts ensembl gene ids to genes names and adds this column to the output", "response": "def id_nameDAVID(df,GTF=None,name_id=None):\n    \"\"\"\n    Given a DAVIDenrich output it converts ensembl gene ids to genes names and adds this column to the output\n\n    :param df: a dataframe output from DAVIDenrich\n    :param GTF: a GTF dataframe from readGTF()\n    :param name_id: instead of a gtf dataframe a dataframe with the columns 'gene_name' and 'gene_id' can be given as input\n\n    :returns: a pandas dataframe with a gene name column added to it.\n    \"\"\"\n    if name_id is None:\n        gene_name=retrieve_GTF_field('gene_name',GTF)\n        gene_id=retrieve_GTF_field('gene_id', GTF)\n        GTF=pd.concat([gene_name,gene_id],axis=1)\n    else:\n        GTF=name_id.copy()\n    df['Gene_names']=\"genes\"\n    terms=df['termName'].tolist()\n    enrichN=pd.DataFrame()\n    for term in terms:\n        tmp=df[df['termName']==term]\n        tmp=tmp.reset_index(drop=True)\n        ids=tmp.xs(0)['geneIds']\n        ids=pd.DataFrame(data=ids.split(\", \"))\n        ids.columns=['geneIds']\n        ids['geneIds']=ids['geneIds'].map(str.lower)\n        GTF['gene_id']=GTF['gene_id'].astype(str)\n        GTF['gene_id']=GTF['gene_id'].map(str.lower)\n        ids=pd.merge(ids, GTF, how='left', left_on='geneIds', right_on='gene_id')\n        names=ids['gene_name'].tolist()\n        names= ', '.join(names)\n        tmp[\"Gene_names\"]=names\n        #tmp=tmp.replace(to_replace=tmp.xs(0)['Gene_names'], value=names)\n        enrichN=pd.concat([enrichN, tmp])\n    enrichN=enrichN.reset_index(drop=True)\n\n    gene_names=enrichN[['Gene_names']]\n    gpos=enrichN.columns.get_loc(\"geneIds\")\n    enrichN=enrichN.drop(['Gene_names'],axis=1)\n    cols=enrichN.columns.tolist()\n    enrichN=pd.concat([enrichN[cols[:gpos+1]],gene_names,enrichN[cols[gpos+1:]]],axis=1)\n\n    return enrichN"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of gene names for given gene ids.", "response": "def DAVIDgetGeneAttribute(x,df,refCol=\"ensembl_gene_id\",fieldTOretrieve=\"gene_name\"):\n    \"\"\"\n    Returns a list of gene names for given gene ids.\n\n    :param x: a string with the list of IDs separated by ', '\n    :param df: a dataframe with the reference column and a the column to retrieve\n    :param refCol: the header of the column containing the identifiers\n    :param fieldTOretrieve: the field to retrieve from parsedGTF eg. 'gene_name'\n\n    :returns: list of fieldTOretrieve separeted by ', ' in the same order as the given in x\n    \"\"\"\n    \n    l=x.split(\", \")\n    l=[ s.upper() for s in l ]\n    tmpdf=pd.DataFrame({refCol:l},index=range(len(l)))\n    df_fix=df[[refCol,fieldTOretrieve]].drop_duplicates()\n    df_fix[refCol]=df_fix[refCol].apply(lambda x: x.upper())\n    ids=pd.merge(tmpdf,df_fix,how=\"left\",on=[refCol])\n    ids=ids[fieldTOretrieve].tolist()\n    ids=[ str(s) for s in ids ]\n    ids=\", \".join(ids)\n    return ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DAVIDplot(database, categories, user, df_ids, output, df_ids_bg = None, name = '', \\\n    name_bg = '', verbose = False, p = 0.1, n = 2):\n    \"\"\"\n    Queries the DAVID database for an enrichment analysis and plots CellPlots as\n    well as SymPlots (see plots).\n    Check https://david.ncifcrf.gov/content.jsp?file=DAVID_API.html for database == \"type\" tag and categories ==  \"annot\" tag.\n\n    :param database: a string for the database to query, e.g. 'WORMBASE_GENE_ID'\n    :param categories: a comma separated string with databases\n    :param user: a user ID registered at DAVID for querying\n    :param df_ids: a dataframe where the first column contains the identifiers\n        to be queried and the second column the respective log2fc for each identifier.\n    :param output: /path/to/output/prefix\n    :param df_ids_bg: a dataframe where the first column contains the identifiers\n        to be used as background. None for whole set.\n    :param name: a string with the name for the query set\n    :param name_bg: a string with the name for the background set\n    :param p: Maximum p value for enrichment of a term\n    :param n: Minimum number of genes within a term\n\n    :returns: Nothing\n    \"\"\"\n\n    idsc1=df_ids.columns.tolist()[0]\n    idsc2=df_ids.columns.tolist()[1]\n\n    ids=df_ids[idsc1].tolist()\n    if type(df_ids_bg)==type(pd.DataFrame()):\n        ids_bg=df_ids_bg[df_ids_bg.columns.tolist()[0]]\n    else:\n        ids_bg=None\n    \n    print(categories)\n    \n    david=DAVIDenrich(database, categories, user, ids, ids_bg = ids_bg, \\\n    name = name, name_bg = name_bg, verbose = verbose, p = p, n = n)\n\n    print(list(set(david[\"categoryName\"].tolist())))\n    if type(david)!=type(pd.DataFrame()):\n        print(\"For this dataset no enrichments could be returned.\")\n        sys.stdout.flush()\n    else:\n        david[idsc2]=david[\"geneIds\"].apply(lambda x: \\\n                          DAVIDgetGeneAttribute(x,\\\n                          df_ids,\\\n                          refCol=idsc1,\\\n                          fieldTOretrieve=idsc2))\n        david[idsc2]=david[idsc2].apply(lambda x: x.replace(\", \", \",\"))\n        EXC=pd.ExcelWriter(output+\".xlsx\")\n        for category in list(set(david[\"categoryName\"].tolist())):\n            david_=david[david[\"categoryName\"]==category]\n            print(category)\n            david_.to_excel(EXC,category)\n\n            tmp=david_[:20]\n            tmp[\"Enrichment\"]=tmp[\"foldEnrichment\"]\n            tmp[\"Term\"]=tmp['termName']\n            tmp[\"Annotated\"]=tmp[\"listHits\"]\n            cellplot=CellPlot(tmp, output_file=output+\".\"+category, gene_expression=idsc2, \\\n            figure_title=category+\"\\n\"+output.split(\"/\")[-1], pvalCol=\"ease\", \\\n            lowerLimit=None, upperLimit=None, colorBarType='bwr')\n\n            symplot=SymPlot(tmp, output_file=output+\".\"+category, \\\n            figure_title=category+\"\\n\"+output.split(\"/\")[-1], \\\n            pvalCol=\"ease\")\n        EXC.save()", "response": "Queries the DAVID database for an enrichment analysis and plots CellPlots as CellPlots"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_configuration(self):\n        filename = os.path.join(os.path.dirname(__file__), 'templates/spline-loc.yml.j2')\n        with open(filename) as handle:\n            return Adapter(safe_load(handle)).configuration", "response": "Loads the configuration from the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies whether to ignore a path.", "response": "def ignore_path(path):\n        \"\"\"\n        Verify whether to ignore a path.\n\n        Args:\n            path (str): path to check.\n\n        Returns:\n            bool: True when to ignore given path.\n        \"\"\"\n        ignore = False\n        for name in ['.tox', 'dist', 'build', 'node_modules', 'htmlcov']:\n            if path.find(name) >= 0:\n                ignore = True\n                break\n        return ignore"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk_files_for(paths, supported_extensions):\n        for path in paths:\n            for root, _, files in os.walk(path):\n                if Application.ignore_path(root.replace(path, '')):\n                    continue\n\n                for filename in files:\n                    extension = os.path.splitext(filename)[1]\n                    if extension in supported_extensions:\n                        yield path, os.path.join(root, filename), extension", "response": "Yields each full path and filename found for given extensions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nanalyse the file and return loc and com for given file.", "response": "def analyse(self, path_and_filename, pattern):\n        \"\"\"\n        Find out lines of code and lines of comments.\n\n        Args:\n            path_and_filename (str): path and filename to parse  for loc and com.\n            pattern (str): regex to search for line commens and block comments\n\n        Returns:\n            int, int: loc and com for given file.\n        \"\"\"\n        with open(path_and_filename) as handle:\n            content = handle.read()\n            loc = content.count('\\n') + 1\n            com = 0\n            for match in re.findall(pattern, content, re.DOTALL):\n                com += match.count('\\n') + 1\n\n            return max(0, loc - com), com"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef datasetsBM(host=biomart_host):\n    stdout_ = sys.stdout #Keep track of the previous value.\n    stream = StringIO()\n    sys.stdout = stream   \n    server = BiomartServer(biomart_host)\n    server.show_datasets()\n    sys.stdout = stdout_ # restore the previous stdout.\n    variable = stream.getvalue() \n    v=variable.replace(\"{\",\" \") \n    v=v.replace(\"}\",\" \") \n    v=v.replace(\": \",\"\\t\")\n    print(v)", "response": "Lists BioMart datasets.\n\n    :param host: address of the host server, default='http://www.ensembl.org/biomart'\n\n    :returns: nothing"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists BioMart filters for a specific dataset.", "response": "def filtersBM(dataset,host=biomart_host):\n    \"\"\"\n    Lists BioMart filters for a specific dataset.\n\n    :param dataset: dataset to list filters of.\n    :param host: address of the host server, default='http://www.ensembl.org/biomart'\n\n    :returns: nothing\n\n    \"\"\"\n    stdout_ = sys.stdout #Keep track of the previous value.\n    stream = StringIO()\n    sys.stdout = stream   \n    server = BiomartServer(host)\n    d=server.datasets[dataset]\n    d.show_filters()\n    sys.stdout = stdout_ # restore the previous stdout.\n    variable = stream.getvalue() \n    v=variable.replace(\"{\",\" \") \n    v=v.replace(\"}\",\" \") \n    v=v.replace(\": \",\"\\t\")\n    print(v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef queryBM(query_attributes,query_dataset,query_filter=None,query_items=None,query_dic=None,host=biomart_host):\n    server = BiomartServer(host)\n    d=server.datasets[query_dataset]\n    res=[]\n\n    if not query_dic:\n        if query_items:\n            chunks=[query_items[x:x+350] for x in xrange(0, len(query_items), 350)]\n            for c in chunks:\n                response=d.search({'filters':{query_filter:c},'attributes':query_attributes})\n                for line in response.iter_lines():\n                    line = line.decode('utf-8')\n                    res.append(line.split(\"\\t\"))\n        else:\n            response=d.search({'attributes':query_attributes})\n            for line in response.iter_lines():\n                line = line.decode('utf-8')\n                res.append(line.split(\"\\t\"))\n    \n    elif query_dic:\n        response=d.search({'filters':query_dic,'attributes':query_attributes})\n        for line in response.iter_lines():\n            line = line.decode('utf-8')\n            res.append(line.split(\"\\t\"))\n    res=pd.DataFrame(res)\n    res.columns=query_attributes\n    return(res)", "response": "Queries BioMart.\n\n    :param query_attributes: list of attributes to recover from BioMart\n    :param query_dataset: dataset to query\n    :param query_filter: one BioMart filter associated with the items being queried\n    :param query_items: list of items to be queried (must assoiate with given filter)\n    :param query_dic: for complex queries this option should be used instead of 'filters' and 'items' and a dictionary of filters provided here eg. querydic={\"filter1\":[\"item1\",\"item2\"],\"filter2\":[\"item3\",\"item4\"]}. If using querydic, don't query more than 350 items at once.\n    :param host: address of the host server, default='http://www.ensembl.org/biomart'\n\n    :returns: a Pandas dataframe of the queried attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FilterGOstring(names_filter=[\"age-\", \"aging\", \"aged\", 'aging', 'aging.', 'aging,'],\\\n                   exclude_names=[\"packaging\",\"voltage\",\"cleavage-\",\\\n                       \"stage-1\",\"cage-like\",\"message-specific\",\\\n                       \"damage-associated\",\"stage-specific\",\"foraging\",\\\n                       \"DNA-damaging\",\"engaging\",\"damaged\",\"packaged\"],\\\n                   defs_filter=[\" age-\", \" aging\", \" aged\", ' aging', ' aging.', ' aging,'],\\\n                   exclude_defs=[\"packaging\",\"voltage\",\"cleavage-\",\\\n                         \"stage-1\",\"cage-like\",\"message-specific\",\\\n                         \"damage-associated\",\"stage-specific\",\"foraging\",\\\n                         \"DNA-damaging\",\"engaging\",\"damaged\",\"packaged\"],\\\n                   host=biomart_host,\\\n                   HSA=None,MUS=None,CEL=None,DMEL=None):\n    \n    \"\"\"\n    Filters GO terms based on given strings using ENSEMBL's biomart homology mapping.\n    \n    :param names_filter: list of substrings to filter GO names on\n    :param exclude_names: list of substrings to be used for exclusion of GO names\n    :param defs_filter: list of substrings to filter GO defenitions on\n    :param exclude_defs: list of substrings to be used for exclustion of GO defenitions\n    :param host: biomart host server, default=\"http://www.ensembl.org/biomart\"\n    :param HSA: retrieved hsa dataframe\n    :param MUS: retrieved mus dataframe\n    :param CEL: retrieved cel dataframe\n    :param DMEL: retrieved dmel dataframe\n    \n    :returns homology_df, HSA, MUS, CEL, DMEL   \n \n    \n    \"\"\"\n    \n    if type(HSA) == type(None):\n        queries={'hsapiens_gene_ensembl':[\"ensembl_gene_id\",\"external_gene_name\", \\\n                                          \"go_id\",\"name_1006\",\"definition_1006\"],\\\n                 \"mmusculus_gene_ensembl\":[\"ensembl_gene_id\",\"external_gene_name\", \\\n                                           \"go_id\",\"name_1006\",\"definition_1006\"],\\\n                 \"celegans_gene_ensembl\":[\"ensembl_gene_id\",\"external_gene_name\", \\\n                                          \"go_id\",\"name_1006\",\"definition_1006\"],\\\n                 \"dmelanogaster_gene_ensembl\":[\"ensembl_gene_id\",\"external_gene_name\", \\\n                                               \"go_id\",\"name_1006\",\"definition_1006\"]}\n\n        def QueryBioMart(dataset,attributes,host=host):\n            #print dataset\n            #sys.stdout.flush()\n            server = BiomartServer( host )\n            organism=server.datasets[dataset]\n            response=organism.search({'attributes':attributes})\n            response=response.content\n            response=response.decode()\n            response=response.split(\"\\n\")\n            response=[s.split(\"\\t\") for s in response ]\n            response=pd.DataFrame(response,columns=attributes)\n            return response\n\n        homology=[ \"ensembl_gene_id\",\"celegans_homolog_ensembl_gene\",\"dmelanogaster_homolog_ensembl_gene\",\"mmusculus_homolog_ensembl_gene\"]\n        hsa_homology=QueryBioMart('hsapiens_gene_ensembl',homology)\n\n        HSA=QueryBioMart('hsapiens_gene_ensembl',queries['hsapiens_gene_ensembl'])\n        MUS=QueryBioMart('mmusculus_gene_ensembl',queries['mmusculus_gene_ensembl'])\n        CEL=QueryBioMart('celegans_gene_ensembl',queries['celegans_gene_ensembl'])\n        DMEL=QueryBioMart('dmelanogaster_gene_ensembl',queries['dmelanogaster_gene_ensembl'])    \n\n        HSA=pd.merge(HSA,hsa_homology,on=[\"ensembl_gene_id\"],how=\"outer\")\n        HSA.columns=['HSA_ensembl_gene_id', 'HSA_external_gene_name','HSA_go_id', 'HSA_name_1006', 'HSA_definition_1006',\\\n                     'CEL_ensembl_gene_id', 'DMEL_ensembl_gene_id', 'MUS_ensembl_gene_id']\n        MUS.columns=['MUS_ensembl_gene_id','MUS_external_gene_name',\"MUS_go_id\",'MUS_name_1006','MUS_definition_1006']\n        CEL.columns=['CEL_ensembl_gene_id','CEL_external_gene_name',\"CEL_go_id\",'CEL_name_1006','CEL_definition_1006']\n        DMEL.columns=['DMEL_ensembl_gene_id','DMEL_external_gene_name',\"DMEL_go_id\",'DMEL_name_1006','DMEL_definition_1006']\n        \n    HSA_gos=HSA[['HSA_go_id','HSA_name_1006','HSA_definition_1006']]\n    MUS_gos=MUS[['MUS_go_id','MUS_name_1006','MUS_definition_1006']]\n    CEL_gos=CEL[['CEL_go_id','CEL_name_1006','CEL_definition_1006']]\n    DMEL_gos=DMEL[['DMEL_go_id','DMEL_name_1006','DMEL_definition_1006']]\n\n    GOS=pd.DataFrame()\n    for tmp in [ HSA_gos, MUS_gos, CEL_gos, DMEL_gos]:\n        tmp.columns=['go_id','name_1006','definition_1006']\n        GOS=pd.concat([GOS,tmp])\n    GOS=GOS.drop_duplicates()\n    GOS=GOS.dropna()\n    GOS.reset_index(inplace=True, drop=True)\n\n    names=GOS[\"name_1006\"].tolist()\n    defs=GOS[\"definition_1006\"].tolist()\n\n    filtered_names=[]\n    for age in names_filter:\n        tmp=list(set( [ s for s in names if age in s ] ))\n        exclude=exclude_names\n        for e in exclude:\n            tmp=[ s for s in tmp if e not in s ]\n        filtered_names.append(tmp)   \n\n    filtered_defs=[]\n    for age in defs_filter:\n        tmp=list(set( [ s for s in defs if age in s ] ))\n        exclude=exclude_defs\n        for e in exclude:\n            tmp=[ s for s in tmp if e not in s ]\n        filtered_defs.append(tmp)\n\n    # def checkStrings(filtered_names,names_filter):\n    #     print_names=\" \".join(filtered_names)\n    #     print_names=print_names.split(\" \")\n    #     print_names_=[]\n    #     for age in names_filter:\n    #         tmp=[s for s in print_names if age in s ]\n    #         print_names_.append(tmp)\n    #     print_names_=[item for sublist in print_names_ for item in sublist]\n    #     print_names_=list(set(print_names_))\n    #     return print_names_\n\n    filtered_names = [item for sublist in filtered_names for item in sublist]\n    filtered_defs = [item for sublist in filtered_defs for item in sublist]\n\n    # names_=checkStrings(filtered_names,names_filter)\n    # defs_=checkStrings(filtered_defs,defs_filter)\n\n    print(\"\\nStrings being used for filtering in names section:\")\n    for f in filtered_names:\n        print(f)\n\n    print(\"\\nStrings being used for filtering in defenitions section:\")\n    for f in filtered_defs:\n        print(\"\\n\"+f)\n\n    def CHECK_AGE(x,l):\n        if x in l:\n            res=x\n        else:\n            res=np.nan\n        return res\n\n    GOS[\"names_filter\"]=GOS[\"name_1006\"].apply(lambda x: CHECK_AGE(x,filtered_names) )\n    GOS[\"defs_filter\"]=GOS[\"definition_1006\"].apply(lambda x: CHECK_AGE(x,filtered_defs) )\n    AGEGOS=GOS[['go_id',\"names_filter\",\"defs_filter\"]].dropna(thresh=2)\n    AGEGOS=list(set(AGEGOS[\"go_id\"].tolist()))\n\n    def CombineAnnHSA(df):\n         return pd.Series(dict(HSA_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['HSA_ensembl_gene_id']))  if str(s) != \"nan\" ] ) ,\\\n                               HSA_go_id = ', '.join([ str(s) for s in list(set(df['HSA_go_id'])) if str(s) != \"nan\" ]), \\\n                               HSA_external_gene_name = ', '.join([ str(s) for s in list(set(df['HSA_external_gene_name'])) if str(s) != \"nan\" ] ) ,\\\n                               HSA_name_1006 = ', '.join([ str(s) for s in list(set(df['HSA_name_1006'])) if str(s) != \"nan\" ] ) ,\\\n                               HSA_definition_1006 = ', '.join([ str(s) for s in list(set(df['HSA_definition_1006'])) if str(s) != \"nan\" ] ) ,\\\n                               CEL_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['CEL_ensembl_gene_id'])) if str(s) != \"nan\" ] ) ,\\\n                               DMEL_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['DMEL_ensembl_gene_id'])) if str(s) != \"nan\"] ) ,\\\n                               MUS_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['MUS_ensembl_gene_id'])) if str(s) != \"nan\" ] ) ,\\\n                              ) ) \n\n    def CombineAnnMUS(df):\n         return pd.Series(dict(MUS_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['MUS_ensembl_gene_id']))  if str(s) != \"nan\" ] ) ,\\\n                               MUS_external_gene_name = ', '.join([ str(s) for s in list(set(df['MUS_external_gene_name'])) if str(s) != \"nan\" ]), \\\n                               MUS_go_id = ', '.join([ str(s) for s in list(set(df['MUS_go_id'])) if str(s) != \"nan\" ] ) ,\\\n                               MUS_name_1006 = ', '.join([ str(s) for s in list(set(df['MUS_name_1006'])) if str(s) != \"nan\" ] ) ,\\\n                               MUS_definition_1006 = ', '.join([ str(s) for s in list(set(df['MUS_definition_1006'])) if str(s) != \"nan\" ] ) ,\\\n                              ) ) \n\n    def CombineAnnCEL(df):\n         return pd.Series(dict(CEL_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['CEL_ensembl_gene_id']))  if str(s) != \"nan\" ] ) ,\\\n                               CEL_external_gene_name = ', '.join([ str(s) for s in list(set(df['CEL_external_gene_name'])) if str(s) != \"nan\" ]), \\\n                               CEL_go_id = ', '.join([ str(s) for s in list(set(df['CEL_go_id'])) if str(s) != \"nan\" ] ) ,\\\n                               CEL_name_1006 = ', '.join([ str(s) for s in list(set(df['CEL_name_1006'])) if str(s) != \"nan\" ] ) ,\\\n                               CEL_definition_1006 = ', '.join([ str(s) for s in list(set(df['CEL_definition_1006'])) if str(s) != \"nan\" ] ) ,\\\n                              ) ) \n    def CombineAnnDMEL(df):\n         return pd.Series(dict(DMEL_ensembl_gene_id = ', '.join([ str(s) for s in list(set(df['DMEL_ensembl_gene_id']))  if str(s) != \"nan\" ] ) ,\\\n                               DMEL_external_gene_name = ', '.join([ str(s) for s in list(set(df['DMEL_external_gene_name'])) if str(s) != \"nan\" ]), \\\n                               DMEL_go_id = ', '.join([ str(s) for s in list(set(df['DMEL_go_id'])) if str(s) != \"nan\" ] ) ,\\\n                               DMEL_name_1006 = ', '.join([ str(s) for s in list(set(df['DMEL_name_1006'])) if str(s) != \"nan\" ] ) ,\\\n                               DMEL_definition_1006 = ', '.join([ str(s) for s in list(set(df['DMEL_definition_1006'])) if str(s) != \"nan\" ] ) ,\\\n                              ) )  \n\n    HSA=HSA.groupby(by=[\"HSA_ensembl_gene_id\",\"MUS_ensembl_gene_id\",\\\n                        \"DMEL_ensembl_gene_id\",\"CEL_ensembl_gene_id\"], as_index=False).apply(CombineAnnHSA)\n    MUS=MUS.groupby(by=\"MUS_ensembl_gene_id\", as_index=False).apply(CombineAnnMUS)\n    DMEL=DMEL.groupby(by=\"DMEL_ensembl_gene_id\", as_index=False).apply(CombineAnnDMEL)\n    CEL=CEL.groupby(by=\"CEL_ensembl_gene_id\", as_index=False).apply(CombineAnnCEL)\n\n    MUS.reset_index(inplace=True,drop=True)\n    HSA.reset_index(inplace=True,drop=True)\n    DMEL.reset_index(inplace=True,drop=True)\n    CEL.reset_index(inplace=True,drop=True)\n    \n    HSA=HSA[['HSA_ensembl_gene_id', 'HSA_external_gene_name', 'HSA_go_id', 'HSA_name_1006','HSA_definition_1006',\\\n             'MUS_ensembl_gene_id', 'CEL_ensembl_gene_id', 'DMEL_ensembl_gene_id']]\n    MUS=MUS[['MUS_ensembl_gene_id', 'MUS_external_gene_name', 'MUS_go_id', 'MUS_name_1006','MUS_definition_1006']]\n    CEL=CEL[['CEL_ensembl_gene_id', 'CEL_external_gene_name', 'CEL_go_id', 'CEL_name_1006','CEL_definition_1006']]\n    DMEL=DMEL[['DMEL_ensembl_gene_id', 'DMEL_external_gene_name', 'DMEL_go_id', 'DMEL_name_1006','DMEL_definition_1006']]\n\n    homDF=pd.merge(HSA,MUS,on=[\"MUS_ensembl_gene_id\"], how=\"outer\")\n    homDF=pd.merge(homDF,CEL,on=[\"CEL_ensembl_gene_id\"], how=\"outer\")\n    homDF=pd.merge(homDF,DMEL,on=[\"DMEL_ensembl_gene_id\"], how=\"outer\")\n\n    def AGE_ORG(df,AGEGOS=AGEGOS):\n        HSA_go_id=str(df[\"HSA_go_id\"]).split(\", \")\n        MUS_go_id=str(df[\"MUS_go_id\"]).split(\", \")\n        CEL_go_id=str(df[\"CEL_go_id\"]).split(\", \")\n        DMEL_go_id=str(df[\"DMEL_go_id\"]).split(\", \")\n\n        res=[]\n\n        for n,l in zip([\"HSA\",\"MUS\",\"CEL\",\"DMEL\"],\\\n                       [HSA_go_id,MUS_go_id,CEL_go_id,DMEL_go_id]):\n            r=[ s for s in l if s in AGEGOS ]\n            if len(r) > 0:\n                res.append(n)\n        if len(res) > 0:\n            res.sort()\n            res=\", \".join(res)\n        else:\n            res=np.nan\n        return res\n\n    homDF.reset_index(inplace=True, drop=True)\n    homDF[\"evidence\"]=homDF.apply(AGE_ORG, axis=1)\n\n    return homDF,HSA,MUS,CEL,DMEL", "response": "Filters GO terms based on given string using ENSEMBL s homology mapping."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the CSV representation of the object", "response": "def format_csv(self, delim=',', qu='\"'):\n        \"\"\"\n        Prepares the data in CSV format\n        \"\"\"\n        res = qu + self.name + qu + delim\n        if self.data:\n            for d in self.data:\n                res += qu + str(d) + qu + delim\n        return res + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_dict(self, delim=':', qu=\"'\"):\n        res = 'name' + delim + qu + self.name + qu + ','\n        for num, d in enumerate(self.data):\n            res += 'col' + str(num) + delim + qu + str(d) + qu + ','\n        return res", "response": "Returns a dictionary with the keys name and data as strings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a trace of all the children of the object", "response": "def format_all(self):\n        \"\"\"\n        return a trace of parents and children of the obect\n        \"\"\"\n        res = '\\n--- Format all : ' + str(self.name) + ' -------------\\n'\n        res += ' parent = ' + str(self.parent) + '\\n'\n        res += self._get_all_children()    \n        res += self._get_links()\n            \n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all children of a node", "response": "def _get_all_children(self,):\n        \"\"\" \n        return the list of children of a node\n        \"\"\"\n        res = ''\n        if self.child_nodes:\n            for c in self.child_nodes:\n                res += ' child = ' + str(c) + '\\n'\n                if c.child_nodes:\n                    for grandchild in c.child_nodes:\n                        res += '   child = ' + str(grandchild) + '\\n'\n        else:\n            res += ' child = None\\n'\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_links(self,):\n        res = ''\n        if self.links:\n            for l in self.links:\n                res += ' links = ' + str(l[0]) + '\\n'\n                if l[0].child_nodes:\n                    for chld in l[0].child_nodes:\n                        res += '   child = ' + str(chld) + '\\n'\n                if l[0].links:\n                    for lnk in l[0].links:\n                        res += '   sublink = ' + str(lnk[0]) + '\\n'\n        else:\n            res += ' links = None\\n'\n            \n        return res", "response": "get the list of links of a node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncontract the current node to its parent and returns the parent and the parent data", "response": "def contract(self, process):\n        \"\"\"\n        this contracts the current node to its parent and \n        then either caclulates the params and values if all \n        child data exists, OR uses the default parent data.\n        (In real terms it returns the parent and recalculates)\n        TODO = processes need to be recalculated\n        \"\"\"\n        print('TODO: process check = ', process)\n        print(self.name, ' contracted to ->', self.parent)\n        return self.parent"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_child_by_name(self, name):\n        for c in self.child_nodes:\n            if c.name == name:\n                return c\n        return None", "response": "find the child object by name and return the object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a link from this thing to other thing using type tpe.", "response": "def links_to(self, other, tpe):\n        \"\"\"\n        adds a link from this thing to other thing\n        using type (is_a, has_a, uses, contains, part_of)\n        \"\"\"\n        if self.check_type(tpe):\n            self.links.append([other, tpe])\n        else:\n            raise Exception('aikif.core_data cannot process this object type')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_filename(self, year):\n        res = self.fldr + os.sep + self.type + year + '.' + self.user \n        return res", "response": "returns the filename of the record"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, file_tag='2016', add_header='N'):\n        fname = self.get_filename(file_tag)\n        with open(fname, 'a') as f:\n            if add_header == 'Y':\n                f.write(self.format_hdr())\n                \n            for e in self.table: \n                    f.write(e.format_csv())", "response": "save the table to file in appropriate files"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the header of the log entry in CSV format", "response": "def format_hdr(self, delim=',', qu='\"'):\n        \"\"\"\n        Prepares the header in CSV format\n        \"\"\"\n        res = ''\n        if self.header:\n            for d in self.header:\n                res += qu + str(d) + qu + delim\n        return res + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates diary files from core tables", "response": "def generate_diary(self):\n        \"\"\"\n        extracts event information from core tables into diary files\n        \"\"\"\n        print('Generate diary files from Event rows only')\n        for r in self.table:\n            print(str(type(r)) + ' = ', r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef type(self, variant_probe_coverages, variant=None):\n        if not isinstance(variant_probe_coverages, list):\n            variant_probe_coverages = [variant_probe_coverages]\n        calls = []\n        for variant_probe_coverage in variant_probe_coverages:\n            calls.append(\n                self._type_variant_probe_coverages(\n                    variant_probe_coverage, variant))\n        hom_alt_calls = [c for c in calls if sum(c[\"genotype\"]) > 1]\n        het_calls = [c for c in calls if sum(c[\"genotype\"]) == 1]\n        if hom_alt_calls:\n            hom_alt_calls.sort(key=lambda x: x[\"info\"][\"conf\"], reverse=True)\n            return hom_alt_calls[0]\n        elif het_calls:\n            het_calls.sort(key=lambda x: x[\"info\"][\"conf\"], reverse=True)\n            return het_calls[0]\n        else:\n            calls.sort(key=lambda x: x[\"info\"][\"conf\"], reverse=True)\n            return calls[0]", "response": "Takes a list of VariantProbeCoverages and returns a Call for the Variant."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions that performs one step of the Game of Life", "response": "def update_gol(self):\n        \"\"\"\n        Function that performs one step of the Game of Life\n        \"\"\"\n        \n        updated_grid = [[self.update_cell(row, col) \\\n                            for col in range(self.get_grid_width())] \\\n                            for row in range(self.get_grid_height())]\n        \n        self.replace_grid(updated_grid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_cell(self, row, col):\n        # compute number of living neighbors\n        neighbors = self.eight_neighbors(row, col)\n        living_neighbors = 0\n        for neighbor in neighbors:\n            if not self.is_empty(neighbor[0], neighbor[1]):\n                living_neighbors += 1\n            \n        # logic for Game of life        \n        if (living_neighbors == 3) or (living_neighbors == 2 and not self.is_empty(row, col)):\n            return mod_grid.FULL\n        else:\n            return mod_grid.EMPTY", "response": "Function that computes the update for one cell in the Game of LifeCOOKIE."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bitmap_pattern_to_list(self, bmp_pat):\n        res = []\n        x = 1\n        y = 1\n        lines = bmp_pat.split('\\n')\n        for line in lines:\n            y += 1\n            for char in line:\n                x += 1\n                if char == 'X':\n                    res.append([y,x])\n        return res", "response": "Takes a list of bitmap points and converts to a list of full coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_offset(self, lst):\n        res = []\n        x = random.randint(4,self.max_x - 42)\n        y = random.randint(4,self.max_y - 10)\n        for itm in lst:\n            res.append([itm[0] + y, itm[1] + x])\n        return res", "response": "offsets a pattern list generated below to a random integer position in the grid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_histogram(cls, histogram, bin_edges, axis_names=None):\n        if len(bin_edges) != len(histogram) + 1:\n            raise ValueError(\"Bin edges must be of length %d, you gave %d!\" % (len(histogram) + 1, len(bin_edges)))\n        self = cls(bins=bin_edges)\n        self.histogram = np.array(histogram)\n        return self", "response": "Make a Hist1D from a numpy array bin_edges + histogram pair\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef density(self):\n        h = self.histogram.astype(np.float)\n        bindifs = np.array(np.diff(self.bin_edges), float)\n        return h / (bindifs * self.n)", "response": "Gives emprical PDF like np. histogram (... density = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_random(self, size=10):\n        bin_i = np.random.choice(np.arange(len(self.bin_centers)), size=size, p=self.normalized_histogram)\n        return self.bin_centers[bin_i] + np.random.uniform(-0.5, 0.5, size=size) * self.bin_volumes()[bin_i]", "response": "Returns random variates from the histogram."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef std(self, bessel_correction=True):\n        if bessel_correction:\n            n = self.n\n            bc = n / (n - 1)\n        else:\n            bc = 1\n        return np.sqrt(np.average((self.bin_centers - self.mean) ** 2, weights=self.histogram)) * bc", "response": "Estimates std of underlying data assuming each datapoint was exactly in the center of its bin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting the histogram with Poisson error bars.", "response": "def plot(self, normed=False, scale_errors_by=1.0, scale_histogram_by=1.0, plt=plt, errors=False, **kwargs):\n        \"\"\"Plots the histogram with Poisson (sqrt(n)) error bars\n          - scale_errors_by multiplies the error bars by its argument\n          - scale_histogram_by multiplies the histogram AND the error bars by its argument\n          - plt thing to call .errorbar on (pylab, figure, axes, whatever the matplotlib guys come up with next)\n        \"\"\"\n        if not CAN_PLOT:\n            raise ValueError(\"matplotlib did not import, so can't plot your histogram...\")\n        if errors:\n            kwargs.setdefault('linestyle', 'none')\n            yerr = np.sqrt(self.histogram)\n            if normed:\n                y = self.normalized_histogram\n                yerr /= self.n\n            else:\n                y = self.histogram.astype(np.float)\n            yerr *= scale_errors_by * scale_histogram_by\n            y *= scale_histogram_by\n            plt.errorbar(self.bin_centers, y, yerr,\n                         marker='.', **kwargs)\n        else:\n            kwargs.setdefault('linestyle', 'steps-mid')\n            plt.plot(self.bin_centers, self.histogram, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn bin center nearest to a given percentile", "response": "def percentile(self, percentile):\n        \"\"\"Return bin center nearest to percentile\"\"\"\n        return self.bin_centers[np.argmin(np.abs(self.cumulative_density * 100 - percentile))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a HistdD from numpy histogram + bin edges", "response": "def from_histogram(cls, histogram, bin_edges, axis_names=None):\n        \"\"\"Make a HistdD from numpy histogram + bin edges\n        :param histogram: Initial histogram\n        :param bin_edges: x bin edges of histogram, y bin edges, ...\n        :return: Histnd instance\n        \"\"\"\n        bin_edges = np.array(bin_edges)\n        self = cls(bins=bin_edges, axis_names=axis_names)\n        self.histogram = histogram\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert data to histogram array", "response": "def _data_to_hist(self, data, **kwargs):\n        \"\"\"Return bin_edges, histogram array\"\"\"\n        if hasattr(self, 'bin_edges'):\n            kwargs.setdefault('bins', self.bin_edges)\n\n        if len(data) == 1 and isinstance(data[0], COLUMNAR_DATA_SOURCES):\n            data = data[0]\n\n            if self.axis_names is None:\n                raise ValueError(\"When histogramming from a columnar data source, \"\n                                 \"axis_names or dimensions is mandatory\")\n            is_dask = False\n            if WE_HAVE_DASK:\n                is_dask = isinstance(data, dask.dataframe.DataFrame)\n\n            if is_dask:\n                fake_histogram = Histdd(axis_names=self.axis_names, bins=kwargs['bins'])\n\n                partial_hists = []\n                for partition in data.to_delayed():\n                    ph = dask.delayed(Histdd)(partition, axis_names=self.axis_names, bins=kwargs['bins'])\n                    ph = dask.delayed(lambda x: x.histogram)(ph)\n                    ph = dask.array.from_delayed(ph,\n                                                 shape=fake_histogram.histogram.shape,\n                                                 dtype=fake_histogram.histogram.dtype)\n                    partial_hists.append(ph)\n                partial_hists = dask.array.stack(partial_hists, axis=0)\n\n                compute_options = kwargs.get('compute_options', {})\n                for k, v in DEFAULT_DASK_COMPUTE_KWARGS.items():\n                    compute_options.setdefault(k, v)\n                histogram = partial_hists.sum(axis=0).compute(**compute_options)\n\n                bin_edges = fake_histogram.bin_edges\n                return histogram, bin_edges\n\n            else:\n                data = np.vstack([data[x].values for x in self.axis_names])\n\n        data = np.array(data).T\n        return np.histogramdd(data,\n                              bins=kwargs.get('bins'),\n                              weights=kwargs.get('weights'),\n                              range=kwargs.get('range'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef axis_names_without(self, axis):\n        if self.axis_names is None:\n            return None\n        return itemgetter(*self.other_axes(axis))(self.axis_names)", "response": "Return axis names without axis"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bin_centers(self, axis=None):\n        if axis is None:\n            return np.array([self.bin_centers(axis=i) for i in range(self.dimensions)])\n        axis = self.get_axis_number(axis)\n        return 0.5 * (self.bin_edges[axis][1:] + self.bin_edges[axis][:-1])", "response": "Return the bin centers along an axis or list of bin_centers along each axis"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_axis_bin_index(self, value, axis):\n        axis = self.get_axis_number(axis)\n        bin_edges = self.bin_edges[axis]\n        # The right bin edge of np.histogram is inclusive:\n        if value == bin_edges[-1]:\n            # Minus two: one for bin edges rather than centers, one for 0-based indexing\n            return len(bin_edges) - 2\n        # For all other bins, it is exclusive.\n        result = np.searchsorted(bin_edges, [value], side='right')[0] - 1\n        if not 0 <= result <= len(bin_edges) - 1:\n            raise CoordinateOutOfRangeException(\"Value %s is not in range (%s-%s) of axis %s\" % (\n                value, bin_edges[0], bin_edges[-1], axis))\n        return result", "response": "Returns the index along axis of bin in histogram which contains value Inclusive on both endpoints\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn index tuple in histogram of bin which contains value", "response": "def get_bin_indices(self, values):\n        \"\"\"Returns index tuple in histogram of bin which contains value\"\"\"\n        return tuple([self.get_axis_bin_index(values[ax_i], ax_i)\n                      for ax_i in range(self.dimensions)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn ndarray of same shape as histogram containing bin center value along axis at each point", "response": "def all_axis_bin_centers(self, axis):\n        \"\"\"Return ndarray of same shape as histogram containing bin center value along axis at each point\"\"\"\n        # Arcane hack that seems to work, at least in 3d... hope\n        axis = self.get_axis_number(axis)\n        return np.meshgrid(*self.bin_centers(), indexing='ij')[axis]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sum(self, axis):\n        axis = self.get_axis_number(axis)\n        if self.dimensions == 2:\n            new_hist = Hist1d\n        else:\n            new_hist = Histdd\n        return new_hist.from_histogram(np.sum(self.histogram, axis=axis),\n                                       bin_edges=itemgetter(*self.other_axes(axis))(self.bin_edges),\n                                       axis_names=self.axis_names_without(axis))", "response": "Sums all data along axis returns d - 1 dimensional histogram"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef slice(self, start, stop=None, axis=0):\n        if stop is None:\n            # Make a 1=bin slice\n            stop = start\n        axis = self.get_axis_number(axis)\n        start_bin = max(0, self.get_axis_bin_index(start, axis))\n        stop_bin = min(len(self.bin_centers(axis)) - 1,  # TODO: test off by one!\n                       self.get_axis_bin_index(stop, axis))\n        new_bin_edges = self.bin_edges.copy()\n        new_bin_edges[axis] = new_bin_edges[axis][start_bin:stop_bin + 2]   # TODO: Test off by one here!\n        return Histdd.from_histogram(np.take(self.histogram, np.arange(start_bin, stop_bin + 1), axis=axis),\n                                     bin_edges=new_bin_edges, axis_names=self.axis_names)", "response": "Restrict histogram to bins whose data values are between start and stop. Returns d dimensional histogram."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nslice the histogram along axis then sums over that slice returning a d - 1 dimensional histogram", "response": "def slicesum(self, start, stop=None, axis=0):\n        \"\"\"Slices the histogram along axis, then sums over that slice, returning a d-1 dimensional histogram\"\"\"\n        return self.slice(start, stop, axis).sum(axis)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef projection(self, axis):\n        axis = self.get_axis_number(axis)\n        projected_hist = np.sum(self.histogram, axis=self.other_axes(axis))\n        return Hist1d.from_histogram(projected_hist, bin_edges=self.bin_edges[axis])", "response": "Sums all data along all other axes then return Hist1D"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cumulate(self, axis):\n        axis = self.get_axis_number(axis)\n        return Histdd.from_histogram(np.cumsum(self.histogram, axis=axis),\n                                     bin_edges=self.bin_edges,\n                                     axis_names=self.axis_names)", "response": "Returns new histogram with all data cumulated along axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns new histogram where all values along axis sum to 1", "response": "def normalize(self, axis):\n        \"\"\"Returns new histogram where all values along axis (in one bin of the other axes) sum to 1\"\"\"\n        axis = self.get_axis_number(axis)\n        sum_along_axis = np.sum(self.histogram, axis=axis)\n        # Don't do anything for subspaces without any entries -- this avoids nans everywhere\n        sum_along_axis[sum_along_axis == 0] = 1\n        hist = self.histogram / sum_along_axis[self._simsalabim_slice(axis)]\n        return Histdd.from_histogram(hist,\n                                     bin_edges=self.bin_edges,\n                                     axis_names=self.axis_names)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new histogram with all values replaced by their central likelihoods along axis.", "response": "def central_likelihood(self, axis):\n        \"\"\"Returns new histogram with all values replaced by their central likelihoods along axis.\"\"\"\n        result = self.cumulative_density(axis)\n        result.histogram = 1 - 2 * np.abs(result.histogram - 0.5)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef percentile(self, percentile, axis, inclusive=True):\n        axis = self.get_axis_number(axis)\n        \n        # Shape of histogram\n        s = self.histogram.shape\n\n        # Shape of histogram after axis has been collapsed to 1\n        s_collapsed = list(s)\n        s_collapsed[axis] = 1\n\n        # Shape of histogram with axis removed entirely\n        s_removed = np.concatenate([s[:axis], s[axis + 1:]]).astype(np.int)\n\n        # Using np.where here is too tricky, as it may not return a value for each \"bin-columns\"\n        # First, get an array which has a minimum at the percentile-containing bins\n        # The minimum may not be unique: if later bins are empty, they will not be \n        if inclusive:\n            ecdf = self.cumulative_density(axis).histogram\n        else:\n            density = self.normalize(axis).histogram\n            ecdf = ecdf - density\n        ecdf = np.nan_to_num(ecdf)    # Since we're relying on self-equality later\n        x = ecdf - 2 * (ecdf >= percentile / 100)\n                \n        # We now want to get the location of the minimum\n        # To ensure it is unique, add a very very very small monotonously increasing bit to x\n        # Nobody will want 1e-9th percentiles, right? TODO\n        sz = np.ones(len(s), dtype=np.int)\n        sz[axis] = -1\n        x += np.linspace(0, 1e-9, s[axis]).reshape(sz)\n        \n        # 1. Find the minimum along the axis\n        # 2. Reshape to s_collapsed and perform == to get a mask\n        # 3. Apply the mask to the bin centers along axis\n        # 4. Unflatten with reshape\n        result = self.all_axis_bin_centers(axis)[\n            x == np.min(x, axis=axis).reshape(s_collapsed)\n        ]\n        result = result.reshape(s_removed)\n\n        if self.dimensions == 2:\n            new_hist = Hist1d\n        else:\n            new_hist = Histdd\n        return new_hist.from_histogram(histogram=result,\n                                       bin_edges=itemgetter(*self.other_axes(axis))(self.bin_edges),\n                                       axis_names=self.axis_names_without(axis))", "response": "Returns d - 1 dimensional histogram containing percentile of values along the specified axis"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef average(self, axis):\n        axis = self.get_axis_number(axis)\n        avg_hist = np.ma.average(self.all_axis_bin_centers(axis),\n                                 weights=self.histogram, axis=axis)\n        if self.dimensions == 2:\n            new_hist = Hist1d\n        else:\n            new_hist = Histdd\n        return new_hist.from_histogram(histogram=avg_hist,\n                                       bin_edges=itemgetter(*self.other_axes(axis))(self.bin_edges),\n                                       axis_names=self.axis_names_without(axis))", "response": "Returns d - 1 dimensional histogram of the average value of axis\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning d - 1 dimensional histogram of the standard deviation along axis", "response": "def std(self, axis):\n        \"\"\"Returns d-1 dimensional histogram of (estimated) std value along axis\n        NB this is very different from just std of the histogram values (which describe bin counts)\n        \"\"\"\n        def weighted_std(values, weights, axis):\n            # Stolen from http://stackoverflow.com/questions/2413522\n            average = np.average(values, weights=weights, axis=axis)\n            average = average[self._simsalabim_slice(axis)]\n            variance = np.average((values-average)**2, weights=weights, axis=axis)\n            return np.sqrt(variance)\n        \n        axis = self.get_axis_number(axis)\n        std_hist = weighted_std(self.all_axis_bin_centers(axis),\n                                weights=self.histogram, axis=axis)\n        if self.dimensions == 2:\n            new_hist = Hist1d\n        else:\n            new_hist = Histdd\n        return new_hist.from_histogram(histogram=std_hist,\n                                       bin_edges=itemgetter(*self.other_axes(axis))(self.bin_edges),\n                                       axis_names=self.axis_names_without(axis))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rebin(self, *factors, **kwargs):\n        if not HAVE_SCIPY:\n            raise NotImplementedError(\"Rebinning requires scipy.ndimage\")\n        if any([x != 'order' for x in kwargs.keys()]):\n            raise ValueError(\"Only 'order' keyword argument is accepted. Yeah, this is confusing.. blame python 2.\")\n        order = kwargs.get('order', 1)\n\n        # Construct a new histogram\n        mh = self.similar_blank_histogram()\n\n        if not len(factors) == self.dimensions:\n            raise ValueError(\"You must pass %d rebin factors to rebin a %d-dimensional histogram\" % (\n                self.dimensions, self.dimensions\n            ))\n\n        # Zoom the bin edges.\n        # It's a bit tricky for non-uniform bins:\n        # we first construct a linear interpolator to take\n        # fraction along axis -> axis coordinate according to current binning.\n        # Then we feed it the new desired binning fractions.\n        for i, f in enumerate(factors):\n            x = self.bin_edges[i]\n            mh.bin_edges[i] = np.interp(\n                x=np.linspace(0, 1, (len(x) - 1) * f + 1),\n                xp=np.linspace(0, 1, len(x)),\n                fp=x)\n\n        # Rebin the histogram using ndimage.zoom, then renormalize\n        mh.histogram = zoom(self.histogram, factors, order=order)\n        mh.histogram *= self.histogram.sum() / mh.histogram.sum()\n        # mh.histogram /= np.product(factors)\n\n        return mh", "response": "Return a new histogram that is rebinned by factors along each axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random array of random variates from the histogram.", "response": "def get_random(self, size=10):\n        \"\"\"Returns (size, n_dim) array of random variates from the histogram.\n        Inside the bins, a uniform distribution is assumed\n        Note this assumes the histogram is an 'events per bin', not a pdf.\n        TODO: test more.\n        \"\"\"\n        # Sample random bin centers\n        bin_centers_ravel = np.array(np.meshgrid(*self.bin_centers(),\n                                                 indexing='ij')).reshape(self.dimensions, -1).T\n        hist_ravel = self.histogram.ravel()\n        hist_ravel = hist_ravel.astype(np.float) / np.nansum(hist_ravel)\n        result = bin_centers_ravel[np.random.choice(len(bin_centers_ravel),\n                                                    p=hist_ravel,\n                                                    size=size)]\n\n        # Randomize the position inside the bin\n        for dim_i in range(self.dimensions):\n            bin_edges = self.bin_edges[dim_i]\n            bin_widths = np.diff(bin_edges)\n\n            # Note the - 1: for the first bin's bin center, searchsorted gives 1, but we want 0 here:\n            index_of_bin = np.searchsorted(bin_edges, result[:, dim_i]) - 1\n            result[:, dim_i] += (np.random.rand(size) - 0.5) * bin_widths[index_of_bin]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lookup(self, *coordinate_arrays):\n        assert len(coordinate_arrays) == self.dimensions\n        # Convert each coordinate array to an index array\n        index_arrays = [np.clip(np.searchsorted(self.bin_edges[i], coordinate_arrays[i]) - 1,\n                                0,\n                                len(self.bin_edges[i]) - 2)\n                        for i in range(self.dimensions)]\n        # Use the index arrays to slice the histogram\n        return self.histogram[index_arrays]", "response": "Lookup values at specific points in the histogram."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lookup_hist(self, mh):\n        result = mh.similar_blank_histogram()\n        points = np.stack([mh.all_axis_bin_centers(i)\n                           for i in range(mh.dimensions)]).reshape(mh.dimensions, -1)\n        values = self.lookup(*points)\n        result.histogram = values.reshape(result.histogram.shape)\n        return result", "response": "Return a similar histogram with values looked up in this histogram."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_roadmap_doc(dat, opFile):\n    op = format_title('Roadmap for AIKIF')\n    for h1 in dat['projects']:\n        op += format_h1(h1)\n        if dat[h1] is None:\n            op += '(No details)\\n'\n        else:\n            for h2 in dat[h1]:\n                op += '\\n' + format_h2(h2)\n                if dat[h1][h2] is None:\n                    op += '(blank text)\\n'\n                else:\n                    for txt in dat[h1][h2]:\n                        op += '  - ' + txt + '\\n'\n        op += '\\n'\n\n    with open(opFile, 'w') as f:\n        f.write(op)", "response": "Creates a roadmap documentation file from a dictionary read from a yaml file and converts it to the roadmap documentation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset(self):\n        self.grid = [[0 for dummy_l in range(self.grid_width)] for dummy_l in range(self.grid_height)]", "response": "Reset the game so the grid is zeros or default items"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear the grid to be EMPTY", "response": "def clear(self):\n        \"\"\"\n        Clears grid to be EMPTY\n        \"\"\"\n        self.grid = [[EMPTY for dummy_col in range(self.grid_width)] for dummy_row in range(self.grid_height)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, fname):\n        try:\n            with open(fname, \"w\") as f:\n                f.write(str(self))\n        except Exception as ex:\n            print('ERROR = cant save grid results to ' + fname + str(ex))", "response": "save a grid to file as ASCII text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a ASCII text file grid to self", "response": "def load(self, fname):\n        \"\"\" loads a ASCII text file grid to self  \"\"\"\n        \n        # get height and width of grid from file\n        self.grid_width = 4\n        self.grid_height = 4\n        \n        # re-read the file and load it\n        self.grid = [[0 for dummy_l in range(self.grid_width)] for dummy_l in range(self.grid_height)]\n        with open(fname, 'r') as f:\n            for row_num, row in enumerate(f):\n                if row.strip('\\n') == '':\n                    break\n                for col_num, col in enumerate(row.strip('\\n')):   \n                    self.set_tile(row_num, col_num, col)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_col(self, col):\n        new_col = [row[col] for row in self.grid]\n        return new_col", "response": "extract column number col"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_row(self,  row):\n        new_row = []\n        for col in range(self.get_grid_width()):\n            new_row.append(self.get_tile(row, col))    \n        return new_row", "response": "extract row number row"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_row(self, line, ndx):\n        for col in range(len(line)):\n            self.set_tile(ndx, col, line[col])", "response": "replace a grids row at index ndx with line"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_col(self, line, ndx):\n        for row in range(len(line)):\n            self.set_tile(row, ndx, line[row])", "response": "replace a grid column at index ndx with line"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new empty area tile in a randomly selected empty area.", "response": "def new_tile(self, num=1):\n        \"\"\"\n        Create a new tile in a randomly selected empty \n        square.  The tile should be 2 90% of the time and\n        4 10% of the time.\n        \"\"\"\n        for _ in range(num):                \n            if random.random() > .5: \n                new_tile = self.pieces[0]\n            else:\n                new_tile = self.pieces[1]\n            \n            # check for game over\n            blanks = self.count_blank_positions()\n            \n            if blanks == 0:\n                print (\"GAME OVER\")\n            else:\n                res = self.find_random_blank_cell()\n                row = res[0]\n                col = res[1]\n                self.set_tile(row, col, new_tile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count_blank_positions(self):\n        blanks = 0\n        for row_ndx in range(self.grid_height - 0):\n            for col_ndx in range(self.grid_width - 0):\n                if self.get_tile(row_ndx, col_ndx) == EMPTY:\n                    blanks += 1\n        return blanks", "response": "return a count of blank cells"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a count of blank cells", "response": "def count_filled_positions(self):\n        \"\"\"\n        return a count of blank cells\n        \"\"\"\n        filled = 0\n        for row_ndx in range(self.grid_height - 0):\n            for col_ndx in range(self.grid_width - 0):\n                if self.get_tile(row_ndx, col_ndx) != EMPTY:\n                    filled += 1\n        return filled"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of the tile at position row col.", "response": "def set_tile(self, row, col, value):\n        \"\"\"\n        Set the tile at position row, col to have the given value.\n        \"\"\"   \n        #print('set_tile: y=', row, 'x=', col)\n        if col < 0:\n            print(\"ERROR - x less than zero\", col)\n            col = 0\n            #return\n            \n        if col > self.grid_width - 1 :\n            print(\"ERROR - x larger than grid\", col)\n            col = self.grid_width - 1\n            #return\n            \n        if row < 0:\n            print(\"ERROR - y less than zero\", row)\n            row = 0\n            #return\n            \n        if row > self.grid_height - 1:\n            print(\"ERROR - y larger than grid\", row)\n            row = self.grid_height - 1\n\n        self.grid[row][col] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of four neighbors of a cell.", "response": "def four_neighbors(self, row, col):\n        \"\"\"\n        Returns horiz/vert neighbors of cell (row, col)\n        \"\"\"\n        ans = []\n        if row > 0:\n            ans.append((row - 1, col))\n        if row < self.grid_height - 1:\n            ans.append((row + 1, col))\n        if col > 0:\n            ans.append((row, col - 1))\n        if col < self.grid_width - 1:\n            ans.append((row, col + 1))\n        return ans"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of eight neighbors of a cell.", "response": "def eight_neighbors(self, row, col):\n        \"\"\"\n        Returns horiz/vert neighbors of cell (row, col) as well as\n        diagonal neighbors\n        \"\"\"\n        ans = []\n        if row > 0:\n            ans.append((row - 1, col))\n        if row < self.grid_height - 1:\n            ans.append((row + 1, col))\n        if col > 0:\n            ans.append((row, col - 1))\n        if col < self.grid_width - 1:\n            ans.append((row, col + 1))\n        if (row > 0) and (col > 0):\n            ans.append((row - 1, col - 1))\n        if (row > 0) and (col < self.grid_width - 1):\n            ans.append((row - 1, col + 1))\n        if (row < self.grid_height - 1) and (col > 0):\n            ans.append((row + 1, col - 1))\n        if (row < self.grid_height - 1) and (col < self.grid_width - 1):\n            ans.append((row + 1, col + 1))\n        return ans"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_grid(self, updated_grid):\n        for col in range(self.get_grid_width()):\n            for row in range(self.get_grid_height()):\n                if updated_grid[row][col] == EMPTY:\n                    self.set_empty(row, col)\n                else:\n                    self.set_full(row, col)", "response": "replace all cells in current grid with updated grid"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a place on the grid which is clear on all sides to avoid starting in the middle of a blockage", "response": "def find_safe_starting_point(self):\n        \"\"\"\n        finds a place on the grid which is clear on all sides \n        to avoid starting in the middle of a blockage\n        \"\"\"\n        y = random.randint(2,self.grid_height-4)\n        x = random.randint(2,self.grid_width-4)\n        return y, x"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef screenshot(fname):\n    try:\n        im = ImageGrab.grab()\n        im.save(fname)\n    except Exception as ex:\n        print('image_tools.screenshot:cant create screenshot ' + str(ex))", "response": "Takes a screenshot of the users desktop"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_stats(img):\n    stat = ImageStat.Stat(img)\n    print(\"extrema    : \", stat.extrema)\n    print(\"count      : \", stat.count)\n    print(\"sum        : \", stat.sum)\n    print(\"sum2       : \", stat.sum2)\n    print(\"mean       : \", stat.mean)\n    print(\"median     : \", stat.median)\n    print(\"rms        : \", stat.rms)\n    print(\"var        : \", stat.var)\n    print(\"stddev     : \", stat.stddev)", "response": "prints stats for the given image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_all_metadata(fname):\n    print(\"Filename   :\", fname )\n    print(\"Basename   :\", os.path.basename(fname))\n    print(\"Path       :\", os.path.dirname(fname))\n    print(\"Size       :\", os.path.getsize(fname))\n    img = Image.open(fname)\n    # get the image's width and height in pixels\n    width, height = img.size\n    # get the largest dimension\n    #max_dim = max(img.size)\n    print(\"Width      :\", width)\n    print(\"Height     :\", height)\n    print(\"Format     :\", img.format)\n    print(\"palette    :\", img.palette )\n     \n    print_stats(img)\n    #print_exif_data(img)\n    exif_data = get_exif_data(img)\n    (lat, lon) = get_lat_lon(exif_data)\n    print(\"GPS Lat    :\", lat )\n    print(\"GPS Long   :\", lon )", "response": "high level that prints all metadata as long list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_metadata_as_dict(fname):\n    imgdict = {}\n    try:\n        imgdict['filename'] = fname\n        imgdict['size'] = str(os.path.getsize(fname)) \n        imgdict['basename'] = os.path.basename(fname)\n        imgdict['path'] = os.path.dirname(fname)\n        img = Image.open(fname)\n        # get the image's width and height in pixels\n        width, height = img.size\n        imgdict['width'] = str(width)\n        imgdict['height'] = str(height)\n        imgdict['format'] = str(img.format) \n        imgdict['palette'] = str(img.palette)\n        stat = ImageStat.Stat(img)\n         \n        #res = res + q + str(stat.extrema) + q + d\n        imgdict['count'] =  List2String(stat.count, \",\")\n        imgdict['sum'] =  List2String(stat.sum, \",\")\n        imgdict['sum2'] =  List2String(stat.sum2, \",\")\n        imgdict['mean'] =  List2String(stat.mean, \",\") \n        imgdict['median'] =  List2String(stat.median, \",\") \n        imgdict['rms'] =  List2String(stat.rms, \",\") \n        imgdict['var'] =  List2String(stat.var, \",\")\n        imgdict['stddev'] =  List2String(stat.stddev, \",\") \n\n        exif_data = get_exif_data(img)\n        print('exif_data = ', exif_data)\n        (lat, lon) = get_lat_lon(exif_data)\n        print('(lat, lon)', (lat, lon))\n        imgdict['lat'] =  str(lat)\n        imgdict['lon'] =  str(lon)\n    except Exception as ex:\n        print('problem reading image file metadata in ', fname, str(ex))\n        imgdict['lat'] =  'ERROR'\n        imgdict['lon'] =  'ERROR'\n    return imgdict", "response": "Gets all metadata and puts into dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all metadata and puts them into a CSV file", "response": "def get_metadata_as_csv(fname):\n    \"\"\" Gets all metadata and puts into CSV format \"\"\"\n    q = chr(34)\n    d = \",\"\n    res = q + fname + q + d\n    res = res + q + os.path.basename(fname) + q + d\n    res = res + q + os.path.dirname(fname) + q + d\n    try:\n        res = res + q + str(os.path.getsize(fname)) + q + d\n        img = Image.open(fname)\n        # get the image's width and height in pixels\n        width, height = img.size\n        res = res + q + str(width) + q + d\n        res = res + q + str(height) + q + d\n        res = res + q + str(img.format) + q + d\n        res = res + q + str(img.palette) + q + d\n        stat = ImageStat.Stat(img)\n        #print(fname, width, height) \n        #res = res + q + str(stat.extrema) + q + d\n        res = res + q + List2String(stat.count, \",\") + q + d\n        res = res + q + List2String(stat.sum, \",\") + q + d\n        res = res + q + List2String(stat.sum2, \",\") + q + d\n        res = res + q + List2String(stat.mean, \",\") + q + d\n        res = res + q + List2String(stat.median, \",\") + q + d\n        res = res + q + List2String(stat.rms, \",\") + q + d\n        res = res + q + List2String(stat.var, \",\") + q + d\n        res = res + q + List2String(stat.stddev, \",\") + q + d\n\n        exif_data = get_exif_data(img)\n        (lat, lon) = get_lat_lon(exif_data)\n        res = res + q + str(lat) + q + d\n        res = res + q + str(lon) + q + d\n    except Exception as ex:\n        print('problem reading image file metadata in ', fname, str(ex))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_text_to_image(fname, txt, opFilename):\n    ft = ImageFont.load(\"T://user//dev//src//python//_AS_LIB//timR24.pil\")\n    #wh = ft.getsize(txt)\n    print(\"Adding text \", txt, \" to \", fname, \" pixels wide to file \" , opFilename)\n    im = Image.open(fname)\n    draw = ImageDraw.Draw(im)\n    draw.text((0, 0), txt, fill=(0, 0, 0), font=ft)\n    del draw  \n    im.save(opFilename)", "response": "convert an image by adding text to fname"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an image by adding a cross hair", "response": "def add_crosshair_to_image(fname, opFilename):\n    \"\"\" convert an image by adding a cross hair \"\"\"\n    im = Image.open(fname)\n    draw = ImageDraw.Draw(im)\n    draw.line((0, 0) + im.size, fill=(255, 255, 255))\n    draw.line((0, im.size[1], im.size[0], 0), fill=(255, 255, 255))\n    del draw  \n    im.save(opFilename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_contour(imageFile, opFile):\n    im = Image.open(imageFile)\n    im1 = im.filter(ImageFilter.CONTOUR)\n    im1.save(opFile)", "response": "convert an image by applying a contour"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if images are duplicated", "response": "def check_image_duplicates(file_list):\n    \"\"\" Checking Images for duplicates (despite resizing, colours, etc) \"\"\"\n    master_hash = ''\n    ham_dist = 0\n    results = []\n    print(\"Checking Images for duplicates (despite resizing, colours, etc) \" )\n    for ndx, fname in enumerate(file_list):\n        #img = Image.open(fname)\n        img = load_image(fname)\n        hsh = get_img_hash(img)\n        if ndx == 0:  # this is the test MASTER image\n            master_hash = hsh\n        else:\n            # compare hamming distance against image 1  \n            #print(\"hash=\" + hash + \"  MASTER_HASH=\" + master_hash)\n            ham_dist = hamming_distance(hsh, master_hash)\n        #print(hsh + \" <- \" + fname + \" ,  hamming dist to img1 = \" + str(ham_dist))\n        #results.append(hsh + \" <- \" + fname + \" ,  hamming dist to img1 = \" + str(ham_dist))\n        results.append({'hsh':hsh, 'fname':fname, 'dist_to_img1':str(ham_dist)})\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Hamming distance between two equal - length sequences.", "response": "def hamming_distance(s1, s2):\n    \"\"\" \n    Return the Hamming distance between equal-length sequences\n    (http://en.wikipedia.org/wiki/Hamming_distance )\n    \"\"\"\n    if len(s1) != len(s2):\n        raise ValueError(\"Undefined for sequences of unequal length\")\n    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the image hash in one step.", "response": "def get_img_hash(image, hash_size = 8):\n    \"\"\" Grayscale and shrink the image in one step \"\"\"\n\n    image = image.resize((hash_size + 1, hash_size), Image.ANTIALIAS, )\n\n    pixels = list(image.getdata())\n    #print('get_img_hash: pixels=', pixels)\n\n    # Compare adjacent pixels.\n    difference = []\n    for row in range(hash_size):\n        for col in range(hash_size):\n            pixel_left = image.getpixel((col, row))\n            pixel_right = image.getpixel((col + 1, row))\n            difference.append(pixel_left > pixel_right)\n\n    # Convert the binary array to a hexadecimal string.\n    decimal_value = 0\n    hex_string = []\n    for index, value in enumerate(difference):\n        if value:\n            decimal_value += 2**(index % 8)\n        if (index % 8) == 7:\n            hex_string.append(hex(decimal_value)[2:].rjust(2, '0'))\n            decimal_value = 0\n\n    return ''.join(hex_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_image(fname):\n    with open(fname, \"rb\") as f:\n        i = Image.open(fname)\n        #i.load()\n        return i", "response": "read an image from file - PIL doesnt close nicely"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_img(fname):\n    img = Image.open(fname)\n    width, _ = img.size\n    txt = ''\n    pixels = list(img.getdata())\n    for col in range(width):\n        txt += str(pixels[col:col+width])\n    return txt", "response": "dump the image as text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CellPlot(df, output_file=None, gene_expression=\"log2FC\", figure_title=\"CellPlot\", pvalCol=\"elimFisher\", lowerLimit=None, upperLimit=None, colorBarType='Spectral'):\n    limits=pd.DataFrame(df['log2fc'].str.split(\",\").tolist())\n    limits=limits.as_matrix().flatten()\n    limits=pd.DataFrame(limits)\n    limits[0]=limits[0].astype(str)\n    limits=limits[limits[0]!=\"None\"][limits[0]!=\"\"]\n\n    try:\n        limits=[float(x) for x in limits[0].tolist()]\n\n    except (ValueError,e):\n        print(\"error\",e,\"on line\")\n\n    if upperLimit:\n        maxFC=upperLimit\n    else:\n        maxFC=np.percentile(limits,90)\n\n    if lowerLimit:\n        minFC=lowerLimit\n    else:\n        minFC=np.percentile(limits,10)\n\n    #maxFC=np.percentile(limits,90)\n    #minFC=np.percentile(limits,10)\n\n    cmap = matplotlib.cm.get_cmap(colorBarType)\n    norm = matplotlib.colors.Normalize(vmin=minFC, vmax=maxFC)\n\n    if len(df)>10:\n        siz=len(df)*3/10\n    elif len(df)==1:\n        siz=1\n    elif len(df)==2:\n        siz=2\n    else:\n        siz=3\n\n\n    fig = plt.figure(figsize=(8, siz))\n    #fig.suptitle(figure_title, fontsize=24, fontweight='bold')\n\n    ax1 = fig.add_axes([0.05, 3.5/( float(siz)*float(10)/float(3) ), 0.9, 2])\n    ax2 = fig.add_axes([0.05, 1.5/( float(siz)*float(10)/float(3) ), 0.9, 1.5/( float(siz)*float(10)/float(3) )])\n    arrangment=np.arange(len(df))+.5\n    df['Enrichment']=df['Enrichment'].astype(float)\n    enr=df['Enrichment'].tolist()\n    enr=[x for x in enr if str(x) != str(float(\"inf\"))]\n    enr=[x for x in enr if str(x) != str(float(\"-inf\"))]\n\n    m=max(enr)\n\n    maxE=max(enr)\n    minE=min(enr)\n\n    def getINFs(x,maxFC=maxFC,minFC=minFC):\n        if x == str(float(\"inf\")):\n            return maxFC\n        elif x == str(float(\"-inf\")):\n            return minFC\n        else:\n            return x\n\n    def fix_enrichment(x,minE=minE,maxE=maxE):\n        if str(x) == str(float(\"inf\")):\n            return maxE\n        elif str(x) == str(float(\"-inf\")):\n            return minE\n        else:\n            return x\n\n    df['Enrichment']=df['Enrichment'].apply(lambda x: fix_enrichment(x))\n\n\n    ax1.barh(arrangment, df['Enrichment'].tolist(), color='white', edgecolor='black')#range(0,len(test))\n    for i,pos in zip(df.index.tolist(),arrangment):\n        fcs=df.ix[i,'log2fc'].split(\",\")\n        fcs=pd.DataFrame(fcs)\n        fcs[0]=fcs[0].astype(str)\n        fcs[0]=fcs[0].apply(lambda x: getINFs(x))\n\n        #fcs=fcs[fcs[0]!=\"\"].astype(float)[0].tolist()\n        fcs=fcs.astype(float)[0].tolist()\n\n        try:\n            w=float(df.ix[i,'Enrichment'])/float(len(fcs))\n        except:\n            print(df.ix[i,])\n        p=0\n        fcs.sort(key=float)\n        for f in fcs:\n            #if float(f) > maxFC:\n            #    f=maxFC\n            #if float(f) < minFC:\n            #    f=minFC\n            #ax1.barh(pos, w, left=p, color=cmap(norm(float(f))), edgecolor='black')\n            ax1.barh(pos, w, left=p, color=cmap(norm(float(f))), edgecolor=cmap(norm(float(f))))\n            p=p+w\n        if pvalCol:\n            df[pvalCol] = df[pvalCol].astype(float)\n            if df.ix[i,pvalCol] < 0.05:\n                barAn=len(fcs)\n            else:\n                barAn=str(len(fcs))+\" (NS)\"\n        else:\n            barAn=len(fcs)\n        ax1.text(df.ix[i,'Enrichment']+m*0.02, pos, barAn, ha='left', va='bottom')\n    ax1.set_yticks(arrangment) # +0.4\n    ax1.set_yticklabels(df['Term'].tolist())\n\n    ax1.tick_params(\n        axis='y',\n        which='both',\n        left='off',\n        right='off',\n        labelleft='on')\n\n    ax1.tick_params(\n        axis='x',\n        which='both',\n        bottom='off',\n        top='on',\n        labelbottom='off',\n        labeltop='on')\n\n    ax1.set_ylim(ymax = max(arrangment) + 1.5 ) #1.5\n    ax1.set_xlabel(\"GO Term Enrichment\")\n    ax1.xaxis.set_label_position('top')\n\n    ax1.spines['right'].set_visible(False)\n    ax1.spines['bottom'].set_visible(False)\n\n    cb1 = matplotlib.colorbar.ColorbarBase(ax2, cmap=cmap,norm=norm, orientation='horizontal')\n    if not lowerLimit:\n        if not upperLimit:\n            cb1.set_label(gene_expression+'\\n(0.1-0.9 percentiles)\\n\\n\\n'+figure_title)\n        else:\n            cb1.set_label(gene_expression+'\\n\\n\\n'+figure_title)\n    else:\n        cb1.set_label(gene_expression+'\\n\\n\\n'+figure_title)\n\n    #plt.subplots_adjust(top=8.5)\n\n    #ax1.annotate('a fractional title', xy=(.025, .975), xycoords='figure fraction', horizontalalignment='center', verticalalignment='top', fontsize=20)\n    #plt.subplots_adjust(top=500)\n    #ax1.text(2, 2, 'right bottom',\n    #    horizontalalignment='center',\n    #    verticalalignment='center',\n    #    transform=ax1.transAxes)\n\n    if output_file:\n        plt.savefig(output_file+\".CellPlot.png\",dpi=300,bbox_inches='tight', pad_inches=0.1,format='png')\n        plt.savefig(output_file+\".CellPlot.svg\",dpi=300,bbox_inches='tight', pad_inches=0.1,format='svg')\n\n    return fig", "response": "This function is a convenience function that returns a matplotlib figure that can be used to plot a cell with the given enrichment term."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize intensities of a gene in two samples :param df: dataframe output of GetData() :param sampleA: column header of sample A :param sampleB: column header of sample B :returns: normalized intensities", "response": "def NormInt(df,sampleA,sampleB):\n    \"\"\"\n    Normalizes intensities of a gene in two samples\n\n    :param df: dataframe output of GetData()\n    :param sampleA: column header of sample A\n    :param sampleB: column header of sample B\n\n    :returns: normalized intensities\n    \"\"\"\n\n    c1=df[sampleA]\n    c2=df[sampleB]\n    return np.log10(np.sqrt(c1*c2))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting a MA plot of the data set.", "response": "def MA(df,title,figName,c, daType=\"counts\",nbins=10,perc=.5,deg=3,eq=True,splines=True,spec=None,Targets=None,ylim=None,sizeRed=8):\n    \"\"\"\n    Plots an MA like plot GetData() outputs.\n\n    :param df: dataframe output of GetData()\n    :param title: plot title, 'Genes' or 'Transcripts'\n    :param figName: /path/to/saved/figure/prefix\n    :param c: pair of samples to be plotted in list format\n    :param daType: data type, ie. 'counts' or 'FPKM'\n    :param nbins: number of bins on normalized intensities to fit the splines\n    :param per: log2(fold change) percentil to which the splines will be fitted\n    :param deg: degress of freedom used to fit the splines\n    :param eq: if true assumes for each bin that the lower and upper values are equally distant to 0, taking the smaller distance for both\n    :param splines: plot splines, default=True\n    :param spec: list of ids to be highlighted\n    :param Targets: list of ids that will be highlighted if outside of the fitted splines\n    :param ylim: a list of limits to apply on the y-axis of the plot\n    :param sizeRed: size of the highlight marker\n\n    :returns df_: a Pandas dataframe similar to the GetData() output with normalized intensities and spline outbounds rows marked as 1.\n    :returns red: list of ids that are highlighted\n    \"\"\"\n\n    df_=df[df[c[0]]>0]\n    df_=df_[df_[c[1]]>0]\n\n    df_[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ]=df_.apply(NormInt, args=(c[0],c[1],), axis=1)\n\n    if daType==\"counts\":\n        lowLim=np.log10(np.sqrt(10))\n    elif daType==\"FPKM\":\n        lowLim=np.log10(0.1)\n\n    df_b=df_[df_[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ]>lowLim ]\n    df_b.reset_index(inplace=True, drop=True)\n\n    Xdata=df_[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist()\n    Ydata=df_[\"log2(%s/%s)\" %( str(c[1]), str(c[0]) )].tolist()\n\n    minX=min(Xdata)\n    maxX=max(Xdata)\n\n    minX_=min(df_b[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist())\n    maxX_=max(df_b[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist())\n\n    df_b[\"bin\"]=pd.cut(df_b[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist(), nbins,labels=False)\n\n    spl=[]\n    for b in set( df_b[\"bin\"].tolist() ):\n        tmp=df_b[df_b[\"bin\"]==b]\n        Xbin = tmp[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist()\n        Xval = np.mean([max(Xbin),min(Xbin)])\n        Ybin = tmp[\"log2(%s/%s)\" %( str(c[1]), str(c[0]) )].tolist()\n        YvalP=np.percentile(Ybin,100.00-float(perc))\n        YvalM=np.percentile(Ybin,float(perc))\n        spl.append([Xval,YvalP,YvalM])\n\n    spl=pd.DataFrame( spl,columns=[\"X\",\"Upper\",\"Lower\"],index=range(len(spl)) )\n\n    def CheckMin(df):\n        U=abs(df[\"Upper\"])\n        L=abs(df[\"Lower\"])\n        return min([U,L])\n\n    spl[\"min\"]=spl.apply(CheckMin, axis=1)\n\n    coeffsUpper = np.polyfit(spl[\"X\"].tolist(), spl[\"Upper\"].tolist(), deg)\n    coeffsLower = np.polyfit(spl[\"X\"].tolist(), spl[\"Lower\"].tolist(), deg)\n\n    Xspl = np.array(np.linspace(minX, maxX, 10*nbins))\n\n    if eq:\n        coeffsUpper = np.polyfit(spl[\"X\"].tolist(), spl[\"min\"].tolist(), deg)\n        coeffsLower = np.polyfit(spl[\"X\"].tolist(), [ ss*-1 for ss in spl[\"min\"].tolist()] , deg)\n        YsplUpper = np.polyval(coeffsUpper, Xspl)\n        YsplLower = np.polyval(coeffsLower, Xspl)\n\n    else:\n        coeffsUpper = np.polyfit(spl[\"X\"].tolist(), spl[\"Upper\"].tolist(), deg)\n        coeffsLower = np.polyfit(spl[\"X\"].tolist(), spl[\"Lower\"].tolist(), deg)\n        YsplUpper = np.polyval(coeffsUpper, Xspl)\n        YsplLower = np.polyval(coeffsLower, Xspl)\n\n    def checkOutbounds(df,Xspl=Xspl,coeffsUpper=coeffsUpper,coeffsLower=coeffsLower,c=c):\n        x=df[\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) )]\n        y=df[\"log2(%s/%s)\" %( str(c[1]), str(c[0]) )]\n        if y < 0:\n            v=np.polyval(coeffsLower, x)\n            if y < v:\n                return 1\n            else:\n                return 0\n        else:\n            v=np.polyval(coeffsUpper, x)\n            if y > v:\n                return 1\n            else:\n                return 0\n\n    df_[\"OutBounds\"]=df_.apply(checkOutbounds,axis=1)\n\n    if Targets:\n        if title == \"Transcripts\":\n            red=df_[df_[\"OutBounds\"]==1][df_[\"transcript_id\"].isin(Targets)][\"transcript_id\"].tolist()\n            Xdata_=df_[df_[\"OutBounds\"]==1][df_[\"transcript_id\"].isin(Targets)][\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist()\n            Ydata_=df_[df_[\"OutBounds\"]==1][df_[\"transcript_id\"].isin(Targets)][\"log2(%s/%s)\" %( str(c[1]), str(c[0]) ) ].tolist()\n        elif title == \"Genes\":\n            red=df_[df_[\"OutBounds\"]==1][df_[\"gene_id\"].isin(Targets)][\"gene_id\"].tolist()\n            Xdata_=df_[df_[\"OutBounds\"]==1][df_[\"gene_id\"].isin(Targets)][\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) )].tolist()\n            Ydata_=df_[df_[\"OutBounds\"]==1][df_[\"gene_id\"].isin(Targets)][\"log2(%s/%s)\" %( str(c[1]), str(c[0]) )].tolist()\n    elif spec:\n        if title == \"Transcripts\":\n            red=df_[df_[\"transcript_id\"].isin(spec)][\"transcript_id\"].tolist()\n            Xdata_=df_[df_[\"transcript_id\"].isin(spec)][\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist()\n            Ydata_=df_[df_[\"transcript_id\"].isin(spec)][\"log2(%s/%s)\" %( str(c[1]), str(c[0]) ) ].tolist()\n        elif title == \"Genes\":\n            red=df_[df_[\"gene_id\"].isin(spec)][\"gene_id\"].tolist()\n            Xdata_=df_[df_[\"gene_id\"].isin(spec)][\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) )].tolist()\n            Ydata_=df_[df_[\"gene_id\"].isin(spec)][\"log2(%s/%s)\" %( str(c[1]), str(c[0]) )].tolist()\n    else:\n        Xdata_=df_[df_[\"OutBounds\"]==1][\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) ].tolist()\n        Ydata_=df_[df_[\"OutBounds\"]==1][\"log2(%s/%s)\" %( str(c[1]), str(c[0]) ) ].tolist()\n        if title == \"Transcripts\":\n            red=df_[df_[\"OutBounds\"]==1][\"transcript_id\"].tolist()\n        elif title == \"Genes\":\n            red=df_[df_[\"OutBounds\"]==1][\"gene_id\"].tolist()\n\n    fig = plt.gcf()\n    fig.set_size_inches(6, 6)\n    plt.scatter(Xdata,Ydata, s=2)\n    plt.scatter(Xdata_,Ydata_,s=sizeRed, c='r')\n    if splines:\n        plt.plot(Xspl,YsplUpper, \"-\",lw=0.5, c='g')\n        plt.plot(Xspl,YsplLower,\"-\", lw=0.5,c='g')\n\n    plt.xlabel(\"normalized intensities (%s vs. %s)\" %( str(c[0]), str(c[1]) ) )\n    plt.ylabel(\"log2(%s/%s)\" %( str(c[1]), str(c[0]) ))\n\n    if ylim:\n        plt.ylim(ylim[0],ylim[1])\n    else:\n        ylims=max([abs(min(Ydata)), abs(max(Ydata)) ])\n        plt.ylim(-ylims*1.1,ylims*1.1)\n\n    plt.title(title)\n    plt.savefig(figName+\".png\",dpi=300,bbox_inches='tight', pad_inches=0.1,format='png')\n    plt.savefig(figName+\".svg\",dpi=300,bbox_inches='tight', pad_inches=0.1,format='svg')\n    plt.show()\n\n    return df_,red"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_prime(number):\n    if number < 2:\n        return False\n    if number % 2 == 0:\n        return number == 2\n\n    limit = int(math.sqrt(number))\n    for divisor in range(3, limit + 1, 2):\n        if number % divisor == 0:\n            return False\n\n    return True", "response": "Test given number to be a prime."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn array of valid flows in a gauged catchment with amax_records set.", "response": "def valid_flows_array(catchment):\n    \"\"\"\n    Return array of valid flows (i.e. excluding rejected years etc)\n\n    :param catchment: gauged catchment with amax_records set\n    :type catchment: :class:`floodestimation.entities.Catchment`\n    :return: 1D array of flow values\n    :rtype: :class:`numpy.ndarray`\n    \"\"\"\n    return np.array([record.flow for record in catchment.amax_records if record.flag == 0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning QMED estimate of the most suitable catchment for a particular class.", "response": "def qmed(self, method='best', **method_options):\n        \"\"\"\n        Return QMED estimate using best available methodology depending on what catchment attributes are available.\n\n        The preferred/best order of methods is defined by :attr:`qmed_methods`. Alternatively, a method can be supplied\n        e.g. `method='descriptors_1999'` to force the use of a particular method.\n\n        ================= ======================= ======================================================================\n        `method`          `method_options`        notes\n        ================= ======================= ======================================================================\n        `amax_records`    n/a                     Simple median of annual maximum flow records using\n                                                  `Catchment.amax_records`.\n        `pot_records`     n/a                     Uses peaks-over-threshold (POT) flow records. Suitable for flow\n                                                  records shorter than 14 years.\n        `descriptors`                             Synonym for `method=descriptors2008`.\n        `descriptors2008` `as_rural=False`        FEH 2008 regression methodology using `Catchment.descriptors`. Setting\n                          `donor_catchments=None` `as_rural=True` returns rural estimate and setting `donor_catchments`\n                                                  to a specific list of :class:`Catchment` object **overrides**\n                                                  automatic selection of the most suitable donor catchment. An empty\n                                                  list forces no donors to be used at all.\n        `descriptors1999` as_rural=False          FEH 1999 regression methodology.\n        `area`            n/a                     Simplified FEH 1999 regression methodology using\n                                                  `Cachment.descriptors.dtm_area` only.\n        `channel_width`   n/a                     Emperical regression method using the river channel width only.\n        ================= ======================= ======================================================================\n\n        :param method: methodology to use to estimate QMED. Default: automatically choose best method.\n        :type method: str\n        :param method_options: any optional parameters for the QMED method function, e.g. `as_rural=True`\n        :type method_options: kwargs\n\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        if method == 'best':\n            # Rules for gauged catchments\n            if self.catchment.pot_dataset:\n                if self.catchment.amax_records:\n                    if self.catchment.record_length <= self.catchment.pot_dataset.record_length < 14:\n                        use_method = 'pot_records'\n                    elif self.catchment.record_length >= 2:\n                        use_method = 'amax_records'\n                    else:\n                        use_method = None\n                elif self.catchment.pot_dataset.record_length >= 1:\n                    use_method = 'pot_records'\n                else:\n                    use_method = None\n            elif self.catchment.record_length >= 2:\n                use_method = 'amax_records'\n            else:\n                use_method = None  # None of the gauged methods will work\n            if use_method:\n                self.results_log['method'] = use_method\n                return getattr(self, '_qmed_from_' + use_method)()\n\n            # Ungauged methods\n            for method in self.methods[1:]:\n                try:\n                    # Return the first method that works\n                    self.results_log['method'] = method\n                    return getattr(self, '_qmed_from_' + method)(**method_options)\n                except (TypeError, InsufficientDataError):\n                    pass\n            # In case none of them worked\n            return None\n\n        else:\n            # A specific method has been requested\n            try:\n                self.results_log['method'] = method\n                return getattr(self, '_qmed_from_' + method)(**method_options)\n            except AttributeError:\n                raise AttributeError(\"Method `{}` to estimate QMED does not exist.\".format(method))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of QMED methods using all available methods.", "response": "def qmed_all_methods(self):\n        \"\"\"\n        Returns a dict of QMED methods using all available methods.\n\n        Available methods are defined in :attr:`qmed_methods`. The returned dict keys contain the method name, e.g.\n        `amax_record` with value representing the corresponding QMED estimate in m\u00b3/s.\n\n        :return: dict of QMED estimates\n        :rtype: dict\n        \"\"\"\n        result = {}\n        for method in self.methods:\n            try:\n                result[method] = getattr(self, '_qmed_from_' + method)()\n            except:\n                result[method] = None\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn QMED estimate based on annual maximum flow records.", "response": "def _qmed_from_amax_records(self):\n        \"\"\"\n        Return QMED estimate based on annual maximum flow records.\n\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        valid_flows = valid_flows_array(self.catchment)\n        n = len(valid_flows)\n        if n < 2:\n            raise InsufficientDataError(\"Insufficient annual maximum flow records available for catchment {}.\"\n                                        .format(self.catchment.id))\n        return np.median(valid_flows)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns QMED estimate based on peaks - over - threshold ( POT records.", "response": "def _qmed_from_pot_records(self):\n        \"\"\"\n        Return QMED estimate based on peaks-over-threshold (POT) records.\n\n        Methodology source: FEH, Vol. 3, pp. 77-78\n\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        pot_dataset = self.catchment.pot_dataset\n        if not pot_dataset:\n            raise InsufficientDataError(\"POT dataset must be set for catchment {} to estimate QMED from POT data.\"\n                                        .format(self.catchment.id))\n\n        complete_year_records, length = self._complete_pot_years(pot_dataset)\n        if length < 1:\n            raise InsufficientDataError(\"Insufficient POT flow records available for catchment {}.\"\n                                        .format(self.catchment.id))\n\n        position = 0.790715789 * length + 0.539684211\n        i = floor(position)\n        w = 1 + i - position  # This is equivalent to table 12.1!\n\n        flows = [record.flow for record in complete_year_records]\n        flows.sort(reverse=True)\n\n        return w * flows[i - 1] + (1 - w) * flows[i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of 12 sets where each set contains the years included in the POT record period.", "response": "def _pot_month_counts(self, pot_dataset):\n        \"\"\"\n        Return a list of 12 sets. Each sets contains the years included in the POT record period.\n\n        :param pot_dataset: POT dataset (records and meta data)\n        :type pot_dataset: :class:`floodestimation.entities.PotDataset`\n        \"\"\"\n        periods = pot_dataset.continuous_periods()\n        result = [set() for x in range(12)]\n        for period in periods:\n            year = period.start_date.year\n            month = period.start_date.month\n            while True:\n                # Month by month, add the year\n                result[month - 1].add(year)\n                # If at end of period, break loop\n                if year == period.end_date.year and month == period.end_date.month:\n                    break\n                # Next month (and year if needed)\n                month += 1\n                if month == 13:\n                    month = 1\n                    year += 1\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a tuple of a list of a list of POTRecords filtering out part - complete years ; and the number of complete years.", "response": "def _complete_pot_years(self, pot_dataset):\n        \"\"\"\n        Return a tuple of a list of :class:`PotRecord`s filtering out part-complete years; and the number of complete\n        years.\n\n        This method creates complete years by ensuring there is an equal number of each month in the entire record,\n        taking into account data gaps. A month is considered to be covered by the record if there is at least a single\n        day of the month in any continuous period. (There doesn't have to be a record!) \"Leftover\" months not needed are\n        left at the beginning of the record, i.e. recent records are prioritised over older records.\n\n        :param pot_dataset: POT dataset (records and meta data)\n        :type pot_dataset: :class:`floodestimation.entities.PotDataset`\n        :return: list of POT records\n        :rtype: list of :class:`floodestimation.entities.PotRecord`\n        \"\"\"\n        # Create a list of 12 sets, one for each month. Each set represents the years for which the POT record includes\n        # a particular month.\n        month_counts = self._pot_month_counts(pot_dataset)\n        # Number of complete years\n        n = min([len(month) for month in month_counts])\n        # Use the last available years only such that there are equal numbers of each month; i.e. part years are\n        # excluded at the beginning of the record\n        years_to_use = [sorted(month)[-n:] for month in month_counts]\n        return (\n            [record for record in pot_dataset.pot_records if record.date.year in years_to_use[record.date.month - 1]],\n            n\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn QMED estimate based on catchment area.", "response": "def _qmed_from_area(self):\n        \"\"\"\n        Return QMED estimate based on catchment area.\n\n        TODO: add source of method\n\n        :return: QMED in m\u00b3/s\n        :rtype: float\n        \"\"\"\n        try:\n            return 1.172 * self.catchment.descriptors.dtm_area ** self._area_exponent()  # Area in km\u00b2\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _qmed_from_descriptors_1999(self, as_rural=False):\n        try:\n            qmed_rural = 1.172 * self.catchment.descriptors.dtm_area ** self._area_exponent() \\\n                         * (self.catchment.descriptors.saar / 1000.0) ** 1.560 \\\n                         * self.catchment.descriptors.farl ** 2.642 \\\n                         * (self.catchment.descriptors.sprhost / 100.0) ** 1.211 * \\\n                         0.0198 ** self._residual_soil()\n            if as_rural:\n                return qmed_rural\n            else:\n                return qmed_rural * self.urban_adj_factor()\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")", "response": "Return QMED estimation based on FEH catchment descriptors 1999 methodology."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _qmed_from_descriptors_2008(self, as_rural=False, donor_catchments=None):\n        try:\n            # Basis rural QMED from descriptors\n            lnqmed_rural = 2.1170 \\\n                           + 0.8510 * log(self.catchment.descriptors.dtm_area) \\\n                           - 1.8734 * 1000 / self.catchment.descriptors.saar \\\n                           + 3.4451 * log(self.catchment.descriptors.farl) \\\n                           - 3.0800 * self.catchment.descriptors.bfihost ** 2.0\n            qmed_rural = exp(lnqmed_rural)\n\n            # Log intermediate results\n            self.results_log['qmed_descr_rural'] = qmed_rural\n\n            if donor_catchments is None:\n                # If no donor catchments are provided, find the nearest 25\n                donor_catchments = self.find_donor_catchments()\n            if donor_catchments:\n                # If found multiply rural estimate with weighted adjustment factors from all donors\n\n                weights = self._vec_alpha(donor_catchments)\n                errors = self._vec_lnqmed_residuals(donor_catchments)\n                correction = np.dot(weights, errors)\n\n                lnqmed_rural += correction\n                qmed_rural = exp(lnqmed_rural)\n\n                # Log intermediate results\n                self.results_log['donors'] = donor_catchments\n                for i, donor in enumerate(self.results_log['donors']):\n                    donor.weight = weights[i]\n                    donor.factor = exp(errors[i])\n                self.results_log['donor_adj_factor'] = exp(correction)\n                self.results_log['qmed_adj_rural'] = qmed_rural\n\n            if as_rural:\n                return qmed_rural\n            else:\n                # Apply urbanisation adjustment\n                urban_adj_factor = self.urban_adj_factor()\n\n                # Log intermediate results\n                self.results_log['qmed_descr_urban'] = self.results_log['qmed_descr_rural'] * urban_adj_factor\n                return qmed_rural * urban_adj_factor\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")", "response": "Return QMED estimation based on FEH catchment descriptors 2008 methodology."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn percentage runoff urban adjustment factor.", "response": "def _pruaf(self):\n        \"\"\"\n        Return percentage runoff urban adjustment factor.\n\n        Methodology source: eqn. 6, Kjeldsen 2010\n        \"\"\"\n        return 1 + 0.47 * self.catchment.descriptors.urbext(self.year) \\\n                   * self.catchment.descriptors.bfihost / (1 - self.catchment.descriptors.bfihost)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the urban adjustment factor used to adjust QMED and growth curves.", "response": "def urban_adj_factor(self):\n        \"\"\"\n        Return urban adjustment factor (UAF) used to adjust QMED and growth curves.\n\n        Methodology source: eqn. 8, Kjeldsen 2010\n\n        :return: urban adjustment factor\n        :rtype: float\n        \"\"\"\n        urbext = self.catchment.descriptors.urbext(self.year)\n        result = self._pruaf() ** 2.16 * (1 + urbext) ** 0.37\n        self.results_log['urban_extent'] = urbext\n        self.results_log['urban_adj_factor'] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dist_corr(dist, phi1, phi2, phi3):\n        return phi1 * exp(-phi2 * dist) + (1 - phi1) * exp(-phi3 * dist)", "response": "Generic distance - decaying correlation function"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _model_error_corr(self, catchment1, catchment2):\n        dist = catchment1.distance_to(catchment2)\n        return self._dist_corr(dist, 0.3998, 0.0283, 0.9494)", "response": "Calculate model error correlation between subject catchment and other catchment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the lnqmed correlation between subject catchment and other catchment.", "response": "def _lnqmed_corr(self, catchment1, catchment2):\n        \"\"\"\n        Return model error correlation between subject catchment and other catchment.\n\n        Methodology source: Kjeldsen & Jones, 2009, fig 3\n\n        :param catchment1: catchment to calculate correlation with\n        :type catchment1: :class:`Catchment`\n        :param catchment2: catchment to calculate correlation with\n        :type catchment2: :class:`Catchment`\n        :return: correlation coefficient, r\n        :rtype: float\n        \"\"\"\n        dist = catchment1.distance_to(catchment2)\n        return self._dist_corr(dist, 0.2791, 0.0039, 0.0632)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning vector b of model error covariance to estimate weights", "response": "def _vec_b(self, donor_catchments):\n        \"\"\"\n        Return vector ``b`` of model error covariances to estimate weights\n\n        Methodology source: Kjeldsen, Jones and Morris, 2009, eqs 3 and 10\n\n        :param donor_catchments: Catchments to use as donors\n        :type donor_catchments: list of :class:`Catchment`\n        :return: Model error covariance vector\n        :rtype: :class:`numpy.ndarray`\n        \"\"\"\n        p = len(donor_catchments)\n        b = 0.1175 * np.ones(p)\n        for i in range(p):\n            b[i] *= self._model_error_corr(self.catchment, donor_catchments[i])\n        return b"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _beta(catchment):\n        lnbeta = -1.1221 \\\n                 - 0.0816 * log(catchment.descriptors.dtm_area) \\\n                 - 0.4580 * log(catchment.descriptors.saar / 1000) \\\n                 + 0.1065 * log(catchment.descriptors.bfihost)\n        return exp(lnbeta)", "response": "Return beta estimate of the GLO scale parameter divided by loc parameter estimated using simple regression model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _matrix_sigma_eta(self, donor_catchments):\n        p = len(donor_catchments)\n        sigma = 0.1175 * np.ones((p, p))\n        for i in range(p):\n            for j in range(p):\n                if i != j:\n                    sigma[i, j] *= self._model_error_corr(donor_catchments[i], donor_catchments[j])\n        return sigma", "response": "Compute model error coveriance matrix Sigma eta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning sampling error coveriance matrix Sigma", "response": "def _matrix_sigma_eps(self, donor_catchments):\n        \"\"\"\n        Return sampling error coveriance matrix Sigma eta\n\n        Methodology source: Kjeldsen & Jones 2009, eq 9\n\n        :param donor_catchments: Catchments to use as donors\n        :type donor_catchments: list of :class:`Catchment`\n        :return: 2-Dimensional, symmetric covariance matrix\n        :rtype: :class:`numpy.ndarray`\n        \"\"\"\n        p = len(donor_catchments)\n        sigma = np.empty((p, p))\n        for i in range(p):\n            beta_i = self._beta(donor_catchments[i])\n            n_i = donor_catchments[i].amax_records_end() - donor_catchments[i].amax_records_start() + 1\n            for j in range(p):\n                beta_j = self._beta(donor_catchments[j])\n                n_j = donor_catchments[j].amax_records_end() - donor_catchments[j].amax_records_start() + 1\n                rho_ij = self._lnqmed_corr(donor_catchments[i], donor_catchments[j])\n                n_ij = min(donor_catchments[i].amax_records_end(), donor_catchments[j].amax_records_end()) - \\\n                       max(donor_catchments[i].amax_records_start(), donor_catchments[j].amax_records_start()) + 1\n                sigma[i, j] = 4 * beta_i * beta_j * n_ij / n_i / n_j * rho_ij\n        return sigma"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns vector alpha which is the weights for donor model errors", "response": "def _vec_alpha(self, donor_catchments):\n        \"\"\"\n        Return vector alpha which is the weights for donor model errors\n\n        Methodology source: Kjeldsen, Jones & Morris 2014, eq 10\n\n        :param donor_catchments: Catchments to use as donors\n        :type donor_catchments: list of :class:`Catchment`\n        :return: Vector of donor weights\n        :rtype: :class:`numpy.ndarray`\n        \"\"\"\n        return np.dot(linalg.inv(self._matrix_omega(donor_catchments)), self._vec_b(donor_catchments))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn ln ( QMED ) model error at a gauged catchment", "response": "def _lnqmed_residual(catchment):\n        \"\"\"\n        Return ln(QMED) model error at a gauged catchment\n\n        :param catchment: Gauged catchment\n        :type catchment: :class:`Catchment`\n        :return: Model error\n        :rtype: float\n        \"\"\"\n        analysis = QmedAnalysis(catchment, year=2000)  # Probably should set the year to the midpoint of amax rec.\n        logmedian_amax = log(analysis.qmed(method='amax_records'))\n        logmedian_descr = log(analysis.qmed(method='descriptors'))\n        return logmedian_amax - logmedian_descr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _vec_lnqmed_residuals(self, catchments):\n        result = np.empty(len(catchments))\n        for index, donor in enumerate(catchments):\n            result[index] = self._lnqmed_residual(donor)\n        return result", "response": "Return ln QMED model errors for a list of catchments\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of nearby catchments for a given subject and donor catchment.", "response": "def find_donor_catchments(self, limit=6, dist_limit=500):\n        \"\"\"\n        Return a suitable donor catchment to improve a QMED estimate based on catchment descriptors alone.\n\n        :param limit: maximum number of catchments to return. Default: 6. Set to `None` to return all available\n                      catchments.\n        :type limit: int\n        :param dist_limit: maximum distance in km. between subject and donor catchment. Default: 500 km. Increasing the\n                           maximum distance will increase computation time!\n        :type dist_limit: float or int\n        :return: list of nearby catchments\n        :rtype: :class:`floodestimation.entities.Catchment`\n        \"\"\"\n        if self.gauged_catchments:\n            return self.gauged_catchments.nearest_qmed_catchments(self.catchment, limit, dist_limit)\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef growth_curve(self, method='best', **method_options):\n        if method == 'best':\n            if self.catchment.amax_records:\n                # Gauged catchment, use enhanced single site\n                self.results_log['method'] = 'enhanced_single_site'\n                return self._growth_curve_enhanced_single_site()\n            else:\n                # Ungauged catchment, standard pooling group\n                self.results_log['method'] = 'pooling_group'\n                return self._growth_curve_pooling_group()\n        else:\n            try:\n                self.results_log['method'] = 'method'\n                return getattr(self, '_growth_curve_' + method)(**method_options)\n            except AttributeError:\n                raise AttributeError(\"Method `{}` to estimate the growth curve does not exist.\".format(method))", "response": "Estimate the growth curve for a given methodology."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _var_and_skew(self, catchments, as_rural=False):\n        if not hasattr(catchments, '__getitem__'):  # In case of a single catchment\n            l_cv, l_skew = self._l_cv_and_skew(self.catchment)\n            self.results_log['donors'] = []\n        else:\n            # Prepare arrays for donor L-CVs and L-SKEWs and their weights\n            n = len(catchments)\n            l_cvs = np.empty(n)\n            l_skews = np.empty(n)\n            l_cv_weights = np.empty(n)\n            l_skew_weights = np.empty(n)\n\n            # Fill arrays\n            for index, donor in enumerate(catchments):\n                l_cvs[index], l_skews[index] = self._l_cv_and_skew(donor)\n                l_cv_weights[index] = self._l_cv_weight(donor)\n                l_skew_weights[index] = self._l_skew_weight(donor)\n\n            # Weighted averages of L-CV and l-SKEW\n            l_cv_weights /= sum(l_cv_weights)  # Weights sum to 1\n            # Special case if the first donor is the subject catchment itself, assumed if similarity distance == 0.\n            if self._similarity_distance(self.catchment, catchments[0]) == 0:\n                l_cv_weights *= self._l_cv_weight_factor()  # Reduce weights of all donor catchments\n                l_cv_weights[0] += 1 - sum(l_cv_weights)    # But increase the weight of the subject catchment\n            l_cv_rural = sum(l_cv_weights * l_cvs)\n            l_skew_weights /= sum(l_skew_weights)  # Weights sum to 1\n            l_skew_rural = sum(l_skew_weights * l_skews)\n            self.results_log['l_cv_rural'] = l_cv_rural\n            self.results_log['l_skew_rural'] = l_skew_rural\n\n            if as_rural:\n                l_cv = l_cv_rural\n                l_skew = l_skew_rural\n            else:\n                # Method source: eqns. 10 and 11, Kjeldsen 2010\n                l_cv = l_cv_rural * 0.5547 ** self.catchment.descriptors.urbext(self.year)\n                l_skew = (l_skew_rural + 1) * 1.1545 ** self.catchment.descriptors.urbext(self.year) - 1\n\n            # Record intermediate results (donors)\n            self.results_log['donors'] = catchments\n            total_record_length = 0\n            for index, donor in enumerate(self.results_log['donors']):\n                donor.l_cv = l_cvs[index]\n                donor.l_cv_weight = l_cv_weights[index]\n                donor.l_skew = l_skews[index]\n                donor.l_skew_weight = l_skew_weights[index]\n                total_record_length += donor.record_length\n            self.results_log['donors_record_length'] = total_record_length\n\n        # Record intermediate results\n        self.results_log['l_cv'] = l_cv\n        self.results_log['l_skew'] = l_skew\n        return l_cv, l_skew", "response": "Calculate the variable and skew of a single catchment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _l_cv_and_skew(self, catchment):\n        z = self._dimensionless_flows(catchment)\n        l1, l2, t3 = lm.lmom_ratios(z, nmom=3)\n        return l2 / l1, t3", "response": "Calculate L - CV and L - SKEW for a gauged catchment. Uses lmoments3 library."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the L - CV weighting for a donor catchment.", "response": "def _l_cv_weight(self, donor_catchment):\n        \"\"\"\n        Return L-CV weighting for a donor catchment.\n\n        Methodology source: Science Report SC050050, eqn. 6.18 and 6.22a\n        \"\"\"\n        try:\n            dist = donor_catchment.similarity_dist\n        except AttributeError:\n            dist = self._similarity_distance(self.catchment, donor_catchment)\n        b = 0.0047 * sqrt(dist) + 0.0023 / 2\n        c = 0.02609 / (donor_catchment.record_length - 1)\n        return 1 / (b + c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _l_cv_weight_factor(self):\n        b = 0.0047 * sqrt(0) + 0.0023 / 2\n        c = 0.02609 / (self.catchment.record_length - 1)\n        return c / (b + c)", "response": "Return multiplier for L - CV weightings in case of enhanced single site analysis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the L - SKEW weighting for a given donor catchment.", "response": "def _l_skew_weight(self, donor_catchment):\n        \"\"\"\n        Return L-SKEW weighting for donor catchment.\n\n        Methodology source: Science Report SC050050, eqn. 6.19 and 6.22b\n        \"\"\"\n        try:\n            dist = donor_catchment.similarity_dist\n        except AttributeError:\n            dist = self._similarity_distance(self.catchment, donor_catchment)\n        b = 0.0219 * (1 - exp(-dist / 0.2360))\n        c = 0.2743 / (donor_catchment.record_length - 2)\n        return 1 / (b + c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _growth_curve_single_site(self, distr='glo'):\n        if self.catchment.amax_records:\n            self.donor_catchments = []\n            return GrowthCurve(distr, *self._var_and_skew(self.catchment))\n        else:\n            raise InsufficientDataError(\"Catchment's `amax_records` must be set for a single site analysis.\")", "response": "Returns the flood growth curve function based on amax_records from the subject catchment only."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _growth_curve_pooling_group(self, distr='glo', as_rural=False):\n        if not self.donor_catchments:\n            self.find_donor_catchments()\n        gc = GrowthCurve(distr, *self._var_and_skew(self.donor_catchments))\n\n        # Record intermediate results\n        self.results_log['distr_name'] = distr.upper()\n        self.results_log['distr_params'] = gc.params\n        return gc", "response": "Return flood growth curve function based on amax_records."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind list of suitable donor cachments, ranked by hydrological similarity distance measure. This method is implicitly called when calling the :meth:`.growth_curve` method unless the attribute :attr:`.donor_catchments` is set manually. The results are stored in :attr:`.donor_catchments`. The (list of) :class:`floodestimation.entities.Catchment` will have an additional attribute :attr:`similarity_dist`. :param include_subject_catchment: - `auto`: include subject catchment if suitable for pooling and if urbext2000 < 0.03 - `force`: always include subject catchment - `exclude`: do not include the subject catchment :type include_subject_catchment: str", "response": "def find_donor_catchments(self, include_subject_catchment='auto'):\n        \"\"\"\n        Find list of suitable donor cachments, ranked by hydrological similarity distance measure. This method is\n        implicitly called when calling the :meth:`.growth_curve` method unless the attribute :attr:`.donor_catchments`\n        is set manually.\n\n        The results are stored in :attr:`.donor_catchments`. The (list of)\n        :class:`floodestimation.entities.Catchment` will have an additional attribute :attr:`similarity_dist`.\n\n        :param include_subject_catchment: - `auto`: include subject catchment if suitable for pooling and if urbext2000\n                                            < 0.03\n                                          - `force`: always include subject catchment\n                                          - `exclude`: do not include the subject catchment\n        :type include_subject_catchment: str\n        \"\"\"\n\n        # Only if we have access to db with gauged catchment data\n        if self.gauged_cachments:\n            self.donor_catchments = self.gauged_cachments. \\\n                most_similar_catchments(subject_catchment=self.catchment,\n                                        similarity_dist_function=lambda c1, c2: self._similarity_distance(c1, c2),\n                                        include_subject_catchment=include_subject_catchment)\n        else:\n            self.donor_catchments = []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the location parameter such that growth_curve = 1.", "response": "def _solve_location_param(self):\n        \"\"\"\n        We're lazy here and simply iterate to find the location parameter such that growth_curve(0.5)=1.\n        \"\"\"\n        params = copy.copy(self.params)\n        del params['loc']\n\n        f = lambda location: self.distr_f.ppf(0.5, loc=location, **params) - 1\n        return optimize.brentq(f, -10, 10)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process(self, document):\n        content = json.dumps(document)\n\n        versions = {}\n        versions.update({'Spline': Version(VERSION)})\n        versions.update(self.get_version(\"Bash\", self.BASH_VERSION))\n\n        if content.find('\"docker(container)\":') >= 0 or content.find('\"docker(image)\":') >= 0:\n            versions.update(VersionsCheck.get_version(\"Docker\", self.DOCKER_VERSION))\n        if content.find('\"packer\":') >= 0:\n            versions.update(VersionsCheck.get_version(\"Packer\", self.PACKER_VERSION))\n        if content.find('\"ansible(simple)\":') >= 0:\n            versions.update(VersionsCheck.get_version('Ansible', self.ANSIBLE_VERSION))\n\n        return versions", "response": "Processes the log document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting name and version of a specific tool.", "response": "def get_version(tool_name, tool_command):\n        \"\"\"\n        Get name and version of a tool defined by given command.\n\n        Args:\n            tool_name (str): name of the tool.\n            tool_command (str): Bash one line command to get the version of the tool.\n\n        Returns:\n            dict: tool name and version or empty when no line has been found\n        \"\"\"\n        result = {}\n        for line in Bash(ShellConfig(script=tool_command, internal=True)).process():\n            if line.find(\"command not found\") >= 0:\n                VersionsCheck.LOGGER.error(\"Required tool '%s' not found (stopping pipeline)!\", tool_name)\n                sys.exit(1)\n            else:\n                version = list(re.findall(r'(\\d+(\\.\\d+)+)+', line))[0][0]\n                result = {tool_name: Version(str(version))}\n            break\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlog version sorted by tool name.", "response": "def process(self, versions):\n        \"\"\"Logging version sorted ascending by tool name.\"\"\"\n        for tool_name in sorted(versions.keys()):\n            version = versions[tool_name]\n            self._log(\"Using tool '%s', %s\" % (tool_name, version))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_event(self, *names):\n        for name in names:\n            if name in self.__events:\n                continue\n            self.__events[name] = Event(name)", "response": "Registers new events after instance creation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bind(self, **kwargs):\n        aio_loop = kwargs.pop('__aio_loop__', None)\n        props = self.__property_events\n        events = self.__events\n        for name, cb in kwargs.items():\n            if name in props:\n                e = props[name]\n            else:\n                e = events[name]\n            e.add_listener(cb, __aio_loop__=aio_loop)", "response": "Subscribes to events or to properties or to updates the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch an event to any subscribed listeners.", "response": "def emit(self, name, *args, **kwargs):\n        \"\"\"Dispatches an event to any subscribed listeners\n\n        Note:\n            If a listener returns :obj:`False`, the event will stop dispatching to\n            other listeners. Any other return value is ignored.\n\n        Args:\n            name (str): The name of the :class:`Event` to dispatch\n            *args (Optional): Positional arguments to be sent to listeners\n            **kwargs (Optional): Keyword arguments to be sent to listeners\n        \"\"\"\n        e = self.__property_events.get(name)\n        if e is None:\n            e = self.__events[name]\n        return e(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dispatcher_event(self, name):\n        e = self.__property_events.get(name)\n        if e is None:\n            e = self.__events[name]\n        return e", "response": "Retrieves an Event object by name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhold emission of events and dispatches the last event on release", "response": "def emission_lock(self, name):\n        \"\"\"Holds emission of events and dispatches the last event on release\n\n        The context manager returned will store the last event data called by\n        :meth:`emit` and prevent callbacks until it exits. On exit, it will\n        dispatch the last event captured (if any)::\n\n            class Foo(Dispatcher):\n                _events_ = ['my_event']\n\n            def on_my_event(value):\n                print(value)\n\n            foo = Foo()\n            foo.bind(my_event=on_my_event)\n\n            with foo.emission_lock('my_event'):\n                foo.emit('my_event', 1)\n                foo.emit('my_event', 2)\n\n            >>> 2\n\n        Args:\n            name (str): The name of the :class:`Event` or\n                :class:`~pydispatch.properties.Property`\n\n        Returns:\n            A context manager to be used by the :keyword:`with` statement.\n\n            If available, this will also be an async context manager to be used\n            with the :keyword:`async with` statement (see `PEP 492`_).\n\n        Note:\n            The context manager is re-entrant, meaning that multiple calls to\n            this method within nested context scopes are possible.\n\n        .. _PEP 492: https://www.python.org/dev/peps/pep-0492/#asynchronous-context-managers-and-async-with\n        \"\"\"\n        e = self.__property_events.get(name)\n        if e is None:\n            e = self.__events[name]\n        return e.emission_lock"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntests function to step through all functions in order to try and identify all features on a map", "response": "def TEST(fname):\n    \"\"\"\n    Test function to step through all functions in\n    order to try and identify all features on a map\n    This test function should be placed in a main \n    section later\n    \"\"\"\n    #fname = os.path.join(os.getcwd(), '..','..',  # os.path.join(os.path.getcwd(), '\n    m = MapObject(fname, os.path.join(os.getcwd(), 'img_prog_results'))\n    m.add_layer(ImagePathFollow('border'))\n    m.add_layer(ImagePathFollow('river'))\n    m.add_layer(ImagePathFollow('road'))\n    \n    m.add_layer(ImageArea('sea', col='Blue', density='light'))\n    m.add_layer(ImageArea('desert', col='Yellow', density='med'))\n    m.add_layer(ImageArea('forest', col='Drak Green', density='light'))\n    m.add_layer(ImageArea('fields', col='Green', density='light'))\n    \n    m.add_layer(ImageObject('mountains'))\n    m.add_layer(ImageObject('trees'))\n    m.add_layer(ImageObject('towns'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndescribes various contents of the data table", "response": "def describe_contents(self):\n        \"\"\" describes various contents of data table \"\"\"\n        print('======================================================================')\n        print(self)\n        print('Table  = ',  str(len(self.header)) + ' cols x ' + str(len(self.arr)) + ' rows')\n        print('HEADER = ', self.get_header())\n        print('arr    = ', self.arr[0:2])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_distinct_values_from_cols(self, l_col_list):\n        uniq_vals = []\n        for l_col_name in l_col_list:\n            #print('col_name: ' + l_col_name)   \n            uniq_vals.append(set(self.get_col_data_by_name(l_col_name)))\n            #print(' unique values = ', uniq_vals)    \n        \n        #print(' unique values[0] = ', uniq_vals[0])\n        #print(' unique values[1] = ', uniq_vals[1])\n        if len(l_col_list) == 0:\n            return []\n        elif len(l_col_list) == 1:\n            return sorted([v for v in uniq_vals])\n        elif len(l_col_list) == 2:\n            res = []\n            res = [(a, b) for a in uniq_vals[0] for b in uniq_vals[1]]\n            return res\n        else:\n            print (\"TODO \")\n            return -44", "response": "returns the list of distinct combinations in a dataset\n            based on the columns in the list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects rows from the array where col_list == val_list", "response": "def select_where(self, where_col_list, where_value_list, col_name=''):\n        \"\"\" \n        selects rows from the array where col_list == val_list\n        \"\"\"\n        res = []        # list of rows to be returned\n        col_ids = []    # ids of the columns to check\n        #print('select_where  : arr = ',  len(self.arr), 'where_value_list = ',  where_value_list)\n        for col_id, col in enumerate(self.header):\n            if col in where_col_list:\n                col_ids.append([col_id, col])\n        #print('select_where    : col_ids = ',  col_ids)   # correctly prints [[0, 'TERM'], [2, 'ID']]\n        \n        for row_num, row in enumerate(self.arr):\n            keep_this_row = True\n            #print('col_ids=', col_ids, ' row = ', row_num, row)\n            for ndx, where_col in enumerate(col_ids):\n                #print('type where_value_list[ndx] = ', type(where_value_list[ndx]))\n                #print('type row[where_col[0]] = ', type(row[where_col[0]]))\n                \n                if row[where_col[0]] != where_value_list[ndx]:\n                    keep_this_row = False\n            if keep_this_row is True:\n                if col_name == '':\n                    res.append([row_num, row])\n                else:   # extracting a single column only\n                    l_dat = self.get_col_by_name(col_name)\n                    if l_dat is not None:\n                        res.append(row[l_dat])\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_where(self, col, value, where_col_list, where_value_list):\n        if type(col) is str:\n            col_ndx = self.get_col_by_name(col)\n        else:\n            col_ndx = col\n        #print('col_ndx = ', col_ndx    )\n        #print(\"updating \" + col + \" to \" , value, \" where \" , where_col_list , \" = \" , where_value_list)\n        new_arr = self.select_where(where_col_list, where_value_list)\n        #print('new_arr', new_arr)\n        for r in new_arr:\n            self.arr[r[0]][col_ndx] = value", "response": "updates the array to set value where col_list == val_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the percentiles of col_name", "response": "def calc_percentiles(self, col_name, where_col_list, where_value_list):\n        \"\"\" \n        calculates the percentiles of col_name \n        WHERE [where_col_list] = [where_value_list]\n        \"\"\"\n        #col_data = self.get_col_data_by_name(col_name)\n        col_data = self.select_where(where_col_list, where_value_list, col_name)\n        #print('calc_percentiles: col_data = ', col_data, ' where_col_list = ', where_col_list, ', where_value_list = ', where_value_list)\n        if len(col_data) == 0:\n            #print(\"Nothing to calculate\")\n            return 0,0,0\n        else:\n            first  = self.percentile(col_data, .25)\n            third  = self.percentile(col_data, .75)\n            median = self.percentile(col_data, .50)\n            #print('CALC_PERCENTILES =  first, third, median ',  first, third, median )\n            return  first, third, median"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef percentile(self, lst_data, percent , key=lambda x:x):\n        new_list = sorted(lst_data)\n        #print('new list = ' , new_list)\n        #n = float(len(lst_data))\n        k = (len(new_list)-1) * percent\n        f = math.floor(k)\n        c = math.ceil(k)\n        if f == c:\n            #print(key(new_list[int(k)]))\n            return key(new_list[int(k)])\n        d0 = float(key(new_list[int(f)])) * (c-k)\n        d1 = float(key(new_list[int(c)])) * (k-f)\n        return d0+d1", "response": "Calculates the num percentile of the items in the list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving a file from a list of lines", "response": "def save(self, filename, content):\n        \"\"\"\n        default is to save a file from list of lines\n        \"\"\"\n        with open(filename, \"w\") as f:\n            if hasattr(content, '__iter__'):\n                f.write('\\n'.join([row for row in content]))\n            else:\n                print('WRINGI CONTWETESWREWR')\n                f.write(str(content))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_csv(self, filename, write_header_separately=True):\n        txt = ''\n        #print(\"SAVING arr = \", self.arr)\n        \n        with open(filename, \"w\") as f:\n            if write_header_separately:\n                f.write(','.join([c for c in self.header]) + '\\n')\n            for row in self.arr:\n                #print('save_csv: saving row = ', row)\n                txt = ','.join([self.force_to_string(col) for col in row])\n                #print(txt)\n                f.write(txt + '\\n')\n            f.write('\\n')", "response": "save the default array as a CSV file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndrop the table view or delete the file", "response": "def drop(self, fname):\n        \"\"\" \n        drop the table, view or delete the file\n        \"\"\"\n        if self.dataset_type == 'file':\n            import os\n            try:\n                os.remove(fname)\n            except Exception as ex:\n                print('cant drop file \"' + fname + '\" : ' + str(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the values of col_name according to WHERE_Clause", "response": "def get_col_data_by_name(self, col_name, WHERE_Clause=''):\n        \"\"\" returns the values of col_name according to where \"\"\"\n        #print('get_col_data_by_name: col_name = ', col_name, ' WHERE = ', WHERE_Clause)\n        col_key = self.get_col_by_name(col_name)\n        if col_key is None:\n            print('get_col_data_by_name: col_name = ', col_name, ' NOT FOUND')\n            return []\n        #print('get_col_data_by_name: col_key =', col_key)\n        res = []\n        for row in self.arr:\n            #print('col_key=',col_key, ' len(row)=', len(row), ' row=', row)\n            res.append(row[col_key])  # need to convert to int for calcs but leave as string for lookups\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn table in RST format", "response": "def format_rst(self):\n        \"\"\"\n        return table in RST format\n        \"\"\"\n        res = ''\n        num_cols = len(self.header)\n        col_width = 25\n        for _ in range(num_cols):\n            res += ''.join(['=' for _ in range(col_width - 1)]) + ' ' \n        res += '\\n'\n        for c in self.header:\n            res += c.ljust(col_width) \n        res += '\\n'\n        for _ in range(num_cols):\n            res += ''.join(['=' for _ in range(col_width - 1)]) + ' ' \n        res += '\\n'\n        for row in self.arr:\n            for c in row:\n                res += self.force_to_string(c).ljust(col_width)\n            res += '\\n' \n        for _ in range(num_cols):\n            res += ''.join(['=' for _ in range(col_width - 1)]) + ' ' \n        res += '\\n'\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads perseus network collection folder format", "response": "def read_networks(folder):\n    \"\"\"\n    Read perseus network collection folder format\n    \n    >>> network_table, networks = read_networks(folder)\n    \n    :param folder: Path to network collection\n    :returns: Network table and dictionary with 'name', 'edge_table', and 'node_table' keys.\n    \"\"\"\n    network_table = read_perseus(path.join(folder, \"networks.txt\"))\n    networks = {}\n    for name, guid in network_table[['Name', 'GUID']].values:\n        networks[guid] = {\n                'name': name,\n                'guid': guid,\n                'node_table': read_perseus(path.join(folder, \"{}_nodes.txt\".format(guid))),\n                'edge_table': read_perseus(path.join(folder, \"{}_edges.txt\".format(guid)))\n                }\n    return network_table, networks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_perseus(network_table, networks):\n    graphs = []\n    for guid, graph_attr in zip(network_table['GUID'], network_table.values):\n        network = networks[guid]\n        edge_table = network['edge_table']\n        if edge_table[['Source', 'Target']].duplicated().any():\n            warnings.warn('Duplicate edges were found and ignored in network {}'.format(network['name']))\n        G = nx.from_pandas_edgelist(edge_table, 'Source', 'Target', True, create_using=nx.DiGraph())\n        for attr, value in zip(network_table.columns, graph_attr):\n            G.graph[attr] = value\n        node_table = network['node_table']\n        if node_table['Node'].duplicated().any():\n            warnings.warn('Duplicate nodes were found and ignored in network {}'.format(network['name']))\n        node_column = node_table['Node']\n        for name, attributes in zip(node_column, node_table.values):\n            if name not in G:\n                G.add_node(name)\n            for attr, value in zip(node_table.columns, attributes):\n                G.node[name][attr] = value\n        graphs.append(G)\n    return graphs", "response": "Create networkx graph from perseus network tables"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_perseus(graphs):\n    graph_attributes = []\n    networks = {}\n    for graph in graphs:\n        attributes = dict(graph.graph)\n        attributes.update({\"Name\" : attributes.get(\"Name\", attributes.get(\"name\", \"networkx graph\")),\n            \"GUID\": attributes.get(\"GUID\", str(uuid.uuid4()))})\n        graph_attributes.append(attributes)\n        if len(graph) > 0:\n            edge_table = pd.DataFrame([dict(data, **{\"Source\": str(f), \"Target\": str(t)}) for f,t,data in graph.edges(data=True)])\n            edge_table.columns.name = \"Column Name\"\n            node_table = pd.DataFrame([dict(data, **{\"Node\": str(n)}) for n,data in graph.nodes(data=True)])\n            node_table.columns.name = \"Column Name\"\n        else:\n            edge_table = pd.DataFrame(columns=pd.Index(['Source', 'Target'], name='Column Name'))\n            node_table = pd.DataFrame(columns=pd.Index(['Node'], name='Column Name'))\n        guid = attributes['GUID']\n        networks[guid] = {\n            'edge_table': edge_table,\n            'node_table': node_table,\n            'name': attributes['Name'],\n            'guid': guid }\n    network_table = pd.DataFrame(graph_attributes)\n    network_table.columns.name = \"Column Name\"\n    return network_table, networks", "response": "Create a network table and the network dictionary for export to Perseus."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_networks(folder, network_table, networks):\n    makedirs(folder, exist_ok=True) \n    network_table.to_perseus(path.join(folder, 'networks.txt'), main_columns=[])\n    for guid, network in networks.items():\n        network['node_table'].to_perseus(path.join(folder, '{}_nodes.txt'.format(guid)), main_columns=[])\n        network['edge_table'].to_perseus(path.join(folder, '{}_edges.txt'.format(guid)), main_columns=[])", "response": "Writes the networks to Perseus readable format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dataframe of the Homolog Gene tables.", "response": "def getHomoloGene(taxfile=\"build_inputs/taxid_taxname\",\\\n                  genefile=\"homologene.data\",\\\n                  proteinsfile=\"build_inputs/all_proteins.data\",\\\n                  proteinsclusterfile=\"build_inputs/proteins_for_clustering.data\",\\\n                  baseURL=\"http://ftp.ncbi.nih.gov/pub/HomoloGene/current/\"):\n    \"\"\"\n    Returns NBCI's Homolog Gene tables.\n\n    :param taxfile: path to local file or to baseURL/taxfile\n    :param genefile: path to local file or to baseURL/genefile\n    :param proteinsfile: path to local file or to baseURL/proteinsfile\n    :param proteinsclusterfile: path to local file or to baseURL/proteinsclusterfile\n    :param baseURL: baseURL for downloading files\n\n    :returns genedf: Homolog gene Pandas dataframe\n    :returns protclusdf: Pandas dataframe. Lists one protein per gene that were used for homologene clustering.\n                        If a gene has multiple protein accessions derived from alternative splicing,\n                        only one protein isoform that give most protein alignment to proteins in other species\n                        was selected for clustering and it is listed in this file.\n    :returns proteinsdf: Pandas dataframe. Lists all proteins and their gene information.\n                        If a gene has multple protein accessions derived from alternative splicing event,\n                        each protein accession is list in a separate line.\n    \"\"\"\n\n    def getDf(inputfile):\n        if os.path.isfile(inputfile):\n            df=pd.read_table(inputfile,header=None)\n        else:\n            df = urllib2.urlopen(baseURL+inputfile)\n            df=df.read().split(\"\\n\")\n            df=[ s for s in df if len(s) > 0 ]\n            df=[s.split(\"\\t\") for s in df]\n            df=pd.DataFrame(df)\n        return df\n\n    taxdf=getDf(taxfile)\n    taxdf.set_index([0],inplace=True)\n    taxdi=taxdf.to_dict().get(1)\n\n    genedf=getDf(genefile)\n    genecols=[\"HID\",\"Taxonomy ID\",\"Gene ID\",\"Gene Symbol\",\"Protein gi\",\"Protein accession\"]\n    genedf.columns=genecols\n    genedf[\"organism\"]=genedf[\"Taxonomy ID\"].apply(lambda x:taxdi.get(x))\n\n    proteinsdf=getDf(proteinsfile)\n    proteinscols=[\"taxid\",\"entrez GeneID\",\"gene symbol\",\"gene description\",\"protein accession.ver\",\"mrna accession.ver\",\\\n                 \"length of protein  listed in column 5\",\"-11) contains data about gene location on the genome\",\\\n                  \"starting position of gene in 0-based coordinate\",\\\n                  \"end position of the gene in 0-based coordinate\",\"strand\",\"nucleotide gi of genomic sequence where this gene is annotated\"]\n    proteinsdf.columns=proteinscols\n    proteinsdf[\"organism\"]=proteinsdf[\"taxid\"].apply(lambda x:taxdi.get(x))\n\n    protclusdf=getDf(proteinsclusterfile)\n    protclustercols=[\"taxid\",\"entrez GeneID\",\"gene symbol\",\"gene description\",\"protein accession.ver\",\"mrna accession.ver\",\\\n                 \"length of protein  listed in column 5\",\"-11) contains data about gene location on the genome\",\\\n                  \"starting position of gene in 0-based coordinate\",\\\n                  \"end position of the gene in 0-based coordinate\",\"strand\",\"nucleotide gi of genomic sequence where this gene is annotated\"]\n    protclusdf.columns=proteinscols\n    protclusdf[\"organism\"]=protclusdf[\"taxid\"].apply(lambda x:taxdi.get(x))\n\n    return genedf, protclusdf, proteinsdf"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getFasta(opened_file, sequence_name):\n\n    lines = opened_file.readlines()\n    seq=str(\"\")\n    for i in range(0, len(lines)):\n        line = lines[i]\n        if line[0] == \">\":\n            fChr=line.split(\" \")[0].split(\"\\n\")[0]\n            fChr=fChr[1:]\n            if fChr == sequence_name:\n                s=i\n                code=['N','A','C','T','G']\n                firstbase=lines[s+1][0]\n                while firstbase in code:\n                    s=s + 1\n                    seq=seq+lines[s]\n                    firstbase=lines[s+1][0]\n\n    if len(seq)==0:\n        seq=None\n    else:\n        seq=seq.split(\"\\n\")\n        seq=\"\".join(seq)\n\n    return seq", "response": "Returns a string with the sequence of interest in the multifasta file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a sequence into a file.", "response": "def writeFasta(sequence, sequence_name, output_file):\n    \"\"\"\n    Writes a fasta sequence into a file.\n\n    :param sequence: a string with the sequence to be written\n    :param sequence_name: name of the the fasta sequence\n    :param output_file: /path/to/file.fa to be written\n\n    :returns: nothing\n    \"\"\"\n    i=0\n    f=open(output_file,'w')\n    f.write(\">\"+str(sequence_name)+\"\\n\")\n    while i <= len(sequence):\n        f.write(sequence[i:i+60]+\"\\n\")\n        i=i+60\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrewriting a specific sequence in a multifasta file while keeping the sequence header.", "response": "def rewriteFasta(sequence, sequence_name, fasta_in, fasta_out):\n    \"\"\"\n    Rewrites a specific sequence in a multifasta file while keeping the sequence header.\n\n    :param sequence: a string with the sequence to be written\n    :param sequence_name: the name of the sequence to be retrieved eg. for '>2 dna:chromosome chromosome:GRCm38:2:1:182113224:1 REF' use: sequence_name=str(2)\n    :param fasta_in: /path/to/original.fa\n    :param fasta_out: /path/to/destination.fa\n\n    :returns: nothing\n    \"\"\"\n    f=open(fasta_in, 'r+')\n    f2=open(fasta_out,'w')\n    lines = f.readlines()\n    i=0\n    while i < len(lines):\n        line = lines[i]\n        if line[0] == \">\":\n            f2.write(line)\n            fChr=line.split(\" \")[0]\n            fChr=fChr[1:]\n            if fChr == sequence_name:\n                code=['N','A','C','T','G']\n                firstbase=lines[i+1][0]\n                while firstbase in code:\n                    i=i+1\n                    firstbase=lines[i][0]\n                s=0\n                while s <= len(sequence):\n                    f2.write(sequence[s:s+60]+\"\\n\")\n                    s=s+60\n            else:\n                i=i+1\n        else:\n            f2.write(line)\n            i=i+1\n\n    f2.close\n    f.close"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_tool_str(self, tool):\n        res = tool['file'] \n        try:\n            res += '.' + tool['function']\n        except Exception as ex:\n            print('Warning - no function defined for tool ' + str(tool))\n        res += '\\n'\n        return res", "response": "get a string representation of the tool"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the tool object by name or file", "response": "def get_tool_by_name(self, nme):\n        \"\"\"\n        get the tool object by name or file\n        \"\"\"\n        for t in self.lstTools:\n            if 'name' in t:\n                if t['name'] == nme:\n                    return t\n            if 'file' in t:\n                if t['file'] == nme:\n                    return t\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, tool):\n        self.lstTools.append(tool)\n        self.lg.record_process(self._get_tool_str(tool))", "response": "Adds a Tool to the list logs the reference and TODO\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, fname=''):\n        if fname != '':\n            with open(fname, 'w') as f:\n                for t in self.lstTools:\n                    self.verify(t)\n                    f.write(self.tool_as_string(t))", "response": "Save the list of tools to AIKIF core and optionally to local file fname"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the tool exists", "response": "def verify(self, tool):\n        \"\"\"\n        check that the tool exists\n        \"\"\"\n        if os.path.isfile(tool['file']):\n            print('Toolbox: program exists = TOK  :: ' + tool['file'])\n            return True\n        else:\n            print('Toolbox: program exists = FAIL :: ' + tool['file'])\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, tool, args, new_import_path=''):\n        if new_import_path != '':\n            #print('APPENDING PATH = ', new_import_path)\n            sys.path.append(new_import_path)\n        \n        #if silent == 'N':\n        print('main called ' + tool['file'] + '->' + tool['function'] + ' with ', args, ' = ', tool['return'])\n        mod = __import__( os.path.basename(tool['file']).split('.')[0]) # for absolute folder names\n        # mod = __import__( tool['file'][:-2]) # for aikif folders (doesnt work)\n        func = getattr(mod, tool['function'])\n        tool['return'] = func(args)\n        return tool['return']", "response": "import the tool and call the function passing the args."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a pipeline document.", "response": "def validate_document(self, definition):\n        \"\"\"\n        Validate given pipeline document.\n\n        The method is trying to load, parse and validate the spline document.\n        The validator verifies the Python structure B{not} the file format.\n\n        Args:\n            definition (str): path and filename of a yaml file containing a valid spline definition.\n\n        Returns:\n            dict: loaded and validated spline document.\n\n        Note:\n            if validation fails the application does exit!\n\n        See Also:\n            spline.validation.Validator\n        \"\"\"\n        initial_document = {}\n        try:\n            initial_document = Loader.load(definition)\n        except RuntimeError as exception:\n            self.logger.error(str(exception))\n            sys.exit(1)\n\n        document = Validator().validate(initial_document)\n        if document is None:\n            self.logger.info(\"Schema validation for '%s' has failed\", definition)\n            sys.exit(1)\n        self.logger.info(\"Schema validation for '%s' succeeded\", definition)\n        return document"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a pipeline via a matrix.", "response": "def run_matrix(self, matrix_definition, document):\n        \"\"\"\n        Running pipeline via a matrix.\n\n        Args:\n            matrix_definition (dict): one concrete matrix item.\n            document (dict): spline document (complete) as loaded from yaml file.\n        \"\"\"\n        matrix = Matrix(matrix_definition, 'matrix(parallel)' in document)\n\n        process_data = MatrixProcessData()\n        process_data.options = self.options\n        process_data.pipeline = document['pipeline']\n        process_data.model = {} if 'model' not in document else document['model']\n        process_data.hooks = Hooks(document)\n\n        return matrix.process(process_data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef provide_temporary_scripts_path(self):\n        if len(self.options.temporary_scripts_path) > 0:\n            if os.path.isfile(self.options.temporary_scripts_path):\n                self.logger.error(\"Error: configured script path seems to be a file!\")\n                # it's ok to leave because called before the collector runs\n                sys.exit(1)\n\n            if not os.path.isdir(self.options.temporary_scripts_path):\n                os.makedirs(self.options.temporary_scripts_path)", "response": "When configured to ensure that the temporary scripts path exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates and run collector process for report data.", "response": "def create_and_run_collector(document, options):\n        \"\"\"Create and run collector process for report data.\"\"\"\n        collector = None\n        if not options.report == 'off':\n            collector = Collector()\n            collector.store.configure(document)\n            Event.configure(collector_queue=collector.queue)\n            collector.start()\n        return collector"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a template with Jinja2 rendering.", "response": "def render(value, **kwargs):\n    \"\"\"\n    Use Jinja2 rendering for given text an key key/values.\n\n    Args:\n        value (str): the template to be rendered.\n        kwargs (dict): named parameters representing available variables\n                       inside the template.\n\n    >>> model = {\"message\": \"hello world 1!\"}\n    >>> rendered_text = render(\"{{model.message}}\", model=model)\n    >>> rendered_text == 'hello world 1!'\n    True\n    >>> model = {\"message\": \"hello world 2!\", \"template\": \"{{ model.message }}\"}\n    >>> rendered_text = render(\"{{ model.template|render(model=model) }}\", model=model)\n    >>> rendered_text == 'hello world 2!'\n    True\n\n    The pipeline process is all about Bash code (inside and outside Docker) and\n    autoescaping wouldn't help. Usually the pipeline runs in a isolated environment\n    and there should not be any injection from outside; that's why: nosec.\n    \"\"\"\n    try:\n        environment = Environment(autoescape=False)  # nosec\n        environment.filters['render'] = render\n        environment.filters['docker_environment'] = docker_environment\n        environment.filters['find_matrix'] = find_matrix\n        environment.filters['find_stages'] = find_stages\n        template = environment.from_string(value)\n        return template.render(**kwargs)\n    except UndefinedError as exception:\n        Logger.get_logger(__name__).error(\"render(undefined): %s\", exception)\n    except TemplateSyntaxError as exception:\n        Logger.get_logger(__name__).error(\"render(syntax error): %s\", exception)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef docker_environment(env):\n    return ' '.join(\n        [\"-e \\\"%s=%s\\\"\" % (key, value.replace(\"$\", \"\\\\$\").replace(\"\\\"\", \"\\\\\\\"\").replace(\"`\", \"\\\\`\"))\n         for key, value in env.items()])", "response": "Transform dictionary of environment variables into Docker - e parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_stages(document):\n    names = []\n    if 'pipeline' in document:\n        for entry in document['pipeline']:\n            # each entry is dictionary with one key only\n            key, _ = list(entry.items())[0]\n            if key.startswith(\"stage(\"):\n                names.append(key.replace('stage(', '').replace(')', ''))\n    return names", "response": "Find the stages in a spline document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the download location for FEH data zip file from hosted json configuration file.", "response": "def _retrieve_download_url():\n    \"\"\"\n    Retrieves download location for FEH data zip file from hosted json configuration file.\n\n    :return: URL for FEH data file\n    :rtype: str\n    \"\"\"\n    try:\n        # Try to obtain the url from the Open Hydrology json config file.\n        with urlopen(config['nrfa']['oh_json_url'], timeout=10) as f:\n            remote_config = json.loads(f.read().decode('utf-8'))\n        # This is just for testing, assuming a relative local file path starting with ./\n        if remote_config['nrfa_url'].startswith('.'):\n            remote_config['nrfa_url'] = 'file:' + pathname2url(os.path.abspath(remote_config['nrfa_url']))\n\n        # Save retrieved config data\n        _update_nrfa_metadata(remote_config)\n\n        return remote_config['nrfa_url']\n    except URLError:\n        # If that fails (for whatever reason) use the fallback constant.\n        return config['nrfa']['url']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether updated NRFA data is available.", "response": "def update_available(after_days=1):\n    \"\"\"\n    Check whether updated NRFA data is available.\n\n    :param after_days: Only check if not checked previously since a certain number of days ago\n    :type after_days: float\n    :return: `True` if update available, `False` if not, `None` if remote location cannot be reached.\n    :rtype: bool or None\n    \"\"\"\n    never_downloaded = not bool(config.get('nrfa', 'downloaded_on', fallback=None) or None)\n    if never_downloaded:\n        config.set_datetime('nrfa', 'update_checked_on', datetime.utcnow())\n        config.save()\n        return True\n\n    last_checked_on = config.get_datetime('nrfa', 'update_checked_on', fallback=None) or datetime.fromtimestamp(0)\n    if datetime.utcnow() < last_checked_on + timedelta(days=after_days):\n        return False\n\n    current_version = LooseVersion(config.get('nrfa', 'version', fallback='0') or '0')\n    try:\n        with urlopen(config['nrfa']['oh_json_url'], timeout=10) as f:\n            remote_version = LooseVersion(json.loads(f.read().decode('utf-8'))['nrfa_version'])\n        config.set_datetime('nrfa', 'update_checked_on', datetime.utcnow())\n        config.save()\n        return remote_version > current_version\n    except URLError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads complete station dataset including catchment descriptors and amax records and saves it into a cache folder.", "response": "def download_data():\n    \"\"\"\n    Downloads complete station dataset including catchment descriptors and amax records. And saves it into a cache\n    folder.\n    \"\"\"\n    with urlopen(_retrieve_download_url()) as f:\n        with open(os.path.join(CACHE_FOLDER, CACHE_ZIP), \"wb\") as local_file:\n            local_file.write(f.read())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_nrfa_metadata(remote_config):\n    config['nrfa']['oh_json_url'] = remote_config['nrfa_oh_json_url']\n    config['nrfa']['version'] = remote_config['nrfa_version']\n    config['nrfa']['url'] = remote_config['nrfa_url']\n    config.set_datetime('nrfa', 'published_on', datetime.utcfromtimestamp(remote_config['nrfa_published_on']))\n    config.set_datetime('nrfa', 'downloaded_on', datetime.utcnow())\n    config.set_datetime('nrfa', 'update_checked_on', datetime.utcnow())\n    config.save()", "response": "Update NRFA metadata in local config file using retrieved config data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning metadata on the NRFA data.", "response": "def nrfa_metadata():\n    \"\"\"\n    Return metadata on the NRFA data.\n\n    Returned metadata is a dict with the following elements:\n\n    - `url`: string with NRFA data download URL\n    - `version`: string with NRFA version number, e.g. '3.3.4'\n    - `published_on`: datetime of data release/publication (only month and year are accurate, rest should be ignored)\n    - `downloaded_on`: datetime of last download\n\n    :return: metadata\n    :rtype: dict\n    \"\"\"\n    result = {\n        'url': config.get('nrfa', 'url', fallback=None) or None,  # Empty strings '' become None\n        'version': config.get('nrfa', 'version', fallback=None) or None,\n        'published_on': config.get_datetime('nrfa', 'published_on', fallback=None) or None,\n        'downloaded_on': config.get_datetime('nrfa', 'downloaded_on', fallback=None) or None\n    }\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts all files from downloaded FEH data zip file.", "response": "def unzip_data():\n    \"\"\"\n    Extract all files from downloaded FEH data zip file.\n    \"\"\"\n    with ZipFile(os.path.join(CACHE_FOLDER, CACHE_ZIP), 'r') as zf:\n        zf.extractall(path=CACHE_FOLDER)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all annual maximum flow files in cache folder and sub folders.", "response": "def amax_files():\n    \"\"\"\n    Return all annual maximum flow (`*.am`) files in cache folder and sub folders.\n\n    :return: List of file paths\n    :rtype: list\n    \"\"\"\n    return [os.path.join(dp, f) for dp, dn, filenames in os.walk(CACHE_FOLDER)\n            for f in filenames if os.path.splitext(f)[1].lower() == '.am']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_xml_stats(fname):\n    f = mod_file.TextFile(fname)\n    res = {}\n    res['shortname'] = f.name\n    res['folder'] = f.path\n    res['filesize'] = str(f.size) + ' bytes'\n    res['num_lines'] = str(f.lines) + ' lines'\n    res['date_modified'] = f.GetDateAsString(f.date_modified)\n    \n    return res", "response": "Returns a dictionary of statistics about an \n XML file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a random xml file only for testing the xml_split", "response": "def make_random_xml_file(fname, num_elements=200, depth=3):\n    \"\"\"\n    makes a random xml file mainly for testing the xml_split\n    \"\"\"\n    with open(fname, 'w') as f:\n        f.write('<?xml version=\"1.0\" ?>\\n<random>\\n')\n        for dep_num, _ in enumerate(range(1,depth)):\n            f.write(' <depth>\\n  <content>\\n')\n            #f.write('<depth' + str(dep_num) + '>\\n')\n            for num, _ in enumerate(range(1, num_elements)):\n                f.write('    <stuff>data line ' + str(num) + '</stuff>\\n')\n            #f.write('</depth' + str(dep_num) + '>\\n')\n            f.write('  </content>\\n </depth>\\n')\n    \n        f.write('</random>\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn ( 511 35082 ) for ANC__WhereToHongKong. xml returns ( 511 35082 ) for ANC__WhereToHongKong. xml returns ( 35082 ) for ANC__WhereToHongKong. xml returns ( 511 35082 ) for ANC__WhereToHongKong. xml returns ( 511 35082 ) for ANC__WhereToHongKong. xml", "response": "def count_elements(fname, element):\n    \"\"\"\n    returns (511, 35082) for ANC__WhereToHongKong.xml\n    \"\"\"\n    num = 0\n    tot = 0\n    for event, elem in iterparse(fname):\n        tot += 1\n        if elem.text != '':\n            #print(' tag  = ', elem.tag)\n            #print(' event  = ', event   # always end\n            #print(' text = ',  elem.text)\n            pass\n        if element in elem.tag:\n            #print(elem.xpath( 'description/text( )' ))\n            #print(elem.text)\n            num += 1\n            elem.clear()\n    return num, tot"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef organismsKEGG():\n    organisms=urlopen(\"http://rest.kegg.jp/list/organism\").read()\n    organisms=organisms.split(\"\\n\")\n    #for o in organisms:\n    #    print o\n    #    sys.stdout.flush()\n    organisms=[ s.split(\"\\t\") for s in organisms ]\n    organisms=pd.DataFrame(organisms)\n    return organisms", "response": "Lists all organisms present in the KEGG database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef databasesKEGG(organism,ens_ids):\n    all_genes=urlopen(\"http://rest.kegg.jp/list/\"+organism).read()\n    all_genes=all_genes.split(\"\\n\")\n    dbs=[]\n    while len(dbs) == 0:\n        for g in all_genes:\n            if len(dbs) == 0:\n                kid = g.split(\"\\t\")[0]\n                gene=urlopen(\"http://rest.kegg.jp/get/\"+kid).read()\n                DBLINKS=gene.split(\"\\n\")\n                DBLINKS=[ s for s in DBLINKS if \":\" in s ]\n                for d in DBLINKS:\n                    test=d.split(\" \")\n                    test=test[len(test)-1]\n                    if test in ens_ids:\n                        DBLINK=[ s for s in DBLINKS if test in s ]\n                        DBLINK=DBLINK[0].split(\":\")\n                        DBLINK=DBLINK[len(DBLINK)-2]\n                        dbs.append(DBLINK)\n            else:\n                break\n    ens_db=dbs[0].split(\" \")\n    ens_db=ens_db[len(ens_db)-1]\n    test_db=urlopen(\"http://rest.genome.jp/link/\"+ens_db+\"/\"+organism).read()\n    test_db=test_db.split(\"\\n\")\n    if len(test_db) == 1:\n        print(\"For \"+organism+\" the following db was found: \"+ens_db)\n        print(\"This database does not seem to be valid KEGG-linked database identifier\")\n        print(\"For \\n'hsa' use 'ensembl-hsa'\\n'mmu' use 'ensembl-mmu'\\n'cel' use 'EnsemblGenomes-Gn'\\n'dme' use 'FlyBase'\")\n        sys.stdout.flush()\n        ens_db = None\n    else:\n        print(\"For \"+organism+\" the following db was found: \"+ens_db)\n        sys.stdout.flush()\n    return ens_db", "response": "Finds KEGG - linked databases for a given organism given a list of ensembl ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Pandas dataframe of with KEGGid and ENSid.", "response": "def ensembl_to_kegg(organism,kegg_db):\n    \"\"\"\n    Looks up KEGG mappings of KEGG ids to ensembl ids\n\n    :param organism: an organisms as listed in organismsKEGG()\n    :param kegg_db: a matching KEGG db as reported in databasesKEGG\n\n    :returns: a Pandas dataframe of with 'KEGGid' and 'ENSid'.\n\n    \"\"\"\n    print(\"KEGG API: http://rest.genome.jp/link/\"+kegg_db+\"/\"+organism)\n    sys.stdout.flush()\n    kegg_ens=urlopen(\"http://rest.genome.jp/link/\"+kegg_db+\"/\"+organism).read()\n    kegg_ens=kegg_ens.split(\"\\n\")\n    final=[]\n    for i in kegg_ens:\n        final.append(i.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n    ens_id=pd.DataFrame(df[1].str.split(\":\").tolist())[1]\n    df=pd.concat([df,ens_id],axis=1)\n    df.columns=['KEGGid','ensDB','ENSid']\n    df=df[['KEGGid','ENSid']]\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ecs_idsKEGG(organism):\n    kegg_ec=urlopen(\"http://rest.kegg.jp/link/\"+organism+\"/enzyme\").read()\n    kegg_ec=kegg_ec.split(\"\\n\")\n    final=[]\n    for k in kegg_ec:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n    df.columns=['ec','KEGGid']\n    return df", "response": "Uses KEGG to retrieve all ids and respective ecs for a given KEGG organism"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing KEGG to retrieve all ids for a given KEGG organism", "response": "def idsKEGG(organism):\n    \"\"\"\n    Uses KEGG to retrieve all ids for a given KEGG organism\n\n    :param organism: an organism as listed in organismsKEGG()\n\n    :returns: a Pandas dataframe of with 'gene_name' and 'KEGGid'.\n\n    \"\"\"\n    ORG=urlopen(\"http://rest.kegg.jp/list/\"+organism).read()\n    ORG=ORG.split(\"\\n\")\n    final=[]\n    for k in ORG:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n    df.columns=['KEGGid','description']\n    field = pd.DataFrame(df['description'].str.split(';',1).tolist())[0]\n    field = pd.DataFrame(field)\n    df = pd.concat([df[['KEGGid']],field],axis=1)\n    df.columns=['KEGGid','gene_name']\n    df=df[['gene_name','KEGGid']]\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving all pathways for a given organism.", "response": "def pathwaysKEGG(organism):\n    \"\"\"\n    Retrieves all pathways for a given organism.\n    :param organism: an organism as listed in organismsKEGG()\n    :returns df: a Pandas dataframe with the columns 'KEGGid','pathIDs', and 'pathName'.\n    :returns df_: a Pandas dataframe with a columns for 'KEGGid', and one column for each pathway with the corresponding gene ids below\n    \"\"\"\n\n    print(\"KEGG API: http://rest.kegg.jp/list/pathway/\"+organism)\n    sys.stdout.flush()\n    kegg_paths=urlopen(\"http://rest.kegg.jp/list/pathway/\"+organism).read()\n    kegg_paths=kegg_paths.split(\"\\n\")\n    final=[]\n    for k in kegg_paths:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n    df.columns=['pathID','pathName']\n\n    print(\"KEGG API: http://rest.kegg.jp/link/\"+organism+\"/pathway/\")\n    sys.stdout.flush()\n    kegg_paths_genes=urlopen(\"http://rest.kegg.jp/link/\"+organism+\"/pathway/\").read()\n    kegg_paths_genes=kegg_paths_genes.split(\"\\n\")\n    kegg_paths_genes=[ s.split(\"\\t\") for s in kegg_paths_genes ]\n    kegg_paths_genes=pd.DataFrame(kegg_paths_genes)\n    kegg_paths_genes.columns=['pathID','KEGGid']\n    \n    df=pd.merge(kegg_paths_genes,df,on=[\"pathID\"],how=\"outer\")\n    \n    def CombineAnn(df):\n        return pd.Series(dict(KEGGid = ', '.join([ s for s in list(set(df['KEGGid']))  if str(s) != \"nan\" ] ) , \n                    pathIDs = ', '.join([ s for s in list(set(df['pathID'])) if str(s) != \"nan\" ]),\n                    pathName = ', '.join([ s for s in list(set(df['pathName'])) if str(s) != \"nan\" ] )  ) ) \n    \n    df=df.groupby('KEGGid',as_index=True).apply(CombineAnn)\n    df.reset_index(inplace=True, drop=True)\n    \n    df_=kegg_paths_genes[['KEGGid']].drop_duplicates()\n    for c in list(set(kegg_paths_genes[\"pathID\"].tolist())):\n        tmp=kegg_paths_genes[kegg_paths_genes[\"pathID\"]==c][[\"KEGGid\"]].drop_duplicates().dropna()\n        tmp.columns=[c]\n        df_=pd.merge(df_,tmp,left_on=[\"KEGGid\"],right_on=[c],how=\"outer\")\n    \n    return df, df_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a pandas dataframe with the columns ensembl_gene_id kegg_enzyme to dataframe ready for use in...", "response": "def biomaRtTOkegg(df):\n    \"\"\"\n    Transforms a pandas dataframe with the columns 'ensembl_gene_id','kegg_enzyme'\n    to dataframe ready for use in ...\n\n    :param df: a pandas dataframe with the following columns: 'ensembl_gene_id','kegg_enzyme'\n\n    :returns: a pandas dataframe with the following columns: 'ensembl_gene_id','kegg_enzyme'\n    \"\"\"\n    df=df.dropna()\n    ECcols=df.columns.tolist()\n    df.reset_index(inplace=True,drop=True)\n    # field = ECsb[['kegg_enzyme']]\n    field = pd.DataFrame(df['kegg_enzyme'].str.split('+',1).tolist())[1]\n    field = pd.DataFrame(field)\n    df=pd.concat([df[['ensembl_gene_id']],field],axis=1)\n    df.columns=ECcols\n    df.drop_duplicates(inplace=True)\n    df.reset_index(inplace=True,drop=True)\n    plus=df['kegg_enzyme'].tolist()\n    plus=[ s for s in plus if \"+\" in s ]\n    noPlus=df[~df['kegg_enzyme'].isin(plus)]\n    plus=df[df['kegg_enzyme'].isin(plus)]\n    noPlus.reset_index(inplace=True, drop=True)\n    plus.reset_index(inplace=True, drop=True)\n    for p in range(0,len(plus)):\n        enz=plus.ix[p]['kegg_enzyme']\n        enz=enz.split(\"+\")\n        enz=pd.DataFrame(enz)\n        enz.colums=['kegg_enzyme']\n        enz['ensembl_gene_id']=plus.ix[p]['kegg_enzyme']\n        noPlus=pd.concat([noPlus,enz])\n    noPlus=noPlus.drop_duplicates()\n    noPlus=noPlus[['ensembl_gene_id','kegg_enzyme']]\n    noPlus['fake']='ec:'\n    noPlus['kegg_enzyme']=noPlus['fake']+noPlus['kegg_enzyme']\n    noPlus=noPlus[['ensembl_gene_id','kegg_enzyme']]\n\n    return noPlus"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves all KEGG pathways for an organism", "response": "def expKEGG(organism,names_KEGGids):\n    \"\"\"\n    Gets all KEGG pathways for an organism\n\n    :param organism: an organism as listed in organismsKEGG()\n    :param names_KEGGids: a Pandas dataframe with the columns 'gene_name': and  'KEGGid' as reported from idsKEGG(organism) (or a subset of it).\n\n    :returns df: a Pandas dataframe with 'KEGGid','pathID(1):pathNAME(1)', 'pathID(n):pathNAME(n)'\n    :returns paths: a list of retrieved KEGG pathways\n    \"\"\"\n    #print \"KEGG API: http://rest.kegg.jp/list/pathway/\"+organism\n    #sys.stdout.flush()\n    kegg_paths=urlopen(\"http://rest.kegg.jp/list/pathway/\"+organism).read()\n    kegg_paths=kegg_paths.split(\"\\n\")\n    final=[]\n    for k in kegg_paths:\n        final.append(k.split(\"\\t\"))\n    df=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n\n    df.columns=['pathID','pathName']\n    print(\"Collecting genes for pathways\")\n    sys.stdout.flush()\n    df_pg=pd.DataFrame()\n    for i in df['pathID'].tolist():\n        print(i)\n        sys.stdout.flush()\n        path_genes=urlopen(\"http://rest.kegg.jp/link/genes/\"+i).read()\n        path_genes=path_genes.split(\"\\n\")\n        final=[]\n        for k in path_genes:\n            final.append(k.split(\"\\t\"))\n        if len(final[0]) > 1:\n            df_tmp=pd.DataFrame(final[0:len(final)-1])[[0,1]]\n            df_tmp.columns=['pathID','KEGGid']\n            df_pg=pd.concat([df_pg,df_tmp])\n    df=pd.merge(df,df_pg,on=[\"pathID\"], how=\"outer\")\n    df=df[df['KEGGid'].isin(names_KEGGids['KEGGid'].tolist())]\n    df=pd.merge(df,names_KEGGids,how='left',on=['KEGGid'])\n    df_fA=pd.DataFrame(columns=['KEGGid'])\n    paths=[]\n    for k in df[['pathID']].drop_duplicates()['pathID'].tolist():\n        df_tmp=df[df['pathID']==k]\n        pathName=df_tmp['pathName'].tolist()[0]\n        pathName=\" : \".join([k,pathName])\n        keggIDs_in_path=df_tmp[['KEGGid']].drop_duplicates()['KEGGid'].tolist()\n        a={pathName:keggIDs_in_path}\n        a=pd.DataFrame(a,index=range(len(keggIDs_in_path)))\n        a['KEGGid']=a[pathName].copy()\n        df_fA=pd.merge(df_fA,a,how='outer',on=['KEGGid'])\n        paths.append(pathName)\n\n    return df_fA, paths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Pandas dataframe with the columns for each KEGG pathway for each organism and the values for each pathways in the KEGG dataset.", "response": "def KEGGmatrix(organism, dataset, query_attributes=['ensembl_gene_id','kegg_enzyme'], host=biomart_host,links=True,dfexp=None,kegg_db=None, database=None ):\n    \"\"\"\n    Looks for all KEGG annotatios of an organism in biomart and the respective pathways in KEGG. It can also retrieve links to pathways figures with red labeled genes provided in a dataframe.\n\n    :param organism: a KEGG organism identifier\n    :param dataset: a biomaRt dataset\n    :param query_attributes: biomaRt query attributes, the name can change but the output should stay in the same order ie. 'ensembl_gene_id','kegg_enzyme'\n    :param host: biomaRt_host\n    :param links: if True, returns df_links\n    :param dfexp: a Pandas dataframe with the following columns: 'ensembl_gene_id', 'log2FC'\n    :param kegg_db: a KEGG database as recovered by the databasesKEGG function\n    :param database: a biomaRt database, depecrated, default=None.\n    :returns df: a Pandas dataframe with the 'KEGGid','pathsIDs','pathName','ensembl_gene_id','kegg_enzyme'\n    :returns df_: a matrix with a column for each KEGG pathway for a given organism and the expression values in the respective dfexp in parameter\n    :returns fullmatrix: a matrix with a column for each KEGG pathway for a given organism\n    :returns df_links: a dataframe with links for each pathway and the links in the dfexp highlighted red (if df_links.\n    \"\"\"\n    try:\n        # Get all ensembl gene ids and keeg enzyme labels from biomaRt\n        #biomaRt = importr(\"biomaRt\")\n        #ensemblMart=biomaRt.useMart(database, host=host)\n        #ensembl=biomaRt.useDataset(dataset, mart=ensemblMart)\n        #biomaRt_output=biomaRt.getBM(attributes=query_attributes,mart=ensembl)\n        #biomaRt_output = [tuple([biomaRt_output[j][i] for j in range(biomaRt_output.ncol)]) for i in range(biomaRt_output.nrow)]\n        #biomaRt_output = pd.DataFrame(biomaRt_output)\n        #biomaRt_output.columns = ['ensembl_gene_id','kegg_enzyme']\n        def QueryBioMart(dataset,attributes,host=host):\n            server = BiomartServer( host )\n            organism=server.datasets[dataset]\n            response=organism.search({'attributes':attributes})\n            response=response.content.split(\"\\n\")\n            response=[s.split(\"\\t\") for s in response ]\n            response=pd.DataFrame(response,columns=attributes)\n            return response\n        biomaRt_output=QueryBioMart(dataset,query_attributes,host=host)\n        biomaRt_output = biomaRt_output[biomaRt_output['kegg_enzyme']!='']\n        biomaRt_output.reset_index(inplace=True,drop=True)\n        biomaRt_output=biomaRtTOkegg(biomaRt_output)\n    except:\n        # Do it wiht KEGG\n        ec_KEGGid=ecs_idsKEGG(organism)\n        KEGGid_ENSid=ensembl_to_kegg(organism,kegg_db)\n        biomaRt_output=pd.merge(ec_KEGGid,KEGGid_ENSid,on=['KEGGid'],how=\"outer\")\n        biomaRt_output=biomaRt_output.drop(['KEGGid'],axis=1)\n        biomaRt_output=biomaRt_output[['ENSid','ec']]\n        biomaRt_output.columns=['ensembl_gene_id','kegg_enzyme']\n\n\n    # Gett all pathways\n    df, df_=pathwaysKEGG(organism)\n    fullmatrix=df_.copy()\n\n    # Get all KEGG ecs from KEGG\n    ecs=ecs_idsKEGG(organism)\n\n    biomaRt_output=pd.merge(biomaRt_output,ecs,left_on=['kegg_enzyme'],right_on=['ec'],how=\"outer\")\n    biomaRt_output=biomaRt_output.drop(['ec'],axis=1)\n\n    df=pd.merge(df, biomaRt_output, how=\"outer\",on=['KEGGid']).drop_duplicates()\n    df=df[df['KEGGid'].astype(str)!=\"nan\"]\n    df=df.sort_values(by=['ensembl_gene_id'])\n    #print df.head()\n    df=df.drop_duplicates(subset=['KEGGid','pathIDs','pathName','kegg_enzyme' ])\n    df=df.reset_index()\n    if not isinstance(dfexp, pd.DataFrame):\n        print(\"Returning df and fullmatrix\")\n        sys.stdout.flush()\n        return df, fullmatrix\n    else:\n        expDic=dfexp[['ensembl_gene_id','log2FC']].dropna()\n        expDic=expDic.set_index(['ensembl_gene_id'])\n        expDic=expDic.to_dict().get(\"log2FC\")\n\n        dfexp=pd.merge(biomaRt_output, dfexp, how=\"right\",on=['ensembl_gene_id'])\n\n        #expDic=dfexp[['KEGGid','log2FC']].dropna()\n        #expDic=expDic.set_index(['KEGGid'])\n        #expDic=expDic.to_dict().get(\"log2FC\")\n\n        cols=df_.columns.tolist()\n        cols=[ s for s in cols if \"KEGGid\" not in s ]\n        #for c in cols:\n        #    df_[c]=df_[c].apply(lambda x: expDic.get(x))\n\n        df_=pd.merge(dfexp,df_,on=['KEGGid'],how=\"left\")\n        df_=df_.dropna(subset=['KEGGid','ensembl_gene_id'])\n        df_=df_.sort_values(by=cols)\n\n        def get_expression(df_,col,expDic=expDic):\n            v=df_[col]\n            if str(v) != \"nan\":\n                eID=df_['ensembl_gene_id']\n                ex=expDic.get(eID)\n            else:\n                ex=v\n            return ex\n\n        for c in cols:\n            df_[c]=df_.apply(get_expression, args=(c,),axis=1)\n\n        if links==True:\n            df_links=pd.DataFrame()\n            for p in cols:\n                dfT=df_.dropna(subset=[p])\n                dfT=dfT.dropna(subset=['kegg_enzyme'])\n                print(dfT.head())\n                dfT=dfT.drop_duplicates(subset=['kegg_enzyme'])\n                if len(dfT) > 0:\n                    pathway=p.split(\":\")[1]\n                    URL=\"http://www.kegg.jp/kegg-bin/show_pathway?\"+pathway\n                    for i in dfT['kegg_enzyme'].tolist():\n                        gKEGG=i\n                        color=\"red\"\n                        text=\"/\"+gKEGG+\"%09\"+color\n                        URL=URL+text\n                    print(URL)\n                    d={\"pathway\":pathway, \"URL\":URL}\n                    d=pd.DataFrame(d,index=[0])\n                    df_links=pd.concat([df_links,d])\n            df_links.reset_index(inplace=True, drop=True)\n\n            return df, df_, fullmatrix, df_links\n\n        else:\n            return df, df_, fullmatrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists BioMart databases through a RPY2 connection.", "response": "def RdatabasesBM(host=rbiomart_host):\n    \"\"\"\n    Lists BioMart databases through a RPY2 connection.\n\n    :param host: address of the host server, default='www.ensembl.org'\n\n    :returns: nothing\n\n    \"\"\"\n    biomaRt = importr(\"biomaRt\")\n    print(biomaRt.listMarts(host=host))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists BioMart datasets through a RPY2 connection.", "response": "def RdatasetsBM(database,host=rbiomart_host):\n    \"\"\"\n    Lists BioMart datasets through a RPY2 connection.\n\n    :param database: a database listed in RdatabasesBM()\n    :param host: address of the host server, default='www.ensembl.org'\n\n    :returns: nothing\n\n    \"\"\"\n    biomaRt = importr(\"biomaRt\")\n    ensemblMart=biomaRt.useMart(database, host=host)\n    print(biomaRt.listDatasets(ensemblMart))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist BioMart filters through a RPY2 connection.", "response": "def RfiltersBM(dataset,database,host=rbiomart_host):\n    \"\"\"\n    Lists BioMart filters through a RPY2 connection.\n\n    :param dataset: a dataset listed in RdatasetsBM()\n    :param database: a database listed in RdatabasesBM()\n    :param host: address of the host server, default='www.ensembl.org'\n\n    :returns: nothing\n\n    \"\"\"\n    biomaRt = importr(\"biomaRt\")\n    ensemblMart=biomaRt.useMart(database, host=host)\n    ensembl=biomaRt.useDataset(dataset, mart=ensemblMart)\n    print(biomaRt.listFilters(ensembl))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RattributesBM(dataset,database,host=rbiomart_host):\n    biomaRt = importr(\"biomaRt\")\n    ensemblMart=biomaRt.useMart(database, host=rbiomart_host)\n    ensembl=biomaRt.useDataset(dataset, mart=ensemblMart)\n    print(biomaRt.listAttributes(ensembl))", "response": "Lists BioMart attributes through a RPY2 connection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery BioMart. :param query_filtery: one BioMart filter associated with the items being queried :param query_items: list of items to be queried (must assoiate with given filter) :param query_attributes: list of attributes to recover from BioMart :param dataset: dataset to query :param database: database to query :param host: address of the host server, default='www.ensembl.org' return: a Pandas dataframe of the queried attributes", "response": "def RqueryBM(query_filter,query_items,query_attributes,dataset,database,host=rbiomart_host):\n    \"\"\"\n    Queries BioMart.\n\n    :param query_filtery: one BioMart filter associated with the items being queried\n    :param query_items: list of items to be queried (must assoiate with given filter)\n    :param query_attributes: list of attributes to recover from BioMart\n    :param dataset: dataset to query\n    :param database: database to query\n    :param host: address of the host server, default='www.ensembl.org'\n\n    return: a Pandas dataframe of the queried attributes\n\n    \"\"\"\n\n    biomaRt = importr(\"biomaRt\")\n    ensemblMart=biomaRt.useMart(database, host=rbiomart_host)\n    ensembl=biomaRt.useDataset(dataset, mart=ensemblMart)\n    df=biomaRt.getBM(attributes=query_attributes, filters=query_filter, values=query_items, mart=ensembl)\n    output = [tuple([df[j][i] for j in range(df.ncol)]) for i in range(df.nrow)]\n    output = pd.DataFrame(output)\n    output.columns = query_attributes\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndocumenting a subset of core programs", "response": "def document_core_programs(p):\n    \"\"\"\n    Document a subset of core programs with purpose (and intent)\n    \"\"\"\n    \n    p.comment('programs.py', 'collects list of aikif programs to show progress and allows comments to be added to each file')\n    p.comment('cls_file_mapping.py', 'uses ontology to get list of files to save data')\n    p.comment('index.py', 'rebuilds indexes')\n    p.comment('dataTools.py', 'data tools to manage database access')\n    p.comment('generateTestData.py', 'Tool to generate various test data')\n    p.comment('bias.py', '[DATA] weight the validity of source data based on location, person, timing')\n    p.comment('cls_collect_files.py', 'duplicate - see agent filelist collecting')\n    p.comment('config.py', '[DATA] central point for settings in AIKIF')\n    p.comment('cls_log.py', 'logging function to map to standard outputs. Almost provides auto aggregation')\n    p.comment('mapper.py', 'maps business rules and columns of source data to standard aikif logs')\n    p.comment('search.py', 'command line search tool [deprecated, but will be redone]')\n    p.comment('tools.py', '[DATA] uses the toolbox class to create list of programs used by aikif')\n    p.comment('check_redis_limit.py', 'starts reddis database and tests limits by repeatedly adding data until it breaks')\n    p.comment('cls_data.py', 'base class for data')\n    p.comment('cls_dataset.py', 'functions for a schema table - progress = stub only')\n    p.comment('cls_datatable.py', 'functions for a single table - progress = TOK')\n    p.comment('cls_sql_code_generator.py', 'useful generation of SQL commands')\n    p.comment('world_generator.py', 'generates a 2D grid world with random terrain - land, sea, blockages')\n    p.comment('gui_view_world.py', 'script to read a saved grid from world.py and show in gui. Good for seeing grids larger than 80x25')\n    p.comment('cls_file.py', 'TOK - class for handling file details - has subclasses for test, pictures and audio')\n    p.comment('cls_goal.py', 'base class for managing goals')\n    p.comment('cls_goal_friendly.py', 'STUB - test if a goal is friendly (needs 10-40 years work to be implemented properly)')\n    p.comment('cls_goal_money.py', 'example based on cls_goal to manage money goals')\n    p.comment('cls_goal_time.py', 'example based on cls_goal to manage time goals')\n    p.comment('cls_plan.py', 'STUB only at this stage - this should provide the link from goals to toolbox (somewhat tricky to say the least)')\n    p.comment('Toolbox.py', 'class to manage the toolbox - list of programs and functions aikif can use')\n    p.comment('cls_grid.py', 'base class for 2D grid for games - 2048, game of life, 2D terrain maps')\n    p.comment('cls_grid_life.py', 'game of life game')\n    p.comment('test_tool.py', 'tesing toolbox (SHOULD BE IN TESTS)')\n    p.comment('page_about.py', 'web_aikif - generates page using flask')\n    p.comment('page_agents.py', 'web_aikif - generates page using flask')\n    p.comment('page_data.py', 'web_aikif - generates page using flask')\n    p.comment('web_aikif.py', 'web_aikif - generates page using flask')\n    p.comment('web_utils.py', 'web_aikif - generates page using flask')\n    p.comment('check_python_env.py', 'script to test imports to ensure all correct packages are available')\n    p.comment('run_tests.py', 'runs all tests in /tests subfolder')\n    p.comment('if_database.py', 'dataTools - interface base class to a database')\n    p.comment('if_mssqlserver.py', 'dataTools - interface class to a mssql database')\n    p.comment('if_oracle.py', 'dataTools - interface class to an oracle database')\n    p.comment('if_redis.py', 'dataTools - interface class to a redis database')\n\n    p.comment('agent_browser.py', 'collects data from browser - bookmarks, visited sites')\n    p.comment('outlook_export.py', 'agent to connect to outlook and export emails')\n    p.comment('run_dummy_learn_1.py', 'sample code to call a learning algorithm')\n    p.comment('cls_collect.py', 'collect filelists')\n    p.comment('cls_context.py', 'estimate what the user and PC are currently actively working on')\n    p.comment('cls_filelist.py', 'fileslist class')\n    p.comment('cls_plan_BDI.py', 'stub for planner based on belief, desire, intent')\n    p.comment('cls_plan_search.py', 'AI planner search functions')\n    p.comment('project.py', 'Core module to manage projects - meta self documentation')\n    p.comment('data_structures.py', 'Node and Graph classes')\n\n    p.comment('knowledge.py', 'processs raw data to information')\n    p.comment('core_data.py', 'classes to manage the core data types')\n    p.comment('if_excel.py', 'data interface to excel')\n    p.comment('network_tools.py', 'toolbox method to download files')\n    p.comment('AI_CLI.py', 'Command Line Interface (IN PROGRESS)')\n    p.comment('install_data.py', 'script to setup data files (IN PROGRESS)')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef document_examples(p):\n    p.comment('maths_ml_algorithms.py', 'machine learning algorithms for toolbox in AIKIF')\n    p.comment('algebra.py', 'toolbox module for based evaluation of maths problems')\n    p.comment('crypt_utils.py', 'scripts to encode / decode data')\n    p.comment('game_board_utils.py', 'board game rules')\n    p.comment('solve_knapsack.py ', 'toolbox - solves knapsack (using trivial algorithms)')\n    p.comment('example_solve_happiness.py', 'toy problem - finding a world to keep all people happy (O^n^n^n complexity :) )')\n    p.comment('finance_example.py', 'toy problem - logging finance data [TODO]')\n    p.comment('maths_fermat_brute_force.py', 'sample script to calculate long running process')\n    p.comment('puzzle_N_queens.py', 'stub only - not implemented///')\n    p.comment('puzzle_missions_canninballs.py', 'calculates the path to solve problem')\n    p.comment('solve_travelling_salesman.py', 'stub only')\n    p.comment('solve_knapsack.py', 'functions to solve the knapsack problem')\n    p.comment('load_ABS_data.py', 'old example showing how to map reading a file to the aikif')\n    p.comment('createMindOntology.py', 'script to parse website wiki page of OpenCog into a simple CSV structure')\n    p.comment('cyc_extract.py', 'script to read OpenCyc dataset and extract data (STUB only)')\n    p.comment('read_opencyc.py', 'script to read OpenCyc dataset')\n    p.comment('read_wordnet.py', 'script to read WordNet dataset')\n    p.comment('review_ontology.py', '[DATA] program to document details of ontology review')\n \n    p.comment('form_example_simple.py', 'creates a TKinter form to show how sql generation works = TOK')\n    p.comment('worlds.py', 'generates a 2d grid world')\n    p.comment('autobackup.py', 'example showing automatic file backups via filelists')\n    p.comment('document_AIKIF.py', 'this program - collect a list of programs and add commments / progress on what is actually implemented')\n    p.comment('ex_index_mydocs.py', 'example showing what to index')\n    p.comment('ex_project_management.py', 'example on using aikif for project management (poor example - needs work)')\n    p.comment('game_of_life_console.py', 'example showing a game of life = TOK')", "response": "Document examples for the AIKIF project"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef document_agents(p):\n    p.comment('agent.py', 'base agent class')\n    p.comment('run_agents.py', 'Top level function to run the agents')\n    \n    p.comment('agent_image_metadata.py', 'agent to collect file picture metadata')\n    p.comment('agent_learn_aixi.py', '')\n    p.comment('dummy_learn_1.py', 'sample (but stub only) learning algorithm to be called as test below')\n\n    p.comment('agent_explore_grid.py', 'working prototype of agent to move through a grid world, using very simple path finding.')\n    p.comment('agent_email.py', 'Agent that reads emails (currently only gmail)')\n    p.comment('agent_filelist.py', 'TOK - correctly scans and logs filelists from an agent')\n    p.comment('collect_Win_processes.py', 'script to collect windows processes. Currently not part of agent process, more an exercise on what can be logged')\n    p.comment('log_PC_usage.py', 'script to read current window title to be used as part of context to see what user is doing')\n    p.comment('log_browser_history.py', 'script to dump chrome browser history to CSV - not used')\n    p.comment('agg_context.py', 'detects context of user and computer')", "response": "A IKIF Agent Documents"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget list of applications", "response": "def get_list_of_applications():\n    \"\"\"\n    Get list of applications\n    \"\"\"\n    apps = mod_prg.Programs('Applications', 'C:\\\\apps')\n    fl = mod_fl.FileList(['C:\\\\apps'], ['*.exe'], [\"\\\\bk\\\\\"])\n    for f in fl.get_list():\n        apps.add(f, 'autogenerated list')\n    apps.list()\n    apps.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbase function for extracting a simple parameter value.", "response": "def _simple_string_value(tree, kind, name):\n    \"\"\" base function for extracting a simple parameter value.\n    :param tree: the parameters tree.\n    :param kind: the xml-tag name of the parameter.\n    :param name: the name of the parameter.\n    :returns value: the content of the parameter 'Value' as string.\"\"\"\n    query = \".//{kind}[@Name='{name}']/Value\".format(kind=kind, name=name)\n    return tree.find(query).text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef boolParam(parameters, name):\n    value = _simple_string_value(parameters, 'BoolParam', name)\n    if value not in {'true', 'false'}:\n        raise ValueError('BoolParam Value has to be either \"true\" or \"false\", was {}.'.format(value))\n    return value == 'true'", "response": "Returns the value of a boolean parameter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef singleChoiceParam(parameters, name, type_converter = str):\n    param = parameters.find(\".//SingleChoiceParam[@Name='{name}']\".format(name=name))\n    value = int(param.find('Value').text)\n    values = param.find('Values')\n    if value < 0:\n        return value\n    return type_converter(values[value].text)", "response": "returns the value of a single choice parameter. Returns - 1 if no value was chosen."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multiChoiceParam(parameters, name, type_converter = str):\n    param = parameters.find(\".//MultiChoiceParam[@Name='{name}']\".format(name=name))\n    value = param.find('Value')\n    values = param.find('Values')\n    return [type_converter(values[int(item.text)].text) for item in value.findall('Item')]", "response": "returns the value of a multi choice parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef boolWithSubParams(parameters, name):\n    param = parameters.find(\".//BoolWithSubParams[@Name='{name}']\".format(name=name))\n    str_value = param.find('Value').text\n    if str_value not in {'true', 'false'}:\n        raise ValueError('BoolParamWithSubParams Value has to be either \"true\" or \"false\", was {}'.format(str_value))\n    value = str_value == 'true'\n    choice = 'SubParamsTrue' if value else 'SubParamsFalse'\n    return value, param.find('{}/Parameters'.format(choice))", "response": "single choice with sub parameters value and chosen subparameters. Returns - 1 and None if no value was chosen. Returns - 1 and None if no value was chosen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a field to the internal configuration dictionary.", "response": "def add_field(self, name, label, field_type, *args, **kwargs):\n        \"\"\" Add the field to the internal configuration dictionary. \"\"\"\n        if name in self._dyn_fields:\n            raise AttributeError('Field already added to the form.')\n        else:\n            self._dyn_fields[name] = {'label': label, 'type': field_type,\n                                      'args': args, 'kwargs': kwargs}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_validator(self, name, validator, *args, **kwargs):\n        if name in self._dyn_fields:\n            if 'validators' in self._dyn_fields[name]:\n                self._dyn_fields[name]['validators'].append(validator)\n                self._dyn_fields[name][validator.__name__] = {}\n                if args:\n                    self._dyn_fields[name][validator.__name__]['args'] = args\n                if kwargs:\n                    self._dyn_fields[name][validator.__name__]['kwargs'] = kwargs\n            else:\n                self._dyn_fields[name]['validators'] = []\n                self.add_validator(name, validator, *args, **kwargs)\n        else:\n            raise AttributeError('Field \"{0}\" does not exist. '\n                                 'Did you forget to add it?'.format(name))", "response": "Adds the validator to the internal configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess the given WTForm Form object and the POST values.", "response": "def process(self, form, post):\n        \"\"\" Process the given WTForm Form object.\n\n        Itterate over the POST values and check each field\n        against the configuration that was made.\n\n        For each field that is valid, check all the validator\n        parameters for possible %field% replacement, then bind\n        these parameters to their validator.\n\n        Finally, add the field together with their validators\n        to the form.\n\n        :param form:\n            A valid WTForm Form object\n        :param post:\n            A MultiDict with the POST variables\n        \"\"\"\n\n        if not isinstance(form, FormMeta):\n            raise TypeError('Given form is not a valid WTForm.')\n\n        re_field_name = re.compile(r'\\%([a-zA-Z0-9_]*)\\%')\n\n        class F(form):\n            pass\n\n        for field, data in post.iteritems():\n            if field in F():\n                # Skip it if the POST field is one of the standard form fields.\n                continue\n            else:\n                if field in self._dyn_fields:\n                    # If we can find the field name directly, it means the field\n                    # is not a set so just set the canonical name and go on.\n                    field_cname = field\n                    # Since we are not in a set, (re)set the current set.\n                    current_set_number = None\n                elif (field.split('_')[-1].isdigit()\n                      and field[:-(len(field.split('_')[-1]))-1] in self._dyn_fields.keys()):\n                    # If the field can be split on underscore characters,\n                    # the last part contains only digits and the \n                    # everything *but* the last part is found in the\n                    # field configuration, we are good to go.\n                    # (Cowardly refusing to use regex here).\n                    field_cname = field[:-(len(field.split('_')[-1]))-1]\n                    # Since we apparently are in a set, remember the\n                    # the set number we are at.\n                    current_set_number = str(field.split('_')[-1])\n                else:\n                    # The field did not match to a canonical name\n                    # from the fields dictionary or the name\n                    # was malformed, throw it out.\n                    continue\n\n            # Since the field seems to be a valid one, let us\n            # prepare the validator arguments and, if we are in a set\n            # replace the %field_name% convention where we find it.\n            validators = []\n            if 'validators' in self._dyn_fields[field_cname]:\n                for validator in self._dyn_fields[field_cname]['validators']:\n                    args = []\n                    kwargs = {}\n                    if 'args' in self._dyn_fields[field_cname]\\\n                       [validator.__name__]:\n                        if not current_set_number:\n                            args = self._dyn_fields[field_cname]\\\n                                   [validator.__name__]['args']\n                        else:\n                            # If we are currently in a set, append the set number\n                            # to all the words that are decorated with %'s within\n                            # the arguments.\n                            for arg in self._dyn_fields[field_cname]\\\n                                [validator.__name__]['args']:\n                                try:\n                                    arg = re_field_name.sub(r'\\1'+'_'+current_set_number,\n                                                            arg)\n                                except:\n                                    # The argument does not seem to be regex-able\n                                    # Probably not a string, thus we can skip it.\n                                    pass\n                                args.append(arg)\n                    if 'kwargs' in self._dyn_fields[field_cname]\\\n                       [validator.__name__]:\n                        if not current_set_number:\n                            kwargs = self._dyn_fields[field_cname]\\\n                                     [validator.__name__]['kwargs']\n                        else:\n                            # If we are currently in a set, append the set number\n                            # to all the words that are decorated with %'s within\n                            # the arguments.\n                            for key, arg in self.iteritems(self._dyn_fields[field_cname]\\\n                                [validator.__name__]['kwargs']):\n                                try:\n                                    arg = re_field_name.sub(r'\\1'+'_'+current_set_number,\n                                                            arg)\n                                except:\n                                    # The argument does not seem to be regex-able\n                                    # Probably not a string, thus we can skip it.\n                                    pass\n                                kwargs[key] = arg\n                    # Finally, bind arguments to the validator\n                    # and add it to the list\n                    validators.append(validator(*args, **kwargs))\n\n            # The field is setup, it is time to add it to the form.\n            field_type = self._dyn_fields[field_cname]['type']\n            field_label = self._dyn_fields[field_cname]['label']\n            field_args = self._dyn_fields[field_cname]['args']\n            field_kwargs = self._dyn_fields[field_cname]['kwargs']\n\n            setattr(F, field, field_type(field_label,\n                                         validators=validators,\n                                         *field_args,\n                                         **field_kwargs))\n\n        # Create an instance of the form with the newly\n        # created fields and give it back to the caller.\n        if self.flask_wtf:\n            # Flask WTF overrides the form initialization\n            # and already injects the POST variables.\n            form = F()\n        else:\n            form = F(post)\n        return form"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetBEDnarrowPeakgz(URL_or_PATH_TO_file):\n\n    if os.path.isfile(URL_or_PATH_TO_file):\n        response=open(URL_or_PATH_TO_file, \"r\")\n        compressedFile = StringIO.StringIO(response.read())\n    else:\n        response = urllib2.urlopen(URL_or_PATH_TO_file)\n        compressedFile = StringIO.StringIO(response.read())\n    decompressedFile = gzip.GzipFile(fileobj=compressedFile)\n    out=decompressedFile.read().split(\"\\n\")\n    out=[ s.split(\"\\t\") for s in out]\n    out=pd.DataFrame(out)\n    out.columns=[\"chrom\",\"chromStart\",\"chromEnd\",\"name\",\"score\",\"strand\",\"signalValue\",\"-log10(pValue)\",\"-log10(qvalue)\",\"peak\"]\n    out[\"name\"]=out.index.tolist()\n    out[\"name\"]=\"Peak_\"+out[\"name\"].astype(str)\n    out=out[:-1]\n    return out", "response": "Reads a gz compressed BED narrow peak file from a web address or local file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dfTObedtool(df):\n\n    df=df.astype(str)\n    df=df.drop_duplicates()\n    df=df.values.tolist()\n    df=[\"\\t\".join(s) for s in df ]\n    df=\"\\n\".join(df)\n    df=BedTool(df, from_string=True)\n    return df", "response": "Transforms a pandas dataframe into a bedtool\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetPeaksExons(bed,parsedGTF):\n\n    bedtool_AB=dfTObedtool(bed)\n\n    exonsGTF=parsedGTF[parsedGTF[\"feature\"]==\"exon\"]\n    exonsGTF.reset_index(inplace=True, drop=True)\n\n    exonsBED=GTFtoBED(exonsGTF, \"exon_id\")\n    exonsBED.columns=['chrom', 'chromStart', 'chromEnd', 'exon_id', 'score', 'strand']\n    exonsBEDcols=exonsBED.columns.tolist()\n\n    bedcols=bed.columns.tolist()\n    exonsBEDcols_=[]\n    for c in exonsBEDcols:\n        if c in bedcols:\n            exonsBEDcols_.append(c+\"_exon\")\n        else:\n            exonsBEDcols_.append(c)\n\n    cols=[bedcols,exonsBEDcols_,[\"overlap\"] ]\n    cols=[item for sublist in cols for item in sublist]\n\n    bedtool_exons=dfTObedtool(exonsBED)\n\n    bedtool_target_exons=bedtool_AB.intersect(bedtool_exons, wo=True, s=True)\n    dfTargetE=pd.read_table(bedtool_target_exons.fn, names=cols)\n    ExonsTransGenes=parsedGTF[[\"exon_id\",\"transcript_id\",\"gene_id\"]].drop_duplicates()\n    dfTargets=pd.merge(dfTargetE,ExonsTransGenes,on=[\"exon_id\"],how=\"left\")\n    dfTargets[\"count\"]=1\n\n    def getCounts(df,field):\n        \"\"\"\n        For each field in a bed narrow peak returns the number or times that field is present,\\\n        the normalized mean of the '-log10(pValue)' and normalized mean of the signal value.\n\n        :param df: a Pandas dataframe of a bed narrow peak\n        :param field: field to analyse, ie. exons or transcripts\n\n        :returns: a Pandas dataframe\n        \"\"\"\n\n        tmp=df[[field,'name',\"count\"]].drop_duplicates()\n        tmp=tmp.drop([\"name\"],axis=1)\n        tmp[\"count\"]=tmp[\"count\"].astype(int)\n        tmp.columns=[field,\"%s_count\" %str(field)]\n        tmp=tmp.groupby(field, as_index=False).sum()\n        df=pd.merge(df,tmp,on=field,how=\"left\")\n\n        tmp=df[[field,'name',\"-log10(pValue)\"]].drop_duplicates()\n        tmp=tmp.drop([\"name\"],axis=1)\n        tmp[\"-log10(pValue)\"]=tmp[\"-log10(pValue)\"].astype(float)\n        tmp=tmp.groupby(field).apply(lambda l: reduce(lambda x, y: x*y, l[\"-log10(pValue)\"]) )\n        tmp=pd.DataFrame(tmp)\n        tmp.reset_index(inplace=True,drop=False)\n        tmp.columns=[field,\"%s norm. mean -log10(pValue)\" %str(field)]\n        df=pd.merge(df,tmp,on=field,how=\"left\")\n\n        tmp=df[[field,'name',\"signalValue\"]].drop_duplicates()\n        tmp=tmp.drop([\"name\"],axis=1)\n        tmp[\"signalValue\"]=tmp[\"signalValue\"].astype(float)\n        tmp=tmp.groupby(field).apply(lambda l: reduce(lambda x, y: x*y, l[\"signalValue\"]) )\n        tmp=pd.DataFrame(tmp)\n        tmp.reset_index(inplace=True,drop=False)\n        tmp.columns=[field,\"%s signalValue\" %str(field)]\n        df=pd.merge(df,tmp,on=field,how=\"left\")\n\n        return df\n\n    for f in [\"exon_id\",\"transcript_id\"]:\n        dfTargets=getCounts(dfTargets,f)\n\n    def getCounts_GeneIDs(df):\n        \"\"\"\n        For each gene id in a bed narrow peak returns the number or times that field is present,\\\n        the normalized mean of the '-log10(pValue)' and normalized mean of the signal value.\n\n        :param df: a Pandas dataframe of a bed narrow peak\n\n        :returns: a Pandas dataframe\n        \"\"\"\n\n        field=\"gene_id\"\n\n        tmp=df[[field,\"transcript_id\",\"transcript_id_count\"]].drop_duplicates()\n        tmp=tmp.drop([\"transcript_id\"],axis=1)\n        tmp[\"transcript_id_count\"]=tmp[\"transcript_id_count\"].astype(int)\n        tmp.columns=[field,\"%s_count\" %str(field)]\n        tmp=tmp.groupby(field, as_index=False).sum()\n        df=pd.merge(df,tmp,on=field,how=\"left\")\n\n        tmp=df[[field,'transcript_id',\"transcript_id norm. mean -log10(pValue)\"]].drop_duplicates()\n        tmp=tmp.drop([\"transcript_id\"],axis=1)\n        tmp[\"transcript_id norm. mean -log10(pValue)\"]=tmp[\"transcript_id norm. mean -log10(pValue)\"].astype(float)\n        tmp.columns=[field,\"%s norm. mean -log10(pValue)\" %str(field)]\n        tmp=tmp.groupby(field, as_index=False).sum()\n        df=pd.merge(df,tmp,on=field,how=\"left\")\n\n\n\n        tmp=df[[field,'transcript_id',\"transcript_id signalValue\"]].drop_duplicates()\n        tmp=tmp.drop([\"transcript_id\"],axis=1)\n        tmp[\"transcript_id signalValue\"]=tmp[\"transcript_id signalValue\"].astype(float)\n        tmp.columns=[field,\"%s signalValue\" %str(field)]\n        tmp=tmp.groupby(field, as_index=False).sum()\n        df=pd.merge(df,tmp,on=field,how=\"left\")\n\n        return df\n\n    dfTargets=getCounts_GeneIDs(dfTargets)\n\n\n    dfTargets=dfTargets.drop([\"count\"],axis=1)\n    return dfTargets", "response": "Returns a pandas dataframe with the number of exons in a narrow peak."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AnnotateBED(bed, GTF, genome_file, bedcols=None, promoter=[1000,200]):\n    if type(bed) == type(\"string\"):\n        bed=pd.read_table(bed,header=None)\n        bed.columns=bedcols.split(\",\")\n\n    print(\"Reading GTF file.\")\n    sys.stdout.flush()\n\n    GTF=readGTF(GTF)\n    GTF[\"gene_name\"]=retrieve_GTF_field(\"gene_name\", GTF)\n    GTF[\"gene_id\"]=retrieve_GTF_field(\"gene_id\", GTF)\n    GTF[\"gene_name\"]=GTF[\"gene_name\"]+\"/\"+GTF[\"gene_id\"]\n    GTF=GTF.drop([\"gene_id\"],axis=1)\n\n    print(\"Generating promoters annotation.\")\n    sys.stdout.flush()\n\n    promoters=GTF[GTF[\"feature\"]==\"transcript\"]\n    promoters_plus=promoters[promoters[\"strand\"]==\"+\"]\n    promoters_minus=promoters[promoters[\"strand\"]==\"-\"]\n\n    upstream=promoter[0]\n    downstream=promoter[1]\n\n    promoters_plus.loc[:,\"promoter_start\"]=promoters_plus.loc[:,\"start\"].astype(int)-upstream\n    promoters_plus.loc[:,\"promoter_end\"]=promoters_plus.loc[:,\"start\"].astype(int)+downstream\n\n    promoters_minus.loc[:,\"promoter_start\"]=promoters_minus[\"end\"].astype(int)-downstream\n    promoters_minus.loc[:,\"promoter_end\"]=promoters_minus[\"end\"].astype(int)+upstream\n\n    promoters=pd.concat([promoters_plus,promoters_minus])\n\n    promoters=promoters[[\"seqname\",\"feature\",\"promoter_start\",\"promoter_end\",\"gene_name\"]]\n    promoters.columns=[\"seqname\",\"feature\",\"start\",\"end\",\"gene_name\"]\n\n    promoters.loc[:,\"feature\"]=\"promoter\"\n    promoters.drop_duplicates(inplace=True)\n    promoters.reset_index(inplace=True, drop=True)\n\n    chr_sizes=pd.read_table(genome_file,header=None)\n    chr_sizes.columns=[\"seqname\",\"size\"]\n    chr_sizes.loc[:,\"seqname\"]=chr_sizes[\"seqname\"].astype(str)\n    promoters.loc[:,\"seqname\"]=promoters[\"seqname\"].astype(str)\n\n    promoters=pd.merge(promoters,chr_sizes,how=\"left\",on=[\"seqname\"])\n    def CorrectStart(df):\n        s=df[\"start\"]\n        if s < 0:\n            s=0\n        return s\n\n    def CorrectEnd(df):\n        s=df[\"end\"]\n        e=df[\"size\"]\n        if s > e:\n            s=e\n        return s\n\n    promoters.loc[:,\"start\"]=promoters.apply(CorrectStart,axis=1)\n    promoters.loc[:,\"end\"]=promoters.apply(CorrectEnd,axis=1)\n\n    promoters.drop([\"size\"],axis=1, inplace=True)\n\n    GTFs=GTF[[\"seqname\",\"feature\",\"start\",\"end\",\"gene_name\"]]\n    GTFs=GTFs[ GTFs[\"feature\"]!= \"gene\"]\n\n    GTFs.drop_duplicates(inplace=True)\n    GTFs.reset_index(inplace=True, drop=True)\n\n    GTFs=pd.concat([GTFs,promoters])\n\n    def NewName(df):\n        name=df[\"gene_name\"]\n        feature=df[\"feature\"]\n        if feature == \"transcript\":\n            res=name\n        else:\n            res=name+\":\"+feature\n        return res\n\n    GTFs.loc[:,\"gene_name\"]=GTFs.apply(NewName, axis=1)\n    GTFs=GTFs[[\"seqname\",\"start\",\"end\",\"gene_name\"]]\n\n    print( \"Intersecting annotation tables and bed.\" )\n    sys.stdout.flush()\n\n    refGTF=dfTObedtool(GTFs)\n    pos=dfTObedtool(bed)\n\n    colsGTF=GTFs.columns.tolist()\n    newCols=bed.columns.tolist()\n\n    for f in colsGTF:\n        newCols.append(f+\"_\")\n    newCols_=[ s for s in newCols if s not in [\"seqname_\",\"start_\", \"end_\"]]\n\n    pos=pos.intersect(refGTF, loj=True)\n    pos=pd.read_table(pos.fn , names=newCols)\n    pos=pos[newCols_]\n\n    print(\"Merging features.\")\n    sys.stdout.flush()\n\n    def GetFeature(x):\n        if \":\" in x:\n            res=x.split(\":\")[1]\n        else:\n            res=np.nan\n        return res\n\n    def GetName(x):\n        if \":\" in x:\n            res=x.split(\":\")[0]\n        elif type(x) == type(\"string\"):\n            if x != \".\":\n                res=x\n            else:\n                res=np.nan\n        else:\n            res=np.nan\n        return res\n\n    pos[\"gene_feature_\"]=pos[\"gene_name_\"].apply( lambda x: GetFeature(x) )\n    pos[\"gene_name_\"]=pos[\"gene_name_\"].apply( lambda x: GetName(x) )\n\n    refcol=pos.columns.tolist()\n    refcol=[ s for s in refcol if s != \"gene_feature_\" ]\n\n    def CombineAnn(df):\n        def JOIN(x):\n            return ', '.join([ str(s) for s in list(set(df[x]))  if str(s) != \"nan\" ] )\n        return pd.Series(dict( gene_feature_ = JOIN(\"gene_feature_\") ) )\n\n    pos_=pos.groupby(refcol).apply(CombineAnn)\n    pos_.reset_index(inplace=True, drop=False)\n\n    def MergeNameFeatures(df):\n        name=df[\"gene_name_\"]\n        feature=df[\"gene_feature_\"]\n        if (type(name) == type(\"string\")) & (name != \".\") :\n            if type(feature) == type(\"string\"):\n                if len(feature) > 0:\n                    res=name+\": \"+feature\n                else:\n                    res=name\n            else:\n                res=name\n        else:\n            res=np.nan\n        return res\n\n    pos_[\"annotated_gene_features\"]=pos_.apply(MergeNameFeatures,axis=1)\n\n    pos_=pos_.drop([\"gene_name_\",\"gene_feature_\"],axis=1)\n\n    def CombineAnn(df):\n        def JOIN(x):\n            return '; '.join([ str(s) for s in list(set(df[x]))  if str(s) != \"nan\" ] )\n        return pd.Series(dict( annotated_gene_features = JOIN(\"annotated_gene_features\") ) )\n\n    refcol=[ s for s in refcol if s != \"gene_name_\" ]\n    pos_=pos_.groupby(refcol).apply(CombineAnn)\n    pos_.reset_index(inplace=True, drop=False)\n\n    return pos_", "response": "Annotate a BED file with a promoter region."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure(**kwargs):\n        for key in kwargs:\n            if key == 'is_logging_enabled':\n                Event.is_logging_enabled = kwargs[key]\n            elif key == 'collector_queue':\n                Event.collector_queue = kwargs[key]\n            else:\n                Logger.get_logger(__name__).error(\"Unknown key %s in configure or bad type %s\",\n                                                  key, type(kwargs[key]))", "response": "Global configuration for event handling."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delegate(self, success, **kwargs):\n        if success:\n            self.succeeded(**kwargs)\n        else:\n            self.failed(**kwargs)", "response": "Delegate success or failure to the right method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfinish event as failed with optional additional information.", "response": "def failed(self, **kwargs):\n        \"\"\"Finish event as failed with optional additional information.\"\"\"\n        self.finished = datetime.now()\n        self.status = 'failed'\n        self.information.update(kwargs)\n        self.logger.info(\"Failed - took %f seconds.\", self.duration())\n        self.update_report_collector(int(time.mktime(self.finished.timetuple())))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_report_collector(self, timestamp):\n        report_enabled = 'report' in self.information and self.information['report'] == 'html'\n        report_enabled = report_enabled and 'stage' in self.information\n        report_enabled = report_enabled and Event.collector_queue is not None\n\n        if report_enabled:\n            Event.collector_queue.put(CollectorUpdate(\n                matrix=self.information['matrix'] if 'matrix' in self.information else 'default',\n                stage=self.information['stage'],\n                status=self.status,\n                timestamp=timestamp,\n                information=self.information\n            ))", "response": "Updates the report collector for the pipeline details."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_txt_to_sql(tbl_name, src_file_and_path, src_file, op_folder):\n    if op_folder == '':\n        pth = ''\n    else:\n        pth = op_folder + os.sep\n    \n    fname_create_script = pth + 'CREATE_' + tbl_name + '.SQL'\n    fname_backout_file  = pth + 'BACKOUT_' + tbl_name + '.SQL'\n    fname_control_file  = pth + tbl_name + '.CTL'\n   \n    cols = read_csv_cols_to_table_cols(src_file)\n    create_script_staging_table(fname_create_script, tbl_name, cols)    \n    create_file(fname_backout_file, 'DROP TABLE ' + tbl_name + ' CASCADE CONSTRAINTS;\\n')\n    create_CTL(fname_control_file, tbl_name, cols, 'TRUNCATE')", "response": "Loads a text file into a database and executes it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_CTL(fname, tbl_name, col_list, TRUNC_OR_APPEND, delim=','): \n    with open(fname, 'w') as ct:\n        ct.write('LOAD DATA\\n')\n        ct.write(TRUNC_OR_APPEND + '\\n')\n        ct.write('into table ' + tbl_name  + '\\n')\n        ct.write(\"fields terminated by '\" + delim + \"'\\n\")\n        ct.write('optionally Enclosed  by \\'\"\\'\\n')\n        ct.write('TRAILING NULLCOLS\\n')\n        ct.write('(\\n')\n        ct.write(',\\n'.join(c for c in col_list ))    \n        ct.write(')\\n')", "response": "Create a new control file in the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an async iterable that yields items from the given object.", "response": "async def aiter(*args):\n    \"\"\"Return an iterator object.\n\n    Args:\n        obj: An object that implements the __iter__ or __aiter__ method.\n        sentinel: An optional sentinel value to look for while iterator.\n\n    Return:\n        iterable: Some iterable that provides a __anext__ method.\n\n    Raises:\n        TypeError: If only the object is given and it is not iterable.\n        TypeError: If two arguments are given and the first is not an async\n            callable.\n\n    This function behaves very differently based on the number of arguments\n    given. If only the first argument is present the method will return\n    an async iterable that implements the __anext__ method by called the\n    given object's __aiter__. If the object does not define __aiter__ but does\n    define __iter__ then the result will be an AsyncIterWrapper that contains\n    the original iterable. This form of the function can be used to coerce all\n    iterables, async or not, into async iterables for interoperablilty.\n\n    If the second argument is given then the first argument _must_ be an async\n    callable. The returned value will still be an iterable implementing the\n    __aiter__ method, but each call to that method will call the underlying\n    async callable. If the value returned from the async callable matches the\n    sentinel value then StopAsyncIteration is raised. Otherwise the value is\n    returned.\n    \"\"\"\n    if not args:\n\n        raise TypeError('aiter() expected at least 1 arguments, got 0')\n\n    if len(args) > 2:\n\n        raise TypeError(\n            'aiter() expected at most 2 arguments, got {}'.format(len(args))\n        )\n\n    if len(args) == 2:\n\n        func, sentinel = args\n        if not isinstance(func, types.CoroutineType):\n\n            raise TypeError('aiter(v, w): v must be async callable')\n        # TODO: repeating call thing\n        raise NotImplementedError()\n\n    obj = args[0]\n    if hasattr(obj, '__anext__'):\n\n        return obj\n\n    if hasattr(obj, '__aiter__'):\n\n        return (await obj.__aiter__())\n\n    if hasattr(obj, '__iter__') or hasattr(obj, '__next__'):\n\n        return AsyncIterWrapper(iter(obj))\n\n    raise TypeError(\"'{}' object is not iterable\".format(type(args[0])))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the next item from an async iterable.", "response": "async def anext(*args):\n    \"\"\"Return the next item from an async iterator.\n\n    Args:\n        iterable: An async iterable.\n        default: An optional default value to return if the iterable is empty.\n\n    Return:\n        The next value of the iterable.\n\n    Raises:\n        TypeError: The iterable given is not async.\n\n    This function will return the next value form an async iterable. If the\n    iterable is empty the StopAsyncIteration will be propogated. However, if\n    a default value is given as a second argument the exception is silenced and\n    the default value is returned instead.\n    \"\"\"\n    if not args:\n\n        raise TypeError('anext() expected at least 1 arguments, got 0')\n\n    if len(args) > 2:\n\n        raise TypeError(\n            'anext() expected at most 2 arguments, got {}'.format(len(args))\n        )\n\n    iterable, default, has_default = args[0], None, False\n    if len(args) == 2:\n\n        iterable, default = args\n        has_default = True\n\n    try:\n\n        return await iterable.__anext__()\n\n    except StopAsyncIteration as exc:\n\n        if has_default:\n\n            return default\n\n        raise StopAsyncIteration() from exc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking an iterator that returns object over and over again.", "response": "def repeat(obj, times=None):\n    \"\"\"Make an iterator that returns object over and over again.\"\"\"\n    if times is None:\n\n        return AsyncIterWrapper(sync_itertools.repeat(obj))\n\n    return AsyncIterWrapper(sync_itertools.repeat(obj, times))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _async_callable(func):\n    if isinstance(func, types.CoroutineType):\n\n        return func\n\n    @functools.wraps(func)\n    async def _async_def_wrapper(*args, **kwargs):\n        \"\"\"Wrap a a sync callable in an async def.\"\"\"\n        return func(*args, **kwargs)\n\n    return _async_def_wrapper", "response": "Ensure the callable is an async def."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tee(iterable, n=2):\n    tees = tuple(AsyncTeeIterable(iterable) for _ in range(n))\n    for tee in tees:\n\n        tee._siblings = tees\n\n    return tees", "response": "Return n independent iterators from a single iterable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _on_change(self, obj, old, value, **kwargs):\n        kwargs['property'] = self\n        obj.emit(self.name, obj, value, old=old, **kwargs)", "response": "Called internally to emit changes from the object object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_str(self, s):\n        self.object = self.parsed_class()\n        in_section = None  # Holds name of FEH file section while traversing through file.\n        for line in s.split('\\n'):\n            if line.lower().startswith('[end]'):\n                # Leave section\n                in_section = None\n            elif line.startswith('['):\n                # Enter section, sanitise `[Section Name]` to `section_name`\n                in_section = line.strip().strip('[]').lower().replace(' ', '_')\n            elif in_section:\n                try:\n                    # Call method `_section_section_name(line)`\n                    getattr(self, '_section_' + in_section)(line.strip())\n                except AttributeError:\n                    pass  # Skip unsupported section\n        return self.object", "response": "Parse string and return relevant object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse entire file and return relevant object.", "response": "def parse(self, file_name):\n        \"\"\"\n        Parse entire file and return relevant object.\n\n        :param file_name: File path\n        :type file_name: str\n        :return: Parsed object\n        \"\"\"\n        self.object = self.parsed_class()\n        with open(file_name, encoding='utf-8') as f:\n            self.parse_str(f.read())\n        return self.object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a file and return a Parsed object.", "response": "def parse(self, file_name):\n        \"\"\"\n        Parse entire file and return a :class:`Catchment` object.\n\n        :param file_name: File path\n        :type file_name: str\n        :return: Parsed object\n        :rtype: :class:`Catchment`\n        \"\"\"\n        root = ET.parse(file_name).getroot()\n        return self._parse(root)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_str(self, s):\n        root = ET.fromstring(s)\n        return self._parse(root)", "response": "Parse a string into a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef page(self, number):\n        number = self.validate_number(number)\n        bottom = (number - 1) * self.per_page\n        top = bottom + self.per_page\n        page_items = self.object_list[bottom:top]\n        # check moved from validate_number\n        if not page_items:\n            if number == 1 and self.allow_empty_first_page:\n                pass\n            else:\n                raise EmptyPage('That page contains no results')\n        return InfinitePage(page_items, number, self)", "response": "Returns a Page object for the given 1 - based page number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef end_index(self):\n        return ((self.number - 1) * self.paginator.per_page +\n            len(self.object_list))", "response": "Returns the index of the last object on this page relative to total objects found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef page(self, number):\n        number = self.validate_number(number)\n        # remove the extra item(s) when creating the page\n        page_items = self.object_list[:self.per_page]\n        return FinitePage(page_items, number, self)", "response": "Returns a Page object for the given 1 - based page number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if there is a next item on this page.", "response": "def has_next(self):\n        \"\"\"\n        Checks for one more item than last on this page.\n        \"\"\"\n        try:\n            next_item = self.paginator.object_list[self.paginator.per_page]\n        except IndexError:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the miss and cann nodes into the two lists.", "response": "def parse_miss_cann(node, m, c):\n    \"\"\"\n    extracts names from the node to get \n    counts of miss + cann on both sides\n    \"\"\"\n    if node[2]:\n        m1 = node[0]\n        m2 = m-node[0]\n        c1 = node[1]\n        c2 = c-node[1]\n    else:\n        m1=m-node[0]\n        m2=node[0]\n        c1=c-node[1]\n        c2=node[1]\n    \n    return m1, c1, m2, c2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npicks next boat from the frontier and returns the path that is transported next", "response": "def pick_next_boat_trip(node, m, c, frontier):\n    \"\"\" \n    based on current situation, pick who\n    gets transported next, and return the path\n    NOTE - improvement here as there are often\n    duplicate paths or backtracking, e.g.\n    \"\"\"\n    next_path = []\n    cur_path = []\n    boat, mult = boat_on_left_bank(node)\n    shore = 1 - boat\n    m1, c1, m2, c2 = parse_miss_cann(node, m, c)\n    if (m1 - 1 >= c1 or m1 == 1) and (m2 + 1 >= c2) and (m1 > 0):\n        cur_path = (node[0]-mult,node[1], shore)\n        if cur_path not in frontier:\n            next_path.append(cur_path)\n\n    if (m1 >= c1-1 or m1 == 0) and (m2 -1 >= c2 or m2 == 0) and ( c1 > 0):\n        cur_path = (node[0],node[1]-mult, shore)\n        if cur_path not in frontier:\n            next_path.append(cur_path)\n        \n    if (m1 >= c1) and (m2 >= c2) and (m1 > 0) and (c1 > 0):\n        cur_path = (node[0]-mult,node[1]-mult, shore)\n        if cur_path not in frontier:\n            next_path.append(cur_path)\n        \n    if (m1 - 2 >= c1 or m1 == 2) and (m2 >= c2 or m2 == 0) and (m1 > 1):\n        cur_path = (node[0]-(mult*2),node[1], shore)\n        if cur_path not in frontier:\n            next_path.append(cur_path)\n        \n    if (m1 >= c1 - 2 or m1 == 0) and (m2 >= c2 + 2 or m2 == 0) and (c1 > 1):\n        cur_path = (node[0],node[1]-(mult*2), shore)\n        if cur_path not in frontier:\n            next_path.append(cur_path)\n\n    #print(next_path)    \n    return next_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solve(m,c):\n    G={ (m,c,1):[] }\n    frontier=[ (m,c,1) ]  # 1 as boat starts on left bank \n    while len(frontier) > 0:\n        hold=list(frontier)\n        for node in hold:\n            newnode=[]\n            frontier.remove(node)\n            newnode.extend(pick_next_boat_trip(node, m,c, frontier))\n            for neighbor in newnode:\n                if neighbor not in G:\n                    G[node].append(neighbor)\n                    G[neighbor]=[node]\n                    frontier.append(neighbor)\n    return mod_plan.find_path_BFS(G,(m,c,1),(0,0,0))", "response": "run the algorithm to find the path list of the boat in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_column_list_from_select(self, txt, col_delim=','):\n        return [c.strip().strip(',') for c in txt.split(col_delim)]", "response": "Takes a list of columns as a string and produces a lst of columns\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_script_fact(self):\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += '-- CREATE Fact Table - ' + self.fact_table + '\\n'\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += 'DROP TABLE ' + self.fact_table + ' CASCADE CONSTRAINTS;\\n'\n        self.ddl_text += 'CREATE TABLE ' + self.fact_table + ' (\\n'\n        self.ddl_text += ' '.join([col + ' VARCHAR2(200), \\n' for col in self.col_list])\n        self.ddl_text += ' ' + self.date_updated_col + ' DATE \\n' # + src_table + '; \\n'\n        self.ddl_text += ');\\n'", "response": "Creates the CREATE TABLE and index tables for the fact table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_script_staging_table(self, output_table, col_list):\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += '-- CREATE Staging Table - ' + output_table + '\\n'\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += 'DROP TABLE ' + output_table + ' CASCADE CONSTRAINTS;\\n'\n        self.ddl_text += 'CREATE TABLE ' + output_table + ' (\\n  '\n        self.ddl_text += '  '.join([col + ' VARCHAR2(200), \\n' for col in col_list])\n        self.ddl_text += '  ' + self.date_updated_col + ' DATE \\n' # + src_table + '; \\n'\n        self.ddl_text += ');\\n'", "response": "Creates the script staging table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating the internal structure of the object with the records from the staging table.", "response": "def populate_from_staging(self, staging_table, from_column_list, output_table):\n        \"\"\" \n        generate SQL to insert staging table records into\n        the core table based on column_list (If no column list\n        then insert sequentially)\n        \"\"\"\n        self.sql_text += 'INSERT INTO ' + output_table + ' (\\n'\n        for c in self.col_list:\n            if c != '':\n                self.sql_text += '    ' + c + ',\\n'\n        self.sql_text += '    ' + self.date_updated_col + ') (\\n'\n        self.sql_text += '    SELECT \\n'\n        for c in from_column_list:\n            if c != '':\n                self.sql_text += '        ' + c + ',\\n'\n        self.sql_text += '        SYSDATE \\n    FROM ' + staging_table\n        self.sql_text += '\\n);\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates all rows and sets COL to NEW_VAL", "response": "def update_old_to_new(self, col, old_val, new_val):\n        \"\"\" simply updates all rows and sets COL to NEW_VAL where col = old_val\n        e.g. update_old_to_new(\"NAME\", \"The University of Adelaide\", \"University of Adelaide\")\n        will generate\n        UPDATE table op SET op.NAME = 'University of Adelaide' WHERE op.NAME = 'The University of Adelaide';\n        \"\"\"\n        self.sql_text += \"UPDATE \" + self.fact_table + \" SET \" + col + \" = '\" + new_val + \"' WHERE \" + col + \" = '\" + old_val + \"'; \\n\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef key_to_dimension(self, fact_key, fact_join_col, dimension_name, dimension_join_col, dimension_key):\n        \n        self.sql_text += \"UPDATE \" + self.fact_table + \" op SET op.\" + fact_key + \" = NVL(\\n\"\n        self.sql_text += \"  (SELECT MAX (ip.\" + dimension_key + \")\\n\"\n        self.sql_text += \"    FROM \" + dimension_name + \" ip WHERE \"\n        self.sql_text += fact_join_col + \" = \\n       ip.\" + dimension_join_col + \"), -1); \\n\\n\"", "response": "create SQL to join a fact table with a dimension"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nselect the src_cols from src_table and groups by dim_grain then inserts into newly created table dim_name the columns as 'dim_cols", "response": "def extract_dimension(self, dim_name, dim_cols, dim_key, dim_stag_table, src_table, src_cols, grain_cols, where_clause):\n        \"\"\"\n        selects the src_cols from src_table and groups by dim_grain\n        then inserts into newly created table dim_name the columns as 'dim_cols\n        \"\"\"\n        \n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += '-- CREATE Dimension - ' + dim_name + '\\n'\n        self.ddl_text += '---------------------------------------------\\n'\n        self.ddl_text += 'DROP TABLE ' + dim_stag_table + ' CASCADE CONSTRAINTS;\\n'\n        self.ddl_text += 'CREATE TABLE ' + dim_stag_table + ' (\\n'\n        self.ddl_text += ' '.join([col + ' VARCHAR2(200), \\n' for col in dim_cols])\n        self.ddl_text += ' ' + self.date_updated_col + '  DATE \\n' # + src_table + '; \\n'\n        self.ddl_text += ');\\n'\n        \n        self.ddl_text += 'DROP TABLE ' + dim_name + ' CASCADE CONSTRAINTS;\\n'\n        self.ddl_text += 'CREATE TABLE ' + dim_name + ' (\\n'\n        self.ddl_text += ' ' + dim_key + ' NUMBER, \\n'\n        self.ddl_text += ' '.join([col + ' VARCHAR2(200), \\n' for col in dim_cols])\n        self.ddl_text += ' REC_SOURCE_SYSTEM  VARCHAR2(100), \\n' # + src_table + '; \\n'\n        self.ddl_text += ' ' + self.date_updated_col + '  DATE \\n' # + src_table + '; \\n'\n        self.ddl_text += ');\\n'\n        self.ddl_text += 'CREATE OR REPLACE VIEW U' + dim_name[1:] + ' AS SELECT * FROM ' + dim_name + ';\\n'\n        self.ddl_text += 'GRANT SELECT ON U' + dim_name[1:] + ' TO ALL_USERS;\\n'\n        self.ddl_text += '\\n'\n        self.ddl_text += 'DROP SEQUENCE SEQ_' + dim_name + ';\\n'\n        self.ddl_text += 'CREATE SEQUENCE SEQ_' + dim_name + ';\\n\\n'\n        \n        \n        self.sql_text += '---------------------------------------------\\n'\n        self.sql_text += '-- Populate Dimension - ' + dim_name + '\\n'\n        self.sql_text += '---------------------------------------------\\n'\n        self.sql_text += \"DELETE FROM \" + dim_stag_table + \";\\n\"\n        self.sql_text += \"COMMIT;\\n\"\n        self.sql_text += \"INSERT INTO \" + dim_stag_table + \" (\\n\"\n        self.sql_text += \", \".join([col for col in dim_cols])\n        self.sql_text += \")\\n (SELECT \\n\"\n        self.sql_text += \", \".join([col for col in src_cols])\n        self.sql_text += \"\\nFROM \" + src_table + \"\\n\"\n        if where_clause != '':\n            self.sql_text += \"WHERE \" + where_clause + \"\\n\"\n        if len(grain_cols) > 0:\n            self.sql_text += \"GROUP BY \" + \", \".join([col for col in grain_cols]) + \"\\n\"\n        self.sql_text += \"); \\n\"\n        self.sql_text += \"COMMIT;\\n\"\n        \n        \n        self.sql_text += \"DELETE FROM \" + dim_name + \";\\n\"\n        self.sql_text += \"COMMIT;\\n\"\n        self.sql_text += \"INSERT INTO \" + dim_name + \" (\\n\"\n        self.sql_text += \", \".join([col for col in dim_cols])\n        self.sql_text += \", REC_SOURCE_SYSTEM, \" + self.date_updated_col + \" \"\n        \n        self.sql_text += \") \\n(SELECT \\n\"\n        self.sql_text += \", \".join([col for col in src_cols])\n        self.sql_text += \", '\" + src_table + \"', sysdate \"\n        self.sql_text += \"\\nFROM \" + dim_stag_table + \"\\n\"\n        self.sql_text += \"); \\n\"\n        self.sql_text += \"COMMIT;\\n\"\n        \n        self.sql_text += \"UPDATE \" + dim_name + \" SET \" + dim_key + \" = SEQ_\" + dim_name + \".nextval;\\n\"\n        self.sql_text += \"COMMIT;\\n\\n\"\n        \n        \n        print(self.ddl_text)\n        print(self.sql_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an aggregate table grouped by col showing meas", "response": "def aggregate(self, opTable, group_by_cols, meas):\n        \"\"\" \n        Create an aggregate table grouped by col showing meas\n        The meas is something like \"sum(in)\" or \"count(*)\"\n        RETURNS:\n            DROP TABLE C_AGG_PRODUCT;\n            CREATE TABLE C_AGG_PRODUCT AS (\n                SELECT PRODUCT, sum(AMOUNT) AS result \n                FROM C_SALES GROUP BY PRODUCT\n            );\n\n        \"\"\"\n        self.sql_text += \"DROP TABLE \" + opTable + \";\\n\"\n        self.sql_text += \"CREATE TABLE \" + opTable + \" AS (\\n\"\n        self.sql_text += \"    SELECT \" + group_by_cols + \", \" + meas + \" AS result \\n\"\n        self.sql_text += \"    FROM \" + self.fact_table + \" GROUP BY \" + group_by_cols + \"\\n\"\n        self.sql_text += \");\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of distinct values from two tables.", "response": "def distinct_values(t_old, t_new):   \n    \"\"\"\n    for all columns, check which values are not in \n    the other table\n    \"\"\"\n    res = []\n    res.append([' -- NOT IN check -- '])\n    for new_col in t_new.header:\n        dist_new = t_new.get_distinct_values_from_cols([new_col])\n        #print('NEW Distinct values for ' + new_col + ' = ' + str(dist_new))\n        for old_col in t_old.header:\n            if old_col == new_col:\n                dist_old = t_old.get_distinct_values_from_cols([old_col])\n                #print('OLD Distinct values for ' + old_col + ' = ' + str(dist_old))\n                \n                # Now compare the old and new values to see what is different\n                not_in_new = [x for x in dist_old[0] if x not in dist_new[0]]\n                if not_in_new != []:\n                    #print(old_col + ' not_in_new = ' , not_in_new)\n                    res.append(['Not in New', old_col, not_in_new])\n                    \n                not_in_old = [x for x in dist_new[0] if x not in dist_old[0]]\n                if not_in_old != []:\n                    #print(new_col + ' not_in_old = ' , not_in_old)\n                    res.append(['Not in Old', new_col, not_in_old])\n                    \n                    \n    \n    return sorted(res)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aikif_web_menu(cur=''):\n    pgeHdg = ''\n    pgeBlurb = ''\n    if cur == '': \n        cur = 'Home'\n    txt = get_header(cur) #\"<div id=top_menu>\"\n    txt += '<div id = \"container\">\\n'\n    txt += '   <div id = \"header\">\\n'\n    txt += '   <!-- Banner -->\\n'\n    txt += '   <img src = \"' + os.path.join('/static','aikif_banner.jpg') + '\" alt=\"AIKIF Banner\"/>\\n'\n    txt += '   <ul id = \"menu_list\">\\n'\n    for m in menu:\n        if m[1] == cur:\n            txt += '      <LI id=\"top_menu_selected\"><a href=' + m[0] + '>' + m[1] + '</a></li>\\n'\n            pgeHdg = m[1]\n            try:\n                pgeBlurb = m[2]\n            except Exception:\n                pass\n        else:\n            txt += '      <LI id=\"top_menu\"><a href=' + m[0] + '>' + m[1] + '</a></li>\\n'\n    txt += \"    </ul>\\n    </div>\\n\\n\"\n    txt += '<H1>AIKIF ' + pgeHdg + '</H1>\\n'\n    txt += '<H4>' + pgeBlurb + '</H4>\\n'\n    return txt", "response": "returns the web page header containing standard AIKIF top level web menu"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    print(\"Generating research notes...\")\n    if os.path.exists(fname):\n       os.remove(fname)\n    append_rst('================================================\\n')\n    append_rst('Comparison of Information Aggregation Techniques\\n')\n    append_rst('================================================\\n\\n')\n    append_rst('.. contents::\\n\\n')\n       \n    # import header\n    append_rst(open('res_core_data_HEADER.rst', 'r').read())\n    append_rst(res_core_data_mthd1.get_method())\n    append_rst(res_core_data_mthd2.get_method())\n    \n    # call programs\n    append_rst('Results\\n')\n    append_rst('=====================================\\n')\n    for dat in data_files:\n        append_rst('\\nData File : ' + dat + '\\n---------------------------------------\\n\\n')\n        res_core_data_mthd1.get_results(fname, dat)\n        res_core_data_mthd2.get_results(fname, dat)\n    \n    \n    # import footer\n    append_rst(open('res_core_data_FOOTER.rst', 'r').read())    \n    print(\"Done!\")", "response": "This function generates the research document based on the results of the data files and returns the research document"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of records containing text txt", "response": "def find(self, txt):\n        \"\"\"\n        returns a list of records containing text\n        \"\"\"\n        result = []\n        for d in self.data:\n            if txt in d:\n                result.append(d)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schema_complete():\n        return Schema({\n            'stage': And(str, len),\n            'timestamp': int,\n            'status': And(str, lambda s: s in ['started', 'succeeded', 'failed']),\n            # optional matrix\n            Optional('matrix', default='default'): And(str, len),\n            # optional information\n            Optional('information', default={}): {\n                Optional(Regex(r'([a-z][_a-z]*)')): object\n            }\n        })", "response": "Schema for data in CollectorUpdate"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef schema_event_items():\n        return {\n            'timestamp': And(int, lambda n: n > 0),\n            Optional('information', default={}): {\n                Optional(Regex(r'([a-z][_a-z]*)')): object\n            }\n        }", "response": "Schema for event items."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef schema_complete():\n        return Schema({\n            'stage': And(str, len),\n            'status': And(str, lambda s: s in ['started', 'succeeded', 'failed']),\n            Optional('events', default=[]): And(len, [CollectorStage.schema_event_items()])\n        })", "response": "Schema for data in CollectorStage."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds event information. Args: timestamp (int): event timestamp. information (dict): event information. Raises: RuntimeError: when validation of parameters has failed.", "response": "def add(self, timestamp, information):\n        \"\"\"\n        Add event information.\n\n        Args:\n            timestamp (int): event timestamp.\n            information (dict): event information.\n\n        Raises:\n            RuntimeError: when validation of parameters has failed.\n        \"\"\"\n        try:\n            item = Schema(CollectorStage.schema_event_items()).validate({\n                'timestamp': timestamp, 'information': information\n            })\n            self.events.append(item)\n        except SchemaError as exception:\n            Logger.get_logger(__name__).error(exception)\n            raise RuntimeError(str(exception))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef duration(self):\n        duration = 0.0\n        if len(self.events) > 0:\n            first = datetime.fromtimestamp(self.events[0]['timestamp'])\n            last = datetime.fromtimestamp(self.events[-1]['timestamp'])\n            duration = (last - first).total_seconds()\n        return duration", "response": "Calculate how long the stage took."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the number of stages registered for given matrix name.", "response": "def count_stages(self, matrix_name):\n        \"\"\"\n        Number of registered stages for given matrix name.\n\n        Parameters:\n            matrix_name (str): name of the matrix\n\n        Returns:\n            int: number of reported stages for given matrix name.\n        \"\"\"\n        return len(self.data[matrix_name]) if matrix_name in self.data else 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the stage of a concrete matrix.", "response": "def get_stage(self, matrix_name, stage_name):\n        \"\"\"\n        Get Stage of a concrete matrix.\n\n        Attributes:\n            matrix_name (str): name of the matrix\n            stage_name (str): name of the stage.\n\n        Returns:\n            CollectorStage: when stage has been found or None.\n        \"\"\"\n        found_stage = None\n        if matrix_name in self.data:\n            result = Select(self.data[matrix_name]).where(\n                lambda entry: entry.stage == stage_name).build()\n            found_stage = result[0] if len(result) > 0 else None\n        return found_stage"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_duration(self, matrix_name):\n        duration = 0.0\n        if matrix_name in self.data:\n            duration = sum([stage.duration() for stage in self.data[matrix_name]])\n        return duration", "response": "Get the duration of a concrete matrix in seconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, item):\n        if item.matrix not in self.data:\n            self.data[item.matrix] = []\n\n        result = Select(self.data[item.matrix]).where(\n            lambda entry: entry.stage == item.stage).build()\n\n        if len(result) > 0:\n            stage = result[0]\n            stage.status = item.status\n            stage.add(item.timestamp, item.information)\n        else:\n            stage = CollectorStage(stage=item.stage, status=item.status)\n            stage.add(item.timestamp, item.information)\n            self.data[item.matrix].append(stage)", "response": "Add a collector item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying a text file in high resolution", "response": "def display_map(fname):\n    \"\"\"\n    view a text file (map) in high resolution\n    \"\"\"\n    print(\"viewing \", fname)\n    \n    wrld = read_map(fname)\n    for row in wrld:\n        #for col in row:\n        print(row)\n    app = gui_view_tk(None)\n    app.add_file(fname)\n    app.show_grid_from_file(fname)\n    app.title('Map View')\n    app.mainloop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a saved text file to list of strings", "response": "def read_map(fname):\n    \"\"\"\n    reads a saved text file to list\n    \"\"\"\n    lst = []\n    with open(fname, \"r\") as f:\n        for line in f:\n            lst.append(line)\n    return lst"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a saved grid file and paints it on the canvas", "response": "def show_grid_from_file(self, fname):\n        \"\"\"\n        reads a saved grid file and paints it on the canvas\n        \"\"\"\n        with open(fname, \"r\") as f:\n            for y, row in enumerate(f):\n                for x, val in enumerate(row):\n                    self.draw_cell(y, x, val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw_cell(self, row, col, val):\n        if val == 'T':\n            self.paint_target(row,col)\n        elif val == '#':\n            self.paint_block(row,col)\n        elif val == 'X':\n            self.paint_hill(row,col)\n        elif val == '.':\n            self.paint_land(row,col)\n        elif val in ['A']:\n            self.paint_agent_location(row,col)\n        elif val in ['1','2','3','4','5','6','7','8','9']:\n            self.paint_agent_trail(row,col, val)", "response": "draw a cell as position row col containing val"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a standard block of data.", "response": "def put_standard_block(self, y, x, val):\n        \"\"\"\n        prints a block, packing out around the y/x location\n        with pixels up to cell width and cell height\n        \"\"\"\n        for j in range(0,self.cell_height):\n            for i in range(0,self.cell_width):\n                self.img.put(val, (x*self.cell_width+i, y*self.cell_height+j))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npaints an agent trail as ONE pixel", "response": "def paint_agent_trail(self, y, x, val):\n        \"\"\"\n        paint an agent trail as ONE pixel to allow for multiple agent\n        trails to be seen in the same cell\n        \"\"\"\n        for j in range(1,self.cell_height-1):\n            for i in range(1,self.cell_width-1):\n                self.img.put(self.agent_color(val), (x*self.cell_width+i, y*self.cell_height+j))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef agent_color(self, val):\n        if val == '0': \n            colour = 'blue'\n        elif val == '1':\n            colour = 'navy'\n        elif val == '2':\n            colour = 'firebrick'\n        elif val == '3':\n            colour = 'blue'\n        elif val == '4':\n            colour = 'blue2'\n        elif val == '5':\n            colour = 'blue4'\n        elif val == '6':\n            colour = 'gray22'\n        elif val == '7':\n            colour = 'gray57'\n        elif val == '8':\n            colour = 'red4'\n        elif val == '9':\n            colour = 'red3'\n\n    \n        \n        return colour", "response": "returns a colour for an agent"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a list of people with randomly generated names and stats", "response": "def create_random_population(num=100):\n    \"\"\"\n    create a list of people with randomly generated names and stats\n    \"\"\"\n    people = []\n    for _ in range(num):\n        nme = 'blah'\n        tax_min = random.randint(1,40)/100\n        tax_max = tax_min + random.randint(1,40)/100\n        tradition = random.randint(1,100)/100\n        equity = random.randint(1,100)/100\n        pers = mod_hap_env.Person(nme, {'tax_min':tax_min, 'tax_max':tax_max, 'tradition':tradition, 'equity':equity})\n        people.append(pers)\n        print(pers)\n\n    return people"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun cleanup script of pipeline when hook is configured.", "response": "def cleanup(self):\n        \"\"\"Run cleanup script of pipeline when hook is configured.\"\"\"\n        if self.data.hooks and len(self.data.hooks.cleanup) > 0:\n            env = self.data.env_list[0].copy()\n            env.update({'PIPELINE_RESULT': 'SUCCESS', 'PIPELINE_SHELL_EXIT_CODE': '0'})\n            config = ShellConfig(script=self.data.hooks.cleanup, model=self.model,\n                                 env=env, dry_run=self.options.dry_run,\n                                 debug=self.options.debug, strict=self.options.strict,\n                                 temporary_scripts_path=self.options.temporary_scripts_path)\n            cleanup_shell = Bash(config)\n            for line in cleanup_shell.process():\n                yield line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process(self, pipeline):\n        output = []\n        for entry in pipeline:\n            key = list(entry.keys())[0]\n            # an environment block can be repeated\n            if key == \"env\":\n                self.data.env_list[0].update(entry[key])\n                self.logger.debug(\"Updating environment at level 0 with %s\",\n                                  self.data.env_list[0])\n                continue\n\n            # after validation it can't be anything else but a stage\n            # and the title is inside the round brackets:\n            stage = Stage(self, re.match(r\"stage\\((?P<title>.*)\\)\", key).group(\"title\"))\n            result = stage.process(entry[key])\n            output += result['output']\n            if not result['success']:\n                return {'success': False, 'output': output}\n\n        # logging the output of the cleanup shell when registered\n        for line in self.cleanup():\n            output.append(line)\n            self.logger.info(\" | %s\", line)\n\n        self.event.succeeded()\n        return {'success': True, 'output': output}", "response": "Processes the whole pipeline definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollects the paths of all dependencies of a single package.", "response": "def collect_dependency_paths(package_name):\n    \"\"\"\n    TODO docstrings\n    \"\"\"\n    deps = []\n    try:\n        dist = pkg_resources.get_distribution(package_name)\n    except (pkg_resources.DistributionNotFound, ValueError):\n        message = \"Distribution '{}' not found.\".format(package_name)\n        raise RequirementNotFoundError(message)\n\n    if dist.has_metadata('top_level.txt'):\n        for line in dist.get_metadata('top_level.txt').split():\n            # do not consider subpackages (e.g. the form 'package/subpackage')\n            if not os.path.split(line)[0]:\n                pkg = os.path.join(dist.location, line)\n                # handle single module packages\n                if not os.path.isdir(pkg) and os.path.exists(pkg+'.py'):\n                    pkg += '.py'\n                deps.append(pkg)\n\n    for req in dist.requires():\n        deps.extend(collect_dependency_paths(req.project_name))\n\n    return deps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_requirements_file(req_file):\n    lines = []\n    for line in req_file.readlines():\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        lines.append(line)\n    return lines", "response": "Parse a requirements file into a list of lines."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_simlinks(dest_dir, paths_list):\n    for path in paths_list:\n        dest = os.path.join(dest_dir, os.path.split(path)[-1])\n        if os.path.exists(dest):\n            if os.path.islink(dest):\n                os.remove(dest)\n            else:\n                sys.stderr.write('A file or dir named {} already exists, skipping...\\n'.format(dest))\n                continue\n        os.symlink(path, dest)", "response": "Make symlinks to the specified directories."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a command from the user", "response": "def get_command(self, mode, txt=''):\n        \"\"\"\n        Takes a raw user input, initially from command line\n        Later: \n            - check user credentials\n            - rate bias\n            - check for malicious commands\n        \"\"\"\n        if mode == 'COMMAND':\n            self.prompt = '> '\n        elif mode == 'ADD':\n            self.prompt = 'ADD > '\n        elif mode == 'QUERY':\n            self.prompt = '?? > '\n        if txt == '':\n            txt = input(self.prompt)\n        return txt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_output(self, txt, device='Console'):\n        if device == 'Console':\n            print(txt)\n        elif device == 'File':\n            raise ('show_output to File not implemented')\n        elif device == 'Function_Return':  # hacky, to run test_AI_CLI.py\n            return txt", "response": "Show the output of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntops level function to process the command, mainly depending on mode. This should work by using the function name defined in all_commamnds", "response": "def process(self, txt, mode):\n        \"\"\"\n        Top level function to process the command, mainly\n        depending on mode.\n        This should work by using the function name defined\n        in all_commamnds\n        \"\"\"\n        result = ''\n        if mode == 'ADD':  # already in add mode, so add data\n            if txt in self.all_commands['cmd'][0]:\n                self.show_output('Returning to Command mode')\n                mode = 'COMMAND'\n                self.prompt = '> '\n            else:\n                self.show_output('Adding Text : ', txt)\n                result = self.cmd_add(txt)\n        elif mode == 'QUERY':\n            if txt in self.all_commands['cmd'][0]:\n                self.show_output('Returning to Command mode')\n                mode = 'COMMAND'\n                self.prompt = '> '\n            else:\n                self.show_output('Query : ', txt)\n                result = self.cmd_query(txt)\n        else:   \n            if txt in self.all_commands['exit'][0]:\n                self.cmd_exit()\n                \n            elif txt in self.all_commands['help'][0]:\n                self.cmd_help()\n                \n            elif txt in self.all_commands['cmd'][0]:\n                result = 'Returning to Command mode'\n                mode = 'COMMAND'\n                self.prompt = '> '\n                \n            elif txt in self.all_commands['add'][0]:\n                result = 'Entering Add mode'\n                mode = 'ADD'\n                self.prompt = 'ADD > '\n            \n            elif txt in self.all_commands['query'][0]:\n                result = 'Entering Query mode'\n                mode = 'QUERY'\n                self.prompt = '?? > '\n            else:\n                result = 'Unknown command - type help for list of commands'\n\n        return result, mode"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd_add(self, txt):\n        self.show_output('Adding ', txt)\n        self.raw.add(txt)\n        print(self.raw)\n        return 'Added ' + txt", "response": "Add a new entry to the cache"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd_query(self, txt):\n        self.show_output('Searching for ', txt)\n        res = self.raw.find(txt)\n        for d in res:\n            self.show_output(d)\n        return str(len(res)) + ' results for ' + txt", "response": "search and query the AIKIF object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_shapefile(shapefilename, srid=4674):\n    # /home/nando/Desktop/IBGE/2010/55MU2500GC_SIR.shp\n    ds = DataSource(shapefilename)\n\n    is_uf = shapefilename.upper().find('UF') != -1\n\n    transform_coord = None\n    if srid != SRID:\n        transform_coord = CoordTransform(SpatialReference(srid), SpatialReference(SRID))\n\n    if is_uf:\n        model = UF\n    else:\n        model = Municipio\n\n    ct = 0\n    for f in ds[0]:\n\n        # 3D para 2D se necess\u00e1rio\n        if f.geom.coord_dim != 2:\n            f.geom.coord_dim = 2\n\n        # converte para MultiPolygon se necess\u00e1rio\n        if isinstance(f.geom, Polygon):\n            g = OGRGeometry(OGRGeomType('MultiPolygon'))\n            g.add(f.geom)\n        else:\n            g = f.geom\n\n        # transforma coordenadas se necess\u00e1rio\n        if transform_coord:\n            g.transform(transform_coord)\n\n        # for\u00e7a 2D\n        g.coord_dim = 2\n        kwargs = {}\n\n        if is_uf:\n            kwargs['nome'] = capitalize_name(unicode(f.get(CAMPO_NOME_UF), 'latin1'))\n            kwargs['geom'] = g.ewkt\n            kwargs['id_ibge'] = f.get(CAMPO_GEOCODIGO_UF)\n            kwargs['regiao'] = capitalize_name(unicode(f.get(CAMPO_REGIAO_UF), 'latin1'))\n            kwargs['uf'] = UF_SIGLAS_DICT.get(kwargs['id_ibge'])\n        else:\n            kwargs['nome'] = capitalize_name(unicode(f.get(CAMPO_NOME_MU), 'latin1'))\n            kwargs['geom'] = g.ewkt\n            kwargs['id_ibge'] = f.get(CAMPO_GEOCODIGO_MU)\n            kwargs['uf'] = UF.objects.get(pk=f.get(CAMPO_GEOCODIGO_MU)[:2])\n            kwargs['uf_sigla'] = kwargs['uf'].uf\n            kwargs['nome_abreviado'] = slugify(kwargs['nome'])\n            # tenta corrigir nomes duplicados, s\u00e3o em torno de 242 nomes repetidos\n            # adicionando a sigla do estado no final\n            if Municipio.objects.filter(nome_abreviado=kwargs['nome_abreviado']).count() > 0:\n                kwargs['nome_abreviado'] = u'%s-%s' % (kwargs['nome_abreviado'], kwargs['uf_sigla'].lower())\n\n        instance = model(**kwargs)\n        instance.save()\n\n        ct += 1\n\n    print(ct, (is_uf and \"Unidades Federativas criadas\" or \"Municipios criados\"))", "response": "Convert a shapefile to a base class"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying that all required functions have been injected.", "response": "def verify_integrity(self):\n        \"\"\"Verifies that all required functions been injected.\"\"\"\n        if not self.__integrity_check:\n            if not self.__appid:\n                raise Exception('U2F_APPID was not defined! Please define it in configuration file.')\n\n            if self.__facets_enabled and not len(self.__facets_list):\n                raise Exception(\"\"\"U2F facets been enabled, but U2F facet list is empty.\n                                   Please either disable facets by setting U2F_FACETS_ENABLED to False.\n                                   Or add facets list using, by assigning it to U2F_FACETS_LIST.\n                                \"\"\")\n\n            # Injection\n            \n            undefined_message = 'U2F {name} handler is not defined! Please import {name} through {method}!'\n\n            if not self.__get_u2f_devices:\n                raise Exception(undefined_message.format(name='Read', method='@u2f.read'))\n\n            if not self.__save_u2f_devices:\n                raise Exception(undefined_message.format(name='Save', method='@u2f.save'))\n\n\n            if not self.__call_success_enroll:\n                raise Exception(undefined_message.format(name='enroll onSuccess', method='@u2f.enroll_on_success'))\n\n            if not self.__call_success_sign:\n                raise Exception(undefined_message.format(name='sign onSuccess', method='@u2f.sign_on_success'))\n\n            self.__integrity_check = True\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsigning the user with the current user", "response": "def sign(self):\n        \"\"\"Signature function\"\"\"\n        self.verify_integrity()\n        \n        if session.get('u2f_sign_required', False):\n            if request.method == 'GET':\n                response = self.get_signature_challenge()\n\n                if response['status'] == 'ok':\n                    return jsonify(response), 200\n                else:\n                    return jsonify(response), 404\n\n            elif request.method == 'POST':\n                response = self.verify_signature(request.json)\n\n                if response['status'] == 'ok':\n                    return jsonify(response), 201\n                else:\n                    return jsonify(response), 400\n\n        return jsonify({'status': 'failed', 'error': 'Unauthorized!'}), 401"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmanage users enrolled u2f devices", "response": "def devices(self):\n        \"\"\"Manages users enrolled u2f devices\"\"\"\n        self.verify_integrity()\n\n        if session.get('u2f_device_management_authorized', False):\n            if request.method == 'GET':\n                return jsonify(self.get_devices()), 200\n\n            elif request.method == 'DELETE':\n                response = self.remove_device(request.json)\n\n                if response['status'] == 'ok':\n                    return jsonify(response), 200\n                else:\n                    return jsonify(response), 404\n\n        return jsonify({'status': 'failed', 'error': 'Unauthorized!'}), 401"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproviding facets support. REQUIRES VALID HTTPS!", "response": "def facets(self):\n        \"\"\"Provides facets support. REQUIRES VALID HTTPS!\"\"\"\n        self.verify_integrity()\n\n        if self.__facets_enabled:\n            data = json.dumps({\n                'trustedFacets' : [{\n                    'version': { 'major': 1, 'minor' : 0 },\n                    'ids': self.__facets_list\n                }]\n            }, sort_keys=True, indent=2, separators=(',', ': '))\n\n            mime = 'application/fido.trusted-apps+json'\n            resp = Response(data, mimetype=mime)\n\n            return resp, 200\n        else:\n            return jsonify({}), 404"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns new enroll seed", "response": "def get_enroll(self):\n        \"\"\"Returns new enroll seed\"\"\"\n\n        devices = [DeviceRegistration.wrap(device) for device in self.__get_u2f_devices()]\n        enroll  = start_register(self.__appid, devices)\n        enroll['status'] = 'ok'\n\n        session['_u2f_enroll_'] = enroll.json\n        return enroll"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_enroll(self, response):\n\n        seed = session.pop('_u2f_enroll_')\n        try:\n            new_device, cert = complete_register(seed, response, self.__facets_list)\n        except Exception as e:\n            if self.__call_fail_enroll:\n                self.__call_fail_enroll(e)\n\n            return {\n                'status' : 'failed', \n                'error'  : 'Invalid key handle!'\n            }\n\n        finally:\n            pass\n\n        \n\n        devices = self.__get_u2f_devices()\n\n        # Setting new device counter to 0\n        new_device['counter'] = 0\n        new_device['index']   = 0\n\n        for device in devices:\n            if new_device['index'] <= device['index']:\n                new_device['index'] = device['index'] + 1\n\n        devices.append(new_device)\n\n        self.__save_u2f_devices(devices)\n        \n        self.__call_success_enroll()\n\n        return {'status': 'ok', 'message': 'Successfully enrolled new U2F device!'}", "response": "Verifies and saves U2F enroll"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_signature_challenge(self):\n\n        devices = [DeviceRegistration.wrap(device) for device in self.__get_u2f_devices()]\n\n        if devices == []:\n            return {\n                'status' : 'failed', \n                'error'  : 'No devices been associated with the account!'\n            }\n\n        challenge = start_authenticate(devices)\n        challenge['status'] = 'ok'\n\n        session['_u2f_challenge_'] = challenge.json\n\n        return challenge", "response": "Returns new signature challenge"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_signature(self, signature):\n\n        devices   = [DeviceRegistration.wrap(device) for device in self.__get_u2f_devices()]\n        challenge = session.pop('_u2f_challenge_')\n\n        try:\n            counter, touch = verify_authenticate(devices, challenge, signature, self.__facets_list)\n        except Exception as e:\n            if self.__call_fail_sign:\n                self.__call_fail_sign(e)\n\n            return {\n                'status':'failed', \n                'error': 'Invalid signature!'\n            }\n        finally:\n            pass\n\n        if self.verify_counter(signature, counter):\n            self.__call_success_sign()\n            self.disable_sign()\n            \n            return {\n                'status'  : 'ok',\n                'counter' : counter,\n                'message': 'Successfully verified your second factor!'\n            }\n\n\n        else:\n            if self.__call_fail_sign:\n                self.__call_fail_sign()\n\n            return {\n                'status':'failed', \n                'error': 'Device clone detected!'\n            }", "response": "Verifies the signature of the current user s current user s current user s current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_device(self, request):\n        \n        devices = self.__get_u2f_devices()\n\n        for i in range(len(devices)):\n            if devices[i]['keyHandle'] == request['id']:\n                del devices[i]\n                self.__save_u2f_devices(devices)\n                \n                return {\n                    'status'  : 'ok', \n                    'message' : 'Successfully deleted your device!'\n                }\n\n        return {\n            'status' : 'failed', \n            'error'  : 'No device with such an id been found!'\n        }", "response": "Removes a device from the list of available U2F devices."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_counter(self, signature, counter):\n\n        devices = self.__get_u2f_devices()\n\n        for device in devices:\n            # Searching for specific keyhandle\n            if device['keyHandle'] == signature['keyHandle']:\n                if counter > device['counter']:\n                    \n                    # Updating counter record\n                    device['counter'] = counter\n                    self.__save_u2f_devices(devices)\n                    \n                    return True\n                else:\n                    return False", "response": "Verifies that the given counter value is greater than previous signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(data):\n        try:\n            return Schema(Validator.SCHEMA).validate(data)\n        except SchemaError as exception:\n            logging.getLogger(__name__).error(exception)\n            return None", "response": "Validate data against the schema."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninclude the defined yaml file.", "response": "def include(self, node):\n        \"\"\"Include the defined yaml file.\"\"\"\n        result = None\n        if isinstance(node, ScalarNode):\n            result = Loader.include_file(self.construct_scalar(node))\n        else:\n            raise RuntimeError(\"Not supported !include on type %s\" % type(node))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef include_file(filename):\n        if os.path.isfile(filename):\n            with open(filename) as handle:\n                return safe_load(handle)\n        raise RuntimeError(\"Include file %s doesn't exist!\" % filename)", "response": "Load another yaml file ( no recursion )."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(filename):\n        if os.path.isfile(filename):\n            with open(filename) as handle:\n                return yaml_load(handle, Loader=Loader)  # nosec\n        raise RuntimeError(\"File %s doesn't exist!\" % filename)", "response": "Load yaml file with specific include loader."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransposes rows and columns and columns of the record set", "response": "def pivot(self):\n        \"\"\"\n        transposes rows and columns\n        \"\"\"\n        self.op_data = [list(i) for i in zip(*self.ip_data)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert list to key value pairs", "response": "def key_value_pairs(self):\n        \"\"\"\n        convert list to key value pairs\n        \n        This should also create unique id's to allow for any\n        dataset to be transposed, and then later manipulated\n        r1c1,r1c2,r1c3\n        r2c1,r2c2,r2c3\n        \n        should be converted to \n        ID  COLNUM  VAL\n        r1c1, \n        \"\"\"\n        self.op_data = []\n        hdrs = self.ip_data[0]\n        for row in self.ip_data[1:]:\n            id_col = row[0]\n            for col_num, col in enumerate(row):\n                self.op_data.append([id_col, hdrs[col_num], col])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef data_to_links(self, id_col_num, link_col_num, include_links_self='Y'):\n        res = []\n        \n        # construct the header - can be done in 1 line, but clarified\n        hdr_col_name = 'Cat_name'\n        hdr_col_val = self.ip_data[0][link_col_num]  # gets the header 'Location'\n        hdr_col_base_id = self.ip_data[0][id_col_num]  # gets the header 'NAME'\n        op_hdr = [hdr_col_name,hdr_col_val,hdr_col_base_id + '_a', hdr_col_base_id + '_b','link_count']\n        \n        res.append(op_hdr)\n        \n        for row in self.ip_data[1:]:  #.sort(key=lambda x:x[id_col_num]):\n            id_col_a = row[id_col_num]\n            link_col = row[link_col_num]\n            row_cat_name = hdr_col_val   # this is replicated for this links list\n            ok_to_add = True\n            for link_row in self.ip_data[1:]:    # find all links to this\n                if link_row[link_col_num] == link_col:\n                    id_col_b = link_row[id_col_num] # get the name of the other link\n                    if id_col_a == id_col_b:\n                        ok_to_add = False\n                        \n                    # check that we aren't adding links in reverse order\n                        \n                    if ok_to_add == True:\n                        res.append([row_cat_name, link_col, id_col_a, id_col_b, 1])\n            \n            if include_links_self == 'Y': # do we add the self link?\n                res.append([row_cat_name, link_col, id_col_a, id_col_a, 0])\n        return res", "response": "This function takes a table of data conaining a person identifier and a common column containing a person identifier and a common column containing a person identifier and a common column containing a person identifier and a common column containing a person identifier. The data is sorted by the number of links in the table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the best plan for the current strategy", "response": "def find_best_plan(self):\n        \"\"\"\n        try each strategy with different amounts\n        \"\"\"\n        for plan in self.plans:\n            for strat in self.strategy:\n                self.run_plan(plan, strat)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload previously exported CSV file to redis database", "response": "def load_data(fname):\n    \"\"\" loads previously exported CSV file to redis database \"\"\"\n    print('Loading ' + fname + ' to redis')\n    r = redis.StrictRedis(host = '127.0.0.1', port = 6379, db = 0);\n    with open(fname, 'r') as f:\n        for line_num, row in enumerate(f): \n            if row.strip('') != '':\n                if line_num < 100000000:\n                    l_key, l_val = parse_n3(row, 'csv')\n                    if line_num % 1000 == 0: \n                        print('loading line #', line_num, 'key=', l_key, ' = ', l_val)\n                    if l_key != '':\n                        r.set(l_key, l_val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_n3(row, src='csv'):\n    if row.strip() == '':\n        return '',''\n    l_root = 'opencyc'\n    key = ''\n    val = ''\n    if src == 'csv': \n        cols = row.split(',')\n        if len(cols) < 3:\n            #print('PARSE ISSUE : ', row)\n            return '',''\n        key = ''\n        val = ''\n        key = l_root + ':' + cols[1].strip('\"').strip() + ':' + cols[2].strip('\"').strip()\n        try:\n            val = cols[3].strip('\"').strip()\n        except Exception:\n            val = \"Error parsing \" + row\n    elif src == 'n3':\n        pass\n    return key, val", "response": "Parses a row from an n3 file and returns the triple containing the key and value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef summarise_file_as_html(fname):\n    txt = '<H1>' + fname + '</H1>'\n    num_lines = 0\n    print('Reading OpenCyc file - ', fname)\n    with open(ip_folder + os.sep + fname, 'r') as f:\n        txt += '<PRE>'\n        for line in f: \n            if line.strip() != '':\n                num_lines += 1\n                if num_lines < 80:\n                    txt += str(num_lines) + ': ' + escape_html(line) + ''\n        txt += '</PRE>'\n        txt += 'Total lines = ' + str(num_lines) + '<BR><BR>'\n    \n    return txt", "response": "Takes a large data file and produces a HTML summary as html\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a single game of life for years and log start and end living cells to aikif", "response": "def run_game_of_life(years, width, height, time_delay, silent=\"N\"):\n    \"\"\"\n    run a single game of life for 'years' and log start and \n    end living cells to aikif\n    \"\"\"\n    lfe = mod_grid.GameOfLife(width, height, ['.', 'x'], 1)\n    set_random_starting_grid(lfe)\n    lg.record_source(lfe, 'game_of_life_console.py')\n    print(lfe)\n    start_cells = lfe.count_filled_positions()\n    for ndx, dummy_idx in enumerate(range(years)):\n        lfe.update_gol()\n        if silent == \"N\":\n            print_there(1,1, \"Game of Life - Iteration # \" + str(ndx))\n            print_there(1, 2, lfe)\n            time.sleep(time_delay)\n    end_cells = lfe.count_filled_positions()\n    return start_cells, end_cells"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a random starting grid for game of life", "response": "def set_random_starting_grid(lfe):\n    \"\"\"\n    generate a random grid for game of life using a \n    set of patterns (just to make it interesting)\n    \"\"\"\n    cls_patterns = mod_grid.GameOfLifePatterns(25)\n    print(cls_patterns)\n    exit(0)\n    \n    patterns = cls_patterns.get_patterns()\n    for pattern in patterns:\n        lfe.set_tile(pattern[0], pattern[1], 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_there(x, y, text):\n    sys.stdout.write(\"\\x1b7\\x1b[%d;%df%s\\x1b8\" % (x, y, text))\n    sys.stdout.flush()", "response": "Print text at x y."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_text_to_table(txt):\r\n\tres = []                # resulting table\r\n\tdelim = identify_delim(txt)\r\n\tprint('txt to parse = ', txt, '\\ndelim=',delim)\r\n\tif delim == '' or delim == ' ':\r\n\t\tfixed_split = identify_col_pos(txt)\r\n\t\tif fixed_split == []:\r\n\t\t\tres = []\r\n\t\telse:\r\n\t\t\tres = parse_text_by_col_pos(txt, fixed_split)\r\n\telse:\r\n\t\tres = parse_text_by_delim(txt, delim)\r\n\r\n\r\n\treturn res", "response": "Parse a text file into a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nidentifies the column position in a string.", "response": "def identify_col_pos(txt):\r\n\t\"\"\"\r\n\tassume no delimiter in this file, so guess the best\r\n\tfixed column widths to split by\r\n\t\"\"\"\r\n\tres = []\r\n\t#res.append(0)\r\n\tlines = txt.split('\\n')\r\n\tprev_ch = ''\r\n\tfor col_pos, ch in enumerate(lines[0]):\r\n\t\tif _is_white_space(ch) is False and _is_white_space(prev_ch) is True:\r\n\t\t\tres.append(col_pos)\r\n\t\tprev_ch = ch\r\n\tres.append(col_pos)\r\n\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_dict_char_count(txt):\r\n\tdct = {}\r\n\tfor letter in txt:\r\n\t\tif letter in dct:\r\n\t\t\tdct[letter] += 1\r\n\t\telse:\r\n\t\t\tdct[letter] = 1\r\n\treturn dct", "response": "Returns a dictionary with the number of characters in txt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef identify_delim(txt):\r\n\tpossible_delims = _get_dict_char_count(txt)  # {'C': 3, 'a': 4, 'b': 5, 'c': 6, ',': 6, 'A': 3, '\\n': 3, 'B': 3})\r\n\r\n\tdelim = max(possible_delims.keys(), key=(lambda k: possible_delims[k]))\r\n\r\n\t\"\"\"\r\n\tcount_by_row = []\r\n\tmax_cols = 0\r\n\tmax_rows = 0\r\n\r\n\tlines = txt.split('\\n')\r\n\tfor line in lines:\r\n\t\tif len(line) > max_cols:\r\n\t\t\tmax_cols = len(line)\r\n\t\tthis_count = _get_dict_char_count(line)\r\n\t\tcount_by_row.append(this_count)\r\n\t\tprint('line = ', line)\r\n\t\tprint('count_by_row = ', this_count)\r\n\t\tmax_rows += 1\r\n\r\n\t# make a matrix\r\n\tmatrix = [[0 for i in range(max_rows)] for j in range(max_cols)]\r\n\tpprint.pprint(matrix)\r\n\t\"\"\"\r\n\r\n\r\n\treturn delim", "response": "Identify the delimiter in a text file and return a count by ROW and the delimiter value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a fingerprint of the string txt", "response": "def fingerprint(txt):\r\n\t\"\"\"\r\n\ttakes a string and truncates to standard form for data matching.\r\n\tBased on the spec at OpenRefine\r\n\thttps://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth#fingerprint\r\n\t- remove leading and trailing whitespace\r\n\t- change all characters to their lowercase representation\r\n\t- remove all punctuation and control characters\r\n\t- split the string into whitespace-separated tokens\r\n\t- sort the tokens and remove duplicates\r\n\t- join the tokens back together\r\n\t- normalize extended western characters to their ASCII representation (for example \"g\u00f6del\" \u2192 \"godel\")\r\n\r\n\t\"\"\"\r\n\traw_text = txt.upper() #.strip(' ').replace('\\n','')\r\n\ttokens = sorted(list(set(raw_text.split(' '))))\r\n\t#print('tokens = ', tokens)\r\n\r\n\tres = ''.join([strip_nonalpha(t) for t in tokens])\r\n\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_environment_variables(self, filename):\n        self.env.update({'PIPELINE_BASH_FILE_ORIGINAL': filename})\n        filename = os.path.join('/root/scripts', os.path.basename(filename))\n        self.env.update({'PIPELINE_BASH_FILE': filename})\n\n        # remove those keys for Docker since the paths inside Docker are different\n        os_environ = os.environ.copy()\n        for remove_variable in ['PATH', 'PYTHONPATH', 'JAVA_HOME', 'HOME']:\n            os_environ.pop(remove_variable, None)\n\n        self.env.update(os_environ)", "response": "Updates OS environment variables and current script path and filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef creator(entry, config):\n        # writing Dockerfile\n        dockerfile = render(config.script, model=config.model, env=config.env,\n                            variables=config.variables, item=config.item)\n        filename = \"dockerfile.dry.run.see.comment\"\n\n        if not config.dry_run:\n            temp = tempfile.NamedTemporaryFile(\n                prefix=\"dockerfile-\", mode='w+t', delete=False)\n            temp.writelines(dockerfile)\n            temp.close()\n            filename = temp.name\n            dockerfile = ''\n\n        # rendering the Bash script for generating the Docker image\n        name = entry['name'] + \"-%s\" % os.getpid() if entry['unique'] else entry['name']\n        tag = render(entry['tag'], model=config.model, env=config.env, item=config.item)\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/docker-image.sh.j2')\n\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, name=name, tag=tag,\n                                   dockerfile_content=dockerfile,\n                                   dockerfile_filename=filename)\n\n        return Image(config)", "response": "Creator function for creating an instance of a Docker image script."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, num):\n        self.log.record_process('enviroment.py', 'Creating ' + str(num) + ' environments - ' + self.name)", "response": "Creates the environment with the given number of environments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stdout_redirector():\n    old_stdout = sys.stdout\n    sys.stdout = Stream()\n    try:\n        yield sys.stdout\n    finally:\n        sys.stdout.close()\n        sys.stdout = old_stdout", "response": "A context manager that redirects stdout to the next available log entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_temporary_file(content, prefix='', suffix=''):\n    temp = tempfile.NamedTemporaryFile(prefix=prefix, suffix=suffix, mode='w+t', delete=False)\n    temp.writelines(content)\n    temp.close()\n    return temp.name", "response": "Generates a temporary file with content."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting a new migration", "response": "def print_new(ctx, name, migration_type):\n    \"\"\"Prints filename of a new migration\"\"\"\n    click.echo(ctx.obj.repository.generate_migration_name(name, migration_type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_agent_name(self, unique_name_file):\n        agt_list = os.path.join(root_fldr, 'data', unique_name_file)\n        if os.path.exists(agt_list):\n            agents_logged = open(agt_list, 'r').read()\n        else:\n            agents_logged = ''\n        print('agents_logged = ', agents_logged)\n        if self._get_instance() not in agents_logged:\n            with open(agt_list, 'a') as f:\n                f.write(self._get_instance() + '\\n')", "response": "Logs the agent name to logfile\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        self.running = True\n        self.status = 'RUNNING'\n        self.mylog.record_process('agent', self.name + ' - starting')", "response": "Starts an agent with standard logging"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_coords(self, x=0, y=0, z=0, t=0):\n        self.coords = {}\n        self.coords['x'] = x\n        self.coords['y'] = y\n        self.coords['z'] = z\n        self.coords['t'] = t", "response": "set coords of agent in an arbitrary world"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_file(file_path, incl_pot=True):\n    filename, ext = os.path.splitext(file_path)\n    am_file_path = filename + '.AM'\n    pot_file_path = filename + '.PT'\n    parser_by_ext = {\n        '.cd3': parsers.Cd3Parser,\n        '.xml': parsers.XmlCatchmentParser\n    }\n    catchment = parser_by_ext[ext.lower()]().parse(file_path)\n\n    # AMAX records\n    try:\n        catchment.amax_records = parsers.AmaxParser().parse(am_file_path)\n    except FileNotFoundError:\n        catchment.amax_records = []\n\n    # POT records\n    if incl_pot:\n        try:\n            catchment.pot_dataset = parsers.PotParser().parse(pot_file_path)\n        except FileNotFoundError:\n            pass\n\n    return catchment", "response": "Loads a catchment from a. CD3 or. xml file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads catchment into the database.", "response": "def to_db(catchment, session, method='create', autocommit=False):\n    \"\"\"\n    Load catchment object into the database.\n\n    A catchment/station number (:attr:`catchment.id`) must be provided. If :attr:`method` is set to `update`, any\n    existing catchment in the database with the same catchment number will be updated.\n\n    :param catchment: New catchment object to replace any existing catchment in the database\n    :type catchment: :class:`.entities.Catchment`\n    :param session: Database session to use, typically `floodestimation.db.Session()`\n    :type session: :class:`sqlalchemy.orm.session.Session`\n    :param method: - ``create``: only new catchments will be loaded, it must not already exist in the database.\n                   - ``update``: any existing catchment in the database will be updated. Otherwise it will be created.\n    :type method: str\n    :param autocommit: Whether to commit the database session immediately. Default: ``False``.\n    :type autocommit: bool\n    \"\"\"\n\n    if not catchment.id:\n        raise ValueError(\"Catchment/station number (`catchment.id`) must be set.\")\n    if method == 'create':\n        session.add(catchment)\n    elif method == 'update':\n        session.merge(catchment)\n    else:\n        raise ValueError(\"Method `{}` invalid. Use either `create` or `update`.\")\n    if autocommit:\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports a folder into the database.", "response": "def folder_to_db(path, session, method='create', autocommit=False, incl_pot=True):\n    \"\"\"\n    Import an entire folder (incl. sub-folders) into the database\n\n    :param path: Folder location\n    :type path: str\n    :param session: database session to use, typically `floodestimation.db.Session()`\n    :type session: :class:`sqlalchemy.orm.session.Session`\n    :param method: - ``create``: only new catchments will be loaded, it must not already exist in the database.\n                   - ``update``: any existing catchment in the database will be updated. Otherwise it will be created.\n    :type method: str\n    :param autocommit: Whether to commit the database session immediately. Default: ``False``.\n    :type autocommit: bool\n    :param incl_pot: Whether to load the POT (peaks-over-threshold) data. Default: ``True``.\n    :type incl_pot: bool\n    \"\"\"\n    if not os.path.isdir(path):\n        raise ValueError(\"Folder `{}` does not exist or is not accesible.\".format(path))\n\n    cd3_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path)\n                 for f in filenames if os.path.splitext(f)[1].lower() == '.cd3']\n    for cd3_file_path in cd3_files:\n        catchment = from_file(cd3_file_path, incl_pot)\n        to_db(catchment, session, method)\n    if autocommit:\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nrfa_to_db(session, method='create', autocommit=False, incl_pot=True):\n\n    fehdata.clear_cache()\n    fehdata.download_data()\n    fehdata.unzip_data()\n    folder_to_db(fehdata.CACHE_FOLDER, session, method=method, autocommit=autocommit, incl_pot=incl_pot)", "response": "Downloads and saves all gauged catchments from National River\n    Flow Archive and saves them to a sqlite database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding catchments from a user folder to the database.", "response": "def userdata_to_db(session, method='update', autocommit=False):\n    \"\"\"\n    Add catchments from a user folder to the database.\n\n    The user folder is specified in the ``config.ini`` file like this::\n\n        [import]\n        folder = path/to/import/folder\n\n    If this configuration key does not exist this will be silently ignored.\n\n    :param session: database session to use, typically `floodestimation.db.Session()`\n    :type session: :class:`sqlalchemy.orm.session.Session`\n    :param method: - ``create``: only new catchments will be loaded, it must not already exist in the database.\n                   - ``update``: any existing catchment in the database will be updated. Otherwise it will be created.\n    :type method: str\n    :param autocommit: Whether to commit the database session immediately. Default: ``False``.\n    :type autocommit: bool\n    \"\"\"\n\n    try:\n        folder = config['import']['folder']\n    except KeyError:\n        return\n    if folder:\n        folder_to_db(folder, session, method=method, autocommit=autocommit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_window_by_caption(caption):\n    try:\n        hwnd = win32gui.FindWindow(None, caption)\n        return hwnd\n    except Exception as ex:\n        print('error calling win32gui.FindWindow ' + str(ex))\n        return -1", "response": "returns the handle of the window with the given caption"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends the text txt to the window handle hwnd using SendMessage", "response": "def send_text(hwnd, txt):\n    \"\"\"\n    sends the text 'txt' to the window handle hwnd using SendMessage\n    \"\"\"\n    try:\n        for c in txt:\n            if c == '\\n':\n                win32api.SendMessage(hwnd, win32con.WM_KEYDOWN, win32con.VK_RETURN, 0)\n                win32api.SendMessage(hwnd, win32con.WM_KEYUP, win32con.VK_RETURN, 0)\n            else:\n                win32api.SendMessage(hwnd, win32con.WM_CHAR, ord(c), 0)            \n    except Exception as ex:\n        print('error calling SendMessage ' + str(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef app_activate(caption):\n    try:\n        shell = win32com.client.Dispatch(\"WScript.Shell\")\n        shell.AppActivate(caption)\n    except Exception as ex:\n        print('error calling win32com.client.Dispatch (AppActivate)')", "response": "activate the application with the given caption"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_keys(key_string):\n    try:\n        shell = win32com.client.Dispatch(\"WScript.Shell\")\n        shell.SendKeys(key_string)\n    except Exception as ex:\n        print('error calling win32com.client.Dispatch (SendKeys)')", "response": "Sends the text or keys to the active application using the key_string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nearest_qmed_catchments(self, subject_catchment, limit=None, dist_limit=500):\n\n        dist_sq = Catchment.distance_to(subject_catchment).label('dist_sq')  # Distance squared, calculated using SQL\n        query = self.db_session.query(Catchment, dist_sq). \\\n            join(Catchment.amax_records). \\\n            join(Catchment.descriptors). \\\n            filter(Catchment.id != subject_catchment.id,  # Exclude subject catchment itself\n                   Catchment.is_suitable_for_qmed,  # Only catchments suitable for QMED estimation\n                   Catchment.country == subject_catchment.country,  # SQL dist method does not cover cross-boundary dist\n                   # Within the distance limit\n                   dist_sq <= dist_limit ** 2). \\\n            group_by(Catchment,\n                     Descriptors.centroid_ngr_x,\n                     Descriptors.centroid_ngr_y). \\\n            order_by(dist_sq). \\\n            having(func.count(AmaxRecord.catchment_id) >= 10)  # At least 10 AMAX records\n\n        if limit:\n            rows = query[0:limit]  # Each row is tuple of (catchment, distance squared)\n        else:\n            rows = query.all()\n\n        # Add real `dist` attribute to catchment list using previously calculated SQL dist squared\n        catchments = []\n        for row in rows:\n            catchment = row[0]\n            catchment.dist = sqrt(row[1])\n            catchments.append(catchment)\n\n        return catchments", "response": "Return a list of catchments nearest to a subject catchment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of catchments sorted by similarity distance between the given subject catchment and the most similar ones.", "response": "def most_similar_catchments(self, subject_catchment, similarity_dist_function, records_limit=500,\n                                include_subject_catchment='auto'):\n        \"\"\"\n        Return a list of catchments sorted by hydrological similarity defined by `similarity_distance_function`\n\n        :param subject_catchment: subject catchment to find similar catchments for\n        :type subject_catchment: :class:`floodestimation.entities.Catchment`\n        :param similarity_dist_function: a method returning a similarity distance measure with 2 arguments, both\n                                         :class:`floodestimation.entities.Catchment` objects\n        :param include_subject_catchment: - `auto`: include subject catchment if suitable for pooling and if urbext < 0.03\n                                          - `force`: always include subject catchment having at least 10 years of data\n                                          - `exclude`: do not include the subject catchment\n        :type include_subject_catchment: str\n        :return: list of catchments sorted by similarity\n        :type: list of :class:`floodestimation.entities.Catchment`\n        \"\"\"\n        if include_subject_catchment not in ['auto', 'force', 'exclude']:\n            raise ValueError(\"Parameter `include_subject_catchment={}` invalid.\".format(include_subject_catchment) +\n                             \"Must be one of `auto`, `force` or `exclude`.\")\n\n        query = (self.db_session.query(Catchment).\n                 join(Catchment.descriptors).\n                 join(Catchment.amax_records).\n                 filter(Catchment.id != subject_catchment.id,\n                        Catchment.is_suitable_for_pooling,\n                        or_(Descriptors.urbext2000 < 0.03, Descriptors.urbext2000 == None),\n                        AmaxRecord.flag == 0).\n                 group_by(Catchment).\n                 having(func.count(AmaxRecord.catchment_id) >= 10))  # At least 10 AMAX records\n        catchments = query.all()\n\n        # Add subject catchment if required (may not exist in database, so add after querying db\n        if include_subject_catchment == 'force':\n            if len(subject_catchment.amax_records) >= 10:  # Never include short-record catchments\n                catchments.append(subject_catchment)\n        elif include_subject_catchment == 'auto':\n            if len(subject_catchment.amax_records) >= 10 and subject_catchment.is_suitable_for_pooling and \\\n               (subject_catchment.descriptors.urbext2000 < 0.03 or subject_catchment.descriptors.urbext2000 is None):\n                catchments.append(subject_catchment)\n\n        # Store the similarity distance as an additional attribute for each catchment\n        for catchment in catchments:\n            catchment.similarity_dist = similarity_dist_function(subject_catchment, catchment)\n        # Then simply sort by this attribute\n        catchments.sort(key=attrgetter('similarity_dist'))\n\n        # Limit catchments until total amax_records counts is at least `records_limit`, default 500\n        amax_records_count = 0\n        catchments_limited = []\n        for catchment in catchments:\n            catchments_limited.append(catchment)\n            amax_records_count += catchment.record_length\n            if amax_records_count >= records_limit:\n                break\n\n        return catchments_limited"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads and parses a SAM file and returns a pandas dataframe with the respective SAM columns and the header information.", "response": "def readSAM(SAMfile,header=False):\n    \"\"\"\n    Reads and parses a sam file.\n\n    :param SAMfile: /path/to/file.sam\n    :param header: logical, if True, reads the header information\n\n    :returns: a pandas dataframe with the respective SAM columns: 'QNAME','FLAG','RNAME','POS','MAPQ','CIGAR','RNEXT','PNEXT','TLEN','SEQ','QUAL' and a list of the headers if header=True\n\n    \"\"\"\n    if header==True:\n        f=open(SAMfile,\"r+\")\n        head=[]\n        for line in f.readlines():\n            if line[0]==\"@\":\n                head.append(line)\n            else:\n                continue\n        f.close()\n\n    sam=pd.read_table(SAMfile,sep=\"this_gives_one_column\",comment=\"@\",header=None)\n    sam=pd.DataFrame(sam[0].str.split(\"\\t\").tolist())\n    acols=[0,1,2,3,4,5,6,7,8,9]\n    sam_=sam[acols]\n    samcols=sam.columns.tolist()\n    bcols=[ s for s in samcols if s not in acols ]\n    sam_[10]=sam[bcols[0]]\n    if len(bcols) > 1:\n        for c in bcols[1:]:\n            sam_[10]=sam_[10].astype(str)\n            sam[c]=sam[c].astype(str)\n            sam_[10]=sam_[10]+\"\\t\"+sam[c]\n\n    sam_.columns=['QNAME','FLAG','RNAME','POS','MAPQ','CIGAR','RNEXT','PNEXT','TLEN','SEQ','QUAL']\n\n    if header==True:\n        return sam_, head\n    else:\n        return sam_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a pandas dataframe with the respective SAM columns and the respective SAM columns into a sam file.", "response": "def writeSAM(sam,SAMfile,header=None):\n    \"\"\"\n    Writes a pandas dataframe with the respective SAM columns: 'QNAME','FLAG','RNAME','POS','MAPQ','CIGAR','RNEXT','PNEXT','TLEN','SEQ','QUAL' into a sam file\n\n    :param sam: pandas dataframe to be writen\n    :param SAMfile: /path/to/file.sam\n\n    :returns: nothing\n    \"\"\"\n    def toNone(x):\n        if x==\"None\":\n            x=np.nan\n        return x\n\n    sam.reset_index(inplace=True,drop=True)\n    QUAL=pd.DataFrame(sam['QUAL'].str.split(\"\\t\").tolist())\n    cols=QUAL.columns.tolist()\n\n    for c in cols:\n        QUAL[c]=QUAL[c].apply(lambda x: toNone(x))\n\n    sam=sam.drop(['QUAL'],axis=1)\n    sam=pd.concat([sam,QUAL],axis=1)\n    sam=sam.astype(str)\n    sam=sam.as_matrix()\n\n    tfile=open(SAMfile, \"w+\")\n\n    if header != None:\n        for l in header:\n            tfile.write(l)\n\n    for l in sam:\n        l=[ s for s in l if s not in ['nan'] ]\n        l=\"\\t\".join(l)\n        tfile.write(l+\"\\n\")\n\n    tfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of flags that define a complete SAM flag.", "response": "def SAMflags(x):\n    \"\"\"\n    Explains a SAM flag.\n\n    :param x: flag\n\n    :returns: complete SAM flag explanaition\n    \"\"\"\n    flags=[]\n\n    if x & 1:\n        l=\"1: Read paired\"\n    else:\n        l=\"0: Read unpaired\"\n    flags.append(l)\n\n    if x & 2 :\n        l=\"1: Read mapped in proper pair\"\n    else:\n        l=\"0: Read not mapped in proper pair\"\n    flags.append(l)\n\n    if x & 4 :\n        l=\"1: Read unmapped\"\n    else:\n        l=\"0: Read mapped\"\n    flags.append(l)\n\n    if x & 8 :\n        l=\"1: Mate unmapped\"\n    else:\n        l=\"0: Mate mapped\"\n    flags.append(l)\n\n    if x & 16 :\n        l=\"1: Read reverse strand\"\n    else:\n        l=\"0: Read direct strand\"\n    flags.append(l)\n\n    if x & 32 :\n        l=\"1: Mate reverse strand\"\n    else:\n        l=\"0: Mate direct strand\"\n    flags.append(l)\n\n    if x & 64 :\n        l=\"1: First in pair\"\n    else:\n        l=\"0: Second in pair\"\n    flags.append(l)\n\n    if x & 128 :\n        l=\"1: Second in pair\"\n    else:\n        l=\"0: First in pair\"\n    flags.append(l)\n\n    if x & 256 :\n        l=\"1: Not primary alignment\"\n    else:\n        l=\"0: Primary alignment\"\n    flags.append(l)\n\n    if x & 512 :\n        l=\"1: Read fails platform/vendor quality checks\"\n    else:\n        l=\"0: Read passes platform/vendor quality checks\"\n    flags.append(l)\n\n    if x & 1024 :\n        l=\"1: Read is PCR or optical duplicate\"\n    else:\n        l=\"0: Read is not PCR or optical duplicate\"\n    flags.append(l)\n\n    if x & 2048 :\n        l=\"1: Supplementary alignment\"\n    else:\n        l=\"0: Not supplementary alignment\"\n    flags.append(l)\n\n    return flags"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string representation of the bias details", "response": "def get_bias_details(self):\n        \"\"\"\n        returns a string representation of the bias details\n        \"\"\"\n        res = 'Bias File Details\\n'\n        for b in self.bias_details:\n            if len(b) > 2:\n                res += b[0].ljust(35)\n                res += b[1].ljust(35)\n                res += b[2].ljust(9)\n            res += '\\n'\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the bias value for the source and updates self. bias_rating based on the bias details.", "response": "def _calculate_bias(self):\n        \"\"\"\n        returns a weighting from 0 to 1 based on the sources.\n        Due to fractions multiplying resulting in very small \n        numbers, adding 0.5 to bias calculations which means\n        actual range is 0.5 -> 1.5 (still testing)\n        \n        Note - range should be from 0 - > 1\n        \n        \"\"\"\n        for m in self.metadata:\n            for b in self.bias_details:\n                if  b[0] == 'bias-' + m['label'] + '.csv':\n                    l_bias = 1.000\n                    try:\n                        l_bias = float(b[2]) + 0.5\n                    except:\n                        lg.record_process('bias.py','ERROR converting bias value to float: ' + str(b))\n                    self.bias_rating *= l_bias"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_bias_rating(self, short_filename):\n        res = {}\n        full_name = os.path.join(root_fldr, 'aikif', 'data', 'ref', short_filename)\n        lg.record_process('bias.py','reading ' + full_name)\n         \n        with open(full_name, 'r') as f:\n            for line in f:\n                if line.strip('') == '':\n                    break\n                bias_line = []\n                cols = line.split(',')\n                bias_line.extend([short_filename])\n                for col in cols:\n                    bias_line.extend([col.strip('\"').strip('\\n')])\n                self.bias_details.append(bias_line)", "response": "read the bias file based on the short_filename and return as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_root_folder():\n    locations = {\n     'linux':{'hme':'/home/duncan/', 'core_folder':'/home/duncan/dev/src/python/AIKIF'},\n     'win32':{'hme':'T:\\\\user\\\\',    'core_folder':'T:\\\\user\\\\dev\\\\src\\\\python\\\\AIKIF'},\n     'cygwin':{'hme':os.getcwd() + os.sep,    'core_folder':os.getcwd()},\n     'darwin':{'hme':os.getcwd() + os.sep,    'core_folder':os.getcwd()}\n    }\n    hme = locations[sys.platform]['hme']\n    core_folder = locations[sys.platform]['core_folder']\n\n    if not os.path.exists(core_folder):\n        hme = os.getcwd()        \n        core_folder = os.getcwd()\n        print('config.py : running on CI build (or you need to modify the paths in config.py)')\n    return hme, core_folder", "response": "returns the home folder and program root depending on OS"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_credentials(fname):\n    with open(fname, 'r') as f:\n        username = f.readline().strip('\\n')\n        password = f.readline().strip('\\n')\n    return username, password", "response": "read a simple text file from a private location to get\n    username and password"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the adjacency matrix as a list of lists", "response": "def get_adjacency_matrix(self, show_in_console=False):\n        \"\"\" return the matrix as a list of lists \n        raw graph =  {'1': ['2', '3', '4'], '2': ['6', '7']}\n        6 nodes: ['1', '2', '3', '4', '6', '7']\n        5 links: [['1', '2'], ['1', '3'], ['1', '4'], ['2', '6'], ['2', '7']]\n        [0, 1, 1, 1, 0, 0]\n        [1, 0, 0, 0, 1, 1]\n        [1, 0, 0, 0, 0, 0]\n        [1, 0, 0, 0, 0, 0]\n        [0, 1, 0, 0, 0, 0]\n        [0, 1, 0, 0, 0, 0]\n        \"\"\"\n        self.links = [[i,j] for i in self.graph for j in self.graph[i]]\n        all_nodes = []\n        op = [] \n        for node in self.graph:\n            all_nodes.append(node)  # to get the root node\n            for connection in self.graph[node]:\n                all_nodes.append(connection)\n        self.nodes = sorted(list(set(all_nodes)))\n        if show_in_console is not False:\n            print (len(self.nodes), 'nodes:', self.nodes)\n            print (len(self.links), 'links:', self.links)\n        \n        for y in range(len(self.nodes)):\n            row = []\n            for x in range(len(self.nodes)):\n                match = False\n                for l in self.links:\n                    if self.nodes[x] == l[0] and self.nodes[y] == l[1]:\n                        match = True\n                    if self.nodes[x] == l[1] and self.nodes[y] == l[0]:\n                        match = True\n                        \n                if match is True:\n                    row.append(1)\n                else:\n                    row.append(0)\n                \n            op.append(row)\n            \n        if show_in_console is not False:\n            for row in op:\n                print(row)\n            \n        return op"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filterMotifs(memeFile,outFile, minSites):\n\n    with open(memeFile, \"r\") as mF:\n        oldMEME=mF.readlines()\n        newMEME=oldMEME[:7]\n        i=7\n        while i < len(oldMEME):\n            if oldMEME[i].split(\" \")[0] == \"MOTIF\":\n                print(oldMEME[i].split(\"\\n\")[0], int(oldMEME[i+2].split(\"nsites= \")[1].split(\" \")[0]))\n                sys.stdout.flush()\n                if int(oldMEME[i+2].split(\"nsites= \")[1].split(\" \")[0]) > minSites:\n                    newMEME.append(oldMEME[i])\n                    f=i+1\n                    while oldMEME[f].split(\" \")[0] != \"MOTIF\":\n                        newMEME.append(oldMEME[f])\n                        f=f+1\n                    i=i+1\n                else:\n                    i=i+1\n            else:\n                i=i+1\n    with open(outFile, \"w+\") as out:\n        out.write(\"\".join(newMEME) )\n\n    return newMEME", "response": "This function filters motifs from a meme file based on the number of sites."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the file and cleans up the standard text ready for parsing", "response": "def _read_file(self):\n        \"\"\"\n        reads the file and cleans into standard text ready for parsing\n        \"\"\"\n        self.raw = []\n        with open(self.fname, 'r') as f:\n            for line in f:\n                #print(line)\n                if line.startswith('#'):    \n                    pass # comment\n                elif line.strip('\\n') == '':\n                    pass # space\n                else:\n                    self.raw.append(line.strip('\\n'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets the default configuration and removes the user s config file.", "response": "def reset(self):\n        \"\"\"\n        Restore the default configuration and remove the user's config file.\n        \"\"\"\n\n        # Delete user config file\n        try:\n            os.remove(self._user_config_file)\n        except FileNotFoundError:\n            pass\n\n        # Empty and refill the config object\n        for section_name in self.sections():\n            self.remove_section(section_name)\n        self.read_defaults()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites data to user config file.", "response": "def save(self):\n        \"\"\"\n        Write data to user config file.\n        \"\"\"\n        with open(self._user_config_file, 'w', encoding='utf-8') as f:\n            self.write(f)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_datetime(self, section, option, fallback):\n        try:\n            s = self[section][option]\n            try:\n                # If stored as timestamp\n                return datetime.utcfromtimestamp(int(s))\n            except ValueError:\n                # Otherwise parse ISO format\n                return datetime.strptime(s, self.DATETIME_FMT)\n        except (KeyError, ValueError):\n            return fallback", "response": "Get UTC datetime from timestamp in config file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_datetime(self, section, option, value):\n        self[section][option] = value.strftime(self.DATETIME_FMT)", "response": "Set the value of the option to the UTC datetime from timestamp in config file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ml_entropy(lst):\n    tot = sum(lst)\n    res = 0\n    for v in lst:\n        if v > 0:\n            p = v / tot\n            l = math.log( p, 2)\n            res += round(p * l, 6)\n    res = round(res * -1, 6)\n    print('lst = ', lst, 'entropy = ', res)\n    return res", "response": "Calculates the General Machine Learning Formulas of the given list of logarithms and returns the Entropy of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the magic data file and return the headers and footers", "response": "def _magic_data(filename=os.path.join(here, 'magic_data.json')):\n    \"\"\" Read the magic file\"\"\"\n    with open(filename) as f:\n        data = json.load(f)\n    headers = [_create_puremagic(x) for x in data['headers']]\n    footers = [_create_puremagic(x) for x in data['footers']]\n    return headers, footers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nroughs confidence based on string length and file extension", "response": "def _confidence(matches, ext=None):\n    \"\"\" Rough confidence based on string length and file extension\"\"\"\n    results = []\n    for match in matches:\n        con = (0.8 if len(match.extension) > 9 else\n               float(\"0.{0}\".format(len(match.extension))))\n        if ext == match.extension:\n            con = 0.9\n        results.append(\n            PureMagicWithConfidence(confidence=con, **match._asdict()))\n    return sorted(results, key=lambda x: x.confidence, reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nidentify all data in a file by its magic numbers.", "response": "def _identify_all(header, footer, ext=None):\n    \"\"\" Attempt to identify 'data' by its magic numbers\"\"\"\n\n    # Capture the length of the data\n    # That way we do not try to identify bytes that don't exist\n    matches = list()\n    for magic_row in magic_header_array:\n        start = magic_row.offset\n        end = magic_row.offset + len(magic_row.byte_match)\n        if end > len(header):\n            continue\n        if header[start:end] == magic_row.byte_match:\n            matches.append(magic_row)\n\n    for magic_row in magic_footer_array:\n        start = magic_row.offset\n        if footer[start:] == magic_row.byte_match:\n            matches.append(magic_row)\n    if not matches:\n        raise PureError(\"Could not identify file\")\n\n    return _confidence(matches, ext)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _magic(header, footer, mime, ext=None):\n    if not header:\n        raise ValueError(\"Input was empty\")\n    info = _identify_all(header, footer, ext)[0]\n    if mime:\n        return info.mime_type\n    return info.extension if not \\\n        isinstance(info.extension, list) else info[0].extension", "response": "Discover what type of file it is based on the incoming string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngrab the start and end of the file", "response": "def _file_details(filename):\n    \"\"\" Grab the start and end of the file\"\"\"\n    max_head, max_foot = _max_lengths()\n    with open(filename, \"rb\") as fin:\n        head = fin.read(max_head)\n        try:\n            fin.seek(-max_foot, os.SEEK_END)\n        except IOError:\n            fin.seek(0)\n        foot = fin.read()\n    return head, foot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ext_from_filename(filename):\n    try:\n        base, ext = filename.lower().rsplit(\".\", 1)\n    except ValueError:\n        return ''\n    ext = \".{0}\".format(ext)\n    all_exts = [x.extension for x in chain(magic_header_array,\n                                           magic_footer_array)]\n\n    if base[-4:].startswith(\".\"):\n        # For double extensions like like .tar.gz\n        long_ext = base[-4:] + ext\n        if long_ext in all_exts:\n            return long_ext\n    return ext", "response": "Scan a filename for the extension of the current object and return the extension off the end."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the mime type or extension of a file.", "response": "def from_file(filename, mime=False):\n    \"\"\" Opens file, attempts to identify content based\n    off magic number and will return the file extension.\n    If mime is True it will return the mime type instead.\n\n    :param filename: path to file\n    :param mime: Return mime, not extension\n    :return: guessed extension or mime\n    \"\"\"\n\n    head, foot = _file_details(filename)\n    return _magic(head, foot, mime, ext_from_filename(filename))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_string(string, mime=False, filename=None):\n    head, foot = _string_details(string)\n    ext = ext_from_filename(filename) if filename else None\n    return _magic(head, foot, mime, ext)", "response": "Reads in a string and returns the mime type or mime type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn tuple of num_of_matches array_of_matches highest confidence match first.", "response": "def magic_file(filename):\n    \"\"\" Returns tuple of (num_of_matches, array_of_matches)\n    arranged highest confidence match first.\n\n    :param filename: path to file\n    :return: list of possible matches, highest confidence first\n    \"\"\"\n    head, foot = _file_details(filename)\n    if not head:\n        raise ValueError(\"Input was empty\")\n    try:\n        info = _identify_all(head, foot, ext_from_filename(filename))\n    except PureError:\n        info = []\n    info.sort(key=lambda x: x.confidence, reverse=True)\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef magic_string(string, filename=None):\n    if not string:\n        raise ValueError(\"Input was empty\")\n    head, foot = _string_details(string)\n    ext = ext_from_filename(filename) if filename else None\n    info = _identify_all(head, foot, ext)\n    info.sort(key=lambda x: x.confidence, reverse=True)\n    return info", "response": "Returns tuple of num_of_matches array_of_matches highest confidence match first\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readGTF(infile):\n    df=pd.read_table(infile, sep='\\t', comment=\"#\", header=None, dtype=str)\n    df.columns=['seqname','source','feature','start','end','score','strand','frame','attribute']\n    #df = df.astype(str) # from DTC\n    return df", "response": "Reads a GTF file and labels the respective columns in agreement with GTF file standards"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_GTF_field(field,gtf):\n    inGTF=gtf.copy()\n    def splits(x):\n        l=x.split(\";\")\n        l=[ s.split(\" \") for s in l]\n        res=np.nan\n        for s in l:\n            if field in s:\n                if '\"' in s[-1]:\n                    res=s[-1][1:-1]\n                else:\n                    res=s[-1]\n        return res\n\n    inGTF[field]=inGTF['attribute'].apply(lambda x: splits(x))\n    return inGTF[[field]]", "response": "Returns a Pandas dataframe containing the field of choice from the attribute column of the GTF"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attributesGTF(inGTF):\n    df=pd.DataFrame(inGTF['attribute'].str.split(\";\").tolist())\n    desc=[]\n    for i in df.columns.tolist():\n        val=df[[i]].dropna()\n        val=pd.DataFrame(val[i].str.split(' \"').tolist())[0]\n        val=list(set(val))\n        for v in val:\n            if len(v) > 0:\n                l=v.split(\" \")\n                if len(l)>1:\n                    l=l[1]\n                else:\n                    l=l[0]\n                desc.append(l)\n    desc=list(set(desc))\n    finaldesc=[]\n    for d in desc:\n        if len(d) > 0:\n            finaldesc.append(d)\n    return finaldesc", "response": "Returns a list of attributes present in a GTF file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parseGTF(inGTF):\n\n    desc=attributesGTF(inGTF)\n    ref=inGTF.copy()\n    ref.reset_index(inplace=True, drop=True)\n    df=ref.drop(['attribute'],axis=1).copy()\n    for d in desc:\n        field=retrieve_GTF_field(d,ref)\n        df=pd.concat([df,field],axis=1)\n    return df", "response": "Reads an input GTF and returns a dataframe with all attributes parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef writeGTF(inGTF,file_path):\n    cols=inGTF.columns.tolist()\n    if len(cols) == 9:\n        if 'attribute' in cols:\n            df=inGTF\n    else:\n        df=inGTF[cols[:8]]\n        df['attribute']=\"\"\n        for c in cols[8:]:\n            if c == cols[len(cols)-1]:\n                df['attribute']=df['attribute']+c+' \"'+inGTF[c].astype(str)+'\";'\n            else:\n                df['attribute']=df['attribute']+c+' \"'+inGTF[c].astype(str)+'\"; '\n    df.to_csv(file_path, sep=\"\\t\",header=None,index=None,quoting=csv.QUOTE_NONE)", "response": "Writes a GTF dataframe into a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a GTF dataframe into a bed dataframe", "response": "def GTFtoBED(inGTF,name):\n    \"\"\"\n    Transform a GTF dataframe into a bed dataframe\n\n    :param inGTF: GTF dataframe for transformation\n    :param name: field of the GTF data frame to be use for the bed 'name' positon\n\n    returns: a bed dataframe with the corresponding bed fiels: 'chrom','chromStart','chromEnd','name','score','strand'\n    \"\"\"\n\n    bed=inGTF.copy()\n    bed.reset_index(inplace=True, drop=True)\n    if name not in bed.columns.tolist():\n        field=retrieve_GTF_field(name, bed)\n        bed=pd.concat([bed,field],axis=1)\n    bed=bed[['seqname','start','end',name,'score','strand']]\n    bed.columns=['chrom','chromStart','chromEnd','name','score','strand']\n    bed.drop_duplicates(inplace=True)\n    bed.reset_index(inplace=True,drop=True)\n    return bed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef MAPGenoToTrans(parsedGTF,feature):\n    GenTransMap=parsedGTF[parsedGTF[\"feature\"]==feature]\n    def getExonsPositions(df):\n        start=int(df[\"start\"])\n        stop=int(df[\"end\"])\n        strand=df[\"strand\"]\n        r=range(start,stop+1)\n        if strand==\"-\":\n            r.sort(reverse=True)\n        r=[ str(s) for s in r]\n        return \",\".join(r)\n\n    GenTransMap[\"feature_bases\"]=GenTransMap.apply(getExonsPositions, axis=1)\n    GenTransMap=GenTransMap.sort_values(by=[\"transcript_id\",\"exon_number\"],ascending=True)\n    def CombineExons(df):\n        return pd.Series(dict( feature_bases = ','.join(df['feature_bases']) ) )\n    GenTransMap=GenTransMap.groupby(\"transcript_id\").apply(CombineExons)\n    GenTransMap=GenTransMap.to_dict().get(\"feature_bases\")\n\n    return GenTransMap", "response": "Returns a string that contains all positions of all bases in a single exon in a single gene."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetTransPosition(df,field,dic,refCol=\"transcript_id\"):\n    try:\n        gen=str(int(df[field]))\n        transid=df[refCol]\n        bases=dic.get(transid).split(\",\")\n        bases=bases.index(str(gen))+1\n    except:\n        bases=np.nan\n    return bases", "response": "Maps a genome position to transcript positon"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads a file from a public website with no logon required", "response": "def download_file_no_logon(url, filename):\n    \"\"\"\n    download a file from a public website with no logon required\n    \n    output = open(filename,'wb')\n    output.write(request.urlopen(url).read())\n    output.close()    \n    \"\"\"\n    import urllib.request\n    #url = \"http://www.google.com/\"\n    request = urllib.request.Request(url)\n    try:\n        response = urllib.request.urlopen(request)\n        with open(filename,'wb') as f:\n            #print (response.read().decode('utf-8'))\n            f.write(response.read())\n    except Exception as ex:\n        lg.record_result(\"Error - cant download \" + url + str(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading a protected page from url and save it to filename", "response": "def get_protected_page(url, user, pwd, filename):\n    \"\"\"\n    having problems with urllib on a specific site so trying requests\n    \"\"\"\n    import requests\n    r = requests.get(url, auth=(user, pwd))\n    print(r.status_code)\n    if r.status_code == 200:\n        print('success')\n        with open(filename, 'wb') as fd:\n            for chunk in r.iter_content(4096):\n                fd.write(chunk)\n        lg.record_result(\"Success - downloaded \" + url)\n    else:\n        lg.record_result('network_tools.get_protected_page:Failed to downloaded ' + url + ' (status code = ' + str(r.status_code) + ')')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a file from a URL and save it to a file in a local file.", "response": "def download_file(p_realm, p_url, p_op_file, p_username, p_password):\n    \"\"\"\n    Currently not working...\n    # https://docs.python.org/3/library/urllib.request.html#examples\n    # Create an OpenerDirector with support for Basic HTTP Authentication...\n    \"\"\"\n    auth_handler = urllib.request.HTTPBasicAuthHandler()\n    auth_handler.add_password(realm=p_realm,\n                              uri=p_url,\n                              user=p_username,\n                              passwd=p_password)\n    opener = urllib.request.build_opener(auth_handler)\n    # ...and install it globally so it can be used with urlopen.\n    urllib.request.install_opener(opener)\n\n    web = urllib.request.urlopen(p_url)\n    with open(p_op_file, 'w') as f:\n        f.write(web.read().decode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading a file from a proxy.", "response": "def download_file_proxy(p_url, p_op_file, p_username, p_password, proxies):\n    \"\"\"\n    Currently fails behind proxy...\n    # https://docs.python.org/3/library/urllib.request.html#examples\n    \"\"\"\n    chunk_size=4096\n    import requests\n    r = requests.get(p_url, auth=(p_username, p_password), proxies=proxies)\n    #print(r.status_code)\n    with open(p_op_file, 'wb') as fd:\n        for chunk in r.iter_content(chunk_size):\n            fd.write(chunk)  \n    return r.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_rawFilesTable(filename):\n    exp = pd.read_table(filename)\n    expected_columns = {'File', 'Exists', 'Size', 'Data format', 'Parameter group', 'Experiment', 'Fraction'}\n    found_columns = set(exp.columns)\n    if len(expected_columns - found_columns) > 0:\n        message = '\\n'.join(['The raw files table has the wrong format!',\n            'It should contain columns:',\n            ', '.join(sorted(expected_columns)),\n            'Found columns:',\n            ', '.join(sorted(found_columns))])\n        raise ValueError(message)\n    exp['Raw file'] = exp['File'].apply(path.basename).apply(path.splitext).str.get(0)\n    exp['Experiment'] = exp['Experiment'].astype(str)\n    return exp", "response": "parse the rawFilesTable. txt file into a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an instance method or function to store", "response": "def add_method(self, m, **kwargs):\n        \"\"\"Add an instance method or function\n\n        Args:\n            m: The instance method or function to store\n        \"\"\"\n        if isinstance(m, types.FunctionType):\n            self['function', id(m)] = m\n        else:\n            f, obj = get_method_vars(m)\n            wrkey = (f, id(obj))\n            self[wrkey] = obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef del_method(self, m):\n        if isinstance(m, types.FunctionType) and not iscoroutinefunction(m):\n            wrkey = ('function', id(m))\n        else:\n            f, obj = get_method_vars(m)\n            wrkey = (f, id(obj))\n        if wrkey in self:\n            del self[wrkey]", "response": "Removes an instance method or function from the cache if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_instance(self, obj):\n        to_remove = set()\n        for wrkey, _obj in self.iter_instances():\n            if obj is _obj:\n                to_remove.add(wrkey)\n        for wrkey in to_remove:\n            del self[wrkey]", "response": "Removes any stored instance methods that belong to an object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_instances(self):\n        for wrkey in set(self.keys()):\n            obj = self.get(wrkey)\n            if obj is None:\n                continue\n            yield wrkey, obj", "response": "Iterate over the stored objects in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating over stored functions and instance methods or function objects", "response": "def iter_methods(self):\n        \"\"\"Iterate over stored functions and instance methods\n\n        Yields:\n            Instance methods or function objects\n        \"\"\"\n        for wrkey, obj in self.iter_instances():\n            f, obj_id = wrkey\n            if f == 'function':\n                yield self[wrkey]\n            else:\n                yield getattr(obj, f.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the subject file to a list", "response": "def load_data_subject_areas(subject_file):\n    \"\"\"\n    reads the subject file to a list, to confirm config is setup\n    \"\"\"\n    lst = []\n    if os.path.exists(subject_file):\n        with open(subject_file, 'r') as f:\n            for line in f:\n                lst.append(line.strip())\n    else:\n        print('MISSING DATA FILE (subject_file) ' , subject_file)\n        print('update your config.py or config.txt')\n    return lst"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_ontology(fname):    \n    with open(fname, 'r') as stream:\n        y = yaml.safe_load(stream)\n    import pprint\n    pprint.pprint(y)", "response": "reads the ontology yaml file and does basic verifcation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind an ontology by name", "response": "def find_ontology(self, txt):\n        \"\"\"\n        top level function used for new data processing which attempts\n        to find a level in a heirarchy and return the key and filename\n        usage res = FindOntology('file')  # returns 'SYSTEM-PC-FILE'\n        \"\"\"\n        totFound = 0\n        searchString = txt.upper()\n        match = []\n        if searchString != '':\n            for i in self.lst_subj:\n                if searchString in i:\n                    totFound = totFound + 1\n                    match.append(i)\n        if len(match) == 0:\n            match.append('_TOP')\n        return match"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_type(self, txt):\n        searchString = txt.upper()\n        match = 'Unknown'\n        for i in self.lst_type:\n            if searchString in i:\n                match = i\n        return match", "response": "find the type of the object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_full_filename(self, dataType, subjectArea):\n        return dataPath + os.sep + 'core' + os.sep + dataType + '_' + subjectArea + '.CSV'", "response": "returns the full filename based on dataType and subjectArea"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(url):\n    config = {}\n\n    url = urlparse.urlparse(url)\n\n    # Remove query strings.\n    path = url.path[1:]\n    path = path.split('?', 2)[0]\n\n    try:\n        port = url.port\n        hostname = url.hostname\n    except ValueError:\n        port = None\n        if url.scheme == 'rdbms':\n            # local appengine stub requires INSTANCE parameter\n            config['INSTANCE'] = url.netloc.split('@')[-1]\n            hostname = None\n        else:\n            hostname = \"/cloudsql/{}\".format(url.netloc.split('@')[-1])\n\n    config.update({\n        'NAME': path,\n        'USER': url.username,\n        'PASSWORD': url.password,\n        'HOST': hostname,\n        'PORT': port,\n    })\n\n    if url.scheme in SCHEMES:\n        config['ENGINE'] = SCHEMES[url.scheme]\n\n    return config", "response": "Parses a database URL in this format and returns a dictionary with the configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a logger by name.", "response": "def get_logger(name):\n        \"\"\"Get a logger by name.\"\"\"\n        if name is None:\n            return NoLogger()\n\n        logger = logging.getLogger(name)\n        if Logger.use_external_configuration:\n            logger.propagate = False\n        return logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_plan(self, fname):    \n        with open(fname, \"r\") as f:\n            for line in f:\n                if line != '': \n                    tpe, txt = self.parse_plan_from_string(line)\n                    #print('tpe= \"' + tpe + '\"', txt)\n                    if tpe == 'name':\n                        self.name = txt\n                    elif tpe == 'version':\n                        self.plan_version = txt\n                    elif tpe == 'belief':\n                        self.beliefs.add(txt)\n                    elif tpe == 'desire':\n                        self.desires.add(txt)\n                    elif tpe == 'intention':\n                        self.intentions.add(txt)", "response": "load the list of thoughts from a text file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_constraint(self, name, tpe, val):\n        self.constraint.append([name, tpe, val])", "response": "Adds a constraint for the plan\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating basic stats on the MapRule elements of the maps that are in the cache.", "response": "def get_maps_stats(self):\n        \"\"\"\n        calculates basic stats on the MapRule elements of the maps\n        to give a quick overview.\n        \"\"\"\n        tpes = {}\n        for m in self.maps:\n            if m.tpe in tpes:\n                tpes[m.tpe] += 1\n            else:\n                tpes[m.tpe] = 1\n        return tpes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the rules from file", "response": "def load_rules(self):\n        \"\"\" \n        load the rules from file\n        \"\"\"\n        self.maps = []\n        with open(self.map_file, 'r') as f:\n            for line in f:\n                if line.strip(' ')[0:1] != '#':\n                    rule = MapRule(line)\n                    #print('rule = ', rule)\n                    self.maps.append(rule)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_rules(self, op_file):\n        with open(op_file, 'w') as f:\n            for m in self.maps:\n                f.write(m.format_for_file_output())", "response": "save the rules to file after web updates or program changes \n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_raw_file(self, raw_file_name, field_names):\n        #num_outouts = 0\n        dist_vals = []\n        group_dat = []\n        events = []\n        #facts = []\n        \n        with open(raw_file_name) as csvfile:\n            reader = csv.DictReader(csvfile, fieldnames = field_names)\n            for num_lines, row in enumerate(reader):\n                #print('row = =',row)\n                for col_num, fld in enumerate(field_names):\n                    try:\n                        #print('self.maps[', col_num, '] = ', self.maps[col_num])\n                        if self.maps[col_num].val == 'group_distinct':\n                            group_dat.append(str(row[fld]))\n                        elif self.maps[col_num].val == 'event_date':\n                            events.append(str(row[fld]))\n\n                    except Exception as ex:\n                        print('parsing error - shouldnt really be splitting using a comma anyway!', str(ex))\n        \n        dist_vals = sorted(list(set(group_dat)))\n        \n        return num_lines, dist_vals, group_dat, sorted(list(set(events)))", "response": "This function takes the filename to be read and uses the maps setup \n        on class instantiation to process the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef identify_data(self, tpe, raw_data):\n        num_applicable_rules = 0\n        formatted_data = self.format_raw_data(tpe, raw_data)\n        for m in self.maps:\n            if m.tpe == tpe:\n                num_applicable_rules += 1\n                self.process_rule(m, formatted_data, tpe)\n        return num_applicable_rules", "response": "function to identify the data for a particular entry in the raw data file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_rule(self, m, dct, tpe):\n        print('TODO - ' + tpe + ' + applying rule ' + str(m).replace('\\n', '') )", "response": "This function is called by the process_data function of the map rule m."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_raw_data(self, tpe, raw_data):\n        \n        if tpe == 'text':\n            formatted_raw_data = self.parse_text_to_dict(raw_data)\n        elif tpe == 'file':\n            formatted_raw_data = self.parse_file_to_dict(raw_data)\n        else:\n            formatted_raw_data = {'ERROR':'unknown data type', 'data':[raw_data]}\n        return formatted_raw_data", "response": "Formats the raw data into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_text_to_dict(self, txt):\n        op = {}\n        print('TODO - import NLP, split into verbs / nouns')\n        op['nouns'] = txt\n        op['verbs'] = txt\n        \n        return op", "response": "takes a string and parses via NLP and returns a dictionary of the keys verbs and nouns"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the file to dict", "response": "def parse_file_to_dict(self, fname):\n        \"\"\"\n        process the file according to the mapping rules.\n        The cols list must match the columns in the filename\n        \"\"\"\n        print('TODO - parse_file_to_dict' + fname)\n        for m in self.maps:\n            if m.tpe == 'file':\n                if m.key[0:3] == 'col':\n                    print('reading column..')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_map_from_dataset(self, l_dataset):\n        l_map = []\n        headers = l_dataset.get_header()\n        print(headers)\n        for row_num, col in enumerate(headers):\n            if col != '':\n                l_map.append('column:name:' + str(row_num) + '=' + l_dataset.force_to_string(col))\n        \n        for row_num, col in enumerate(headers):\n            if col != '':\n                vals = l_dataset.get_distinct_values_from_cols([col])\n                l_map.append('column:count:distinct:' + col + '=' + str(len(vals[0])) )\n                \n        for row_num, col in enumerate(headers):\n            if col != '':\n                col_vals = l_dataset.count_unique_values(row_num, col, 10)\n                for val_num, v in enumerate(col_vals):\n                    l_map.append('column:topvalues:' + col + ':' + str(val_num) + '='  + v )\n                #l_map.append('column:values:top5:' + str(row_num) + '=' + col_vals)\n                \n                \n        return l_map", "response": "Generates a list of CSV files based on the columns of a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_map_from_file(self, data_filename):\n        \n        op_filename = data_filename + '.rule'\n        \n        dataset = mod_datatable.DataTable(data_filename, ',')\n        dataset.load_to_array()\n        l_map = self.generate_map_from_dataset(dataset)\n        with open(op_filename, 'w') as f:\n            f.write('# rules file autogenerated by mapper.py v0.1\\n')\n            f.write('filename:source=' + data_filename + '\\n')\n            f.write('filename:rule=' + op_filename + '\\n\\n')\n            for row in l_map:\n                #print('ROW = ' , row)\n                if type(row) is str:\n                    f.write(row + '\\n')\n                else:\n                    for v in row:\n                        f.write(v)", "response": "Reads the data_filename into a matrix and generates a. rule file based on the data in the map\necords."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the rules from file . col_file", "response": "def load_rules(self):\n        \"\"\" \n        load the rules from file\n        \"\"\"\n        self.col_maps = []\n        #print(\"reading mapping table\")\n        with open(self.col_file, 'r') as f:\n            for line in f:\n                rule = MapColumn(line)\n                #rule = line\n                self.col_maps.append(rule)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_csv_col_rules(self):\n        self.cols = self.csv_line.split(',')\n        self.table = self.extract_col(0)\n        self.column = self.extract_col(1)\n        self.data_type = self.extract_col(2)\n        self.aikif_map = self.extract_col(3)\n        self.aikif_map_name = self.extract_col(4)\n        self.extract = self.extract_col(5)\n        self.format = self.extract_col(6)\n        self.where = self.extract_col(7)\n        self.index = self.extract_col(8)", "response": "Parses the CSV line of the current format and puts into \n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        while self.status != 'EXIT':\n            print(self.process_input(self.get_input()))\n        \n        print('Bye')", "response": "loop until exit command given\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_input(self, question):\n        ans = ''\n        if self.status == 'EXIT':\n            print('bye')\n            sys.exit()\n        \n        if '?' in question:\n            ans = self.info.find_answer(question)\n        elif question.startswith(':LIST'):\n            ans = 'List of Raw Input\\n'\n            for i in self.info.raw_input:\n                ans += str(i) + '\\n'\n            \n            \n        else:\n            #ans = 'I dont'' know'\n            ans = 'Adding info..'\n            self.info.raw_input.append(question)\n        self.lg.record_process('aggie.py', 'Question > ' +  question)\n        self.lg.record_process('aggie.py', 'Answer > ' + ans)\n        return ans", "response": "Takes a question and returns the best answer based on known skills"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_data_file(fname):\n    txt = '<H2>' + fname + '</H2>'\n    print (fname)\n    #try:\n    txt += web.read_csv_to_html_table(fname, 'Y')  # it is ok to use a table for actual table data\n    #except:\n    #\ttxt += '<H2>ERROR - cant read file</H2>'\n    #txt += web.read_csv_to_html_list(fname)  # only use this for single column lists\n    \n    txt += '</div>\\n'\n    return txt", "response": "shows a data file in CSV format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef managed_process(process):\n    try:\n        yield process\n    finally:\n        for stream in [process.stdout, process.stdin, process.stderr]:\n            if stream:\n                stream.close()\n        process.wait()", "response": "Wrapper for subprocess. Popen to work across various Python versions when using the with syntax."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_environment_variables(self, filename):\n        self.env.update(os.environ.copy())\n        self.env.update({'PIPELINE_BASH_FILE': filename})", "response": "Updates OS environment variables and current script path and filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_temporary_scripts_path(self):\n        result = None\n        if len(self.config.temporary_scripts_path) > 0:\n            if os.path.isdir(self.config.temporary_scripts_path):\n                result = self.config.temporary_scripts_path\n        return result", "response": "Get path for temporary scripts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_file_for(self, script):\n        temp = tempfile.NamedTemporaryFile(\n            prefix=\"pipeline-script-\", mode='w+t', suffix=\".sh\", delete=False,\n            dir=self.get_temporary_scripts_path())\n\n        self.update_environment_variables(temp.name)\n        rendered_script = render(script, model=self.config.model, env=self.env, item=self.config.item,\n                                 variables=self.config.variables)\n        if rendered_script is None:\n            self.success = False\n            temp.close()\n            os.remove(temp.name)\n            return None\n\n        to_file_map = {2: lambda s: s.encode('utf-8'), 3: lambda s: s}\n\n        if all(ord(ch) < 128 for ch in rendered_script) and os.path.isfile(rendered_script):\n            with open(rendered_script) as handle:\n                content = str(handle.read())\n                temp.writelines(content)\n        else:\n            temp.write(u\"#!/bin/bash\\n%s\" % self.render_bash_options())\n            temp.write(to_file_map[sys.version_info.major](rendered_script))\n        temp.close()\n        # make Bash script executable\n        os.chmod(temp.name, 0o700)\n        return temp.name", "response": "Create a temporary file for the given script."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the Bash code.", "response": "def process_script(self, filename):\n        \"\"\"Running the Bash code.\"\"\"\n        try:\n            with managed_process(subprocess.Popen(shlex.split(\"bash %s\" % filename),\n                                                  stdout=self.stdout, stderr=self.stderr,\n                                                  shell=self.shell, env=self.env)) as process:  # nosec\n                for line in iter(process.stdout.readline, ' '):\n                    if not line:\n                        break\n                    yield line[0:-1].decode('utf-8')\n                process.wait()\n                self.exit_code = process.returncode\n                self.success = (process.returncode == 0)\n                if not self.config.internal:\n                    if process.returncode == 0:\n                        self.logger.info(\"Exit code has been %d\", process.returncode)\n                    else:\n                        self.logger.error(\"Exit code has been %d\", process.returncode)\n        except OSError as exception:\n            self.exit_code = 1\n            self.success = False\n            yield str(exception)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the Bash code.", "response": "def process(self):\n        \"\"\"Running the Bash code.\"\"\"\n        temp_filename = self.create_file_for(self.config.script)\n\n        if len(self.config.title) > 0:\n            self.logger.info(render(self.config.title, model=self.config.model, env=self.env,\n                                    item=self.config.item, variables=self.config.variables))\n\n        if temp_filename is not None:\n            try:\n                for line in self.process_file(temp_filename):\n                    yield line\n            finally:\n                # removing script\n                os.remove(temp_filename)\n\n        if not self.config.internal:\n            if self.exit_code == 0:\n                self.event.succeeded()\n            else:\n                self.event.failed(exit_code=self.exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an image to the RGB color space.", "response": "def _to_pil_rgb_image(image):\n    \"\"\"Returns an PIL Image converted to the RGB color space. If the image has\n    an alpha channel (transparency), it will be overlaid on a black background.\n\n    :param image: the PIL image to convert\n\n    :returns: The input image if it was already in RGB mode, or a new RGB image\n              if converted.\n\n    :raises ImportError: PIL / Pillow cannot be imported.\n    \"\"\"\n    if image.mode == \"RGB\":\n        return image\n\n    from PIL import Image\n\n    image.load()\n    rgb_image = Image.new(\"RGB\", image.size, (0x00, 0x00, 0x00))\n    mask = None\n\n    if image.mode == \"RGBA\":\n        mask = image.split()[3]  # bands: R=0, G=1, B=2, 1=3\n\n    rgb_image.paste(image, mask=mask)\n\n    return rgb_image"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_pil_image(image, quality=guetzli.DEFAULT_JPEG_QUALITY):\n    image_rgb = _to_pil_rgb_image(image)\n    image_rgb_bytes = image_rgb.tobytes()\n    return guetzli.process_rgb_bytes(\n            image_rgb_bytes,\n            *image.size,\n            quality=quality\n            )", "response": "Generates an optimized JPEG from a PIL image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a file descriptor from a file object.", "response": "def _fileobj_to_fd(fileobj):\n    \"\"\" Return a file descriptor from a file object. If\n    given an integer will simply return that integer back. \"\"\"\n    if isinstance(fileobj, _INTEGER_TYPES):\n        fd = fileobj\n    else:\n        for _integer_type in _INTEGER_TYPES:\n            try:\n                fd = _integer_type(fileobj.fileno())\n                break\n            except (AttributeError, TypeError, ValueError):\n                continue\n        else:\n            raise ValueError(\"Invalid file object: {0!r}\".format(fileobj))\n    if fd < 0:\n        raise ValueError(\"Invalid file descriptor: {0}\".format(fd))\n    return fd"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unregister(self, fileobj):\n        try:\n            key = self._fd_to_key.pop(self._fileobj_lookup(fileobj))\n        except KeyError:\n            raise KeyError(\"{0!r} is not registered\".format(fileobj))\n\n        # Getting the fileno of a closed socket on Windows errors with EBADF.\n        except socket.error as err:\n            if err.errno != errno.EBADF:\n                raise\n            else:\n                for key in self._fd_to_key.values():\n                    if key.fileobj is fileobj:\n                        self._fd_to_key.pop(key.fd)\n                        break\n                else:\n                    raise KeyError(\"{0!r} is not registered\".format(fileobj))\n        return key", "response": "Unregisters a file object from being monitored."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a channel to the list of channels.", "response": "def add_channel(self, channel, pwd_hash):\n        \"\"\"\n        adds a channel, but must have authenication\n        \"\"\"\n        if channel.pwd_hash == pwd_hash:\n            self.channels.append(channel)\n            lg.record_process('comms.py', 'Added channel ' + channel.name)\n\n            return True\n        else:\n            lg.record_process('comms.py', 'ERROR - Cant add channel : wrong hash for ' + channel.name)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_channel(self, channel, pwd_hash):\n        if channel.pwd_hash == pwd_hash:\n            self.channels.remove(channel)\n            lg.record_process('comms.py', 'Removed channel ' + channel.name)\n\n            return True\n        else:\n            lg.record_process('comms.py', 'ERROR - Cant delete : wrong hash for  ' + channel.name)\n            return False", "response": "Delete a channel from the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoes some basic validation of the object", "response": "def prepare(self):\n        \"\"\"\n        does some basic validation\n        \"\"\"\n        try:\n            assert(type(self.sender) is Channel)\n            assert(type(self.receiver) is Channel)\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self):\n        #print('sending message to ' + self.receiver)\n        if self.prepare():\n            ## TODO - send message via library\n            print('sending message')\n            lg.record_process('comms.py', 'Sending message ' + self.title)\n\n            return True\n        else:\n            return False", "response": "sends a message to the receiver"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buildIndex(ipFile, ndxFile, append='Y', silent='N', useShortFileName='Y'):\n    if silent == 'N':\n        pass\n    if append == 'N':\n        try:\n            os.remove(ndxFile)\n        except Exception as ex:\n            print('file already deleted - ignore' + str(ex))\n            \n    delims = [',', chr(31), '\u001f', '$', '&', '\"', '%', '/', '\\\\', '.', ';', ':', '!', '?', '-', '_', ' ', '\\n', '*', '\\'', '(', ')', '[', ']', '{', '}']\n    # 1st pass - index the ontologies, including 2 depths up (later - TODO)\n    #buildIndex(ipFile, ndxFile, ' ', 1, 'Y')\n\n    # 2nd pass - use ALL delims to catch each word as part of hyphenated - eg AI Build py\n    totWords, totLines, uniqueWords = getWordList(ipFile, delims)\n    \n    AppendIndexDictionaryToFile(uniqueWords, ndxFile, ipFile, useShortFileName)\n    if silent == 'N':\n        print(format_op_row(ipFile, totLines, totWords, uniqueWords))\n   \n        show('uniqueWords', uniqueWords, 5)\n    DisplayIndexAsDictionary(uniqueWords)", "response": "This function builds an index of a text file specifically for use in AIKIF."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_op_row(ipFile, totLines, totWords, uniqueWords):\n    txt = os.path.basename(ipFile).ljust(36) + ' '\n    txt += str(totLines).rjust(7) + ' '\n    txt += str(totWords).rjust(7) + ' '\n    txt += str(len(uniqueWords)).rjust(7) + ' '\n    return txt", "response": "Format the output row with stats\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_op_hdr():\n    txt = 'Base Filename'.ljust(36) + ' '\n    txt += 'Lines'.rjust(7) + ' '\n    txt += 'Words'.rjust(7) + '  '\n    txt += 'Unique'.ljust(8) + ''\n    return txt", "response": "Build the header for the operation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AppendIndexDictionaryToFile(uniqueWords, ndxFile, ipFile, useShortFileName='Y'):\n    if useShortFileName == 'Y':\n        f = os.path.basename(ipFile)\n    else:\n        f = ipFile\n    with open(ndxFile, \"a\", encoding='utf-8', errors='replace') as ndx:\n        word_keys = uniqueWords.keys()\n        #uniqueWords.sort()\n        for word in sorted(word_keys):\n            if word != '':\n                line_nums = uniqueWords[word]\n                ndx.write(f + ', ' + word + ', ')\n                for line_num in line_nums:\n                    ndx.write(str(line_num))\n                ndx.write('\\n')", "response": "Append the list of unique words to the master list \n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying the index as a dictionary.", "response": "def DisplayIndexAsDictionary(word_occurrences):\n    \"\"\" \n    print the index as a dict \n    \"\"\"\n    word_keys = word_occurrences.keys()\n    for num, word in enumerate(word_keys):\n        line_nums = word_occurrences[word]\n        print(word + \" \")\n        if num > 3:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show(title, lst, full=-1):\n    txt = title + ' (' + str(len(lst)) + ') items :\\n '\n    num = 0\n    for i in lst:\n        if full == -1 or num < full:\n            if type(i) is str:\n                txt = txt + i + ',\\n '\n            else:\n                txt = txt + i + ', ['\n                for j in i:\n                    txt = txt + j + ', '\n                txt = txt + ']\\n'\n        num = num + 1\n    try:\n        print(txt)\n    except Exception as ex:\n        print('index.show() - cant print line, error ' + str(ex))", "response": "shows a list of items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getWordList(ipFile, delim):\n    indexedWords = {}\n    totWords = 0\n    totLines = 0\n    with codecs.open(ipFile, \"r\",encoding='utf-8', errors='replace') as f:\n        for line in f:\n            totLines = totLines + 1\n            words = multi_split(line, delim)\n            totWords = totWords + len(words)\n            for word in words:\n                cleanedWord = word.lower().strip()\n                if cleanedWord not in indexedWords:\n                    indexedWords[cleanedWord] =  str(totLines)\n                else:\n                    indexedWords[cleanedWord] = indexedWords[cleanedWord] + ' ' + str(totLines)\n    return totWords, totLines, indexedWords", "response": "extract a unique list of words and have line numbers that word appears\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef multi_split(txt, delims):\n    res = [txt]\n    for delimChar in delims:\n        txt, res = res, []\n        for word in txt:\n            if len(word) > 1:\n                res += word.split(delimChar)\n    return res", "response": "split by multiple delimiters \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconsolidates the file with one index file per word which shows the word file and line number of the line.", "response": "def consolidate(ipFile, opFile):\n    \"\"\"\n    make a single index file with 1 record per word which shows the word, file and linenums\n        # storms, knowledge.csv - 3\n        # string, rawData.csv - 1\n        # structure, EVENT_SYSTEM-PC-FILE.CSV - 18, OBJECT_SYSTEM-PC-FILE.CSV - 4, sample-filelist-for-AIKIF.csv - 18 18\n        # subgoal, goals.csv - 3 4 12 13 14, goal_types.csv - 8\n        # subgoals, goal_types.csv - 9\n        # subgoals;, goals.csv - 2\n    \"\"\"\n    curFile = ''\n    curWord = ''\n    curLineNums = ''\n    indexedWords = {}\n    with open(ipFile, \"r\", encoding='utf-8', errors='replace') as ip:\n        for line in ip:\n            cols = line.split(',')\n            curFile = cols[0]\n            curWord = cols[1]\n            curLineNums = cols[2].strip()\n            #DebugIndexing(curFile, curWord, curLineNums, line)\n            if curWord in indexedWords:\n                indexedWords[curWord] =  indexedWords[curWord] + ', ' + curFile + ' - ' + curLineNums\n            else:\n                indexedWords[curWord] = curFile + ' - ' + curLineNums\n    with open(opFile, \"w\",encoding='utf-8', errors='replace') as op:\n        op.write('word, filenames\\n')  # this shows which words appear in which files\n        word_keys = indexedWords.keys()\n        for word in sorted(word_keys):\n            if word != '':\n                line_nums = indexedWords[word]\n                op.write(word + ', ')\n                for line_num in line_nums:\n                    op.write(str(line_num))\n            op.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares and creating script.", "response": "def creator(entry, config):\n        \"\"\"Preparing and creating script.\"\"\"\n        script = render(config.script, model=config.model, env=config.env, item=config.item)\n\n        temp = tempfile.NamedTemporaryFile(prefix=\"script-\", suffix=\".py\", mode='w+t', delete=False)\n        temp.writelines(script)\n        temp.close()\n\n        language = 'python' if 'type' not in entry else entry['type']\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/%s-script.sh.j2' % language)\n\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, script=temp.name)\n\n        return Script(config)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef force_to_string(unknown):\n    result = ''\n    if type(unknown) is str:\n        result = unknown\n    if type(unknown) is int:\n        result = str(unknown)\n    if type(unknown) is float:\n        result = str(unknown)\n    if type(unknown) is dict:\n        result = Dict2String(unknown)\n    if type(unknown) is list:\n        result = List2String(unknown)\n    return result", "response": "converts and unknown type to string for display purposes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_watch_point(self, string, rating, importance=5):\n        d = {}\n        d['string'] = string\n        d['rating'] = rating\n        d['importance'] = importance\n        self.watch_points.append(d)", "response": "Adds a watch point to the list of watch points that can be used in aggregation and extraction of the log session."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_session_id(self):\n        max_session = '0'\n        try:\n            with open(self.log_folder + os.sep + '_sessions.txt', 'r') as f:\n                for _ in f:\n                    txt = f.readline()\n                    if txt.strip('\\n') != '':\n                        max_session = txt\n        except Exception:\n            max_session = '1'\n        \n        this_session = str(int(max_session) + random.randint(9,100)).zfill(9) # not a great way to ensure uniqueness - TODO FIX  \n        with open(self.log_folder + os.sep + '_sessions.txt', 'a') as f2:\n            f2.write(this_session + '\\n')\n        return this_session", "response": "get a unique id for the log record"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef estimate_complexity(self, x,y,z,n):\n        num_calculations = x * y * z * n\n        run_time = num_calculations / 100000  # a 2014 PC does about 100k calcs in a second (guess based on prior logs)\n        return self.show_time_as_short_string(run_time)", "response": "estimate the complexity of the object based on product of parameters \n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting seconds to a string in terms of seconds -> years to show complexity of algorithm", "response": "def show_time_as_short_string(self, seconds):\n        \"\"\" \n        converts seconds to a string in terms of \n        seconds -> years to show complexity of algorithm\n        \"\"\"\n        if seconds < 60:\n            return str(seconds) + ' seconds'\n        elif seconds < 3600:\n            return str(round(seconds/60, 1)) + ' minutes'\n        elif seconds < 3600*24:\n            return str(round(seconds/(60*24), 1)) + ' hours'\n        elif seconds < 3600*24*365:\n            return str(round(seconds/(3600*24), 1)) + ' days'\n        else:\n            print('WARNING - this will take ' + str(seconds/(60*24*365)) + ' YEARS to run' )\n            return str(round(seconds/(60*24*365), 1)) + ' years'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _log(self, fname, txt, prg=''):\n        if os.sep not in fname:\n            fname = self.log_folder + os.sep + fname\n        delim = ','\n        q = '\"'\n        dte = TodayAsString()\n        usr = GetUserName()\n        hst = GetHostName()\n        i = self.session_id\n \n        if prg == '':\n            prg = 'cls_log.log' \n        logEntry = q + dte + q + delim + q + i + q + delim + q + usr + q + delim + q + hst + q + delim + q + prg + q + delim + q + txt + q + delim + '\\n'\n        with open(fname, \"a\", encoding='utf-8', errors='replace') as myfile:\n            myfile.write(logEntry)", "response": "Logs an entry to fname along with standard date and user details"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to collect raw data from the web and hard drive Examples - new source file for ontologies, email contacts list, folder for xmas photos", "response": "def record_source(self, src, prg=''):\n        \"\"\"\n        function to collect raw data from the web and hard drive\n        Examples - new source file for ontologies, email contacts list, folder for xmas photos\n        \"\"\"\n        self._log(self.logFileSource , force_to_string(src), prg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef record_process(self, process, prg=''):\n        self._log(self.logFileProcess, force_to_string(process), prg)", "response": "record a process or program"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef record_command(self, cmd, prg=''):\n        self._log(self.logFileCommand , force_to_string(cmd), prg)", "response": "record the command passed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrecords the output of the command", "response": "def record_result(self, res, prg=''):\n        \"\"\"\n        record the output of the command. Records the result, can have \n        multiple results, so will need to work out a consistent way to aggregate this\n        \"\"\"\n        self._log(self.logFileResult , force_to_string(res), prg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_by_program(self, prg, opFile):\n        log_1 = open(self.process_file, 'r')\n        log_2 = open(self.command_file, 'r')\n        log_3 = open(self.result_file, 'r')\n        log_4 = open(self.source_file, 'r')\n        \n        with open(opFile, 'a') as f:\n            for line in log_1:\n                if prg in line:\n                    f.write('PROCESS, ' + line)\n            for line in log_2:\n                if prg in line:\n                    f.write('COMMAND, ' + line)\n            for line in log_3:\n                if prg in line:\n                    f.write('RESULT, ' + line)\n            for line in log_4:\n                if prg in line:\n                    f.write('SOURCE, ' + line)\n                    \n        log_1.close()\n        log_2.close()\n        log_3.close()\n        log_4.close()", "response": "Filter the log files by program."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a logfile and return entries for a program", "response": "def extract_logs(self, fname, prg):\n        \"\"\"\n        read a logfile and return entries for a program\n        \"\"\"\n        op = []\n        with open(fname, 'r') as f:\n            for line in f:\n                if prg in line:\n                    op.append(line)\n        return op"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake the logfiles and produces an event summary matrix for each log entry.", "response": "def summarise_events(self):\n        \"\"\"\n        takes the logfiles and produces an event summary matrix\n            date        command result  process source\n            20140421    9       40      178     9\n            20140423    0       0       6       0\n            20140424    19      1       47      19\n            20140425    24      0       117     24\n            20140426    16      0       83      16\n            20140427    1       0       6       1\n            20140429    0       0       0       4\n\n        \"\"\"\n        all_dates = []\n        d_command = self._count_by_date(self.command_file, all_dates)\n        d_result  = self._count_by_date(self.result_file,  all_dates)\n        d_process = self._count_by_date(self.process_file, all_dates)\n        d_source  = self._count_by_date(self.source_file,  all_dates)\n\n        with open(self.log_sum, \"w\") as sum_file:\n            sum_file.write('date,command,result,process,source\\n')\n            for dte in sorted(set(all_dates)):\n                sum_file.write(dte + ',')\n                if dte in d_command:\n                    sum_file.write(str(d_command[dte]) + ',')\n                else:\n                    sum_file.write('0,')\n                if dte in d_result:\n                    sum_file.write(str(d_result[dte]) + ',')\n                else:\n                    sum_file.write('0,')\n                if dte in d_process:\n                    sum_file.write(str(d_process[dte]) + ',')\n                else:\n                    sum_file.write('0,')\n                if dte in d_source:\n                    sum_file.write(str(d_source[dte]) + '\\n')\n                else:\n                    sum_file.write('0\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _count_by_date(self, fname, all_dates):\n        if not os.path.isfile(fname):\n            return {}\n        d_log_sum = {}\n        with open(fname, \"r\") as raw_log:\n            for line in raw_log:\n                cols = line.split(',')\n                dte = cols[0].strip('\"')[0:10].replace('-', '')\n                all_dates.append(dte)\n                if dte in d_log_sum:\n                    d_log_sum[dte] += 1\n                else:\n                    d_log_sum[dte] = 1\n        return d_log_sum", "response": "reads a logfile and returns a dictionary by date and count the log entries"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprovides a mapping from the CSV file to the aikif data structures.", "response": "def map_data(self):\n        \"\"\"\n        provides a mapping from the CSV file to the \n        aikif data structures.\n        \"\"\"\n        with open(self.src_file, \"r\") as f:\n            for line in f:\n                cols = line.split(',')\n                print(cols)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the dependent peptides table and extract localiztion information", "response": "def read_dependent_peptides(filename):\n    \"\"\" read the dependent peptides table and extract localiztion information\n    :param filename: path to the 'allPeptides.txt' table.\n    :returns dep, localization: the dependent peptide table, localization information.\n    \"\"\"\n    df = (pd.read_perseus(filename, usecols=_cols)\n            .dropna(subset=['DP Ratio mod/base']))\n    df['DP Ratio mod/base'] = df['DP Ratio mod/base'].astype(float)\n    dep = df.pivot_table('DP Ratio mod/base', index=_index_columns,\n                columns='Raw file', aggfunc=np.median)\n    localization = _count_localizations(df)\n    return dep, localization"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_column_names(dep, exp):\n    colnames = exp['Experiment'].astype(str) + '_' + exp['Fraction'].astype(str)\n    file2col = dict(zip(exp['Raw file'], colnames))\n    _dep = dep.rename(columns=file2col)\n    _dep.columns.name = 'Column Name'\n    return _dep", "response": "rename the columns in the dependent peptides table from\n    the raw file to the corresponding experiment}_{fraction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncounting occurences in a list of lists", "response": "def count(args):\n    \"\"\" count occurences in a list of lists\n    >>> count([['a','b'],['a']])\n    defaultdict(int, {'a' : 2, 'b' : 1})\n    \"\"\"\n    counts = defaultdict(int)\n    for arg in args:\n        for item in arg:\n            counts[item] = counts[item] + 1\n    return counts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the most likely localization for each depentent peptide.", "response": "def _count_localizations(df):\n    \"\"\" count the most likely localization for each depentent peptide.\n    :param df: allPeptides.txt table.\n    \"\"\"\n    grp = df.groupby(_index_columns)\n    counts = grp['DP AA'].apply(lambda x: count(x.str.split(';').values))\n    counts.index = counts.index.set_names('DP AA', level=4)\n    counts.name = 'DP AA count'\n    best_localization = counts.reset_index().groupby(_index_columns).apply(_frequent_localizations)\n    return best_localization"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _frequent_localizations(df):\n    max_count = int(df['DP AA count'].max())\n    max_aa = set(df[df['DP AA count'] == max_count]['DP AA'].unique())\n    result = {'DP AA max count' : max_count}\n    if 'nterm' in max_aa:\n        result['DP AA'] = 'nterm'\n    else:\n        result['DP AA'] = ';'.join(sorted(max_aa))\n    return pd.Series(result)", "response": "Returns the most frequent localization for any dependent peptide."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform a allPeptides. txt and experimentalDesign. txt table into the dependentPeptides. txt table written in outfile.", "response": "def run_dependent_peptides_from_parameters(paramfile, outfile):\n    \"\"\" transform a allPeptides.txt and experimentalDesign.txt table\n    into the dependentPeptides.txt table written in outfile.\n    :param paramfile: Perseus parameters.xml including at least two FileParam\n    entries names 'allPeptides.txt' and 'experimentalDesign.txt'.\n    :param outfile: Path to the output file.\n    \"\"\"\n    parameters = parse_parameters(paramfile)\n    allPeptides_file = fileParam(parameters, 'allPeptides.txt')\n    rawFilesTable_file = fileParam(parameters, 'Raw files table')\n    run_dependent_peptides(allPeptides_file, rawFilesTable_file, outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms a allPeptides. txt and experimentalDesign. txt table into the dependentPeptides. txt table written in outfile.", "response": "def run_dependent_peptides(allPeptides_file, rawFilesTable_file, outfile):\n    \"\"\" transform a allPeptides.txt and experimentalDesign.txt table\n    into the dependentPeptides.txt table written in outfile.\n    :param allPeptides_file: MaxQuant 'allPeptides.txt' output table.\n    :param rawFilesTable_file: MaxQuant 'Raw files'-tab table.\n    :param outfile: Path to the output file.\n    \"\"\"\n    __dep, localization = read_dependent_peptides(allPeptides_file)\n    exp = read_rawFilesTable(rawFilesTable_file)\n    _dep = _set_column_names(__dep, exp)\n    main_columns = list(_dep.columns)\n    dep = _dep.join(localization).reset_index()\n    dep.to_perseus(outfile, main_columns=main_columns)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef variablename(var):\n    s=[tpl[0] for tpl in itertools.ifilter(lambda x: var is x[1], globals().items())]\n    s=s[0].upper()\n    return s", "response": "Returns the string of a variable name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a blast query online. As in https://ncbi.github.io/blast-cloud/ :param query: Search query. Allowed values: Accession, GI, or FASTA. :param database: BLAST database. Allowed values: nt, nr, refseq_rna, refseq_protein, swissprot, pdbaa, pdbnt :param program: BLAST program. Allowed values: blastn, megablast, blastp, blastx, tblastn, tblastx :param filter: Low complexity filtering. Allowed values: F to disable. T or L to enable. Prepend \"m\" for mask at lookup (e.g., mL) :param format_type: Report type. Allowed values: HTML, Text, XML, XML2, JSON2, or Tabular. HTML is the default. :param expect: Expect value. Allowed values: Number greater than zero. :param nucl_reward: Reward for matching bases (BLASTN and megaBLAST). Allowed values: Integer greater than zero. :param nucl_penalty: Cost for mismatched bases (BLASTN and megaBLAST). Allowed values: Integer less than zero. :param gapcosts: Gap existence and extension costs. Allowed values: Pair of positive integers separated by a space such as \"11 1\". :param matrix: Scoring matrix name. Allowed values: One of BLOSUM45, BLOSUM50, BLOSUM62, BLOSUM80, BLOSUM90, PAM250, PAM30 or PAM70. Default: BLOSUM62 for all applicable programs. :param hitlist_size: Number of databases sequences to keep. Allowed values: Integer greater than zero. :param descriptions: Number of descriptions to print (applies to HTML and Text). Allowed values: Integer greater than zero. :param alignments: Number of alignments to print (applies to HTML and Text). Allowed values: Integer greater than zero. :param ncbi_gi: Show NCBI GIs in report. Allowed values: T or F. :param threshold: Neighboring score for initial words. Allowed values: Positive integer (BLASTP default is 11). Does not apply to BLASTN or MegaBLAST). :param word_size: Size of word for initial matches. Allowed values: Positive integer. :param composition_based_statistics: Composition based statistics algorithm to use. Allowed values: One of 0, 1, 2, or 3. See comp_based_stats command line option in the BLAST+ user manual for details. :param organism: an organism as in https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome :param others: here you can add other parameters as seen in a blast bookmarked page. Define you query in https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome Once your query is defined click on \"Bookmark\" on right upper side of the page. You can copy fragments of the URL which define the query. Eg. For organism \"Homo sapiens (taxid:9606)\" you will see the string \"EQ_MENU=Homo%20sapiens%20%28taxid%3A9606%29\" - this is the string you can use here in others. :param num_threads: Number of virtual CPUs to use. Allowed values: Integer greater than zero (default is 1). Supported only on the cloud. :param verbose: print more :returns: BLAST search request identifier", "response": "def BLASTquery(query,database,program,filter=None,\\\n               format_type=None, expect=None,\\\n               nucl_reward=None, nucl_penalty=None,\\\n               gapcosts=None, matrix=None,\\\n               hitlist_size=None, descriptions=None,\\\n               alignments=None,\\\n               ncbi_gi=None, threshold=None,\\\n               word_size=None, composition_based_statistics=None,\\\n               organism=None, others=None,\\\n               num_threads=None, baseURL=\"http://blast.ncbi.nlm.nih.gov\",\\\n              verbose=False):\n    \"\"\"\n    Performs a blast query online.\n\n    As in https://ncbi.github.io/blast-cloud/\n\n    :param query: Search query. Allowed values: Accession, GI, or FASTA.\n    :param database: BLAST database. Allowed values: nt, nr, refseq_rna, refseq_protein, swissprot, pdbaa, pdbnt\n    :param program: BLAST program. Allowed values:  blastn, megablast, blastp, blastx, tblastn, tblastx\n    :param filter: Low complexity filtering. Allowed values: F to disable. T or L to enable. Prepend \"m\" for mask at lookup (e.g., mL)\n    :param format_type: Report type. Allowed values: HTML, Text, XML, XML2, JSON2, or Tabular. HTML is the default.\n    :param expect: Expect value. Allowed values: Number greater than zero.\n    :param nucl_reward: Reward for matching bases (BLASTN and megaBLAST). Allowed values: Integer greater than zero.\n    :param nucl_penalty: Cost for mismatched bases (BLASTN and megaBLAST). Allowed values: Integer less than zero.\n    :param gapcosts: Gap existence and extension costs. Allowed values: Pair of positive integers separated by a space such as \"11 1\".\n    :param matrix: Scoring matrix name. Allowed values: One of BLOSUM45, BLOSUM50, BLOSUM62, BLOSUM80, BLOSUM90, PAM250, PAM30 or PAM70. Default: BLOSUM62 for all applicable programs.\n    :param hitlist_size: Number of databases sequences to keep. Allowed values: Integer greater than zero.\n    :param descriptions: Number of descriptions to print (applies to HTML and Text). Allowed values: Integer greater than zero.\n    :param alignments: Number of alignments to print (applies to HTML and Text). Allowed values: Integer greater than zero.\n    :param ncbi_gi: Show NCBI GIs in report. Allowed values: T or F.\n    :param threshold: Neighboring score for initial words. Allowed values: Positive integer (BLASTP default is 11). Does not apply to BLASTN or MegaBLAST).\n    :param word_size: Size of word for initial matches. Allowed values: Positive integer.\n    :param composition_based_statistics: Composition based statistics algorithm to use. Allowed values: One of 0, 1, 2, or 3. See comp_based_stats command line option in the BLAST+ user manual for details.\n    :param organism: an organism as in https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome\n    :param others: here you can add other parameters as seen in a blast bookmarked page. Define you query in https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome\n            Once your query is defined click on \"Bookmark\" on right upper side of the page. You can copy fragments of the URL\n            which define the query. Eg. For organism \"Homo sapiens (taxid:9606)\" you will see the string \"EQ_MENU=Homo%20sapiens%20%28taxid%3A9606%29\" - this is\n            the string you can use here in others.\n    :param num_threads: Number of virtual CPUs to use. Allowed values: Integer greater than zero (default is 1). Supported only on the cloud.\n    :param verbose: print more\n\n    :returns: BLAST search request identifier\n    \"\"\"\n\n    if organism:\n        organism=organism.replace(\" \", \"%20\").replace(\"(\", \"%28\").replace(\")\", \"%29\").replace(\":\", \"%3A\")\n        EQ_MENU=organism\n    else:\n        EQ_MENU=None\n\n    URL=baseURL+\"/Blast.cgi?\"\n    URL=URL+\"QUERY=\"+str(query)+\"&DATABASE=\"+str(database)+\"&PROGRAM=\"+str(program)\n    for o,varname in zip([filter, format_type, expect, nucl_reward, nucl_penalty,\\\n              gapcosts, matrix, hitlist_size, descriptions, alignments,\\\n              ncbi_gi, threshold, word_size, composition_based_statistics,\\\n              EQ_MENU, num_threads],\\\n              ['FILTER' , 'FORMAT_TYPE', 'EXPECT', 'NUCL_REWARD', 'NUCL_PENALTY',\\\n              'GAPCOSTS', 'MATRIX', 'HITLIST_SIZE', 'DESCRIPTIONS', 'ALIGNMENTS',\\\n              'NCBI_GI', 'THRESHOLD', 'WORD_SIZE', 'COMPOSITION_BASED_STATISTICS',\\\n              'EQ_MENU', 'NUM_THREADS']):\n        if o:\n            URL=URL+\"&\"+ varname +\"=\"+str(o)\n\n    if others:\n        URL=URL+\"&\"+others\n\n    URL=URL+\"&CMD=Put\"\n\n    if verbose:\n        print(URL)\n        sys.stdout.flush()\n\n    response=requests.get(url = URL)\n    r=response.content.split(\"\\n\")\n    RID=[ s for s in r if \"RID = \" in s ]\n    if len(RID) > 0:\n        RID=RID[0].split(\" \")[-1]\n    else:\n        print(\"Could not return an RID for this query.\")\n        RID=None\n    return RID"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the status of a BLAST query.", "response": "def BLASTcheck(rid,baseURL=\"http://blast.ncbi.nlm.nih.gov\"):\n    \"\"\"\n    Checks the status of a query.\n\n    :param rid: BLAST search request identifier. Allowed values: The Request ID (RID) returned when the search was submitted\n    :param baseURL: server url. Default=http://blast.ncbi.nlm.nih.gov\n\n    :returns status: status for the query.\n    :returns therearehist: yes or no for existing hits on a finished query.\n    \"\"\"\n\n    URL=baseURL+\"/Blast.cgi?\"\n    URL=URL+\"FORMAT_OBJECT=SearchInfo&RID=\"+rid+\"&CMD=Get\"\n    response=requests.get(url = URL)\n    r=response.content.split(\"\\n\")\n    try:\n        status=[ s for s in r if \"Status=\" in s ][0].split(\"=\")[-1]\n        ThereAreHits=[ s for s in r if \"ThereAreHits=\" in s ][0].split(\"=\")[-1]\n    except:\n        status=None\n        ThereAreHits=None\n\n    print(rid, status, ThereAreHits)\n    sys.stdout.flush()\n\n    return status, ThereAreHits"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BLASTresults(rid, format_type=\"Tabular\", \\\n                 hitlist_size= None, alignments=None, \\\n                 ncbi_gi = None, format_object=None,\\\n                 baseURL=\"http://blast.ncbi.nlm.nih.gov\"):\n    \"\"\"\n    Retrieves results for an RID.\n\n    :param rid: BLAST search request identifier. Allowed values: The Request ID (RID) returned when the search was submitted\n    :param format_type: Report type. Allowed values: HTML, Text, XML, XML2, JSON2, or Tabular. Tabular is the default.\n    :param hitlist_size: Number of databases sequences to keep. Allowed values: Integer greater than zero.\n    :param alignments: Number of alignments to print (applies to HTML and Text). Allowed values: Integer greater than zero.\n    :param ncbi_gi: Show NCBI GIs in report. Allowed values: T or F.\n    :param format_object: Object type. Allowed values: SearchInfo (status check) or Alignment (report formatting).\n    :param baseURL: server url. Default=http://blast.ncbi.nlm.nih.gov\n\n    :returns: the result of a BLAST query. If format_type=\"Tabular\" it will parse the content into a Pandas dataframe.\n    \"\"\"\n\n    URL=baseURL+\"/Blast.cgi?\"\n    URL=URL+\"RID=\"+str(rid)+\"&FORMAT_TYPE=\"+str(format_type)\n    for o in [ hitlist_size, alignments,\\\n              ncbi_gi, format_object]:\n        if o:\n            URL=URL+\"&\"+ variablename(var) +\"=\"+str(o)\n    URL=URL+\"&CMD=Get\"\n    response=requests.get(url = URL)\n    response=response.content\n\n    if format_type==\"Tabular\":\n        result=response.split(\"\\n\")\n        result=[ s.split(\"\\t\") for s in result][6:]\n        header=result[:7]\n        content=result[7:]\n        fields=header[5][0].strip(\"# Fields: \").split(\", \")\n        result=pd.DataFrame(content,columns=fields)\n        response=result[:int(header[-1][0].split(\" \")[1])]\n\n    return response", "response": "Returns the results of a BLAST query for a given RID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate HTML report. Args: store (Store): report data. Returns: str: rendered HTML template.", "response": "def generate_html(store):\n    \"\"\"\n    Generating HTML report.\n\n    Args:\n        store (Store): report data.\n\n    Returns:\n        str: rendered HTML template.\n    \"\"\"\n    spline = {\n        'version': VERSION,\n        'url': 'https://github.com/Nachtfeuer/pipeline',\n        'generated': datetime.now().strftime(\"%A, %d. %B %Y - %I:%M:%S %p\")\n    }\n\n    html_template_file = os.path.join(os.path.dirname(__file__), 'templates/report.html.j2')\n    with open(html_template_file) as handle:\n        html_template = handle.read()\n        return render(html_template, spline=spline, store=store)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(store, report_format, path):\n    success = False\n    if report_format in ['html']:\n        rendered_content = {\n            'html': generate_html\n        }[report_format](store)\n\n        if not os.path.isdir(path):\n            os.makedirs(path)\n\n        if rendered_content is not None:\n            # writing report file\n            with open(os.path.join(path, 'pipeline.' + report_format), 'w') as handle:\n                handle.write(rendered_content)\n            success = True\n    else:\n        Logger.get_logger(__name__).error(\"Unknown report format %s\", report_format)\n    return success", "response": "Generate a new file in defined format representing the report of pipeline(s."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the beginning of a list.", "response": "def __begin_of_list(self, ast_token):\n        \"\"\"Handle begin of a list.\"\"\"\n        self.list_level += 1\n        if self.list_level == 1:\n            self.final_ast_tokens.append(ast_token)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __end_of_list(self, ast_token):\n        self.list_level -= 1\n        if self.list_level == 0:\n            if self.list_entry is not None:\n                self.final_ast_tokens.append(self.list_entry)\n                self.list_entry = None\n            self.final_ast_tokens.append(ast_token)", "response": "Handle end of a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __default(self, ast_token):\n        if self.list_level == 1:\n            if self.list_entry is None:\n                self.list_entry = ast_token\n            elif not isinstance(ast_token, type(self.list_entry)):\n                self.final_ast_tokens.append(ast_token)\n        elif self.list_level == 0:\n            self.final_ast_tokens.append(ast_token)", "response": "Handle tokens inside the list or outside the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compress(self):\n        for ast_token in self.ast_tokens:\n            if type(ast_token) in self.dispatcher:  # pylint: disable=unidiomatic-typecheck\n                self.dispatcher[type(ast_token)](ast_token)\n            else:\n                self.dispatcher['default'](ast_token)", "response": "Main function of compression."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets AST tokens for Python condition.", "response": "def get_tokens(condition):\n        \"\"\"\n        Get AST tokens for Python condition.\n\n        Returns:\n            list: list of AST tokens\n        \"\"\"\n        try:\n            ast_tokens = list(ast.walk(ast.parse(condition.strip())))\n        except SyntaxError as exception:\n            Logger.get_logger(__name__).error(\"Syntax error: %s\", exception)\n            ast_tokens = []\n        return ast_tokens"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that each token in order does match the expected types.", "response": "def match_tokens(ast_tokens, ast_types):\n        \"\"\"\n        Verify that each token in order does match the expected types.\n\n        The list provided by `get_tokens` does have three more elements\n        at the beginning of the list which should be always the same\n        for a condition (Module and Expr). Those are automatically\n        added first to the final list of expected types so you don't have\n        to specify it yourself each time.\n\n        >>> tokens = Condition.get_tokens('2 == 3')\n        >>> Condition.match_tokens(tokens, [ast.Compare, ast.Num, ast.Eq, ast.Num])\n        True\n\n        Args:\n            ast_entries (list): list of AST tokens parsers previously.\n            ast_types (list): list of expected AST types.\n\n        Returns:\n            bool: when all tokes match the expected types\n        \"\"\"\n        ast_final_types = [ast.Module, ast.Expr] + ast_types\n        return all(isinstance(ast_token, ast_type)\n                   for ast_token, ast_type in zip(ast_tokens, ast_final_types))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying condition and return True if it is valid.", "response": "def is_valid(condition):\n        \"\"\"\n        Verify condition (format).\n\n        >>> Condition.is_valid('{{ foo }} == 42')\n        True\n        >>> Condition.is_valid('\"{{ foo }}\" == 42')\n        False\n        >>> Condition.is_valid('  not \"{{ foo }}\" == \"42\"  ')\n        True\n        >>> Condition.is_valid('  not {{ foo }} == 42  ')\n        True\n        >>> Condition.is_valid('{{ foo }} in [ 42, 43, 44 ]')\n        True\n        \"\"\"\n        matched = False\n\n        if len(condition) > 0:\n            final_condition = re.sub('{{.*}}', '42', condition)\n            ast_tokens = Condition.get_tokens(final_condition)\n            ast_compressed_tokens = Condition.compress_tokens(ast_tokens)\n\n            for rule in Condition.RULES:\n                if Condition.match_tokens(ast_compressed_tokens, rule['types']):\n                    matched = True\n                    break\n        else:\n            matched = True\n\n        return matched"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind rule for given condition.", "response": "def find_rule(condition):\n        \"\"\"\n        Find rule for given condition.\n\n        Args:\n            condition (str): Python condition as string.\n\n        Returns:\n            str, list, function: found rule name, list of AST tokens for condition\n                                 and verification function.\n        \"\"\"\n        final_condition = re.sub('{{.*}}', '42', condition)\n        ast_tokens = Condition.get_tokens(final_condition)\n        ast_compressed_tokens = Condition.compress_tokens(ast_tokens)\n\n        name = 'undefined'\n        function = lambda tokens: False\n\n        if len(ast_compressed_tokens) > 0:\n            for rule in Condition.RULES:\n                if Condition.match_tokens(ast_compressed_tokens, rule['types']):\n                    name = rule['name']\n                    function = rule['evaluate']\n                    break\n        return name, ast_tokens, function"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evaluate(condition):\n        success = False\n        if len(condition) > 0:\n            try:\n                rule_name, ast_tokens, evaluate_function = Condition.find_rule(condition)\n                if not rule_name == 'undefined':\n                    success = evaluate_function(ast_tokens)\n            except AttributeError as exception:\n                Logger.get_logger(__name__).error(\"Attribute error: %s\", exception)\n        else:\n            success = True\n        return success", "response": "Evaluate a condition and return True if it evaluates to True."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_aikif():\n    if sys.platform[0:3] == 'win':\n        os.system(\"start go_web_aikif.bat\") \n    else:\n        os.system(\"../aikif/web_app/web_aikif.py\")\n        import webbrowser\n        import time\n        time.sleep(1)\n        webbrowser.open('http://127.0.0.1:5000')", "response": "starts the web interface and possibly other processes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_creator_by_name(name):\n    return {'docker(container)': Container.creator,\n            'shell': Bash.creator, 'docker(image)': Image.creator,\n            'python': Script.creator, 'packer': Packer.creator,\n            'ansible(simple)': Ansible.creator}[name]", "response": "Get creator function by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun on shell via multiprocessing.", "response": "def worker(data):\n    \"\"\"Running on shell via multiprocessing.\"\"\"\n    creator = get_creator_by_name(data['creator'])\n    shell = creator(data['entry'],\n                    ShellConfig(script=data['entry']['script'],\n                                title=data['entry']['title'] if 'title' in data['entry'] else '',\n                                model=data['model'], env=data['env'], item=data['item'],\n                                dry_run=data['dry_run'], debug=data['debug'], strict=data['strict'],\n                                variables=data['variables'],\n                                temporary_scripts_path=data['temporary_scripts_path']))\n    output = []\n    for line in shell.process():\n        output.append(line)\n        Logger.get_logger(__name__ + '.worker').info(\" | %s\", line)\n    return {'id': data['id'], 'success': shell.success, 'output': output}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy and merging environment variables.", "response": "def get_merged_env(self, include_os=False):\n        \"\"\"\n        Copying and merging environment variables.\n\n        Args:\n            include_os (bool): when true then include the environment variables (default: False)\n\n        Returns:\n            dict: environment variables as defined in the pipeline\n                  (optional including system environment variables).\n        \"\"\"\n        env = {}\n        if include_os:\n            env.update(os.environ.copy())\n        for level in range(3):\n            env.update(self.pipeline.data.env_list[level].copy())\n        return env"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare one shell or docker task.", "response": "def prepare_shell_data(self, shells, key, entry):\n        \"\"\"Prepare one shell or docker task.\"\"\"\n        if self.can_process_shell(entry):\n            if key in ['python']:\n                entry['type'] = key\n\n            if 'with' in entry and isinstance(entry['with'], str):\n                rendered_with = ast.literal_eval(render(entry['with'],\n                                                        variables=self.pipeline.variables,\n                                                        model=self.pipeline.model,\n                                                        env=self.get_merged_env(include_os=True)))\n            elif 'with' in entry:\n                rendered_with = entry['with']\n            else:\n                rendered_with = ['']\n\n            for item in rendered_with:\n                shells.append({\n                    'id': self.next_task_id,\n                    'creator': key,\n                    'entry': entry,\n                    'model': self.pipeline.model,\n                    'env': self.get_merged_env(),\n                    'item': item,\n                    'dry_run': self.pipeline.options.dry_run,\n                    'debug': self.pipeline.options.debug,\n                    'strict': self.pipeline.options.strict,\n                    'variables': self.pipeline.variables,\n                    'temporary_scripts_path': self.pipeline.options.temporary_scripts_path})\n                self.next_task_id += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a group of tasks.", "response": "def process(self, document):\n        \"\"\"Processing a group of tasks.\"\"\"\n        self.logger.info(\"Processing group of tasks (parallel=%s)\", self.get_parallel_mode())\n        self.pipeline.data.env_list[2] = {}\n\n        output, shells = [], []\n        result = Adapter({'success': True, 'output': []})\n        for task_entry in document:\n            key, entry = list(task_entry.items())[0]\n\n            if (not self.parallel or key == 'env') and len(shells) > 0:\n                result = Adapter(self.process_shells(shells))\n                output += result.output\n                shells = []\n                if not result.success:\n                    break\n\n            if key == 'env':\n                self.pipeline.data.env_list[2].update(entry)\n\n            elif key in ['shell', 'docker(container)', 'docker(image)', 'python',\n                         'packer', 'ansible(simple)']:\n                self.prepare_shell_data(shells, key, entry)\n\n        if result.success:\n            result = Adapter(self.process_shells(shells))\n            output += result.output\n\n        self.event.delegate(result.success)\n        return {'success': result.success, 'output': output}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing a list of shells in parallel.", "response": "def process_shells_parallel(self, shells):\n        \"\"\"Processing a list of shells parallel.\"\"\"\n        output = []\n        success = True\n        with closing(multiprocessing.Pool(multiprocessing.cpu_count())) as pool:\n            for result in [Adapter(entry) for entry in pool.map(worker, [shell for shell in shells])]:\n                output += result.output\n                the_shell = [shell for shell in shells if shell['id'] == result.id][0]\n                self.__handle_variable(the_shell['entry'], result.output)\n                if not result.success:\n                    success = False\n        if success:\n            self.logger.info(\"Parallel Processing Bash code: finished\")\n            return {'success': True, 'output': output}\n\n        for line in self.run_cleanup(shells[0]['env'], 99):\n            output.append(line)\n        self.logger.error(\"Pipeline has failed: immediately leaving!\")\n        self.event.failed()\n        return {'success': False, 'output': output}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing a list of shells one after the other.", "response": "def process_shells_ordered(self, shells):\n        \"\"\"Processing a list of shells one after the other.\"\"\"\n        output = []\n        for shell in shells:\n            entry = shell['entry']\n            config = ShellConfig(script=entry['script'], title=entry['title'] if 'title' in entry else '',\n                                 model=shell['model'], env=shell['env'], item=shell['item'],\n                                 dry_run=shell['dry_run'], debug=shell['debug'], strict=shell['strict'],\n                                 variables=shell['variables'],\n                                 temporary_scripts_path=shell['temporary_scripts_path'])\n            result = Adapter(self.process_shell(get_creator_by_name(shell['creator']), entry, config))\n            output += result.output\n            self.__handle_variable(entry, result.output)\n            if not result.success:\n                return {'success': False, 'output': output}\n        return {'success': True, 'output': output}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_shells(self, shells):\n        result = {'success': True, 'output': []}\n        if self.parallel and len(shells) > 1:\n            result = self.process_shells_parallel(shells)\n        elif len(shells) > 0:\n            result = self.process_shells_ordered(shells)\n        return result", "response": "Processing a list of shells."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef can_process_shell(self, entry):\n        count = 0\n        condition = render(entry['when'], variables=self.pipeline.variables,\n                           model=self.pipeline.model, env=self.get_merged_env(include_os=True))\n\n        if Condition.evaluate(\"\" if condition is None else condition):\n            if len(self.pipeline.options.tags) == 0:\n                return True\n\n            if 'tags' in entry:\n                for tag in self.pipeline.options.tags:\n                    if tag in entry['tags']:\n                        count += 1\n\n        return count > 0", "response": "Returns True when shell can be executed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_shell(self, creator, entry, config):\n        self.logger.info(\"Processing Bash code: start\")\n\n        output = []\n        shell = creator(entry, config)\n        for line in shell.process():\n            output.append(line)\n            self.logger.info(\" | %s\", line)\n\n        if shell.success:\n            self.logger.info(\"Processing Bash code: finished\")\n            return {'success': True, 'output': output}\n\n        for line in self.run_cleanup(config.env, shell.exit_code):\n            output.append(line)\n\n        self.logger.error(\"Pipeline has failed: leaving as soon as possible!\")\n        self.event.failed()\n        return {'success': False, 'output': output}", "response": "Process a single shell entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns cleanup hook when configured.", "response": "def run_cleanup(self, env, exit_code):\n        \"\"\"Run cleanup hook when configured.\"\"\"\n        output = []\n        if self.pipeline.data.hooks and len(self.pipeline.data.hooks.cleanup) > 0:\n            env.update({'PIPELINE_RESULT': 'FAILURE'})\n            env.update({'PIPELINE_SHELL_EXIT_CODE': str(exit_code)})\n            config = ShellConfig(script=self.pipeline.data.hooks.cleanup,\n                                 model=self.pipeline.model, env=env,\n                                 dry_run=self.pipeline.options.dry_run,\n                                 debug=self.pipeline.options.debug,\n                                 strict=self.pipeline.options.strict,\n                                 temporary_scripts_path=self.pipeline.options.temporary_scripts_path)\n            cleanup_shell = Bash(config)\n            for line in cleanup_shell.process():\n                output.append(line)\n                self.logger.info(\" | %s\", line)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the output of a variable name command.", "response": "def __handle_variable(self, shell_entry, output):\n        \"\"\"\n        Saving output for configured variable name.\n\n        Args:\n            shell_entry(dict): shell based configuration (shell, docker container or Python).\n            output: list of strings representing output of last shell\n        \"\"\"\n        if 'variable' in shell_entry:\n            variable_name = shell_entry['variable']\n            self.pipeline.variables[variable_name] = \"\\n\".join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the environment and websites.", "response": "def create(self, num_sites):\n        \"\"\"\n        Creates the environment\n        Code in Base class = self.log.record_process('enviroment.py', 'Creating environment - ' + self.name)\n        \"\"\"\n        super(Internet, self).create(num_sites)\n        #print('building websites')\n        for _ in range(0,num_sites):\n            self.websites.append(Website())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves parameters whose values are set to None.", "response": "def _clean_params(self, params):\n        \"\"\"Removes parameters whose values are set to None.\n        \"\"\"\n        clean_params = {}\n        for key, value in params.iteritems():\n            if value is not None:\n                clean_params[key] = value\n\n        return clean_params"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef distance_to(self, other_catchment):\n        try:\n            if self.country == other_catchment.country:\n                try:\n                    return 0.001 * hypot(self.descriptors.centroid_ngr.x - other_catchment.descriptors.centroid_ngr.x,\n                                         self.descriptors.centroid_ngr.y - other_catchment.descriptors.centroid_ngr.y)\n                except TypeError:\n                    # In case no centroid available, just return infinity which is helpful in most cases\n                    return float('+inf')\n            else:\n                # If the catchments are in a different country (e.g. `ni` versus `gb`) then set distance to infinity.\n                return float('+inf')\n        except (TypeError, KeyError):\n            raise InsufficientDataError(\"Catchment `descriptors` attribute must be set first.\")", "response": "Calculates the distance between the centroids of two catchments in kilometers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef urbext(self, year):\n\n        # Decimal places increased to ensure year 2000 corresponds with 1\n        urban_expansion = 0.7851 + 0.2124 * atan((year - 1967.5) / 20.331792998)\n        try:\n            return self.catchment.descriptors.urbext2000 * urban_expansion\n        except TypeError:\n            # Sometimes urbext2000 is not set, assume zero\n            return 0", "response": "Estimate the urbext2000 parameter for a given year assuming a nation - wide urbanisation curve."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of continuous data periods by removing the data gaps from the overall record.", "response": "def continuous_periods(self):\n        \"\"\"\n        Return a list of continuous data periods by removing the data gaps from the overall record.\n        \"\"\"\n        result = []\n\n        # For the first period\n        start_date = self.start_date\n        for gap in self.pot_data_gaps:\n            end_date = gap.start_date - timedelta(days=1)\n            result.append(PotPeriod(start_date, end_date))\n            # For the next period\n            start_date = gap.end_date + timedelta(days=1)\n        # For the last period\n        end_date = self.end_date\n        result.append(PotPeriod(start_date, end_date))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_path(self, path, path_filter=None):\n        for root, _, files in os.walk(path):\n            for filename in files:\n                full_path_and_filename = os.path.join(root, filename)\n                if path_filter is None or path_filter(full_path_and_filename):\n                    relative_path_and_filename = full_path_and_filename.replace(path + '/', '')\n                    with open(full_path_and_filename, 'rb') as handle:\n                        self.files[relative_path_and_filename] = b64encode(handle.read()).decode('utf-8')", "response": "Adds all files from given path to the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the contents of the files in the cache at a given path.", "response": "def save(self, path):\n        \"\"\"\n        Saving stored files at a given path (relative paths are added).\n\n        Args:\n            path (str): root path where to save the files.\n        \"\"\"\n        for relative_path_and_filename, content in self.files.items():\n            full_path_and_filename = os.path.join(path, relative_path_and_filename)\n            full_path = os.path.dirname(full_path_and_filename)\n\n            if not os.path.isdir(full_path):\n                os.makedirs(full_path)\n\n            with open(full_path_and_filename, 'wb') as handle:\n                handle.write(b64decode(content))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_json(data):\n        memfiles = InMemoryFiles()\n        memfiles.files = json.loads(data)\n        return memfiles", "response": "Convert JSON into a in memory file storage."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_file(f, ignore_errors=False):\n\ttry:\n\t\tos.remove(f)\n\texcept Exception as ex:\n\t\tif ignore_errors:\n\t\t\treturn\n\t\tprint('ERROR deleting file ' + str(ex))", "response": "delete a single file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting all files in folder freldr", "response": "def delete_files_in_folder(fldr):\n\t\"\"\"\n\tdelete all files in folder 'fldr'\n\t\"\"\"\n\tfl = glob.glob(fldr + os.sep + '*.*')\n\tfor f in fl:\n\t\tdelete_file(f, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_file(src, dest):\n\ttry:\n\t\tshutil.copy2(src , dest)\n\texcept Exception as ex:\n\t\tprint('ERROR copying file' + str(ex))", "response": "copy a single file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_files_to_folder(src, dest, xtn='*.txt'):\n\t\n\ttry:\n\t\tall_files = glob.glob(os.path.join(src,xtn))\n\t\tfor f in all_files:\n\t\t\tcopy_file(f, dest)\n\texcept Exception as ex:\n\t\tprint('ERROR copy_files_to_folder - ' + str(ex))", "response": "Copy all the files from src to dest folder"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying all files and subfolders to a new folder.", "response": "def copy_all_files_and_subfolders(src, dest, base_path_ignore, xtn_list):\n\t\"\"\"\n\tfile_tools.copy_all_files_and_subfolders(src, dest, backup_path, ['*.*'])\n\tgets list of all subfolders and copies each file to \n\tits own folder in 'dest' folder\n\tpaths, xtn, excluded, output_file_name = 'my_files.csv')\n\t\"\"\"\n\tensure_dir(dest)\n\tfl = mod_fl.FileList([src], xtn_list, exclude_folders,  '')\n\tall_paths = fl.get_list_of_paths()\n\tfl.save_filelist(os.path.join(dest,'files_backed_up.csv'),  [\"name\", \"path\", \"size\", \"date\"])\n\t\n\tfor p in all_paths:\n\t\tdest_folder = os.path.join(dest, p[len(base_path_ignore):])\n\t\tensure_dir(dest_folder)\n\t\t#print('copying ' + p)\n\t\tcopy_files_to_folder(p, dest_folder, xtn='*')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads an RDF file into a graph", "response": "def load_graph_from_rdf(fname):\n    \"\"\" reads an RDF file into a graph \"\"\"\n    print(\"reading RDF from \" + fname + \"....\")\n    store = Graph()\n    store.parse(fname, format=\"n3\")\n    print(\"Loaded \" + str(len(store)) + \" tuples\")\n    return store"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_graph_summary(g):\n    sample_data = []\n    print(\"list(g[RDFS.Class]) = \" + str(len(list(g[RDFS.Class]))))\n    # Get Subject Lists\n    num_subj = 0\n    for subj in g.subjects(RDF.type):\n        num_subj += 1\n        if num_subj < 5:\n            sample_data.append(\"subjects.subject: \" + get_string_from_rdf(subj))\n    print(\"g.subjects(RDF.type) = \" + str(num_subj))\n    \n    # Get Sample of Subjects, Predicates, Objects\n    num_subj = 0\n    for subj, pred, obj in g:\n        num_subj += 1\n        if num_subj < 5:\n            sample_data.append(\"g.subject   : \" + get_string_from_rdf(pred))\n            sample_data.append(\"g.predicate : \" + get_string_from_rdf(subj))\n            sample_data.append(\"g.object    : \" + get_string_from_rdf(obj))\n            \n    print(\"g.obj(RDF.type) = \" + str(num_subj))\n    \n    \n    print (\"------ Sample Data ------\")\n    for line in sample_data:\n        print(line)", "response": "display sample data from a graph"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting a graph to a CSV file for simpler viewing", "response": "def export(g, csv_fname):\n    \"\"\" export a graph to CSV for simpler viewing \"\"\"\n    with open(csv_fname, \"w\") as f:\n        num_tuples = 0\n        f.write('\"num\",\"subject\",\"predicate\",\"object\"\\n')\n        for subj, pred, obj in g:\n            num_tuples += 1\n            f.write('\"' + str(num_tuples) + '\",')\n            f.write('\"' + get_string_from_rdf(subj) + '\",')\n            f.write('\"' + get_string_from_rdf(pred) + '\",')\n            f.write('\"' + get_string_from_rdf(obj) + '\"\\n')\n    print(\"Finished exporting \" , num_tuples, \" tuples\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the real content from an RDF info object", "response": "def get_string_from_rdf(src):\n    \"\"\" extracts the real content from an RDF info object \"\"\"\n    res = src.split(\"/\") #[:-1]\n    return \"\".join([l.replace('\"', '\"\"') for l in res[len(res) - 1]])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_sample_file(ip, op, num_lines): \n    with open(ip, \"rb\") as f:\n        with open(op, \"wb\") as fout:\n            for _ in range(num_lines):\n                fout.write(f.readline() )", "response": "create a sample file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflattening nested sequences into one.", "response": "def flatten(*sequence):\n        \"\"\"Flatten nested sequences into one.\"\"\"\n        result = []\n        for entry in sequence:\n            if isinstance(entry, list):\n                result += Select.flatten(*entry)\n            elif isinstance(entry, tuple):\n                result += Select.flatten(*entry)\n            else:\n                result.append(entry)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a list of all the entries in the sequence.", "response": "def build(self):\n        \"\"\"Do the query.\"\"\"\n        result = []\n        for entry in self.sequence:\n            ignore = False\n            for filter_function in self.filter_functions:\n                if not filter_function(entry):\n                    ignore = True\n                    break\n            if not ignore:\n                value = entry\n                for transform_function in self.transform_functions:\n                    value = transform_function(value)\n                result.append(value)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the zip file determines compression and unzips recursively until all source files in the zip file are extracted recursively", "response": "def extract_all(zipfile, dest_folder):\n    \"\"\"\n    reads the zip file, determines compression\n    and unzips recursively until source files \n    are extracted \n    \"\"\"\n    z = ZipFile(zipfile)\n    print(z)\n    z.extract(dest_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a zip file from a file", "response": "def create_zip_from_file(zip_file, fname):\n    \"\"\"\n    add a file to the archive\n    \"\"\"\n    with zipfile.ZipFile(zip_file, 'w') as myzip:\n        myzip.write(fname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a zip file from folder fldr", "response": "def create_zip_from_folder(zip_file, fldr, mode=\"r\"):\n    \"\"\"\n    add all the files from the folder fldr\n    to the archive\n    \"\"\"\n    #print('zip from folder - adding folder : ', fldr)\n    zipf = zipfile.ZipFile(zip_file, 'w')\n    for root, dirs, files in os.walk(fldr):\n        for file in files:\n            fullname = os.path.join(root, file)\n            #print('zip - adding file : ', fullname)\n            zipf.write(fullname)\n    \n    \n    zipf.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract(self, dest_fldr, password=''):\n        #print('extracting to ' + dest_fldr)\n        if self.type == 'ZIP':\n            self._extract_zip(dest_fldr, password)\n        elif self.type == 'GZ':\n            self._extract_gz(dest_fldr, password)\n        elif self.type == 'TAR':\n            self._extract_tar(dest_fldr, self.fname)\n        else:\n            raise('Unknown archive file type')", "response": "extract the contents of the file to the dest_fldr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the filename of the first file that matches xtn", "response": "def get_file_named(self, fldr, xtn):\n        \"\"\"\n        scans a directory for files like *.GZ or *.ZIP and returns\n        the filename of the first one found (should only be one of\n        each file here\n        \"\"\"\n        res = []       # list of Sample objects\n        for root, _, files in os.walk(fldr):\n            for basename in files:\n                if fnmatch.fnmatch(basename, xtn):\n                    filename = os.path.join(root, basename)\n                    res.append(filename)\n\n        if len(res) > 0:   \n            return res[0]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef acquire(self, blocking=True, timeout=-1):\n        result = self.lock.acquire(blocking, timeout)\n        return result", "response": "Acquire the :attr:`lock`\n\n        Args:\n            blocking (bool): See :meth:`threading.Lock.acquire`\n            timeout (float): See :meth:`threading.Lock.acquire`\n\n        Returns:\n            bool: :obj:`True` if the lock was acquired, otherwise :obj:`False`"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def acquire_async(self):\n        r = self.acquire(blocking=False)\n        while not r:\n            await asyncio.sleep(.01)\n            r = self.acquire(blocking=False)", "response": "Acquire the lock asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling on event emission and notifies the AioEventWaiters when the event is dispatched.", "response": "def trigger(self, *args, **kwargs):\n        \"\"\"Called on event emission and notifies the :meth:`wait` method\n\n        Called by :class:`AioEventWaiters` when the\n        :class:`~pydispatch.dispatch.Event` instance is dispatched.\n\n        Positional and keyword arguments are stored as instance attributes for\n        use in the :meth:`wait` method and :attr:`aio_event` is set.\n        \"\"\"\n        self.args = args\n        self.kwargs = kwargs\n        self.aio_event.set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def add_waiter(self):\n        loop = asyncio.get_event_loop()\n        async with self.lock:\n            waiter = AioEventWaiter(loop)\n            self.waiters.add(waiter)\n        return waiter", "response": "Add a new AioEventWaiter to the list of waiters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a coroutine function to the event loop.", "response": "def add_method(self, loop, callback):\n        \"\"\"Add a coroutine function\n\n        Args:\n            loop: The :class:`event loop <asyncio.BaseEventLoop>` instance\n                on which to schedule callbacks\n            callback: The :term:`coroutine function` to add\n        \"\"\"\n        f, obj = get_method_vars(callback)\n        wrkey = (f, id(obj))\n        self[wrkey] = obj\n        self.event_loop_map[wrkey] = loop"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over stored coroutine functions Used by the event loop.", "response": "def iter_methods(self):\n        \"\"\"Iterate over stored coroutine functions\n\n        Yields:\n            Stored :term:`coroutine function` objects\n\n        .. seealso:: :meth:`pydispatch.utils.WeakMethodContainer.iter_instances`\n        \"\"\"\n        for wrkey, obj in self.iter_instances():\n            f, obj_id = wrkey\n            loop = self.event_loop_map[wrkey]\n            m = getattr(obj, f.__name__)\n            yield loop, m"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nschedule and await a coroutine on the specified loop.", "response": "def submit_coroutine(self, coro, loop):\n        \"\"\"Schedule and await a coroutine on the specified loop\n\n        The coroutine is wrapped and scheduled using\n        :func:`asyncio.run_coroutine_threadsafe`. While the coroutine is\n        \"awaited\", the result is not available as method returns immediately.\n\n        Args:\n            coro: The :term:`coroutine` to schedule\n            loop: The :class:`event loop <asyncio.BaseEventLoop>` on which to\n                schedule the coroutine\n\n        Note:\n            This method is used internally by :meth:`__call__` and is not meant\n            to be called directly.\n        \"\"\"\n        async def _do_call(_coro):\n            with _IterationGuard(self):\n                await _coro\n        asyncio.run_coroutine_threadsafe(_do_call(coro), loop=loop)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch(self):\n        #os.system(self.fullname) # gives permission denied seeing it needs to be chmod +x\n        import subprocess\n        try:\n            retcode = subprocess.call(self.fullname, shell=True)\n            if retcode < 0:\n                print(\"Child was terminated by signal\", -retcode, file=sys.stderr)\n                return False\n            else:\n                print(\"Child returned\", retcode, file=sys.stderr)\n                return True\n        except OSError as e:\n            print(\"Execution failed:\", e, file=sys.stderr)\n            return False", "response": "launch a file - used for starting html pages"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        if self.fullname != \"\":\n            try:\n                os.remove(self.fullname)\n            except IOError:\n                print(\"Cant delete \",self.fullname)", "response": "delete a file, don't really care if it doesn't exist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_lines_in_file(self, fname=''):\n        i = 0\n        if fname == '':\n            fname = self.fullname\n        try:\n            #with open(fname, encoding=\"utf8\") as f:\n            with codecs.open(fname, \"r\",encoding='utf8', errors='ignore') as f:    \n                for i, _ in enumerate(f):\n                    pass\n            return i + 1    \n        except Exception as ex:\n            print('cant count lines in file in \"', fname, '\":', str(ex))\n            return 0", "response": "count the number of lines in a file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count_lines_of_code(self, fname=''):\n        if fname == '':\n            fname = self.fullname\n        loc = 0    \n        try:\n            with open(fname) as f:\n                for l in f:\n                    if l.strip() != '':\n                        loc += 1\n            return loc    \n        except Exception as ex:\n            print('cant count lines of code in \"', fname, '\":', str(ex))\n            return 0", "response": "count the number of lines of code in a file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_file_sample(self, numLines=10):\n        res = ''\n        try:\n            with open(self.fullname, 'r') as f:\n                for line_num, line in enumerate(f):\n                    res += str(line_num).zfill(5) + ' ' + line \n                    if line_num >= numLines-1:\n                        break\n            return res\n        except Exception as ex:\n            print('cant get_file_sample in \"', self.fullname, '\":', str(ex))\n            return res", "response": "retrieve a sample of the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends a line of text to a file", "response": "def append_text(self, txt):\n        \"\"\" adds a line of text to a file \"\"\"\n        with open(self.fullname, \"a\") as myfile:\n            myfile.write(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a file to a string", "response": "def load_file_to_string(self):\n        \"\"\" load a file to a string \"\"\"\n        try:\n            with open(self.fullname, 'r') as f:\n                txt = f.read()\n            return txt\n        except IOError:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_file_to_list(self):\n        lst = []\n        try:\n            with open(self.fullname, 'r') as f:\n                for line in f:\n                    lst.append(line) \n            return lst  \n        except IOError:\n            return lst", "response": "load a file to a list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_program_list():\n    colList = ['FileName','FileSize','Functions', 'Imports']\n\n    txt = '<TABLE width=90% border=0>'\n    txt += format_file_table_header(colList)\n    fl = web.GetFileList(aikif_folder, ['*.py'], 'N')\n    for f in fl:\n        if '__init__.py' in f:\n            txt += '<TR><TD colspan=4><HR><H3>' + get_subfolder(f) + '</h3></td></tr>\\n'\n        else:\n            txt += format_file_to_html_row(f, colList)\n    txt += '</TABLE>\\n\\n'\n    return txt", "response": "get a HTML formatted view of all Python programs in AIKIF"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts a displayable subfolder name from full filename", "response": "def get_subfolder(txt):\n    \"\"\"\n    extracts a displayable subfolder name from full filename\n    \"\"\"\n    root_folder = os.sep + 'aikif' + os.sep\n    ndx = txt.find(root_folder, 1)\n    return txt[ndx:].replace('__init__.py', '')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of functions from a Python program", "response": "def get_functions(fname):\n    \"\"\" get a list of functions from a Python program \"\"\"\n    txt = '' \n    with open(fname, 'r') as f:\n        for line in f:\n            if line.strip()[0:4] == 'def ':\n                txt += '<PRE>' + strip_text_after_string(strip_text_after_string(line, '#')[4:], ':') + '</PRE>\\n'\n            if line[0:5] == 'class':\n                txt += '<PRE>' + strip_text_after_string(strip_text_after_string(line, '#'), ':') + '</PRE>\\n'\n    return txt + '<BR>'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_text_after_string(txt, junk):\n    if junk in txt:\n        return txt[:txt.find(junk)]\n    else:\n        return txt", "response": "used to strip any poorly documented comments at the end of function defs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of imports from a Python program", "response": "def get_imports(fname):\n    \"\"\" get a list of imports from a Python program \"\"\"\n    txt = ''\n    with open(fname, 'r') as f:\n        for line in f:\n            if line[0:6] == 'import':\n                txt += '<PRE>' + strip_text_after_string(line[7:], ' as ') + '</PRE>\\n'\n    return txt + '<BR>'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, key):  \n        res = self.connection.get(key)\n        print(res)\n        return res", "response": "get a set of keys from redis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting a datatable into the database.", "response": "def import_datatable(self, l_datatable, schema='datatable', col_key=0):\n        \"\"\"\n        import a datatable (grid) by using the schema:table:column as keys.\n        e.g. Sample input ( via cls_database.py -> test.csv)\n        TERM,GENDER,ID,tot1,tot2\n        5320,M,78,18,66\n        1310,M,78,10,12\n        \n        Loads the following:\n        \"\"\"\n        key = ''\n        hdr = l_datatable.get_header()\n        schema_root_key = schema + ':' + os.path.basename(l_datatable.name) + ':'\n        print(hdr)\n        row_num = 0\n        for row_num, row in enumerate(l_datatable.get_arr()):\n            #print(row)\n            for col_num, col in enumerate(row):\n                #print('col_num, col = ', col_num, col)\n                if col and col_num < len(hdr):\n                    key = schema_root_key + row[col_key] + ':' + hdr[col_num]\n                    self.connection.set(key, col)\n                    #self.connection.lpush(key, col)\n        print ('loaded ', str(row_num) , ' rows')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef creator(_, config):\n        packer_script = render(config.script, model=config.model, env=config.env,\n                               variables=config.variables, item=config.item)\n        filename = \"packer.dry.run.see.comment\"\n\n        if not config.dry_run:\n            # writing Packer file (JSON)\n            filename = write_temporary_file(packer_script, 'packer-', '.json')\n            packer_script = ''\n\n        # rendering the Bash script for generating the Packer image\n        template_file = os.path.join(os.path.dirname(__file__), 'templates/packer-image.sh.j2')\n\n        with open(template_file) as handle:\n            template = handle.read()\n            config.script = render(template, debug=config.debug,\n                                   packer_content=packer_script,\n                                   packer_filename=filename)\n\n        return Packer(config)", "response": "Creator function for creating an instance of a Packer image script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating an optimized JPEG from JPEG - encoded bytes.", "response": "def process_jpeg_bytes(bytes_in, quality=DEFAULT_JPEG_QUALITY):\n    \"\"\"Generates an optimized JPEG from JPEG-encoded bytes.\n\n    :param bytes_in: the input image's bytes\n    :param quality: the output JPEG quality (default 95)\n\n    :returns: Optimized JPEG bytes\n    :rtype: bytes\n\n    :raises ValueError: Guetzli was not able to decode the image (the image is\n                        probably corrupted or is not a JPEG)\n\n    .. code:: python\n\n        import pyguetzli\n\n        input_jpeg_bytes = open(\"./test/image.jpg\", \"rb\").read()\n        optimized_jpeg = pyguetzli.process_jpeg_bytes(input_jpeg_bytes)\n    \"\"\"\n    bytes_out_p = ffi.new(\"char**\")\n    bytes_out_p_gc = ffi.gc(bytes_out_p, lib.guetzli_free_bytes)\n\n    length = lib.guetzli_process_jpeg_bytes(\n            bytes_in,\n            len(bytes_in),\n            bytes_out_p_gc,\n            quality\n            )\n\n    if length == 0:\n        raise ValueError(\"Invalid JPEG: Guetzli was not able to decode the image\")  # noqa\n\n    bytes_out = ffi.cast(\"char*\", bytes_out_p_gc[0])\n    return ffi.unpack(bytes_out, length)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_rgb_bytes(bytes_in, width, height, quality=DEFAULT_JPEG_QUALITY):\n    if len(bytes_in) != width * height * 3:\n        raise ValueError(\"bytes_in length is not coherent with given width and height\")  # noqa\n\n    bytes_out_p = ffi.new(\"char**\")\n    bytes_out_p_gc = ffi.gc(bytes_out_p, lib.guetzli_free_bytes)\n\n    length = lib.guetzli_process_rgb_bytes(\n            bytes_in,\n            width,\n            height,\n            bytes_out_p_gc,\n            quality\n            )\n\n    bytes_out = ffi.cast(\"char*\", bytes_out_p_gc[0])\n    return ffi.unpack(bytes_out, length)", "response": "Generates an optimized JPEG from RGB bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_path_BFS(Graph,n,m):\n    if m not in Graph:\n        return None\n    if n == m:\n        return [m]\n    path = [[n]]\n    searched = []\n    while True:\n        j = len(path)\n        #k = len(Graph[n])\n        for i in range(j):\n            node = path[i][-1]\n            for neighbor in Graph[node]:\n                if neighbor not in searched:                    \n                    path.append(path[i]+[neighbor])  \n                    searched.append(neighbor)\n                    if neighbor==m:\n                        return path[-1]\n        for i in range(j):\n            path.pop(0)\n    return path", "response": "Find the path of a node in a Breadth first search of a node in a tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the heuristic cost of the given start and target", "response": "def heuristic_cost(self, start, target):\n        \"\"\" assumes start and target are an (x,y) grid \"\"\"\n        (x1, y1) = start\n        (x2, y2) = target\n        return abs(x1 - x2) + abs(y1 - y2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a 2048 starting board Printing Grid 2 4 } }", "response": "def build_board_2048():\n    \"\"\" builds a 2048 starting board \n    Printing Grid\n     0     0     0     2\n     0     0     4     0\n     0     0     0     0\n     0     0     0     0\n\n    \"\"\"\n    grd = Grid(4,4, [2,4])\n    grd.new_tile()\n    grd.new_tile()\n    print(grd)\n    return grd"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a checkers starting board", "response": "def build_board_checkers():\n    \"\"\" builds a checkers starting board \n    Printing Grid\n     0     B     0     B     0     B     0     B\n     B     0     B     0     B     0     B     0\n     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0\n     0     W     0     W     0     W     0     W\n     W     0     W     0     W     0     W     0\n    \"\"\"\n    grd = Grid(8,8, [\"B\",\"W\"])\n    for c in range(4):\n        grd.set_tile(0,(c*2) - 1, \"B\")\n        grd.set_tile(1,(c*2) - 0, \"B\")\n        grd.set_tile(6,(c*2) + 1, \"W\")\n        grd.set_tile(7,(c*2) - 0, \"W\")\n    print(grd)\n\n    return grd"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntests for this module", "response": "def TEST():\n    \"\"\" tests for this module \"\"\"\n    grd = Grid(4,4, [2,4])\n    grd.new_tile()\n    grd.new_tile()\n    print(grd)\n    print(\"There are \", grd.count_blank_positions(), \" blanks in grid 1\\n\")\n\n    grd2 = Grid(5,5, ['A','B'])\n    grd2.new_tile(26)\n    print(grd2)\n    build_board_checkers()\n\n    print(\"There are \", grd2.count_blank_positions(), \" blanks in grid 2\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path(self, name):\n        if not name:\n            raise SuspiciousOperation(\"Attempted access to '%s' denied.\" % name)\n        return os.path.join(self._bucket, name)", "response": "Returns the full path to the file including leading slash and bucket name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url(self, name):\n        key = blobstore.create_gs_key('/gs' + name)\n        return images.get_serving_url(key)", "response": "Ask blobstore api for an url to directly serve the file\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the virtual MAC of the", "response": "def _set_virtual_mac(self, v, load=False):\n    \"\"\"\n    Setter method for virtual_mac, mapped from YANG variable /rbridge_id/interface/ve/ipv6/vrrpv3e/virtual_mac (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_virtual_mac is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_virtual_mac() directly.\n\n    YANG Description: Virtual MAC\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=virtual_mac.virtual_mac, is_container='container', presence=False, yang_name=\"virtual-mac\", rest_name=\"virtual-mac\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Virtual MAC'}}, namespace='urn:brocade.com:mgmt:brocade-vrrpv3', defining_module='brocade-vrrpv3', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"virtual_mac must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=virtual_mac.virtual_mac, is_container='container', presence=False, yang_name=\"virtual-mac\", rest_name=\"virtual-mac\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Virtual MAC'}}, namespace='urn:brocade.com:mgmt:brocade-vrrpv3', defining_module='brocade-vrrpv3', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__virtual_mac = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_disable_res(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=disable_res.disable_res, is_container='container', presence=False, yang_name=\"disable-res\", rest_name=\"disable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Disable process restart for fault recovery', u'cli-compact-syntax': None, u'alt-name': u'disable'}}, namespace='urn:brocade.com:mgmt:brocade-ha', defining_module='brocade-ha', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"disable_res must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=disable_res.disable_res, is_container='container', presence=False, yang_name=\"disable-res\", rest_name=\"disable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Disable process restart for fault recovery', u'cli-compact-syntax': None, u'alt-name': u'disable'}}, namespace='urn:brocade.com:mgmt:brocade-ha', defining_module='brocade-ha', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__disable_res = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the disable flag for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the redundancy of the node.", "response": "def _set_redundancy(self, v, load=False):\n    \"\"\"\n    Setter method for redundancy, mapped from YANG variable /brocade_ha_rpc/redundancy (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_redundancy is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_redundancy() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=redundancy.redundancy, is_leaf=True, yang_name=\"redundancy\", rest_name=\"redundancy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Show high availability redundancy state', u'hidden': u'rpccmd', u'actionpoint': u'showha'}}, namespace='urn:brocade.com:mgmt:brocade-ha', defining_module='brocade-ha', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"redundancy must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=redundancy.redundancy, is_leaf=True, yang_name=\"redundancy\", rest_name=\"redundancy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Show high availability redundancy state', u'hidden': u'rpccmd', u'actionpoint': u'showha'}}, namespace='urn:brocade.com:mgmt:brocade-ha', defining_module='brocade-ha', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__redundancy = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting reload property of", "response": "def _set_reload(self, v, load=False):\n    \"\"\"\n    Setter method for reload, mapped from YANG variable /brocade_ha_rpc/reload (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_reload is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_reload() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=reload.reload, is_leaf=True, yang_name=\"reload\", rest_name=\"reload\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'reload switch', u'hidden': u'rpccmd', u'actionpoint': u'reloadha'}}, namespace='urn:brocade.com:mgmt:brocade-ha', defining_module='brocade-ha', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"reload must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=reload.reload, is_leaf=True, yang_name=\"reload\", rest_name=\"reload\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'reload switch', u'hidden': u'rpccmd', u'actionpoint': u'reloadha'}}, namespace='urn:brocade.com:mgmt:brocade-ha', defining_module='brocade-ha', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__reload = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the circuit type of the ISIS node.", "response": "def _set_circuit_type(self, v, load=False):\n    \"\"\"\n    Setter method for circuit_type, mapped from YANG variable /isis_state/interface_brief/isis_intf_brief/circuit_type (isis-circ-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_circuit_type is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_circuit_type() directly.\n\n    YANG Description: Type of ISIS Circuit\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'is-circ-lan': {'value': 2}, u'is-circ-ptpt': {'value': 1}, u'is-circ-unknown': {'value': 0}},), is_leaf=True, yang_name=\"circuit-type\", rest_name=\"circuit-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='isis-circ-type', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"circuit_type must be of a type compatible with isis-circ-type\"\"\",\n          'defined-type': \"brocade-isis-operational:isis-circ-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'is-circ-lan': {'value': 2}, u'is-circ-ptpt': {'value': 1}, u'is-circ-unknown': {'value': 0}},), is_leaf=True, yang_name=\"circuit-type\", rest_name=\"circuit-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='isis-circ-type', is_config=False)\"\"\",\n        })\n\n    self.__circuit_type = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches all trading fees.", "response": "def trading_fees(self) -> TradingFees:\n        \"\"\"Fetch trading fees.\"\"\"\n        return self._fetch('trading fees', self.market.code)(self._trading_fees)()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the market ticker.", "response": "def fetch_ticker(self) -> Ticker:\n        \"\"\"Fetch the market ticker.\"\"\"\n        return self._fetch('ticker', self.market.code)(self._ticker)()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the order book.", "response": "def fetch_order_book(self) -> OrderBook:\n        \"\"\"Fetch the order book.\"\"\"\n        return self._fetch('order book', self.market.code)(self._order_book)()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching trades since given timestamp.", "response": "def fetch_trades_since(self, since: int) -> List[Trade]:\n        \"\"\"Fetch trades since given timestamp.\"\"\"\n        return self._fetch_since('trades', self.market.code)(self._trades_since)(since)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching latest deposits, must provide a limit.", "response": "def fetch_deposits(self, limit: int) -> List[Deposit]:\n        \"\"\"Fetch latest deposits, must provide a limit.\"\"\"\n        return self._transactions(self._deposits, 'deposits', limit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch all deposits since the given timestamp.", "response": "def fetch_deposits_since(self, since: int) -> List[Deposit]:\n        \"\"\"Fetch all deposits since the given timestamp.\"\"\"\n        return self._transactions_since(self._deposits_since, 'deposits', since)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_withdrawals(self, limit: int) -> List[Withdrawal]:\n        return self._transactions(self._withdrawals, 'withdrawals', limit)", "response": "Fetch latest withdrawals. Must provide a limit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_withdrawals_since(self, since: int) -> List[Withdrawal]:\n        return self._transactions_since(self._withdrawals_since, 'withdrawals', since)", "response": "Fetch all withdrawals since the given timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_order(self, order_id: str) -> Order:\n        return self._fetch(f'order id={order_id}', exc=OrderNotFound)(self._order)(order_id)", "response": "Fetch an order by ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch latest open orders.", "response": "def fetch_open_orders(self, limit: int) -> List[Order]:\n        \"\"\"Fetch latest open orders, must provide a limit.\"\"\"\n        return self._fetch_orders_limit(self._open_orders, limit)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches latest closed orders.", "response": "def fetch_closed_orders(self, limit: int) -> List[Order]:\n        \"\"\"Fetch latest closed orders, must provide a limit.\"\"\"\n        return self._fetch_orders_limit(self._closed_orders, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_closed_orders_since(self, since: int) -> List[Order]:\n        return self._fetch_orders_since(self._closed_orders_since, since)", "response": "Fetch closed orders since the given timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncancels an order by ID.", "response": "def cancel_order(self, order_id: str) -> str:\n        \"\"\"Cancel an order by ID.\"\"\"\n        self.log.debug(f'Canceling order id={order_id} on {self.name}')\n\n        if self.dry_run:  # Don't cancel if dry run\n            self.log.warning(f'DRY RUN: Order cancelled on {self.name}: id={order_id}')\n            return order_id\n\n        try:  # Cancel order\n            self._cancel_order(order_id)\n        except Exception as e:\n            raise self.exception(OrderNotFound, f'Failed to cancel order: id={order_id}', e) from e\n\n        self.log.info(f'Order cancelled on {self.name}: id={order_id}')\n        return order_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncanceling multiple orders by a list of IDs.", "response": "def cancel_orders(self, order_ids: List[str]) -> List[str]:\n        \"\"\"Cancel multiple orders by a list of IDs.\"\"\"\n        orders_to_cancel = order_ids\n        self.log.debug(f'Canceling orders on {self.name}: ids={orders_to_cancel}')\n        cancelled_orders = []\n\n        if self.dry_run:  # Don't cancel if dry run\n            self.log.warning(f'DRY RUN: Orders cancelled on {self.name}: {orders_to_cancel}')\n            return orders_to_cancel\n\n        try:  # Iterate and cancel orders\n            if self.has_batch_cancel:\n                self._cancel_orders(orders_to_cancel)\n                cancelled_orders.append(orders_to_cancel)\n                orders_to_cancel.clear()\n            else:\n                for i, order_id in enumerate(orders_to_cancel):\n                    self._cancel_order(order_id)\n                    cancelled_orders.append(order_id)\n                    orders_to_cancel.pop(i)\n        except Exception as e:\n            msg = f'Failed to cancel {len(orders_to_cancel)} orders on {self.name}: ids={orders_to_cancel}'\n            raise self.exception(OrderNotFound, msg, e) from e\n\n        self.log.info(f'Orders cancelled on {self.name}: ids={cancelled_orders}')\n        return cancelled_orders"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancel_all_orders(self) -> List[str]:\n        order_ids = [o.id for o in self.fetch_all_open_orders()]\n        return self.cancel_orders(order_ids)", "response": "Cancel all open orders."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef place_order(self, side: Side, order_type: OrderType, amount: Number, price: Number=None) -> Order:\n        order_repr = f'side={side} type={order_type} amount={amount} price={price}'\n        order_err = f'Failed to place order on {self.name}!: {order_repr}'\n\n        self.log.debug(f'Placing order on {self.name}: {order_repr}')\n        amount = self._parse_base(amount)\n        price = self._parse_quote(price)\n\n        min_amount = self.min_order_amount.amount  # Don\u00b4t place order if the amount < min allowed\n        if min_amount and amount < min_amount:\n            msg = f'{order_err}\\n> Reason: amount={amount} < min_amount={min_amount}'\n            raise self.exception(OrderTooSmall, msg)\n\n        if self.dry_run:  # Don't place order if dry run\n            order = Order.create_default(self.market, order_type, side, amount, price)\n            self.log.warning(f'DRY RUN: Order placed: {order}')\n            return order\n\n        try:  # Place order\n            order = self._place_order(side, order_type, amount, price)\n        except Exception as e:\n            raise self.exception(OrderNotPlaced, order_err, e) from e\n\n        self.log.info(f'Order placed on {self.name}: {order}')\n        return order", "response": "Place an order on the basket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplacing a market order.", "response": "def place_market_order(self, side: Side, amount: Number) -> Order:\n        \"\"\"Place a market order.\"\"\"\n        return self.place_order(side, OrderType.MARKET, amount)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplaces a limit order.", "response": "def place_limit_order(self, side: Side, amount: Number, price: Number) -> Order:\n        \"\"\"Place a limit order.\"\"\"\n        return self.place_order(side, OrderType.LIMIT, amount, price)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_node_id(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"node_id\",node_id.node_id, yang_name=\"node-id\", rest_name=\"node-id\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='node-id', extensions={u'tailf-common': {u'info': u'Node Id for Node Specific configuration', u'callpoint': u'mgmtclusternodespecificcallpoint', u'cli-suppress-no': None}}), is_container='list', yang_name=\"node-id\", rest_name=\"node-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Node Id for Node Specific configuration', u'callpoint': u'mgmtclusternodespecificcallpoint', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-node', defining_module='brocade-node', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"node_id must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"node_id\",node_id.node_id, yang_name=\"node-id\", rest_name=\"node-id\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='node-id', extensions={u'tailf-common': {u'info': u'Node Id for Node Specific configuration', u'callpoint': u'mgmtclusternodespecificcallpoint', u'cli-suppress-no': None}}), is_container='list', yang_name=\"node-id\", rest_name=\"node-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Node Id for Node Specific configuration', u'callpoint': u'mgmtclusternodespecificcallpoint', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-node', defining_module='brocade-node', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__node_id = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the node_id of the\n    based on node_id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_firmware(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=firmware.firmware, is_container='container', presence=False, yang_name=\"firmware\", rest_name=\"firmware\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'firmware operations', u'action': u'recover'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"firmware must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=firmware.firmware, is_container='container', presence=False, yang_name=\"firmware\", rest_name=\"firmware\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'firmware operations', u'action': u'recover'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__firmware = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the firmware property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of the IGMP snooping root MO .", "response": "def _set_igmp_snooping_state(self, v, load=False):\n    \"\"\"\n    Setter method for igmp_snooping_state, mapped from YANG variable /igmp_snooping_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_igmp_snooping_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_igmp_snooping_state() directly.\n\n    YANG Description: IGMP Snooping Root MO\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=igmp_snooping_state.igmp_snooping_state, is_container='container', presence=False, yang_name=\"igmp-snooping-state\", rest_name=\"igmp-snooping-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mc-hms-igmp-snooping', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mc-hms-operational', defining_module='brocade-mc-hms-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmp_snooping_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=igmp_snooping_state.igmp_snooping_state, is_container='container', presence=False, yang_name=\"igmp-snooping-state\", rest_name=\"igmp-snooping-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mc-hms-igmp-snooping', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mc-hms-operational', defining_module='brocade-mc-hms-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__igmp_snooping_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_police_remark_profile(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"profile_name\",police_remark_profile.police_remark_profile, yang_name=\"police-remark-profile\", rest_name=\"police-remark-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='profile-name', extensions={u'tailf-common': {u'info': u'Configure police remark profile', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'74', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'police_remark_profile', u'cli-mode-name': u'police-remark-profile-$(profile-name)'}}), is_container='list', yang_name=\"police-remark-profile\", rest_name=\"police-remark-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure police remark profile', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'74', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'police_remark_profile', u'cli-mode-name': u'police-remark-profile-$(profile-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mqc', defining_module='brocade-qos-mqc', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"police_remark_profile must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"profile_name\",police_remark_profile.police_remark_profile, yang_name=\"police-remark-profile\", rest_name=\"police-remark-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='profile-name', extensions={u'tailf-common': {u'info': u'Configure police remark profile', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'74', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'police_remark_profile', u'cli-mode-name': u'police-remark-profile-$(profile-name)'}}), is_container='list', yang_name=\"police-remark-profile\", rest_name=\"police-remark-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure police remark profile', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'74', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'police_remark_profile', u'cli-mode-name': u'police-remark-profile-$(profile-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mqc', defining_module='brocade-qos-mqc', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__police_remark_profile = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the police remark profile for a node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_hardware(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=hardware.hardware, is_container='container', presence=False, yang_name=\"hardware\", rest_name=\"hardware\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Hardware Management configuration', u'cli-add-mode': None, u'cli-suppress-show-path': None, u'cli-suppress-no': None, u'cli-full-command': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"hardware must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=hardware.hardware, is_container='container', presence=False, yang_name=\"hardware\", rest_name=\"hardware\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Hardware Management configuration', u'cli-add-mode': None, u'cli-suppress-show-path': None, u'cli-suppress-no': None, u'cli-full-command': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__hardware = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of hardware in the base base"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_zoning(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=zoning.zoning, is_container='container', presence=False, yang_name=\"zoning\", rest_name=\"zoning\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Zoning commands', u'display-when': u'/vcsmode/vcs-mode = \"true\"', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"zoning must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=zoning.zoning, is_container='container', presence=False, yang_name=\"zoning\", rest_name=\"zoning\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Zoning commands', u'display-when': u'/vcsmode/vcs-mode = \"true\"', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__zoning = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the zoning property of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_resource_monitor(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=resource_monitor.resource_monitor, is_container='container', presence=False, yang_name=\"resource-monitor\", rest_name=\"resource-monitor\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure resource monitoring', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-resource-monitor', defining_module='brocade-resource-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"resource_monitor must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=resource_monitor.resource_monitor, is_container='container', presence=False, yang_name=\"resource-monitor\", rest_name=\"resource-monitor\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure resource monitoring', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-resource-monitor', defining_module='brocade-resource-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__resource_monitor = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the resource monitor for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the state of the", "response": "def _set_acl_state(self, v, load=False):\n    \"\"\"\n    Setter method for acl_state, mapped from YANG variable /acl_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_acl_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_acl_state() directly.\n\n    YANG Description:  Vxlan ACL information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=acl_state.acl_state, is_container='container', presence=False, yang_name=\"acl-state\", rest_name=\"acl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-acl', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"acl_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=acl_state.acl_state, is_container='container', presence=False, yang_name=\"acl-state\", rest_name=\"acl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-acl', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__acl_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_cpu_queue_info_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=cpu_queue_info_state.cpu_queue_info_state, is_container='container', presence=False, yang_name=\"cpu-queue-info-state\", rest_name=\"cpu-queue-info-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-cpu-queue-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cpu_queue_info_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=cpu_queue_info_state.cpu_queue_info_state, is_container='container', presence=False, yang_name=\"cpu-queue-info-state\", rest_name=\"cpu-queue-info-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-cpu-queue-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__cpu_queue_info_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the CPU Queue info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of the filter - info - tree.", "response": "def _set_filter_info_state(self, v, load=False):\n    \"\"\"\n    Setter method for filter_info_state, mapped from YANG variable /filter_info_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_filter_info_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_filter_info_state() directly.\n\n    YANG Description: Filter Info\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=filter_info_state.filter_info_state, is_container='container', presence=False, yang_name=\"filter-info-state\", rest_name=\"filter-info-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-filter-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"filter_info_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=filter_info_state.filter_info_state, is_container='container', presence=False, yang_name=\"filter-info-state\", rest_name=\"filter-info-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-filter-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__filter_info_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_overlay_service_policy_brief_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=overlay_service_policy_brief_state.overlay_service_policy_brief_state, is_container='container', presence=False, yang_name=\"overlay-service-policy-brief-state\", rest_name=\"overlay-service-policy-brief-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-overlay-service-policy-brief', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_service_policy_brief_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=overlay_service_policy_brief_state.overlay_service_policy_brief_state, is_container='container', presence=False, yang_name=\"overlay-service-policy-brief-state\", rest_name=\"overlay-service-policy-brief-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-overlay-service-policy-brief', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__overlay_service_policy_brief_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the overlay service policy to brief."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of the VXLAN stats ACL.", "response": "def _set_vxlan_stats_acl_state(self, v, load=False):\n    \"\"\"\n    Setter method for vxlan_stats_acl_state, mapped from YANG variable /vxlan_stats_acl_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vxlan_stats_acl_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vxlan_stats_acl_state() directly.\n\n    YANG Description:  Vxlan stats ACL information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vxlan_stats_acl_state.vxlan_stats_acl_state, is_container='container', presence=False, yang_name=\"vxlan-stats-acl-state\", rest_name=\"vxlan-stats-acl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-vxlan-stats-acl', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vxlan_stats_acl_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vxlan_stats_acl_state.vxlan_stats_acl_state, is_container='container', presence=False, yang_name=\"vxlan-stats-acl-state\", rest_name=\"vxlan-stats-acl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-vxlan-stats-acl', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vxlan_stats_acl_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_overlay_class_map(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"cmap_name\",overlay_class_map.overlay_class_map, yang_name=\"overlay-class-map\", rest_name=\"overlay-class-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cmap-name', extensions={u'tailf-common': {u'info': u'Overlay Class Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayClassMapCallPoint', u'cli-mode-name': u'config-overlay-classmap-$(cmap-name)'}}), is_container='list', yang_name=\"overlay-class-map\", rest_name=\"overlay-class-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Overlay Class Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayClassMapCallPoint', u'cli-mode-name': u'config-overlay-classmap-$(cmap-name)'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_class_map must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"cmap_name\",overlay_class_map.overlay_class_map, yang_name=\"overlay-class-map\", rest_name=\"overlay-class-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cmap-name', extensions={u'tailf-common': {u'info': u'Overlay Class Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayClassMapCallPoint', u'cli-mode-name': u'config-overlay-classmap-$(cmap-name)'}}), is_container='list', yang_name=\"overlay-class-map\", rest_name=\"overlay-class-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Overlay Class Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayClassMapCallPoint', u'cli-mode-name': u'config-overlay-classmap-$(cmap-name)'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__overlay_class_map = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the overlay - class - map property of the base base."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_overlay_policy_map(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"pmap_name\",overlay_policy_map.overlay_policy_map, yang_name=\"overlay-policy-map\", rest_name=\"overlay-policy-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='pmap-name', extensions={u'tailf-common': {u'info': u'Overlay Policy Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayPolicyMapCallPoint', u'cli-mode-name': u'config-overlay-policymap-$(pmap-name)'}}), is_container='list', yang_name=\"overlay-policy-map\", rest_name=\"overlay-policy-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Overlay Policy Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayPolicyMapCallPoint', u'cli-mode-name': u'config-overlay-policymap-$(pmap-name)'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_policy_map must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"pmap_name\",overlay_policy_map.overlay_policy_map, yang_name=\"overlay-policy-map\", rest_name=\"overlay-policy-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='pmap-name', extensions={u'tailf-common': {u'info': u'Overlay Policy Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayPolicyMapCallPoint', u'cli-mode-name': u'config-overlay-policymap-$(pmap-name)'}}), is_container='list', yang_name=\"overlay-policy-map\", rest_name=\"overlay-policy-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Overlay Policy Map Configuration', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'75', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'OverlayPolicyMapCallPoint', u'cli-mode-name': u'config-overlay-policymap-$(pmap-name)'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__overlay_policy_map = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the policy map for the given overlay - policy - map"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the overlay_transit variable.", "response": "def _set_overlay_transit(self, v, load=False):\n    \"\"\"\n    Setter method for overlay_transit, mapped from YANG variable /overlay_transit (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_overlay_transit is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_overlay_transit() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"transit_name\",overlay_transit.overlay_transit, yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='transit-name', extensions={u'tailf-common': {u'info': u'Create new overlay-transit Instance', u'cli-full-no': None, u'sort-priority': u'76', u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-full-command': None, u'callpoint': u'OverlayTransitCallPoint', u'cli-mode-name': u'config-overlay-transit-$(transit-name)'}}), is_container='list', yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Create new overlay-transit Instance', u'cli-full-no': None, u'sort-priority': u'76', u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-full-command': None, u'callpoint': u'OverlayTransitCallPoint', u'cli-mode-name': u'config-overlay-transit-$(transit-name)'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_transit must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"transit_name\",overlay_transit.overlay_transit, yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='transit-name', extensions={u'tailf-common': {u'info': u'Create new overlay-transit Instance', u'cli-full-no': None, u'sort-priority': u'76', u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-full-command': None, u'callpoint': u'OverlayTransitCallPoint', u'cli-mode-name': u'config-overlay-transit-$(transit-name)'}}), is_container='list', yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Create new overlay-transit Instance', u'cli-full-no': None, u'sort-priority': u'76', u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-full-command': None, u'callpoint': u'OverlayTransitCallPoint', u'cli-mode-name': u'config-overlay-transit-$(transit-name)'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__overlay_transit = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the routing system of the", "response": "def _set_routing_system(self, v, load=False):\n    \"\"\"\n    Setter method for routing_system, mapped from YANG variable /routing_system (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_routing_system is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_routing_system() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=routing_system.routing_system, is_container='container', presence=False, yang_name=\"routing-system\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_LEVEL_RBRIDGE'}}, namespace='urn:brocade.com:mgmt:brocade-common-def', defining_module='brocade-common-def', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"routing_system must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=routing_system.routing_system, is_container='container', presence=False, yang_name=\"routing-system\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_LEVEL_RBRIDGE'}}, namespace='urn:brocade.com:mgmt:brocade-common-def', defining_module='brocade-common-def', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__routing_system = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_vc_peer_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vc_peer_state.vc_peer_state, is_container='container', presence=False, yang_name=\"vc-peer-state\", rest_name=\"vc-peer-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'pwm-vc-peer', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-pwm-operational', defining_module='brocade-pwm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vc_peer_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vc_peer_state.vc_peer_state, is_container='container', presence=False, yang_name=\"vc-peer-state\", rest_name=\"vc-peer-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'pwm-vc-peer', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-pwm-operational', defining_module='brocade-pwm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vc_peer_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the VC peer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the state of the openflow - tree.", "response": "def _set_openflow_state(self, v, load=False):\n    \"\"\"\n    Setter method for openflow_state, mapped from YANG variable /openflow_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_openflow_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_openflow_state() directly.\n\n    YANG Description: OPENFLOW Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=openflow_state.openflow_state, is_container='container', presence=False, yang_name=\"openflow-state\", rest_name=\"openflow-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'openflow-openflow', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-openflow-operational', defining_module='brocade-openflow-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"openflow_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=openflow_state.openflow_state, is_container='container', presence=False, yang_name=\"openflow-state\", rest_name=\"openflow-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'openflow-openflow', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-openflow-operational', defining_module='brocade-openflow-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__openflow_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of the Queues", "response": "def _set_queues_state(self, v, load=False):\n    \"\"\"\n    Setter method for queues_state, mapped from YANG variable /queues_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_queues_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_queues_state() directly.\n\n    YANG Description: Queues\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=queues_state.queues_state, is_container='container', presence=False, yang_name=\"queues-state\", rest_name=\"queues-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'openflow-queues', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-openflow-operational', defining_module='brocade-openflow-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"queues_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=queues_state.queues_state, is_container='container', presence=False, yang_name=\"queues-state\", rest_name=\"queues-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'openflow-queues', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-openflow-operational', defining_module='brocade-openflow-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__queues_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the state of the MCTD client.", "response": "def _set_mctd_client_state_state(self, v, load=False):\n    \"\"\"\n    Setter method for mctd_client_state_state, mapped from YANG variable /mctd_client_state_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mctd_client_state_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mctd_client_state_state() directly.\n\n    YANG Description: MCT Client Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mctd_client_state_state.mctd_client_state_state, is_container='container', presence=False, yang_name=\"mctd-client-state-state\", rest_name=\"mctd-client-state-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mct-mctd-client-state', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mct-operational', defining_module='brocade-mct-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mctd_client_state_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mctd_client_state_state.mctd_client_state_state, is_container='container', presence=False, yang_name=\"mctd-client-state-state\", rest_name=\"mctd-client-state-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mct-mctd-client-state', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mct-operational', defining_module='brocade-mct-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mctd_client_state_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_ptp_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ptp_state.ptp_state, is_container='container', presence=False, yang_name=\"ptp-state\", rest_name=\"ptp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ptp-ptp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ptp-operational', defining_module='brocade-ptp-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ptp_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ptp_state.ptp_state, is_container='container', presence=False, yang_name=\"ptp-state\", rest_name=\"ptp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ptp-ptp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ptp-operational', defining_module='brocade-ptp-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ptp_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the PTP state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the monitor property of the", "response": "def _set_monitor(self, v, load=False):\n    \"\"\"\n    Setter method for monitor, mapped from YANG variable /monitor (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_monitor is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_monitor() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=monitor.monitor, is_container='container', presence=False, yang_name=\"monitor\", rest_name=\"monitor\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Entering span sessions', u'cli-incomplete-no': None, u'callpoint': u'Span', u'sort-priority': u'RUNNCFG_LEVEL_SPAN_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-span', defining_module='brocade-span', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"monitor must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=monitor.monitor, is_container='container', presence=False, yang_name=\"monitor\", rest_name=\"monitor\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Entering span sessions', u'cli-incomplete-no': None, u'callpoint': u'Span', u'sort-priority': u'RUNNCFG_LEVEL_SPAN_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-span', defining_module='brocade-span', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__monitor = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_mac(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mac.mac, is_container='container', presence=False, yang_name=\"mac\", rest_name=\"mac\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC access list', u'cli-incomplete-no': None, u'sort-priority': u'RUNNCFG_LEVEL_GLOBAL_MAC_ACL'}}, namespace='urn:brocade.com:mgmt:brocade-mac-access-list', defining_module='brocade-mac-access-list', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mac must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mac.mac, is_container='container', presence=False, yang_name=\"mac\", rest_name=\"mac\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC access list', u'cli-incomplete-no': None, u'sort-priority': u'RUNNCFG_LEVEL_GLOBAL_MAC_ACL'}}, namespace='urn:brocade.com:mgmt:brocade-mac-access-list', defining_module='brocade-mac-access-list', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mac = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the MAC address of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the terminal_cfg variable.", "response": "def _set_terminal_cfg(self, v, load=False):\n    \"\"\"\n    Setter method for terminal_cfg, mapped from YANG variable /terminal_cfg (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_terminal_cfg is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_terminal_cfg() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=terminal_cfg.terminal_cfg, is_container='container', presence=False, yang_name=\"terminal-cfg\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'CLI terminal configuration', u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-terminal', defining_module='brocade-terminal', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"terminal_cfg must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=terminal_cfg.terminal_cfg, is_container='container', presence=False, yang_name=\"terminal-cfg\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'CLI terminal configuration', u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-terminal', defining_module='brocade-terminal', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__terminal_cfg = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of the MPLS archive.", "response": "def _set_mpls_state(self, v, load=False):\n    \"\"\"\n    Setter method for mpls_state, mapped from YANG variable /mpls_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mpls_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mpls_state() directly.\n\n    YANG Description: MPLS Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mpls_state.mpls_state, is_container='container', presence=False, yang_name=\"mpls-state\", rest_name=\"mpls-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-mpls', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mpls_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mpls_state.mpls_state, is_container='container', presence=False, yang_name=\"mpls-state\", rest_name=\"mpls-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-mpls', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mpls_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of the", "response": "def _set_tm_state(self, v, load=False):\n    \"\"\"\n    Setter method for tm_state, mapped from YANG variable /tm_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tm_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tm_state() directly.\n\n    YANG Description: TM statistics\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tm_state.tm_state, is_container='container', presence=False, yang_name=\"tm-state\", rest_name=\"tm-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'sysdiag-tm', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-sysdiag-operational', defining_module='brocade-sysdiag-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tm_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tm_state.tm_state, is_container='container', presence=False, yang_name=\"tm-state\", rest_name=\"tm-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'sysdiag-tm', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-sysdiag-operational', defining_module='brocade-sysdiag-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tm_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the vrf of the", "response": "def _set_vrf(self, v, load=False):\n    \"\"\"\n    Setter method for vrf, mapped from YANG variable /vrf (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vrf is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vrf() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"vrf_name\",vrf.vrf, yang_name=\"vrf\", rest_name=\"vrf\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='vrf-name', extensions={u'tailf-common': {u'info': u'VRF configurations', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'RUNNCFG_LEVEL_SYSTEM_VRF_NAME', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'vrfCallpoint'}}), is_container='list', yang_name=\"vrf\", rest_name=\"vrf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'VRF configurations', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'RUNNCFG_LEVEL_SYSTEM_VRF_NAME', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'vrfCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-vrf', defining_module='brocade-vrf', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vrf must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"vrf_name\",vrf.vrf, yang_name=\"vrf\", rest_name=\"vrf\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='vrf-name', extensions={u'tailf-common': {u'info': u'VRF configurations', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'RUNNCFG_LEVEL_SYSTEM_VRF_NAME', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'vrfCallpoint'}}), is_container='list', yang_name=\"vrf\", rest_name=\"vrf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'VRF configurations', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'RUNNCFG_LEVEL_SYSTEM_VRF_NAME', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'vrfCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-vrf', defining_module='brocade-vrf', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__vrf = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_fcoe_fsb(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoe_fsb.fcoe_fsb, is_container='container', presence=False, yang_name=\"fcoe-fsb\", rest_name=\"fsb\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'fcoe_fsb_cp', u'info': u'Enable/Disable the fsb mode', u'hidden': u'debug', u'alt-name': u'fsb', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe_fsb must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoe_fsb.fcoe_fsb, is_container='container', presence=False, yang_name=\"fcoe-fsb\", rest_name=\"fsb\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'fcoe_fsb_cp', u'info': u'Enable/Disable the fsb mode', u'hidden': u'debug', u'alt-name': u'fsb', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoe_fsb = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the FIP_FSB variable for the sequence of FIP_FSBs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_fcoe(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoe.fcoe, is_container='container', presence=False, yang_name=\"fcoe\", rest_name=\"fcoe\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'FCoE configuration commands', u'sort-priority': u'RUNNCFG_LEVEL_FEATURE_FCOE', u'cli-suppress-no': None, u'cli-full-command': None, u'cli-add-mode': None, u'display-when': u'(/vcsmode/vcs-mode = \"true\")'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoe.fcoe, is_container='container', presence=False, yang_name=\"fcoe\", rest_name=\"fcoe\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'FCoE configuration commands', u'sort-priority': u'RUNNCFG_LEVEL_FEATURE_FCOE', u'cli-suppress-no': None, u'cli-full-command': None, u'cli-add-mode': None, u'display-when': u'(/vcsmode/vcs-mode = \"true\")'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoe = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the FCOE map."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the protocol vrrp of the", "response": "def _set_protocol_vrrp(self, v, load=False):\n    \"\"\"\n    Setter method for protocol_vrrp, mapped from YANG variable /protocol_vrrp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_protocol_vrrp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_protocol_vrrp() directly.\n\n    YANG Description: An intermediary node that separates the protocol vrrp from other protocols.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=protocol_vrrp.protocol_vrrp, is_container='container', presence=False, yang_name=\"protocol-vrrp\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_LEVEL_ROUTER_GLOBAL'}}, namespace='urn:brocade.com:mgmt:brocade-vrrp', defining_module='brocade-vrrp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"protocol_vrrp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=protocol_vrrp.protocol_vrrp, is_container='container', presence=False, yang_name=\"protocol-vrrp\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_LEVEL_ROUTER_GLOBAL'}}, namespace='urn:brocade.com:mgmt:brocade-vrrp', defining_module='brocade-vrrp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__protocol_vrrp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_acl_policy(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=acl_policy.acl_policy, is_container='container', presence=False, yang_name=\"acl-policy\", rest_name=\"acl-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-add-mode': None, u'cli-full-command': None, u'hidden': u'full', u'info': u'ACL related Global commands', u'callpoint': u'GlobalAclPolicyConfig'}}, namespace='urn:brocade.com:mgmt:brocade-acl-policy', defining_module='brocade-acl-policy', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"acl_policy must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=acl_policy.acl_policy, is_container='container', presence=False, yang_name=\"acl-policy\", rest_name=\"acl-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-add-mode': None, u'cli-full-command': None, u'hidden': u'full', u'info': u'ACL related Global commands', u'callpoint': u'GlobalAclPolicyConfig'}}, namespace='urn:brocade.com:mgmt:brocade-acl-policy', defining_module='brocade-acl-policy', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__acl_policy = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ACL policy for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the state of the MAC brief bridge.", "response": "def _set_bd_mac_br_state(self, v, load=False):\n    \"\"\"\n    Setter method for bd_mac_br_state, mapped from YANG variable /bd_mac_br_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bd_mac_br_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bd_mac_br_state() directly.\n\n    YANG Description: Bridge-domain mac brief info\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bd_mac_br_state.bd_mac_br_state, is_container='container', presence=False, yang_name=\"bd-mac-br-state\", rest_name=\"bd-mac-br-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'l2sys-bd-mac-br', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-l2sys-operational', defining_module='brocade-l2sys-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bd_mac_br_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bd_mac_br_state.bd_mac_br_state, is_container='container', presence=False, yang_name=\"bd-mac-br-state\", rest_name=\"bd-mac-br-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'l2sys-bd-mac-br', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-l2sys-operational', defining_module='brocade-l2sys-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__bd_mac_br_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_adj_neighbor_entries_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=adj_neighbor_entries_state.adj_neighbor_entries_state, is_container='container', presence=False, yang_name=\"adj-neighbor-entries-state\", rest_name=\"adj-neighbor-entries-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-adj-neighbor-entries', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"adj_neighbor_entries_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=adj_neighbor_entries_state.adj_neighbor_entries_state, is_container='container', presence=False, yang_name=\"adj-neighbor-entries-state\", rest_name=\"adj-neighbor-entries-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-adj-neighbor-entries', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__adj_neighbor_entries_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the Adjacency Neighbor Entries to the given state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_counts_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=counts_state.counts_state, is_container='container', presence=False, yang_name=\"counts-state\", rest_name=\"counts-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-counts', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"counts_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=counts_state.counts_state, is_container='container', presence=False, yang_name=\"counts-state\", rest_name=\"counts-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-counts', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__counts_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the counts state of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_isis_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=isis_state.isis_state, is_container='container', presence=False, yang_name=\"isis-state\", rest_name=\"isis-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"isis_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=isis_state.isis_state, is_container='container', presence=False, yang_name=\"isis-state\", rest_name=\"isis-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__isis_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the isis - tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_traffic_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=traffic_state.traffic_state, is_container='container', presence=False, yang_name=\"traffic-state\", rest_name=\"traffic-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-traffic', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"traffic_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=traffic_state.traffic_state, is_container='container', presence=False, yang_name=\"traffic-state\", rest_name=\"traffic-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-traffic', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__traffic_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the IS - IS packet counts\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the local node of the", "response": "def _set_local_node(self, v, load=False):\n    \"\"\"\n    Setter method for local_node, mapped from YANG variable /local_node (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_local_node is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_local_node() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=local_node.local_node, is_container='container', presence=False, yang_name=\"local-node\", rest_name=\"local-node\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'VcsModeCallpoint', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"local_node must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=local_node.local_node, is_container='container', presence=False, yang_name=\"local-node\", rest_name=\"local-node\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'VcsModeCallpoint', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__local_node = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the cluster property.", "response": "def _set_cluster(self, v, load=False):\n    \"\"\"\n    Setter method for cluster, mapped from YANG variable /cluster (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_cluster is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_cluster() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"cluster_name cluster_id\",cluster.cluster, yang_name=\"cluster\", rest_name=\"cluster\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cluster-name cluster-id', extensions={u'tailf-common': {u'info': u' MCT Cluster Specific configuration', u'cli-full-no': None, u'sort-priority': u'145', u'cli-full-command': None, u'callpoint': u'MctBasicCallpoint', u'cli-mode-name': u'config-cluster-$(cluster-id)'}}), is_container='list', yang_name=\"cluster\", rest_name=\"cluster\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' MCT Cluster Specific configuration', u'cli-full-no': None, u'sort-priority': u'145', u'cli-full-command': None, u'callpoint': u'MctBasicCallpoint', u'cli-mode-name': u'config-cluster-$(cluster-id)'}}, namespace='urn:brocade.com:mgmt:brocade-mct', defining_module='brocade-mct', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cluster must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"cluster_name cluster_id\",cluster.cluster, yang_name=\"cluster\", rest_name=\"cluster\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cluster-name cluster-id', extensions={u'tailf-common': {u'info': u' MCT Cluster Specific configuration', u'cli-full-no': None, u'sort-priority': u'145', u'cli-full-command': None, u'callpoint': u'MctBasicCallpoint', u'cli-mode-name': u'config-cluster-$(cluster-id)'}}), is_container='list', yang_name=\"cluster\", rest_name=\"cluster\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' MCT Cluster Specific configuration', u'cli-full-no': None, u'sort-priority': u'145', u'cli-full-command': None, u'callpoint': u'MctBasicCallpoint', u'cli-mode-name': u'config-cluster-$(cluster-id)'}}, namespace='urn:brocade.com:mgmt:brocade-mct', defining_module='brocade-mct', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__cluster = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of the property to v.", "response": "def _set_copy(self, v, load=False):\n    \"\"\"\n    Setter method for copy, mapped from YANG variable /copy (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_copy is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_copy() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=copy.copy, is_container='container', presence=False, yang_name=\"copy\", rest_name=\"copy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'RAS copy operation', u'action': u'support-interactive'}}, namespace='urn:brocade.com:mgmt:brocade-ras', defining_module='brocade-ras', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"copy must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=copy.copy, is_container='container', presence=False, yang_name=\"copy\", rest_name=\"copy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'RAS copy operation', u'action': u'support-interactive'}}, namespace='urn:brocade.com:mgmt:brocade-ras', defining_module='brocade-ras', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__copy = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the support property of the", "response": "def _set_support(self, v, load=False):\n    \"\"\"\n    Setter method for support, mapped from YANG variable /support (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_support is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_support() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=support.support, is_container='container', presence=False, yang_name=\"support\", rest_name=\"support\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Support configuration', u'callpoint': u'RASGlobalConfigCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-ras', defining_module='brocade-ras', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"support must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=support.support, is_container='container', presence=False, yang_name=\"support\", rest_name=\"support\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Support configuration', u'callpoint': u'RASGlobalConfigCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-ras', defining_module='brocade-ras', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__support = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_qos_mpls(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=qos_mpls.qos_mpls, is_container='container', presence=False, yang_name=\"qos-mpls\", rest_name=\"qos-mpls\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MPLS Quality of Service (QoS)', u'sort-priority': u'RUNNCFG_LEVEL_SYSTEM_MPLS_QOS'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"qos_mpls must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=qos_mpls.qos_mpls, is_container='container', presence=False, yang_name=\"qos-mpls\", rest_name=\"qos-mpls\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MPLS Quality of Service (QoS)', u'sort-priority': u'RUNNCFG_LEVEL_SYSTEM_MPLS_QOS'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__qos_mpls = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the QoS parameter in the base node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_preprovision(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=preprovision.preprovision, is_container='container', presence=False, yang_name=\"preprovision\", rest_name=\"preprovision\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Preprovision profile', u'hidden': u'full', u'display-when': u'((/vcsmode/vcs-mode = \"true\") and (/vcsmode/vcs-cluster-mode = \"true\"))', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-preprovision', defining_module='brocade-preprovision', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"preprovision must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=preprovision.preprovision, is_container='container', presence=False, yang_name=\"preprovision\", rest_name=\"preprovision\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Preprovision profile', u'hidden': u'full', u'display-when': u'((/vcsmode/vcs-mode = \"true\") and (/vcsmode/vcs-cluster-mode = \"true\"))', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-preprovision', defining_module='brocade-preprovision', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__preprovision = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the pre - provisioning property of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the global MTU configuration for the node.", "response": "def _set_global_mtu_conf(self, v, load=False):\n    \"\"\"\n    Setter method for global_mtu_conf, mapped from YANG variable /global_mtu_conf (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_global_mtu_conf is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_global_mtu_conf() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=global_mtu_conf.global_mtu_conf, is_container='container', presence=False, yang_name=\"global-mtu-conf\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'global-mtu-cfg-cp', u'sort-priority': u'RUNNCFG_LEVEL_FEATURE_GLOBAL_MTU'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"global_mtu_conf must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=global_mtu_conf.global_mtu_conf, is_container='container', presence=False, yang_name=\"global-mtu-conf\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'global-mtu-cfg-cp', u'sort-priority': u'RUNNCFG_LEVEL_FEATURE_GLOBAL_MTU'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__global_mtu_conf = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_rbridge_id(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"rbridge_id\",rbridge_id.rbridge_id, yang_name=\"rbridge-id\", rest_name=\"rbridge-id\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rbridge-id', extensions={u'tailf-common': {u'info': u'Rbridge Id for Node Specific configuration', u'callpoint': u'vcsnodespecificcallpoint', u'sort-priority': u'RUNNCFG_LEVEL_RBRIDGE', u'cli-suppress-no': None, u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}), is_container='list', yang_name=\"rbridge-id\", rest_name=\"rbridge-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Rbridge Id for Node Specific configuration', u'callpoint': u'vcsnodespecificcallpoint', u'sort-priority': u'RUNNCFG_LEVEL_RBRIDGE', u'cli-suppress-no': None, u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge', defining_module='brocade-rbridge', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rbridge_id must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"rbridge_id\",rbridge_id.rbridge_id, yang_name=\"rbridge-id\", rest_name=\"rbridge-id\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rbridge-id', extensions={u'tailf-common': {u'info': u'Rbridge Id for Node Specific configuration', u'callpoint': u'vcsnodespecificcallpoint', u'sort-priority': u'RUNNCFG_LEVEL_RBRIDGE', u'cli-suppress-no': None, u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}), is_container='list', yang_name=\"rbridge-id\", rest_name=\"rbridge-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Rbridge Id for Node Specific configuration', u'callpoint': u'vcsnodespecificcallpoint', u'sort-priority': u'RUNNCFG_LEVEL_RBRIDGE', u'cli-suppress-no': None, u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge', defining_module='brocade-rbridge', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__rbridge_id = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the rbridge_id of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_dpod(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=dpod.dpod, is_container='container', presence=False, yang_name=\"dpod\", rest_name=\"dpod\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Manage and display DPOD license assignments.\\nUsage: dpod [slot/port] [reserve|release]', u'display-when': u'(/c:capabilities/c:license/c:dpod_display = \"true\")'}}, namespace='urn:brocade.com:mgmt:brocade-license', defining_module='brocade-license', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dpod must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=dpod.dpod, is_container='container', presence=False, yang_name=\"dpod\", rest_name=\"dpod\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Manage and display DPOD license assignments.\\nUsage: dpod [slot/port] [reserve|release]', u'display-when': u'(/c:capabilities/c:license/c:dpod_display = \"true\")'}}, namespace='urn:brocade.com:mgmt:brocade-license', defining_module='brocade-license', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__dpod = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the dpod variable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_vrrp_rbridge_global(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vrrp_rbridge_global.vrrp_rbridge_global, is_container='container', presence=False, yang_name=\"vrrp-rbridge-global\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'vrrpv3GlobalConf', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-vrrpv3', defining_module='brocade-vrrpv3', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vrrp_rbridge_global must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vrrp_rbridge_global.vrrp_rbridge_global, is_container='container', presence=False, yang_name=\"vrrp-rbridge-global\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'vrrpv3GlobalConf', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-vrrpv3', defining_module='brocade-vrrpv3', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vrrp_rbridge_global = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the vrrp_rbridge_global variable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_pw_profile(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"pw_profile_name\",pw_profile.pw_profile, yang_name=\"pw-profile\", rest_name=\"pw-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='pw-profile-name', extensions={u'tailf-common': {u'info': u'pw-profile for Node Specific configuration', u'callpoint': u'PWProfileBasicCallpoint', u'cli-mode-name': u'config-pw-profile-$(pw-profile-name)'}}), is_container='list', yang_name=\"pw-profile\", rest_name=\"pw-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'pw-profile for Node Specific configuration', u'callpoint': u'PWProfileBasicCallpoint', u'cli-mode-name': u'config-pw-profile-$(pw-profile-name)'}}, namespace='urn:brocade.com:mgmt:brocade-pw-profile', defining_module='brocade-pw-profile', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"pw_profile must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"pw_profile_name\",pw_profile.pw_profile, yang_name=\"pw-profile\", rest_name=\"pw-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='pw-profile-name', extensions={u'tailf-common': {u'info': u'pw-profile for Node Specific configuration', u'callpoint': u'PWProfileBasicCallpoint', u'cli-mode-name': u'config-pw-profile-$(pw-profile-name)'}}), is_container='list', yang_name=\"pw-profile\", rest_name=\"pw-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'pw-profile for Node Specific configuration', u'callpoint': u'PWProfileBasicCallpoint', u'cli-mode-name': u'config-pw-profile-$(pw-profile-name)'}}, namespace='urn:brocade.com:mgmt:brocade-pw-profile', defining_module='brocade-pw-profile', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__pw_profile = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the pw - profile of a private\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of the cee_map variable.", "response": "def _set_cee_map(self, v, load=False):\n    \"\"\"\n    Setter method for cee_map, mapped from YANG variable /cee_map (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_cee_map is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_cee_map() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",cee_map.cee_map, yang_name=\"cee-map\", rest_name=\"cee-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'CEE map command', u'callpoint': u'qos_cee_map', u'sort-priority': u'36'}}), is_container='list', yang_name=\"cee-map\", rest_name=\"cee-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'CEE map command', u'callpoint': u'qos_cee_map', u'sort-priority': u'36'}}, namespace='urn:brocade.com:mgmt:brocade-qos-cee', defining_module='brocade-qos-cee', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cee_map must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",cee_map.cee_map, yang_name=\"cee-map\", rest_name=\"cee-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'CEE map command', u'callpoint': u'qos_cee_map', u'sort-priority': u'36'}}), is_container='list', yang_name=\"cee-map\", rest_name=\"cee-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'CEE map command', u'callpoint': u'qos_cee_map', u'sort-priority': u'36'}}, namespace='urn:brocade.com:mgmt:brocade-qos-cee', defining_module='brocade-qos-cee', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__cee_map = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the AAA_CONFIG variable.", "response": "def _set_aaa_config(self, v, load=False):\n    \"\"\"\n    Setter method for aaa_config, mapped from YANG variable /aaa_config (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_aaa_config is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_aaa_config() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=aaa_config.aaa_config, is_container='container', presence=False, yang_name=\"aaa-config\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'16'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"aaa_config must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=aaa_config.aaa_config, is_container='container', presence=False, yang_name=\"aaa-config\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'16'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__aaa_config = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the username of the", "response": "def _set_username(self, v, load=False):\n    \"\"\"\n    Setter method for username, mapped from YANG variable /username (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_username is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_username() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",username.username, yang_name=\"username\", rest_name=\"username\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configuration of local Users', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'sort-priority': u'19', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'callpoint': u'user_cp'}}), is_container='list', yang_name=\"username\", rest_name=\"username\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configuration of local Users', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'sort-priority': u'19', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'callpoint': u'user_cp'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"username must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",username.username, yang_name=\"username\", rest_name=\"username\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configuration of local Users', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'sort-priority': u'19', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'callpoint': u'user_cp'}}), is_container='list', yang_name=\"username\", rest_name=\"username\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configuration of local Users', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'sort-priority': u'19', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'callpoint': u'user_cp'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__username = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_service(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=service.service, is_container='container', presence=False, yang_name=\"service\", rest_name=\"service\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Perform services', u'sort-priority': u'18'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"service must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=service.service, is_container='container', presence=False, yang_name=\"service\", rest_name=\"service\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Perform services', u'sort-priority': u'18'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__service = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the service of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_sfm_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=sfm_state.sfm_state, is_container='container', presence=False, yang_name=\"sfm-state\", rest_name=\"sfm-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'sysmgr-sfm', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmgr-operational', defining_module='brocade-sysmgr-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sfm_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=sfm_state.sfm_state, is_container='container', presence=False, yang_name=\"sfm-state\", rest_name=\"sfm-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'sysmgr-sfm', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmgr-operational', defining_module='brocade-sysmgr-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__sfm_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the Sfm system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the capabilities of the", "response": "def _set_capabilities(self, v, load=False):\n    \"\"\"\n    Setter method for capabilities, mapped from YANG variable /capabilities (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_capabilities is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_capabilities() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=capabilities.capabilities, is_container='container', presence=False, yang_name=\"capabilities\", rest_name=\"capabilities\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'CapabilitiesCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-system-capabilities', defining_module='brocade-system-capabilities', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"capabilities must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=capabilities.capabilities, is_container='container', presence=False, yang_name=\"capabilities\", rest_name=\"capabilities\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'CapabilitiesCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-system-capabilities', defining_module='brocade-system-capabilities', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__capabilities = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_openflow_global(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=openflow_global.openflow_global, is_container='container', presence=False, yang_name=\"openflow-global\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'enables openflow and version ', u'cli-drop-node-name': None, u'callpoint': u'OpenflowBasicConfigCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"openflow_global must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=openflow_global.openflow_global, is_container='container', presence=False, yang_name=\"openflow-global\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'enables openflow and version ', u'cli-drop-node-name': None, u'callpoint': u'OpenflowBasicConfigCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__openflow_global = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the openflow global variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the system monitor mail.", "response": "def _set_system_monitor_mail(self, v, load=False):\n    \"\"\"\n    Setter method for system_monitor_mail, mapped from YANG variable /system_monitor_mail (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_system_monitor_mail is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_system_monitor_mail() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=system_monitor_mail.system_monitor_mail, is_container='container', presence=False, yang_name=\"system-monitor-mail\", rest_name=\"system-monitor-mail\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FRU mail setting', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"system_monitor_mail must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=system_monitor_mail.system_monitor_mail, is_container='container', presence=False, yang_name=\"system-monitor-mail\", rest_name=\"system-monitor-mail\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FRU mail setting', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__system_monitor_mail = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of the tpvm variable.", "response": "def _set_tpvm(self, v, load=False):\n    \"\"\"\n    Setter method for tpvm, mapped from YANG variable /tpvm (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tpvm is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tpvm() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tpvm.tpvm, is_container='container', presence=False, yang_name=\"tpvm\", rest_name=\"tpvm\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'TPVM administration command', u'action': u'stop'}}, namespace='urn:brocade.com:mgmt:brocade-tpvm', defining_module='brocade-tpvm', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tpvm must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tpvm.tpvm, is_container='container', presence=False, yang_name=\"tpvm\", rest_name=\"tpvm\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'TPVM administration command', u'action': u'stop'}}, namespace='urn:brocade.com:mgmt:brocade-tpvm', defining_module='brocade-tpvm', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tpvm = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_dscp_exp_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=dscp_exp_state.dscp_exp_state, is_container='container', presence=False, yang_name=\"dscp-exp-state\", rest_name=\"dscp-exp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-dscp-exp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dscp_exp_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=dscp_exp_state.dscp_exp_state, is_container='container', presence=False, yang_name=\"dscp-exp-state\", rest_name=\"dscp-exp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-dscp-exp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__dscp_exp_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the dscp - exp - tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of the exp - DSCP in the sequence.", "response": "def _set_exp_dscp_state(self, v, load=False):\n    \"\"\"\n    Setter method for exp_dscp_state, mapped from YANG variable /exp_dscp_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_exp_dscp_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_exp_dscp_state() directly.\n\n    YANG Description: exp_dscp\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=exp_dscp_state.exp_dscp_state, is_container='container', presence=False, yang_name=\"exp-dscp-state\", rest_name=\"exp-dscp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-exp-dscp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"exp_dscp_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=exp_dscp_state.exp_dscp_state, is_container='container', presence=False, yang_name=\"exp-dscp-state\", rest_name=\"exp-dscp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-exp-dscp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__exp_dscp_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the state of the exp - traffic - class.", "response": "def _set_exp_traffic_class_state(self, v, load=False):\n    \"\"\"\n    Setter method for exp_traffic_class_state, mapped from YANG variable /exp_traffic_class_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_exp_traffic_class_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_exp_traffic_class_state() directly.\n\n    YANG Description: exp_traffic_class\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=exp_traffic_class_state.exp_traffic_class_state, is_container='container', presence=False, yang_name=\"exp-traffic-class-state\", rest_name=\"exp-traffic-class-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-exp-traffic-class', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"exp_traffic_class_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=exp_traffic_class_state.exp_traffic_class_state, is_container='container', presence=False, yang_name=\"exp-traffic-class-state\", rest_name=\"exp-traffic-class-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-exp-traffic-class', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__exp_traffic_class_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the state of the traffic class exp", "response": "def _set_traffic_class_exp_state(self, v, load=False):\n    \"\"\"\n    Setter method for traffic_class_exp_state, mapped from YANG variable /traffic_class_exp_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_traffic_class_exp_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_traffic_class_exp_state() directly.\n\n    YANG Description: traffic_class_exp\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=traffic_class_exp_state.traffic_class_exp_state, is_container='container', presence=False, yang_name=\"traffic-class-exp-state\", rest_name=\"traffic-class-exp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-traffic-class-exp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"traffic_class_exp_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=traffic_class_exp_state.traffic_class_exp_state, is_container='container', presence=False, yang_name=\"traffic-class-exp-state\", rest_name=\"traffic-class-exp-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'qos-traffic-class-exp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-operational', defining_module='brocade-qos-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__traffic_class_exp_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_overlay_gateway(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",overlay_gateway.overlay_gateway, yang_name=\"overlay-gateway\", rest_name=\"overlay-gateway\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure Overaly gateway instance', u'sort-priority': u'RUNNCFG_LEVEL_OVERLAY_GATEWAY_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'TunnelsGwCallpoint', u'cli-mode-name': u'config-overlay-gw-$(name)'}}), is_container='list', yang_name=\"overlay-gateway\", rest_name=\"overlay-gateway\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Overaly gateway instance', u'sort-priority': u'RUNNCFG_LEVEL_OVERLAY_GATEWAY_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'TunnelsGwCallpoint', u'cli-mode-name': u'config-overlay-gw-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_gateway must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",overlay_gateway.overlay_gateway, yang_name=\"overlay-gateway\", rest_name=\"overlay-gateway\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure Overaly gateway instance', u'sort-priority': u'RUNNCFG_LEVEL_OVERLAY_GATEWAY_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'TunnelsGwCallpoint', u'cli-mode-name': u'config-overlay-gw-$(name)'}}), is_container='list', yang_name=\"overlay-gateway\", rest_name=\"overlay-gateway\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Overaly gateway instance', u'sort-priority': u'RUNNCFG_LEVEL_OVERLAY_GATEWAY_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'callpoint': u'TunnelsGwCallpoint', u'cli-mode-name': u'config-overlay-gw-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__overlay_gateway = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the overlay_gateway variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the state of the CFM.", "response": "def _set_cfm_state(self, v, load=False):\n    \"\"\"\n    Setter method for cfm_state, mapped from YANG variable /cfm_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_cfm_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_cfm_state() directly.\n\n    YANG Description: CFM Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=cfm_state.cfm_state, is_container='container', presence=False, yang_name=\"cfm-state\", rest_name=\"cfm-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'dot1ag-cfm', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag-operational', defining_module='brocade-dot1ag-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cfm_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=cfm_state.cfm_state, is_container='container', presence=False, yang_name=\"cfm-state\", rest_name=\"cfm-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'dot1ag-cfm', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag-operational', defining_module='brocade-dot1ag-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__cfm_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_certutil(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=certutil.certutil, is_container='container', presence=False, yang_name=\"certutil\", rest_name=\"certutil\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Security Certificate Management Operations'}}, namespace='urn:brocade.com:mgmt:certutil', defining_module='brocade-certutil', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"certutil must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=certutil.certutil, is_container='container', presence=False, yang_name=\"certutil\", rest_name=\"certutil\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Security Certificate Management Operations'}}, namespace='urn:brocade.com:mgmt:certutil', defining_module='brocade-certutil', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__certutil = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the certutil variable"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_bridge_domain_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bridge_domain_state.bridge_domain_state, is_container='container', presence=False, yang_name=\"bridge-domain-state\", rest_name=\"bridge-domain-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-bridge-domain', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bridge_domain_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bridge_domain_state.bridge_domain_state, is_container='container', presence=False, yang_name=\"bridge-domain-state\", rest_name=\"bridge-domain-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-bridge-domain', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__bridge_domain_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the Bridge - domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_logical_interface_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=logical_interface_state.logical_interface_state, is_container='container', presence=False, yang_name=\"logical-interface-state\", rest_name=\"logical-interface-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-logical-interface', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"logical_interface_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=logical_interface_state.logical_interface_state, is_container='container', presence=False, yang_name=\"logical-interface-state\", rest_name=\"logical-interface-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-logical-interface', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__logical_interface_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the logical interface state for the sequence of logical interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_mct_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mct_state.mct_state, is_container='container', presence=False, yang_name=\"mct-state\", rest_name=\"mct-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-mct', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mct_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mct_state.mct_state, is_container='container', presence=False, yang_name=\"mct-state\", rest_name=\"mct-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-mct', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mct_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the MCT - state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state of the sub - interface statistics.", "response": "def _set_sub_interface_statistics_state(self, v, load=False):\n    \"\"\"\n    Setter method for sub_interface_statistics_state, mapped from YANG variable /sub_interface_statistics_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_sub_interface_statistics_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_sub_interface_statistics_state() directly.\n\n    YANG Description: sub-interface statistics\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=sub_interface_statistics_state.sub_interface_statistics_state, is_container='container', presence=False, yang_name=\"sub-interface-statistics-state\", rest_name=\"sub-interface-statistics-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-sub-interface-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sub_interface_statistics_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=sub_interface_statistics_state.sub_interface_statistics_state, is_container='container', presence=False, yang_name=\"sub-interface-statistics-state\", rest_name=\"sub-interface-statistics-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-sub-interface-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__sub_interface_statistics_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state of the topology group.", "response": "def _set_topology_group_state(self, v, load=False):\n    \"\"\"\n    Setter method for topology_group_state, mapped from YANG variable /topology_group_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_topology_group_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_topology_group_state() directly.\n\n    YANG Description:  Topology Group related information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=topology_group_state.topology_group_state, is_container='container', presence=False, yang_name=\"topology-group-state\", rest_name=\"topology-group-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-topology-group', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"topology_group_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=topology_group_state.topology_group_state, is_container='container', presence=False, yang_name=\"topology-group-state\", rest_name=\"topology-group-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-topology-group', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__topology_group_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the profile of the current node.", "response": "def _set_sflow_profile(self, v, load=False):\n    \"\"\"\n    Setter method for sflow_profile, mapped from YANG variable /sflow_profile (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_sflow_profile is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_sflow_profile() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"profile_name\",sflow_profile.sflow_profile, yang_name=\"sflow-profile\", rest_name=\"sflow-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='profile-name', extensions={u'tailf-common': {u'info': u'Sflow Profile Configuration', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'SflowProfile'}}), is_container='list', yang_name=\"sflow-profile\", rest_name=\"sflow-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Sflow Profile Configuration', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'SflowProfile'}}, namespace='urn:brocade.com:mgmt:brocade-sflow', defining_module='brocade-sflow', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sflow_profile must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"profile_name\",sflow_profile.sflow_profile, yang_name=\"sflow-profile\", rest_name=\"sflow-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='profile-name', extensions={u'tailf-common': {u'info': u'Sflow Profile Configuration', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'SflowProfile'}}), is_container='list', yang_name=\"sflow-profile\", rest_name=\"sflow-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Sflow Profile Configuration', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'SflowProfile'}}, namespace='urn:brocade.com:mgmt:brocade-sflow', defining_module='brocade-sflow', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__sflow_profile = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_port_type(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'E-Port|U-Port|G-Port|F-Port', 'length': [u'6']}), is_leaf=True, yang_name=\"port-type\", rest_name=\"port-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Fibre Channel port type'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='porttype-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"port_type must be of a type compatible with porttype-type\"\"\",\n          'defined-type': \"brocade-fabric-service:porttype-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'E-Port|U-Port|G-Port|F-Port', 'length': [u'6']}), is_leaf=True, yang_name=\"port-type\", rest_name=\"port-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Fibre Channel port type'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='porttype-type', is_config=True)\"\"\",\n        })\n\n    self.__port_type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the port type of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the hash of the", "response": "def _set_hash(self, v, load=False):\n    \"\"\"\n    Setter method for hash, mapped from YANG variable /load_balance/hash (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_hash is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_hash() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=hash.hash, is_container='container', presence=False, yang_name=\"hash\", rest_name=\"hash\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'hash'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge-lag', defining_module='brocade-rbridge-lag', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"hash must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=hash.hash, is_container='container', presence=False, yang_name=\"hash\", rest_name=\"hash\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'hash'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge-lag', defining_module='brocade-rbridge-lag', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__hash = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_po_load_balance(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=po_load_balance.po_load_balance, is_container='container', presence=False, yang_name=\"po-load-balance\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'display-when': u'((/local-node/swbd-number = \"163\") or (/local-node/swbd-number = \"3000\") or (/local-node/swbd-number = \"3001\"))'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge-lag', defining_module='brocade-rbridge-lag', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"po_load_balance must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=po_load_balance.po_load_balance, is_container='container', presence=False, yang_name=\"po-load-balance\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'display-when': u'((/local-node/swbd-number = \"163\") or (/local-node/swbd-number = \"3000\") or (/local-node/swbd-number = \"3001\"))'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge-lag', defining_module='brocade-rbridge-lag', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__po_load_balance = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the load balance of a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_secpath_standby(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"secpath-standby\", rest_name=\"standby\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Make secondary-path hot standby', u'alt-name': u'standby'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"secpath_standby must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"secpath-standby\", rest_name=\"standby\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Make secondary-path hot standby', u'alt-name': u'standby'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__secpath_standby = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the standby section of the secondary path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_secpath_ipmtu(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'576..1526']}), is_leaf=True, yang_name=\"secpath-ipmtu\", rest_name=\"ipmtu\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'IP Packet Maximum Transmission Unit', u'cli-full-no': None, u'alt-name': u'ipmtu'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"secpath_ipmtu must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'576..1526']}), is_leaf=True, yang_name=\"secpath-ipmtu\", rest_name=\"ipmtu\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'IP Packet Maximum Transmission Unit', u'cli-full-no': None, u'alt-name': u'ipmtu'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__secpath_ipmtu = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the IP MTU of the secondary path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_lsp_reoptimize_timer(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'300..65535']}), is_leaf=True, yang_name=\"lsp-reoptimize-timer\", rest_name=\"reoptimize-timer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Configure Reoptimization timer', u'cli-full-no': None, u'alt-name': u'reoptimize-timer'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_reoptimize_timer must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'300..65535']}), is_leaf=True, yang_name=\"lsp-reoptimize-timer\", rest_name=\"reoptimize-timer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Configure Reoptimization timer', u'cli-full-no': None, u'alt-name': u'reoptimize-timer'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__lsp_reoptimize_timer = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the reoptimization timer for the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_lsp_commit(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"lsp-commit\", rest_name=\"commit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Commit the changes to adaptive LSP', u'alt-name': u'commit', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_commit must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"lsp-commit\", rest_name=\"commit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Commit the changes to adaptive LSP', u'alt-name': u'commit', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__lsp_commit = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the flag for the LSP commit command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the cspf - computation - mode of the current node.", "response": "def _set_lsp_cspf_computation_mode(self, v, load=False):\n    \"\"\"\n    Setter method for lsp_cspf_computation_mode, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/secondary_path/lsp_cspf_computation_mode (cspf-computation-mode)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_cspf_computation_mode is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_cspf_computation_mode() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'use-igp-metric': {'value': 1}, u'use-te-metric': {'value': 2}},), is_leaf=True, yang_name=\"lsp-cspf-computation-mode\", rest_name=\"cspf-computation-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Specify cspf-computation-mode', u'cli-full-no': None, u'alt-name': u'cspf-computation-mode'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='cspf-computation-mode', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_cspf_computation_mode must be of a type compatible with cspf-computation-mode\"\"\",\n          'defined-type': \"brocade-mpls:cspf-computation-mode\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'use-igp-metric': {'value': 1}, u'use-te-metric': {'value': 2}},), is_leaf=True, yang_name=\"lsp-cspf-computation-mode\", rest_name=\"cspf-computation-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Specify cspf-computation-mode', u'cli-full-no': None, u'alt-name': u'cspf-computation-mode'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='cspf-computation-mode', is_config=True)\"\"\",\n        })\n\n    self.__lsp_cspf_computation_mode = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_lsp_traffic_engineering(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lsp_traffic_engineering.lsp_traffic_engineering, is_container='container', presence=False, yang_name=\"lsp-traffic-engineering\", rest_name=\"traffic-engineering\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'LSP traffic engineering parameters', u'alt-name': u'traffic-engineering', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_traffic_engineering must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lsp_traffic_engineering.lsp_traffic_engineering, is_container='container', presence=False, yang_name=\"lsp-traffic-engineering\", rest_name=\"traffic-engineering\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'LSP traffic engineering parameters', u'alt-name': u'traffic-engineering', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lsp_traffic_engineering = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the LSP Traffic Engineering variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of the lsp_exclude_any variable in the MPL file.", "response": "def _set_lsp_exclude_any(self, v, load=False):\n    \"\"\"\n    Setter method for lsp_exclude_any, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/secondary_path/lsp_exclude_any (string)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_exclude_any is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_exclude_any() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=TypedListType(allowed_type=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..256']})), is_leaf=False, yang_name=\"lsp-exclude-any\", rest_name=\"exclude-any\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Exclude any of the administrative groups', u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-full-command': None, u'cli-flat-list-syntax': None, u'alt-name': u'exclude-any'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='string', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_exclude_any must be of a type compatible with string\"\"\",\n          'defined-type': \"string\",\n          'generated-type': \"\"\"YANGDynClass(base=TypedListType(allowed_type=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..256']})), is_leaf=False, yang_name=\"lsp-exclude-any\", rest_name=\"exclude-any\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Exclude any of the administrative groups', u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-full-command': None, u'cli-flat-list-syntax': None, u'alt-name': u'exclude-any'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='string', is_config=True)\"\"\",\n        })\n\n    self.__lsp_exclude_any = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset auto - bandwidth on secondary path", "response": "def _set_lsp_secpath_auto_bandwidth(self, v, load=False):\n    \"\"\"\n    Setter method for lsp_secpath_auto_bandwidth, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/secondary_path/lsp_secpath_auto_bandwidth (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_secpath_auto_bandwidth is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_secpath_auto_bandwidth() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lsp_secpath_auto_bandwidth.lsp_secpath_auto_bandwidth, is_container='container', presence=True, yang_name=\"lsp-secpath-auto-bandwidth\", rest_name=\"autobw\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable Auto-bandwidth on primary path', u'callpoint': u'MplsLspSecPathAutoBandwidth', u'cli-full-command': None, u'cli-add-mode': None, u'hidden': u'full', u'alt-name': u'autobw', u'cli-mode-name': u'config-router-mpls-lsp-$(../../lsp-name)-secpath-$(../secpath-name)-autobw'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_secpath_auto_bandwidth must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lsp_secpath_auto_bandwidth.lsp_secpath_auto_bandwidth, is_container='container', presence=True, yang_name=\"lsp-secpath-auto-bandwidth\", rest_name=\"autobw\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable Auto-bandwidth on primary path', u'callpoint': u'MplsLspSecPathAutoBandwidth', u'cli-full-command': None, u'cli-add-mode': None, u'hidden': u'full', u'alt-name': u'autobw', u'cli-mode-name': u'config-router-mpls-lsp-$(../../lsp-name)-secpath-$(../secpath-name)-autobw'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lsp_secpath_auto_bandwidth = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the input of the", "response": "def _set_input(self, v, load=False):\n    \"\"\"\n    Setter method for input, mapped from YANG variable /brocade_system_monitor_ext_rpc/show_system_monitor/input (input)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_input is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_input() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=input.input, is_leaf=True, yang_name=\"input\", rest_name=\"input\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-system-monitor-ext', defining_module='brocade-system-monitor-ext', yang_type='input', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"input must be of a type compatible with input\"\"\",\n          'defined-type': \"brocade-system-monitor-ext:input\",\n          'generated-type': \"\"\"YANGDynClass(base=input.input, is_leaf=True, yang_name=\"input\", rest_name=\"input\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-system-monitor-ext', defining_module='brocade-system-monitor-ext', yang_type='input', is_config=True)\"\"\",\n        })\n\n    self.__input = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the if_type of the", "response": "def _set_if_type(self, v, load=False):\n    \"\"\"\n    Setter method for if_type, mapped from YANG variable /mpls_state/dynamic_bypass/dynamic_bypass_interface/if_type (mpls-if-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_if_type is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_if_type() directly.\n\n    YANG Description: Interface type\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'loopback-interface': {'value': 7}, u'ethernet-interface': {'value': 2}, u'port-channel-interface': {'value': 5}, u'unknown-interface': {'value': 1}, u've-interface': {'value': 6}, u'fbr-channel-interface': {'value': 8}},), is_leaf=True, yang_name=\"if-type\", rest_name=\"if-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='mpls-if-type', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"if_type must be of a type compatible with mpls-if-type\"\"\",\n          'defined-type': \"brocade-mpls-operational:mpls-if-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'loopback-interface': {'value': 7}, u'ethernet-interface': {'value': 2}, u'port-channel-interface': {'value': 5}, u'unknown-interface': {'value': 1}, u've-interface': {'value': 6}, u'fbr-channel-interface': {'value': 8}},), is_leaf=True, yang_name=\"if-type\", rest_name=\"if-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='mpls-if-type', is_config=False)\"\"\",\n        })\n\n    self.__if_type = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the scp variable.", "response": "def _set_scp(self, v, load=False):\n    \"\"\"\n    Setter method for scp, mapped from YANG variable /brocade_firmware_rpc/firmware_download/input/scp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_scp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_scp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=scp.scp, is_container='container', presence=False, yang_name=\"scp\", rest_name=\"scp\", parent=self, choice=(u'protocol-type', u'scp-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"scp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=scp.scp, is_container='container', presence=False, yang_name=\"scp\", rest_name=\"scp\", parent=self, choice=(u'protocol-type', u'scp-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__scp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of the ftp property.", "response": "def _set_ftp(self, v, load=False):\n    \"\"\"\n    Setter method for ftp, mapped from YANG variable /brocade_firmware_rpc/firmware_download/input/ftp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ftp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ftp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ftp.ftp, is_container='container', presence=False, yang_name=\"ftp\", rest_name=\"ftp\", parent=self, choice=(u'protocol-type', u'ftp-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ftp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ftp.ftp, is_container='container', presence=False, yang_name=\"ftp\", rest_name=\"ftp\", parent=self, choice=(u'protocol-type', u'ftp-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ftp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the value of the sftp property.", "response": "def _set_sftp(self, v, load=False):\n    \"\"\"\n    Setter method for sftp, mapped from YANG variable /brocade_firmware_rpc/firmware_download/input/sftp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_sftp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_sftp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=sftp.sftp, is_container='container', presence=False, yang_name=\"sftp\", rest_name=\"sftp\", parent=self, choice=(u'protocol-type', u'sftp-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sftp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=sftp.sftp, is_container='container', presence=False, yang_name=\"sftp\", rest_name=\"sftp\", parent=self, choice=(u'protocol-type', u'sftp-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__sftp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the USB parameter.", "response": "def _set_usb(self, v, load=False):\n    \"\"\"\n    Setter method for usb, mapped from YANG variable /brocade_firmware_rpc/firmware_download/input/usb (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_usb is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_usb() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=usb.usb, is_container='container', presence=False, yang_name=\"usb\", rest_name=\"usb\", parent=self, choice=(u'protocol-type', u'usb-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"usb must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=usb.usb, is_container='container', presence=False, yang_name=\"usb\", rest_name=\"usb\", parent=self, choice=(u'protocol-type', u'usb-protocol'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__usb = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_coldboot(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"coldboot\", rest_name=\"coldboot\", parent=self, choice=(u'reboot-options', u'coldboot'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Perform non ISSU firmware download.'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"coldboot must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"coldboot\", rest_name=\"coldboot\", parent=self, choice=(u'reboot-options', u'coldboot'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Perform non ISSU firmware download.'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__coldboot = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the coldboot value for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_event(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=event.event, is_container='container', presence=False, yang_name=\"event\", rest_name=\"event\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure action profile events and action(s)', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"event must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=event.event, is_container='container', presence=False, yang_name=\"event\", rest_name=\"event\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure action profile events and action(s)', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__event = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the event field of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_on_board(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=on_board.on_board, is_container='container', presence=False, yang_name=\"on-board\", rest_name=\"on-board\", parent=self, choice=(u'interface-identifier', u'on-board'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"on_board must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=on_board.on_board, is_container='container', presence=False, yang_name=\"on-board\", rest_name=\"on-board\", parent=self, choice=(u'interface-identifier', u'on-board'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__on_board = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the on - board field of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the current object to be the gbc", "response": "def _set_gbc(self, v, load=False):\n    \"\"\"\n    Setter method for gbc, mapped from YANG variable /brocade_interface_ext_rpc/get_media_detail/output/interface/gbc (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_gbc is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_gbc() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=gbc.gbc, is_container='container', presence=False, yang_name=\"gbc\", rest_name=\"gbc\", parent=self, choice=(u'interface-identifier', u'gbic'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"gbc must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=gbc.gbc, is_container='container', presence=False, yang_name=\"gbc\", rest_name=\"gbc\", parent=self, choice=(u'interface-identifier', u'gbic'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__gbc = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the extended sequence of parameters.", "response": "def _set_xfp(self, v, load=False):\n    \"\"\"\n    Setter method for xfp, mapped from YANG variable /brocade_interface_ext_rpc/get_media_detail/output/interface/xfp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_xfp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_xfp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=xfp.xfp, is_container='container', presence=False, yang_name=\"xfp\", rest_name=\"xfp\", parent=self, choice=(u'interface-identifier', u'xfp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"xfp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=xfp.xfp, is_container='container', presence=False, yang_name=\"xfp\", rest_name=\"xfp\", parent=self, choice=(u'interface-identifier', u'xfp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__xfp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_xff(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=xff.xff, is_container='container', presence=False, yang_name=\"xff\", rest_name=\"xff\", parent=self, choice=(u'interface-identifier', u'xff'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"xff must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=xff.xff, is_container='container', presence=False, yang_name=\"xff\", rest_name=\"xff\", parent=self, choice=(u'interface-identifier', u'xff'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__xff = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the xff field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_xfpe(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=xfpe.xfpe, is_container='container', presence=False, yang_name=\"xfpe\", rest_name=\"xfpe\", parent=self, choice=(u'interface-identifier', u'xfpe'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"xfpe must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=xfpe.xfpe, is_container='container', presence=False, yang_name=\"xfpe\", rest_name=\"xfpe\", parent=self, choice=(u'interface-identifier', u'xfpe'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__xfpe = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the xfpe variable for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the QSF field of the", "response": "def _set_qsfp(self, v, load=False):\n    \"\"\"\n    Setter method for qsfp, mapped from YANG variable /brocade_interface_ext_rpc/get_media_detail/output/interface/qsfp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_qsfp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_qsfp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=qsfp.qsfp, is_container='container', presence=False, yang_name=\"qsfp\", rest_name=\"qsfp\", parent=self, choice=(u'interface-identifier', u'qsfp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"qsfp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=qsfp.qsfp, is_container='container', presence=False, yang_name=\"qsfp\", rest_name=\"qsfp\", parent=self, choice=(u'interface-identifier', u'qsfp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__qsfp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the QSFP field of the", "response": "def _set_qsfpp(self, v, load=False):\n    \"\"\"\n    Setter method for qsfpp, mapped from YANG variable /brocade_interface_ext_rpc/get_media_detail/output/interface/qsfpp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_qsfpp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_qsfpp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=qsfpp.qsfpp, is_container='container', presence=False, yang_name=\"qsfpp\", rest_name=\"qsfpp\", parent=self, choice=(u'interface-identifier', u'qsfpp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"qsfpp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=qsfpp.qsfpp, is_container='container', presence=False, yang_name=\"qsfpp\", rest_name=\"qsfpp\", parent=self, choice=(u'interface-identifier', u'qsfpp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__qsfpp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_cfp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=cfp.cfp, is_container='container', presence=False, yang_name=\"cfp\", rest_name=\"cfp\", parent=self, choice=(u'interface-identifier', u'cfp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cfp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=cfp.cfp, is_container='container', presence=False, yang_name=\"cfp\", rest_name=\"cfp\", parent=self, choice=(u'interface-identifier', u'cfp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__cfp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the CFP field of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_cfp2(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=cfp2.cfp2, is_container='container', presence=False, yang_name=\"cfp2\", rest_name=\"cfp2\", parent=self, choice=(u'interface-identifier', u'cfp2'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cfp2 must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=cfp2.cfp2, is_container='container', presence=False, yang_name=\"cfp2\", rest_name=\"cfp2\", parent=self, choice=(u'interface-identifier', u'cfp2'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__cfp2 = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the CFP2 variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_qsfp28(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=qsfp28.qsfp28, is_container='container', presence=False, yang_name=\"qsfp28\", rest_name=\"qsfp28\", parent=self, choice=(u'interface-identifier', u'qsfp28'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"qsfp28 must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=qsfp28.qsfp28, is_container='container', presence=False, yang_name=\"qsfp28\", rest_name=\"qsfp28\", parent=self, choice=(u'interface-identifier', u'qsfp28'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__qsfp28 = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the QSF28 variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_maximum_prefix(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=maximum_prefix.maximum_prefix, is_container='container', presence=False, yang_name=\"maximum-prefix\", rest_name=\"maximum-prefix\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Maximum number of prefix accept from this peer', u'cli-incomplete-no': None, u'cli-break-sequence-commands': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"maximum_prefix must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=maximum_prefix.maximum_prefix, is_container='container', presence=False, yang_name=\"maximum-prefix\", rest_name=\"maximum-prefix\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Maximum number of prefix accept from this peer', u'cli-incomplete-no': None, u'cli-break-sequence-commands': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__maximum_prefix = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the maximum prefix of the BGP neighbor."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the neighbor route map for the BGP neighbor.", "response": "def _set_neighbor_route_map(self, v, load=False):\n    \"\"\"\n    Setter method for neighbor_route_map, mapped from YANG variable /routing_system/router/router_bgp/address_family/ipv4/ipv4_unicast/af_vrf/neighbor/af_ipv4_vrf_neighbor_address_holder/af_ipv4_neighbor_addr/neighbor_route_map (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_neighbor_route_map is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_neighbor_route_map() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=neighbor_route_map.neighbor_route_map, is_container='container', presence=False, yang_name=\"neighbor-route-map\", rest_name=\"route-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Apply route map to neighbor', u'alt-name': u'route-map', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"neighbor_route_map must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=neighbor_route_map.neighbor_route_map, is_container='container', presence=False, yang_name=\"neighbor-route-map\", rest_name=\"route-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Apply route map to neighbor', u'alt-name': u'route-map', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__neighbor_route_map = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the associate_peer_group field of the BGP neighbor.", "response": "def _set_associate_peer_group(self, v, load=False):\n    \"\"\"\n    Setter method for associate_peer_group, mapped from YANG variable /routing_system/router/router_bgp/address_family/ipv4/ipv4_unicast/af_vrf/neighbor/af_ipv4_vrf_neighbor_address_holder/af_ipv4_neighbor_addr/associate_peer_group (bgp-peergroup)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_associate_peer_group is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_associate_peer_group() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'[a-zA-Z]{1}([-a-zA-Z0-9\\\\\\\\\\\\\\\\@#\\\\+\\\\*\\\\(\\\\)=\\\\{~\\\\}%<>=$_\\\\[\\\\]\\\\|]{0,62})'}), is_leaf=True, yang_name=\"associate-peer-group\", rest_name=\"peer-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Assign peer-group to neighbor', u'alt-name': u'peer-group'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='bgp-peergroup', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"associate_peer_group must be of a type compatible with bgp-peergroup\"\"\",\n          'defined-type': \"brocade-bgp:bgp-peergroup\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'[a-zA-Z]{1}([-a-zA-Z0-9\\\\\\\\\\\\\\\\@#\\\\+\\\\*\\\\(\\\\)=\\\\{~\\\\}%<>=$_\\\\[\\\\]\\\\|]{0,62})'}), is_leaf=True, yang_name=\"associate-peer-group\", rest_name=\"peer-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Assign peer-group to neighbor', u'alt-name': u'peer-group'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='bgp-peergroup', is_config=True)\"\"\",\n        })\n\n    self.__associate_peer_group = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the local - as number of the neighbor.", "response": "def _set_local_as(self, v, load=False):\n    \"\"\"\n    Setter method for local_as, mapped from YANG variable /routing_system/router/router_bgp/address_family/ipv4/ipv4_unicast/af_vrf/neighbor/af_ipv4_vrf_neighbor_address_holder/af_ipv4_neighbor_addr/local_as (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_local_as is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_local_as() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=local_as.local_as, is_container='container', presence=False, yang_name=\"local-as\", rest_name=\"local-as\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Assign local-as number to neighbor', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-break-sequence-commands': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"local_as must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=local_as.local_as, is_container='container', presence=False, yang_name=\"local-as\", rest_name=\"local-as\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Assign local-as number to neighbor', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-break-sequence-commands': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__local_as = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_advertisement_interval(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=advertisement_interval.advertisement_interval, is_container='container', presence=False, yang_name=\"advertisement-interval\", rest_name=\"advertisement-interval\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Minimum interval between sending BGP routing updates', u'cli-compact-syntax': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"advertisement_interval must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=advertisement_interval.advertisement_interval, is_container='container', presence=False, yang_name=\"advertisement-interval\", rest_name=\"advertisement-interval\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Minimum interval between sending BGP routing updates', u'cli-compact-syntax': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__advertisement_interval = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the advertisement interval for BGP routing updates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the password of the BGP neighbor.", "response": "def _set_password(self, v, load=False):\n    \"\"\"\n    Setter method for password, mapped from YANG variable /routing_system/router/router_bgp/address_family/ipv4/ipv4_unicast/af_vrf/neighbor/af_ipv4_vrf_neighbor_address_holder/af_ipv4_neighbor_addr/password (bgp-password)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_password is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_password() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=unicode, is_leaf=True, yang_name=\"password\", rest_name=\"password\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable TCP-MD5 password protection', u'cli-multi-value': None, u'suppress-echo': u'true'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='bgp-password', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"password must be of a type compatible with bgp-password\"\"\",\n          'defined-type': \"brocade-bgp:bgp-password\",\n          'generated-type': \"\"\"YANGDynClass(base=unicode, is_leaf=True, yang_name=\"password\", rest_name=\"password\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable TCP-MD5 password protection', u'cli-multi-value': None, u'suppress-echo': u'true'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='bgp-password', is_config=True)\"\"\",\n        })\n\n    self.__password = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the long - distance -isl of the link.", "response": "def _set_long_distance_isl(self, v, load=False):\n    \"\"\"\n    Setter method for long_distance_isl, mapped from YANG variable /interface/ethernet/long_distance_isl (enumeration)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_long_distance_isl is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_long_distance_isl() directly.\n\n    YANG Description: Configure the link as long-distance-link\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'2000': {'value': 2000}, u'5000': {'value': 5000}, u'10000': {'value': 10000}, u'30000': {'value': 30000}},), is_leaf=True, yang_name=\"long-distance-isl\", rest_name=\"long-distance-isl\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure the link as long-distance-link', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"long_distance_isl must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-interface:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'2000': {'value': 2000}, u'5000': {'value': 5000}, u'10000': {'value': 10000}, u'30000': {'value': 30000}},), is_leaf=True, yang_name=\"long-distance-isl\", rest_name=\"long-distance-isl\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure the link as long-distance-link', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__long_distance_isl = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_description(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1 .. 63']}), is_leaf=True, yang_name=\"description\", rest_name=\"description\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Interface specific description', u'cli-multi-value': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_BASIC_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='string', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"description must be of a type compatible with string\"\"\",\n          'defined-type': \"string\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1 .. 63']}), is_leaf=True, yang_name=\"description\", rest_name=\"description\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Interface specific description', u'cli-multi-value': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_BASIC_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='string', is_config=True)\"\"\",\n        })\n\n    self.__description = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the description of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the variable to be used as a private", "response": "def _set_channel_group(self, v, load=False):\n    \"\"\"\n    Setter method for channel_group, mapped from YANG variable /interface/ethernet/channel_group (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_channel_group is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_channel_group() directly.\n\n    YANG Description: A container of configuration leaf elements for managing\nthe channel-group membership.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=channel_group.channel_group, is_container='container', presence=False, yang_name=\"channel-group\", rest_name=\"channel-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'LACP channel commands', u'cli-sequence-commands': None, u'cli-full-no': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_MODE_CHANNEL_GROUP_MEMBER'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"channel_group must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=channel_group.channel_group, is_container='container', presence=False, yang_name=\"channel-group\", rest_name=\"channel-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'LACP channel commands', u'cli-sequence-commands': None, u'cli-full-no': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_MODE_CHANNEL_GROUP_MEMBER'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__channel_group = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_switchport_basic(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=switchport_basic.switchport_basic, is_container='container', presence=False, yang_name=\"switchport-basic\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_MODE_SWITCHPORT_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"switchport_basic must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=switchport_basic.switchport_basic, is_container='container', presence=False, yang_name=\"switchport-basic\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_MODE_SWITCHPORT_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__switchport_basic = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the switchport basic property."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_switchport(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=switchport.switchport, is_container='container', presence=False, yang_name=\"switchport\", rest_name=\"switchport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set the switching characteristics of the Layer2 \\ninterface', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_MODE_SWITCHPORT_CONFIG', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"switchport must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=switchport.switchport, is_container='container', presence=False, yang_name=\"switchport\", rest_name=\"switchport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set the switching characteristics of the Layer2 \\ninterface', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_MODE_SWITCHPORT_CONFIG', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__switchport = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the switchport of the network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_vepa(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vepa.vepa, is_container='container', presence=False, yang_name=\"vepa\", rest_name=\"vepa\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable vepa to support U-turn of the traffic on the \\nselected interface', u'hidden': u'foscmd'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vepa must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vepa.vepa, is_container='container', presence=False, yang_name=\"vepa\", rest_name=\"vepa\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable vepa to support U-turn of the traffic on the \\nselected interface', u'hidden': u'foscmd'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vepa = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the IANA network in order to be used in the next set of network traffic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_edge_loop_detection_native(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=edge_loop_detection_native.edge_loop_detection_native, is_container='container', presence=False, yang_name=\"edge-loop-detection-native\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_ELD'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"edge_loop_detection_native must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=edge_loop_detection_native.edge_loop_detection_native, is_container='container', presence=False, yang_name=\"edge-loop-detection-native\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_ELD'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__edge_loop_detection_native = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the edge - loop - detection - native variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of link_oam_interface mapped from YANG variable ethernet / link_oam_interface", "response": "def _set_link_oam_interface(self, v, load=False):\n    \"\"\"\n    Setter method for link_oam_interface, mapped from YANG variable /interface/ethernet/link_oam_interface (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_link_oam_interface is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_link_oam_interface() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=link_oam_interface.link_oam_interface, is_container='container', presence=False, yang_name=\"link-oam-interface\", rest_name=\"link-oam\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Interface - Link OAM commands', u'alt-name': u'link-oam', u'sort-priority': u'117', u'cli-incomplete-command': None, u'cli-incomplete-no': None, u'callpoint': u'setDot3ahEnableInterface'}}, namespace='urn:brocade.com:mgmt:brocade-dot3ah', defining_module='brocade-dot3ah', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"link_oam_interface must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=link_oam_interface.link_oam_interface, is_container='container', presence=False, yang_name=\"link-oam-interface\", rest_name=\"link-oam\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Interface - Link OAM commands', u'alt-name': u'link-oam', u'sort-priority': u'117', u'cli-incomplete-command': None, u'cli-incomplete-no': None, u'callpoint': u'setDot3ahEnableInterface'}}, namespace='urn:brocade.com:mgmt:brocade-dot3ah', defining_module='brocade-dot3ah', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__link_oam_interface = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of the LACP PDU Forward in the base order.", "response": "def _set_lacp_pdu_forward(self, v, load=False):\n    \"\"\"\n    Setter method for lacp_pdu_forward, mapped from YANG variable /interface/ethernet/lacp_pdu_forward (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lacp_pdu_forward is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lacp_pdu_forward() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lacp_pdu_forward.lacp_pdu_forward, is_container='container', presence=False, yang_name=\"lacp-pdu-forward\", rest_name=\"lacp-pdu-forward\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'LACP PDU Forward related commands', u'callpoint': u'LacpPduForwardPhyCP', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-lacp-pdu-forward', defining_module='brocade-lacp-pdu-forward', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lacp_pdu_forward must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lacp_pdu_forward.lacp_pdu_forward, is_container='container', presence=False, yang_name=\"lacp-pdu-forward\", rest_name=\"lacp-pdu-forward\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'LACP PDU Forward related commands', u'callpoint': u'LacpPduForwardPhyCP', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-lacp-pdu-forward', defining_module='brocade-lacp-pdu-forward', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lacp_pdu_forward = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_link_fault_signaling(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=link_fault_signaling.link_fault_signaling, is_container='container', presence=False, yang_name=\"link-fault-signaling\", rest_name=\"link-fault-signaling\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure a link-fault-signaling', u'callpoint': u'Lfs', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-lfs', defining_module='brocade-lfs', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"link_fault_signaling must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=link_fault_signaling.link_fault_signaling, is_container='container', presence=False, yang_name=\"link-fault-signaling\", rest_name=\"link-fault-signaling\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure a link-fault-signaling', u'callpoint': u'Lfs', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-lfs', defining_module='brocade-lfs', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__link_fault_signaling = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the flag for link_fault_signaling"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_lldp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lldp.lldp, is_container='container', presence=False, yang_name=\"lldp\", rest_name=\"lldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'The Link Layer Discovery Protocol(LLDP).', u'sort-priority': u'111', u'callpoint': u'lldp_phy_interface_conf', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-lldp', defining_module='brocade-lldp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lldp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lldp.lldp, is_container='container', presence=False, yang_name=\"lldp\", rest_name=\"lldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'The Link Layer Discovery Protocol(LLDP).', u'sort-priority': u'111', u'callpoint': u'lldp_phy_interface_conf', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-lldp', defining_module='brocade-lldp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lldp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the lldp field in the base network."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the flag to disable the link error.", "response": "def _set_link_error_disable(self, v, load=False):\n    \"\"\"\n    Setter method for link_error_disable, mapped from YANG variable /interface/ethernet/link_error_disable (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_link_error_disable is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_link_error_disable() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=link_error_disable.link_error_disable, is_container='container', presence=False, yang_name=\"link-error-disable\", rest_name=\"link-error-disable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'port link dampening', u'callpoint': u'Pld', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-pld', defining_module='brocade-pld', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"link_error_disable must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=link_error_disable.link_error_disable, is_container='container', presence=False, yang_name=\"link-error-disable\", rest_name=\"link-error-disable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'port link dampening', u'callpoint': u'Pld', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-pld', defining_module='brocade-pld', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__link_error_disable = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_packet_error_counters(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=packet_error_counters.packet_error_counters, is_container='container', presence=False, yang_name=\"packet-error-counters\", rest_name=\"packet-error-counters\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-rsvp-packet-error-counters', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"packet_error_counters must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=packet_error_counters.packet_error_counters, is_container='container', presence=False, yang_name=\"packet-error-counters\", rest_name=\"packet-error-counters\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-rsvp-packet-error-counters', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__packet_error_counters = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of packet_error_counters in the tree of unseen packet counters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_port_sec_max(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..8192']}), is_leaf=True, yang_name=\"port-sec-max\", rest_name=\"max\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Maximum number of allowed MACs', u'alt-name': u'max', u'cli-run-template': u'$(.?:)'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"port_sec_max must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..8192']}), is_leaf=True, yang_name=\"port-sec-max\", rest_name=\"max\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Maximum number of allowed MACs', u'alt-name': u'max', u'cli-run-template': u'$(.?:)'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__port_sec_max = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the port_sec_max property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the action on violation", "response": "def _set_port_sec_violation(self, v, load=False):\n    \"\"\"\n    Setter method for port_sec_violation, mapped from YANG variable /interface/port_channel/switchport/port_security/port_sec_violation (port-sec-violation)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_port_sec_violation is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_port_sec_violation() directly.\n\n    YANG Description: Set the action on violation\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'restrict': {'value': 1}, u'shutdown': {'value': 2}},), is_leaf=True, yang_name=\"port-sec-violation\", rest_name=\"violation\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set the action on violation', u'alt-name': u'violation'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='port-sec-violation', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"port_sec_violation must be of a type compatible with port-sec-violation\"\"\",\n          'defined-type': \"brocade-interface:port-sec-violation\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'restrict': {'value': 1}, u'shutdown': {'value': 2}},), is_leaf=True, yang_name=\"port-sec-violation\", rest_name=\"violation\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set the action on violation', u'alt-name': u'violation'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='port-sec-violation', is_config=True)\"\"\",\n        })\n\n    self.__port_sec_violation = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_allowed_ouis(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"oui\",allowed_ouis.allowed_ouis, yang_name=\"allowed-ouis\", rest_name=\"allowed-ouis\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='oui', extensions={u'tailf-common': {u'info': u'List of allowed OUIs', u'cli-drop-node-name': None, u'cli-suppress-mode': None, u'callpoint': u'interface_po_portsecurity_oui', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"allowed-ouis\", rest_name=\"allowed-ouis\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of allowed OUIs', u'cli-drop-node-name': None, u'cli-suppress-mode': None, u'callpoint': u'interface_po_portsecurity_oui', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"allowed_ouis must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"oui\",allowed_ouis.allowed_ouis, yang_name=\"allowed-ouis\", rest_name=\"allowed-ouis\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='oui', extensions={u'tailf-common': {u'info': u'List of allowed OUIs', u'cli-drop-node-name': None, u'cli-suppress-mode': None, u'callpoint': u'interface_po_portsecurity_oui', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"allowed-ouis\", rest_name=\"allowed-ouis\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of allowed OUIs', u'cli-drop-node-name': None, u'cli-suppress-mode': None, u'callpoint': u'interface_po_portsecurity_oui', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__allowed_ouis = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the allowed OUIs in the order they appear in the port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_active_interfaces(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=active_interfaces.active_interfaces, is_container='container', presence=False, yang_name=\"active-interfaces\", rest_name=\"active-interfaces\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-overlay-service-policy-brief-active-interface', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"active_interfaces must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=active_interfaces.active_interfaces, is_container='container', presence=False, yang_name=\"active-interfaces\", rest_name=\"active-interfaces\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-overlay-service-policy-brief-active-interface', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__active_interfaces = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the active_interfaces property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_auth(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'sha': {'value': 1}, u'noauth': {'value': 2}, u'md5': {'value': 0}},), default=unicode(\"noauth\"), is_leaf=True, yang_name=\"auth\", rest_name=\"auth\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authorization protocol for username\\n(Default=noauth)'}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"auth must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-snmp:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'sha': {'value': 1}, u'noauth': {'value': 2}, u'md5': {'value': 0}},), default=unicode(\"noauth\"), is_leaf=True, yang_name=\"auth\", rest_name=\"auth\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authorization protocol for username\\n(Default=noauth)'}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__auth = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the auth parameter of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_priv(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'AES128': {'value': 2}, u'DES': {'value': 0}, u'nopriv': {'value': 1}},), default=unicode(\"nopriv\"), is_leaf=True, yang_name=\"priv\", rest_name=\"priv\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Privacy protocol for username (Default=nopriv)'}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"priv must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-snmp:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'AES128': {'value': 2}, u'DES': {'value': 0}, u'nopriv': {'value': 1}},), default=unicode(\"nopriv\"), is_leaf=True, yang_name=\"priv\", rest_name=\"priv\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Privacy protocol for username (Default=nopriv)'}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__priv = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the priv property in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the private password of the node.", "response": "def _set_priv_password(self, v, load=False):\n    \"\"\"\n    Setter method for priv_password, mapped from YANG variable /rbridge_id/snmp_server/user/priv_password (string)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_priv_password is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_priv_password() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=unicode, default=unicode(\"\"), is_leaf=True, yang_name=\"priv-password\", rest_name=\"priv-password\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Privacy password associated with username', u'suppress-echo': u'true', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='string', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"priv_password must be of a type compatible with string\"\"\",\n          'defined-type': \"string\",\n          'generated-type': \"\"\"YANGDynClass(base=unicode, default=unicode(\"\"), is_leaf=True, yang_name=\"priv-password\", rest_name=\"priv-password\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Privacy password associated with username', u'suppress-echo': u'true', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='string', is_config=True)\"\"\",\n        })\n\n    self.__priv_password = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the ip configuration for the", "response": "def _set_ip_config(self, v, load=False):\n    \"\"\"\n    Setter method for ip_config, mapped from YANG variable /interface/gigabitethernet/ip/ip_config (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ip_config is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ip_config() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ip_config.ip_config, is_container='container', presence=False, yang_name=\"ip-config\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'phy-intf-ip-cfg-cp', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_IP_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-ip-config', defining_module='brocade-ip-config', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ip_config must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ip_config.ip_config, is_container='container', presence=False, yang_name=\"ip-config\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'phy-intf-ip-cfg-cp', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_IP_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-ip-config', defining_module='brocade-ip-config', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ip_config = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery S3 to identify the region hosting the provided bucket.", "response": "def _get_bucket_endpoint(self):\n        \"\"\"\n        Queries S3 to identify the region hosting the provided bucket.\n        \"\"\"\n        conn = S3Connection()\n        bucket = conn.lookup(self.bucket_name)\n        if not bucket:\n            # TODO: Make the bucket here?\n            raise InputParameterError('The provided bucket %s doesn\\'t exist' % self.bucket_name)\n        endpoint = str(bucket.get_location())\n        return endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_action_profile_name(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"action_profile_name\",action_profile_name.action_profile_name, yang_name=\"action-profile-name\", rest_name=\"action-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='action-profile-name', extensions={u'tailf-common': {u'info': u'Configure action profile related parameters', u'cli-full-no': None, u'cli-suppress-list-no': None, u'alt-name': u'action-profile', u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'setY1731ActionProfiles', u'cli-mode-name': u'config-cfm-y1731-action-profile-$(action-profile-name)'}}), is_container='list', yang_name=\"action-profile-name\", rest_name=\"action-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure action profile related parameters', u'cli-full-no': None, u'cli-suppress-list-no': None, u'alt-name': u'action-profile', u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'setY1731ActionProfiles', u'cli-mode-name': u'config-cfm-y1731-action-profile-$(action-profile-name)'}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"action_profile_name must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"action_profile_name\",action_profile_name.action_profile_name, yang_name=\"action-profile-name\", rest_name=\"action-profile\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='action-profile-name', extensions={u'tailf-common': {u'info': u'Configure action profile related parameters', u'cli-full-no': None, u'cli-suppress-list-no': None, u'alt-name': u'action-profile', u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'setY1731ActionProfiles', u'cli-mode-name': u'config-cfm-y1731-action-profile-$(action-profile-name)'}}), is_container='list', yang_name=\"action-profile-name\", rest_name=\"action-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure action profile related parameters', u'cli-full-no': None, u'cli-suppress-list-no': None, u'alt-name': u'action-profile', u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'setY1731ActionProfiles', u'cli-mode-name': u'config-cfm-y1731-action-profile-$(action-profile-name)'}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__action_profile_name = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the action - profile name of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_route_source(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=route_source.route_source, is_container='container', presence=False, yang_name=\"route-source\", rest_name=\"route-source\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Source address of route'}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"route_source must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=route_source.route_source, is_container='container', presence=False, yang_name=\"route-source\", rest_name=\"route-source\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Source address of route'}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__route_source = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the route_source of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the reachable state of the linkinfo domain.", "response": "def _set_linkinfo_domain_reachable(self, v, load=False):\n    \"\"\"\n    Setter method for linkinfo_domain_reachable, mapped from YANG variable /brocade_fabric_service_rpc/show_linkinfo/output/show_link_info/linkinfo_domain_reachable (linkinfo-domain-reachable-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_linkinfo_domain_reachable is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_linkinfo_domain_reachable() directly.\n\n    YANG Description: Indicates whether the RBridge is reachable\nor not.\nYes - Indicates RBridge is reachable\nNo  - Indicates RBridge is not reachable.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'Yes|No|yes|no', 'length': [u'0..3']}), is_leaf=True, yang_name=\"linkinfo-domain-reachable\", rest_name=\"linkinfo-domain-reachable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Indicates whether the RBridge is reachable\\nor not'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='linkinfo-domain-reachable-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"linkinfo_domain_reachable must be of a type compatible with linkinfo-domain-reachable-type\"\"\",\n          'defined-type': \"brocade-fabric-service:linkinfo-domain-reachable-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'Yes|No|yes|no', 'length': [u'0..3']}), is_leaf=True, yang_name=\"linkinfo-domain-reachable\", rest_name=\"linkinfo-domain-reachable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Indicates whether the RBridge is reachable\\nor not'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='linkinfo-domain-reachable-type', is_config=True)\"\"\",\n        })\n\n    self.__linkinfo_domain_reachable = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_proto(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=proto.proto, is_container='container', presence=False, yang_name=\"proto\", rest_name=\"proto\", parent=self, choice=(u'class-type', u'proto'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Proto - specify an ethernet protocol\\n                            classification', u'cli-sequence-commands': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-vlan', defining_module='brocade-vlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"proto must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=proto.proto, is_container='container', presence=False, yang_name=\"proto\", rest_name=\"proto\", parent=self, choice=(u'class-type', u'proto'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Proto - specify an ethernet protocol\\n                            classification', u'cli-sequence-commands': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-vlan', defining_module='brocade-vlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__proto = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the proto property of the\n    based on class - type"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_mld(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mld.mld, is_container='container', presence=False, yang_name=\"mld\", rest_name=\"mld\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Multicast Listener Discovery (MLD) Snooping', u'callpoint': u'MldsGlobal', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-mld-snooping', defining_module='brocade-mld-snooping', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mld must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mld.mld, is_container='container', presence=False, yang_name=\"mld\", rest_name=\"mld\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Multicast Listener Discovery (MLD) Snooping', u'callpoint': u'MldsGlobal', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-mld-snooping', defining_module='brocade-mld-snooping', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mld = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the mld field of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the maprole of the", "response": "def _set_maprole(self, v, load=False):\n    \"\"\"\n    Setter method for maprole, mapped from YANG variable /ldap_server/maprole (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_maprole is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_maprole() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=maprole.maprole, is_container='container', presence=False, yang_name=\"maprole\", rest_name=\"maprole\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Maps a role to a group', u'cli-incomplete-no': None, u'sort-priority': u'17'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"maprole must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=maprole.maprole, is_container='container', presence=False, yang_name=\"maprole\", rest_name=\"maprole\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Maps a role to a group', u'cli-incomplete-no': None, u'sort-priority': u'17'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__maprole = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_enabled_zone(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"zone_name\",enabled_zone.enabled_zone, yang_name=\"enabled-zone\", rest_name=\"enabled-zone\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='zone-name', extensions={u'tailf-common': {u'info': u'List of enabled Zones'}}), is_container='list', yang_name=\"enabled-zone\", rest_name=\"enabled-zone\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'List of enabled Zones'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"enabled_zone must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"zone_name\",enabled_zone.enabled_zone, yang_name=\"enabled-zone\", rest_name=\"enabled-zone\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='zone-name', extensions={u'tailf-common': {u'info': u'List of enabled Zones'}}), is_container='list', yang_name=\"enabled-zone\", rest_name=\"enabled-zone\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'List of enabled Zones'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__enabled_zone = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the enabled zone of the order."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the duplicateWWN value for the duplicateWWN field.", "response": "def _set_duplicateWWN(self, v, load=False):\n    \"\"\"\n    Setter method for duplicateWWN, mapped from YANG variable /rbridge_id/fabric/login_policy/duplicateWWN (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_duplicateWWN is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_duplicateWWN() directly.\n\n    YANG Description: It decides the DuplicateWWN login policy of a switch\nin a fabric.The below mentioned policies are supported.\n- old login will have precedence.(Default behavior)\n- new or second(dup) login takes precedence.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=duplicateWWN.duplicateWWN, is_container='container', presence=False, yang_name=\"duplicateWWN\", rest_name=\"duplicateWWN\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-add-mode': None, u'cli-full-command': None, u'info': u'Configure the DuplicateWWN login policy of a switch in fabric.'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"duplicateWWN must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=duplicateWWN.duplicateWWN, is_container='container', presence=False, yang_name=\"duplicateWWN\", rest_name=\"duplicateWWN\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-add-mode': None, u'cli-full-command': None, u'info': u'Configure the DuplicateWWN login policy of a switch in fabric.'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__duplicateWWN = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_red_profile(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=red_profile.red_profile, is_container='container', presence=False, yang_name=\"red-profile\", rest_name=\"red-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure RED profiles', u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-qos', defining_module='brocade-qos', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"red_profile must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=red_profile.red_profile, is_container='container', presence=False, yang_name=\"red-profile\", rest_name=\"red-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure RED profiles', u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-qos', defining_module='brocade-qos', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__red_profile = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the red profile of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the replicator of the", "response": "def _set_replicator(self, v, load=False):\n    \"\"\"\n    Setter method for replicator, mapped from YANG variable /tunnel_settings/system/tunnel/replicator (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_replicator is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_replicator() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=replicator.replicator, is_container='container', presence=False, yang_name=\"replicator\", rest_name=\"replicator\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'NSX replicator tunnel related settings', u'hidden': u'debug', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"replicator must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=replicator.replicator, is_container='container', presence=False, yang_name=\"replicator\", rest_name=\"replicator\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'NSX replicator tunnel related settings', u'hidden': u'debug', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__replicator = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the value of the Dscp field in the .", "response": "def _set_dscp(self, v, load=False):\n    \"\"\"\n    Setter method for dscp, mapped from YANG variable /qos_mpls/map/dscp_exp/dscp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dscp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dscp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"dscp_in_values\",dscp.dscp, yang_name=\"dscp\", rest_name=\"dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dscp-in-values', extensions={u'tailf-common': {u'info': u'Map Dscp value to Exp value', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'QosMplsDscpExpCallpoint', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"dscp\", rest_name=\"dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Map Dscp value to Exp value', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'QosMplsDscpExpCallpoint', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dscp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"dscp_in_values\",dscp.dscp, yang_name=\"dscp\", rest_name=\"dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dscp-in-values', extensions={u'tailf-common': {u'info': u'Map Dscp value to Exp value', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'QosMplsDscpExpCallpoint', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"dscp\", rest_name=\"dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Map Dscp value to Exp value', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'QosMplsDscpExpCallpoint', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__dscp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_auth_type(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=auth_type.auth_type, is_container='container', presence=False, yang_name=\"auth-type\", rest_name=\"auth-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authentication type'}}, namespace='urn:brocade.com:mgmt:brocade-vrrp', defining_module='brocade-vrrp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"auth_type must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=auth_type.auth_type, is_container='container', presence=False, yang_name=\"auth-type\", rest_name=\"auth-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authentication type'}}, namespace='urn:brocade.com:mgmt:brocade-vrrp', defining_module='brocade-vrrp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__auth_type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the authentication type of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the bandwidth value of the autobw threshold table.", "response": "def _set_autobw_threshold_table_bandwidth(self, v, load=False):\n    \"\"\"\n    Setter method for autobw_threshold_table_bandwidth, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/autobw_threshold_table/autobw_threshold_table_bandwidth (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_autobw_threshold_table_bandwidth is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_autobw_threshold_table_bandwidth() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"bandwidth_value\",autobw_threshold_table_bandwidth.autobw_threshold_table_bandwidth, yang_name=\"autobw-threshold-table-bandwidth\", rest_name=\"bandwidth\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='bandwidth-value', extensions={u'tailf-common': {u'info': u'Define Autobw Threshold Table Entries', u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwThresholdTableEntries', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-incomplete-command': None, u'alt-name': u'bandwidth'}}), is_container='list', yang_name=\"autobw-threshold-table-bandwidth\", rest_name=\"bandwidth\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Autobw Threshold Table Entries', u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwThresholdTableEntries', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-incomplete-command': None, u'alt-name': u'bandwidth'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"autobw_threshold_table_bandwidth must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"bandwidth_value\",autobw_threshold_table_bandwidth.autobw_threshold_table_bandwidth, yang_name=\"autobw-threshold-table-bandwidth\", rest_name=\"bandwidth\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='bandwidth-value', extensions={u'tailf-common': {u'info': u'Define Autobw Threshold Table Entries', u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwThresholdTableEntries', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-incomplete-command': None, u'alt-name': u'bandwidth'}}), is_container='list', yang_name=\"autobw-threshold-table-bandwidth\", rest_name=\"bandwidth\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Autobw Threshold Table Entries', u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwThresholdTableEntries', u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-incomplete-command': None, u'alt-name': u'bandwidth'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__autobw_threshold_table_bandwidth = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_random_detect(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=random_detect.random_detect, is_container='container', presence=False, yang_name=\"random-detect\", rest_name=\"random-detect\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Random Early Detect (RED) Profile', u'callpoint': u'cos_profile_te', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"random_detect must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=random_detect.random_detect, is_container='container', presence=False, yang_name=\"random-detect\", rest_name=\"random-detect\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Random Early Detect (RED) Profile', u'callpoint': u'cos_profile_te', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__random_detect = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the random_detect variable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_drop_monitor(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=drop_monitor.drop_monitor, is_container='container', presence=False, yang_name=\"drop-monitor\", rest_name=\"drop-monitor\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure QoS drop monitor polling', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"drop_monitor must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=drop_monitor.drop_monitor, is_container='container', presence=False, yang_name=\"drop-monitor\", rest_name=\"drop-monitor\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure QoS drop monitor polling', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__drop_monitor = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the drop monitor for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the standard list of the availabe", "response": "def _set_standard(self, v, load=False):\n    \"\"\"\n    Setter method for standard, mapped from YANG variable /overlay/access_list/type/vxlan/standard (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_standard is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_standard() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"user_acl_name\",standard.standard, yang_name=\"standard\", rest_name=\"standard\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='user-acl-name', extensions={u'tailf-common': {u'info': u'standard <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityStandardCallpoint', u'cli-mode-name': u'config-overlay-vxlan-std-$(user-acl-name)'}}), is_container='list', yang_name=\"standard\", rest_name=\"standard\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'standard <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityStandardCallpoint', u'cli-mode-name': u'config-overlay-vxlan-std-$(user-acl-name)'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"standard must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"user_acl_name\",standard.standard, yang_name=\"standard\", rest_name=\"standard\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='user-acl-name', extensions={u'tailf-common': {u'info': u'standard <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityStandardCallpoint', u'cli-mode-name': u'config-overlay-vxlan-std-$(user-acl-name)'}}), is_container='list', yang_name=\"standard\", rest_name=\"standard\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'standard <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityStandardCallpoint', u'cli-mode-name': u'config-overlay-vxlan-std-$(user-acl-name)'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__standard = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset extended list of extended user acl.", "response": "def _set_extended(self, v, load=False):\n    \"\"\"\n    Setter method for extended, mapped from YANG variable /overlay/access_list/type/vxlan/extended (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_extended is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_extended() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"ext_user_acl_name\",extended.extended, yang_name=\"extended\", rest_name=\"extended\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ext-user-acl-name', extensions={u'tailf-common': {u'info': u'extended <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityExtendedCallpoint', u'cli-mode-name': u'config-overlay-vxlan-ext-$(ext-user-acl-name)'}}), is_container='list', yang_name=\"extended\", rest_name=\"extended\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'extended <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityExtendedCallpoint', u'cli-mode-name': u'config-overlay-vxlan-ext-$(ext-user-acl-name)'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"extended must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"ext_user_acl_name\",extended.extended, yang_name=\"extended\", rest_name=\"extended\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ext-user-acl-name', extensions={u'tailf-common': {u'info': u'extended <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityExtendedCallpoint', u'cli-mode-name': u'config-overlay-vxlan-ext-$(ext-user-acl-name)'}}), is_container='list', yang_name=\"extended\", rest_name=\"extended\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'extended <user-acl-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityExtendedCallpoint', u'cli-mode-name': u'config-overlay-vxlan-ext-$(ext-user-acl-name)'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__extended = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_server(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=server.server, is_container='container', presence=False, yang_name=\"server\", rest_name=\"server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure SSH Server', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-sec-services', defining_module='brocade-sec-services', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"server must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=server.server, is_container='container', presence=False, yang_name=\"server\", rest_name=\"server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure SSH Server', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-sec-services', defining_module='brocade-sec-services', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__server = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the server property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_client(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=client.client, is_container='container', presence=False, yang_name=\"client\", rest_name=\"client\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure SSH Client', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-sec-services', defining_module='brocade-sec-services', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"client must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=client.client, is_container='container', presence=False, yang_name=\"client\", rest_name=\"client\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure SSH Client', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-sec-services', defining_module='brocade-sec-services', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__client = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the client property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the ipv6_nd_ra property of the base node.", "response": "def _set_ipv6_nd_ra(self, v, load=False):\n    \"\"\"\n    Setter method for ipv6_nd_ra, mapped from YANG variable /rbridge_id/interface/ve/ipv6/ipv6_nd_ra (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ipv6_nd_ra is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ipv6_nd_ra() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ipv6_nd_ra.ipv6_nd_ra, is_container='container', presence=False, yang_name=\"ipv6-nd-ra\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IpV6NdRaVlanIntf'}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-nd-ra', defining_module='brocade-ipv6-nd-ra', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ipv6_nd_ra must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ipv6_nd_ra.ipv6_nd_ra, is_container='container', presence=False, yang_name=\"ipv6-nd-ra\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IpV6NdRaVlanIntf'}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-nd-ra', defining_module='brocade-ipv6-nd-ra', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ipv6_nd_ra = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the values of ipv6_intf_cmds in the order they are defined.", "response": "def _set_ipv6_ve_intf_cmds(self, v, load=False):\n    \"\"\"\n    Setter method for ipv6_ve_intf_cmds, mapped from YANG variable /rbridge_id/interface/ve/ipv6/ipv6_ve_intf_cmds (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ipv6_ve_intf_cmds is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ipv6_ve_intf_cmds() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ipv6_ve_intf_cmds.ipv6_ve_intf_cmds, is_container='container', presence=False, yang_name=\"ipv6-ve-intf-cmds\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'ipv6 mlds ve interface commands', u'cli-drop-node-name': None, u'callpoint': u'MldsVe'}}, namespace='urn:brocade.com:mgmt:brocade-mld-snooping', defining_module='brocade-mld-snooping', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ipv6_ve_intf_cmds must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ipv6_ve_intf_cmds.ipv6_ve_intf_cmds, is_container='container', presence=False, yang_name=\"ipv6-ve-intf-cmds\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'ipv6 mlds ve interface commands', u'cli-drop-node-name': None, u'callpoint': u'MldsVe'}}, namespace='urn:brocade.com:mgmt:brocade-mld-snooping', defining_module='brocade-mld-snooping', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ipv6_ve_intf_cmds = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_interface_ospfv3_conf(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=interface_ospfv3_conf.interface_ospfv3_conf, is_container='container', presence=False, yang_name=\"interface-ospfv3-conf\", rest_name=\"ospf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Open Shortest Path First version 3 (OSPFv3)', u'alt-name': u'ospf', u'cli-incomplete-no': None, u'callpoint': u'Ospfv3VeInterfaceConfig', u'cli-incomplete-command': None, u'sort-priority': u'113', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"interface_ospfv3_conf must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=interface_ospfv3_conf.interface_ospfv3_conf, is_container='container', presence=False, yang_name=\"interface-ospfv3-conf\", rest_name=\"ospf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Open Shortest Path First version 3 (OSPFv3)', u'alt-name': u'ospf', u'cli-incomplete-no': None, u'callpoint': u'Ospfv3VeInterfaceConfig', u'cli-incomplete-command': None, u'sort-priority': u'113', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__interface_ospfv3_conf = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of interface_ospfv3_conf in the top - level OSPF file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_vrrpv3(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"vrid\",vrrpv3.vrrpv3, yang_name=\"vrrpv3\", rest_name=\"vrrp-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='vrid', extensions={u'tailf-common': {u'info': u'Start VRRP configuration', u'cli-no-key-completion': None, u'alt-name': u'vrrp-group', u'sort-priority': u'121', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'vrrpv3SessionVlan'}}), is_container='list', yang_name=\"vrrpv3\", rest_name=\"vrrp-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Start VRRP configuration', u'cli-no-key-completion': None, u'alt-name': u'vrrp-group', u'sort-priority': u'121', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'vrrpv3SessionVlan'}}, namespace='urn:brocade.com:mgmt:brocade-vrrpv3', defining_module='brocade-vrrpv3', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vrrpv3 must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"vrid\",vrrpv3.vrrpv3, yang_name=\"vrrpv3\", rest_name=\"vrrp-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='vrid', extensions={u'tailf-common': {u'info': u'Start VRRP configuration', u'cli-no-key-completion': None, u'alt-name': u'vrrp-group', u'sort-priority': u'121', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'vrrpv3SessionVlan'}}), is_container='list', yang_name=\"vrrpv3\", rest_name=\"vrrp-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Start VRRP configuration', u'cli-no-key-completion': None, u'alt-name': u'vrrp-group', u'sort-priority': u'121', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'vrrpv3SessionVlan'}}, namespace='urn:brocade.com:mgmt:brocade-vrrpv3', defining_module='brocade-vrrpv3', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__vrrpv3 = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the vrrpv3 mapped variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_show_firmware_option(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=show_firmware_option.show_firmware_option, is_container='container', presence=False, yang_name=\"show-firmware-option\", rest_name=\"firmware\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'show firmware', u'alt-name': u'firmware', u'display-when': u'(/local-node/swbd-number = \"4000\")'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"show_firmware_option must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=show_firmware_option.show_firmware_option, is_container='container', presence=False, yang_name=\"show-firmware-option\", rest_name=\"firmware\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'show firmware', u'alt-name': u'firmware', u'display-when': u'(/local-node/swbd-number = \"4000\")'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__show_firmware_option = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the show_firmware_option in the base of the\n "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the value of anycast - gateway - mac", "response": "def _set_anycast_gateway_mac(self, v, load=False):\n    \"\"\"\n    Setter method for anycast_gateway_mac, mapped from YANG variable /rbridge_id/ipv6/static_ag_ipv6_config/anycast_gateway_mac (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_anycast_gateway_mac is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_anycast_gateway_mac() directly.\n\n    YANG Description: Anycast gateway MAC address.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=anycast_gateway_mac.anycast_gateway_mac, is_container='container', presence=False, yang_name=\"anycast-gateway-mac\", rest_name=\"anycast-gateway-mac\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Anycast gateway MAC address.'}}, namespace='urn:brocade.com:mgmt:brocade-vrrp', defining_module='brocade-vrrp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"anycast_gateway_mac must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=anycast_gateway_mac.anycast_gateway_mac, is_container='container', presence=False, yang_name=\"anycast-gateway-mac\", rest_name=\"anycast-gateway-mac\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Anycast gateway MAC address.'}}, namespace='urn:brocade.com:mgmt:brocade-vrrp', defining_module='brocade-vrrp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__anycast_gateway_mac = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the fru variable for the", "response": "def _set_fru(self, v, load=False):\n    \"\"\"\n    Setter method for fru, mapped from YANG variable /system_monitor_mail/fru (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fru is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fru() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fru.fru, is_container='container', presence=False, yang_name=\"fru\", rest_name=\"fru\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FRU mail settings'}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fru must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fru.fru, is_container='container', presence=False, yang_name=\"fru\", rest_name=\"fru\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FRU mail settings'}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fru = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the default VRF for BGP", "response": "def _set_default_vrf(self, v, load=False):\n    \"\"\"\n    Setter method for default_vrf, mapped from YANG variable /rbridge_id/router/router_bgp/address_family/ipv6/ipv6_unicast/default_vrf (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_default_vrf is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_default_vrf() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=default_vrf.default_vrf, is_container='container', presence=False, yang_name=\"default-vrf\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IPv4 unicast address Family', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-drop-node-name': None, u'cli-full-command': None, u'callpoint': u'AfIpv6Ucast', u'cli-mode-name': u'config-bgp-ipv6u'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"default_vrf must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=default_vrf.default_vrf, is_container='container', presence=False, yang_name=\"default-vrf\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IPv4 unicast address Family', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-drop-node-name': None, u'cli-full-command': None, u'callpoint': u'AfIpv6Ucast', u'cli-mode-name': u'config-bgp-ipv6u'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__default_vrf = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the ldp session summary for the object.", "response": "def _set_ldp_session_summary(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_session_summary, mapped from YANG variable /mpls_state/ldp/ldp_session_summary (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_session_summary is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_session_summary() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_session_summary.ldp_session_summary, is_container='container', presence=False, yang_name=\"ldp-session-summary\", rest_name=\"ldp-session-summary\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-session-summary', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_session_summary must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_session_summary.ldp_session_summary, is_container='container', presence=False, yang_name=\"ldp-session-summary\", rest_name=\"ldp-session-summary\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-session-summary', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_session_summary = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_ldp_fec_statistics(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_fec_statistics.ldp_fec_statistics, is_container='container', presence=False, yang_name=\"ldp-fec-statistics\", rest_name=\"ldp-fec-statistics\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_fec_statistics must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_fec_statistics.ldp_fec_statistics, is_container='container', presence=False, yang_name=\"ldp-fec-statistics\", rest_name=\"ldp-fec-statistics\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_fec_statistics = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the LDP FEC statistics for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_mpls_traffic_bypasses(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"mpls_traffic_bypass_name\",mpls_traffic_bypasses.mpls_traffic_bypasses, yang_name=\"mpls-traffic-bypasses\", rest_name=\"bypass-lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='mpls-traffic-bypass-name', extensions={u'tailf-common': {u'callpoint': u'Mplstrafficbypass', u'cli-suppress-mode': None, u'alt-name': u'bypass-lsp', u'info': u'MPLS Stats profile by Bypass LSP name', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"mpls-traffic-bypasses\", rest_name=\"bypass-lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'Mplstrafficbypass', u'cli-suppress-mode': None, u'alt-name': u'bypass-lsp', u'info': u'MPLS Stats profile by Bypass LSP name', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mpls_traffic_bypasses must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"mpls_traffic_bypass_name\",mpls_traffic_bypasses.mpls_traffic_bypasses, yang_name=\"mpls-traffic-bypasses\", rest_name=\"bypass-lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='mpls-traffic-bypass-name', extensions={u'tailf-common': {u'callpoint': u'Mplstrafficbypass', u'cli-suppress-mode': None, u'alt-name': u'bypass-lsp', u'info': u'MPLS Stats profile by Bypass LSP name', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"mpls-traffic-bypasses\", rest_name=\"bypass-lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'Mplstrafficbypass', u'cli-suppress-mode': None, u'alt-name': u'bypass-lsp', u'info': u'MPLS Stats profile by Bypass LSP name', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mpls_traffic_bypasses = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the bypass - lsp field in the MPL file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the state of the fwdl - archive.", "response": "def _set_fwdl_state(self, v, load=False):\n    \"\"\"\n    Setter method for fwdl_state, mapped from YANG variable /brocade_firmware_rpc/fwdl_status/output/fwdl_state (enumeration)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fwdl_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fwdl_state() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'in-progress': {'value': 1}, u'downloaded': {'value': 2}, u'completed': {'value': 4}, u'failed': {'value': 3}},), is_leaf=True, yang_name=\"fwdl-state\", rest_name=\"fwdl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Firmware download state'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fwdl_state must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-firmware:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'in-progress': {'value': 1}, u'downloaded': {'value': 2}, u'completed': {'value': 4}, u'failed': {'value': 3}},), is_leaf=True, yang_name=\"fwdl-state\", rest_name=\"fwdl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Firmware download state'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__fwdl_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the value of auth_check_level2 in the base order of LSPs.", "response": "def _set_auth_check_level2(self, v, load=False):\n    \"\"\"\n    Setter method for auth_check_level2, mapped from YANG variable /routing_system/interface/ve/intf_isis/interface_isis/auth_check/auth_check_level2 (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_auth_check_level2 is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_auth_check_level2() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=auth_check_level2.auth_check_level2, is_container='container', presence=False, yang_name=\"auth-check-level2\", rest_name=\"level-2\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authenticate incoming PDUs for Level-2 LSPs, CSNP, PSNP', u'alt-name': u'level-2', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"auth_check_level2 must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=auth_check_level2.auth_check_level2, is_container='container', presence=False, yang_name=\"auth-check-level2\", rest_name=\"level-2\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authenticate incoming PDUs for Level-2 LSPs, CSNP, PSNP', u'alt-name': u'level-2', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__auth_check_level2 = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_get_port_channel_detail(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=get_port_channel_detail.get_port_channel_detail, is_leaf=True, yang_name=\"get-port-channel-detail\", rest_name=\"get-port-channel-detail\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getlacpportchanneldetails-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-lag', defining_module='brocade-lag', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"get_port_channel_detail must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=get_port_channel_detail.get_port_channel_detail, is_leaf=True, yang_name=\"get-port-channel-detail\", rest_name=\"get-port-channel-detail\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getlacpportchanneldetails-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-lag', defining_module='brocade-lag', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__get_port_channel_detail = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the get_port_channel_detail property of the\n    based on the rpc parameter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_get_portchannel_info_by_intf(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=get_portchannel_info_by_intf.get_portchannel_info_by_intf, is_leaf=True, yang_name=\"get-portchannel-info-by-intf\", rest_name=\"get-portchannel-info-by-intf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getlacpportportchannel-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-lag', defining_module='brocade-lag', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"get_portchannel_info_by_intf must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=get_portchannel_info_by_intf.get_portchannel_info_by_intf, is_leaf=True, yang_name=\"get-portchannel-info-by-intf\", rest_name=\"get-portchannel-info-by-intf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getlacpportportchannel-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-lag', defining_module='brocade-lag', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__get_portchannel_info_by_intf = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "This method is used to set the value of get_portchannel_info_by_intf in the portchannel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_cir(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range':  ['0..18446744073709551615']}, int_size=64), restriction_dict={'range': [u'40000..100000000000']}), is_leaf=True, yang_name=\"cir\", rest_name=\"cir\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Committed Information Rate.', u'cli-suppress-no': None, u'cli-hide-in-submode': None}}, namespace='urn:brocade.com:mgmt:brocade-policer', defining_module='brocade-policer', yang_type='uint64', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cir must be of a type compatible with uint64\"\"\",\n          'defined-type': \"uint64\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range':  ['0..18446744073709551615']}, int_size=64), restriction_dict={'range': [u'40000..100000000000']}), is_leaf=True, yang_name=\"cir\", rest_name=\"cir\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Committed Information Rate.', u'cli-suppress-no': None, u'cli-hide-in-submode': None}}, namespace='urn:brocade.com:mgmt:brocade-policer', defining_module='brocade-policer', yang_type='uint64', is_config=True)\"\"\",\n        })\n\n    self.__cir = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the cir field of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_conform_set_dscp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0 .. 63']}), is_leaf=True, yang_name=\"conform-set-dscp\", rest_name=\"conform-set-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'DCSP Priority for conformant traffic.', u'cli-optional-in-sequence': None, u'display-when': u\"(../conform-set-prec = '64') or not(../conform-set-prec)\"}}, namespace='urn:brocade.com:mgmt:brocade-policer', defining_module='brocade-policer', yang_type='dscp-value', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"conform_set_dscp must be of a type compatible with dscp-value\"\"\",\n          'defined-type': \"brocade-policer:dscp-value\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0 .. 63']}), is_leaf=True, yang_name=\"conform-set-dscp\", rest_name=\"conform-set-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'DCSP Priority for conformant traffic.', u'cli-optional-in-sequence': None, u'display-when': u\"(../conform-set-prec = '64') or not(../conform-set-prec)\"}}, namespace='urn:brocade.com:mgmt:brocade-policer', defining_module='brocade-policer', yang_type='dscp-value', is_config=True)\"\"\",\n        })\n\n    self.__conform_set_dscp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the DSCP field in the order of the DSCP."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the vlag of the", "response": "def _set_vlag(self, v, load=False):\n    \"\"\"\n    Setter method for vlag, mapped from YANG variable /interface/port_channel/vlag (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vlag is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vlag() directly.\n\n    YANG Description: The vLAG properties for this port-channel.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vlag.vlag, is_container='container', presence=False, yang_name=\"vlag\", rest_name=\"vlag\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Virtual LAG', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vlag must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vlag.vlag, is_container='container', presence=False, yang_name=\"vlag\", rest_name=\"vlag\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Virtual LAG', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vlag = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset priority tagging for the", "response": "def _set_priority_tag_enable(self, v, load=False):\n    \"\"\"\n    Setter method for priority_tag_enable, mapped from YANG variable /interface/port_channel/priority_tag_enable (empty)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_priority_tag_enable is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_priority_tag_enable() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"priority-tag-enable\", rest_name=\"priority-tag\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure 802.1p priority tagging', u'cli-full-command': None, u'callpoint': u'interface_po', u'alt-name': u'priority-tag'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"priority_tag_enable must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"priority-tag-enable\", rest_name=\"priority-tag\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure 802.1p priority tagging', u'cli-full-command': None, u'callpoint': u'interface_po', u'alt-name': u'priority-tag'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__priority_tag_enable = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_load_balance_type(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'hash-based': {'value': 1}},), default=unicode(\"hash-based\"), is_leaf=True, yang_name=\"load-balance-type\", rest_name=\"load-balance-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Port-channel load balancing type'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"load_balance_type must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-interface:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'hash-based': {'value': 1}},), default=unicode(\"hash-based\"), is_leaf=True, yang_name=\"load-balance-type\", rest_name=\"load-balance-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Port-channel load balancing type'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__load_balance_type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the load balance type for the node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_fcoeport(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoeport.fcoeport, is_container='container', presence=False, yang_name=\"fcoeport\", rest_name=\"fcoeport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure the LAG to enable FCoE', u'callpoint': u'fcoeport_attr_lag_cp', u'sort-priority': u'138', u'display-when': u'(/vcsmode/vcs-mode = \"true\")'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoeport must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoeport.fcoeport, is_container='container', presence=False, yang_name=\"fcoeport\", rest_name=\"fcoeport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure the LAG to enable FCoE', u'callpoint': u'fcoeport_attr_lag_cp', u'sort-priority': u'138', u'display-when': u'(/vcsmode/vcs-mode = \"true\")'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoeport = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the FCoE port field in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_openflowPo(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=openflowPo.openflowPo, is_container='container', presence=False, yang_name=\"openflowPo\", rest_name=\"openflow\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'enables openflow ', u'alt-name': u'openflow', u'sort-priority': u'116', u'callpoint': u'OpenflowPo'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"openflowPo must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=openflowPo.openflowPo, is_container='container', presence=False, yang_name=\"openflowPo\", rest_name=\"openflow\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'enables openflow ', u'alt-name': u'openflow', u'sort-priority': u'116', u'callpoint': u'OpenflowPo'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__openflowPo = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the openflow - po variable for the sequence of openflows."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_port_profile_port(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"port-profile-port\", rest_name=\"port-profile-port\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set the interface to AMPP profile mode', u'sort-priority': u'135'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"port_profile_port must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"port-profile-port\", rest_name=\"port-profile-port\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set the interface to AMPP profile mode', u'sort-priority': u'135'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__port_profile_port = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the port - profile - port of the base node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the service policy for the", "response": "def _set_service_policy(self, v, load=False):\n    \"\"\"\n    Setter method for service_policy, mapped from YANG variable /interface/port_channel/service_policy (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_service_policy is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_service_policy() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=service_policy.service_policy, is_container='container', presence=False, yang_name=\"service-policy\", rest_name=\"service-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Attach Input/Output Policy Map', u'callpoint': u'interface_po', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mqc', defining_module='brocade-qos-mqc', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"service_policy must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=service_policy.service_policy, is_container='container', presence=False, yang_name=\"service-policy\", rest_name=\"service-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Attach Input/Output Policy Map', u'callpoint': u'interface_po', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mqc', defining_module='brocade-qos-mqc', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__service_policy = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the offsets of the current node.", "response": "def _set_offsets(self, v, load=False):\n    \"\"\"\n    Setter method for offsets, mapped from YANG variable /interface/port_channel/offsets (uda-profile-name)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_offsets is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_offsets() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'[a-zA-Z0-9]{1}([-a-zA-Z0-9_]{0,62})', 'length': [u'1..63']}), is_leaf=True, yang_name=\"offsets\", rest_name=\"uda-profile-apply\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Apply UDA profile', u'alt-name': u'uda-profile-apply', u'sort-priority': u'126', u'callpoint': u'interface_po'}}, namespace='urn:brocade.com:mgmt:brocade-uda-access-list', defining_module='brocade-uda-access-list', yang_type='uda-profile-name', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"offsets must be of a type compatible with uda-profile-name\"\"\",\n          'defined-type': \"brocade-uda-access-list:uda-profile-name\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'[a-zA-Z0-9]{1}([-a-zA-Z0-9_]{0,62})', 'length': [u'1..63']}), is_leaf=True, yang_name=\"offsets\", rest_name=\"uda-profile-apply\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Apply UDA profile', u'alt-name': u'uda-profile-apply', u'sort-priority': u'126', u'callpoint': u'interface_po'}}, namespace='urn:brocade.com:mgmt:brocade-uda-access-list', defining_module='brocade-uda-access-list', yang_type='uda-profile-name', is_config=True)\"\"\",\n        })\n\n    self.__offsets = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef align_rna(job, fastqs, univ_options, star_options):\n    star = job.wrapJobFn(run_star, fastqs, univ_options, star_options,\n                         cores=star_options['n'],\n                         memory=PromisedRequirement(lambda x: int(1.85 * x.size),\n                                                    star_options['index']),\n                         disk=PromisedRequirement(star_disk, fastqs, star_options['index']))\n    s_and_i = job.wrapJobFn(sort_and_index_star, star.rv(), univ_options,\n                            star_options).encapsulate()\n    job.addChild(star)\n    star.addChild(s_and_i)\n    return s_and_i.rv()", "response": "A wrapper for the entire rna alignment subgraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nalign a pair of fastqs with STAR. :param list fastqs: The input fastqs for alignment :param dict univ_options: Dict of universal options used by almost all tools :param dict star_options: Options specific to star :return: Dict containing output genome bam, genome bai, and transcriptome bam output_files: |- 'rnaAligned.toTranscriptome.out.bam': fsID +- 'rnaAligned.out.bam': fsID +- 'rnaChimeric.out.junction': fsID :rtype: dict", "response": "def run_star(job, fastqs, univ_options, star_options):\n    \"\"\"\n    Align a pair of fastqs with STAR.\n\n    :param list fastqs: The input fastqs for alignment\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict star_options: Options specific to star\n    :return: Dict containing output genome bam, genome bai, and transcriptome bam\n                 output_files:\n                    |- 'rnaAligned.toTranscriptome.out.bam': fsID\n                    +- 'rnaAligned.out.bam': fsID\n                    +- 'rnaChimeric.out.junction': fsID\n    :rtype: dict\n    \"\"\"\n    assert star_options['type'] in ('star', 'starlong')\n    work_dir = os.getcwd()\n    input_files = {\n        'rna_cutadapt_1.fastq': fastqs[0],\n        'rna_cutadapt_2.fastq': fastqs[1],\n        'star_index.tar.gz': star_options['index']}\n    input_files = get_files_from_filestore(job, input_files, work_dir,\n                                           docker=False)\n    # Handle gzipped file\n    gz = '.gz' if is_gzipfile(input_files['rna_cutadapt_1.fastq']) else ''\n    if gz:\n        for read_file in 'rna_cutadapt_1.fastq', 'rna_cutadapt_2.fastq':\n            os.symlink(read_file, read_file + gz)\n            input_files[read_file + gz] = input_files[read_file] + gz\n    # Untar the index\n    input_files['star_index'] = untargz(input_files['star_index.tar.gz'], work_dir)\n\n    # Check to see if user is using a STAR-Fusion index\n    star_fusion_idx = os.path.join(input_files['star_index'], 'ref_genome.fa.star.idx')\n    if os.path.exists(star_fusion_idx):\n        input_files['star_index'] = star_fusion_idx\n\n    input_files = {key: docker_path(path, work_dir=work_dir) for key, path in input_files.items()}\n\n    # Using recommended STAR-Fusion parameters:\n    # https://github.com/STAR-Fusion/STAR-Fusion/wiki\n    parameters = ['--runThreadN', str(star_options['n']),\n                  '--genomeDir', input_files['star_index'],\n                  '--twopassMode', 'Basic',\n                  '--outReadsUnmapped', 'None',\n                  '--chimSegmentMin', '12',\n                  '--chimJunctionOverhangMin', '12',\n                  '--alignSJDBoverhangMin', '10',\n                  '--alignMatesGapMax', '200000',\n                  '--alignIntronMax', '200000',\n                  '--chimSegmentReadGapMax', 'parameter', '3',\n                  '--alignSJstitchMismatchNmax', '5', '-1', '5', '5',\n                  '--outFileNamePrefix', 'rna',\n                  '--readFilesIn',\n                  input_files['rna_cutadapt_1.fastq' + gz],\n                  input_files['rna_cutadapt_2.fastq' + gz],\n                  '--outSAMattributes', 'NH', 'HI', 'AS', 'NM', 'MD',\n                  '--outSAMtype', 'BAM', 'Unsorted',\n                  '--quantMode', 'TranscriptomeSAM']\n    if gz:\n        parameters.extend(['--readFilesCommand', 'zcat'])\n\n    if star_options['type'] == 'star':\n        docker_call(tool='star', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], tool_version=star_options['version'])\n    else:\n        docker_call(tool='starlong', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], tool_version=star_options['version'])\n    output_files = defaultdict()\n    for output_file in ['rnaAligned.toTranscriptome.out.bam',\n                     'rnaAligned.out.bam',\n                     'rnaChimeric.out.junction']:\n        output_files[output_file] = job.fileStore.writeGlobalFile('/'.join([work_dir, output_file]))\n    export_results(job, output_files['rnaAligned.toTranscriptome.out.bam'], 'rna_transcriptome.bam',\n                   univ_options, subfolder='alignments')\n    export_results(job, output_files['rnaChimeric.out.junction'], 'rna_chimeric.junction',\n                   univ_options, subfolder='mutations/fusions')\n    job.fileStore.logToMaster('Ran STAR on %s successfully' % univ_options['patient'])\n    return output_files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_pfc(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"pfc_cos\",pfc.pfc, yang_name=\"pfc\", rest_name=\"pfc\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='pfc-cos', extensions={u'tailf-common': {u'info': u'Priority-based Flow Control (PFC)', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'pfc_flowcontrol_po', u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"pfc\", rest_name=\"pfc\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Priority-based Flow Control (PFC)', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'pfc_flowcontrol_po', u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos', defining_module='brocade-qos', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"pfc must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"pfc_cos\",pfc.pfc, yang_name=\"pfc\", rest_name=\"pfc\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='pfc-cos', extensions={u'tailf-common': {u'info': u'Priority-based Flow Control (PFC)', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'pfc_flowcontrol_po', u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"pfc\", rest_name=\"pfc\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Priority-based Flow Control (PFC)', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'pfc_flowcontrol_po', u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos', defining_module='brocade-qos', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__pfc = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the pfc field of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the xstp property of the", "response": "def _set_xstp(self, v, load=False):\n    \"\"\"\n    Setter method for xstp, mapped from YANG variable /hardware/custom_profile/kap_custom_profile/xstp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_xstp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_xstp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=xstp.xstp, is_container='container', presence=False, yang_name=\"xstp\", rest_name=\"xstp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure xSTP protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"xstp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=xstp.xstp, is_container='container', presence=False, yang_name=\"xstp\", rest_name=\"xstp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure xSTP protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__xstp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the value of the rpvst property in the base KAP object.", "response": "def _set_rpvst(self, v, load=False):\n    \"\"\"\n    Setter method for rpvst, mapped from YANG variable /hardware/custom_profile/kap_custom_profile/rpvst (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_rpvst is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_rpvst() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=rpvst.rpvst, is_container='container', presence=False, yang_name=\"rpvst\", rest_name=\"rpvst\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure RPVST protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rpvst must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=rpvst.rpvst, is_container='container', presence=False, yang_name=\"rpvst\", rest_name=\"rpvst\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure RPVST protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__rpvst = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_bfd_vxlan(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bfd_vxlan.bfd_vxlan, is_container='container', presence=False, yang_name=\"bfd-vxlan\", rest_name=\"bfd-vxlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure BFD-VXLAN protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bfd_vxlan must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bfd_vxlan.bfd_vxlan, is_container='container', presence=False, yang_name=\"bfd-vxlan\", rest_name=\"bfd-vxlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure BFD-VXLAN protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__bfd_vxlan = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the bfd_vxlan property."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the bfd - l3 protocol KAP parameter.", "response": "def _set_bfd_l3(self, v, load=False):\n    \"\"\"\n    Setter method for bfd_l3, mapped from YANG variable /hardware/custom_profile/kap_custom_profile/bfd_l3 (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bfd_l3 is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bfd_l3() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bfd_l3.bfd_l3, is_container='container', presence=False, yang_name=\"bfd-l3\", rest_name=\"bfd-l3\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure BFD-L3 protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bfd_l3 must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bfd_l3.bfd_l3, is_container='container', presence=False, yang_name=\"bfd-l3\", rest_name=\"bfd-l3\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure BFD-L3 protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__bfd_l3 = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the FCOE protocol KAP parameters.", "response": "def _set_fcoe(self, v, load=False):\n    \"\"\"\n    Setter method for fcoe, mapped from YANG variable /hardware/custom_profile/kap_custom_profile/fcoe (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fcoe is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fcoe() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoe.fcoe, is_container='container', presence=False, yang_name=\"fcoe\", rest_name=\"fcoe\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FCOE protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoe.fcoe, is_container='container', presence=False, yang_name=\"fcoe\", rest_name=\"fcoe\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FCOE protocol KAP parameters', u'cli-compact-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoe = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_priority_table(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=priority_table.priority_table, is_container='container', presence=False, yang_name=\"priority-table\", rest_name=\"priority-table\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' Configure Priority Table', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'callpoint': u'qos_priority_map', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-cee-map', defining_module='brocade-cee-map', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"priority_table must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=priority_table.priority_table, is_container='container', presence=False, yang_name=\"priority-table\", rest_name=\"priority-table\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' Configure Priority Table', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'callpoint': u'qos_priority_map', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-cee-map', defining_module='brocade-cee-map', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__priority_table = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the priority table of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_remap(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=remap.remap, is_container='container', presence=False, yang_name=\"remap\", rest_name=\"remap\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' Configure Class of Service (CoS) to be \\n remapped', u'callpoint': u'qos_cee_remap', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-cee-map', defining_module='brocade-cee-map', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"remap must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=remap.remap, is_container='container', presence=False, yang_name=\"remap\", rest_name=\"remap\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' Configure Class of Service (CoS) to be \\n remapped', u'callpoint': u'qos_cee_remap', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-cee-map', defining_module='brocade-cee-map', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__remap = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets remap property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset(self):\n        self.expr = []\n        self.matcher = None\n        self.last_matcher = None\n        self.description = None", "response": "Resets the state of the expression"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve the current expression against the supplied value", "response": "def resolve(self, value=None):\n        \"\"\" Resolve the current expression against the supplied value \"\"\"\n\n        # If we still have an uninitialized matcher init it now\n        if self.matcher:\n            self._init_matcher()\n\n        # Evaluate the current set of matchers forming the expression\n        matcher = self.evaluate()\n\n        try:\n            value = self._transform(value)\n            self._assertion(matcher, value)\n        except AssertionError as ex:\n            # By re-raising here the exception we reset the traceback\n            raise ex\n        finally:\n            # Reset the state of the object so we can use it again\n            if self.deferred:\n                self.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming the actual assertion for the given matcher and value.", "response": "def _assertion(self, matcher, value):\n        \"\"\" Perform the actual assertion for the given matcher and value. Override\n            this method to apply a special configuration when performing the assertion.\n            If the assertion fails it should raise an AssertionError.\n        \"\"\"\n        # To support the syntax `any_of(subject) | should ...` we check if the\n        # value to check is an Expectation object and if it is we use the descriptor\n        # protocol to bind the value's assertion logic to this expectation.\n        if isinstance(value, Expectation):\n            assertion = value._assertion.__get__(self, Expectation)\n            assertion(matcher, value.value)\n        else:\n            hc.assert_that(value, matcher)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transform(self, value):\n        if self.transform:\n            try:\n                value = self.transform(value)\n            except:\n                import sys\n                exc_type, exc_obj, exc_tb = sys.exc_info()\n                raise AssertionError('Error applying transformation <{0}>: {2}: {3}'.format(\n                    self.transform.__name__, value, exc_type.__name__, exc_obj))\n\n        return value", "response": "Applies any defined transformation to the given value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluate(self):\n\n        # Apply Shunting Yard algorithm to convert the infix expression\n        # into Reverse Polish Notation. Since we have a very limited\n        # set of operators and binding rules, the implementation becomes\n        # really simple. The expression is formed of hamcrest matcher instances\n        # and operators identifiers (ints).\n        ops = []\n        rpn = []\n        for token in self.expr:\n            if isinstance(token, int):\n                while len(ops) and token <= ops[-1]:\n                    rpn.append(ops.pop())\n                ops.append(token)\n            else:\n                rpn.append(token)\n\n        # Append the remaining operators\n        while len(ops):\n            rpn.append(ops.pop())\n\n        # Walk the RPN expression to create AllOf/AnyOf matchers\n        stack = []\n        for token in rpn:\n            if isinstance(token, int):\n                # Handle the NOT case in a special way since it's unary\n                if token == OPERATOR.NOT:\n                    stack[-1] = IsNot(stack[-1])\n                    continue\n\n                # Our operators always need two operands\n                if len(stack) < 2:\n                    raise RuntimeError('Unable to build a valid expression. Not enough operands available.')\n\n                # Check what kind of matcher we need to create\n                if token == OPERATOR.OR:\n                    matcher = hc.any_of(*stack[-2:])\n                else:  # AND, BUT\n                    matcher = hc.all_of(*stack[-2:])\n\n                stack[-2:] = [matcher]\n            else:\n                stack.append(token)\n\n        if len(stack) != 1:\n            raise RuntimeError('Unable to build a valid expression. The RPN stack should have just one item.')\n\n        matcher = stack.pop()\n\n        # If a description has been given include it in the matcher\n        if self.description:\n            matcher = hc.described_as(self.description, matcher)\n\n        return matcher", "response": "Converts the current expression into a single matcher applying the infix expression to operands according to their binding rules\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_matcher(self, alias):\n        matcher = lookup(alias)\n        if not matcher:\n            msg = 'Matcher \"%s\" not found' % alias\n\n            # Try to find similarly named matchers to help the user\n            similar = suggest(alias, max=3, cutoff=0.5)\n            if len(similar) > 1:\n                last = similar.pop()\n                msg += '. Perhaps you meant to use %s or %s?' % (', '.join(similar), last)\n            elif len(similar) > 0:\n                msg += '. Perhaps you meant to use %s?' % similar.pop()\n\n            raise KeyError(msg)\n\n        return matcher", "response": "Find a matcher based on the given alias or raises an error if no matcher could be found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_matcher(self, *args, **kwargs):\n\n        # If subject-less expectation are provided as arguments convert them\n        # to plain Hamcrest matchers in order to allow complex compositions\n        fn = lambda x: x.evaluate() if isinstance(x, Expectation) else x\n        args = [fn(x) for x in args]\n        kwargs = dict((k, fn(v)) for k, v in kwargs.items())\n\n        matcher = self.matcher(*args, **kwargs)\n        self.expr.append(matcher)\n        self.matcher = None\n        return matcher", "response": "Executes the current matcher appending it to the expression"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef described_as(self, description, *args):\n        if len(args):\n            description = description.format(*args)\n        self.description = description\n        return self", "response": "Specify a custom message for the matcher"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_fwdl_status(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fwdl_status.fwdl_status, is_leaf=True, yang_name=\"fwdl-status\", rest_name=\"fwdl-status\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Display firmware download status for the specified node', u'hidden': u'rpccmd', u'actionpoint': u'firmware'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fwdl_status must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=fwdl_status.fwdl_status, is_leaf=True, yang_name=\"fwdl-status\", rest_name=\"fwdl-status\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'info': u'Display firmware download status for the specified node', u'hidden': u'rpccmd', u'actionpoint': u'firmware'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__fwdl_status = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the status of the fwdl node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the status of the port profile.", "response": "def _set_get_port_profile_status(self, v, load=False):\n    \"\"\"\n    Setter method for get_port_profile_status, mapped from YANG variable /brocade_port_profile_ext_rpc/get_port_profile_status (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_get_port_profile_status is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_get_port_profile_status() directly.\n\n    YANG Description: This is a function that returns the status of a port \nprofile or all the port profiles.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=get_port_profile_status.get_port_profile_status, is_leaf=True, yang_name=\"get-port-profile-status\", rest_name=\"get-port-profile-status\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'appm-port-profile'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile-ext', defining_module='brocade-port-profile-ext', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"get_port_profile_status must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=get_port_profile_status.get_port_profile_status, is_leaf=True, yang_name=\"get-port-profile-status\", rest_name=\"get-port-profile-status\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'appm-port-profile'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile-ext', defining_module='brocade-port-profile-ext', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__get_port_profile_status = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_fast_flood(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fast_flood.fast_flood, is_container='container', presence=True, yang_name=\"fast-flood\", rest_name=\"fast-flood\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Define number of LSPs to be flooded before SPF Run'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fast_flood must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fast_flood.fast_flood, is_container='container', presence=True, yang_name=\"fast-flood\", rest_name=\"fast-flood\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Define number of LSPs to be flooded before SPF Run'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fast_flood = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the fast_flood variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_set_overload_bit(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=set_overload_bit.set_overload_bit, is_container='container', presence=True, yang_name=\"set-overload-bit\", rest_name=\"set-overload-bit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Indicate to other routers not to use us'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"set_overload_bit must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=set_overload_bit.set_overload_bit, is_container='container', presence=True, yang_name=\"set-overload-bit\", rest_name=\"set-overload-bit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Indicate to other routers not to use us'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__set_overload_bit = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the overload bit of the ISIS resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the reverse metric of the node.", "response": "def _set_reverse_metric(self, v, load=False):\n    \"\"\"\n    Setter method for reverse_metric, mapped from YANG variable /routing_system/router/isis/router_isis_cmds_holder/router_isis_attributes/reverse_metric (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_reverse_metric is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_reverse_metric() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=reverse_metric.reverse_metric, is_container='container', presence=True, yang_name=\"reverse-metric\", rest_name=\"reverse-metric\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Configure IS-IS reverse metric at the router level'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"reverse_metric must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=reverse_metric.reverse_metric, is_container='container', presence=True, yang_name=\"reverse-metric\", rest_name=\"reverse-metric\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Configure IS-IS reverse metric at the router level'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__reverse_metric = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the mirror_interface property of the .", "response": "def _set_mirror_interface(self, v, load=False):\n    \"\"\"\n    Setter method for mirror_interface, mapped from YANG variable /openflow_global/openflow/mirror/destination/mirror_interface (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mirror_interface is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mirror_interface() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"interface_type interface_value\",mirror_interface.mirror_interface, yang_name=\"mirror-interface\", rest_name=\"mirror-interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='interface-type interface-value', extensions={u'tailf-common': {u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OpenflowMirrorInterface'}}), is_container='list', yang_name=\"mirror-interface\", rest_name=\"mirror-interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OpenflowMirrorInterface'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mirror_interface must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"interface_type interface_value\",mirror_interface.mirror_interface, yang_name=\"mirror-interface\", rest_name=\"mirror-interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='interface-type interface-value', extensions={u'tailf-common': {u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OpenflowMirrorInterface'}}), is_container='list', yang_name=\"mirror-interface\", rest_name=\"mirror-interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-sequence-commands': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OpenflowMirrorInterface'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mirror_interface = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_igmp_po_intf_cfg(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=igmp_po_intf_cfg.igmp_po_intf_cfg, is_container='container', presence=False, yang_name=\"igmp-po-intf-cfg\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IgmpPo', u'sort-priority': u'123'}}, namespace='urn:brocade.com:mgmt:brocade-igmp', defining_module='brocade-igmp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmp_po_intf_cfg must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=igmp_po_intf_cfg.igmp_po_intf_cfg, is_container='container', presence=False, yang_name=\"igmp-po-intf-cfg\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IgmpPo', u'sort-priority': u'123'}}, namespace='urn:brocade.com:mgmt:brocade-igmp', defining_module='brocade-igmp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__igmp_po_intf_cfg = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the igmp_po_intf_cfg variable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_interface_PO_ospf_conf(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=interface_PO_ospf_conf.interface_PO_ospf_conf, is_container='container', presence=False, yang_name=\"interface-PO-ospf-conf\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'OSPFPoInterfaceCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"interface_PO_ospf_conf must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=interface_PO_ospf_conf.interface_PO_ospf_conf, is_container='container', presence=False, yang_name=\"interface-PO-ospf-conf\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'OSPFPoInterfaceCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__interface_PO_ospf_conf = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of interface_PO_ospf_conf in the base tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_interface_type(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'dcm-interface-type-unknown': {'value': 1}, u'dcm-interface-type-loopback': {'value': 7}, u'dcm-interface-type-ve': {'value': 6}, u'dcm-interface-type-ethernet': {'value': 2}, u'dcm-interface-type-fiber-channel': {'value': 8}, u'dcm-interface-type-port-channel': {'value': 5}},), is_leaf=True, yang_name=\"interface-type\", rest_name=\"interface-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='dcm-interface-type', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"interface_type must be of a type compatible with dcm-interface-type\"\"\",\n          'defined-type': \"brocade-mpls-operational:dcm-interface-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'dcm-interface-type-unknown': {'value': 1}, u'dcm-interface-type-loopback': {'value': 7}, u'dcm-interface-type-ve': {'value': 6}, u'dcm-interface-type-ethernet': {'value': 2}, u'dcm-interface-type-fiber-channel': {'value': 8}, u'dcm-interface-type-port-channel': {'value': 5}},), is_leaf=True, yang_name=\"interface-type\", rest_name=\"interface-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='dcm-interface-type', is_config=False)\"\"\",\n        })\n\n    self.__interface_type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the interface type of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the hello status of the", "response": "def _set_hello_status(self, v, load=False):\n    \"\"\"\n    Setter method for hello_status, mapped from YANG variable /mpls_state/rsvp/interfaces/hello_status (feature-config-status)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_hello_status is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_hello_status() directly.\n\n    YANG Description: 1\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'disabled': {'value': 0}, u'enabled-local': {'value': 2}, u'disabled-global': {'value': 3}, u'disabled-local': {'value': 4}, u'enabled-global': {'value': 1}},), is_leaf=True, yang_name=\"hello-status\", rest_name=\"hello-status\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='feature-config-status', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"hello_status must be of a type compatible with feature-config-status\"\"\",\n          'defined-type': \"brocade-mpls-operational:feature-config-status\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'disabled': {'value': 0}, u'enabled-local': {'value': 2}, u'disabled-global': {'value': 3}, u'disabled-local': {'value': 4}, u'enabled-global': {'value': 1}},), is_leaf=True, yang_name=\"hello-status\", rest_name=\"hello-status\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='feature-config-status', is_config=False)\"\"\",\n        })\n\n    self.__hello_status = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the floodup threshold for the", "response": "def _set_interface_flooding_up_threshold(self, v, load=False):\n    \"\"\"\n    Setter method for interface_flooding_up_threshold, mapped from YANG variable /mpls_state/rsvp/interfaces/interface_flooding_up_threshold (feature-config-source)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_interface_flooding_up_threshold is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_interface_flooding_up_threshold() directly.\n\n    YANG Description: Interface flood up threshold is taken from global, local or default settings\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'local-config': {'value': 2}, u'default-config': {'value': 3}, u'global-config': {'value': 1}},), is_leaf=True, yang_name=\"interface-flooding-up-threshold\", rest_name=\"interface-flooding-up-threshold\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='feature-config-source', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"interface_flooding_up_threshold must be of a type compatible with feature-config-source\"\"\",\n          'defined-type': \"brocade-mpls-operational:feature-config-source\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'local-config': {'value': 2}, u'default-config': {'value': 3}, u'global-config': {'value': 1}},), is_leaf=True, yang_name=\"interface-flooding-up-threshold\", rest_name=\"interface-flooding-up-threshold\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='feature-config-source', is_config=False)\"\"\",\n        })\n\n    self.__interface_flooding_up_threshold = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_error_counters(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=error_counters.error_counters, is_container='container', presence=False, yang_name=\"error-counters\", rest_name=\"error-counters\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-rsvp-interface-error-counters', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"error_counters must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=error_counters.error_counters, is_container='container', presence=False, yang_name=\"error-counters\", rest_name=\"error-counters\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-rsvp-interface-error-counters', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__error_counters = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the error_counters property of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_Cpu(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=Cpu.Cpu, is_container='container', presence=False, yang_name=\"Cpu\", rest_name=\"Cpu\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure settings for component:CPU', u'cli-compact-syntax': None, u'callpoint': u'CpuMonitor', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-threshold-monitor', defining_module='brocade-threshold-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"Cpu must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=Cpu.Cpu, is_container='container', presence=False, yang_name=\"Cpu\", rest_name=\"Cpu\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure settings for component:CPU', u'cli-compact-syntax': None, u'callpoint': u'CpuMonitor', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-threshold-monitor', defining_module='brocade-threshold-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__Cpu = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the CPU setting for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_Memory(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=Memory.Memory, is_container='container', presence=False, yang_name=\"Memory\", rest_name=\"Memory\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure settings for component:MEMORY', u'cli-compact-syntax': None, u'callpoint': u'MemoryMonitor', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-threshold-monitor', defining_module='brocade-threshold-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"Memory must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=Memory.Memory, is_container='container', presence=False, yang_name=\"Memory\", rest_name=\"Memory\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure settings for component:MEMORY', u'cli-compact-syntax': None, u'callpoint': u'MemoryMonitor', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-threshold-monitor', defining_module='brocade-threshold-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__Memory = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the Memory property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_Buffer(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=Buffer.Buffer, is_container='container', presence=False, yang_name=\"Buffer\", rest_name=\"Buffer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure settings for component:Buffer', u'cli-compact-syntax': None, u'callpoint': u'BufferMonitor', u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-threshold-monitor', defining_module='brocade-threshold-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"Buffer must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=Buffer.Buffer, is_container='container', presence=False, yang_name=\"Buffer\", rest_name=\"Buffer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure settings for component:Buffer', u'cli-compact-syntax': None, u'callpoint': u'BufferMonitor', u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-threshold-monitor', defining_module='brocade-threshold-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__Buffer = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the Buffer property in the base node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the global_rsvp_hello_acknowledgements variable in the rsvp container.", "response": "def _set_global_rsvp_hello_acknowledgements(self, v, load=False):\n    \"\"\"\n    Setter method for global_rsvp_hello_acknowledgements, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/rsvp/global_rsvp_hello_acknowledgements (empty)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_global_rsvp_hello_acknowledgements is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_global_rsvp_hello_acknowledgements() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"global-rsvp-hello-acknowledgements\", rest_name=\"hello-acknowledgements\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Acknowledge RSVP Hellos on interfaces supporting RSVP Hello and not having RSVP sessions', u'alt-name': u'hello-acknowledgements'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"global_rsvp_hello_acknowledgements must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"global-rsvp-hello-acknowledgements\", rest_name=\"hello-acknowledgements\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Acknowledge RSVP Hellos on interfaces supporting RSVP Hello and not having RSVP sessions', u'alt-name': u'hello-acknowledgements'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__global_rsvp_hello_acknowledgements = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the state of the internal statistics tree.", "response": "def _set_interface_statistics_state(self, v, load=False):\n    \"\"\"\n    Setter method for interface_statistics_state, mapped from YANG variable /interface_statistics_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_interface_statistics_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_interface_statistics_state() directly.\n\n    YANG Description: Interafce Statistics\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=interface_statistics_state.interface_statistics_state, is_container='container', presence=False, yang_name=\"interface-statistics-state\", rest_name=\"interface-statistics-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'interface-interface-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-interface-operational', defining_module='brocade-interface-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"interface_statistics_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=interface_statistics_state.interface_statistics_state, is_container='container', presence=False, yang_name=\"interface-statistics-state\", rest_name=\"interface-statistics-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'interface-interface-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-interface-operational', defining_module='brocade-interface-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__interface_statistics_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_system_config(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=system_config.system_config, is_container='container', presence=False, yang_name=\"system-config\", rest_name=\"system\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'system enable/disable commands', u'alt-name': u'system'}}, namespace='urn:brocade.com:mgmt:brocade-system-watermark', defining_module='brocade-system-watermark', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"system_config must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=system_config.system_config, is_container='container', presence=False, yang_name=\"system-config\", rest_name=\"system\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'system enable/disable commands', u'alt-name': u'system'}}, namespace='urn:brocade.com:mgmt:brocade-system-watermark', defining_module='brocade-system-watermark', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__system_config = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the system configuration for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of the VXLAN ACL.", "response": "def _set_vxlan_acl_state(self, v, load=False):\n    \"\"\"\n    Setter method for vxlan_acl_state, mapped from YANG variable /vxlan_acl_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vxlan_acl_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vxlan_acl_state() directly.\n\n    YANG Description:  Vxlan ACL information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vxlan_acl_state.vxlan_acl_state, is_container='container', presence=False, yang_name=\"vxlan-acl-state\", rest_name=\"vxlan-acl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-vxlan-acl', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vxlan_acl_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vxlan_acl_state.vxlan_acl_state, is_container='container', presence=False, yang_name=\"vxlan-acl-state\", rest_name=\"vxlan-acl-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'ssm-vxlan-acl', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-ssm-operational', defining_module='brocade-ssm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vxlan_acl_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_cpu_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=cpu_state.cpu_state, is_container='container', presence=False, yang_name=\"cpu-state\", rest_name=\"cpu-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'RAS-cpu', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-RAS-operational', defining_module='brocade-RAS-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cpu_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=cpu_state.cpu_state, is_container='container', presence=False, yang_name=\"cpu-state\", rest_name=\"cpu-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'RAS-cpu', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-RAS-operational', defining_module='brocade-RAS-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__cpu_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the CPU state of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of the memory group.", "response": "def _set_mem_state(self, v, load=False):\n    \"\"\"\n    Setter method for mem_state, mapped from YANG variable /mem_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mem_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mem_state() directly.\n\n    YANG Description: Memory information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mem_state.mem_state, is_container='container', presence=False, yang_name=\"mem-state\", rest_name=\"mem-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'RAS-mem', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-RAS-operational', defining_module='brocade-RAS-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mem_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mem_state.mem_state, is_container='container', presence=False, yang_name=\"mem-state\", rest_name=\"mem-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'RAS-mem', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-RAS-operational', defining_module='brocade-RAS-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mem_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_load_balance_lag(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=load_balance_lag.load_balance_lag, is_container='container', presence=False, yang_name=\"load-balance-lag\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'RbridgeLagCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge-lag', defining_module='brocade-rbridge-lag', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"load_balance_lag must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=load_balance_lag.load_balance_lag, is_container='container', presence=False, yang_name=\"load-balance-lag\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'RbridgeLagCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-rbridge-lag', defining_module='brocade-rbridge-lag', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__load_balance_lag = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the load balance of a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_mac_address_table(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mac_address_table.mac_address_table, is_container='container', presence=False, yang_name=\"mac-address-table\", rest_name=\"mac-address-table\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC forwarding table information', u'cli-incomplete-no': None, u'sort-priority': u'85'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mac_address_table must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mac_address_table.mac_address_table, is_container='container', presence=False, yang_name=\"mac-address-table\", rest_name=\"mac-address-table\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC forwarding table information', u'cli-incomplete-no': None, u'sort-priority': u'85'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mac_address_table = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the MAC address table in the order they are assigned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_mac_group(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"mac_group_id\",mac_group.mac_group, yang_name=\"mac-group\", rest_name=\"mac-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='mac-group-id', extensions={u'tailf-common': {u'info': u'MAC Group Configuration', u'cli-no-key-completion': None, u'sort-priority': u'54', u'cli-suppress-list-no': None, u'hidden': u'full', u'callpoint': u'mac-group-config'}}), is_container='list', yang_name=\"mac-group\", rest_name=\"mac-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC Group Configuration', u'cli-no-key-completion': None, u'sort-priority': u'54', u'cli-suppress-list-no': None, u'hidden': u'full', u'callpoint': u'mac-group-config'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mac_group must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"mac_group_id\",mac_group.mac_group, yang_name=\"mac-group\", rest_name=\"mac-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='mac-group-id', extensions={u'tailf-common': {u'info': u'MAC Group Configuration', u'cli-no-key-completion': None, u'sort-priority': u'54', u'cli-suppress-list-no': None, u'hidden': u'full', u'callpoint': u'mac-group-config'}}), is_container='list', yang_name=\"mac-group\", rest_name=\"mac-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC Group Configuration', u'cli-no-key-completion': None, u'sort-priority': u'54', u'cli-suppress-list-no': None, u'hidden': u'full', u'callpoint': u'mac-group-config'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mac_group = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the MAC group in the order they are assigned."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_latch_detection_config(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=latch_detection_config.latch_detection_config, is_container='container', presence=False, yang_name=\"latch-detection-config\", rest_name=\"latch-detection\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'linecard latch screw detection', u'alt-name': u'latch-detection', u'display-when': u'((/local-node/swbd-number = \"2000\") or (/local-node/swbd-number = \"2001\"))'}}, namespace='urn:brocade.com:mgmt:brocade-linecard-management', defining_module='brocade-linecard-management', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"latch_detection_config must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=latch_detection_config.latch_detection_config, is_container='container', presence=False, yang_name=\"latch-detection-config\", rest_name=\"latch-detection\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'linecard latch screw detection', u'alt-name': u'latch-detection', u'display-when': u'((/local-node/swbd-number = \"2000\") or (/local-node/swbd-number = \"2001\"))'}}, namespace='urn:brocade.com:mgmt:brocade-linecard-management', defining_module='brocade-linecard-management', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__latch_detection_config = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the latch - detection configuration for a node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_topology_group(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"topology_group_id\",topology_group.topology_group, yang_name=\"topology-group\", rest_name=\"topology-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='topology-group-id', extensions={u'tailf-common': {u'info': u'Configure topology vlan group for L2 protocols', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'145', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'TopologyGroupCallpoint', u'cli-mode-name': u'config-topo-group-$(topology-group-id)'}}), is_container='list', yang_name=\"topology-group\", rest_name=\"topology-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure topology vlan group for L2 protocols', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'145', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'TopologyGroupCallpoint', u'cli-mode-name': u'config-topo-group-$(topology-group-id)'}}, namespace='urn:brocade.com:mgmt:brocade-topology-group', defining_module='brocade-topology-group', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"topology_group must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"topology_group_id\",topology_group.topology_group, yang_name=\"topology-group\", rest_name=\"topology-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='topology-group-id', extensions={u'tailf-common': {u'info': u'Configure topology vlan group for L2 protocols', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'145', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'TopologyGroupCallpoint', u'cli-mode-name': u'config-topo-group-$(topology-group-id)'}}), is_container='list', yang_name=\"topology-group\", rest_name=\"topology-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure topology vlan group for L2 protocols', u'cli-no-key-completion': None, u'cli-full-no': None, u'sort-priority': u'145', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'TopologyGroupCallpoint', u'cli-mode-name': u'config-topo-group-$(topology-group-id)'}}, namespace='urn:brocade.com:mgmt:brocade-topology-group', defining_module='brocade-topology-group', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__topology_group = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the topology group of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the state of the MCT L2SYS state.", "response": "def _set_mct_l2ys_state(self, v, load=False):\n    \"\"\"\n    Setter method for mct_l2ys_state, mapped from YANG variable /mct_l2ys_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mct_l2ys_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mct_l2ys_state() directly.\n\n    YANG Description: MCT L2sys Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mct_l2ys_state.mct_l2ys_state, is_container='container', presence=False, yang_name=\"mct-l2ys-state\", rest_name=\"mct-l2ys-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'l2sys-mct-l2ys', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-l2sys-operational', defining_module='brocade-l2sys-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mct_l2ys_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mct_l2ys_state.mct_l2ys_state, is_container='container', presence=False, yang_name=\"mct-l2ys-state\", rest_name=\"mct-l2ys-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'l2sys-mct-l2ys', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-l2sys-operational', defining_module='brocade-l2sys-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mct_l2ys_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of the bridge_domain property in the base order.", "response": "def _set_bridge_domain(self, v, load=False):\n    \"\"\"\n    Setter method for bridge_domain, mapped from YANG variable /bridge_domain (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bridge_domain is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bridge_domain() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"bridge_domain_id bridge_domain_type\",bridge_domain.bridge_domain, yang_name=\"bridge-domain\", rest_name=\"bridge-domain\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='bridge-domain-id bridge-domain-type', extensions={u'tailf-common': {u'info': u'bridge-domain name for Node Specific configuration', u'cli-no-key-completion': None, u'sort-priority': u'106', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'BridgeDomainBasicCallpoint', u'cli-mode-name': u'config-bridge-domain-$(bridge-domain-id)'}}), is_container='list', yang_name=\"bridge-domain\", rest_name=\"bridge-domain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'bridge-domain name for Node Specific configuration', u'cli-no-key-completion': None, u'sort-priority': u'106', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'BridgeDomainBasicCallpoint', u'cli-mode-name': u'config-bridge-domain-$(bridge-domain-id)'}}, namespace='urn:brocade.com:mgmt:brocade-bridge-domain', defining_module='brocade-bridge-domain', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bridge_domain must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"bridge_domain_id bridge_domain_type\",bridge_domain.bridge_domain, yang_name=\"bridge-domain\", rest_name=\"bridge-domain\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='bridge-domain-id bridge-domain-type', extensions={u'tailf-common': {u'info': u'bridge-domain name for Node Specific configuration', u'cli-no-key-completion': None, u'sort-priority': u'106', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'BridgeDomainBasicCallpoint', u'cli-mode-name': u'config-bridge-domain-$(bridge-domain-id)'}}), is_container='list', yang_name=\"bridge-domain\", rest_name=\"bridge-domain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'bridge-domain name for Node Specific configuration', u'cli-no-key-completion': None, u'sort-priority': u'106', u'cli-suppress-list-no': None, u'cli-no-match-completion': None, u'cli-full-command': None, u'callpoint': u'BridgeDomainBasicCallpoint', u'cli-mode-name': u'config-bridge-domain-$(bridge-domain-id)'}}, namespace='urn:brocade.com:mgmt:brocade-bridge-domain', defining_module='brocade-bridge-domain', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__bridge_domain = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_chassis(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=chassis.chassis, is_container='container', presence=False, yang_name=\"chassis\", rest_name=\"chassis\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable/Disable Chassis', u'action': u'disable', u'display-when': u'((/local-node/swbd-number = \"131\"))', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-chassis', defining_module='brocade-chassis', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"chassis must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=chassis.chassis, is_container='container', presence=False, yang_name=\"chassis\", rest_name=\"chassis\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable/Disable Chassis', u'action': u'disable', u'display-when': u'((/local-node/swbd-number = \"131\"))', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-chassis', defining_module='brocade-chassis', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__chassis = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the chassis property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of ovsdb_server mapped from YANG variable name", "response": "def _set_ovsdb_server(self, v, load=False):\n    \"\"\"\n    Setter method for ovsdb_server, mapped from YANG variable /ovsdb_server (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ovsdb_server is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ovsdb_server() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",ovsdb_server.ovsdb_server, yang_name=\"ovsdb-server\", rest_name=\"ovsdb-server\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure OVSDB server.', u'callpoint': u'ovsdbServerConfig', u'sort-priority': u'RUNNCFG_LEVEL_OVSDB_SERVER_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'hidden': u'full', u'cli-full-no': None, u'cli-mode-name': u'config-server-$(name)'}}), is_container='list', yang_name=\"ovsdb-server\", rest_name=\"ovsdb-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure OVSDB server.', u'callpoint': u'ovsdbServerConfig', u'sort-priority': u'RUNNCFG_LEVEL_OVSDB_SERVER_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'hidden': u'full', u'cli-full-no': None, u'cli-mode-name': u'config-server-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ovsdb_server must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",ovsdb_server.ovsdb_server, yang_name=\"ovsdb-server\", rest_name=\"ovsdb-server\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure OVSDB server.', u'callpoint': u'ovsdbServerConfig', u'sort-priority': u'RUNNCFG_LEVEL_OVSDB_SERVER_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'hidden': u'full', u'cli-full-no': None, u'cli-mode-name': u'config-server-$(name)'}}), is_container='list', yang_name=\"ovsdb-server\", rest_name=\"ovsdb-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure OVSDB server.', u'callpoint': u'ovsdbServerConfig', u'sort-priority': u'RUNNCFG_LEVEL_OVSDB_SERVER_CONFIG', u'cli-suppress-list-no': None, u'cli-full-command': None, u'hidden': u'full', u'cli-full-no': None, u'cli-mode-name': u'config-server-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ovsdb_server = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the loam state of the node.", "response": "def _set_loam_state(self, v, load=False):\n    \"\"\"\n    Setter method for loam_state, mapped from YANG variable /loam_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_loam_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_loam_state() directly.\n\n    YANG Description: LINK-OAM Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=loam_state.loam_state, is_container='container', presence=False, yang_name=\"loam-state\", rest_name=\"loam-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'dot1ag-loam', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag-operational', defining_module='brocade-dot1ag-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"loam_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=loam_state.loam_state, is_container='container', presence=False, yang_name=\"loam-state\", rest_name=\"loam-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'dot1ag-loam', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag-operational', defining_module='brocade-dot1ag-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__loam_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_loam_show_debug_state(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=loam_show_debug_state.loam_show_debug_state, is_container='container', presence=False, yang_name=\"loam-show-debug-state\", rest_name=\"loam-show-debug-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'dot1ag-loam-show-debug', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag-operational', defining_module='brocade-dot1ag-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"loam_show_debug_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=loam_show_debug_state.loam_show_debug_state, is_container='container', presence=False, yang_name=\"loam-show-debug-state\", rest_name=\"loam-show-debug-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'dot1ag-loam-show-debug', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag-operational', defining_module='brocade-dot1ag-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__loam_show_debug_state = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the state of the LINK - OAM debug in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the overlay_transit variable.", "response": "def _set_overlay_transit(self, v, load=False):\n    \"\"\"\n    Setter method for overlay_transit, mapped from YANG variable /overlay_transit (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_overlay_transit is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_overlay_transit() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"user_transit_name\",overlay_transit.overlay_transit, yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='user-transit-name', extensions={u'tailf-common': {u'info': u'overlay-transit <user-transit-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityTransitCallpoint', u'cli-mode-name': u'config-overlay-transit-$(user-transit-name)'}}), is_container='list', yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'overlay-transit <user-transit-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityTransitCallpoint', u'cli-mode-name': u'config-overlay-transit-$(user-transit-name)'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_transit must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"user_transit_name\",overlay_transit.overlay_transit, yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='user-transit-name', extensions={u'tailf-common': {u'info': u'overlay-transit <user-transit-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityTransitCallpoint', u'cli-mode-name': u'config-overlay-transit-$(user-transit-name)'}}), is_container='list', yang_name=\"overlay-transit\", rest_name=\"overlay-transit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'overlay-transit <user-transit-name>', u'cli-sequence-commands': None, u'callpoint': u'VxlanVisibilityTransitCallpoint', u'cli-mode-name': u'config-overlay-transit-$(user-transit-name)'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__overlay_transit = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the state of the vpn_statistics_state of the node.", "response": "def _set_vpn_statistics_state(self, v, load=False):\n    \"\"\"\n    Setter method for vpn_statistics_state, mapped from YANG variable /vpn_statistics_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vpn_statistics_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vpn_statistics_state() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vpn_statistics_state.vpn_statistics_state, is_container='container', presence=False, yang_name=\"vpn-statistics-state\", rest_name=\"vpn-statistics-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-vpn-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vpn_statistics_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vpn_statistics_state.vpn_statistics_state, is_container='container', presence=False, yang_name=\"vpn-statistics-state\", rest_name=\"vpn-statistics-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-vpn-statistics', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vpn_statistics_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of the system utilization group.", "response": "def _set_system_utilization_state(self, v, load=False):\n    \"\"\"\n    Setter method for system_utilization_state, mapped from YANG variable /system_utilization_state (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_system_utilization_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_system_utilization_state() directly.\n\n    YANG Description: System Utilization statistics\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=system_utilization_state.system_utilization_state, is_container='container', presence=False, yang_name=\"system-utilization-state\", rest_name=\"system-utilization-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'systemutilization-system-utilization', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-systemutilization-operational', defining_module='brocade-systemutilization-operational', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"system_utilization_state must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=system_utilization_state.system_utilization_state, is_container='container', presence=False, yang_name=\"system-utilization-state\", rest_name=\"system-utilization-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'systemutilization-system-utilization', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-systemutilization-operational', defining_module='brocade-systemutilization-operational', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__system_utilization_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_get_show_cfm(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=get_show_cfm.get_show_cfm, is_leaf=True, yang_name=\"get-show-cfm\", rest_name=\"get-show-cfm\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'dot1agSummaryShowCfm'}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"get_show_cfm must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=get_show_cfm.get_show_cfm, is_leaf=True, yang_name=\"get-show-cfm\", rest_name=\"get-show-cfm\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'dot1agSummaryShowCfm'}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__get_show_cfm = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the variable to be read - only."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_dbsource(**kwargs):\n    if 'spatialite' in connection.settings_dict.get('ENGINE'):\n        kwargs.setdefault('file', connection.settings_dict['NAME'])\n        return mapnik.SQLite(wkb_format='spatialite', **kwargs)\n    names = (('dbname', 'NAME'), ('user', 'USER'),\n             ('password', 'PASSWORD'), ('host', 'HOST'), ('port', 'PORT'))\n    for mopt, dopt in names:\n        val = connection.settings_dict.get(dopt)\n        if val:\n            kwargs.setdefault(mopt, val)\n    return mapnik.PostGIS(**kwargs)", "response": "Returns a mapnik PostGIS Datasource or SQLite Datasource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef layer(self, queryset, stylename=None):\n        cls = RasterLayer if hasattr(queryset, 'image') else VectorLayer\n        layer = cls(queryset, style=stylename)\n        try:\n            style = self.map.find_style(layer.stylename)\n        except KeyError:\n            self.map.append_style(layer.stylename, layer.style())\n        layer.styles.append(layer.stylename)\n        self.map.layers.append(layer._layer)\n        return layer", "response": "Returns a new map Layer object with the specified queryset and style"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zoom_bbox(self, bbox):\n        try:\n            bbox.transform(self.map.srs)\n        except gdal.GDALException:\n            pass\n        else:\n            self.map.zoom_to_box(mapnik.Box2d(*bbox.extent))", "response": "Zoom map to bounding box."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a default Style.", "response": "def style(self):\n        \"\"\"Returns a default Style.\"\"\"\n        style = mapnik.Style()\n        rule = mapnik.Rule()\n        self._symbolizer = self.symbolizer()\n        rule.symbols.append(self._symbolizer)\n        style.rules.append(rule)\n        return style"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_cos_traffic_class(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",cos_traffic_class.cos_traffic_class, yang_name=\"cos-traffic-class\", rest_name=\"cos-traffic-class\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure CoS-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_traffic_class', u'cli-mode-name': u'cos-traffic-class-$(name)'}}), is_container='list', yang_name=\"cos-traffic-class\", rest_name=\"cos-traffic-class\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure CoS-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_traffic_class', u'cli-mode-name': u'cos-traffic-class-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cos_traffic_class must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",cos_traffic_class.cos_traffic_class, yang_name=\"cos-traffic-class\", rest_name=\"cos-traffic-class\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure CoS-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_traffic_class', u'cli-mode-name': u'cos-traffic-class-$(name)'}}), is_container='list', yang_name=\"cos-traffic-class\", rest_name=\"cos-traffic-class\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure CoS-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_traffic_class', u'cli-mode-name': u'cos-traffic-class-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__cos_traffic_class = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the cos_traffic_class of the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of cos_dscp mapped from QoS map", "response": "def _set_cos_dscp(self, v, load=False):\n    \"\"\"\n    Setter method for cos_dscp, mapped from YANG variable /qos/map/cos_dscp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_cos_dscp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_cos_dscp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",cos_dscp.cos_dscp, yang_name=\"cos-dscp\", rest_name=\"cos-dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure CoS-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_dscp_map', u'cli-mode-name': u'cos-dscp-$(name)'}}), is_container='list', yang_name=\"cos-dscp\", rest_name=\"cos-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure CoS-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_dscp_map', u'cli-mode-name': u'cos-dscp-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cos_dscp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",cos_dscp.cos_dscp, yang_name=\"cos-dscp\", rest_name=\"cos-dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure CoS-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_dscp_map', u'cli-mode-name': u'cos-dscp-$(name)'}}), is_container='list', yang_name=\"cos-dscp\", rest_name=\"cos-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure CoS-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'cos_dscp_map', u'cli-mode-name': u'cos-dscp-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__cos_dscp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_traffic_class_cos(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"traffic_class_cos_map_name\",traffic_class_cos.traffic_class_cos, yang_name=\"traffic-class-cos\", rest_name=\"traffic-class-cos\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='traffic-class-cos-map-name', extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-CoS map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_cos', u'cli-mode-name': u'traffic-class-cos-$(traffic-class-cos-map-name)'}}), is_container='list', yang_name=\"traffic-class-cos\", rest_name=\"traffic-class-cos\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-CoS map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_cos', u'cli-mode-name': u'traffic-class-cos-$(traffic-class-cos-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"traffic_class_cos must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"traffic_class_cos_map_name\",traffic_class_cos.traffic_class_cos, yang_name=\"traffic-class-cos\", rest_name=\"traffic-class-cos\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='traffic-class-cos-map-name', extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-CoS map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_cos', u'cli-mode-name': u'traffic-class-cos-$(traffic-class-cos-map-name)'}}), is_container='list', yang_name=\"traffic-class-cos\", rest_name=\"traffic-class-cos\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-CoS map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_cos', u'cli-mode-name': u'traffic-class-cos-$(traffic-class-cos-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__traffic_class_cos = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the Traffic - Class - COS mapped variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of the Traffic - Class - Mutation variable in the tree.", "response": "def _set_traffic_class_mutation(self, v, load=False):\n    \"\"\"\n    Setter method for traffic_class_mutation, mapped from YANG variable /qos/map/traffic_class_mutation (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_traffic_class_mutation is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_traffic_class_mutation() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",traffic_class_mutation.traffic_class_mutation, yang_name=\"traffic-class-mutation\", rest_name=\"traffic-class-mutation\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-Mutation map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_mutation_map', u'cli-mode-name': u'traffic-class-mutation-$(name)'}}), is_container='list', yang_name=\"traffic-class-mutation\", rest_name=\"traffic-class-mutation\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-Mutation map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_mutation_map', u'cli-mode-name': u'traffic-class-mutation-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"traffic_class_mutation must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",traffic_class_mutation.traffic_class_mutation, yang_name=\"traffic-class-mutation\", rest_name=\"traffic-class-mutation\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-Mutation map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_mutation_map', u'cli-mode-name': u'traffic-class-mutation-$(name)'}}), is_container='list', yang_name=\"traffic-class-mutation\", rest_name=\"traffic-class-mutation\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-Mutation map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_mutation_map', u'cli-mode-name': u'traffic-class-mutation-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__traffic_class_mutation = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_traffic_class_dscp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",traffic_class_dscp.traffic_class_dscp, yang_name=\"traffic-class-dscp\", rest_name=\"traffic-class-dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_dscp_map', u'cli-mode-name': u'traffic-class-dscp-$(name)'}}), is_container='list', yang_name=\"traffic-class-dscp\", rest_name=\"traffic-class-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_dscp_map', u'cli-mode-name': u'traffic-class-dscp-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"traffic_class_dscp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",traffic_class_dscp.traffic_class_dscp, yang_name=\"traffic-class-dscp\", rest_name=\"traffic-class-dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_dscp_map', u'cli-mode-name': u'traffic-class-dscp-$(name)'}}), is_container='list', yang_name=\"traffic-class-dscp\", rest_name=\"traffic-class-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic-Class-to-DSCP map', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'traffic_class_dscp_map', u'cli-mode-name': u'traffic-class-dscp-$(name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__traffic_class_dscp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the Traffic - Class - DSCP property in the base node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the DSCP Traffic Class map.", "response": "def _set_dscp_traffic_class(self, v, load=False):\n    \"\"\"\n    Setter method for dscp_traffic_class, mapped from YANG variable /qos/map/dscp_traffic_class (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dscp_traffic_class is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dscp_traffic_class() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"dscp_traffic_class_map_name\",dscp_traffic_class.dscp_traffic_class, yang_name=\"dscp-traffic-class\", rest_name=\"dscp-traffic-class\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dscp-traffic-class-map-name', extensions={u'tailf-common': {u'info': u'Configure DSCP-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'dscp_traffic_class', u'cli-mode-name': u'dscp-traffic-class-$(dscp-traffic-class-map-name)'}}), is_container='list', yang_name=\"dscp-traffic-class\", rest_name=\"dscp-traffic-class\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure DSCP-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'dscp_traffic_class', u'cli-mode-name': u'dscp-traffic-class-$(dscp-traffic-class-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dscp_traffic_class must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"dscp_traffic_class_map_name\",dscp_traffic_class.dscp_traffic_class, yang_name=\"dscp-traffic-class\", rest_name=\"dscp-traffic-class\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dscp-traffic-class-map-name', extensions={u'tailf-common': {u'info': u'Configure DSCP-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'dscp_traffic_class', u'cli-mode-name': u'dscp-traffic-class-$(dscp-traffic-class-map-name)'}}), is_container='list', yang_name=\"dscp-traffic-class\", rest_name=\"dscp-traffic-class\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure DSCP-to-Traffic-Class map', u'cli-no-key-completion': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'dscp_traffic_class', u'cli-mode-name': u'dscp-traffic-class-$(dscp-traffic-class-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__dscp_traffic_class = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_nport(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=nport.nport, is_container='container', presence=False, yang_name=\"nport\", rest_name=\"nport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Adds N port(s) to the PG'}}, namespace='urn:brocade.com:mgmt:brocade-ag', defining_module='brocade-ag', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"nport must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=nport.nport, is_container='container', presence=False, yang_name=\"nport\", rest_name=\"nport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Adds N port(s) to the PG'}}, namespace='urn:brocade.com:mgmt:brocade-ag', defining_module='brocade-ag', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__nport = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the nport property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the modes of the", "response": "def _set_modes(self, v, load=False):\n    \"\"\"\n    Setter method for modes, mapped from YANG variable /rbridge_id/ag/pg/modes (pg-policy-types)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_modes is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_modes() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=TypedListType(allowed_type=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..10']})), is_leaf=False, yang_name=\"modes\", rest_name=\"modes\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Adds mode(s) to the PG', u'cli-flat-list-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-ag', defining_module='brocade-ag', yang_type='pg-policy-types', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"modes must be of a type compatible with pg-policy-types\"\"\",\n          'defined-type': \"brocade-ag:pg-policy-types\",\n          'generated-type': \"\"\"YANGDynClass(base=TypedListType(allowed_type=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..10']})), is_leaf=False, yang_name=\"modes\", rest_name=\"modes\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Adds mode(s) to the PG', u'cli-flat-list-syntax': None}}, namespace='urn:brocade.com:mgmt:brocade-ag', defining_module='brocade-ag', yang_type='pg-policy-types', is_config=True)\"\"\",\n        })\n\n    self.__modes = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_service_policy(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"direction policy_map_name\",service_policy.service_policy, yang_name=\"service-policy\", rest_name=\"service-policy\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='direction policy-map-name', extensions={u'tailf-common': {u'info': u'Attach Input Policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'callpoint': u'global-service-policy', u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"service-policy\", rest_name=\"service-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Attach Input Policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'callpoint': u'global-service-policy', u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mqc', defining_module='brocade-qos-mqc', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"service_policy must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"direction policy_map_name\",service_policy.service_policy, yang_name=\"service-policy\", rest_name=\"service-policy\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='direction policy-map-name', extensions={u'tailf-common': {u'info': u'Attach Input Policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'callpoint': u'global-service-policy', u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"service-policy\", rest_name=\"service-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Attach Input Policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'callpoint': u'global-service-policy', u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mqc', defining_module='brocade-qos-mqc', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__service_policy = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the service policy for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun STAR-Fusion and filters fusion calls using FusionInspector :param tuple fastqs: RNA-Seq FASTQ Filestore IDs :param toil.fileStore.FileID junction_file: Chimeric junction file :param dict univ_options: universal arguments used by almost all tools :param dict star_fusion_options: STAR-Fusion specific parameters :return: Transgene BEDPE file :rtype: toil.fileStore.FileID", "response": "def run_fusion(job,\n               fastqs,\n               junction_file,\n               univ_options,\n               star_fusion_options,\n               fusion_inspector_options):\n    \"\"\"\n    Runs STAR-Fusion and filters fusion calls using FusionInspector\n\n    :param tuple fastqs: RNA-Seq FASTQ Filestore IDs\n    :param toil.fileStore.FileID junction_file: Chimeric junction file\n    :param dict univ_options: universal arguments used by almost all tools\n    :param dict star_fusion_options: STAR-Fusion specific parameters\n    :return: Transgene BEDPE file\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n\n    input_files = {'rna_1.fq.gz': fastqs[0],\n                   'rna_2.fq.gz': fastqs[1],\n                   'tool_index.tar.gz': star_fusion_options['index']}\n\n    parameters = []\n\n    # If there isn't a junction file, then we can run STAR-Fusion from the fastq files\n    if junction_file:\n        input_files['STAR.junction'] = junction_file\n        parameters.extend(['--chimeric_junction', '/data/STAR.junction'])\n\n    else:\n        parameters.extend(['--left_fq', '/data/rna_1.fq.gz', '--right_fq', '/data/rna_2.fq.gz'])\n\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    input_files['tool_index'] = os.path.basename(untargz(input_files['tool_index.tar.gz'],\n                                                         work_dir))\n\n    cores = star_fusion_options['n']\n    parameters.extend(['--output_dir', '/data/fusion-output',\n                       '--genome_lib_dir', input_files['tool_index'],\n                       '--CPU', str(cores)])\n\n    docker_call(tool='star-fusion',\n                tool_parameters=parameters,\n                work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'],\n                tool_version=star_fusion_options['version'])\n\n    star_output = 'fusion-output/star-fusion.fusion_candidates.final.abridged'\n    fusion_path = os.path.join(work_dir, star_output)\n\n    # Export the STAR-Fusion predictions\n    export_results(job,\n                   job.fileStore.writeGlobalFile(fusion_path),\n                   'star-fusion-predictions.tsv',\n                   univ_options, subfolder='mutations/fusions')\n\n    # Check for fusion prediction\n    with open(fusion_path, 'r') as f:\n        # Skip header\n        f.next()\n        try:\n            f.next()\n        except StopIteration:\n            logging.warning('%s: Did not find any fusions!' % univ_options['patient'])\n            return\n\n    parameters = ['--fusions', '/data/%s' % star_output,\n                  '--genome_lib', input_files['tool_index'],\n                  '--left_fq', '/data/rna_1.fq.gz',\n                  '--right_fq', '/data/rna_2.fq.gz',\n                  '--out_dir', '/data/FusionInspector',\n                  '--out_prefix', 'FusionInspector',\n                  '--CPU', str(cores)]\n\n    if fusion_inspector_options['run_trinity']:\n        parameters.append('--include_Trinity')\n\n    docker_call(tool='fusion-inspector',\n                tool_parameters=parameters,\n                work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'],\n                tool_version=fusion_inspector_options['version'])\n\n    found_fusion = False\n    inspector_output = 'FusionInspector/FusionInspector.fusion_predictions.final.abridged.FFPM'\n    fusion_path = os.path.join(work_dir, inspector_output)\n    output_path = os.path.join(work_dir, 'fusion.final')\n\n    # Export the FusionInpsector predictions\n    export_results(job,\n                   job.fileStore.writeGlobalFile(fusion_path),\n                   'fusion-inspector-predictions.tsv',\n                   univ_options, subfolder='mutations/fusions')\n\n    # Remove fusions without a large anchor sequence and at least 0.1\n    # fusion fragments per million reads\n    if os.path.exists(fusion_path):\n        with open(fusion_path, 'r') as f, open(output_path, 'w') as g:\n            g.write(f.next())\n            for line in f:\n                fields = line.strip().split()\n\n                # Check for a large anchor support\n                ldas = fields[10]\n\n                assert ldas in {'YES', 'NO'}, 'FusionInpsector file is malformed!'\n\n                j_ffpm, s_ffpm = fields[-2:]\n\n                # Fusions without a larger anchor support or low read support\n                # are suspicious and should not be consider for further analysis\n                if ldas == 'YES' and sum([float(j_ffpm), float(s_ffpm)]) > 0.1:\n                    found_fusion = True\n                    g.write(line)\n\n    if found_fusion:\n        fusion_bed_f = 'FusionInspector/FusionInspector.bed'\n        fusion_bed_path = os.path.join(work_dir, fusion_bed_f)\n        transcript_f = 'FusionInspector/FusionInspector.gmap_trinity_GG.fusions.fasta'\n        transcript_path = os.path.join(work_dir, transcript_f)\n        transcript_gff_f = 'FusionInspector/FusionInspector.gmap_trinity_GG.fusions.gff3'\n        transcript_gff_path = os.path.join(work_dir, transcript_gff_f)\n\n        transcripts = None\n        transcript_annotation = None\n\n        if os.path.exists(transcript_path):\n            transcripts = job.fileStore.writeGlobalFile(transcript_path)\n            export_results(job,\n                           transcripts,\n                           transcript_path,\n                           univ_options,\n                           subfolder='mutations/fusions')\n\n        if os.path.exists(transcript_gff_path):\n            transcript_annotation = job.fileStore.writeGlobalFile(transcript_gff_path)\n            export_results(job,\n                           transcript_annotation,\n                           transcript_gff_path,\n                           univ_options,\n                           subfolder='mutations/fusions')\n\n        fusion_annotation = job.fileStore.writeGlobalFile(fusion_bed_path)\n        filtered_fusions = job.fileStore.writeGlobalFile(output_path)\n\n        export_results(job,\n                       filtered_fusions,\n                       output_path,\n                       univ_options,\n                       subfolder='mutations/fusions')\n        job.fileStore.logToMaster('Ran STAR-Fusion on %s successfully' % univ_options['patient'])\n        return job.addChildJobFn(reformat_star_fusion_output,\n                                 fusion_annotation,\n                                 filtered_fusions,\n                                 transcripts,\n                                 transcript_annotation,\n                                 univ_options).rv()\n\n    else:\n        job.fileStore.logToMaster('No fusions detected for %s' % univ_options['patient'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_star_fusion(infile):\n    reader = csv.reader(infile, delimiter='\\t')\n    header = reader.next()\n    header = {key: index for index, key in enumerate(header)}\n\n    features = ['LeftGene', 'LeftLocalBreakpoint', 'LeftBreakpoint',\n                'RightGene', 'RightLocalBreakpoint', 'RightBreakpoint',\n                'LargeAnchorSupport', 'JunctionReadCount', 'SpanningFragCount']\n\n    for line in reader:\n        yield Expando(dict((feature, line[header[feature]]) for feature in features))", "response": "Parses STAR - Fusion prediction file and returns an Expando object with basic features and attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the FusionInspector transcript file and returns a dictionary of transcripts", "response": "def get_transcripts(transcript_file):\n    \"\"\"\n    Parses FusionInspector transcript file and returns dictionary of sequences\n\n    :param str transcript_file: path to transcript FASTA\n    :return: de novo assembled transcripts\n    :rtype: dict\n    \"\"\"\n    with open(transcript_file, 'r') as fa:\n        transcripts = {}\n        regex_s = r\"(?P<ID>TRINITY.*)\\s(?P<fusion>.*--.*):(?P<left_start>\\d+)-(?P<right_start>\\d+)\"\n        regex = re.compile(regex_s)\n        while True:\n            # Usually the transcript is on one line\n            try:\n                info = fa.next()\n                seq = fa.next()\n\n                assert info.startswith('>')\n\n                m = regex.search(info)\n                if m:\n                    transcripts[m.group('ID')] = seq.strip()\n\n            except StopIteration:\n                break\n\n            except AssertionError:\n                print(\"WARNING: Malformed fusion transcript file\")\n    return transcripts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_fusion_transcript(annotation_path, transcripts):\n    annotation = collections.defaultdict(dict)\n\n    forward = 'ACGTN'\n    reverse = 'TGCAN'\n    trans = string.maketrans(forward, reverse)\n\n    # Pull in assembled transcript annotation\n    five_pr_splits = collections.defaultdict(dict)\n    three_pr_splits = collections.defaultdict(dict)\n\n    regex = re.compile(r'ID=(?P<ID>.*);Name=(?P<Name>.*);Target=(?P<Target>.*)\\s(?P<start>\\d+)\\s(?P<stop>\\d+)')\n\n    with open(annotation_path, 'r') as gff:\n        for line in gff:\n            print(line)\n            if line.startswith('#'):\n                _, eyd, fusion = line.strip().split()\n                fusion, start_stop = fusion.split(':')\n                left_break, right_break = start_stop.split('-')\n\n                annotation[fusion][eyd] = {}\n                annotation[fusion][eyd]['left_break'] = left_break\n                annotation[fusion][eyd]['right_break'] = right_break\n\n            else:\n                line = line.strip().split('\\t')\n                fusion = line[0]\n                strand = line[6]\n                block_start = line[3]\n                block_stop = line[4]\n                attr = line[8]\n                m = regex.search(attr)\n                if m:\n                    transcript_id = m.group('Name')\n\n                    rb = any([block_start == annotation[fusion][transcript_id]['right_break'],\n                              block_stop == annotation[fusion][transcript_id]['right_break']])\n\n                    lb = any([block_start == annotation[fusion][transcript_id]['left_break'],\n                              block_stop == annotation[fusion][transcript_id]['left_break']])\n\n                    if strand == '-' and rb:\n                        transcript_split = int(m.group('stop')) + 1   # Off by one\n                        # Take the reverse complement to orient transcripts from 5' to 3'\n                        five_seq = transcripts[transcript_id][transcript_split:]\n                        five_pr_splits[fusion][transcript_id] = five_seq.translate(trans)[::-1]\n                        three_seq = transcripts[transcript_id][:transcript_split]\n                        three_pr_splits[fusion][transcript_id] = three_seq.translate(trans)[::-1]\n\n                    elif strand == '+' and lb:\n                        transcript_split = int(m.group('stop'))\n                        s1 = transcripts[transcript_id][:transcript_split]\n                        five_pr_splits[fusion][transcript_id] = s1\n                        s2 = transcripts[transcript_id][transcript_split:]\n                        three_pr_splits[fusion][transcript_id] = s2\n\n    return five_pr_splits, three_pr_splits", "response": "Reads the annotation file and splits the 5 donor sequences and 3 acceptor sequences"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_gene_ids(fusion_bed):\n    with open(fusion_bed, 'r') as f:\n        gene_to_id = {}\n        regex = re.compile(r'(?P<gene>ENSG\\d*)')\n        for line in f:\n            line = line.split('\\t')\n            transcript, gene_bit, name = line[3].split(';')\n            m = regex.search(gene_bit)\n            if m:\n                gene_to_id[name] = m.group('gene')\n    return gene_to_id", "response": "Parses the ENSEMBL gene ids from a FusionInspector bed file to ascertain the ENSEMBL gene ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reformat_star_fusion_output(job,\n                                fusion_annot,\n                                fusion_file,\n                                transcript_file,\n                                transcript_gff_file,\n                                univ_options):\n    \"\"\"\n    Writes STAR-Fusion results in Transgene BEDPE format\n\n    :param toil.fileStore.FileID fusion_annot: Fusion annotation\n    :param toil.fileStore.FileID fusion_file: STAR-fusion prediction file\n    :param toil.fileStore.FileID transcript_file: Fusion transcript FASTA file\n    :param toil.fileStore.FileID transcript_gff_file: Fusion transcript GFF file\n    :param dict univ_options: universal arguments used by almost all tools\n    :return: Transgene BEDPE file\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    input_files = {'results.tsv': fusion_file,\n                   'fusion.bed': fusion_annot}\n\n    if transcript_file and transcript_gff_file:\n        input_files['transcripts.fa'] = transcript_file\n        input_files['transcripts.gff'] = transcript_gff_file\n\n    work_dir = job.fileStore.getLocalTempDir()\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    # Pull in assembled transcript file\n    hugo_to_gene_ids = get_gene_ids(input_files['fusion.bed'])\n\n    if transcript_file and transcript_gff_file:\n        transcripts = get_transcripts(input_files['transcripts.fa'])\n        five_pr_splits, three_pr_splits = split_fusion_transcript(input_files['transcripts.gff'],\n                                                                  transcripts)\n\n    else:\n        five_pr_splits = collections.defaultdict(dict)\n        three_pr_splits = collections.defaultdict(dict)\n\n    # Pull in assembled transcript annotation\n\n    # Header for BEDPE file\n    header = ['# chr1', 'start1', 'end1',\n              'chr2', 'start2', 'end2',\n              'name', 'score',\n              'strand1', 'strand2',\n              'junctionSeq1', 'junctionSeq2',\n              'hugo1', 'hugo2']\n\n    output_path = os.path.join(work_dir, 'fusion_results.bedpe')\n    with open(input_files['results.tsv'], 'r') as in_f, open(output_path, 'w') as out_f:\n        writer = csv.writer(out_f, delimiter='\\t')\n        writer.writerow(header)\n        for record in parse_star_fusion(in_f):\n\n            left_chr, left_break, left_strand = record.LeftBreakpoint.split(':')\n\n            right_chr, right_break, right_strand = record.RightBreakpoint.split(':')\n\n            fusion = ''.join([record.LeftGene, '--', record.RightGene])\n            name = '-'.join([hugo_to_gene_ids[record.LeftGene], hugo_to_gene_ids[record.RightGene]])\n            score = 'Junction:%s-Spanning:%s' % (record.JunctionReadCount, record.SpanningFragCount)\n\n            # Add empty sequences in case Trinity doesn't output one\n            if len(five_pr_splits[fusion].keys()) == 0:\n                five_pr_splits[fusion]['N/A'] = '.'\n\n            if len(three_pr_splits[fusion].keys()) == 0:\n                three_pr_splits[fusion]['N/A'] = '.'\n\n            for transcript_id in five_pr_splits[fusion].keys():\n                five_prime_seq = five_pr_splits[fusion][transcript_id]\n                three_prime_seq = three_pr_splits[fusion][transcript_id]\n\n                writer.writerow([left_chr,\n                                 '.',  # Donor start position is not necessary\n                                 left_break,\n                                 right_chr,\n                                 right_break,\n                                 '.',  # Acceptor end position is not necessary\n                                 name,\n                                 score,\n                                 left_strand,\n                                 right_strand,\n                                 five_prime_seq,\n                                 three_prime_seq,\n                                 record.LeftGene,\n                                 record.RightGene])\n\n    bedpe_id = job.fileStore.writeGlobalFile(output_path)\n    export_results(job, bedpe_id, 'fusion.bedpe', univ_options, subfolder='mutations/fusions')\n    job.fileStore.logToMaster('Reformatted STAR-Fusion output for %s successfully'\n                              % univ_options['patient'])\n    return bedpe_id", "response": "This function reformats the STAR - Fusion output into a Transgene BEDPE file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_association(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=association.association, is_container='container', presence=False, yang_name=\"association\", rest_name=\"association\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'trunk-association', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_PVLAN_ASSOCIATION'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"association must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=association.association, is_container='container', presence=False, yang_name=\"association\", rest_name=\"association\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'trunk-association', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_PVLAN_ASSOCIATION'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__association = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set association for the private\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the mapping of the private vrf.", "response": "def _set_mapping(self, v, load=False):\n    \"\"\"\n    Setter method for mapping, mapped from YANG variable /interface/port_channel/switchport/private_vlan/mapping (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mapping is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mapping() directly.\n\n    YANG Description: Promiscuous mapping\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"promis_pri_pvlan\",mapping.mapping, yang_name=\"mapping\", rest_name=\"mapping\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='promis-pri-pvlan', extensions={u'tailf-common': {u'info': u'Promiscuous Mapping', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'pvlanMappingCallPointWorker_po'}}), is_container='list', yang_name=\"mapping\", rest_name=\"mapping\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Promiscuous Mapping', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'pvlanMappingCallPointWorker_po'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mapping must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"promis_pri_pvlan\",mapping.mapping, yang_name=\"mapping\", rest_name=\"mapping\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='promis-pri-pvlan', extensions={u'tailf-common': {u'info': u'Promiscuous Mapping', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'pvlanMappingCallPointWorker_po'}}), is_container='list', yang_name=\"mapping\", rest_name=\"mapping\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Promiscuous Mapping', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'pvlanMappingCallPointWorker_po'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mapping = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ensure_set_contains(test_object, required_object, test_set_name=None):\n    assert isinstance(test_object, (set, dict)), '%s,%s' % (test_object, test_set_name)\n    assert isinstance(required_object, (set, dict)), '%s,%s' % (required_object, test_set_name)\n    # set(dict) = set of keys of the dict\n    test_set = set(test_object)\n    required_set = set(required_object)\n    set_name = ' ' if test_set_name is None else ' entry \"%s\" of ' % test_set_name\n    missing_opts = required_set.difference(test_set)\n    if len(missing_opts) > 0:\n        raise ParameterError('The following entries are missing in%sthe config file:\\n%s'\n                             % (set_name, '\\n'.join(missing_opts)))", "response": "Ensures that the required entries of a dict are present in the set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that the provided entries for the patient group are valid.", "response": "def _ensure_patient_group_is_ok(patient_object, patient_name=None):\n    \"\"\"\n    Ensure that the provided entries for the patient groups is formatted properly.\n\n    :param set|dict patient_object: The values passed to the samples patient group\n    :param str patient_name: Optional name for the set\n    :raises ParameterError: If required entry doesnt exist\n    \"\"\"\n    from protect.addons.common import TCGAToGTEx\n    assert isinstance(patient_object, (set, dict)), '%s,%s' % (patient_object, patient_name)\n    # set(dict) = set of keys of the dict\n    test_set = set(patient_object)\n    if 'tumor_type' not in patient_object:\n        raise ParameterError(('The patient entry for sample %s ' % patient_name) +\n                             'does not contain a Tumor type.')\n    elif patient_object['tumor_type'] not in TCGAToGTEx:\n        raise ParameterError(('The patient entry for sample %s ' % patient_name) +\n                             'does contains an invalid Tumor type. Please use one of the '\n                             'valid TCGA tumor types.')\n    if {'tumor_dna_fastq_1', 'normal_dna_fastq_1', 'tumor_rna_fastq_1'}.issubset(test_set):\n        # Best case scenario, we get all fastqs\n        pass\n    else:\n        # We have less than 3 fastqs so we have to have a haplotype.\n        if 'hla_haplotype_files' not in test_set:\n            raise ParameterError(('The patient entry for sample %s ' % patient_name) +\n                                 'does not contain a hla_haplotype_files entry.\\nCannot haplotype '\n                                 'patient if all the input sequence files are not fastqs.')\n        # Either we have a fastq and/or bam for the tumor and normal, or we need to be given a vcf\n        if (({re.search('tumor_dna_((bam)|(fastq_1)).*', x) for x in test_set} == {None} or\n                {re.search('normal_dna_((bam)|(fastq_1)).*', x) for x in test_set} == {None}) and\n                ('mutation_vcf' not in test_set and 'fusion_bedpe' not in test_set)):\n            raise ParameterError(('The patient entry for sample %s ' % patient_name) +\n                                 'does not contain a mutation_vcf or fusion_bedpe entry. If both '\n                                 'tumor and normal DNA sequences (fastqs or bam) are not provided, '\n                                 'a pre-computed vcf and/or bedpe must be provided.')\n        # We have to be given a tumor rna fastq or bam unless we are processing ONLY fusions\n        if {re.search('tumor_rna_((bam)|(fastq_1)).*', x) for x in test_set} == {None}:\n            if 'mutation_vcf' not in test_set and 'fusion_bedpe' in test_set:\n                # The only case where it is ok to not have the genome mapped rna.\n                pass\n            else:\n                raise ParameterError(('The patient entry for sample %s ' % patient_name) +\n                                     'does not contain a tumor rna sequence data entry. We require '\n                                     'either tumor_rna_fastq_1 or tumor_rna_bam.')\n        # If we are given an RNA bam then it needs to have a corresponding transcriptome bam unless\n        # we have also been provided expression values.\n        if 'tumor_rna_bam' in test_set and 'tumor_rna_transcriptome_bam' not in test_set:\n            if 'expression_files' not in test_set:\n                raise ParameterError(('The patient entry for sample %s ' % patient_name +\n                                      'was provided a tumor rna bam with sequences mapped to the '\n                                      'genome but was not provided a matching rna bam for the '\n                                      'transcriptome or a tar containing expression values. '\n                                      'We require either a matching transcriptome bam to estimate'\n                                      'expression, or the precomputed expression values.'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_default_entries(input_dict, defaults_dict):\n    for key, value in defaults_dict.iteritems():\n        if key == 'patients':\n            print('Cannot default `patients`.')\n            continue\n        if isinstance(value, dict):\n            if key not in input_dict or input_dict[key] is None:\n                # User didn't specify anython for the tool, but the entry was still in there so we\n                # just copy over the whole defaults dict\n                input_dict[key] = value\n            else:\n                r = _add_default_entries(input_dict.get(key, {}), value)\n                input_dict[key] = r\n        else:\n            # Only write if not in input_dict\n            if key not in input_dict or input_dict[key] is None:\n                # Either the user didn't have the entry, or had it without a value\n                input_dict[key] = value\n    return input_dict", "response": "Adds the entries in defaults dict into input_dict if they don t exist in input_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_group(input_group, required_group, groupname, append_subgroups=None):\n    if append_subgroups is None:\n        append_subgroups = []\n    tool_options = {}\n    for key in input_group:\n        _ensure_set_contains(input_group[key], required_group.get(key, {}), groupname + '::' + key)\n        if key in append_subgroups:\n            continue\n        else:\n            tool_options[key] = input_group[key]\n    for key in input_group:\n        if key in append_subgroups:\n            continue\n        else:\n            for yek in append_subgroups:\n                tool_options[key].update(input_group[yek])\n    return tool_options", "response": "Process one group from the input yaml."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_fastq_2(job, patient_id, sample_type, fastq_1):\n    prefix, extn = fastq_1, 'temp'\n    final_extn = ''\n    while extn:\n        prefix, extn = os.path.splitext(prefix)\n        final_extn = extn + final_extn\n        if prefix.endswith('1'):\n            prefix = prefix[:-1]\n            job.fileStore.logToMaster('\"%s\" prefix for \"%s\" determined to be %s'\n                                      % (sample_type, patient_id, prefix))\n            break\n    else:\n        raise ParameterError('Could not determine prefix from provided fastq (%s). Is it '\n                             'of the form <fastq_prefix>1.[fq/fastq][.gz]?' % fastq_1)\n    if final_extn not in ['.fastq', '.fastq.gz', '.fq', '.fq.gz']:\n        raise ParameterError('If and _2 fastq path is not specified, only .fastq, .fq or '\n                             'their gzippped extensions are accepted. Could not process '\n                             '%s:%s.' % (patient_id, sample_type + '_fastq_1'))\n    return ''.join([prefix, '2', final_extn])", "response": "Returns a path to a fastq_2 file with the same prefix and naming scheme."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_patients(job, patient_dict, skip_fusions=False):\n    output_dict = {'ssec_encrypted': patient_dict.get('ssec_encrypted') in (True, 'True', 'true'),\n                   'patient_id': patient_dict['patient_id'],\n                   'tumor_type': patient_dict['tumor_type'],\n                   'filter_for_OxoG': patient_dict.get('filter_for_OxoG') in (True, 'True', 'true')}\n    out_keys = set()\n\n    if 'hla_haplotype_files' not in patient_dict:\n        # If we don't have the haplotype, we necessarily need all the fastqs\n        for stype in 'tumor_dna', 'normal_dna', 'tumor_rna':\n            out_keys.update([x for x in patient_dict if x.startswith(stype + '_fastq')])\n    else:\n        out_keys.add('hla_haplotype_files')\n\n    if 'mutation_vcf' in patient_dict:\n        out_keys.add('mutation_vcf')\n        # We either need a genome mapped RNA bam or fastqs for this to work\n        if 'tumor_rna_bam' in patient_dict:\n            out_keys.add('tumor_rna_bam')\n            if 'tumor_rna_bai' in patient_dict:\n                out_keys.add('tumor_rna_bai')\n        else:\n            out_keys.update([x for x in patient_dict if x.startswith('tumor_rna_fastq')])\n    else:\n        if 'fusion_bedpe' not in patient_dict:\n            # We are not looking at just fusions so we either need 3 bams/fastqs to run ProTECT\n            for stype in 'tumor_dna', 'normal_dna', 'tumor_rna':\n                if stype + '_bam' in patient_dict:\n                    out_keys.add(stype + '_bam')\n                else:\n                    out_keys.update([x for x in patient_dict if x.startswith(stype + '_fastq')])\n\n    if 'expression_files' in patient_dict:\n        out_keys.add('expression_files')\n    else:\n        # We need the transcriptome mapped RNA bam or fastqs\n        if 'tumor_rna_transcriptome_bam' in patient_dict:\n            out_keys.add('tumor_rna_transcriptome_bam')\n        else:\n            out_keys.update([x for x in patient_dict if x.startswith('tumor_rna_fastq')])\n\n    if 'fusion_bedpe' in patient_dict:\n        out_keys.add('fusion_bedpe')\n\n    for key in out_keys:\n        output_dict[key] = patient_dict[key]\n    fastq1s = [x for x in output_dict if x.endswith('fastq_1')]\n    for f in fastq1s:\n        f = f[:-8]\n        if f + '_fastq_2' not in output_dict:\n            output_dict[f + '_fastq_2'] = get_fastq_2(job, patient_dict['patient_id'], f,\n                                                      output_dict[f + '_fastq_1'])\n    output_dict['gdc_inputs'] = [k for k, v in output_dict.items() if str(v).startswith('gdc')]\n    if not any('dna' in k for k in output_dict.keys()):\n        # There are no input DNA files so we cannot filter for oxog\n        output_dict['filter_for_OxoG'] = False\n    return output_dict", "response": "Parse a dictionary of patient entries to retain only the useful entries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_config_file(job, config_file, max_cores=None):\n    job.fileStore.logToMaster('Parsing config file')\n    config_file = os.path.abspath(config_file)\n    if not os.path.exists(config_file):\n        raise ParameterError('The config file was not found at specified location. Please verify ' +\n                             'and retry.')\n    # Initialize variables to hold the sample sets, the universal options, and the per-tool options\n    sample_set = {}\n    univ_options = {}\n    tool_options = {}\n\n    # Read in the input yaml\n    with open(config_file, 'r') as conf:\n        input_config = yaml.load(conf.read())\n\n    # Read the set of all required keys\n    required_entries_file = pkg_resources.resource_filename(__name__, \"required_entries.yaml\")\n    with open(required_entries_file) as ref:\n        required_keys = yaml.load(ref.read())\n\n    # Ensure every required entry is present in the file\n    all_keys = set(input_config.keys())\n    _ensure_set_contains(all_keys, required_keys)\n\n    # Now that we are sure that mutation_callers is an entry in the file we can initialise this\n    mutation_caller_list = []\n\n    # Get the default values from the defaults file\n    protect_defaults_file = pkg_resources.resource_filename(__name__, \"defaults.yaml\")\n    with open(protect_defaults_file) as pdf:\n        protect_defaults = yaml.load(pdf.read())\n\n    # Update the input yaml with defaults\n    input_config = _add_default_entries(input_config, protect_defaults)\n\n    # Flags to check for presence of encryption keys if required\n    gdc_inputs = ssec_encrypted = False\n    for key in input_config.keys():\n        if key == 'patients':\n            # Ensure each patient contains the required entries\n            for sample_name in input_config[key]:\n                patient_keys = input_config[key][sample_name]\n                _ensure_patient_group_is_ok(patient_keys, sample_name)\n                # Add options to the sample_set dictionary\n                input_config['patients'][sample_name]['patient_id'] = str(sample_name)\n                sample_set[sample_name] = parse_patients(\n                    job, input_config['patients'][sample_name],\n                    not input_config['mutation_calling']['star_fusion']['run'])\n                # If any of the samples requires gdc or ssec encrypted input, make the flag True\n                if sample_set[sample_name]['ssec_encrypted']:\n                    ssec_encrypted = True\n                if sample_set[sample_name]['gdc_inputs']:\n                    if 'tumor_rna_bam' in sample_set[sample_name]['gdc_inputs']:\n                        raise ParameterError('Cannot run ProTECT using GDC RNA bams. Please fix '\n                                             'sample %s' % sample_name)\n                    gdc_inputs = True\n        else:\n            # Ensure the required entries exist for this key\n            _ensure_set_contains(input_config[key], required_keys[key], key)\n            if key == 'Universal_Options':\n                univ_options.update(input_config['Universal_Options'])\n                if univ_options['reference_build'].lower() in ['hg19', 'grch37']:\n                    univ_options['ref'] = 'hg19'\n                elif univ_options['reference_build'].lower() in ['hg38', 'grch38']:\n                    univ_options['ref'] = 'hg38'\n                else:\n                    raise ParameterError('reference_build can only be hg19, hg38, GRCh37 or GRCh38')\n                assert univ_options['storage_location'].startswith(('Local', 'local', 'aws'))\n                if univ_options['storage_location'] in ('Local', 'local'):\n                    assert os.path.isabs(univ_options['output_folder']), ('Needs to be absolute if '\n                                                                          'storage_location is '\n                                                                          'Local.')\n                    assert univ_options['output_folder'] != 'NA', ('Cannot have NA as output '\n                                                                   'folder if storage location is '\n                                                                   'Local.')\n                    univ_options['storage_location'] = 'local'\n                if univ_options['storage_location'].startswith('aws'):\n                    if 'sse_key' not in univ_options:\n                        raise ParameterError('Cannot write results to aws without an sse key.')\n                    if 'sse_key_is_master' in univ_options:\n                        if univ_options['sse_key_is_master'] not in (True, False):\n                            raise ParameterError('sse_key_is_master must be True or False')\n                    else:\n                        univ_options['sse_key_is_master'] = False\n                univ_options['max_cores'] = cpu_count() if max_cores is None else max_cores\n            else:\n                if key == 'reports':\n                    # The reporting group doesn't have any sub-dicts\n                    tool_options[key] = input_config[key]\n                else:\n                    if key == 'alignment':\n                        append_subgroup = ['post']\n                    elif key == 'mutation_calling':\n                        mutation_caller_list = input_config[key].keys()\n                        append_subgroup = []\n                    else:\n                        append_subgroup = []\n                    tool_options.update(_process_group(input_config[key], required_keys[key],\n                                                       key, append_subgroup))\n    # netmhciipan needs to be handled separately\n    tool_options['mhcii']['netmhciipan'] = tool_options['netmhciipan']\n    tool_options.pop('netmhciipan')\n    # Check for encryption related issues before we download files.\n    if ssec_encrypted:\n        assert univ_options['sse_key'] is not None, 'Cannot read ssec encrypted data without a key.'\n    if gdc_inputs:\n        assert univ_options['gdc_download_token'] is not None, ('Cannot read from GDC without a '\n                                                                'token.')\n    # Get all the tool inputs\n    job.fileStore.logToMaster('Obtaining tool inputs')\n    process_tool_inputs = job.addChildJobFn(get_all_tool_inputs, tool_options,\n                                            mutation_caller_list=mutation_caller_list)\n    job.fileStore.logToMaster('Obtained tool inputs')\n    return sample_set, univ_options, process_tool_inputs.rv()", "response": "Parse the input yaml config file and download all tool inputs into the file store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_config_file(job, config_file, max_cores=None):\n    sample_set, univ_options, processed_tool_inputs = _parse_config_file(job, config_file,\n                                                                         max_cores)\n    # Start a job for each sample in the sample set\n    for patient_id in sample_set.keys():\n        job.addFollowOnJobFn(launch_protect, sample_set[patient_id], univ_options,\n                             processed_tool_inputs)\n    return None", "response": "Parse the config file and spawn a ProTECT job for every input sample."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nascertain the number of cores allowed for each high - compte job instance.", "response": "def ascertain_cpu_share(max_cores=None):\n    \"\"\"\n    Ascertain the number of cpus allowed for each high-compte job instance (bwa, star, rsem, phlat).\n\n    :param max_cores: The user-specified max\n    :return: The number of cpus allowed for each high-compte job instance\n    :rtype: int\n    \"\"\"\n    # Ascertain the number of available CPUs. Jobs will be given fractions of this value.\n    num_cores = cpu_count()\n    # The minimum number of cpus should be at least 6 if possible\n    min_cores = min(num_cores, 6)\n    cpu_share = max(num_cores / 2, min_cores)\n    if max_cores is not None:\n        cpu_share = min(cpu_share, max_cores)\n    return cpu_share"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_tool_inputs(job, tools, outer_key='', mutation_caller_list=None):\n    for tool in tools:\n        for option in tools[tool]:\n            if isinstance(tools[tool][option], dict):\n                tools[tool][option] = get_all_tool_inputs(\n                    job, {option: tools[tool][option]},\n                    outer_key=':'.join([outer_key, tool]).lstrip(':'))[option]\n            else:\n                # If a file is of the type file, vcf, tar or fasta, it needs to be downloaded from\n                # S3 if reqd, then written to job store.\n                if option.split('_')[-1] in ['file', 'vcf', 'index', 'fasta', 'fai', 'idx', 'dict',\n                                             'tbi', 'beds', 'gtf', 'config']:\n                    tools[tool][option] = job.addChildJobFn(\n                        get_pipeline_inputs, ':'.join([outer_key, tool, option]).lstrip(':'),\n                        tools[tool][option]).rv()\n                elif option == 'version':\n                    tools[tool][option] = str(tools[tool][option])\n    if mutation_caller_list is not None:\n        # Guaranteed to occur only in the outermost loop\n        indexes = tools.pop('indexes')\n        indexes['chromosomes'] = parse_chromosome_string(job, indexes['chromosomes'])\n        for mutation_caller in mutation_caller_list:\n            if mutation_caller == 'indexes':\n                continue\n            tools[mutation_caller].update(indexes)\n    return tools", "response": "This function recursively walks through all the tools and returns a dict of all the tools that need to be downloaded from the remote locations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the input file from s3 or disk and write to file store.", "response": "def get_pipeline_inputs(job, input_flag, input_file, encryption_key=None, per_file_encryption=False,\n                        gdc_download_token=None):\n    \"\"\"\n    Get the input file from s3 or disk and write to file store.\n\n    :param str input_flag: The name of the flag\n    :param str input_file: The value passed in the config file\n    :param str encryption_key: Path to the encryption key if encrypted with sse-c\n    :param bool per_file_encryption: If encrypted, was the file encrypted using the per-file method?\n    :param str gdc_download_token: The download token to obtain files from the GDC\n    :return: fsID for the file\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    job.fileStore.logToMaster('Obtaining file (%s) to the file job store' % input_flag)\n    if input_file.startswith(('http', 'https', 'ftp')):\n        input_file = get_file_from_url(job, input_file, encryption_key=encryption_key,\n                                       per_file_encryption=per_file_encryption,\n                                       write_to_jobstore=True)\n    elif input_file.startswith(('S3', 's3')):\n        input_file = get_file_from_s3(job, input_file, encryption_key=encryption_key,\n                                      per_file_encryption=per_file_encryption,\n                                      write_to_jobstore=True)\n    elif input_file.startswith(('GDC', 'gdc')):\n        input_file = get_file_from_gdc(job, input_file, gdc_download_token=gdc_download_token,\n                                       write_to_jobstore=True)\n    else:\n        assert os.path.exists(input_file), 'Bogus Input : ' + input_file\n        input_file = job.fileStore.writeGlobalFile(input_file)\n    return input_file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nobtain the input files for the patient and write them to the file store. :param dict patient_dict: The input fastq dict patient_dict: |- 'tumor_dna_fastq_[12]' OR 'tumor_dna_bam': str |- 'tumor_rna_fastq_[12]' OR 'tumor_rna_bam': str |- 'normal_dna_fastq_[12]' OR 'normal_dna_bam': str |- 'mutation_vcf': str |- 'hla_haplotype_files': str +- 'patient_id': str :param dict univ_options: Dict of universal options used by almost all tools :return: Updated fastq dict output_dict: |- 'tumor_dna_fastq_[12]' OR 'tumor_dna_bam': fsID |- 'tumor_rna_fastq_[12]' OR 'tumor_rna_bam': fsID |- 'normal_dna_fastq_[12]' OR 'normal_dna_bam': fsID |- 'mutation_vcf': fsID |- 'hla_haplotype_files': fsId +- 'patient_id': str :rtype: dict", "response": "def prepare_samples(job, patient_dict, univ_options):\n    \"\"\"\n    Obtain the input files for the patient and write them to the file store.\n\n    :param dict patient_dict: The input fastq dict\n           patient_dict:\n               |- 'tumor_dna_fastq_[12]' OR 'tumor_dna_bam': str\n               |- 'tumor_rna_fastq_[12]' OR 'tumor_rna_bam': str\n               |- 'normal_dna_fastq_[12]' OR 'normal_dna_bam': str\n               |- 'mutation_vcf': str\n               |- 'hla_haplotype_files': str\n               +- 'patient_id': str\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :return: Updated fastq dict\n             output_dict:\n                 |- 'tumor_dna_fastq_[12]' OR 'tumor_dna_bam': fsID\n                 |- 'tumor_rna_fastq_[12]' OR 'tumor_rna_bam': fsID\n                 |- 'normal_dna_fastq_[12]' OR 'normal_dna_bam': fsID\n                 |- 'mutation_vcf': fsID\n                 |- 'hla_haplotype_files': fsId\n                 +- 'patient_id': str\n    :rtype: dict\n    \"\"\"\n    job.fileStore.logToMaster('Downloading Inputs for %s' % univ_options['patient'])\n    # For each sample type, check if the prefix is an S3 link or a regular file\n    # Download S3 files.\n    output_dict = {}\n    for input_file in patient_dict:\n        if not input_file.endswith(('bam', 'bai', '_1', '_2', 'files', 'vcf', 'bedpe')):\n            output_dict[input_file] = patient_dict[input_file]\n            continue\n        output_dict[input_file] = get_pipeline_inputs(\n            job, ':'.join([univ_options['patient'], input_file]), patient_dict[input_file],\n            encryption_key=(univ_options['sse_key'] if patient_dict['ssec_encrypted'] else None),\n            per_file_encryption=univ_options['sse_key_is_master'],\n            gdc_download_token=univ_options['gdc_download_token'])\n    return output_dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_patient_bams(job, patient_dict, sample_type, univ_options, bwa_options, mutect_options):\n    output_dict = {}\n    if 'dna' in sample_type:\n        sample_info = 'fix_pg_sorted'\n        prefix = sample_type + '_' + sample_info\n    else:\n        sample_info = 'genome_sorted'\n        prefix = 'rna_' + sample_info\n    if sample_type + '_bam' in patient_dict['gdc_inputs']:\n        output_dict[prefix + '.bam'] = patient_dict[sample_type + '_bam'][0]\n        output_dict[prefix + '.bam.bai'] = patient_dict[sample_type + '_bam'][1]\n    elif sample_type + '_bai' in patient_dict:\n        output_dict[prefix + '.bam'] = patient_dict[sample_type + '_bam']\n        output_dict[prefix + '.bam.bai'] = patient_dict[sample_type + '_bai']\n    else:\n        from protect.alignment.dna import index_bamfile, index_disk\n        output_job = job.wrapJobFn(index_bamfile, patient_dict[sample_type + '_bam'],\n                                   'rna' if sample_type == 'tumor_rna' else sample_type,\n                                   univ_options, bwa_options['samtools'],\n                                   sample_info=sample_info, export=False,\n                                   disk=PromisedRequirement(index_disk,\n                                                            patient_dict[sample_type + '_bam']))\n        job.addChild(output_job)\n        output_dict = output_job.rv()\n    if sample_type == 'tumor_rna':\n        if 'tumor_rna_transcriptome_bam' not in patient_dict:\n            patient_dict['tumor_rna_transcriptome_bam'] = None\n        return{'rna_genome': output_dict,\n               'rna_transcriptome.bam': patient_dict['tumor_rna_transcriptome_bam']}\n    else:\n        return output_dict", "response": "This function returns the bam and bai for a particular sample type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_patient_expression(job, patient_dict):\n    expression_archive = job.fileStore.readGlobalFile(patient_dict['expression_files'])\n    expression_archive = untargz(expression_archive, os.getcwd())\n    output_dict = {}\n    for filename in 'rsem.genes.results', 'rsem.isoforms.results':\n        output_dict[filename] = job.fileStore.writeGlobalFile(os.path.join(expression_archive,\n                                                                           filename))\n    return output_dict", "response": "This function returns the expression from the patient dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a config file for a single node of the hg19 project", "response": "def generate_config_file():\n    \"\"\"\n    Generate a config file for a ProTECT run on hg19.\n\n    :return: None\n    \"\"\"\n    shutil.copy(os.path.join(os.path.dirname(__file__), 'input_parameters.yaml'),\n                os.path.join(os.getcwd(), 'ProTECT_config.yaml'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the object in the tree of unseen items.", "response": "def _set_stp(self, v, load=False):\n    \"\"\"\n    Setter method for stp, mapped from YANG variable /brocade_xstp_ext_rpc/get_stp_brief_info/output/spanning_tree_info/stp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_stp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_stp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=stp.stp, is_container='container', presence=False, yang_name=\"stp\", rest_name=\"stp\", parent=self, choice=(u'spanning-tree-mode', u'stp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-xstp-ext', defining_module='brocade-xstp-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"stp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=stp.stp, is_container='container', presence=False, yang_name=\"stp\", rest_name=\"stp\", parent=self, choice=(u'spanning-tree-mode', u'stp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-xstp-ext', defining_module='brocade-xstp-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__stp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the rstp variable for the internal list of random tree elements.", "response": "def _set_rstp(self, v, load=False):\n    \"\"\"\n    Setter method for rstp, mapped from YANG variable /brocade_xstp_ext_rpc/get_stp_brief_info/output/spanning_tree_info/rstp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_rstp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_rstp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=rstp.rstp, is_container='container', presence=False, yang_name=\"rstp\", rest_name=\"rstp\", parent=self, choice=(u'spanning-tree-mode', u'rstp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-xstp-ext', defining_module='brocade-xstp-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rstp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=rstp.rstp, is_container='container', presence=False, yang_name=\"rstp\", rest_name=\"rstp\", parent=self, choice=(u'spanning-tree-mode', u'rstp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-xstp-ext', defining_module='brocade-xstp-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__rstp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the base MSTP element.", "response": "def _set_mstp(self, v, load=False):\n    \"\"\"\n    Setter method for mstp, mapped from YANG variable /brocade_xstp_ext_rpc/get_stp_brief_info/output/spanning_tree_info/mstp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mstp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mstp() directly.\n\n    YANG Description: CIST information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mstp.mstp, is_container='container', presence=False, yang_name=\"mstp\", rest_name=\"mstp\", parent=self, choice=(u'spanning-tree-mode', u'mstp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-xstp-ext', defining_module='brocade-xstp-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mstp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mstp.mstp, is_container='container', presence=False, yang_name=\"mstp\", rest_name=\"mstp\", parent=self, choice=(u'spanning-tree-mode', u'mstp'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions=None, namespace='urn:brocade.com:mgmt:brocade-xstp-ext', defining_module='brocade-xstp-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mstp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_template(bot_or_project, name, target=None, **options):\n    bot_or_project = bot_or_project\n    paths_to_remove = []\n    verbosity = int(options['verbosity'])\n\n    validate_name(name, bot_or_project)\n\n    # if some directory is given, make sure it's nicely expanded\n    if target is None:\n        top_dir = path.join(os.getcwd(), name)\n        try:\n            os.makedirs(top_dir)\n        except FileExistsError:\n            raise click.ClickException(\"'%s' already exists\" % top_dir)\n        except OSError as e:\n            raise click.ClickException(e)\n    else:\n        top_dir = os.path.abspath(path.expanduser(target))\n        if not os.path.exists(top_dir):\n            raise click.ClickException(\"Destination directory '%s' does not \"\n                                       \"exist, please create it first.\" % top_dir)\n\n    base_name = '%s_name' % bot_or_project\n    base_subdir = '%s_template' % bot_or_project\n    base_directory = '%s_directory' % bot_or_project\n    target_name = '%s_target' % bot_or_project\n    pascal_case_name = 'pascal_case_%s_name' % bot_or_project\n    pascal_case_value = stringcase.pascalcase(name)\n    snake_case_name = 'snake_case_%s_name' % bot_or_project\n    snake_case_value = stringcase.snakecase(name)\n\n    context = {\n        **options,\n        base_name: name,\n        base_directory: top_dir,\n        target_name: target,\n        pascal_case_name: pascal_case_value,\n        snake_case_name: snake_case_value,\n        'settings_files': defaults.SETTINGS,\n        'version': getattr(trading_bots.__version__, '__version__'),\n    }\n\n    # Setup a stub settings environment for template rendering\n    settings.configure()\n    trading_bots.setup()\n\n    template_dir = path.join(trading_bots.__path__[0], 'conf', base_subdir)\n    prefix_length = len(template_dir) + 1\n\n    for root, dirs, files in os.walk(template_dir):\n\n        path_rest = root[prefix_length:]\n        relative_dir = path_rest.replace(snake_case_name, snake_case_value)\n        if relative_dir:\n            target_dir = path.join(top_dir, relative_dir)\n            if not path.exists(target_dir):\n                os.mkdir(target_dir)\n\n        for dirname in dirs[:]:\n            if dirname.startswith('.') or dirname == '__pycache__':\n                dirs.remove(dirname)\n\n        for filename in files:\n            if filename.endswith(('.pyo', '.pyc', '.py.class')):\n                # Ignore some files as they cause various breakages.\n                continue\n            old_path = path.join(root, filename)\n            new_path = path.join(top_dir, relative_dir,\n                                 filename.replace(snake_case_name, snake_case_value))\n            for old_suffix, new_suffix in rewrite_template_suffixes:\n                if new_path.endswith(old_suffix):\n                    new_path = new_path[:-len(old_suffix)] + new_suffix\n                    break  # Only rewrite once\n\n            if path.exists(new_path):\n                raise click.ClickException(\"%s already exists, overlaying a \"\n                                           \"project or bot into an existing \"\n                                           \"directory won't replace conflicting \"\n                                           \"files\" % new_path)\n\n            # Only render the Python files, as we don't want to\n            # accidentally render Trading-Bots templates files\n            if new_path.endswith(extensions):\n                with open(old_path, 'r', encoding='utf-8') as template_file:\n                    content = template_file.read()\n                template = Template(content, keep_trailing_newline=True)\n                content = template.render(**context)\n                with open(new_path, 'w', encoding='utf-8') as new_file:\n                    new_file.write(content)\n            else:\n                shutil.copyfile(old_path, new_path)\n\n            if verbosity >= 2:\n                click.echo(\"Creating %s\\n\" % new_path)\n            try:\n                shutil.copymode(old_path, new_path)\n                make_writeable(new_path)\n            except OSError:\n                click.echo(\n                    \"Notice: Couldn't set permission bits on %s. You're \"\n                    \"probably using an uncommon filesystem setup. No \"\n                    \"problem.\" % new_path)\n\n    if paths_to_remove:\n        if verbosity >= 2:\n            click.echo(\"Cleaning up temporary files.\\n\")\n        for path_to_remove in paths_to_remove:\n            if path.isfile(path_to_remove):\n                os.remove(path_to_remove)\n            else:\n                shutil.rmtree(path_to_remove)", "response": "Copy a bot or project layout template into a specified directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake sure that the file is writeable.", "response": "def make_writeable(filename):\n    \"\"\"\n    Make sure that the file is writeable.\n    Useful if our source is read-only.\n    \"\"\"\n    if not os.access(filename, os.W_OK):\n        st = os.stat(filename)\n        new_permissions = stat.S_IMODE(st.st_mode) | stat.S_IWUSR\n        os.chmod(filename, new_permissions)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_fcoe_fabric_mode(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'local|remote', 'length': [u'1..32']}), is_leaf=True, yang_name=\"fcoe-fabric-mode\", rest_name=\"san-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Configure the san mode', u'alt-name': u'san-mode', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='fcoe-fabric-mode-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe_fabric_mode must be of a type compatible with fcoe-fabric-mode-type\"\"\",\n          'defined-type': \"brocade-fcoe:fcoe-fabric-mode-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'local|remote', 'length': [u'1..32']}), is_leaf=True, yang_name=\"fcoe-fabric-mode\", rest_name=\"san-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Configure the san mode', u'alt-name': u'san-mode', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='fcoe-fabric-mode-type', is_config=True)\"\"\",\n        })\n\n    self.__fcoe_fabric_mode = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the mode of the non - local or remote fabrics."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the FCF map for the current FCF group.", "response": "def _set_fcoe_fcf_map(self, v, load=False):\n    \"\"\"\n    Setter method for fcoe_fcf_map, mapped from YANG variable /fcoe/fcoe_fabric_map/fcoe_fcf_map (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fcoe_fcf_map is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fcoe_fcf_map() directly.\n\n    YANG Description: The list of FCF Groups. Each row contains the FCF group\nname, member FCoE map, FCF rbid and FDF rbids\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"fcf_map_name\",fcoe_fcf_map.fcoe_fcf_map, yang_name=\"fcoe-fcf-map\", rest_name=\"fcf-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='fcf-map-name', extensions={u'tailf-common': {u'callpoint': u'fcf_map_cp', u'cli-suppress-list-no': None, u'alt-name': u'fcf-group', u'info': u'Configure an FCF Group', u'cli-mode-name': u'config-fabric-map-fcf-group-$(fcf-map-name)'}}), is_container='list', yang_name=\"fcoe-fcf-map\", rest_name=\"fcf-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'fcf_map_cp', u'cli-suppress-list-no': None, u'alt-name': u'fcf-group', u'info': u'Configure an FCF Group', u'cli-mode-name': u'config-fabric-map-fcf-group-$(fcf-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe_fcf_map must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"fcf_map_name\",fcoe_fcf_map.fcoe_fcf_map, yang_name=\"fcoe-fcf-map\", rest_name=\"fcf-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='fcf-map-name', extensions={u'tailf-common': {u'callpoint': u'fcf_map_cp', u'cli-suppress-list-no': None, u'alt-name': u'fcf-group', u'info': u'Configure an FCF Group', u'cli-mode-name': u'config-fabric-map-fcf-group-$(fcf-map-name)'}}), is_container='list', yang_name=\"fcoe-fcf-map\", rest_name=\"fcf-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'fcf_map_cp', u'cli-suppress-list-no': None, u'alt-name': u'fcf-group', u'info': u'Configure an FCF Group', u'cli-mode-name': u'config-fabric-map-fcf-group-$(fcf-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__fcoe_fcf_map = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the configuration of the FCoE port group.", "response": "def _set_fcoe_fcport_group_config(self, v, load=False):\n    \"\"\"\n    Setter method for fcoe_fcport_group_config, mapped from YANG variable /fcoe/fcoe_fabric_map/fcoe_fcport_group_config (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fcoe_fcport_group_config is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fcoe_fcport_group_config() directly.\n\n    YANG Description: This specifies the fcport-group parameters for the fabric-map\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoe_fcport_group_config.fcoe_fcport_group_config, is_container='container', presence=False, yang_name=\"fcoe-fcport-group-config\", rest_name=\"fcport-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure fcport-group parameters for the fabric-map', u'alt-name': u'fcport-group', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-full-command': None, u'callpoint': u'fcoe_fabric_map_cp', u'cli-mode-name': u'config-fabric-map-fcport-group-$(fcoe-fabric-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe_fcport_group_config must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoe_fcport_group_config.fcoe_fcport_group_config, is_container='container', presence=False, yang_name=\"fcoe-fcport-group-config\", rest_name=\"fcport-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure fcport-group parameters for the fabric-map', u'alt-name': u'fcport-group', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-full-command': None, u'callpoint': u'fcoe_fabric_map_cp', u'cli-mode-name': u'config-fabric-map-fcport-group-$(fcoe-fabric-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoe_fcport_group_config = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_filter_cardborder(*cardborder_type):\n    filter_ = []\n\n    for type_ in cardborder_type:\n        if not type_:\n            continue\n        filter_.append('category_' + APPID_CARDS + '_cardborder[]=tag_' + type_)\n\n    return '&'.join(filter_)", "response": "Returns a URL filter for a given cardborder type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_set_http_application_url(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=set_http_application_url.set_http_application_url, is_leaf=True, yang_name=\"set-http-application-url\", rest_name=\"set-http-application-url\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'set-http-app-url'}}, namespace='urn:brocade.com:mgmt:brocade-http-redirect', defining_module='brocade-http-redirect', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"set_http_application_url must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=set_http_application_url.set_http_application_url, is_leaf=True, yang_name=\"set-http-application-url\", rest_name=\"set-http-application-url\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'set-http-app-url'}}, namespace='urn:brocade.com:mgmt:brocade-http-redirect', defining_module='brocade-http-redirect', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__set_http_application_url = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the http application url for the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the mode of the", "response": "def _set_mode(self, v, load=False):\n    \"\"\"\n    Setter method for mode, mapped from YANG variable /brocade_interface_ext_rpc/get_interface_switchport/output/switchport/mode (interface:switchport-mode-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mode is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mode() directly.\n\n    YANG Description: This indicates the mode of Layer2 interface.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'pvlan-promiscuous': {'value': 4}, u'trunk-no-default-native': {'value': 9}, u'pvlan-trunk-promiscuous': {'value': 5}, u'pvlan-trunk-host': {'value': 7}, u'unknown': {'value': 0}, u'pvlan-host': {'value': 6}, u'access': {'value': 1}, u'pvlan-trunk': {'value': 8}, u'trunk': {'value': 2}, u'converged': {'value': 3}},), is_leaf=True, yang_name=\"mode\", rest_name=\"mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='interface:switchport-mode-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mode must be of a type compatible with interface:switchport-mode-type\"\"\",\n          'defined-type': \"interface:switchport-mode-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'pvlan-promiscuous': {'value': 4}, u'trunk-no-default-native': {'value': 9}, u'pvlan-trunk-promiscuous': {'value': 5}, u'pvlan-trunk-host': {'value': 7}, u'unknown': {'value': 0}, u'pvlan-host': {'value': 6}, u'access': {'value': 1}, u'pvlan-trunk': {'value': 8}, u'trunk': {'value': 2}, u'converged': {'value': 3}},), is_leaf=True, yang_name=\"mode\", rest_name=\"mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-interface-ext', defining_module='brocade-interface-ext', yang_type='interface:switchport-mode-type', is_config=True)\"\"\",\n        })\n\n    self.__mode = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the igmps version of the IGIMP Snooping tree.", "response": "def _set_igmps_version(self, v, load=False):\n    \"\"\"\n    Setter method for igmps_version, mapped from YANG variable /bridge_domain/ip/bd_ip_igmp/snooping/igmps_version (igmps-version-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_igmps_version is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_igmps_version() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..3']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(2), is_leaf=True, yang_name=\"igmps-version\", rest_name=\"version\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IGMP Snooping Version', u'cli-full-command': None, u'alt-name': u'version'}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='igmps-version-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmps_version must be of a type compatible with igmps-version-type\"\"\",\n          'defined-type': \"brocade-igmp-snooping:igmps-version-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..3']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(2), is_leaf=True, yang_name=\"igmps-version\", rest_name=\"version\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IGMP Snooping Version', u'cli-full-command': None, u'alt-name': u'version'}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='igmps-version-type', is_config=True)\"\"\",\n        })\n\n    self.__igmps_version = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_igmps_static_group(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"igmps_mcast_address igmps_interface igmps_if_type igmps_value\",igmps_static_group.igmps_static_group, yang_name=\"igmps_static-group\", rest_name=\"static-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='igmps-mcast-address igmps-interface igmps-if-type igmps-value', extensions={u'tailf-common': {u'callpoint': u'BDIgmpsSg', u'cli-suppress-mode': None, u'alt-name': u'static-group', u'info': u'Static Group to be Joined', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"igmps_static-group\", rest_name=\"static-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'BDIgmpsSg', u'cli-suppress-mode': None, u'alt-name': u'static-group', u'info': u'Static Group to be Joined', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmps_static_group must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"igmps_mcast_address igmps_interface igmps_if_type igmps_value\",igmps_static_group.igmps_static_group, yang_name=\"igmps_static-group\", rest_name=\"static-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='igmps-mcast-address igmps-interface igmps-if-type igmps-value', extensions={u'tailf-common': {u'callpoint': u'BDIgmpsSg', u'cli-suppress-mode': None, u'alt-name': u'static-group', u'info': u'Static Group to be Joined', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"igmps_static-group\", rest_name=\"static-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'BDIgmpsSg', u'cli-suppress-mode': None, u'alt-name': u'static-group', u'info': u'Static Group to be Joined', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__igmps_static_group = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the igmps_static_group property in the IGIMP system."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the flag for the MPLS dynamic bypass node.", "response": "def _set_dynamic_bypass_global(self, v, load=False):\n    \"\"\"\n    Setter method for dynamic_bypass_global, mapped from YANG variable /mpls_state/dynamic_bypass/dynamic_bypass_global (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dynamic_bypass_global is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dynamic_bypass_global() directly.\n\n    YANG Description: MPLS dynamic bypass\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=dynamic_bypass_global.dynamic_bypass_global, is_container='container', presence=False, yang_name=\"dynamic-bypass-global\", rest_name=\"dynamic-bypass-global\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-dynamic-bypass-global', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dynamic_bypass_global must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=dynamic_bypass_global.dynamic_bypass_global, is_container='container', presence=False, yang_name=\"dynamic-bypass-global\", rest_name=\"dynamic-bypass-global\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-dynamic-bypass-global', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__dynamic_bypass_global = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_spt_threshold(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=[RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..4294967295']}),RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'infinity': {'value': 0}},),], default=unicode(\"1\"), is_leaf=True, yang_name=\"spt-threshold\", rest_name=\"spt-threshold\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set threshold for switching to shortest-path-tree'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='spt-thr-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"spt_threshold must be of a type compatible with spt-thr-type\"\"\",\n          'defined-type': \"brocade-pim:spt-thr-type\",\n          'generated-type': \"\"\"YANGDynClass(base=[RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..4294967295']}),RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'infinity': {'value': 0}},),], default=unicode(\"1\"), is_leaf=True, yang_name=\"spt-threshold\", rest_name=\"spt-threshold\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set threshold for switching to shortest-path-tree'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='spt-thr-type', is_config=True)\"\"\",\n        })\n\n    self.__spt_threshold = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the threshold for the shortest path tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the rp_address field of the", "response": "def _set_rp_address(self, v, load=False):\n    \"\"\"\n    Setter method for rp_address, mapped from YANG variable /rbridge_id/router/hide_pim_holder/pim/rp_address (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_rp_address is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_rp_address() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"rp_ip_addr\",rp_address.rp_address, yang_name=\"rp-address\", rest_name=\"rp-address\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rp-ip-addr', extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-suppress-mode': None, u'callpoint': u'PimStaticRpCfgCallpoint', u'info': u'Static RP', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"rp-address\", rest_name=\"rp-address\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-suppress-mode': None, u'callpoint': u'PimStaticRpCfgCallpoint', u'info': u'Static RP', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rp_address must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"rp_ip_addr\",rp_address.rp_address, yang_name=\"rp-address\", rest_name=\"rp-address\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rp-ip-addr', extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-suppress-mode': None, u'callpoint': u'PimStaticRpCfgCallpoint', u'info': u'Static RP', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"rp-address\", rest_name=\"rp-address\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-suppress-mode': None, u'callpoint': u'PimStaticRpCfgCallpoint', u'info': u'Static RP', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__rp_address = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_system_utilization(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",system_utilization.system_utilization, yang_name=\"system-utilization\", rest_name=\"system-utilization\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'SystemProfile', u'info': u'System Utilization profile'}}), is_container='list', yang_name=\"system-utilization\", rest_name=\"system-utilization\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'SystemProfile', u'info': u'System Utilization profile'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"system_utilization must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",system_utilization.system_utilization, yang_name=\"system-utilization\", rest_name=\"system-utilization\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'SystemProfile', u'info': u'System Utilization profile'}}), is_container='list', yang_name=\"system-utilization\", rest_name=\"system-utilization\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'SystemProfile', u'info': u'System Utilization profile'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__system_utilization = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the system_utilization variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_enhanced_voq_discard_pkts(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",enhanced_voq_discard_pkts.enhanced_voq_discard_pkts, yang_name=\"enhanced-voq-discard-pkts\", rest_name=\"enhanced-voq-discard-pkts\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqDiscardPktsProfile', u'info': u'Enhanced VOQ discard packets'}}), is_container='list', yang_name=\"enhanced-voq-discard-pkts\", rest_name=\"enhanced-voq-discard-pkts\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqDiscardPktsProfile', u'info': u'Enhanced VOQ discard packets'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"enhanced_voq_discard_pkts must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",enhanced_voq_discard_pkts.enhanced_voq_discard_pkts, yang_name=\"enhanced-voq-discard-pkts\", rest_name=\"enhanced-voq-discard-pkts\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqDiscardPktsProfile', u'info': u'Enhanced VOQ discard packets'}}), is_container='list', yang_name=\"enhanced-voq-discard-pkts\", rest_name=\"enhanced-voq-discard-pkts\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqDiscardPktsProfile', u'info': u'Enhanced VOQ discard packets'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__enhanced_voq_discard_pkts = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the enhanced VOQ discard packets in the order they were added."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_enhanced_voq_max_queue_depth(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",enhanced_voq_max_queue_depth.enhanced_voq_max_queue_depth, yang_name=\"enhanced-voq-max-queue-depth\", rest_name=\"enhanced-voq-max-queue-depth\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqMaxQueueDepthProfile', u'info': u'Enhanced VOQ max queue depth'}}), is_container='list', yang_name=\"enhanced-voq-max-queue-depth\", rest_name=\"enhanced-voq-max-queue-depth\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqMaxQueueDepthProfile', u'info': u'Enhanced VOQ max queue depth'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"enhanced_voq_max_queue_depth must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",enhanced_voq_max_queue_depth.enhanced_voq_max_queue_depth, yang_name=\"enhanced-voq-max-queue-depth\", rest_name=\"enhanced-voq-max-queue-depth\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqMaxQueueDepthProfile', u'info': u'Enhanced VOQ max queue depth'}}), is_container='list', yang_name=\"enhanced-voq-max-queue-depth\", rest_name=\"enhanced-voq-max-queue-depth\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'EnhancedVoqMaxQueueDepthProfile', u'info': u'Enhanced VOQ max queue depth'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__enhanced_voq_max_queue_depth = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the maximum queue depth of a resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the tm_voq property in the base order is important.", "response": "def _set_tm_voq(self, v, load=False):\n    \"\"\"\n    Setter method for tm_voq, mapped from YANG variable /telemetry/profile/tm_voq (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tm_voq is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tm_voq() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",tm_voq.tm_voq, yang_name=\"tm-voq\", rest_name=\"tm-voq\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'TmVoqProfile', u'info': u'TM VOQ'}}), is_container='list', yang_name=\"tm-voq\", rest_name=\"tm-voq\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'TmVoqProfile', u'info': u'TM VOQ'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tm_voq must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",tm_voq.tm_voq, yang_name=\"tm-voq\", rest_name=\"tm-voq\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'TmVoqProfile', u'info': u'TM VOQ'}}), is_container='list', yang_name=\"tm-voq\", rest_name=\"tm-voq\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'TmVoqProfile', u'info': u'TM VOQ'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__tm_voq = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of the property to v.", "response": "def _set_mpls_traffic_bypass(self, v, load=False):\n    \"\"\"\n    Setter method for mpls_traffic_bypass, mapped from YANG variable /telemetry/profile/mpls_traffic_bypass (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mpls_traffic_bypass is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mpls_traffic_bypass() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name\",mpls_traffic_bypass.mpls_traffic_bypass, yang_name=\"mpls-traffic-bypass\", rest_name=\"mpls-traffic-bypass\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'MplstrafficbypassProfile', u'info': u'MPLS LSP profile'}}), is_container='list', yang_name=\"mpls-traffic-bypass\", rest_name=\"mpls-traffic-bypass\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'MplstrafficbypassProfile', u'info': u'MPLS LSP profile'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mpls_traffic_bypass must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name\",mpls_traffic_bypass.mpls_traffic_bypass, yang_name=\"mpls-traffic-bypass\", rest_name=\"mpls-traffic-bypass\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name', extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'MplstrafficbypassProfile', u'info': u'MPLS LSP profile'}}), is_container='list', yang_name=\"mpls-traffic-bypass\", rest_name=\"mpls-traffic-bypass\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-suppress-list-no': None, u'callpoint': u'MplstrafficbypassProfile', u'info': u'MPLS LSP profile'}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mpls_traffic_bypass = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting any value of the", "response": "def _set_any(self, v, load=False):\n    \"\"\"\n    Setter method for any, mapped from YANG variable /overlay_class_map/cmap_seq/match/any (empty)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_any is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_any() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"any\", rest_name=\"any\", parent=self, choice=(u'overlay-match-ip', u'case-overlay-ip-any'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Any IP Address'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"any must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"any\", rest_name=\"any\", parent=self, choice=(u'overlay-match-ip', u'case-overlay-ip-any'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Any IP Address'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__any = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of contn_src_dst in the internal list of the .", "response": "def _set_contn_src_dst(self, v, load=False):\n    \"\"\"\n    Setter method for contn_src_dst, mapped from YANG variable /overlay_class_map/cmap_seq/match/contn_src_dst (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_contn_src_dst is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_contn_src_dst() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=contn_src_dst.contn_src_dst, is_container='container', presence=False, yang_name=\"contn-src-dst\", rest_name=\"\", parent=self, choice=(u'overlay-match-ip', u'case-overlay-ip-src-dest'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-drop-node-name': None, u'cli-flatten-container': None}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"contn_src_dst must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=contn_src_dst.contn_src_dst, is_container='container', presence=False, yang_name=\"contn-src-dst\", rest_name=\"\", parent=self, choice=(u'overlay-match-ip', u'case-overlay-ip-src-dest'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-drop-node-name': None, u'cli-flatten-container': None}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__contn_src_dst = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_source(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])(%[\\\\p{N}\\\\p{L}]+)?'}), is_leaf=True, yang_name=\"source\", rest_name=\"source\", parent=self, choice=(u'overlay-match-ip', u'case-overlay-ip-src'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Source IPv4 Address: A.B.C.D'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='ipv4-address', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"source must be of a type compatible with ipv4-address\"\"\",\n          'defined-type': \"brocade-overlay-policy:ipv4-address\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])(%[\\\\p{N}\\\\p{L}]+)?'}), is_leaf=True, yang_name=\"source\", rest_name=\"source\", parent=self, choice=(u'overlay-match-ip', u'case-overlay-ip-src'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Source IPv4 Address: A.B.C.D'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='ipv4-address', is_config=True)\"\"\",\n        })\n\n    self.__source = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the source of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_ma_bd_vid(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..16384']}), is_leaf=True, yang_name=\"ma-bd-vid\", rest_name=\"bridge-domain\", parent=self, choice=(u'vid-type', u'bridgeDomain'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'bridge-domain association', u'cli-run-template': u'$(.?:)', u'alt-name': u'bridge-domain', u'cli-incomplete-command': None, u'cli-hide-in-submode': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ma_bd_vid must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..16384']}), is_leaf=True, yang_name=\"ma-bd-vid\", rest_name=\"bridge-domain\", parent=self, choice=(u'vid-type', u'bridgeDomain'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'bridge-domain association', u'cli-run-template': u'$(.?:)', u'alt-name': u'bridge-domain', u'cli-incomplete-command': None, u'cli-hide-in-submode': None}}, namespace='urn:brocade.com:mgmt:brocade-dot1ag', defining_module='brocade-dot1ag', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__ma_bd_vid = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ma_bd_vid variable in the domain name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_dom_name(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=dom_name.dom_name, is_container='container', presence=False, yang_name=\"dom-name\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configuration of Domain Name', u'cli-drop-node-name': None, u'callpoint': u'IpadmDomainNameCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-ip-administration', defining_module='brocade-ip-administration', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dom_name must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=dom_name.dom_name, is_container='container', presence=False, yang_name=\"dom-name\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configuration of Domain Name', u'cli-drop-node-name': None, u'callpoint': u'IpadmDomainNameCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-ip-administration', defining_module='brocade-ip-administration', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__dom_name = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the domain name of the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_name_server(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"name_server_ip\",name_server.name_server, yang_name=\"name-server\", rest_name=\"name-server\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name-server-ip', extensions={u'tailf-common': {u'cli-suppress-key-sort': None, u'cli-suppress-mode': None, u'callpoint': u'IpadmNameSrvCallpoint', u'info': u' Name Server configurations', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"name-server\", rest_name=\"name-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-suppress-key-sort': None, u'cli-suppress-mode': None, u'callpoint': u'IpadmNameSrvCallpoint', u'info': u' Name Server configurations', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ip-administration', defining_module='brocade-ip-administration', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"name_server must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"name_server_ip\",name_server.name_server, yang_name=\"name-server\", rest_name=\"name-server\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='name-server-ip', extensions={u'tailf-common': {u'cli-suppress-key-sort': None, u'cli-suppress-mode': None, u'callpoint': u'IpadmNameSrvCallpoint', u'info': u' Name Server configurations', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"name-server\", rest_name=\"name-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-suppress-key-sort': None, u'cli-suppress-mode': None, u'callpoint': u'IpadmNameSrvCallpoint', u'info': u' Name Server configurations', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ip-administration', defining_module='brocade-ip-administration', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__name_server = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the name server of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the circuit enclosure for the", "response": "def _set_circuit_encap(self, v, load=False):\n    \"\"\"\n    Setter method for circuit_encap, mapped from YANG variable /isis_state/interface_detail/isis_intf/circuit_encap (isis-circ-encap)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_circuit_encap is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_circuit_encap() directly.\n\n    YANG Description: Circuit Encapsulation\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'ppp': {'value': 2}, u'undef': {'value': 0}, u'chdlc': {'value': 1}},), is_leaf=True, yang_name=\"circuit-encap\", rest_name=\"circuit-encap\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='isis-circ-encap', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"circuit_encap must be of a type compatible with isis-circ-encap\"\"\",\n          'defined-type': \"brocade-isis-operational:isis-circ-encap\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'ppp': {'value': 2}, u'undef': {'value': 0}, u'chdlc': {'value': 1}},), is_leaf=True, yang_name=\"circuit-encap\", rest_name=\"circuit-encap\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='isis-circ-encap', is_config=False)\"\"\",\n        })\n\n    self.__circuit_encap = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_circ_chstats(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=circ_chstats.circ_chstats, is_container='container', presence=False, yang_name=\"circ-chstats\", rest_name=\"circ-chstats\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-circuit-change-stats', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"circ_chstats must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=circ_chstats.circ_chstats, is_container='container', presence=False, yang_name=\"circ-chstats\", rest_name=\"circ-chstats\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-circuit-change-stats', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__circ_chstats = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the circuit change statistics for the ISIS - CHStats interface."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_mpls_info(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mpls_info.mpls_info, is_container='container', presence=False, yang_name=\"mpls-info\", rest_name=\"mpls-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis-mpls-te-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mpls_info must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mpls_info.mpls_info, is_container='container', presence=False, yang_name=\"mpls-info\", rest_name=\"mpls-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis-mpls-te-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__mpls_info = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the MPLS TE info for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_reverse_metric_info(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=reverse_metric_info.reverse_metric_info, is_container='container', presence=False, yang_name=\"reverse-metric-info\", rest_name=\"reverse-metric-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-reverse-metric-interface', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"reverse_metric_info must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=reverse_metric_info.reverse_metric_info, is_container='container', presence=False, yang_name=\"reverse-metric-info\", rest_name=\"reverse-metric-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-reverse-metric-interface', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__reverse_metric_info = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of reverse_metric_info in the ISIS network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the LDP sync info for the ISIS LDP virtual list.", "response": "def _set_ldp_sync_info(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_sync_info, mapped from YANG variable /isis_state/interface_detail/isis_intf/ldp_sync_info (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_sync_info is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_sync_info() directly.\n\n    YANG Description: ISIS LDP sync info\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_sync_info.ldp_sync_info, is_container='container', presence=False, yang_name=\"ldp-sync-info\", rest_name=\"ldp-sync-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis-ldp-sync-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_sync_info must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_sync_info.ldp_sync_info, is_container='container', presence=False, yang_name=\"ldp-sync-info\", rest_name=\"ldp-sync-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis-ldp-sync-info', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_sync_info = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_config_src(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'bgp-evpn': {'value': 3}, u'vtep-controller': {'value': 1}, u'site-config': {'value': 2}},), is_leaf=True, yang_name=\"config-src\", rest_name=\"config-src\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-tunnels-ext', defining_module='brocade-tunnels-ext', yang_type='config-src-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"config_src must be of a type compatible with config-src-type\"\"\",\n          'defined-type': \"brocade-tunnels-ext:config-src-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'bgp-evpn': {'value': 3}, u'vtep-controller': {'value': 1}, u'site-config': {'value': 2}},), is_leaf=True, yang_name=\"config-src\", rest_name=\"config-src\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-tunnels-ext', defining_module='brocade-tunnels-ext', yang_type='config-src-type', is_config=True)\"\"\",\n        })\n\n    self.__config_src = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the configuration source of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of fcoe_interface_bind", "response": "def _set_fcoe_interface_bind(self, v, load=False):\n    \"\"\"\n    Setter method for fcoe_interface_bind, mapped from YANG variable /interface/fcoe/fcoe_interface_bind (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fcoe_interface_bind is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fcoe_interface_bind() directly.\n\n    YANG Description: Bind the FCoE interface to a Physical Ethernet Port.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoe_interface_bind.fcoe_interface_bind, is_container='container', presence=False, yang_name=\"fcoe-interface-bind\", rest_name=\"bind\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Bind the FCoE interface to a Physical Ethernet Port.', u'cli-sequence-commands': None, u'alt-name': u'bind', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe_interface_bind must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoe_interface_bind.fcoe_interface_bind, is_container='container', presence=False, yang_name=\"fcoe-interface-bind\", rest_name=\"bind\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Bind the FCoE interface to a Physical Ethernet Port.', u'cli-sequence-commands': None, u'alt-name': u'bind', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoe_interface_bind = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the microcode of the", "response": "def _set_microcode(self, v, load=False):\n    \"\"\"\n    Setter method for microcode, mapped from YANG variable /firmware/peripheral_update/microcode (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_microcode is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_microcode() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=microcode.microcode, is_container='container', presence=False, yang_name=\"microcode\", rest_name=\"microcode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Microcode image'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"microcode must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=microcode.microcode, is_container='container', presence=False, yang_name=\"microcode\", rest_name=\"microcode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Microcode image'}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__microcode = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the ldp - fec - summary for the given object.", "response": "def _set_ldp_fec_summary(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_fec_summary, mapped from YANG variable /mpls_state/ldp/fec/ldp_fec_summary (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_fec_summary is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_fec_summary() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_fec_summary.ldp_fec_summary, is_container='container', presence=False, yang_name=\"ldp-fec-summary\", rest_name=\"ldp-fec-summary\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-summary', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_fec_summary must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_fec_summary.ldp_fec_summary, is_container='container', presence=False, yang_name=\"ldp-fec-summary\", rest_name=\"ldp-fec-summary\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-summary', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_fec_summary = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_ldp_fec_prefixes(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_fec_prefixes.ldp_fec_prefixes, is_container='container', presence=False, yang_name=\"ldp-fec-prefixes\", rest_name=\"ldp-fec-prefixes\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-prefixes', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_fec_prefixes must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_fec_prefixes.ldp_fec_prefixes, is_container='container', presence=False, yang_name=\"ldp-fec-prefixes\", rest_name=\"ldp-fec-prefixes\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-prefixes', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_fec_prefixes = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the LDP FEC prefixes for the given sequence of LDP FEC prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_ldp_fec_vcs(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_fec_vcs.ldp_fec_vcs, is_container='container', presence=False, yang_name=\"ldp-fec-vcs\", rest_name=\"ldp-fec-vcs\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-vcs', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_fec_vcs must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_fec_vcs.ldp_fec_vcs, is_container='container', presence=False, yang_name=\"ldp-fec-vcs\", rest_name=\"ldp-fec-vcs\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-vcs', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_fec_vcs = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the LDP FEC VCS parameter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_ldp_fec_prefix_prefix(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_fec_prefix_prefix.ldp_fec_prefix_prefix, is_container='container', presence=False, yang_name=\"ldp-fec-prefix-prefix\", rest_name=\"ldp-fec-prefix-prefix\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-prefix-prefix-ldp-fec-prefix-prefix-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_fec_prefix_prefix must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_fec_prefix_prefix.ldp_fec_prefix_prefix, is_container='container', presence=False, yang_name=\"ldp-fec-prefix-prefix\", rest_name=\"ldp-fec-prefix-prefix\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-fec-prefix-prefix-ldp-fec-prefix-prefix-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_fec_prefix_prefix = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the LDP FEC prefix for the sequence of LDP routes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_fcf_map_fif_rbid(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcf_map_fif_rbid.fcf_map_fif_rbid, is_container='container', presence=False, yang_name=\"fcf-map-fif-rbid\", rest_name=\"fif-rbid\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FIF rbridge-id/s in the FCF Group', u'alt-name': u'fif-rbid', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcf_map_fif_rbid must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcf_map_fif_rbid.fcf_map_fif_rbid, is_container='container', presence=False, yang_name=\"fcf-map-fif-rbid\", rest_name=\"fif-rbid\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure FIF rbridge-id/s in the FCF Group', u'alt-name': u'fif-rbid', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcf_map_fif_rbid = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the FCF RBID of the current FCF Group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting tunnel destination IP address.", "response": "def _set_tunnel_dst(self, v, load=False):\n    \"\"\"\n    Setter method for tunnel_dst, mapped from YANG variable /overlay_gateway/site/tunnel_dst (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tunnel_dst is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tunnel_dst() directly.\n\n    YANG Description: Site IP address configuration represents\ndestination IP of tunnel to the site. Tunnel will\nnot be setup without the IP address configuration.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"address\",tunnel_dst.tunnel_dst, yang_name=\"tunnel-dst\", rest_name=\"ip\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='address', extensions={u'tailf-common': {u'info': u'IP configuration for site.', u'cli-suppress-mode': None, u'cli-compact-syntax': None, u'alt-name': u'ip', u'callpoint': u'overlay-site-ip-cp'}}), is_container='list', yang_name=\"tunnel-dst\", rest_name=\"ip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IP configuration for site.', u'cli-suppress-mode': None, u'cli-compact-syntax': None, u'alt-name': u'ip', u'callpoint': u'overlay-site-ip-cp'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tunnel_dst must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"address\",tunnel_dst.tunnel_dst, yang_name=\"tunnel-dst\", rest_name=\"ip\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='address', extensions={u'tailf-common': {u'info': u'IP configuration for site.', u'cli-suppress-mode': None, u'cli-compact-syntax': None, u'alt-name': u'ip', u'callpoint': u'overlay-site-ip-cp'}}), is_container='list', yang_name=\"tunnel-dst\", rest_name=\"ip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IP configuration for site.', u'cli-suppress-mode': None, u'cli-compact-syntax': None, u'alt-name': u'ip', u'callpoint': u'overlay-site-ip-cp'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__tunnel_dst = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_extend(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=extend.extend, is_container='container', presence=False, yang_name=\"extend\", rest_name=\"extend\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure layer2 domains to be extended towards\\nthis site.'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"extend must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=extend.extend, is_container='container', presence=False, yang_name=\"extend\", rest_name=\"extend\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure layer2 domains to be extended towards\\nthis site.'}}, namespace='urn:brocade.com:mgmt:brocade-tunnels', defining_module='brocade-tunnels', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__extend = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the extend variable for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset show - linkinfo field of the .", "response": "def _set_show_linkinfo(self, v, load=False):\n    \"\"\"\n    Setter method for show_linkinfo, mapped from YANG variable /brocade_fabric_service_rpc/show_linkinfo (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_show_linkinfo is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_show_linkinfo() directly.\n\n    YANG Description: Provides details of all the links connected in\nthe fabric. This information is given in groups\nfor all the RBridges in the fabric.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=show_linkinfo.show_linkinfo, is_leaf=True, yang_name=\"show-linkinfo\", rest_name=\"show-linkinfo\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'show_linkinfo_all'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"show_linkinfo must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=show_linkinfo.show_linkinfo, is_leaf=True, yang_name=\"show-linkinfo\", rest_name=\"show-linkinfo\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'show_linkinfo_all'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__show_linkinfo = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the show_portindex_interface_info field of the .", "response": "def _set_show_portindex_interface_info(self, v, load=False):\n    \"\"\"\n    Setter method for show_portindex_interface_info, mapped from YANG variable /brocade_fabric_service_rpc/show_portindex_interface_info (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_show_portindex_interface_info is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_show_portindex_interface_info() directly.\n\n    YANG Description: Provides the details of 10G Ethernet and fibrechannel\nover ethernet ports. It consists of port index of the\nRBridge, port type (Te or FCOE) and port interface.\nPort interface is in the format\nrbridge-id/slot/port for Te ports and\nvlan-id/rbridge-id/port for FCOE ports.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=show_portindex_interface_info.show_portindex_interface_info, is_leaf=True, yang_name=\"show-portindex-interface-info\", rest_name=\"show-portindex-interface-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'show_portindex_interface_all'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"show_portindex_interface_info must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=show_portindex_interface_info.show_portindex_interface_info, is_leaf=True, yang_name=\"show-portindex-interface-info\", rest_name=\"show-portindex-interface-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'show_portindex_interface_all'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__show_portindex_interface_info = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_show_fibrechannel_interface_info(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=show_fibrechannel_interface_info.show_fibrechannel_interface_info, is_leaf=True, yang_name=\"show-fibrechannel-interface-info\", rest_name=\"show-fibrechannel-interface-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'show_fi_interface_info'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"show_fibrechannel_interface_info must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=show_fibrechannel_interface_info.show_fibrechannel_interface_info, is_leaf=True, yang_name=\"show-fibrechannel-interface-info\", rest_name=\"show-fibrechannel-interface-info\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'show_fi_interface_info'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__show_fibrechannel_interface_info = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the show_fibrechannel_interface_info field of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef request(self, command_string):\n        \n        \"\"\" Request \"\"\"\n        \n        self.tn.write((command_string + \"\\n\").encode())\n        if self.debug: print \"Telnet Request:  %s\" % (command_string)\n        while True:\n            response = urllib.unquote(self.tn.read_until(b\"\\n\").decode())\n            if \"success\" in response:   # Normal successful reply\n                break\n            if \"huh\" in response:       # Something went wrong\n                break\n            if \"connect\" in response:   # Special reply to \"hello\"\n                break\n            # TODO Keep track of which screen is displayed\n            # Try again if response was key, menu or visibility notification.\n        if \"huh\" in response or self.debug: print \"Telnet Response: %s\" % (response[:-1])\n        return response", "response": "Send a command to the Telnet device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef poll(self):\n        if select.select([self.tn], [], [], 0) == ([self.tn], [], []):\n            response = urllib.unquote(self.tn.read_until(b\"\\n\").decode())\n            if self.debug: print \"Telnet Poll: %s\" % (response[:-1])\n            # TODO Keep track of which screen is displayed\n            return response\n        else:\n            return None", "response": "Check for a non - response string generated by LCDd and return any string read."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the client s output on some display modules to this value.", "response": "def output(self, value):\n        \"\"\"\n        Sets the client's output (on, off, int)\n        \n        Sets the general purpose output on some display modules to this value.\n        Use on to set all outputs to high state, and off to set all to low state.\n        The meaning of the integer value depends on your specific device, usually\n        it is a bit pattern describing the state of each output line.\n        \n        Return None or LCDd response on error\n        \"\"\"\n        response = self.request((\"output %s\" % (value)).encode())\n        if \"success\" in response:\n            return None\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_af_ipv6_unicast(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=af_ipv6_unicast.af_ipv6_unicast, is_container='container', presence=True, yang_name=\"af-ipv6-unicast\", rest_name=\"unicast\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IPv6 unicast address Family', u'cli-full-no': None, u'callpoint': u'IsisAfIpv6Ucast', u'cli-add-mode': None, u'cli-full-command': None, u'alt-name': u'unicast', u'cli-mode-name': u'config-router-isis-ipv6u'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"af_ipv6_unicast must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=af_ipv6_unicast.af_ipv6_unicast, is_container='container', presence=True, yang_name=\"af-ipv6-unicast\", rest_name=\"unicast\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IPv6 unicast address Family', u'cli-full-no': None, u'callpoint': u'IsisAfIpv6Ucast', u'cli-add-mode': None, u'cli-full-command': None, u'alt-name': u'unicast', u'cli-mode-name': u'config-router-isis-ipv6u'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__af_ipv6_unicast = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the af_ipv6_unicast property in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the rp - candidate - group - prefix property.", "response": "def _set_rp_cand_grp_prefix(self, v, load=False):\n    \"\"\"\n    Setter method for rp_cand_grp_prefix, mapped from YANG variable /rbridge_id/router/hide_pim_holder/pim/rp_candidate/rp_cand_grp_prefix (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_rp_cand_grp_prefix is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_rp_cand_grp_prefix() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"rp_cand_grp_prefix_ip rp_cand_grp_prefix_length\",rp_cand_grp_prefix.rp_cand_grp_prefix, yang_name=\"rp-cand-grp-prefix\", rest_name=\"group-range\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rp-cand-grp-prefix-ip rp-cand-grp-prefix-length', extensions={u'tailf-common': {u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'group-range', u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'PimCandRpPrefixCfgCallpoint'}}), is_container='list', yang_name=\"rp-cand-grp-prefix\", rest_name=\"group-range\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'group-range', u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'PimCandRpPrefixCfgCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rp_cand_grp_prefix must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"rp_cand_grp_prefix_ip rp_cand_grp_prefix_length\",rp_cand_grp_prefix.rp_cand_grp_prefix, yang_name=\"rp-cand-grp-prefix\", rest_name=\"group-range\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rp-cand-grp-prefix-ip rp-cand-grp-prefix-length', extensions={u'tailf-common': {u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'group-range', u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'PimCandRpPrefixCfgCallpoint'}}), is_container='list', yang_name=\"rp-cand-grp-prefix\", rest_name=\"group-range\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'group-range', u'cli-compact-syntax': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'PimCandRpPrefixCfgCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__rp_cand_grp_prefix = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the bots and populate the app registry.", "response": "def setup():\n    \"\"\"\n    Configure the settings (this happens as a side effect of accessing the\n    first setting), configure logging and populate the app registry.\n    \"\"\"\n    from trading_bots.bots import bots\n    from trading_bots.conf import settings\n\n    bots.populate(settings.installed_bots)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_gre(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=gre.gre, is_container='container', presence=False, yang_name=\"gre\", rest_name=\"gre\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'GRE encapsulation'}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"gre must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=gre.gre, is_container='container', presence=False, yang_name=\"gre\", rest_name=\"gre\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'GRE encapsulation'}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__gre = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the gre variable in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_key_table(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=key_table.key_table, is_container='container', presence=False, yang_name=\"key-table\", rest_name=\"key-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' MD5 authentication key ID table ', u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'alt-name': u'key-id'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"key_table must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=key_table.key_table, is_container='container', presence=False, yang_name=\"key-table\", rest_name=\"key-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' MD5 authentication key ID table ', u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'alt-name': u'key-id'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__key_table = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the key table of the current NIC."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the state of the node hardware synchronization.", "response": "def _set_node_hw_sync_state(self, v, load=False):\n    \"\"\"\n    Setter method for node_hw_sync_state, mapped from YANG variable /brocade_vcs_rpc/show_vcs/output/vcs_nodes/vcs_node_info/node_hw_sync_state (node-hw-sync-state-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_node_hw_sync_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_node_hw_sync_state() directly.\n\n    YANG Description: Node hardware synchronization state\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'node-in-sync': {'value': 4}, u'node-uninitialized': {'value': 2}, u'node-unknown': {'value': 1}, u'node-synchronizing': {'value': 3}, u'node-out-of-sync': {'value': 5}},), is_leaf=True, yang_name=\"node-hw-sync-state\", rest_name=\"node-hw-sync-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='node-hw-sync-state-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"node_hw_sync_state must be of a type compatible with node-hw-sync-state-type\"\"\",\n          'defined-type': \"brocade-vcs:node-hw-sync-state-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'node-in-sync': {'value': 4}, u'node-uninitialized': {'value': 2}, u'node-unknown': {'value': 1}, u'node-synchronizing': {'value': 3}, u'node-out-of-sync': {'value': 5}},), is_leaf=True, yang_name=\"node-hw-sync-state\", rest_name=\"node-hw-sync-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='node-hw-sync-state-type', is_config=True)\"\"\",\n        })\n\n    self.__node_hw_sync_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state of the node in the sequence.", "response": "def _set_node_state(self, v, load=False):\n    \"\"\"\n    Setter method for node_state, mapped from YANG variable /brocade_vcs_rpc/show_vcs/output/vcs_nodes/vcs_node_info/node_state (node-state-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_node_state is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_node_state() directly.\n\n    YANG Description: Node state\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'Replacing': {'value': 4}, u'Unknown': {'value': 1}, u'Rejoining': {'value': 6}, u'Awaiting-Rejoin': {'value': 7}, u'Online': {'value': 2}, u'Offline': {'value': 3}, u'Coming-Online': {'value': 5}},), is_leaf=True, yang_name=\"node-state\", rest_name=\"node-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='node-state-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"node_state must be of a type compatible with node-state-type\"\"\",\n          'defined-type': \"brocade-vcs:node-state-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'Replacing': {'value': 4}, u'Unknown': {'value': 1}, u'Rejoining': {'value': 6}, u'Awaiting-Rejoin': {'value': 7}, u'Online': {'value': 2}, u'Offline': {'value': 3}, u'Coming-Online': {'value': 5}},), is_leaf=True, yang_name=\"node-state\", rest_name=\"node-state\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='node-state-type', is_config=True)\"\"\",\n        })\n\n    self.__node_state = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_rp_cand_interface(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"rp_cand_intf_type rp_cand_intf_id\",rp_cand_interface.rp_cand_interface, yang_name=\"rp-cand-interface\", rest_name=\"interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rp-cand-intf-type rp-cand-intf-id', extensions={u'tailf-common': {u'info': u'Interface information', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-compact-syntax': None, u'callpoint': u'PimCandRpCfgCallpoint'}}), is_container='list', yang_name=\"rp-cand-interface\", rest_name=\"interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Interface information', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-compact-syntax': None, u'callpoint': u'PimCandRpCfgCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rp_cand_interface must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"rp_cand_intf_type rp_cand_intf_id\",rp_cand_interface.rp_cand_interface, yang_name=\"rp-cand-interface\", rest_name=\"interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rp-cand-intf-type rp-cand-intf-id', extensions={u'tailf-common': {u'info': u'Interface information', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-compact-syntax': None, u'callpoint': u'PimCandRpCfgCallpoint'}}), is_container='list', yang_name=\"rp-cand-interface\", rest_name=\"interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Interface information', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-compact-syntax': None, u'callpoint': u'PimCandRpCfgCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__rp_cand_interface = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the rp_cand_interface variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the address of the", "response": "def _set_address(self, v, load=False):\n    \"\"\"\n    Setter method for address, mapped from YANG variable /interface/management/ip/address (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_address is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_address() directly.\n\n    YANG Description: The IPv4 address configuration for this \nmanagement interface.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=address.address, is_container='container', presence=False, yang_name=\"address\", rest_name=\"address\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'The IPv4 address configuration for this \\nmanagement interface.'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"address must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=address.address, is_container='container', presence=False, yang_name=\"address\", rest_name=\"address\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'The IPv4 address configuration for this \\nmanagement interface.'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__address = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a module namespace to a Python dictionary. Used by get_settings_diff.", "response": "def module_to_dict(module, omittable=lambda k: k.startswith('_')):\n    \"\"\"\n    Converts a module namespace to a Python dictionary. Used by get_settings_diff.\n    \"\"\"\n    return dict([(k, repr(v)) for k, v in module.__dict__.items() if not omittable(k)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun snpeff on an input vcf. :param toil.fileStore.FileID merged_mutation_file: fsID for input vcf :param dict univ_options: Dict of universal options used by almost all tools :param dict snpeff_options: Options specific to snpeff :return: fsID for the snpeffed vcf :rtype: toil.fileStore.FileID", "response": "def run_snpeff(job, merged_mutation_file, univ_options, snpeff_options):\n    \"\"\"\n    Run snpeff on an input vcf.\n\n    :param toil.fileStore.FileID merged_mutation_file: fsID for input vcf\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict snpeff_options: Options specific to snpeff\n    :return: fsID for the snpeffed vcf\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        'merged_mutations.vcf': merged_mutation_file,\n        'snpeff_index.tar.gz': snpeff_options['index']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    input_files['snpeff_index'] = untargz(input_files['snpeff_index.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    parameters = ['eff',\n                  '-dataDir', input_files['snpeff_index'],\n                  '-c', '/'.join([input_files['snpeff_index'],\n                                  'snpEff_' + univ_options['ref'] + '_gencode.config']),\n                  '-no-intergenic',\n                  '-no-downstream',\n                  '-no-upstream',\n                  # '-canon',\n                  '-noStats',\n                  univ_options['ref'] + '_gencode',\n                  input_files['merged_mutations.vcf']]\n    xmx = snpeff_options['java_Xmx'] if snpeff_options['java_Xmx'] else univ_options['java_Xmx']\n    with open('/'.join([work_dir, 'mutations.vcf']), 'w') as snpeff_file:\n        docker_call(tool='snpeff', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], java_xmx=xmx, outfile=snpeff_file,\n                    tool_version=snpeff_options['version'])\n    output_file = job.fileStore.writeGlobalFile(snpeff_file.name)\n    export_results(job, output_file, snpeff_file.name, univ_options, subfolder='mutations/snpeffed')\n    job.fileStore.logToMaster('Ran snpeff on %s successfully' % univ_options['patient'])\n    return output_file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of igmps_prefix_list in the Igmps header.", "response": "def _set_igmps_prefix_list(self, v, load=False):\n    \"\"\"\n    Setter method for igmps_prefix_list, mapped from YANG variable /igmp_snooping/ip/igmp/ssm_map/igmps_prefix_list (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_igmps_prefix_list is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_igmps_prefix_list() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"igmps_prefix_list_name igmps_prefix_src_addr\",igmps_prefix_list.igmps_prefix_list, yang_name=\"igmps-prefix-list\", rest_name=\"igmps-prefix-list\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='igmps-prefix-list-name igmps-prefix-src-addr', extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IgmpsPrefixList', u'cli-suppress-mode': None, u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"igmps-prefix-list\", rest_name=\"igmps-prefix-list\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IgmpsPrefixList', u'cli-suppress-mode': None, u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmps_prefix_list must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"igmps_prefix_list_name igmps_prefix_src_addr\",igmps_prefix_list.igmps_prefix_list, yang_name=\"igmps-prefix-list\", rest_name=\"igmps-prefix-list\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='igmps-prefix-list-name igmps-prefix-src-addr', extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IgmpsPrefixList', u'cli-suppress-mode': None, u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"igmps-prefix-list\", rest_name=\"igmps-prefix-list\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'IgmpsPrefixList', u'cli-suppress-mode': None, u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__igmps_prefix_list = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of static_route_oif in the virtual network.", "response": "def _set_static_route_oif(self, v, load=False):\n    \"\"\"\n    Setter method for static_route_oif, mapped from YANG variable /rbridge_id/vrf/address_family/ip/unicast/ip/route/static_route_oif (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_static_route_oif is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_static_route_oif() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"static_route_dest static_route_oif_type static_route_oif_name\",static_route_oif.static_route_oif, yang_name=\"static-route-oif\", rest_name=\"static-route-oif\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='static-route-dest static-route-oif-type static-route-oif-name', extensions={u'tailf-common': {u'info': u'Route with egress interface', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-drop-node-name': None, u'callpoint': u'rtm-if-static-route'}}), is_container='list', yang_name=\"static-route-oif\", rest_name=\"static-route-oif\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Route with egress interface', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-drop-node-name': None, u'callpoint': u'rtm-if-static-route'}}, namespace='urn:brocade.com:mgmt:brocade-rtm', defining_module='brocade-rtm', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"static_route_oif must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"static_route_dest static_route_oif_type static_route_oif_name\",static_route_oif.static_route_oif, yang_name=\"static-route-oif\", rest_name=\"static-route-oif\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='static-route-dest static-route-oif-type static-route-oif-name', extensions={u'tailf-common': {u'info': u'Route with egress interface', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-drop-node-name': None, u'callpoint': u'rtm-if-static-route'}}), is_container='list', yang_name=\"static-route-oif\", rest_name=\"static-route-oif\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Route with egress interface', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-drop-node-name': None, u'callpoint': u'rtm-if-static-route'}}, namespace='urn:brocade.com:mgmt:brocade-rtm', defining_module='brocade-rtm', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__static_route_oif = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the member_zone of the based on member_zone. member_zone", "response": "def _set_member_zone(self, v, load=False):\n    \"\"\"\n    Setter method for member_zone, mapped from YANG variable /zoning/defined_configuration/cfg/member_zone (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_member_zone is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_member_zone() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"zone_name\",member_zone.member_zone, yang_name=\"member-zone\", rest_name=\"member-zone\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='zone-name', extensions={u'tailf-common': {u'info': u'List of Zones for CFGs', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'hidden': u'wyser-write-hook', u'callpoint': u'zone_defined_cfg_member'}}), is_container='list', yang_name=\"member-zone\", rest_name=\"member-zone\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of Zones for CFGs', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'hidden': u'wyser-write-hook', u'callpoint': u'zone_defined_cfg_member'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"member_zone must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"zone_name\",member_zone.member_zone, yang_name=\"member-zone\", rest_name=\"member-zone\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='zone-name', extensions={u'tailf-common': {u'info': u'List of Zones for CFGs', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'hidden': u'wyser-write-hook', u'callpoint': u'zone_defined_cfg_member'}}), is_container='list', yang_name=\"member-zone\", rest_name=\"member-zone\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of Zones for CFGs', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'hidden': u'wyser-write-hook', u'callpoint': u'zone_defined_cfg_member'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__member_zone = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_bridge_domain_type(self, v, load=False):\n    parent = getattr(self, \"_parent\", None)\n    if parent is not None and load is False:\n      raise AttributeError(\"Cannot set keys directly when\" +\n                             \" within an instantiated list\")\n\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'p2mp': {'value': 1}, u'p2p': {'value': 2}},), is_leaf=True, yang_name=\"bridge-domain-type\", rest_name=\"bridge-domain-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set the Bridge Domain Type', u'key-default': u'p2mp'}}, is_keyval=True, namespace='urn:brocade.com:mgmt:brocade-bridge-domain', defining_module='brocade-bridge-domain', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bridge_domain_type must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-bridge-domain:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'p2mp': {'value': 1}, u'p2p': {'value': 2}},), is_leaf=True, yang_name=\"bridge-domain-type\", rest_name=\"bridge-domain-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set the Bridge Domain Type', u'key-default': u'p2mp'}}, is_keyval=True, namespace='urn:brocade.com:mgmt:brocade-bridge-domain', defining_module='brocade-bridge-domain', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__bridge_domain_type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the bridge domain type for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_suppress_arp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=suppress_arp.suppress_arp, is_container='container', presence=False, yang_name=\"suppress-arp\", rest_name=\"suppress-arp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure ARP suppression'}}, namespace='urn:brocade.com:mgmt:brocade-arp', defining_module='brocade-arp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"suppress_arp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=suppress_arp.suppress_arp, is_container='container', presence=False, yang_name=\"suppress-arp\", rest_name=\"suppress-arp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure ARP suppression'}}, namespace='urn:brocade.com:mgmt:brocade-arp', defining_module='brocade-arp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__suppress_arp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the suppress - arp variable for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the suppress_nd property of the", "response": "def _set_suppress_nd(self, v, load=False):\n    \"\"\"\n    Setter method for suppress_nd, mapped from YANG variable /bridge_domain/suppress_nd (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_suppress_nd is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_suppress_nd() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=suppress_nd.suppress_nd, is_container='container', presence=False, yang_name=\"suppress-nd\", rest_name=\"suppress-nd\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure ND suppression'}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-nd-ra', defining_module='brocade-ipv6-nd-ra', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"suppress_nd must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=suppress_nd.suppress_nd, is_container='container', presence=False, yang_name=\"suppress-nd\", rest_name=\"suppress-nd\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure ND suppression'}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-nd-ra', defining_module='brocade-ipv6-nd-ra', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__suppress_nd = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the session type of the", "response": "def _set_session_type(self, v, load=False):\n    \"\"\"\n    Setter method for session_type, mapped from YANG variable /mpls_state/rsvp/sessions/psbs/session_type (session-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_session_type is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_session_type() directly.\n\n    YANG Description: Session type\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'session-type-none': {'value': 0}, u'merged-backup': {'value': 6}, u'ingress-detour': {'value': 1}, u'egress-backup': {'value': 7}, u'repaired-session': {'value': 8}, u'bypass-ingress': {'value': 9}, u'transit-detour': {'value': 2}, u'egress-detour': {'value': 4}, u'ingress-backup': {'value': 5}, u'merged-detour': {'value': 3}},), is_leaf=True, yang_name=\"session-type\", rest_name=\"session-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='session-type', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"session_type must be of a type compatible with session-type\"\"\",\n          'defined-type': \"brocade-mpls-operational:session-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'session-type-none': {'value': 0}, u'merged-backup': {'value': 6}, u'ingress-detour': {'value': 1}, u'egress-backup': {'value': 7}, u'repaired-session': {'value': 8}, u'bypass-ingress': {'value': 9}, u'transit-detour': {'value': 2}, u'egress-detour': {'value': 4}, u'ingress-backup': {'value': 5}, u'merged-detour': {'value': 3}},), is_leaf=True, yang_name=\"session-type\", rest_name=\"session-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='session-type', is_config=False)\"\"\",\n        })\n\n    self.__session_type = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_frr_cspf_group_computation_mode(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'frr-cspf-group-comp-mode-add-penalty': {'value': 1}, u'frr-cspf-group-comp-mode-high-penalty': {'value': 3}, u'frr-cspf-group-comp-mode-exclude-groups': {'value': 2}, u'frr-cspf-group-comp-mode-disabled': {'value': 0}},), is_leaf=True, yang_name=\"frr-cspf-group-computation-mode\", rest_name=\"frr-cspf-group-computation-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='frr-cspf-group-computation-mode', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"frr_cspf_group_computation_mode must be of a type compatible with frr-cspf-group-computation-mode\"\"\",\n          'defined-type': \"brocade-mpls-operational:frr-cspf-group-computation-mode\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'frr-cspf-group-comp-mode-add-penalty': {'value': 1}, u'frr-cspf-group-comp-mode-high-penalty': {'value': 3}, u'frr-cspf-group-comp-mode-exclude-groups': {'value': 2}, u'frr-cspf-group-comp-mode-disabled': {'value': 0}},), is_leaf=True, yang_name=\"frr-cspf-group-computation-mode\", rest_name=\"frr-cspf-group-computation-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='frr-cspf-group-computation-mode', is_config=False)\"\"\",\n        })\n\n    self.__frr_cspf_group_computation_mode = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the CSPF group computation mode for the current CSPF group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the session style of the", "response": "def _set_session_style(self, v, load=False):\n    \"\"\"\n    Setter method for session_style, mapped from YANG variable /mpls_state/rsvp/sessions/psbs/session_style (session-reservation-style)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_session_style is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_session_style() directly.\n\n    YANG Description: Style of session\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'reservation-style-shared-explicit': {'value': 2}, u'reservation-style-wildcard-filter': {'value': 0}, u'reservation-style-unknown': {'value': 3}, u'reservation-style-fixed-filter': {'value': 1}},), is_leaf=True, yang_name=\"session-style\", rest_name=\"session-style\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='session-reservation-style', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"session_style must be of a type compatible with session-reservation-style\"\"\",\n          'defined-type': \"brocade-mpls-operational:session-reservation-style\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'reservation-style-shared-explicit': {'value': 2}, u'reservation-style-wildcard-filter': {'value': 0}, u'reservation-style-unknown': {'value': 3}, u'reservation-style-fixed-filter': {'value': 1}},), is_leaf=True, yang_name=\"session-style\", rest_name=\"session-style\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='session-reservation-style', is_config=False)\"\"\",\n        })\n\n    self.__session_style = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the defaults of the", "response": "def _set_defaults(self, v, load=False):\n    \"\"\"\n    Setter method for defaults, mapped from YANG variable /show/defaults (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_defaults is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_defaults() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=defaults.defaults, is_container='container', presence=False, yang_name=\"defaults\", rest_name=\"defaults\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Display default configuration'}}, namespace='urn:brocade.com:mgmt:brocade-common-def', defining_module='brocade-common-def', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"defaults must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=defaults.defaults, is_container='container', presence=False, yang_name=\"defaults\", rest_name=\"defaults\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Display default configuration'}}, namespace='urn:brocade.com:mgmt:brocade-common-def', defining_module='brocade-common-def', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__defaults = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_fabric(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fabric.fabric, is_container='container', presence=False, yang_name=\"fabric\", rest_name=\"fabric\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Provides fabric related information', u'action': u'trunk', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fabric must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fabric.fabric, is_container='container', presence=False, yang_name=\"fabric\", rest_name=\"fabric\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Provides fabric related information', u'action': u'trunk', u'display-when': u'/vcsmode/vcs-mode = \"true\"'}}, namespace='urn:brocade.com:mgmt:brocade-fabric-service', defining_module='brocade-fabric-service', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fabric = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the fabric property."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the show_firmware_dummy variable.", "response": "def _set_show_firmware_dummy(self, v, load=False):\n    \"\"\"\n    Setter method for show_firmware_dummy, mapped from YANG variable /show/show_firmware_dummy (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_show_firmware_dummy is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_show_firmware_dummy() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=show_firmware_dummy.show_firmware_dummy, is_container='container', presence=False, yang_name=\"show-firmware-dummy\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'show firmware-dummy', u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"show_firmware_dummy must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=show_firmware_dummy.show_firmware_dummy, is_container='container', presence=False, yang_name=\"show-firmware-dummy\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'show firmware-dummy', u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-firmware', defining_module='brocade-firmware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__show_firmware_dummy = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_infra(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=infra.infra, is_container='container', presence=False, yang_name=\"infra\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'action': u'chassis', u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-ras-ext', defining_module='brocade-ras-ext', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"infra must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=infra.infra, is_container='container', presence=False, yang_name=\"infra\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'action': u'chassis', u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-ras-ext', defining_module='brocade-ras-ext', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__infra = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the infra variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_http(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=http.http, is_container='container', presence=False, yang_name=\"http\", rest_name=\"http\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Display HTTP/HTTPS server status'}}, namespace='urn:brocade.com:mgmt:brocade-http', defining_module='brocade-http-config', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"http must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=http.http, is_container='container', presence=False, yang_name=\"http\", rest_name=\"http\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Display HTTP/HTTPS server status'}}, namespace='urn:brocade.com:mgmt:brocade-http', defining_module='brocade-http-config', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__http = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the http property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the bpswitch property of the", "response": "def _set_bpswitch(self, v, load=False):\n    \"\"\"\n    Setter method for bpswitch, mapped from YANG variable /show/bpswitch (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bpswitch is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bpswitch() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bpswitch.bpswitch, is_container='container', presence=False, yang_name=\"bpswitch\", rest_name=\"bpswitch\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Show bpswitch related details', u'display-when': u'((/local-node/swbd-number = \"2000\") or (/local-node/swbd-number = \"2001\"))'}}, namespace='urn:brocade.com:mgmt:brocade-sysmgr', defining_module='brocade-sysmgr', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bpswitch must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bpswitch.bpswitch, is_container='container', presence=False, yang_name=\"bpswitch\", rest_name=\"bpswitch\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Show bpswitch related details', u'display-when': u'((/local-node/swbd-number = \"2000\") or (/local-node/swbd-number = \"2001\"))'}}, namespace='urn:brocade.com:mgmt:brocade-sysmgr', defining_module='brocade-sysmgr', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__bpswitch = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of the vnetwork property.", "response": "def _set_vnetwork(self, v, load=False):\n    \"\"\"\n    Setter method for vnetwork, mapped from YANG variable /show/vnetwork (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vnetwork is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vnetwork() directly.\n\n    YANG Description: Shows virtual infrastructure information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vnetwork.vnetwork, is_container='container', presence=False, yang_name=\"vnetwork\", rest_name=\"vnetwork\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Shows virtual infrastructure information', u'action': u'pgs'}}, namespace='urn:brocade.com:mgmt:brocade-vswitch', defining_module='brocade-vswitch', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vnetwork must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vnetwork.vnetwork, is_container='container', presence=False, yang_name=\"vnetwork\", rest_name=\"vnetwork\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Shows virtual infrastructure information', u'action': u'pgs'}}, namespace='urn:brocade.com:mgmt:brocade-vswitch', defining_module='brocade-vswitch', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vnetwork = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the member entry of the", "response": "def _set_member_entry(self, v, load=False):\n    \"\"\"\n    Setter method for member_entry, mapped from YANG variable /rbridge_id/secpolicy/defined_policy/policies/member_entry (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_member_entry is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_member_entry() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"member\",member_entry.member_entry, yang_name=\"member-entry\", rest_name=\"member-entry\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='member', extensions={u'tailf-common': {u'info': u'List of defined members', u'cli-suppress-list-no': None, u'callpoint': u'secpolicy_defined_policy_member', u'cli-suppress-key-abbreviation': None, u'cli-suppress-mode': None}}), is_container='list', yang_name=\"member-entry\", rest_name=\"member-entry\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined members', u'cli-suppress-list-no': None, u'callpoint': u'secpolicy_defined_policy_member', u'cli-suppress-key-abbreviation': None, u'cli-suppress-mode': None}}, namespace='urn:brocade.com:mgmt:brocade-fc-auth', defining_module='brocade-fc-auth', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"member_entry must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"member\",member_entry.member_entry, yang_name=\"member-entry\", rest_name=\"member-entry\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='member', extensions={u'tailf-common': {u'info': u'List of defined members', u'cli-suppress-list-no': None, u'callpoint': u'secpolicy_defined_policy_member', u'cli-suppress-key-abbreviation': None, u'cli-suppress-mode': None}}), is_container='list', yang_name=\"member-entry\", rest_name=\"member-entry\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined members', u'cli-suppress-list-no': None, u'callpoint': u'secpolicy_defined_policy_member', u'cli-suppress-key-abbreviation': None, u'cli-suppress-mode': None}}, namespace='urn:brocade.com:mgmt:brocade-fc-auth', defining_module='brocade-fc-auth', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__member_entry = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_protocol_type(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'udp': {'value': 17}, u'ipv6-icmp': {'value': 58}, u'tcp': {'value': 6}, u'ipv6': {'value': 41}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..255']}),], is_leaf=True, yang_name=\"protocol-type\", rest_name=\"protocol-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"protocol_type must be of a type compatible with union\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:union\",\n          'generated-type': \"\"\"YANGDynClass(base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'udp': {'value': 17}, u'ipv6-icmp': {'value': 58}, u'tcp': {'value': 6}, u'ipv6': {'value': 41}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..255']}),], is_leaf=True, yang_name=\"protocol-type\", rest_name=\"protocol-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\"\"\",\n        })\n\n    self.__protocol_type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the protocol_type of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of src_host_any_sip in the virtual network.", "response": "def _set_src_host_any_sip(self, v, load=False):\n    \"\"\"\n    Setter method for src_host_any_sip, mapped from YANG variable /ipv6_acl/ipv6/access_list/extended/seq/src_host_any_sip (union)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_src_host_any_sip is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_src_host_any_sip() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'host': {'value': 2}, u'any': {'value': 1}},),RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'((:|[0-9a-fA-F]{0,4}):)([0-9a-fA-F]{0,4}:){0,5}((([0-9a-fA-F]{0,4}:)?(:|[0-9a-fA-F]{0,4}))|(((25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])\\\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])))(/(([0-9])|([0-9]{2})|(1[0-1][0-9])|(12[0-8])))'}),], is_leaf=True, yang_name=\"src-host-any-sip\", rest_name=\"src-host-any-sip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"src_host_any_sip must be of a type compatible with union\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:union\",\n          'generated-type': \"\"\"YANGDynClass(base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'host': {'value': 2}, u'any': {'value': 1}},),RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'((:|[0-9a-fA-F]{0,4}):)([0-9a-fA-F]{0,4}:){0,5}((([0-9a-fA-F]{0,4}:)?(:|[0-9a-fA-F]{0,4}))|(((25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])\\\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])))(/(([0-9])|([0-9]{2})|(1[0-1][0-9])|(12[0-8])))'}),], is_leaf=True, yang_name=\"src-host-any-sip\", rest_name=\"src-host-any-sip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\"\"\",\n        })\n\n    self.__src_host_any_sip = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_src_host_ip(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'((:|[0-9a-fA-F]{0,4}):)([0-9a-fA-F]{0,4}:){0,5}((([0-9a-fA-F]{0,4}:)?(:|[0-9a-fA-F]{0,4}))|(((25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])\\\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])))(%[\\\\p{N}\\\\p{L}]+)?'}), is_leaf=True, yang_name=\"src-host-ip\", rest_name=\"src-host-ip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='sip', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"src_host_ip must be of a type compatible with sip\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:sip\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'((:|[0-9a-fA-F]{0,4}):)([0-9a-fA-F]{0,4}:){0,5}((([0-9a-fA-F]{0,4}:)?(:|[0-9a-fA-F]{0,4}))|(((25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])\\\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9]?[0-9])))(%[\\\\p{N}\\\\p{L}]+)?'}), is_leaf=True, yang_name=\"src-host-ip\", rest_name=\"src-host-ip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='sip', is_config=True)\"\"\",\n        })\n\n    self.__src_host_ip = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the src - host - ip of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_sport(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'lt': {'value': 3}, u'gt': {'value': 2}, u'eq': {'value': 1}, u'range': {'value': 5}, u'neq': {'value': 4}},), is_leaf=True, yang_name=\"sport\", rest_name=\"sport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-incomplete-command': None, u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-optional-in-sequence': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sport must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'lt': {'value': 3}, u'gt': {'value': 2}, u'eq': {'value': 1}, u'range': {'value': 5}, u'neq': {'value': 4}},), is_leaf=True, yang_name=\"sport\", rest_name=\"sport\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-incomplete-command': None, u'cli-drop-node-name': None, u'cli-suppress-no': None, u'cli-optional-in-sequence': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__sport = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the sport of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of sport - number - eq - tcp in the ipv6 - access - list", "response": "def _set_sport_number_eq_neq_tcp(self, v, load=False):\n    \"\"\"\n    Setter method for sport_number_eq_neq_tcp, mapped from YANG variable /ipv6_acl/ipv6/access_list/extended/seq/sport_number_eq_neq_tcp (union)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_sport_number_eq_neq_tcp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_sport_number_eq_neq_tcp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'ftp': {'value': 21}, u'domain': {'value': 53}, u'tacacs': {'value': 49}, u'hostname': {'value': 101}, u'smtp': {'value': 25}, u'www': {'value': 80}, u'telnet': {'value': 23}, u'echo': {'value': 7}, u'bgp': {'value': 179}, u'syslog': {'value': 514}, u'ftp-data': {'value': 20}, u'daytime': {'value': 13}, u'time': {'value': 37}, u'pim-auto-rp': {'value': 496}, u'login': {'value': 513}, u'talk': {'value': 517}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0 .. 65535']}),], is_leaf=True, yang_name=\"sport-number-eq-neq-tcp\", rest_name=\"sport-number-eq-neq-tcp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sport_number_eq_neq_tcp must be of a type compatible with union\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:union\",\n          'generated-type': \"\"\"YANGDynClass(base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'ftp': {'value': 21}, u'domain': {'value': 53}, u'tacacs': {'value': 49}, u'hostname': {'value': 101}, u'smtp': {'value': 25}, u'www': {'value': 80}, u'telnet': {'value': 23}, u'echo': {'value': 7}, u'bgp': {'value': 179}, u'syslog': {'value': 514}, u'ftp-data': {'value': 20}, u'daytime': {'value': 13}, u'time': {'value': 37}, u'pim-auto-rp': {'value': 496}, u'login': {'value': 513}, u'talk': {'value': 517}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0 .. 65535']}),], is_leaf=True, yang_name=\"sport-number-eq-neq-tcp\", rest_name=\"sport-number-eq-neq-tcp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\"\"\",\n        })\n\n    self.__sport_number_eq_neq_tcp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of sport - number - lt - udp in the cluster.", "response": "def _set_sport_number_lt_udp(self, v, load=False):\n    \"\"\"\n    Setter method for sport_number_lt_udp, mapped from YANG variable /ipv6_acl/ipv6/access_list/extended/seq/sport_number_lt_udp (union)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_sport_number_lt_udp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_sport_number_lt_udp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'pim-auto-rp': {'value': 496}, u'domain': {'value': 53}, u'tacacs': {'value': 49}, u'snmp': {'value': 161}, u'bootps': {'value': 67}, u'rip': {'value': 520}, u'echo': {'value': 7}, u'syslog': {'value': 514}, u'ntp': {'value': 123}, u'tftp': {'value': 69}, u'bootpc': {'value': 68}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1 .. 65535']}),], is_leaf=True, yang_name=\"sport-number-lt-udp\", rest_name=\"sport-number-lt-udp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sport_number_lt_udp must be of a type compatible with union\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:union\",\n          'generated-type': \"\"\"YANGDynClass(base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'pim-auto-rp': {'value': 496}, u'domain': {'value': 53}, u'tacacs': {'value': 49}, u'snmp': {'value': 161}, u'bootps': {'value': 67}, u'rip': {'value': 520}, u'echo': {'value': 7}, u'syslog': {'value': 514}, u'ntp': {'value': 123}, u'tftp': {'value': 69}, u'bootpc': {'value': 68}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1 .. 65535']}),], is_leaf=True, yang_name=\"sport-number-lt-udp\", rest_name=\"sport-number-lt-udp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\"\"\",\n        })\n\n    self.__sport_number_lt_udp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the DSCP field of the .", "response": "def _set_dscp(self, v, load=False):\n    \"\"\"\n    Setter method for dscp, mapped from YANG variable /ipv6_acl/ipv6/access_list/extended/seq/dscp (union)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dscp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dscp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'af23': {'value': 22}, u'af22': {'value': 20}, u'af21': {'value': 18}, u'af33': {'value': 30}, u'af41': {'value': 34}, u'af43': {'value': 38}, u'af31': {'value': 26}, u'af32': {'value': 28}, u'af42': {'value': 36}, u'af12': {'value': 12}, u'af13': {'value': 14}, u'af11': {'value': 10}, u'default': {'value': 0}, u'ef': {'value': 46}, u'cs5': {'value': 40}, u'cs4': {'value': 32}, u'cs7': {'value': 56}, u'cs6': {'value': 48}, u'cs1': {'value': 8}, u'cs3': {'value': 24}, u'cs2': {'value': 16}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..63']}),], is_leaf=True, yang_name=\"dscp\", rest_name=\"dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Differentiated Service Code Point', u'cli-optional-in-sequence': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dscp must be of a type compatible with union\"\"\",\n          'defined-type': \"brocade-ipv6-access-list:union\",\n          'generated-type': \"\"\"YANGDynClass(base=[RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'af23': {'value': 22}, u'af22': {'value': 20}, u'af21': {'value': 18}, u'af33': {'value': 30}, u'af41': {'value': 34}, u'af43': {'value': 38}, u'af31': {'value': 26}, u'af32': {'value': 28}, u'af42': {'value': 36}, u'af12': {'value': 12}, u'af13': {'value': 14}, u'af11': {'value': 10}, u'default': {'value': 0}, u'ef': {'value': 46}, u'cs5': {'value': 40}, u'cs4': {'value': 32}, u'cs7': {'value': 56}, u'cs6': {'value': 48}, u'cs1': {'value': 8}, u'cs3': {'value': 24}, u'cs2': {'value': 16}},),RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..63']}),], is_leaf=True, yang_name=\"dscp\", rest_name=\"dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Differentiated Service Code Point', u'cli-optional-in-sequence': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='union', is_config=True)\"\"\",\n        })\n\n    self.__dscp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_drop_precedence_force(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..2']}), is_leaf=True, yang_name=\"drop-precedence-force\", rest_name=\"drop-precedence-force\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Force drop precedence', u'cli-optional-in-sequence': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='ip-access-list:drop-prec-uint', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"drop_precedence_force must be of a type compatible with ip-access-list:drop-prec-uint\"\"\",\n          'defined-type': \"ip-access-list:drop-prec-uint\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..2']}), is_leaf=True, yang_name=\"drop-precedence-force\", rest_name=\"drop-precedence-force\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Force drop precedence', u'cli-optional-in-sequence': None, u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ipv6-access-list', defining_module='brocade-ipv6-access-list', yang_type='ip-access-list:drop-prec-uint', is_config=True)\"\"\",\n        })\n\n    self.__drop_precedence_force = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the drop precedence force for the given node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the port_id of the based on the port_id field.", "response": "def _set_port_id(self, v, load=False):\n    \"\"\"\n    Setter method for port_id, mapped from YANG variable /dpod/port_id (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_port_id is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_port_id() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"port_id\",port_id.port_id, yang_name=\"port-id\", rest_name=\"port-id\", parent=self, is_container='list', user_ordered=True, path_helper=self._path_helper, yang_keys='port-id', extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'licensePod_callpoint'}}), is_container='list', yang_name=\"port-id\", rest_name=\"port-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'licensePod_callpoint'}}, namespace='urn:brocade.com:mgmt:brocade-license', defining_module='brocade-license', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"port_id must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"port_id\",port_id.port_id, yang_name=\"port-id\", rest_name=\"port-id\", parent=self, is_container='list', user_ordered=True, path_helper=self._path_helper, yang_keys='port-id', extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'licensePod_callpoint'}}), is_container='list', yang_name=\"port-id\", rest_name=\"port-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'callpoint': u'licensePod_callpoint'}}, namespace='urn:brocade.com:mgmt:brocade-license', defining_module='brocade-license', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__port_id = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of evpn_instance mapped from YANG variable instance_name", "response": "def _set_evpn_instance(self, v, load=False):\n    \"\"\"\n    Setter method for evpn_instance, mapped from YANG variable /routing_system/evpn_config/evpn/evpn_instance (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_evpn_instance is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_evpn_instance() directly.\n\n    YANG Description: EVPN instance config\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"instance_name\",evpn_instance.evpn_instance, yang_name=\"evpn-instance\", rest_name=\"evpn-instance\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='instance-name', extensions={u'tailf-common': {u'info': u'Evpn instance config', u'callpoint': u'EvpnInstances', u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"evpn-instance\", rest_name=\"evpn-instance\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Evpn instance config', u'callpoint': u'EvpnInstances', u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"evpn_instance must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"instance_name\",evpn_instance.evpn_instance, yang_name=\"evpn-instance\", rest_name=\"evpn-instance\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='instance-name', extensions={u'tailf-common': {u'info': u'Evpn instance config', u'callpoint': u'EvpnInstances', u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}), is_container='list', yang_name=\"evpn-instance\", rest_name=\"evpn-instance\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Evpn instance config', u'callpoint': u'EvpnInstances', u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__evpn_instance = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_mac_address(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mac_address.mac_address, is_container='container', presence=False, yang_name=\"mac-address\", rest_name=\"mac-address\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC Address'}}, namespace='urn:brocade.com:mgmt:brocade-bridge-domain', defining_module='brocade-bridge-domain', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mac_address must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mac_address.mac_address, is_container='container', presence=False, yang_name=\"mac-address\", rest_name=\"mac-address\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC Address'}}, namespace='urn:brocade.com:mgmt:brocade-bridge-domain', defining_module='brocade-bridge-domain', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mac_address = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the MAC Address of the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of _breakout", "response": "def _set_breakout(self, v, load=False):\n    \"\"\"\n    Setter method for breakout, mapped from YANG variable /hardware/connector/breakout (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_breakout is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_breakout() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=breakout.breakout, is_container='container', presence=True, yang_name=\"breakout\", rest_name=\"breakout\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable connector breakout', u'cli-show-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"breakout must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=breakout.breakout, is_container='container', presence=True, yang_name=\"breakout\", rest_name=\"breakout\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable connector breakout', u'cli-show-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-hardware', defining_module='brocade-hardware', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__breakout = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_basic(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=basic.basic, is_container='container', presence=False, yang_name=\"basic\", rest_name=\"basic\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-basic', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"basic must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=basic.basic, is_container='container', presence=False, yang_name=\"basic\", rest_name=\"basic\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-basic', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__basic = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the basic property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_forwarding(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=forwarding.forwarding, is_container='container', presence=False, yang_name=\"forwarding\", rest_name=\"forwarding\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-forwarding', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"forwarding must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=forwarding.forwarding, is_container='container', presence=False, yang_name=\"forwarding\", rest_name=\"forwarding\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-forwarding', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__forwarding = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the forwarding information for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the FRR field of the .", "response": "def _set_frr(self, v, load=False):\n    \"\"\"\n    Setter method for frr, mapped from YANG variable /mpls_state/lsp/frr (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_frr is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_frr() directly.\n\n    YANG Description: MPLS LSP FRR information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=frr.frr, is_container='container', presence=False, yang_name=\"frr\", rest_name=\"frr\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-frr', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"frr must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=frr.frr, is_container='container', presence=False, yang_name=\"frr\", rest_name=\"frr\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-frr', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__frr = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets backup state of the", "response": "def _set_backup(self, v, load=False):\n    \"\"\"\n    Setter method for backup, mapped from YANG variable /mpls_state/lsp/backup (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_backup is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_backup() directly.\n\n    YANG Description: MPLS LSP detail backup information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=backup.backup, is_container='container', presence=False, yang_name=\"backup\", rest_name=\"backup\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-backup', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"backup must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=backup.backup, is_container='container', presence=False, yang_name=\"backup\", rest_name=\"backup\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-lsp-backup', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__backup = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the bd - vc - peer - counter property.", "response": "def _set_bd_vc_peer_counter(self, v, load=False):\n    \"\"\"\n    Setter method for bd_vc_peer_counter, mapped from YANG variable /bd_vc_peer_state/bd_vc_peer_counter (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bd_vc_peer_counter is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bd_vc_peer_counter() directly.\n\n    YANG Description:  VC peer counters\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bd_vc_peer_counter.bd_vc_peer_counter, is_container='container', presence=False, yang_name=\"bd-vc-peer-counter\", rest_name=\"bd-vc-peer-counter\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'pwm-bd-vc-peer-counter', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-pwm-operational', defining_module='brocade-pwm-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bd_vc_peer_counter must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bd_vc_peer_counter.bd_vc_peer_counter, is_container='container', presence=False, yang_name=\"bd-vc-peer-counter\", rest_name=\"bd-vc-peer-counter\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'pwm-bd-vc-peer-counter', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-pwm-operational', defining_module='brocade-pwm-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__bd_vc_peer_counter = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the logicalgroup of the", "response": "def _set_logicalgroup(self, v, load=False):\n    \"\"\"\n    Setter method for logicalgroup, mapped from YANG variable /rbridge_id/maps/logicalgroup (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_logicalgroup is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_logicalgroup() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"logicalgroupname\",logicalgroup.logicalgroup, yang_name=\"logicalgroup\", rest_name=\"group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='logicalgroupname', extensions={u'tailf-common': {u'info': u'Configure (logical) group', u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'group', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsLogicalgroup'}}), is_container='list', yang_name=\"logicalgroup\", rest_name=\"group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure (logical) group', u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'group', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsLogicalgroup'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"logicalgroup must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"logicalgroupname\",logicalgroup.logicalgroup, yang_name=\"logicalgroup\", rest_name=\"group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='logicalgroupname', extensions={u'tailf-common': {u'info': u'Configure (logical) group', u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'group', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsLogicalgroup'}}), is_container='list', yang_name=\"logicalgroup\", rest_name=\"group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure (logical) group', u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'group', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsLogicalgroup'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__logicalgroup = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_rule(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"rulename\",rule.rule, yang_name=\"rule\", rest_name=\"rule\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rulename', extensions={u'tailf-common': {u'info': u'Configure Rule', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsRule'}}), is_container='list', yang_name=\"rule\", rest_name=\"rule\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Rule', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsRule'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rule must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"rulename\",rule.rule, yang_name=\"rule\", rest_name=\"rule\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='rulename', extensions={u'tailf-common': {u'info': u'Configure Rule', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsRule'}}), is_container='list', yang_name=\"rule\", rest_name=\"rule\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Rule', u'cli-suppress-mode': None, u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MapsRule'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__rule = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the rule of the\n    based on the given list of rulenames."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the policy of the based on the given list of policy parameters.", "response": "def _set_policy(self, v, load=False):\n    \"\"\"\n    Setter method for policy, mapped from YANG variable /rbridge_id/maps/policy (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_policy is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_policy() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"policyname\",policy.policy, yang_name=\"policy\", rest_name=\"policy\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='policyname', extensions={u'tailf-common': {u'info': u'Configure Policy', u'callpoint': u'MapsPolicy'}}), is_container='list', yang_name=\"policy\", rest_name=\"policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Policy', u'callpoint': u'MapsPolicy'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"policy must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"policyname\",policy.policy, yang_name=\"policy\", rest_name=\"policy\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='policyname', extensions={u'tailf-common': {u'info': u'Configure Policy', u'callpoint': u'MapsPolicy'}}), is_container='list', yang_name=\"policy\", rest_name=\"policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Policy', u'callpoint': u'MapsPolicy'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__policy = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_relay(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"hostip\",relay.relay, yang_name=\"relay\", rest_name=\"relay\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='hostip', extensions={u'tailf-common': {u'info': u'Configure relay ip mail settings', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'maps_relay_callpoint'}}), is_container='list', yang_name=\"relay\", rest_name=\"relay\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure relay ip mail settings', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'maps_relay_callpoint'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"relay must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"hostip\",relay.relay, yang_name=\"relay\", rest_name=\"relay\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='hostip', extensions={u'tailf-common': {u'info': u'Configure relay ip mail settings', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'maps_relay_callpoint'}}), is_container='list', yang_name=\"relay\", rest_name=\"relay\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure relay ip mail settings', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'maps_relay_callpoint'}}, namespace='urn:brocade.com:mgmt:brocade-maps', defining_module='brocade-maps', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__relay = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the relay property."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the interval of the SPF IPv6 addresses.", "response": "def _set_spf6_interval(self, v, load=False):\n    \"\"\"\n    Setter method for spf6_interval, mapped from YANG variable /routing_system/router/isis/router_isis_cmds_holder/address_family/ipv6/af_ipv6_unicast/af_ipv6_attributes/spf6_interval (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_spf6_interval is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_spf6_interval() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"spf6_interval_level\",spf6_interval.spf6_interval, yang_name=\"spf6-interval\", rest_name=\"spf-interval\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='spf6-interval-level', extensions={u'tailf-common': {u'info': u'SPF calculation Timers', u'cli-full-no': None, u'callpoint': u'IsisSpf6Interval', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'alt-name': u'spf-interval'}}), is_container='list', yang_name=\"spf6-interval\", rest_name=\"spf-interval\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'SPF calculation Timers', u'cli-full-no': None, u'callpoint': u'IsisSpf6Interval', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'alt-name': u'spf-interval'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"spf6_interval must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"spf6_interval_level\",spf6_interval.spf6_interval, yang_name=\"spf6-interval\", rest_name=\"spf-interval\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='spf6-interval-level', extensions={u'tailf-common': {u'info': u'SPF calculation Timers', u'cli-full-no': None, u'callpoint': u'IsisSpf6Interval', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'alt-name': u'spf-interval'}}), is_container='list', yang_name=\"spf6-interval\", rest_name=\"spf-interval\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'SPF calculation Timers', u'cli-full-no': None, u'callpoint': u'IsisSpf6Interval', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-suppress-mode': None, u'cli-suppress-key-abbreviation': None, u'cli-incomplete-command': None, u'alt-name': u'spf-interval'}}, namespace='urn:brocade.com:mgmt:brocade-isis', defining_module='brocade-isis', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__spf6_interval = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_member_vlan(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=member_vlan.member_vlan, is_container='container', presence=False, yang_name=\"member-vlan\", rest_name=\"member-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Member VLANs for this topology group', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-topology-group', defining_module='brocade-topology-group', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"member_vlan must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=member_vlan.member_vlan, is_container='container', presence=False, yang_name=\"member-vlan\", rest_name=\"member-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Member VLANs for this topology group', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-topology-group', defining_module='brocade-topology-group', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__member_vlan = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the member vlan of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_member_bridge_domain(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=member_bridge_domain.member_bridge_domain, is_container='container', presence=False, yang_name=\"member-bridge-domain\", rest_name=\"member-bridge-domain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Member Bridge Domains for this topology group', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-topology-group', defining_module='brocade-topology-group', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"member_bridge_domain must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=member_bridge_domain.member_bridge_domain, is_container='container', presence=False, yang_name=\"member-bridge-domain\", rest_name=\"member-bridge-domain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Member Bridge Domains for this topology group', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-topology-group', defining_module='brocade-topology-group', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__member_bridge_domain = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the member bridge domain for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_community_map(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"community\",community_map.community_map, yang_name=\"community-map\", rest_name=\"community-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='community', extensions={u'tailf-common': {u'info': u'community string to map', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'snmpcommunitymapping'}}), is_container='list', yang_name=\"community-map\", rest_name=\"community-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'community string to map', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'snmpcommunitymapping'}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"community_map must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"community\",community_map.community_map, yang_name=\"community-map\", rest_name=\"community-map\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='community', extensions={u'tailf-common': {u'info': u'community string to map', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'snmpcommunitymapping'}}), is_container='list', yang_name=\"community-map\", rest_name=\"community-map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'community string to map', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'snmpcommunitymapping'}}, namespace='urn:brocade.com:mgmt:brocade-snmp', defining_module='brocade-snmp', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__community_map = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the community map for the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_get_last_config_update_time(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=get_last_config_update_time.get_last_config_update_time, is_leaf=True, yang_name=\"get-last-config-update-time\", rest_name=\"get-last-config-update-time\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'last-config-update-time-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"get_last_config_update_time must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=get_last_config_update_time.get_last_config_update_time, is_leaf=True, yang_name=\"get-last-config-update-time\", rest_name=\"get-last-config-update-time\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'last-config-update-time-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__get_last_config_update_time = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "This method is used to set the last config update time of the \nconfigutation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the show_vcs field of the cluster.", "response": "def _set_show_vcs(self, v, load=False):\n    \"\"\"\n    Setter method for show_vcs, mapped from YANG variable /brocade_vcs_rpc/show_vcs (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_show_vcs is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_show_vcs() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=show_vcs.show_vcs, is_leaf=True, yang_name=\"show-vcs\", rest_name=\"show-vcs\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getclusterinfo-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"show_vcs must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=show_vcs.show_vcs, is_leaf=True, yang_name=\"show-vcs\", rest_name=\"show-vcs\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getclusterinfo-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__show_vcs = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_get_vcs_details(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=get_vcs_details.get_vcs_details, is_leaf=True, yang_name=\"get-vcs-details\", rest_name=\"get-vcs-details\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getvcsdetails-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"get_vcs_details must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=get_vcs_details.get_vcs_details, is_leaf=True, yang_name=\"get-vcs-details\", rest_name=\"get-vcs-details\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'getvcsdetails-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__get_vcs_details = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Setter method for get_vcs_details, mapped from YANG variable /brocade_vcs_rpc/get_vcs_details (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_get_vcs_details is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_get_vcs_details() directly."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_vcs_rbridge_config(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vcs_rbridge_config.vcs_rbridge_config, is_leaf=True, yang_name=\"vcs-rbridge-config\", rest_name=\"vcs-rbridge-config\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'vcsenable-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vcs_rbridge_config must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=vcs_rbridge_config.vcs_rbridge_config, is_leaf=True, yang_name=\"vcs-rbridge-config\", rest_name=\"vcs-rbridge-config\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'vcsenable-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__vcs_rbridge_config = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the vcs - rbridge - config for the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of the property.", "response": "def _set_vcs_rbridge_context(self, v, load=False):\n    \"\"\"\n    Setter method for vcs_rbridge_context, mapped from YANG variable /brocade_vcs_rpc/vcs_rbridge_context (rpc)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vcs_rbridge_context is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vcs_rbridge_context() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vcs_rbridge_context.vcs_rbridge_context, is_leaf=True, yang_name=\"vcs-rbridge-context\", rest_name=\"vcs-rbridge-context\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'vcscontextrbridgeid-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vcs_rbridge_context must be of a type compatible with rpc\"\"\",\n          'defined-type': \"rpc\",\n          'generated-type': \"\"\"YANGDynClass(base=vcs_rbridge_context.vcs_rbridge_context, is_leaf=True, yang_name=\"vcs-rbridge-context\", rest_name=\"vcs-rbridge-context\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=False, extensions={u'tailf-common': {u'hidden': u'rpccmd', u'actionpoint': u'vcscontextrbridgeid-action-point'}}, namespace='urn:brocade.com:mgmt:brocade-vcs', defining_module='brocade-vcs', yang_type='rpc', is_config=True)\"\"\",\n        })\n\n    self.__vcs_rbridge_context = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_event_handler(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=event_handler.event_handler, is_container='container', presence=False, yang_name=\"event-handler\", rest_name=\"event-handler\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'event-handler-callpoint'}}, namespace='urn:brocade.com:mgmt:brocade-event-handler', defining_module='brocade-event-handler', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"event_handler must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=event_handler.event_handler, is_container='container', presence=False, yang_name=\"event-handler\", rest_name=\"event-handler\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'event-handler-callpoint'}}, namespace='urn:brocade.com:mgmt:brocade-event-handler', defining_module='brocade-event-handler', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__event_handler = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the event handler for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset hide_intf_loopback_holder to True if the variable is read - only.", "response": "def _set_hide_intf_loopback_holder(self, v, load=False):\n    \"\"\"\n    Setter method for hide_intf_loopback_holder, mapped from YANG variable /hide_intf_loopback_holder (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_hide_intf_loopback_holder is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_hide_intf_loopback_holder() directly.\n\n    YANG Description: An intermediary node that separates the loopback related \nmanaged objects from rest of the interface types.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=hide_intf_loopback_holder.hide_intf_loopback_holder, is_container='container', presence=False, yang_name=\"hide-intf-loopback-holder\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_LEVEL_INTERFACE_LOOPBACK_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-intf-loopback', defining_module='brocade-intf-loopback', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"hide_intf_loopback_holder must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=hide_intf_loopback_holder.hide_intf_loopback_holder, is_container='container', presence=False, yang_name=\"hide-intf-loopback-holder\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'sort-priority': u'RUNNCFG_LEVEL_INTERFACE_LOOPBACK_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-intf-loopback', defining_module='brocade-intf-loopback', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__hide_intf_loopback_holder = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the reserved vlan of the node.", "response": "def _set_reserved_vlan(self, v, load=False):\n    \"\"\"\n    Setter method for reserved_vlan, mapped from YANG variable /reserved_vlan (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_reserved_vlan is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_reserved_vlan() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=reserved_vlan.reserved_vlan, is_container='container', presence=False, yang_name=\"reserved-vlan\", rest_name=\"reserved-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Sets the range of vlans used for internal purposes', u'sort-priority': u'RUNNCFG_LEVEL_INTERFACE_VLAN_CONFIG', u'cli-suppress-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'callpoint': u'nsmReservedVlanConfig'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"reserved_vlan must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=reserved_vlan.reserved_vlan, is_container='container', presence=False, yang_name=\"reserved-vlan\", rest_name=\"reserved-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Sets the range of vlans used for internal purposes', u'sort-priority': u'RUNNCFG_LEVEL_INTERFACE_VLAN_CONFIG', u'cli-suppress-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'callpoint': u'nsmReservedVlanConfig'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__reserved_vlan = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the role of the", "response": "def _set_role(self, v, load=False):\n    \"\"\"\n    Setter method for role, mapped from YANG variable /role (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_role is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_role() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=role.role, is_container='container', presence=False, yang_name=\"role\", rest_name=\"role\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Role configuration', u'cli-incomplete-no': None, u'sort-priority': u'9'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"role must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=role.role, is_container='container', presence=False, yang_name=\"role\", rest_name=\"role\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Role configuration', u'cli-incomplete-no': None, u'sort-priority': u'9'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__role = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the radius server for the cluster.", "response": "def _set_radius_server(self, v, load=False):\n    \"\"\"\n    Setter method for radius_server, mapped from YANG variable /radius_server (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_radius_server is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_radius_server() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=radius_server.radius_server, is_container='container', presence=False, yang_name=\"radius-server\", rest_name=\"radius-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'RADIUS server configuration', u'cli-incomplete-no': None, u'sort-priority': u'10'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"radius_server must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=radius_server.radius_server, is_container='container', presence=False, yang_name=\"radius-server\", rest_name=\"radius-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'RADIUS server configuration', u'cli-incomplete-no': None, u'sort-priority': u'10'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__radius_server = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_tacacs_server(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tacacs_server.tacacs_server, is_container='container', presence=False, yang_name=\"tacacs-server\", rest_name=\"tacacs-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'TACACS+ server configuration', u'cli-incomplete-no': None, u'sort-priority': u'11'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tacacs_server must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tacacs_server.tacacs_server, is_container='container', presence=False, yang_name=\"tacacs-server\", rest_name=\"tacacs-server\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'TACACS+ server configuration', u'cli-incomplete-no': None, u'sort-priority': u'11'}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tacacs_server = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the tacacs_server variable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_password_attributes(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=password_attributes.password_attributes, is_container='container', presence=False, yang_name=\"password-attributes\", rest_name=\"password-attributes\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure system wide user password attributes', u'sort-priority': u'8', u'callpoint': u'password_attributes_cp', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"password_attributes must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=password_attributes.password_attributes, is_container='container', presence=False, yang_name=\"password-attributes\", rest_name=\"password-attributes\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure system wide user password attributes', u'sort-priority': u'8', u'callpoint': u'password_attributes_cp', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__password_attributes = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the password attributes of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the banner of the", "response": "def _set_banner(self, v, load=False):\n    \"\"\"\n    Setter method for banner, mapped from YANG variable /banner (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_banner is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_banner() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=banner.banner, is_container='container', presence=False, yang_name=\"banner\", rest_name=\"banner\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Banner message', u'sort-priority': u'7', u'callpoint': u'banner_cp', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"banner must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=banner.banner, is_container='container', presence=False, yang_name=\"banner\", rest_name=\"banner\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Banner message', u'sort-priority': u'7', u'callpoint': u'banner_cp', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__banner = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_openflow_controller(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"controller_name\",openflow_controller.openflow_controller, yang_name=\"openflow-controller\", rest_name=\"openflow-controller\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='controller-name', extensions={u'tailf-common': {u'info': u'OpenFlow controller configuration', u'cli-no-key-completion': None, u'sort-priority': u'66', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'callpoint': u'OpenFlowGlobalController'}}), is_container='list', yang_name=\"openflow-controller\", rest_name=\"openflow-controller\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'OpenFlow controller configuration', u'cli-no-key-completion': None, u'sort-priority': u'66', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'callpoint': u'OpenFlowGlobalController'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"openflow_controller must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"controller_name\",openflow_controller.openflow_controller, yang_name=\"openflow-controller\", rest_name=\"openflow-controller\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='controller-name', extensions={u'tailf-common': {u'info': u'OpenFlow controller configuration', u'cli-no-key-completion': None, u'sort-priority': u'66', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'callpoint': u'OpenFlowGlobalController'}}), is_container='list', yang_name=\"openflow-controller\", rest_name=\"openflow-controller\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'OpenFlow controller configuration', u'cli-no-key-completion': None, u'sort-priority': u'66', u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'cli-no-match-completion': None, u'callpoint': u'OpenFlowGlobalController'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__openflow_controller = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the openflow_controller variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_minimum_links(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1 .. 64']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(1), is_leaf=True, yang_name=\"minimum-links\", rest_name=\"minimum-links\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'interface_po', u'info': u'Least number of operationally UP links to declare \\nport-channel UP', u'display-when': u'not(../insight/insight-enable)'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"minimum_links must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1 .. 64']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(1), is_leaf=True, yang_name=\"minimum-links\", rest_name=\"minimum-links\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'interface_po', u'info': u'Least number of operationally UP links to declare \\nport-channel UP', u'display-when': u'not(../insight/insight-enable)'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__minimum_links = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the minimum_links of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_tvf_domain(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tvf_domain.tvf_domain, is_container='container', presence=False, yang_name=\"tvf-domain\", rest_name=\"tvf-domain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'TVF Domain configuration', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tvf_domain must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tvf_domain.tvf_domain, is_container='container', presence=False, yang_name=\"tvf-domain\", rest_name=\"tvf-domain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'TVF Domain configuration', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tvf_domain = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the TVF domain of the node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_npb(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=npb.npb, is_container='container', presence=False, yang_name=\"npb\", rest_name=\"npb\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'NPB', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"npb must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=npb.npb, is_container='container', presence=False, yang_name=\"npb\", rest_name=\"npb\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'NPB', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__npb = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the NPB field of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_ospf(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"vrf\",ospf.ospf, yang_name=\"ospf\", rest_name=\"ospf\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='vrf', extensions={u'tailf-common': {u'info': u'Open Shortest Path First (OSPF) version 3', u'cli-run-template-enter': u' ipv6 router ospf$($(vrf)==default-vrf?: vrf $(vrf))\\n', u'callpoint': u'Ospfv3Config', u'cli-suppress-list-no': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-ipv6-router-ospf-vrf-$(vrf)'}}), is_container='list', yang_name=\"ospf\", rest_name=\"ospf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Open Shortest Path First (OSPF) version 3', u'cli-run-template-enter': u' ipv6 router ospf$($(vrf)==default-vrf?: vrf $(vrf))\\n', u'callpoint': u'Ospfv3Config', u'cli-suppress-list-no': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-ipv6-router-ospf-vrf-$(vrf)'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ospf must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"vrf\",ospf.ospf, yang_name=\"ospf\", rest_name=\"ospf\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='vrf', extensions={u'tailf-common': {u'info': u'Open Shortest Path First (OSPF) version 3', u'cli-run-template-enter': u' ipv6 router ospf$($(vrf)==default-vrf?: vrf $(vrf))\\n', u'callpoint': u'Ospfv3Config', u'cli-suppress-list-no': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-ipv6-router-ospf-vrf-$(vrf)'}}), is_container='list', yang_name=\"ospf\", rest_name=\"ospf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Open Shortest Path First (OSPF) version 3', u'cli-run-template-enter': u' ipv6 router ospf$($(vrf)==default-vrf?: vrf $(vrf))\\n', u'callpoint': u'Ospfv3Config', u'cli-suppress-list-no': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-ipv6-router-ospf-vrf-$(vrf)'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ospf = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of OSPF mapped from YANG variable VRF to OSPF list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the path hop of the based on the given list of path hop ips.", "response": "def _set_path_hop(self, v, load=False):\n    \"\"\"\n    Setter method for path_hop, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/path/path_hop (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_path_hop is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_path_hop() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"path_hop_ip\",path_hop.path_hop, yang_name=\"path-hop\", rest_name=\"hop\", parent=self, is_container='list', user_ordered=True, path_helper=self._path_helper, yang_keys='path-hop-ip', extensions={u'tailf-common': {u'info': u'Configure path strict or loose hops', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'hop', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathHop'}}), is_container='list', yang_name=\"path-hop\", rest_name=\"hop\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure path strict or loose hops', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'hop', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathHop'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"path_hop must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"path_hop_ip\",path_hop.path_hop, yang_name=\"path-hop\", rest_name=\"hop\", parent=self, is_container='list', user_ordered=True, path_helper=self._path_helper, yang_keys='path-hop-ip', extensions={u'tailf-common': {u'info': u'Configure path strict or loose hops', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'hop', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathHop'}}), is_container='list', yang_name=\"path-hop\", rest_name=\"hop\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure path strict or loose hops', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-full-no': None, u'alt-name': u'hop', u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathHop'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__path_hop = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of path_insert for the", "response": "def _set_path_insert(self, v, load=False):\n    \"\"\"\n    Setter method for path_insert, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/path/path_insert (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_path_insert is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_path_insert() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"path_insert_ip\",path_insert.path_insert, yang_name=\"path-insert\", rest_name=\"insert\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='path-insert-ip', extensions={u'tailf-common': {u'info': u'Insert path strict or loose hops', u'cli-suppress-mode': None, u'cli-suppress-no': None, u'alt-name': u'insert', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathInsert'}}), is_container='list', yang_name=\"path-insert\", rest_name=\"insert\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Insert path strict or loose hops', u'cli-suppress-mode': None, u'cli-suppress-no': None, u'alt-name': u'insert', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathInsert'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"path_insert must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"path_insert_ip\",path_insert.path_insert, yang_name=\"path-insert\", rest_name=\"insert\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='path-insert-ip', extensions={u'tailf-common': {u'info': u'Insert path strict or loose hops', u'cli-suppress-mode': None, u'cli-suppress-no': None, u'alt-name': u'insert', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathInsert'}}), is_container='list', yang_name=\"path-insert\", rest_name=\"insert\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Insert path strict or loose hops', u'cli-suppress-mode': None, u'cli-suppress-no': None, u'alt-name': u'insert', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'MplsPathInsert'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__path_insert = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the ldp_ecmp field of the cluster.", "response": "def _set_ldp_ecmp(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_ecmp, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp/ldp_holder/ldp_ecmp (uint32)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_ecmp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_ecmp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..16']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(1), is_leaf=True, yang_name=\"ldp-ecmp\", rest_name=\"load-sharing\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Number of load-sharing paths: range 1-16, default is 1', u'cli-full-no': None, u'alt-name': u'load-sharing'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_ecmp must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..16']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(1), is_leaf=True, yang_name=\"ldp-ecmp\", rest_name=\"load-sharing\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Number of load-sharing paths: range 1-16, default is 1', u'cli-full-no': None, u'alt-name': u'load-sharing'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__ldp_ecmp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_ldp_hello_interval_basic(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..32767']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(5), is_leaf=True, yang_name=\"ldp-hello-interval-basic\", rest_name=\"hello-interval-link\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'In seconds (1-32767, default 5)', u'cli-full-no': None, u'alt-name': u'hello-interval-link'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_hello_interval_basic must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1..32767']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(5), is_leaf=True, yang_name=\"ldp-hello-interval-basic\", rest_name=\"hello-interval-link\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'In seconds (1-32767, default 5)', u'cli-full-no': None, u'alt-name': u'hello-interval-link'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__ldp_hello_interval_basic = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ldp_hello_interval_basic variable in the MPL file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_ldp_hello_timeout_basic(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'2..65535']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(15), is_leaf=True, yang_name=\"ldp-hello-timeout-basic\", rest_name=\"hello-timeout-link\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'In seconds (2-65535, default 15)', u'cli-full-no': None, u'alt-name': u'hello-timeout-link'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_hello_timeout_basic must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'2..65535']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(15), is_leaf=True, yang_name=\"ldp-hello-timeout-basic\", rest_name=\"hello-timeout-link\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'In seconds (2-65535, default 15)', u'cli-full-no': None, u'alt-name': u'hello-timeout-link'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__ldp_hello_timeout_basic = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ldp_hello_timeout_basic variable in the MPL file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the LDP LSR id for the given IP address.", "response": "def _set_ldp_lsr_id(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_lsr_id, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp/ldp_holder/ldp_lsr_id (inet:ipv4-address)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_lsr_id is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_lsr_id() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])(%[\\\\p{N}\\\\p{L}]+)?'}), is_leaf=True, yang_name=\"ldp-lsr-id\", rest_name=\"lsr-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set IP address to be used as LSR id for LDP', u'cli-full-no': None, u'alt-name': u'lsr-id'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='inet:ipv4-address', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_lsr_id must be of a type compatible with inet:ipv4-address\"\"\",\n          'defined-type': \"inet:ipv4-address\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.){3}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])(%[\\\\p{N}\\\\p{L}]+)?'}), is_leaf=True, yang_name=\"ldp-lsr-id\", rest_name=\"lsr-id\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set IP address to be used as LSR id for LDP', u'cli-full-no': None, u'alt-name': u'lsr-id'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='inet:ipv4-address', is_config=True)\"\"\",\n        })\n\n    self.__ldp_lsr_id = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the ldp session for the cluster.", "response": "def _set_ldp_session(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_session, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp/ldp_holder/ldp_session (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_session is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_session() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"ldp_session_ip\",ldp_session.ldp_session, yang_name=\"ldp-session\", rest_name=\"session\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ldp-session-ip', extensions={u'tailf-common': {u'info': u'Define LDP Session', u'cli-suppress-list-no': None, u'alt-name': u'session', u'callpoint': u'MplsLdpSession', u'cli-mode-name': u'config-router-mpls-ldp-session-$(ldp-session-ip)'}}), is_container='list', yang_name=\"ldp-session\", rest_name=\"session\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define LDP Session', u'cli-suppress-list-no': None, u'alt-name': u'session', u'callpoint': u'MplsLdpSession', u'cli-mode-name': u'config-router-mpls-ldp-session-$(ldp-session-ip)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_session must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"ldp_session_ip\",ldp_session.ldp_session, yang_name=\"ldp-session\", rest_name=\"session\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ldp-session-ip', extensions={u'tailf-common': {u'info': u'Define LDP Session', u'cli-suppress-list-no': None, u'alt-name': u'session', u'callpoint': u'MplsLdpSession', u'cli-mode-name': u'config-router-mpls-ldp-session-$(ldp-session-ip)'}}), is_container='list', yang_name=\"ldp-session\", rest_name=\"session\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define LDP Session', u'cli-suppress-list-no': None, u'alt-name': u'session', u'callpoint': u'MplsLdpSession', u'cli-mode-name': u'config-router-mpls-ldp-session-$(ldp-session-ip)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ldp_session = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the ldp targeted peer in the order of their IP address.", "response": "def _set_ldp_targeted_peer(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_targeted_peer, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp/ldp_holder/ldp_targeted_peer (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_targeted_peer is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_targeted_peer() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"ldp_targeted_peer_ip\",ldp_targeted_peer.ldp_targeted_peer, yang_name=\"ldp-targeted-peer\", rest_name=\"targeted-peer\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ldp-targeted-peer-ip', extensions={u'tailf-common': {u'info': u'IP address of the targeted peer', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'MplsLdpTargetedPeer', u'alt-name': u'targeted-peer'}}), is_container='list', yang_name=\"ldp-targeted-peer\", rest_name=\"targeted-peer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IP address of the targeted peer', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'MplsLdpTargetedPeer', u'alt-name': u'targeted-peer'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_targeted_peer must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"ldp_targeted_peer_ip\",ldp_targeted_peer.ldp_targeted_peer, yang_name=\"ldp-targeted-peer\", rest_name=\"targeted-peer\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ldp-targeted-peer-ip', extensions={u'tailf-common': {u'info': u'IP address of the targeted peer', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'MplsLdpTargetedPeer', u'alt-name': u'targeted-peer'}}), is_container='list', yang_name=\"ldp-targeted-peer\", rest_name=\"targeted-peer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IP address of the targeted peer', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'callpoint': u'MplsLdpTargetedPeer', u'alt-name': u'targeted-peer'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ldp_targeted_peer = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the ldp_rcv_label_silence_time field in the last NDP message", "response": "def _set_ldp_rcv_label_silence_time(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_rcv_label_silence_time, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp/ldp_holder/ldp_rcv_label_silence_time (uint32)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_rcv_label_silence_time is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_rcv_label_silence_time() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'100..60000']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(1000), is_leaf=True, yang_name=\"ldp-rcv-label-silence-time\", rest_name=\"rx-label-silence-timer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Receive label silence time (100-60000 ms)', u'cli-full-no': None, u'alt-name': u'rx-label-silence-timer'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_rcv_label_silence_time must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'100..60000']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(1000), is_leaf=True, yang_name=\"ldp-rcv-label-silence-time\", rest_name=\"rx-label-silence-timer\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Receive label silence time (100-60000 ms)', u'cli-full-no': None, u'alt-name': u'rx-label-silence-timer'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__ldp_rcv_label_silence_time = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the ldp_gr property of the base node.", "response": "def _set_ldp_gr(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_gr, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp/ldp_holder/ldp_gr (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_gr is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_gr() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_gr.ldp_gr, is_container='container', presence=True, yang_name=\"ldp-gr\", rest_name=\"graceful-restart\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enter MPLS LDP GR Config mode', u'alt-name': u'graceful-restart', u'callpoint': u'MplsLdpGr', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-ldp-gr'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_gr must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_gr.ldp_gr, is_container='container', presence=True, yang_name=\"ldp-gr\", rest_name=\"graceful-restart\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enter MPLS LDP GR Config mode', u'alt-name': u'graceful-restart', u'callpoint': u'MplsLdpGr', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-ldp-gr'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ldp_gr = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_ldp_eol(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_eol.ldp_eol, is_container='container', presence=True, yang_name=\"ldp-eol\", rest_name=\"eol\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enter MPLS LDP EOL Config mode', u'alt-name': u'eol', u'callpoint': u'MplsLdpEol', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-ldp-eol'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_eol must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_eol.ldp_eol, is_container='container', presence=True, yang_name=\"ldp-eol\", rest_name=\"eol\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enter MPLS LDP EOL Config mode', u'alt-name': u'eol', u'callpoint': u'MplsLdpEol', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-ldp-eol'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ldp_eol = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the LDP EOL configuration for the given container"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_ldp_lw_delay(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..300']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(60), is_leaf=True, yang_name=\"ldp-lw-delay\", rest_name=\"label-withdrawal-delay\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'LDP Label Withdrawal Delay (0-300, default 60) seconds', u'cli-full-no': None, u'alt-name': u'label-withdrawal-delay'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_lw_delay must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0..300']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(60), is_leaf=True, yang_name=\"ldp-lw-delay\", rest_name=\"label-withdrawal-delay\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'LDP Label Withdrawal Delay (0-300, default 60) seconds', u'cli-full-no': None, u'alt-name': u'label-withdrawal-delay'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__ldp_lw_delay = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ldp_lw_delay of the last n - device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_retain(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=retain.retain, is_container='container', presence=False, yang_name=\"retain\", rest_name=\"retain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Retain route targets'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"retain must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=retain.retain, is_container='container', presence=False, yang_name=\"retain\", rest_name=\"retain\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Retain route targets'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__retain = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the retain property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_overlay_service_policy(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"overlay_sp_direction overlay_sp_pmap_name\",overlay_service_policy.overlay_service_policy, yang_name=\"overlay-service-policy\", rest_name=\"overlay-service-policy\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='overlay-sp-direction overlay-sp-pmap-name', extensions={u'tailf-common': {u'info': u'Attach Overlay policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OverlayServicePolicyCallPoint'}}), is_container='list', yang_name=\"overlay-service-policy\", rest_name=\"overlay-service-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Attach Overlay policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OverlayServicePolicyCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"overlay_service_policy must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"overlay_sp_direction overlay_sp_pmap_name\",overlay_service_policy.overlay_service_policy, yang_name=\"overlay-service-policy\", rest_name=\"overlay-service-policy\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='overlay-sp-direction overlay-sp-pmap-name', extensions={u'tailf-common': {u'info': u'Attach Overlay policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OverlayServicePolicyCallPoint'}}), is_container='list', yang_name=\"overlay-service-policy\", rest_name=\"overlay-service-policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Attach Overlay policy Map', u'cli-no-key-completion': None, u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-suppress-key-abbreviation': None, u'callpoint': u'OverlayServicePolicyCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-overlay-policy', defining_module='brocade-overlay-policy', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__overlay_service_policy = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the overlay service policy for the base node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of the transit_overlay property.", "response": "def _set_transit_overlay(self, v, load=False):\n    \"\"\"\n    Setter method for transit_overlay, mapped from YANG variable /overlay_transit/transit_overlay (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_transit_overlay is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_transit_overlay() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"access_group in_out\",transit_overlay.transit_overlay, yang_name=\"transit-overlay\", rest_name=\"overlay\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='access-group in-out', extensions={u'tailf-common': {u'info': u'overlay', u'cli-suppress-mode': None, u'alt-name': u'overlay', u'callpoint': u'VxlanVisibilityTransitOverlayCallpoint'}}), is_container='list', yang_name=\"transit-overlay\", rest_name=\"overlay\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'overlay', u'cli-suppress-mode': None, u'alt-name': u'overlay', u'callpoint': u'VxlanVisibilityTransitOverlayCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"transit_overlay must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"access_group in_out\",transit_overlay.transit_overlay, yang_name=\"transit-overlay\", rest_name=\"overlay\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='access-group in-out', extensions={u'tailf-common': {u'info': u'overlay', u'cli-suppress-mode': None, u'alt-name': u'overlay', u'callpoint': u'VxlanVisibilityTransitOverlayCallpoint'}}), is_container='list', yang_name=\"transit-overlay\", rest_name=\"overlay\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'overlay', u'cli-suppress-mode': None, u'alt-name': u'overlay', u'callpoint': u'VxlanVisibilityTransitOverlayCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__transit_overlay = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the rt property of the", "response": "def _set_rt(self, v, load=False):\n    \"\"\"\n    Setter method for rt, mapped from YANG variable /rbridge_id/route_map/content/set/extcommunity/rt (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_rt is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_rt() directly.\n\n    YANG Description: Route Target extended community\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=rt.rt, is_container='container', presence=False, yang_name=\"rt\", rest_name=\"rt\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Route Target extended community'}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rt must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=rt.rt, is_container='container', presence=False, yang_name=\"rt\", rest_name=\"rt\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Route Target extended community'}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__rt = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_soo(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=soo.soo, is_container='container', presence=False, yang_name=\"soo\", rest_name=\"soo\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Site-of-Origin extended community'}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"soo must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=soo.soo, is_container='container', presence=False, yang_name=\"soo\", rest_name=\"soo\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Site-of-Origin extended community'}}, namespace='urn:brocade.com:mgmt:brocade-ip-policy', defining_module='brocade-ip-policy', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__soo = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the soo variable in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the Pvlan tag for the private NIC.", "response": "def _set_pvlan_tag(self, v, load=False):\n    \"\"\"\n    Setter method for pvlan_tag, mapped from YANG variable /interface/port_channel/switchport/private_vlan/trunk/pvlan_tag (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_pvlan_tag is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_pvlan_tag() directly.\n\n    YANG Description: This specifies vlan tagging characteristics for a \ntrunk port.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=pvlan_tag.pvlan_tag, is_container='container', presence=False, yang_name=\"pvlan-tag\", rest_name=\"tag\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable tagging', u'alt-name': u'tag', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"pvlan_tag must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=pvlan_tag.pvlan_tag, is_container='container', presence=False, yang_name=\"pvlan-tag\", rest_name=\"tag\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable tagging', u'alt-name': u'tag', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__pvlan_tag = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_modId(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"modId\",modId.modId, yang_name=\"modId\", rest_name=\"modId\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='modId', extensions={u'tailf-common': {u'info': u'Configure RAS module configuration', u'cli-drop-node-name': None, u'callpoint': u'RASMODConfigureCallPoint'}}), is_container='list', yang_name=\"modId\", rest_name=\"modId\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure RAS module configuration', u'cli-drop-node-name': None, u'callpoint': u'RASMODConfigureCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-ras', defining_module='brocade-ras', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"modId must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"modId\",modId.modId, yang_name=\"modId\", rest_name=\"modId\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='modId', extensions={u'tailf-common': {u'info': u'Configure RAS module configuration', u'cli-drop-node-name': None, u'callpoint': u'RASMODConfigureCallPoint'}}), is_container='list', yang_name=\"modId\", rest_name=\"modId\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure RAS module configuration', u'cli-drop-node-name': None, u'callpoint': u'RASMODConfigureCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-ras', defining_module='brocade-ras', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__modId = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the modId of the\n    based on the given list of modId values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the area of the", "response": "def _set_area(self, v, load=False):\n    \"\"\"\n    Setter method for area, mapped from YANG variable /routing_system/interface/ve/ip/interface_vlan_ospf_conf/ospf1/area (ospf-area-id)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_area is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_area() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'((([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.)(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.){2}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]))|(([0-9])|([1-9]([0-9]{1,8}))|([1]([0-9]{1,9}))|([2][0]([0-9]{1,8}))|([2][1][0-3]([0-9]{1,7}))|([2][1][4][0-6]([0-9]{1,6}))|([2][1][4][7][0-3]([0-9]{1,5}))|([2][1][4][7][4][0-7]([0-9]{1,4}))|([2][1][4][7][4][8][0-2]([0-9]{1,3}))|([2][1][4][7][4][8][3][0-5]([0-9]{1,2}))|([2][1][4][7][4][8][3][6][0-3][0-9])|([2][1][4][7][4][8][3][6][4][0-7]))'}), is_leaf=True, yang_name=\"area\", rest_name=\"area\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'OSPF areas'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='ospf-area-id', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"area must be of a type compatible with ospf-area-id\"\"\",\n          'defined-type': \"brocade-ospf:ospf-area-id\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'pattern': u'((([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.)(([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\\\.){2}([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5]))|(([0-9])|([1-9]([0-9]{1,8}))|([1]([0-9]{1,9}))|([2][0]([0-9]{1,8}))|([2][1][0-3]([0-9]{1,7}))|([2][1][4][0-6]([0-9]{1,6}))|([2][1][4][7][0-3]([0-9]{1,5}))|([2][1][4][7][4][0-7]([0-9]{1,4}))|([2][1][4][7][4][8][0-2]([0-9]{1,3}))|([2][1][4][7][4][8][3][0-5]([0-9]{1,2}))|([2][1][4][7][4][8][3][6][0-3][0-9])|([2][1][4][7][4][8][3][6][4][0-7]))'}), is_leaf=True, yang_name=\"area\", rest_name=\"area\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'OSPF areas'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='ospf-area-id', is_config=True)\"\"\",\n        })\n\n    self.__area = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the authentication key for the base NICs", "response": "def _set_authentication_key(self, v, load=False):\n    \"\"\"\n    Setter method for authentication_key, mapped from YANG variable /routing_system/interface/ve/ip/interface_vlan_ospf_conf/ospf1/authentication_key (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_authentication_key is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_authentication_key() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=authentication_key.authentication_key, is_container='container', presence=False, yang_name=\"authentication-key\", rest_name=\"authentication-key\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authentication password (key)', u'cli-full-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"authentication_key must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=authentication_key.authentication_key, is_container='container', presence=False, yang_name=\"authentication-key\", rest_name=\"authentication-key\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Authentication password (key)', u'cli-full-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__authentication_key = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_intf_ldp_sync(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'enable': {'value': 1}, u'disable': {'value': 2}},), is_leaf=True, yang_name=\"intf-ldp-sync\", rest_name=\"ldp-sync\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set LDP-SYNC operation mode on this interface', u'cli-full-no': None, u'alt-name': u'ldp-sync'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"intf_ldp_sync must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-ospf:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'enable': {'value': 1}, u'disable': {'value': 2}},), is_leaf=True, yang_name=\"intf-ldp-sync\", rest_name=\"ldp-sync\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Set LDP-SYNC operation mode on this interface', u'cli-full-no': None, u'alt-name': u'ldp-sync'}}, namespace='urn:brocade.com:mgmt:brocade-ospf', defining_module='brocade-ospf', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__intf_ldp_sync = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the LDP - SYNCHRONOUS flag of the specified interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_type(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=type.type, is_container='container', presence=False, yang_name=\"type\", rest_name=\"type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'type'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"type must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=type.type, is_container='container', presence=False, yang_name=\"type\", rest_name=\"type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'type'}}, namespace='urn:brocade.com:mgmt:brocade-vxlan-visibility', defining_module='brocade-vxlan-visibility', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__type = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the type of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the redist BGP routing table.", "response": "def _set_redist_bgp(self, v, load=False):\n    \"\"\"\n    Setter method for redist_bgp, mapped from YANG variable /isis_state/router_isis_config/is_address_family_v4/redist_bgp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_redist_bgp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_redist_bgp() directly.\n\n    YANG Description: IS-IS redistribution config for BGP routes\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=redist_bgp.redist_bgp, is_container='container', presence=False, yang_name=\"redist-bgp\", rest_name=\"redist-bgp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-bgp-redistribution', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"redist_bgp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=redist_bgp.redist_bgp, is_container='container', presence=False, yang_name=\"redist-bgp\", rest_name=\"redist-bgp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-bgp-redistribution', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__redist_bgp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_redist_isis(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=redist_isis.redist_isis, is_container='container', presence=False, yang_name=\"redist-isis\", rest_name=\"redist-isis\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis-to-isis-redistribution', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"redist_isis must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=redist_isis.redist_isis, is_container='container', presence=False, yang_name=\"redist-isis\", rest_name=\"redist-isis\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-isis-to-isis-redistribution', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__redist_isis = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of isis_container in the state of isis_state_v4"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of the REDIST_OSPF property in the IS - IS", "response": "def _set_redist_ospf(self, v, load=False):\n    \"\"\"\n    Setter method for redist_ospf, mapped from YANG variable /isis_state/router_isis_config/is_address_family_v4/redist_ospf (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_redist_ospf is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_redist_ospf() directly.\n\n    YANG Description: Redistribution config for OSPF routes into IS-IS\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=redist_ospf.redist_ospf, is_container='container', presence=False, yang_name=\"redist-ospf\", rest_name=\"redist-ospf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-ospf-to-isis-redistribution', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"redist_ospf must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=redist_ospf.redist_ospf, is_container='container', presence=False, yang_name=\"redist-ospf\", rest_name=\"redist-ospf\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'isis-ospf-to-isis-redistribution', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-isis-operational', defining_module='brocade-isis-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__redist_ospf = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the default behavior of the", "response": "def _set_default_behavior(self, v, load=False):\n    \"\"\"\n    Setter method for default_behavior, mapped from YANG variable /openflow_global/openflow/default_behavior (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_default_behavior is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_default_behavior() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=default_behavior.default_behavior, is_container='container', presence=False, yang_name=\"default-behavior\", rest_name=\"default-behavior\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'set openflow behavior'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"default_behavior must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=default_behavior.default_behavior, is_container='container', presence=False, yang_name=\"default-behavior\", rest_name=\"default-behavior\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'set openflow behavior'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__default_behavior = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_ssm_enable(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ssm_enable.ssm_enable, is_container='container', presence=True, yang_name=\"ssm-enable\", rest_name=\"ssm-enable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable/disable SSM mode for PIM'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ssm_enable must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ssm_enable.ssm_enable, is_container='container', presence=True, yang_name=\"ssm-enable\", rest_name=\"ssm-enable\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable/disable SSM mode for PIM'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ssm_enable = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the enable flag for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of anycast_rp in the order of the specified IP addresses.", "response": "def _set_anycast_rp(self, v, load=False):\n    \"\"\"\n    Setter method for anycast_rp, mapped from YANG variable /routing_system/router/hide_pim_holder/pim/anycast_rp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_anycast_rp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_anycast_rp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"anycast_ip_addr\",anycast_rp.anycast_rp, yang_name=\"anycast-rp\", rest_name=\"anycast-rp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='anycast-ip-addr', extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peers', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'PimAnycastRpCfgCallpoint'}}), is_container='list', yang_name=\"anycast-rp\", rest_name=\"anycast-rp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peers', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'PimAnycastRpCfgCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"anycast_rp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"anycast_ip_addr\",anycast_rp.anycast_rp, yang_name=\"anycast-rp\", rest_name=\"anycast-rp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='anycast-ip-addr', extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peers', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'PimAnycastRpCfgCallpoint'}}), is_container='list', yang_name=\"anycast-rp\", rest_name=\"anycast-rp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peers', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-compact-syntax': None, u'cli-incomplete-command': None, u'callpoint': u'PimAnycastRpCfgCallpoint'}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__anycast_rp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_anycast_rp_ip(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"anycast_rp_ip_addr\",anycast_rp_ip.anycast_rp_ip, yang_name=\"anycast-rp-ip\", rest_name=\"anycast-rp-ip\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='anycast-rp-ip-addr', extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peer address', u'cli-suppress-mode': None, u'hidden': u'full', u'callpoint': u'PimAnycastRpIpCfgCallpoint', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"anycast-rp-ip\", rest_name=\"anycast-rp-ip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peer address', u'cli-suppress-mode': None, u'hidden': u'full', u'callpoint': u'PimAnycastRpIpCfgCallpoint', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"anycast_rp_ip must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"anycast_rp_ip_addr\",anycast_rp_ip.anycast_rp_ip, yang_name=\"anycast-rp-ip\", rest_name=\"anycast-rp-ip\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='anycast-rp-ip-addr', extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peer address', u'cli-suppress-mode': None, u'hidden': u'full', u'callpoint': u'PimAnycastRpIpCfgCallpoint', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"anycast-rp-ip\", rest_name=\"anycast-rp-ip\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set Anycast RP address and peer address', u'cli-suppress-mode': None, u'hidden': u'full', u'callpoint': u'PimAnycastRpIpCfgCallpoint', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__anycast_rp_ip = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set anycast RP IP address in the order they are assigned."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the route precedence of a node.", "response": "def _set_route_precedence(self, v, load=False):\n    \"\"\"\n    Setter method for route_precedence, mapped from YANG variable /routing_system/router/hide_pim_holder/pim/route_precedence (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_route_precedence is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_route_precedence() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=route_precedence.route_precedence, is_container='container', presence=False, yang_name=\"route-precedence\", rest_name=\"route-precedence\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Specify Route Selection criteria', u'callpoint': u'PimRoutePrecedenceCallpoint', u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"route_precedence must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=route_precedence.route_precedence, is_container='container', presence=False, yang_name=\"route-precedence\", rest_name=\"route-precedence\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'info': u'Specify Route Selection criteria', u'callpoint': u'PimRoutePrecedenceCallpoint', u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-pim', defining_module='brocade-pim', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__route_precedence = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef paths_in_directory(input_directory):\n    paths = []\n    for base_path, directories, filenames in os.walk(input_directory):\n        relative_path = os.path.relpath(base_path, input_directory)\n        path_components = relative_path.split(os.sep)\n        if path_components[0] == \".\":\n            path_components = path_components[1:]\n        if path_components and path_components[0].startswith(\".\"):\n            # hidden dir\n            continue\n        path_components = filter(bool, path_components)  # remove empty components\n        for filename in filenames:\n            if filename.startswith(\".\"):\n                # hidden file\n                continue\n            paths.append(path_components + [filename])\n    return paths", "response": "Generate a list of all files in input_directory each as a list containing path components."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef static_uint8_variable_for_data(variable_name, data, max_line_length=120, comment=\"\", indent=2):\n    hex_components = []\n    for byte in data:\n        byte_as_hex = \"0x{u:02X}\".format(u=ord(byte))\n        hex_components.append(byte_as_hex)\n\n    chunk_size = (max_line_length - indent + 2 - 1) // 6  # 6 is len(\"0xAA, \"); +2 for the last element's \", \"; -1 for the trailing comma\n\n    array_lines = []\n    for chunk_offset in xrange(0, len(hex_components), chunk_size):\n        chunk = hex_components[chunk_offset:chunk_offset + chunk_size]\n        array_lines.append(\" \" * indent + \", \".join(chunk) + \",\")\n\n    array_data = \"\\n\".join(array_lines)\n\n    if comment != \"\":\n        comment = \" // \" + comment\n\n    substitutions = {\"v\": variable_name,\n                     \"l\": len(hex_components),\n                     \"d\": array_data,\n                     \"c\": comment}\n    declaration = \"static uint8_t {v}[{l}] = {{{c}\\n{d}\\n}}; // {v}\".format(**substitutions)\n    return declaration", "response": "r Creates a variable with the given name and data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the stats group for the current session.", "response": "def _set_stats_group(self, v, load=False):\n    \"\"\"\n    Setter method for stats_group, mapped from YANG variable /mpls_state/ldp/ldp_session/session_ldp_stats/protocol_errors/stats_group (mpls-ldp-stats-error-group)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_stats_group is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_stats_group() directly.\n\n    YANG Description: Describes if the stats are for a given session, global-all or global-since-last-clear\n    \"\"\"\n    parent = getattr(self, \"_parent\", None)\n    if parent is not None and load is False:\n      raise AttributeError(\"Cannot set keys directly when\" +\n                             \" within an instantiated list\")\n\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'global-stats-all': {'value': 1}, u'per-session-stats': {'value': 0}, u'global-stats-since-last-clear': {'value': 2}},), is_leaf=True, yang_name=\"stats-group\", rest_name=\"stats-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, is_keyval=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='mpls-ldp-stats-error-group', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"stats_group must be of a type compatible with mpls-ldp-stats-error-group\"\"\",\n          'defined-type': \"brocade-mpls-operational:mpls-ldp-stats-error-group\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'global-stats-all': {'value': 1}, u'per-session-stats': {'value': 0}, u'global-stats-since-last-clear': {'value': 2}},), is_leaf=True, yang_name=\"stats-group\", rest_name=\"stats-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, is_keyval=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='mpls-ldp-stats-error-group', is_config=False)\"\"\",\n        })\n\n    self.__stats_group = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_policy(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=policy.policy, is_container='container', presence=True, yang_name=\"policy\", rest_name=\"policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enter MPLS Policy Config mode', u'callpoint': u'MplsPolicy', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-policy'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"policy must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=policy.policy, is_container='container', presence=True, yang_name=\"policy\", rest_name=\"policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enter MPLS Policy Config mode', u'callpoint': u'MplsPolicy', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-policy'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__policy = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the policy of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the ldp field of the", "response": "def _set_ldp(self, v, load=False):\n    \"\"\"\n    Setter method for ldp, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/ldp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp.ldp, is_container='container', presence=True, yang_name=\"ldp\", rest_name=\"ldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MPLS Protocol (MPLS)', u'callpoint': u'MplsLdp', u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-ldp'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp.ldp, is_container='container', presence=True, yang_name=\"ldp\", rest_name=\"ldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MPLS Protocol (MPLS)', u'callpoint': u'MplsLdp', u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-ldp'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__ldp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_bfd(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bfd.bfd, is_container='container', presence=True, yang_name=\"bfd\", rest_name=\"bfd\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure BFD parameters', u'callpoint': u'MplsBfd', u'cli-add-mode': None, u'cli-full-command': None, u'hidden': u'full', u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-bfd'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bfd must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bfd.bfd, is_container='container', presence=True, yang_name=\"bfd\", rest_name=\"bfd\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure BFD parameters', u'callpoint': u'MplsBfd', u'cli-add-mode': None, u'cli-full-command': None, u'hidden': u'full', u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-bfd'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__bfd = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the bfd parameter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the MPLS Interface field in the cluster.", "response": "def _set_mpls_interface(self, v, load=False):\n    \"\"\"\n    Setter method for mpls_interface, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/mpls_interface (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mpls_interface is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mpls_interface() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"interface_type interface_name\",mpls_interface.mpls_interface, yang_name=\"mpls-interface\", rest_name=\"mpls-interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='interface-type interface-name', extensions={u'tailf-common': {u'info': u'Define MPLS Interface', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsInterface', u'cli-mode-name': u'config-router-mpls-if-$(interface-type)-$(interface-name)'}}), is_container='list', yang_name=\"mpls-interface\", rest_name=\"mpls-interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define MPLS Interface', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsInterface', u'cli-mode-name': u'config-router-mpls-if-$(interface-type)-$(interface-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mpls_interface must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"interface_type interface_name\",mpls_interface.mpls_interface, yang_name=\"mpls-interface\", rest_name=\"mpls-interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='interface-type interface-name', extensions={u'tailf-common': {u'info': u'Define MPLS Interface', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsInterface', u'cli-mode-name': u'config-router-mpls-if-$(interface-type)-$(interface-name)'}}), is_container='list', yang_name=\"mpls-interface\", rest_name=\"mpls-interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define MPLS Interface', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsInterface', u'cli-mode-name': u'config-router-mpls-if-$(interface-type)-$(interface-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mpls_interface = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_autobw_template(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"autobw_template_name\",autobw_template.autobw_template, yang_name=\"autobw-template\", rest_name=\"autobw-template\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='autobw-template-name', extensions={u'tailf-common': {u'info': u'Define Autobw Template', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwTemplate', u'cli-mode-name': u'config-router-mpls-autobw-template-$(autobw-template-name)'}}), is_container='list', yang_name=\"autobw-template\", rest_name=\"autobw-template\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Autobw Template', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwTemplate', u'cli-mode-name': u'config-router-mpls-autobw-template-$(autobw-template-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"autobw_template must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"autobw_template_name\",autobw_template.autobw_template, yang_name=\"autobw-template\", rest_name=\"autobw-template\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='autobw-template-name', extensions={u'tailf-common': {u'info': u'Define Autobw Template', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwTemplate', u'cli-mode-name': u'config-router-mpls-autobw-template-$(autobw-template-name)'}}), is_container='list', yang_name=\"autobw-template\", rest_name=\"autobw-template\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Autobw Template', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsAutobwTemplate', u'cli-mode-name': u'config-router-mpls-autobw-template-$(autobw-template-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__autobw_template = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Setter method for autobw_template, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/autobw_template (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_autobw_template is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_autobw_template() directly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the autobw threshold table for the given autobw - threshold - table", "response": "def _set_autobw_threshold_table(self, v, load=False):\n    \"\"\"\n    Setter method for autobw_threshold_table, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/autobw_threshold_table (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_autobw_threshold_table is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_autobw_threshold_table() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=autobw_threshold_table.autobw_threshold_table, is_container='container', presence=True, yang_name=\"autobw-threshold-table\", rest_name=\"autobw-threshold-table\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Autobw Threshold Table', u'callpoint': u'MplsAutobwThresholdTable', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-autobw-threshold-table'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"autobw_threshold_table must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=autobw_threshold_table.autobw_threshold_table, is_container='container', presence=True, yang_name=\"autobw-threshold-table\", rest_name=\"autobw-threshold-table\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Autobw Threshold Table', u'callpoint': u'MplsAutobwThresholdTable', u'cli-add-mode': None, u'cli-full-command': None, u'cli-full-no': None, u'cli-mode-name': u'config-router-mpls-autobw-threshold-table'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__autobw_threshold_table = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_cspf_group(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"cspf_group_name\",cspf_group.cspf_group, yang_name=\"cspf-group\", rest_name=\"cspf-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cspf-group-name', extensions={u'tailf-common': {u'info': u'Define a CSPF group', u'callpoint': u'MplsCspfGroup', u'cli-mode-name': u'config-router-cspf-group-$(cspf-group-name)'}}), is_container='list', yang_name=\"cspf-group\", rest_name=\"cspf-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define a CSPF group', u'callpoint': u'MplsCspfGroup', u'cli-mode-name': u'config-router-cspf-group-$(cspf-group-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cspf_group must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"cspf_group_name\",cspf_group.cspf_group, yang_name=\"cspf-group\", rest_name=\"cspf-group\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cspf-group-name', extensions={u'tailf-common': {u'info': u'Define a CSPF group', u'callpoint': u'MplsCspfGroup', u'cli-mode-name': u'config-router-cspf-group-$(cspf-group-name)'}}), is_container='list', yang_name=\"cspf-group\", rest_name=\"cspf-group\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define a CSPF group', u'callpoint': u'MplsCspfGroup', u'cli-mode-name': u'config-router-cspf-group-$(cspf-group-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__cspf_group = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the cspf group of the current CSPS group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value of bypass_lsp mapped from YANG variable bypass_lsp_name", "response": "def _set_bypass_lsp(self, v, load=False):\n    \"\"\"\n    Setter method for bypass_lsp, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/bypass_lsp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bypass_lsp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bypass_lsp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"bypass_lsp_name\",bypass_lsp.bypass_lsp, yang_name=\"bypass-lsp\", rest_name=\"bypass-lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='bypass-lsp-name', extensions={u'tailf-common': {u'info': u'Define Bypass LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsBypassLsp', u'cli-mode-name': u'config-router-mpls-bypass-lsp-$(bypass-lsp-name)'}}), is_container='list', yang_name=\"bypass-lsp\", rest_name=\"bypass-lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Bypass LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsBypassLsp', u'cli-mode-name': u'config-router-mpls-bypass-lsp-$(bypass-lsp-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bypass_lsp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"bypass_lsp_name\",bypass_lsp.bypass_lsp, yang_name=\"bypass-lsp\", rest_name=\"bypass-lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='bypass-lsp-name', extensions={u'tailf-common': {u'info': u'Define Bypass LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsBypassLsp', u'cli-mode-name': u'config-router-mpls-bypass-lsp-$(bypass-lsp-name)'}}), is_container='list', yang_name=\"bypass-lsp\", rest_name=\"bypass-lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Bypass LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsBypassLsp', u'cli-mode-name': u'config-router-mpls-bypass-lsp-$(bypass-lsp-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__bypass_lsp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the lsp field in the cluster.", "response": "def _set_lsp(self, v, load=False):\n    \"\"\"\n    Setter method for lsp, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"lsp_name\",lsp.lsp, yang_name=\"lsp\", rest_name=\"lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='lsp-name', extensions={u'tailf-common': {u'info': u'Define LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLsp', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)'}}), is_container='list', yang_name=\"lsp\", rest_name=\"lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLsp', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"lsp_name\",lsp.lsp, yang_name=\"lsp\", rest_name=\"lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='lsp-name', extensions={u'tailf-common': {u'info': u'Define LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLsp', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)'}}), is_container='list', yang_name=\"lsp\", rest_name=\"lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLsp', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__lsp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_optional_tlv(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=optional_tlv.optional_tlv, is_container='container', presence=False, yang_name=\"optional-tlv\", rest_name=\"optional-tlv\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'The Optional TLVs.', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-lldp', defining_module='brocade-lldp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"optional_tlv must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=optional_tlv.optional_tlv, is_container='container', presence=False, yang_name=\"optional-tlv\", rest_name=\"optional-tlv\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'The Optional TLVs.', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-lldp', defining_module='brocade-lldp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__optional_tlv = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the optional TLV field of the optional list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the ipv6 interface of the anycast - gateway", "response": "def _set_ipv6_interface(self, v, load=False):\n    \"\"\"\n    Setter method for ipv6_interface, mapped from YANG variable /rbridge_id/interface/ve/ipv6/ipv6_local_anycast_gateway/ipv6_track/ipv6_interface (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ipv6_interface is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ipv6_interface() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"ipv6_interface_type ipv6_interface_name\",ipv6_interface.ipv6_interface, yang_name=\"ipv6-interface\", rest_name=\"interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ipv6-interface-type ipv6-interface-name', extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackInterfaceConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}), is_container='list', yang_name=\"ipv6-interface\", rest_name=\"interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackInterfaceConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-anycast-gateway', defining_module='brocade-anycast-gateway', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ipv6_interface must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"ipv6_interface_type ipv6_interface_name\",ipv6_interface.ipv6_interface, yang_name=\"ipv6-interface\", rest_name=\"interface\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ipv6-interface-type ipv6-interface-name', extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackInterfaceConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}), is_container='list', yang_name=\"ipv6-interface\", rest_name=\"interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackInterfaceConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'interface', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-anycast-gateway', defining_module='brocade-anycast-gateway', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ipv6_interface = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_ipv6_network(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"ipv6_network_address\",ipv6_network.ipv6_network, yang_name=\"ipv6-network\", rest_name=\"network\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ipv6-network-address', extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNetworkConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'network', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}), is_container='list', yang_name=\"ipv6-network\", rest_name=\"network\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNetworkConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'network', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-anycast-gateway', defining_module='brocade-anycast-gateway', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ipv6_network must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"ipv6_network_address\",ipv6_network.ipv6_network, yang_name=\"ipv6-network\", rest_name=\"network\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ipv6-network-address', extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNetworkConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'network', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}), is_container='list', yang_name=\"ipv6-network\", rest_name=\"network\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNetworkConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'network', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-anycast-gateway', defining_module='brocade-anycast-gateway', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ipv6_network = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ipv6 network of the anycast - gateway."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_ipv6_next_hop(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"ipv6_next_hop_address\",ipv6_next_hop.ipv6_next_hop, yang_name=\"ipv6-next-hop\", rest_name=\"next-hop\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ipv6-next-hop-address', extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNextHopConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'next-hop', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}), is_container='list', yang_name=\"ipv6-next-hop\", rest_name=\"next-hop\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNextHopConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'next-hop', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-anycast-gateway', defining_module='brocade-anycast-gateway', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ipv6_next_hop must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"ipv6_next_hop_address\",ipv6_next_hop.ipv6_next_hop, yang_name=\"ipv6-next-hop\", rest_name=\"next-hop\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='ipv6-next-hop-address', extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNextHopConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'next-hop', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}), is_container='list', yang_name=\"ipv6-next-hop\", rest_name=\"next-hop\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'AnycastGatewayLocalIpv6TrackNextHopConfig', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'alt-name': u'next-hop', u'cli-incomplete-command': None, u'cli-no-match-completion': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-anycast-gateway', defining_module='brocade-anycast-gateway', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__ipv6_next_hop = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the next hop address of the next hop in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_vlanoper(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vlanoper.vlanoper, is_container='container', presence=False, yang_name=\"vlanoper\", rest_name=\"vlanoper\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'hidden': u'netconfonly'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vlanoper must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vlanoper.vlanoper, is_container='container', presence=False, yang_name=\"vlanoper\", rest_name=\"vlanoper\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'hidden': u'netconfonly'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vlanoper = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the vlanoper variable"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_vlan_profile(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=vlan_profile.vlan_profile, is_container='container', presence=True, yang_name=\"vlan-profile\", rest_name=\"vlan-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'callpoint': u'vlan-profile-config', u'info': u'VLAN profile', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vlan_profile must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=vlan_profile.vlan_profile, is_container='container', presence=True, yang_name=\"vlan-profile\", rest_name=\"vlan-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'callpoint': u'vlan-profile-config', u'info': u'VLAN profile', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__vlan_profile = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the vlan profile of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the FCoE profile for the sequence of FCOE ports.", "response": "def _set_fcoe_profile(self, v, load=False):\n    \"\"\"\n    Setter method for fcoe_profile, mapped from YANG variable /port_profile/fcoe_profile (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fcoe_profile is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fcoe_profile() directly.\n\n    YANG Description: The FCoE profile.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcoe_profile.fcoe_profile, is_container='container', presence=True, yang_name=\"fcoe-profile\", rest_name=\"fcoe-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'callpoint': u'fcoe-profile-config', u'info': u'FCoE profile', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcoe_profile must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcoe_profile.fcoe_profile, is_container='container', presence=True, yang_name=\"fcoe-profile\", rest_name=\"fcoe-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'callpoint': u'fcoe-profile-config', u'info': u'FCoE profile', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcoe_profile = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_qos_profile(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=qos_profile.qos_profile, is_container='container', presence=True, yang_name=\"qos-profile\", rest_name=\"qos-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'info': u'QoS profile', u'callpoint': u'qos-profile-config'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"qos_profile must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=qos_profile.qos_profile, is_container='container', presence=True, yang_name=\"qos-profile\", rest_name=\"qos-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'info': u'QoS profile', u'callpoint': u'qos-profile-config'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__qos_profile = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the qos - profile for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_security_profile(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=security_profile.security_profile, is_container='container', presence=True, yang_name=\"security-profile\", rest_name=\"security-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'info': u'Security profile', u'callpoint': u'security-profile-config'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"security_profile must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=security_profile.security_profile, is_container='container', presence=True, yang_name=\"security-profile\", rest_name=\"security-profile\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'info': u'Security profile', u'callpoint': u'security-profile-config'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__security_profile = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the security profile for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the restrict_flooding_container variable.", "response": "def _set_restrict_flooding_container(self, v, load=False):\n    \"\"\"\n    Setter method for restrict_flooding_container, mapped from YANG variable /port_profile/restrict_flooding_container (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_restrict_flooding_container is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_restrict_flooding_container() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=restrict_flooding_container.restrict_flooding_container, is_container='container', presence=False, yang_name=\"restrict-flooding-container\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'display-when': u'../name = \"default\"'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"restrict_flooding_container must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=restrict_flooding_container.restrict_flooding_container, is_container='container', presence=False, yang_name=\"restrict-flooding-container\", rest_name=\"\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None, u'display-when': u'../name = \"default\"'}}, namespace='urn:brocade.com:mgmt:brocade-port-profile', defining_module='brocade-port-profile', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__restrict_flooding_container = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_values(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=values.values, is_container='container', presence=False, yang_name=\"values\", rest_name=\"\", parent=self, choice=(u'ch-dampening-source', u'ca-dampening-specify-values'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-drop-node-name': None, u'cli-sequence-commands': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"values must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=values.values, is_container='container', presence=False, yang_name=\"values\", rest_name=\"\", parent=self, choice=(u'ch-dampening-source', u'ca-dampening-specify-values'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-compact-syntax': None, u'cli-drop-node-name': None, u'cli-sequence-commands': None}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__values = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the values of the\n    based on dampening source."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_dampening_route_map(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..63']}), is_leaf=True, yang_name=\"dampening-route-map\", rest_name=\"route-map\", parent=self, choice=(u'ch-dampening-source', u'ca-dampening-route-map'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Route-map to specify criteria for dampening', u'alt-name': u'route-map'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='rmap-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dampening_route_map must be of a type compatible with rmap-type\"\"\",\n          'defined-type': \"brocade-bgp:rmap-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..63']}), is_leaf=True, yang_name=\"dampening-route-map\", rest_name=\"route-map\", parent=self, choice=(u'ch-dampening-source', u'ca-dampening-route-map'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Route-map to specify criteria for dampening', u'alt-name': u'route-map'}}, namespace='urn:brocade.com:mgmt:brocade-bgp', defining_module='brocade-bgp', yang_type='rmap-type', is_config=True)\"\"\",\n        })\n\n    self.__dampening_route_map = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of dampening_route_map in the virtual node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the mode of the", "response": "def _set_mode(self, v, load=False):\n    \"\"\"\n    Setter method for mode, mapped from YANG variable /interface/tunnel/mode (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mode is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mode() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=mode.mode, is_container='container', presence=False, yang_name=\"mode\", rest_name=\"mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Tunnel encapsulation method', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mode must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=mode.mode, is_container='container', presence=False, yang_name=\"mode\", rest_name=\"mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Tunnel encapsulation method', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__mode = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the gre_source property of the", "response": "def _set_gre_source(self, v, load=False):\n    \"\"\"\n    Setter method for gre_source, mapped from YANG variable /interface/tunnel/gre_source (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_gre_source is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_gre_source() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=gre_source.gre_source, is_container='container', presence=False, yang_name=\"gre-source\", rest_name=\"source\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Source of tunnel', u'cli-full-no': None, u'alt-name': u'source'}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"gre_source must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=gre_source.gre_source, is_container='container', presence=False, yang_name=\"gre-source\", rest_name=\"source\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Source of tunnel', u'cli-full-no': None, u'alt-name': u'source'}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__gre_source = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of tunnel_router_interface in the virtual namespace.", "response": "def _set_tunnel_router_interface(self, v, load=False):\n    \"\"\"\n    Setter method for tunnel_router_interface, mapped from YANG variable /interface/tunnel/tunnel_router_interface (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tunnel_router_interface is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tunnel_router_interface() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tunnel_router_interface.tunnel_router_interface, is_container='container', presence=False, yang_name=\"tunnel-router-interface\", rest_name=\"router-interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Tunnel router-interface', u'cli-full-no': None, u'alt-name': u'router-interface'}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tunnel_router_interface must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tunnel_router_interface.tunnel_router_interface, is_container='container', presence=False, yang_name=\"tunnel-router-interface\", rest_name=\"router-interface\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Tunnel router-interface', u'cli-full-no': None, u'alt-name': u'router-interface'}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tunnel_router_interface = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_tunnel_map(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tunnel_map.tunnel_map, is_container='container', presence=False, yang_name=\"tunnel-map\", rest_name=\"map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'map', u'alt-name': u'map', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'hidden': u'full', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tunnel_map must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tunnel_map.tunnel_map, is_container='container', presence=False, yang_name=\"tunnel-map\", rest_name=\"map\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'map', u'alt-name': u'map', u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'hidden': u'full', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tunnel_map = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the tunnel map for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the gre_ttl variable in the hierarchy.", "response": "def _set_gre_ttl(self, v, load=False):\n    \"\"\"\n    Setter method for gre_ttl, mapped from YANG variable /interface/tunnel/gre_ttl (uint32)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_gre_ttl is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_gre_ttl() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1 .. 255']}), is_leaf=True, yang_name=\"gre-ttl\", rest_name=\"ttl\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel ttl range 1 to 255', u'alt-name': u'ttl', u'cli-full-no': None, u'cli-break-sequence-commands': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"gre_ttl must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'1 .. 255']}), is_leaf=True, yang_name=\"gre-ttl\", rest_name=\"ttl\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel ttl range 1 to 255', u'alt-name': u'ttl', u'cli-full-no': None, u'cli-break-sequence-commands': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__gre_ttl = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the gre_dscp variable in the order of the given sequence.", "response": "def _set_gre_dscp(self, v, load=False):\n    \"\"\"\n    Setter method for gre_dscp, mapped from YANG variable /interface/tunnel/gre_dscp (uint32)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_gre_dscp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_gre_dscp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0 .. 63']}), is_leaf=True, yang_name=\"gre-dscp\", rest_name=\"dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel dscp range 0 to 63', u'alt-name': u'dscp', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"gre_dscp must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'0 .. 63']}), is_leaf=True, yang_name=\"gre-dscp\", rest_name=\"dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel dscp range 0 to 63', u'alt-name': u'dscp', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__gre_dscp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the tunnel name for the", "response": "def _set_tunnel_name(self, v, load=False):\n    \"\"\"\n    Setter method for tunnel_name, mapped from YANG variable /interface/tunnel/tunnel_name (string)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tunnel_name is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tunnel_name() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..256']}), is_leaf=True, yang_name=\"tunnel-name\", rest_name=\"name\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel name', u'alt-name': u'name', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='string', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tunnel_name must be of a type compatible with string\"\"\",\n          'defined-type': \"string\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1..256']}), is_leaf=True, yang_name=\"tunnel-name\", rest_name=\"name\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel name', u'alt-name': u'name', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='string', is_config=True)\"\"\",\n        })\n\n    self.__tunnel_name = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the dscp ttl mode for the given sequence of objects.", "response": "def _set_dscp_ttl_mode(self, v, load=False):\n    \"\"\"\n    Setter method for dscp_ttl_mode, mapped from YANG variable /interface/tunnel/dscp_ttl_mode (enumeration)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dscp_ttl_mode is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dscp_ttl_mode() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'pipe': {'value': 2}, u'uniform': {'value': 1}},), is_leaf=True, yang_name=\"dscp-ttl-mode\", rest_name=\"dscp-ttl-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel dscp ttl mode', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dscp_ttl_mode must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-gre-vxlan:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'pipe': {'value': 2}, u'uniform': {'value': 1}},), is_leaf=True, yang_name=\"dscp-ttl-mode\", rest_name=\"dscp-ttl-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Tunnel dscp ttl mode', u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__dscp_ttl_mode = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_keepalive(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=keepalive.keepalive, is_container='container', presence=False, yang_name=\"keepalive\", rest_name=\"keepalive\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Tunnel keepalive', u'cli-sequence-commands': None, u'cli-full-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"keepalive must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=keepalive.keepalive, is_container='container', presence=False, yang_name=\"keepalive\", rest_name=\"keepalive\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Tunnel keepalive', u'cli-sequence-commands': None, u'cli-full-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-gre-vxlan', defining_module='brocade-gre-vxlan', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__keepalive = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets keepalive for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_car_t_validity_assessment(job, rsem_files, univ_options, reports_options):\n    return job.addChildJobFn(assess_car_t_validity, rsem_files['rsem.genes.results'],\n                             univ_options, reports_options).rv()", "response": "A wrapper for assess_car_t_validity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assess_car_t_validity(job, gene_expression, univ_options, reports_options):\n    work_dir = os.getcwd()\n\n    tumor_type = univ_options['tumor_type']\n\n    input_files = {\n        'rsem_quant.tsv': gene_expression,\n        'car_t_targets.tsv.tar.gz': reports_options['car_t_targets_file']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n\n    input_files['car_t_targets.tsv'] = untargz(input_files['car_t_targets.tsv.tar.gz'],\n                                                 work_dir)\n\n    target_data = pd.read_table(input_files['car_t_targets.tsv'], index_col=0)\n    patient_df = pd.read_csv('rsem_quant.tsv', sep=' ', delimiter='\\t', header='infer', index_col=0)\n    patient_df.index = (patient_df.index).str.replace('\\\\..*$', '')\n\n    overexpressed = []\n    # Check if the tumor has a corresponding normal\n    try:\n        tissue_of_origin = TCGAToGTEx[tumor_type]\n    except KeyError:\n        tissue_of_origin = 'NA'\n    # Write the report\n    with open('car_t_target_report.txt', 'w') as car_t_report:\n        #print(target_data.index, file=car_t_report)\n        if tissue_of_origin in target_data.index:\n            print('Available clinical trials for ' + str.lower(tissue_of_origin) +\n                  ' cancer with GTEX and TCGA median values', file=car_t_report)\n\n            print(('\\t{:10}{:<10}{:<10}{:<10}{:<40}{:<12}\\n'.format('Gene', 'GTEX',\n                                                                    'TCGA N', 'Observed',\n                                                                    'DOI for gene papers',\n                                                                    'Clinical Trials')),\n                                                                     file=car_t_report)\n            collected_values = []\n            # Get the gene name, GTEX, TCGA, and observed values\n            for index, row in target_data.iterrows():\n                if index == tissue_of_origin:\n                    gene = row['ENSG']\n                    gtex = '{0:.2f}'.format(float(row['GTEX']))\n                    tcga = '{0:.2f}'.format(float(row['TCGA']))\n                    observed = '{0:.2f}'.format(\n                        float(patient_df.loc[gene, 'TPM'])) if gene in patient_df.index else 'NA'\n                    doi = row['DOI']\n                    target = str.upper(row['TARGET'])\n                    clinical_trial = row['Clinical trials']\n                    collection = [target, gtex, tcga, observed, doi, clinical_trial]\n                    collected_values.append(collection)\n                    if observed != 'NA':\n                        if float(gtex) <= float(observed) or float(tcga) <= float(observed):\n                            overexpressed.append(gene)\n\n            collected_values = sorted(collected_values, key=lambda col: float(col[3]), reverse=True)\n            for entry in collected_values:\n                print(('\\t{:10}{:<10}{:<10}{:<10}{:<40}{:<12}'.format(entry[0],\n                                                                      entry[1], entry[2],\n                                                                      str(entry[3]), entry[4],\n                                                                      entry[5])), file=car_t_report)\n\n            print('\\nBased on the genes overexpressed in this cancer type, here\\'s a list of clinical '\n                 'trials for other types of cancer', file=car_t_report)\n            if len(overexpressed) != 0:\n                # Check if there are other clinical trials for other cancer types\n                print(('\\t{:10}{:<10}{:<10}{:<10}{:<40}{:<17}{:<20}\\n'.format('Gene', 'GTEX',\n                                                                              'TCGA N', 'Observed',\n                                                                              'DOI for gene papers',\n                                                                              'Clinical Trials',\n                                                                              'Cancer')),\n                                                                              file=car_t_report)\n                other_trials = []\n                for index, row in target_data.iterrows():\n                    if row['ENSG'] in overexpressed and index != tissue_of_origin:\n                        gene = row['ENSG']\n                        gtex = '{0:.2f}'.format(float(row['GTEX']))\n                        tcga = '{0:.2f}'.format(float(row['TCGA']))\n                        doi = row['DOI']\n                        target = str.upper(row['TARGET'])\n                        observed = '{0:.2f}'.format(\n                            float(patient_df.loc[gene, 'TPM'])) if gene in patient_df.index else 'NA'\n                        collected_values = [target, gtex, tcga, observed, doi, row['Clinical trials'],\n                                            index]\n                        other_trials.append(collected_values)\n\n                other_trials = sorted(other_trials, key=lambda col: col[0])\n                for entry in other_trials:\n                    print(('\\t{:10}{:<10}{:<10}{:<10}{:<40}{:<17}{:<20}'.format(entry[0], entry[1],\n                                                                                entry[2], entry[3],\n                                                                                entry[4], entry[5],\n                                                                                entry[6])),\n                                                                                file=car_t_report)\n            else:\n                print(\"Data not available\", file=car_t_report)\n\n        else:\n            print('Data not available for ' + tumor_type, file=car_t_report)\n\n    output_file = job.fileStore.writeGlobalFile(car_t_report.name)\n    export_results(job, output_file, car_t_report.name, univ_options, subfolder='reports')\n    job.fileStore.logToMaster('Ran car t validity assessment on %s successfully'\n                              % univ_options['patient'])\n    return output_file", "response": "This function creates a report on the clinical trials and scientific literature for the overexpressed genes in the specified tumor type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the variable to be used as a private .", "response": "def _set_linecard(self, v, load=False):\n    \"\"\"\n    Setter method for linecard, mapped from YANG variable /global_lc_holder/linecard (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_linecard is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_linecard() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=linecard.linecard, is_container='container', presence=False, yang_name=\"linecard\", rest_name=\"linecard\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Config linecard for the specified slot', u'display-when': u'((/local-node/swbd-number = \"1000\") or (/local-node/swbd-number = \"1001\") or (/local-node/swbd-number = \"1002\") or (/local-node/swbd-number = \"2000\") or (/local-node/swbd-number = \"2001\"))', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-linecard-management', defining_module='brocade-linecard-management', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"linecard must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=linecard.linecard, is_container='container', presence=False, yang_name=\"linecard\", rest_name=\"linecard\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Config linecard for the specified slot', u'display-when': u'((/local-node/swbd-number = \"1000\") or (/local-node/swbd-number = \"1001\") or (/local-node/swbd-number = \"1002\") or (/local-node/swbd-number = \"2000\") or (/local-node/swbd-number = \"2001\"))', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-linecard-management', defining_module='brocade-linecard-management', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__linecard = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef align_dna(job, fastqs, sample_type, univ_options, bwa_options):\n    # The mkdup and regroup steps use picard that allots heap space using the Xmx key in the\n    # univ_options dictionary. This should reflect in the job allotment. Since We want all these\n    # jobs to occur on the same node, we ened to give them all the same memory requirements.\n\n    bwa = job.wrapJobFn(run_bwa, fastqs, sample_type, univ_options, bwa_options,\n                        disk=PromisedRequirement(bwa_disk, fastqs, bwa_options['index']),\n                        memory=univ_options['java_Xmx'],\n                        cores=bwa_options['n'])\n    sam2bam = job.wrapJobFn(bam_conversion, bwa.rv(), sample_type, univ_options,\n                            bwa_options['samtools'],\n                            disk=PromisedRequirement(sam2bam_disk, bwa.rv()),\n                            memory=univ_options['java_Xmx'])\n    # reheader takes the same disk as sam2bam so we can serialize this on the same worker.\n    reheader = job.wrapJobFn(fix_bam_header, sam2bam.rv(), sample_type, univ_options,\n                             bwa_options['samtools'],\n                             disk=PromisedRequirement(sam2bam_disk, bwa.rv()),\n                             memory=univ_options['java_Xmx'])\n    regroup = job.wrapJobFn(add_readgroups, reheader.rv(), sample_type, univ_options,\n                            bwa_options['picard'],\n                            disk=PromisedRequirement(regroup_disk, reheader.rv()),\n                            memory=univ_options['java_Xmx'])\n    mkdup = job.wrapJobFn(mark_duplicates, regroup.rv(), sample_type, univ_options,\n                          bwa_options['picard'],\n                          disk=PromisedRequirement(mkdup_disk, regroup.rv()),\n                          memory=univ_options['java_Xmx'])\n    index = job.wrapJobFn(index_bamfile, mkdup.rv(), sample_type, univ_options,\n                          bwa_options['samtools'], sample_info='fix_pg_sorted',\n                          disk=PromisedRequirement(index_disk, mkdup.rv()),\n                          memory=univ_options['java_Xmx'])\n    job.addChild(bwa)\n    bwa.addChild(sam2bam)\n    sam2bam.addChild(reheader)\n    reheader.addChild(regroup)\n    regroup.addChild(mkdup)\n    mkdup.addChild(index)\n    return index.rv()", "response": "A wrapper for the entire DNA alignment subgraph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_bwa(job, fastqs, sample_type, univ_options, bwa_options):\n    work_dir = os.getcwd()\n    input_files = {\n        'dna_1.fastq': fastqs[0],\n        'dna_2.fastq': fastqs[1],\n        'bwa_index.tar.gz': bwa_options['index']}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=False)\n    # Handle gzipped file\n    gz = '.gz' if is_gzipfile(input_files['dna_1.fastq']) else ''\n    if gz:\n        for read_file in 'dna_1.fastq', 'dna_2.fastq':\n            os.symlink(read_file, read_file + gz)\n            input_files[read_file + gz] = input_files[read_file] + gz\n    # Untar the index\n    input_files['bwa_index'] = untargz(input_files['bwa_index.tar.gz'], work_dir)\n    input_files = {key: docker_path(path) for key, path in input_files.items()}\n\n    parameters = ['mem',\n                  '-t', str(bwa_options['n']),\n                  '-v', '1',  # Don't print INFO messages to the stderr\n                  '/'.join([input_files['bwa_index'], univ_options['ref']]),\n                  input_files['dna_1.fastq' + gz],\n                  input_files['dna_2.fastq' + gz]]\n    with open(''.join([work_dir, '/', sample_type, '.sam']), 'w') as samfile:\n        docker_call(tool='bwa', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=samfile,\n                    tool_version=bwa_options['version'])\n    # samfile.name retains the path info\n    output_file = job.fileStore.writeGlobalFile(samfile.name)\n    job.fileStore.logToMaster('Ran bwa on %s:%s successfully'\n                              % (univ_options['patient'], sample_type))\n    return output_file", "response": "This function will align a pair of fastqs with bwa."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a sam to a bam. :param dict samfile: The input sam file :param str sample_type: Description of the sample to inject into the filename :param dict univ_options: Dict of universal options used by almost all tools :param dict samtools_options: Options specific to samtools :return: fsID for the generated bam :rtype: toil.fileStore.FileID", "response": "def bam_conversion(job, samfile, sample_type, univ_options, samtools_options):\n    \"\"\"\n    Convert a sam to a bam.\n\n    :param dict samfile: The input sam file\n    :param str sample_type: Description of the sample to inject into the filename\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict samtools_options: Options specific to samtools\n    :return: fsID for the generated bam\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        sample_type + '.sam': samfile}\n    input_files = get_files_from_filestore(job, input_files, work_dir,\n                                           docker=True)\n    bamfile = '/'.join([work_dir, sample_type + '.bam'])\n    parameters = ['view',\n                  '-bS',\n                  '-o', docker_path(bamfile),\n                  input_files[sample_type + '.sam']\n                  ]\n    docker_call(tool='samtools', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], tool_version=samtools_options['version'])\n    output_file = job.fileStore.writeGlobalFile(bamfile)\n    # The samfile is no longer useful so delete it\n    job.fileStore.deleteGlobalFile(samfile)\n    job.fileStore.logToMaster('Ran sam2bam on %s:%s successfully'\n                              % (univ_options['patient'], sample_type))\n    return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfix the bam header to remove the command line call. Failing to do this causes Picard to reject the bam. :param dict bamfile: The input bam file :param str sample_type: Description of the sample to inject into the filename :param dict univ_options: Dict of universal options used by almost all tools :param dict samtools_options: Options specific to samtools :param list retained_chroms: A list of chromosomes to retain :return: fsID for the output bam :rtype: toil.fileStore.FileID", "response": "def fix_bam_header(job, bamfile, sample_type, univ_options, samtools_options, retained_chroms=None):\n    \"\"\"\n    Fix the bam header to remove the command line call.  Failing to do this causes Picard to reject\n    the bam.\n\n    :param dict bamfile: The input bam file\n    :param str sample_type: Description of the sample to inject into the filename\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict samtools_options: Options specific to samtools\n    :param list retained_chroms: A list of chromosomes to retain\n    :return: fsID for the output bam\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    if retained_chroms is None:\n        retained_chroms = []\n\n    work_dir = os.getcwd()\n    input_files = {\n        sample_type + '.bam': bamfile}\n    input_files = get_files_from_filestore(job, input_files, work_dir, docker=True)\n    parameters = ['view',\n                  '-H',\n                  input_files[sample_type + '.bam']]\n    with open('/'.join([work_dir, sample_type + '_input_bam.header']), 'w') as headerfile:\n        docker_call(tool='samtools', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=headerfile,\n                    tool_version=samtools_options['version'])\n    with open(headerfile.name, 'r') as headerfile, \\\n            open('/'.join([work_dir, sample_type + '_output_bam.header']), 'w') as outheaderfile:\n        for line in headerfile:\n            if line.startswith('@PG'):\n                line = '\\t'.join([x for x in line.strip().split('\\t') if not x.startswith('CL')])\n            if retained_chroms and line.startswith('@SQ'):\n                if line.strip().split()[1].lstrip('SN:') not in retained_chroms:\n                    continue\n            print(line.strip(), file=outheaderfile)\n    parameters = ['reheader',\n                  docker_path(outheaderfile.name),\n                  input_files[sample_type + '.bam']]\n    with open('/'.join([work_dir, sample_type + '_fixPG.bam']), 'w') as fixpg_bamfile:\n        docker_call(tool='samtools', tool_parameters=parameters, work_dir=work_dir,\n                    dockerhub=univ_options['dockerhub'], outfile=fixpg_bamfile,\n                    tool_version=samtools_options['version'])\n    output_file = job.fileStore.writeGlobalFile(fixpg_bamfile.name)\n    # The old bam file is now useless.\n    job.fileStore.deleteGlobalFile(bamfile)\n    job.fileStore.logToMaster('Ran reheader on %s:%s successfully'\n                              % (univ_options['patient'], sample_type))\n    return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding read groups to the bam. :param dict bamfile: The input bam file :param str sample_type: Description of the sample to inject into the filename :param dict univ_options: Dict of universal options used by almost all tools :param dict picard_options: Options specific to picard :return: fsID for the output bam :rtype: toil.fileStore.FileID", "response": "def add_readgroups(job, bamfile, sample_type, univ_options, picard_options):\n    \"\"\"\n    Add read groups to the bam.\n\n    :param dict bamfile: The input bam file\n    :param str sample_type: Description of the sample to inject into the filename\n    :param dict univ_options: Dict of universal options used by almost all tools\n    :param dict picard_options: Options specific to picard\n    :return: fsID for the output bam\n    :rtype: toil.fileStore.FileID\n    \"\"\"\n    work_dir = os.getcwd()\n    input_files = {\n        sample_type + '.bam': bamfile}\n    get_files_from_filestore(job, input_files, work_dir, docker=True)\n    parameters = ['AddOrReplaceReadGroups',\n                  'CREATE_INDEX=false',\n                  'I=/data/' + sample_type + '.bam',\n                  'O=/data/' + sample_type + '_reheader.bam',\n                  'SO=coordinate',\n                  'ID=1',\n                  ''.join(['LB=', univ_options['patient']]),\n                  'PL=ILLUMINA',\n                  'PU=12345',\n                  ''.join(['SM=', sample_type.rstrip('_dna')])]\n    docker_call(tool='picard', tool_parameters=parameters, work_dir=work_dir,\n                dockerhub=univ_options['dockerhub'], java_xmx=univ_options['java_Xmx'],\n                tool_version=picard_options['version'])\n    output_file = job.fileStore.writeGlobalFile(\n        '/'.join([work_dir, sample_type + '_reheader.bam']))\n    # Delete the old bam file\n    job.fileStore.deleteGlobalFile(bamfile)\n    job.fileStore.logToMaster('Ran add_read_groups on %s:%s successfully'\n                              % (univ_options['patient'], sample_type))\n    return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the FC port - group rbid.", "response": "def _set_fcport_group_rbid(self, v, load=False):\n    \"\"\"\n    Setter method for fcport_group_rbid, mapped from YANG variable /fcoe/fcoe_fabric_map/fcoe_fcport_group_config/fcport_group_rbid (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fcport_group_rbid is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fcport_group_rbid() directly.\n\n    YANG Description: This specifies the FIF rbridge-id/s in the\nFCF Group\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fcport_group_rbid.fcport_group_rbid, is_container='container', presence=False, yang_name=\"fcport-group-rbid\", rest_name=\"fcport-group-rbid\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure fcport-group rbridge-id/s.', u'alt-name': u'fcport-group-rbid', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fcport_group_rbid must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fcport_group_rbid.fcport_group_rbid, is_container='container', presence=False, yang_name=\"fcport-group-rbid\", rest_name=\"fcport-group-rbid\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure fcport-group rbridge-id/s.', u'alt-name': u'fcport-group-rbid', u'cli-suppress-no': None}}, namespace='urn:brocade.com:mgmt:brocade-fcoe', defining_module='brocade-fcoe', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fcport_group_rbid = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_route(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"dest\",route.route, yang_name=\"route\", rest_name=\"route\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dest', extensions={u'tailf-common': {u'info': u'Configure ipv6 static route', u'cli-suppress-list-no': None, u'hidden': u'full', u'cli-suppress-mode': None, u'cli-full-no': None}}), is_container='list', yang_name=\"route\", rest_name=\"route\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure ipv6 static route', u'cli-suppress-list-no': None, u'hidden': u'full', u'cli-suppress-mode': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ip-forward', defining_module='brocade-ip-forward', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"route must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"dest\",route.route, yang_name=\"route\", rest_name=\"route\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dest', extensions={u'tailf-common': {u'info': u'Configure ipv6 static route', u'cli-suppress-list-no': None, u'hidden': u'full', u'cli-suppress-mode': None, u'cli-full-no': None}}), is_container='list', yang_name=\"route\", rest_name=\"route\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure ipv6 static route', u'cli-suppress-list-no': None, u'hidden': u'full', u'cli-suppress-mode': None, u'cli-full-no': None}}, namespace='urn:brocade.com:mgmt:brocade-ip-forward', defining_module='brocade-ip-forward', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__route = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the route of the\n    based on the given route."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_lsp_tie_breaking(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'most-fill': {'value': 2}, u'random': {'value': 0}, u'least-fill': {'value': 1}},), default=unicode(\"random\"), is_leaf=True, yang_name=\"lsp-tie-breaking\", rest_name=\"tie-breaking\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Choose the tie breaking mode for cspf', u'cli-full-no': None, u'alt-name': u'tie-breaking'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='tie-breaking', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_tie_breaking must be of a type compatible with tie-breaking\"\"\",\n          'defined-type': \"brocade-mpls:tie-breaking\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'most-fill': {'value': 2}, u'random': {'value': 0}, u'least-fill': {'value': 1}},), default=unicode(\"random\"), is_leaf=True, yang_name=\"lsp-tie-breaking\", rest_name=\"tie-breaking\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-full-command': None, u'info': u'Choose the tie breaking mode for cspf', u'cli-full-no': None, u'alt-name': u'tie-breaking'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='tie-breaking', is_config=True)\"\"\",\n        })\n\n    self.__lsp_tie_breaking = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the lsp_tie_breaking variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset auto - bandwidth for the given lsp", "response": "def _set_lsp_auto_bandwidth(self, v, load=False):\n    \"\"\"\n    Setter method for lsp_auto_bandwidth, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/lsp_auto_bandwidth (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_auto_bandwidth is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_auto_bandwidth() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lsp_auto_bandwidth.lsp_auto_bandwidth, is_container='container', presence=True, yang_name=\"lsp-auto-bandwidth\", rest_name=\"autobw\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable Auto-bandwidth on primary path', u'callpoint': u'MplsLspAutoBandwidth', u'cli-full-command': None, u'cli-add-mode': None, u'hidden': u'full', u'alt-name': u'autobw', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)-autobw'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_auto_bandwidth must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lsp_auto_bandwidth.lsp_auto_bandwidth, is_container='container', presence=True, yang_name=\"lsp-auto-bandwidth\", rest_name=\"autobw\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Enable Auto-bandwidth on primary path', u'callpoint': u'MplsLspAutoBandwidth', u'cli-full-command': None, u'cli-add-mode': None, u'hidden': u'full', u'alt-name': u'autobw', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)-autobw'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lsp_auto_bandwidth = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the fast reroute options for the specified LSP sequence.", "response": "def _set_lsp_frr(self, v, load=False):\n    \"\"\"\n    Setter method for lsp_frr, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/lsp_frr (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_frr is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_frr() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lsp_frr.lsp_frr, is_container='container', presence=True, yang_name=\"lsp-frr\", rest_name=\"frr\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set Fast Reroute options', u'callpoint': u'MplsLspFrr', u'cli-full-command': None, u'cli-add-mode': None, u'alt-name': u'frr', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)-frr'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_frr must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lsp_frr.lsp_frr, is_container='container', presence=True, yang_name=\"lsp-frr\", rest_name=\"frr\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set Fast Reroute options', u'callpoint': u'MplsLspFrr', u'cli-full-command': None, u'cli-add-mode': None, u'alt-name': u'frr', u'cli-mode-name': u'config-router-mpls-lsp-$(lsp-name)-frr'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lsp_frr = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset secondary path for the LSP", "response": "def _set_secondary_path(self, v, load=False):\n    \"\"\"\n    Setter method for secondary_path, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/secondary_path (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_secondary_path is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_secondary_path() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"secpath_name\",secondary_path.secondary_path, yang_name=\"secondary-path\", rest_name=\"secondary-path\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='secpath-name', extensions={u'tailf-common': {u'info': u'Define Secondary Path for the LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLspSecPath', u'cli-mode-name': u'config-router-mpls-lsp-$(../lsp-name)-secpath-$(secpath-name)'}}), is_container='list', yang_name=\"secondary-path\", rest_name=\"secondary-path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Secondary Path for the LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLspSecPath', u'cli-mode-name': u'config-router-mpls-lsp-$(../lsp-name)-secpath-$(secpath-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"secondary_path must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"secpath_name\",secondary_path.secondary_path, yang_name=\"secondary-path\", rest_name=\"secondary-path\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='secpath-name', extensions={u'tailf-common': {u'info': u'Define Secondary Path for the LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLspSecPath', u'cli-mode-name': u'config-router-mpls-lsp-$(../lsp-name)-secpath-$(secpath-name)'}}), is_container='list', yang_name=\"secondary-path\", rest_name=\"secondary-path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Secondary Path for the LSP', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsLspSecPath', u'cli-mode-name': u'config-router-mpls-lsp-$(../lsp-name)-secpath-$(secpath-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__secondary_path = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the selected path in the order of the selected paths.", "response": "def _set_lsp_select_path(self, v, load=False):\n    \"\"\"\n    Setter method for lsp_select_path, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/lsp/lsp_select_path (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lsp_select_path is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lsp_select_path() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lsp_select_path.lsp_select_path, is_container='container', presence=False, yang_name=\"lsp-select-path\", rest_name=\"select-path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set select-path parameters', u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'alt-name': u'select-path'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lsp_select_path must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lsp_select_path.lsp_select_path, is_container='container', presence=False, yang_name=\"lsp-select-path\", rest_name=\"select-path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Set select-path parameters', u'cli-full-no': None, u'cli-compact-syntax': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'alt-name': u'select-path'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lsp_select_path = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the fe_access_check property of the .", "response": "def _set_fe_access_check(self, v, load=False):\n    \"\"\"\n    Setter method for fe_access_check, mapped from YANG variable /sysmon/fe_access_check (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_fe_access_check is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_fe_access_check() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fe_access_check.fe_access_check, is_container='container', presence=False, yang_name=\"fe-access-check\", rest_name=\"fe-access-check\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Fe Access Check', u'callpoint': u'feAccessCheck', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmon', defining_module='brocade-sysmon', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fe_access_check must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fe_access_check.fe_access_check, is_container='container', presence=False, yang_name=\"fe-access-check\", rest_name=\"fe-access-check\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Fe Access Check', u'callpoint': u'feAccessCheck', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmon', defining_module='brocade-sysmon', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fe_access_check = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the value of link_crc_monitoring in the base node.", "response": "def _set_link_crc_monitoring(self, v, load=False):\n    \"\"\"\n    Setter method for link_crc_monitoring, mapped from YANG variable /sysmon/link_crc_monitoring (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_link_crc_monitoring is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_link_crc_monitoring() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=link_crc_monitoring.link_crc_monitoring, is_container='container', presence=False, yang_name=\"link-crc-monitoring\", rest_name=\"link-crc-monitoring\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Link CRC Monitoring', u'callpoint': u'linkCrcMonitoring', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmon', defining_module='brocade-sysmon', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"link_crc_monitoring must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=link_crc_monitoring.link_crc_monitoring, is_container='container', presence=False, yang_name=\"link-crc-monitoring\", rest_name=\"link-crc-monitoring\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Link CRC Monitoring', u'callpoint': u'linkCrcMonitoring', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmon', defining_module='brocade-sysmon', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__link_crc_monitoring = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_sfm_walk(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=sfm_walk.sfm_walk, is_container='container', presence=False, yang_name=\"sfm-walk\", rest_name=\"sfm-walk\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'SFM Walk', u'callpoint': u'sfmWalk', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmon', defining_module='brocade-sysmon', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"sfm_walk must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=sfm_walk.sfm_walk, is_container='container', presence=False, yang_name=\"sfm-walk\", rest_name=\"sfm-walk\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'SFM Walk', u'callpoint': u'sfmWalk', u'cli-incomplete-no': None, u'cli-incomplete-command': None}}, namespace='urn:brocade.com:mgmt:brocade-sysmon', defining_module='brocade-sysmon', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__sfm_walk = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the SFM_WATCH variable in the sysmon output."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_servers(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"relay_ip_addr server_vrf_name\",servers.servers, yang_name=\"servers\", rest_name=\"servers\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='relay-ip-addr server-vrf-name', extensions={u'tailf-common': {u'info': u'DHCP Server IP Address', u'cli-run-template-enter': u' ip dhcp relay address$(relay-ip-addr) $($(server-vrf-name)==.?: use-vrf $(server-vrf-name))\\n', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'callpoint': u'DHCPRelayPhyInterfaceCallPoint'}}), is_container='list', yang_name=\"servers\", rest_name=\"servers\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'DHCP Server IP Address', u'cli-run-template-enter': u' ip dhcp relay address$(relay-ip-addr) $($(server-vrf-name)==.?: use-vrf $(server-vrf-name))\\n', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'callpoint': u'DHCPRelayPhyInterfaceCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-dhcp', defining_module='brocade-dhcp', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"servers must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"relay_ip_addr server_vrf_name\",servers.servers, yang_name=\"servers\", rest_name=\"servers\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='relay-ip-addr server-vrf-name', extensions={u'tailf-common': {u'info': u'DHCP Server IP Address', u'cli-run-template-enter': u' ip dhcp relay address$(relay-ip-addr) $($(server-vrf-name)==.?: use-vrf $(server-vrf-name))\\n', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'callpoint': u'DHCPRelayPhyInterfaceCallPoint'}}), is_container='list', yang_name=\"servers\", rest_name=\"servers\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'DHCP Server IP Address', u'cli-run-template-enter': u' ip dhcp relay address$(relay-ip-addr) $($(server-vrf-name)==.?: use-vrf $(server-vrf-name))\\n', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-drop-node-name': None, u'callpoint': u'DHCPRelayPhyInterfaceCallPoint'}}, namespace='urn:brocade.com:mgmt:brocade-dhcp', defining_module='brocade-dhcp', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__servers = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the list of servers in the order they are added to the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_ldp_protocol_stats_instance_total(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_protocol_stats_instance_total.ldp_protocol_stats_instance_total, is_container='container', presence=False, yang_name=\"ldp-protocol-stats-instance-total\", rest_name=\"ldp-protocol-stats-instance-total\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-protocol-stats-instance-ldp-protocol-stats-instance-total-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_protocol_stats_instance_total must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_protocol_stats_instance_total.ldp_protocol_stats_instance_total, is_container='container', presence=False, yang_name=\"ldp-protocol-stats-instance-total\", rest_name=\"ldp-protocol-stats-instance-total\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-protocol-stats-instance-ldp-protocol-stats-instance-total-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_protocol_stats_instance_total = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ldp - protocol - stats - instance - total value for the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value of ldp_protocol_stats_instance_since_clear in the current state of the tree.", "response": "def _set_ldp_protocol_stats_instance_since_clear(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_protocol_stats_instance_since_clear, mapped from YANG variable /mpls_state/ldp/statistics/ldp_protocol_stats_instance_since_clear (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_protocol_stats_instance_since_clear is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_protocol_stats_instance_since_clear() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_protocol_stats_instance_since_clear.ldp_protocol_stats_instance_since_clear, is_container='container', presence=False, yang_name=\"ldp-protocol-stats-instance-since-clear\", rest_name=\"ldp-protocol-stats-instance-since-clear\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-protocol-stats-instance-ldp-protocol-stats-instance-since-clear-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_protocol_stats_instance_since_clear must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_protocol_stats_instance_since_clear.ldp_protocol_stats_instance_since_clear, is_container='container', presence=False, yang_name=\"ldp-protocol-stats-instance-since-clear\", rest_name=\"ldp-protocol-stats-instance-since-clear\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-protocol-stats-instance-ldp-protocol-stats-instance-since-clear-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_protocol_stats_instance_since_clear = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the value of ldp_protocol_errors_instance_since_clear in the current state of the object.", "response": "def _set_ldp_protocol_errors_instance_since_clear(self, v, load=False):\n    \"\"\"\n    Setter method for ldp_protocol_errors_instance_since_clear, mapped from YANG variable /mpls_state/ldp/statistics/ldp_protocol_errors_instance_since_clear (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_ldp_protocol_errors_instance_since_clear is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_ldp_protocol_errors_instance_since_clear() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp_protocol_errors_instance_since_clear.ldp_protocol_errors_instance_since_clear, is_container='container', presence=False, yang_name=\"ldp-protocol-errors-instance-since-clear\", rest_name=\"ldp-protocol-errors-instance-since-clear\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-protocol-errors-instance-ldp-protocol-errors-instance-since-clear-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp_protocol_errors_instance_since_clear must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp_protocol_errors_instance_since_clear.ldp_protocol_errors_instance_since_clear, is_container='container', presence=False, yang_name=\"ldp-protocol-errors-instance-since-clear\", rest_name=\"ldp-protocol-errors-instance-since-clear\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp-protocol-errors-instance-ldp-protocol-errors-instance-since-clear-1'}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp_protocol_errors_instance_since_clear = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the distance of the cluster.", "response": "def _set_distance(self, v, load=False):\n    \"\"\"\n    Setter method for distance, mapped from YANG variable /routing_system/ipv6/router/ospf/distance (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_distance is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_distance() directly.\n\n    YANG Description: A unique administrative distance can be configured for each type of OSPFv3 route. This can be used to influence the device to prefer a static route over an OSPF inter-area route and to prefer OSPF intra-area routes to static routes.The distance specified influences the choice of routes when the device has multiple routes to the same network from different protocols. The device prefers the route with the lower administrative distance.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"route_type\",distance.distance, yang_name=\"distance\", rest_name=\"distance\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='route-type', extensions={u'tailf-common': {u'info': u'Define an administrative distance', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'Ospfv3Distance'}}), is_container='list', yang_name=\"distance\", rest_name=\"distance\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define an administrative distance', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'Ospfv3Distance'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"distance must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"route_type\",distance.distance, yang_name=\"distance\", rest_name=\"distance\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='route-type', extensions={u'tailf-common': {u'info': u'Define an administrative distance', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'Ospfv3Distance'}}), is_container='list', yang_name=\"distance\", rest_name=\"distance\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define an administrative distance', u'cli-suppress-mode': None, u'cli-suppress-list-no': None, u'cli-sequence-commands': None, u'cli-incomplete-command': None, u'callpoint': u'Ospfv3Distance'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__distance = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the global metric type for the cluster.", "response": "def _set_global_metric_type(self, v, load=False):\n    \"\"\"\n    Setter method for global_metric_type, mapped from YANG variable /routing_system/ipv6/router/ospf/global_metric_type (ospf:metric-type)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_global_metric_type is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_global_metric_type() directly.\n\n    YANG Description: OSPFv3 metric type for redistributed routes\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'type1': {'value': 1}, u'type2': {'value': 2}},), is_leaf=True, yang_name=\"global-metric-type\", rest_name=\"metric-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'OSPFv3 metric type for redistributed routes', u'alt-name': u'metric-type'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='ospf:metric-type', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"global_metric_type must be of a type compatible with ospf:metric-type\"\"\",\n          'defined-type': \"ospf:metric-type\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'type1': {'value': 1}, u'type2': {'value': 2}},), is_leaf=True, yang_name=\"global-metric-type\", rest_name=\"metric-type\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'OSPFv3 metric type for redistributed routes', u'alt-name': u'metric-type'}}, namespace='urn:brocade.com:mgmt:brocade-ospfv3', defining_module='brocade-ospfv3', yang_type='ospf:metric-type', is_config=True)\"\"\",\n        })\n\n    self.__global_metric_type = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the weekday of the date. 0 = aaitabar", "response": "def weekday(cls, year, month, day):\n        \"\"\"Returns the weekday of the date. 0 = aaitabar\"\"\"\n        return NepDate.from_bs_date(year, month, day).weekday()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef monthrange(cls, year, month):\n        functions.check_valid_bs_range(NepDate(year, month, 1))\n        return values.NEPALI_MONTH_DAY_DATA[year][month - 1]", "response": "Returns the number of days in a month"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef itermonthdates(cls, year, month):\n        curday = NepDate.from_bs_date(year, month, 1)\n        start_weekday = curday.weekday()\n        # Start_weekday represents the number of days we have to pad\n        for i in range(start_weekday, 0, -1):\n            yield (curday - timedelta(days=i))\n\n        for i in range(0, values.NEPALI_MONTH_DAY_DATA[year][month - 1]):\n            if i > 0:\n                curday.day += 1\n                curday.en_date = curday.en_date + timedelta(days=1)\n            # Create a new object and return it\n            n_date = NepDate(curday.year, curday.month, curday.day)\n            n_date.en_date = curday.en_date\n            yield n_date\n        # Now, curday points to the last day of the month. Check it's weekday\n        # and return days from next month to complete the week\n        last_weekday = curday.weekday()\n        remain = 6 - last_weekday\n\n        for i in range(1, remain + 1):\n            yield (curday + timedelta(days=i))", "response": "Iterate over the month dates in a year."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef itermonthdays(cls, year, month):\n        for day in NepCal.itermonthdates(year, month):\n            if day.month == month:\n                yield day.day\n            else:\n                yield 0", "response": "Similar to itermonthdates but returns day number instead of NepDate object\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef itermonthdays2(cls, year, month):\n        for day in NepCal.itermonthdates(year, month):\n            if day.month == month:\n                yield (day.day, day.weekday())\n            else:\n                yield (0, day.weekday())", "response": "Similar to itermonthdays but returns tuples of day and weekday."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of week in a month. A week is a list of NepDate objects.", "response": "def monthdatescalendar(cls, year, month):\n        \"\"\" Returns a list of week in a month. A week is a list of NepDate objects \"\"\"\n        weeks = []\n        week = []\n        for day in NepCal.itermonthdates(year, month):\n            week.append(day)\n            if len(week) == 7:\n                weeks.append(week)\n                week = []\n        if len(week) > 0:\n            weeks.append(week)\n        return weeks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef monthdayscalendar(cls, year, month):\n        weeks = []\n        week = []\n        for day in NepCal.itermonthdays(year, month):\n            week.append(day)\n            if len(week) == 7:\n                weeks.append(week)\n                week = []\n        if len(week) > 0:\n            weeks.append(week)\n        return weeks", "response": "Return a list of the weeks in the month of the year as full weeks. Weeks are lists of seven day numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of the weeks in the month of the year as full weeks.", "response": "def monthdays2calendar(cls, year, month):\n        \"\"\" Return a list of the weeks in the month month of the year as full weeks.\n        Weeks are lists of seven tuples of day numbers and weekday numbers. \"\"\"\n        weeks = []\n        week = []\n        for day in NepCal.itermonthdays2(year, month):\n            week.append(day)\n            if len(week) == 7:\n                weeks.append(week)\n                week = []\n        if len(week) > 0:\n            weeks.append(week)\n        return weeks"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the limit of the MAC move detector.", "response": "def _set_mac_move_limit(self, v, load=False):\n    \"\"\"\n    Setter method for mac_move_limit, mapped from YANG variable /mac_address_table/mac_move/mac_move_limit (uint32)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mac_move_limit is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mac_move_limit() directly.\n\n    YANG Description: MAC move detect limit (default = 20)\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'5..500']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(20), is_leaf=True, yang_name=\"mac-move-limit\", rest_name=\"limit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC move detect limit (default = 20)', u'cli-full-command': None, u'alt-name': u'limit'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='uint32', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mac_move_limit must be of a type compatible with uint32\"\"\",\n          'defined-type': \"uint32\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32), restriction_dict={'range': [u'5..500']}), default=RestrictedClassType(base_type=long, restriction_dict={'range': ['0..4294967295']}, int_size=32)(20), is_leaf=True, yang_name=\"mac-move-limit\", rest_name=\"limit\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'MAC move detect limit (default = 20)', u'cli-full-command': None, u'alt-name': u'limit'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='uint32', is_config=True)\"\"\",\n        })\n\n    self.__mac_move_limit = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_mac_move_action(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'raslog': {'value': 2}, u'shutdown': {'value': 1}},), default=unicode(\"shutdown\"), is_leaf=True, yang_name=\"mac-move-action\", rest_name=\"action\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Action on MAC move', u'cli-full-command': None, u'alt-name': u'action'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mac_move_action must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-mac-address-table:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'raslog': {'value': 2}, u'shutdown': {'value': 1}},), default=unicode(\"shutdown\"), is_leaf=True, yang_name=\"mac-move-action\", rest_name=\"action\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Action on MAC move', u'cli-full-command': None, u'alt-name': u'action'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__mac_move_action = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the action of the MAC move sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets auto recovery of port on MAC move", "response": "def _set_auto_recovery(self, v, load=False):\n    \"\"\"\n    Setter method for auto_recovery, mapped from YANG variable /mac_address_table/mac_move/auto_recovery (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_auto_recovery is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_auto_recovery() directly.\n\n    YANG Description: Auto recovery of port on MAC move\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=auto_recovery.auto_recovery, is_container='container', presence=False, yang_name=\"auto-recovery\", rest_name=\"auto-recovery\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Auto recovery of port on MAC move'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"auto_recovery must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=auto_recovery.auto_recovery, is_container='container', presence=False, yang_name=\"auto-recovery\", rest_name=\"auto-recovery\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Auto recovery of port on MAC move'}}, namespace='urn:brocade.com:mgmt:brocade-mac-address-table', defining_module='brocade-mac-address-table', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__auto_recovery = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of the MPLS Traffic LSPs field in the MPL file.", "response": "def _set_mpls_traffic_lsps(self, v, load=False):\n    \"\"\"\n    Setter method for mpls_traffic_lsps, mapped from YANG variable /telemetry/profile/mpls_traffic_lsp/mpls_traffic_lsps (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_mpls_traffic_lsps is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_mpls_traffic_lsps() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"mpls_traffic_lsp_name\",mpls_traffic_lsps.mpls_traffic_lsps, yang_name=\"mpls-traffic-lsps\", rest_name=\"lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='mpls-traffic-lsp-name', extensions={u'tailf-common': {u'callpoint': u'Mplstrafficlsp', u'cli-suppress-mode': None, u'alt-name': u'lsp', u'info': u'MPLS Stats profile by LSP name', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"mpls-traffic-lsps\", rest_name=\"lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'Mplstrafficlsp', u'cli-suppress-mode': None, u'alt-name': u'lsp', u'info': u'MPLS Stats profile by LSP name', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"mpls_traffic_lsps must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"mpls_traffic_lsp_name\",mpls_traffic_lsps.mpls_traffic_lsps, yang_name=\"mpls-traffic-lsps\", rest_name=\"lsp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='mpls-traffic-lsp-name', extensions={u'tailf-common': {u'callpoint': u'Mplstrafficlsp', u'cli-suppress-mode': None, u'alt-name': u'lsp', u'info': u'MPLS Stats profile by LSP name', u'cli-suppress-list-no': None}}), is_container='list', yang_name=\"mpls-traffic-lsps\", rest_name=\"lsp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'Mplstrafficlsp', u'cli-suppress-mode': None, u'alt-name': u'lsp', u'info': u'MPLS Stats profile by LSP name', u'cli-suppress-list-no': None}}, namespace='urn:brocade.com:mgmt:brocade-telemetry', defining_module='brocade-telemetry', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__mpls_traffic_lsps = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_ldp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=ldp.ldp, is_container='container', presence=False, yang_name=\"ldp\", rest_name=\"ldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"ldp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=ldp.ldp, is_container='container', presence=False, yang_name=\"ldp\", rest_name=\"ldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-ldp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__ldp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the ldp property of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_policy(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=policy.policy, is_container='container', presence=False, yang_name=\"policy\", rest_name=\"policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-policy', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"policy must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=policy.policy, is_container='container', presence=False, yang_name=\"policy\", rest_name=\"policy\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-policy', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__policy = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the policy of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_rsvp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=rsvp.rsvp, is_container='container', presence=False, yang_name=\"rsvp\", rest_name=\"rsvp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-rsvp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"rsvp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=rsvp.rsvp, is_container='container', presence=False, yang_name=\"rsvp\", rest_name=\"rsvp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-rsvp', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__rsvp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the rsvp property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the dynamic bypass of the", "response": "def _set_dynamic_bypass(self, v, load=False):\n    \"\"\"\n    Setter method for dynamic_bypass, mapped from YANG variable /mpls_state/dynamic_bypass (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dynamic_bypass is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dynamic_bypass() directly.\n\n    YANG Description: MPLS dynamic bypass\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=dynamic_bypass.dynamic_bypass, is_container='container', presence=False, yang_name=\"dynamic-bypass\", rest_name=\"dynamic-bypass\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-dynamic-bypass', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dynamic_bypass must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=dynamic_bypass.dynamic_bypass, is_container='container', presence=False, yang_name=\"dynamic-bypass\", rest_name=\"dynamic-bypass\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-dynamic-bypass', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__dynamic_bypass = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the te field of the", "response": "def _set_te(self, v, load=False):\n    \"\"\"\n    Setter method for te, mapped from YANG variable /mpls_state/te (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_te is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_te() directly.\n\n    YANG Description: MPLS Traffic Engineering Operational Information\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=te.te, is_container='container', presence=False, yang_name=\"te\", rest_name=\"te\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-te', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"te must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=te.te, is_container='container', presence=False, yang_name=\"te\", rest_name=\"te\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-te', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__te = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the autobw_threshold_table_summary property of the autobw_threshold_table_summary variable.", "response": "def _set_autobw_threshold_table_summary(self, v, load=False):\n    \"\"\"\n    Setter method for autobw_threshold_table_summary, mapped from YANG variable /mpls_state/autobw_threshold_table_summary (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_autobw_threshold_table_summary is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_autobw_threshold_table_summary() directly.\n\n    YANG Description: MPLS Auto Bandwidth Threshold TableSummary\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=autobw_threshold_table_summary.autobw_threshold_table_summary, is_container='container', presence=False, yang_name=\"autobw-threshold-table-summary\", rest_name=\"autobw-threshold-table-summary\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-autobw-threshold-table-summary', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"autobw_threshold_table_summary must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=autobw_threshold_table_summary.autobw_threshold_table_summary, is_container='container', presence=False, yang_name=\"autobw-threshold-table-summary\", rest_name=\"autobw-threshold-table-summary\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-autobw-threshold-table-summary', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__autobw_threshold_table_summary = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the statistics_oam variable.", "response": "def _set_statistics_oam(self, v, load=False):\n    \"\"\"\n    Setter method for statistics_oam, mapped from YANG variable /mpls_state/statistics_oam (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_statistics_oam is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_statistics_oam() directly.\n\n    YANG Description: OAM packet statistics\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=statistics_oam.statistics_oam, is_container='container', presence=False, yang_name=\"statistics-oam\", rest_name=\"statistics-oam\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-statistics-oam', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"statistics_oam must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=statistics_oam.statistics_oam, is_container='container', presence=False, yang_name=\"statistics-oam\", rest_name=\"statistics-oam\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'mpls-statistics-oam', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__statistics_oam = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of the bridge_domain_counter variable in the network.", "response": "def _set_bridge_domain_counter(self, v, load=False):\n    \"\"\"\n    Setter method for bridge_domain_counter, mapped from YANG variable /bridge_domain_state/bridge_domain_counter (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_bridge_domain_counter is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_bridge_domain_counter() directly.\n\n    YANG Description:  bridge_domain_counter\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=bridge_domain_counter.bridge_domain_counter, is_container='container', presence=False, yang_name=\"bridge-domain-counter\", rest_name=\"bridge-domain-counter\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-bridge-domain-counter', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"bridge_domain_counter must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=bridge_domain_counter.bridge_domain_counter, is_container='container', presence=False, yang_name=\"bridge-domain-counter\", rest_name=\"bridge-domain-counter\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'callpoint': u'nsm-bridge-domain-counter', u'cli-suppress-show-path': None}}, namespace='urn:brocade.com:mgmt:brocade-nsm-operational', defining_module='brocade-nsm-operational', yang_type='container', is_config=False)\"\"\",\n        })\n\n    self.__bridge_domain_counter = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the path of the based on the path_name property.", "response": "def _set_path(self, v, load=False):\n    \"\"\"\n    Setter method for path, mapped from YANG variable /mpls_config/router/mpls/mpls_cmds_holder/path (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_path is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_path() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"path_name\",path.path, yang_name=\"path\", rest_name=\"path\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='path-name', extensions={u'tailf-common': {u'info': u'Define Path', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsPath', u'cli-mode-name': u'config-router-mpls-path-$(path-name)'}}), is_container='list', yang_name=\"path\", rest_name=\"path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Path', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsPath', u'cli-mode-name': u'config-router-mpls-path-$(path-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"path must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"path_name\",path.path, yang_name=\"path\", rest_name=\"path\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='path-name', extensions={u'tailf-common': {u'info': u'Define Path', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsPath', u'cli-mode-name': u'config-router-mpls-path-$(path-name)'}}), is_container='list', yang_name=\"path\", rest_name=\"path\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Define Path', u'cli-suppress-list-no': None, u'cli-no-key-completion': None, u'callpoint': u'MplsPath', u'cli-mode-name': u'config-router-mpls-path-$(path-name)'}}, namespace='urn:brocade.com:mgmt:brocade-mpls', defining_module='brocade-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__path = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_igmpPIM(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=igmpPIM.igmpPIM, is_container='container', presence=False, yang_name=\"igmpPIM\", rest_name=\"pim\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IP PIM Snooping', u'alt-name': u'pim', u'cli-incomplete-no': None, u'sort-priority': u'128', u'hidden': u'full', u'callpoint': u'IgmpsVlan'}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmpPIM must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=igmpPIM.igmpPIM, is_container='container', presence=False, yang_name=\"igmpPIM\", rest_name=\"pim\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'IP PIM Snooping', u'alt-name': u'pim', u'cli-incomplete-no': None, u'sort-priority': u'128', u'hidden': u'full', u'callpoint': u'IgmpsVlan'}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__igmpPIM = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of the igmpPIM variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_igmpVlan(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=igmpVlan.igmpVlan, is_container='container', presence=False, yang_name=\"igmpVlan\", rest_name=\"igmp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Internet Group Management Protocol (IGMP)', u'cli-incomplete-no': None, u'callpoint': u'IgmpsVlan', u'sort-priority': u'129', u'alt-name': u'igmp'}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"igmpVlan must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=igmpVlan.igmpVlan, is_container='container', presence=False, yang_name=\"igmpVlan\", rest_name=\"igmp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Internet Group Management Protocol (IGMP)', u'cli-incomplete-no': None, u'callpoint': u'IgmpsVlan', u'sort-priority': u'129', u'alt-name': u'igmp'}}, namespace='urn:brocade.com:mgmt:brocade-igmp-snooping', defining_module='brocade-igmp-snooping', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__igmpVlan = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the value of igmpVlan in the base node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the logical_instance of the specified virtual environment.", "response": "def _set_logical_instance(self, v, load=False):\n    \"\"\"\n    Setter method for logical_instance, mapped from YANG variable /rbridge_id/openflow/logical_instance (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_logical_instance is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_logical_instance() directly.\n\n    YANG Description: OpenFlow logical instance configuration. There can be multiple\nlogical instances under a physical switch.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"instance_id\",logical_instance.logical_instance, yang_name=\"logical-instance\", rest_name=\"logical-instance\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='instance-id', extensions={u'tailf-common': {u'info': u'OpenFlow logical instance configuration', u'callpoint': u'OpenFlowLogicalInstance'}}), is_container='list', yang_name=\"logical-instance\", rest_name=\"logical-instance\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'OpenFlow logical instance configuration', u'callpoint': u'OpenFlowLogicalInstance'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"logical_instance must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"instance_id\",logical_instance.logical_instance, yang_name=\"logical-instance\", rest_name=\"logical-instance\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='instance-id', extensions={u'tailf-common': {u'info': u'OpenFlow logical instance configuration', u'callpoint': u'OpenFlowLogicalInstance'}}), is_container='list', yang_name=\"logical-instance\", rest_name=\"logical-instance\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'OpenFlow logical instance configuration', u'callpoint': u'OpenFlowLogicalInstance'}}, namespace='urn:brocade.com:mgmt:brocade-openflow', defining_module='brocade-openflow', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__logical_instance = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_cfg(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"cfg_name\",cfg.cfg, yang_name=\"cfg\", rest_name=\"cfg\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cfg-name', extensions={u'tailf-common': {u'info': u'List of defined CFGs', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_cfg'}}), is_container='list', yang_name=\"cfg\", rest_name=\"cfg\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined CFGs', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_cfg'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cfg must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"cfg_name\",cfg.cfg, yang_name=\"cfg\", rest_name=\"cfg\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='cfg-name', extensions={u'tailf-common': {u'info': u'List of defined CFGs', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_cfg'}}), is_container='list', yang_name=\"cfg\", rest_name=\"cfg\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined CFGs', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_cfg'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__cfg = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of cfg in the base order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the zone of the based on zone_name", "response": "def _set_zone(self, v, load=False):\n    \"\"\"\n    Setter method for zone, mapped from YANG variable /zoning/defined_configuration/zone (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_zone is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_zone() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"zone_name\",zone.zone, yang_name=\"zone\", rest_name=\"zone\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='zone-name', extensions={u'tailf-common': {u'info': u'List of defined Zones', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_zone'}}), is_container='list', yang_name=\"zone\", rest_name=\"zone\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined Zones', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_zone'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"zone must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"zone_name\",zone.zone, yang_name=\"zone\", rest_name=\"zone\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='zone-name', extensions={u'tailf-common': {u'info': u'List of defined Zones', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_zone'}}), is_container='list', yang_name=\"zone\", rest_name=\"zone\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined Zones', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_zone'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__zone = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_alias(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"alias_name\",alias.alias, yang_name=\"alias\", rest_name=\"alias\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='alias-name', extensions={u'tailf-common': {u'info': u'List of defined Zone Aliases', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_alias'}}), is_container='list', yang_name=\"alias\", rest_name=\"alias\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined Zone Aliases', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_alias'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"alias must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"alias_name\",alias.alias, yang_name=\"alias\", rest_name=\"alias\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='alias-name', extensions={u'tailf-common': {u'info': u'List of defined Zone Aliases', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_alias'}}), is_container='list', yang_name=\"alias\", rest_name=\"alias\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'List of defined Zone Aliases', u'cli-no-key-completion': None, u'cli-full-no': None, u'cli-suppress-key-abbreviation': None, u'cli-full-command': None, u'callpoint': u'zone_defined_alias'}}, namespace='urn:brocade.com:mgmt:brocade-zone', defining_module='brocade-zone', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__alias = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the alias of the\n    based on the given list of aliases."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_fan(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=fan.fan, is_container='container', presence=False, yang_name=\"fan\", rest_name=\"fan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold and alert setting for \\n component:FAN', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"fan must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=fan.fan, is_container='container', presence=False, yang_name=\"fan\", rest_name=\"fan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold and alert setting for \\n component:FAN', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__fan = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the fan value for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the temperature of the", "response": "def _set_temp(self, v, load=False):\n    \"\"\"\n    Setter method for temp, mapped from YANG variable /system_monitor/temp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_temp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_temp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=temp.temp, is_container='container', presence=False, yang_name=\"temp\", rest_name=\"temp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold for component:TEMPERATURE SENSOR', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"temp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=temp.temp, is_container='container', presence=False, yang_name=\"temp\", rest_name=\"temp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold for component:TEMPERATURE SENSOR', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__temp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the cid_card of the", "response": "def _set_cid_card(self, v, load=False):\n    \"\"\"\n    Setter method for cid_card, mapped from YANG variable /system_monitor/cid_card (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_cid_card is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_cid_card() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=cid_card.cid_card, is_container='container', presence=False, yang_name=\"cid-card\", rest_name=\"cid-card\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold and alert setting for\\ncomponent:CID-CARD', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"cid_card must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=cid_card.cid_card, is_container='container', presence=False, yang_name=\"cid-card\", rest_name=\"cid-card\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold and alert setting for\\ncomponent:CID-CARD', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__cid_card = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_compact_flash(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=compact_flash.compact_flash, is_container='container', presence=False, yang_name=\"compact-flash\", rest_name=\"compact-flash\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold for component:COMPACT-FLASH', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"compact_flash must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=compact_flash.compact_flash, is_container='container', presence=False, yang_name=\"compact-flash\", rest_name=\"compact-flash\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold for component:COMPACT-FLASH', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__compact_flash = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the compact_flash variable for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the MM variable.", "response": "def _set_MM(self, v, load=False):\n    \"\"\"\n    Setter method for MM, mapped from YANG variable /system_monitor/MM (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_MM is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_MM() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=MM.MM, is_container='container', presence=False, yang_name=\"MM\", rest_name=\"MM\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold setting for \\n component:MM', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"MM must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=MM.MM, is_container='container', presence=False, yang_name=\"MM\", rest_name=\"MM\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold setting for \\n component:MM', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__MM = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the LineCard field of the .", "response": "def _set_LineCard(self, v, load=False):\n    \"\"\"\n    Setter method for LineCard, mapped from YANG variable /system_monitor/LineCard (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_LineCard is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_LineCard() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=LineCard.LineCard, is_container='container', presence=False, yang_name=\"LineCard\", rest_name=\"LineCard\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold and alert setting for \\n component:LineCard', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"LineCard must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=LineCard.LineCard, is_container='container', presence=False, yang_name=\"LineCard\", rest_name=\"LineCard\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold and alert setting for \\n component:LineCard', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__LineCard = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_SFM(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=SFM.SFM, is_container='container', presence=False, yang_name=\"SFM\", rest_name=\"SFM\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold setting for \\n component:SFM', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"SFM must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=SFM.SFM, is_container='container', presence=False, yang_name=\"SFM\", rest_name=\"SFM\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure threshold setting for \\n component:SFM', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__SFM = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the SOFM variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_port(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=port.port, is_container='container', presence=True, yang_name=\"port\", rest_name=\"port\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Port Monitoring', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-full-command': None, u'callpoint': u'PortCrcMonitoring', u'cli-mode-name': u'config-sys-mon-port'}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"port must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=port.port, is_container='container', presence=True, yang_name=\"port\", rest_name=\"port\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Port Monitoring', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-full-command': None, u'callpoint': u'PortCrcMonitoring', u'cli-mode-name': u'config-sys-mon-port'}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__port = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the port property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of the tm variable in the system monitor", "response": "def _set_tm(self, v, load=False):\n    \"\"\"\n    Setter method for tm, mapped from YANG variable /system_monitor/tm (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_tm is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_tm() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tm.tm, is_container='container', presence=True, yang_name=\"tm\", rest_name=\"tm\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Traffic Manager', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-full-command': None, u'callpoint': u'tmCngnMon', u'cli-mode-name': u'config-sys-mon-tm'}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tm must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tm.tm, is_container='container', presence=True, yang_name=\"tm\", rest_name=\"tm\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Traffic Manager', u'cli-suppress-no': None, u'cli-add-mode': None, u'cli-full-command': None, u'callpoint': u'tmCngnMon', u'cli-mode-name': u'config-sys-mon-tm'}}, namespace='urn:brocade.com:mgmt:brocade-system-monitor', defining_module='brocade-system-monitor', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tm = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of the lldp field.", "response": "def _set_lldp(self, v, load=False):\n    \"\"\"\n    Setter method for lldp, mapped from YANG variable /protocol/lldp (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_lldp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_lldp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=lldp.lldp, is_container='container', presence=True, yang_name=\"lldp\", rest_name=\"lldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Link Layer Discovery Protocol(LLDP)', u'callpoint': u'lldp_global_conf', u'sort-priority': u'49', u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'cli-mode-name': u'conf-lldp'}}, namespace='urn:brocade.com:mgmt:brocade-lldp', defining_module='brocade-lldp', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"lldp must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=lldp.lldp, is_container='container', presence=True, yang_name=\"lldp\", rest_name=\"lldp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Link Layer Discovery Protocol(LLDP)', u'callpoint': u'lldp_global_conf', u'sort-priority': u'49', u'cli-full-command': None, u'cli-add-mode': None, u'cli-full-no': None, u'cli-mode-name': u'conf-lldp'}}, namespace='urn:brocade.com:mgmt:brocade-lldp', defining_module='brocade-lldp', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__lldp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of the enumList property of the base base", "response": "def _set_enumList(self, v, load=False):\n    \"\"\"\n    Setter method for enumList, mapped from YANG variable /rule/command/enumList (enumeration)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_enumList is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_enumList() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'debug1': {}, u'system-monitor': {}, u'qos': {}, u'ag': {}, u'ip': {'value': 48}, u'mac-rebalance': {}, u'switch-attributes': {'value': 55}, u'python': {}, u'lacp': {}, u'unlock': {}, u'service': {}, u'port-profile': {}, u'tacacs-server': {}, u'mac-address-table': {}, u'vCenter': {}, u'terminal': {}, u'management': {}, u'monitor': {}, u'lccli': {}, u'snmp-server': {}, u'diag': {}, u'support': {}, u'firmware': {}, u'ldap-server': {}, u'radius-server': {}, u'prompt1': {}, u'nas': {}, u'prompt2': {}, u'role': {}, u'alias-config': {}, u'protocol': {}, u'fcsp': {}, u'nsx-controller-client': {}, u'fastboot': {}, u'password-attributes': {}, u'username': {}, u'cee-map': {}, u'configure': {}, u'df': {}, u'ntp': {}, u'vlan': {}, u'telnet': {}, u'debug': {}, u'mac': {}, u'oscmd': {}, u'ssh': {}, u'rmon': {}, u'logging': {}, u'no-operation': {}, u'banner': {}, u'fabric': {}, u'cidrecov': {}, u'vrf': {}, u'aaa': {}, u'license': {}, u'sflow': {}, u'reload': {}, u'vcs': {}, u'bp-rate-limit': {}, u'clock': {}, u'secpolicy': {}, u'rule': {}, u'dot1x': {}, u'ipv6': {}, u'rename': {}, u'filter-change-update-delay': {}, u'fcoe': {}, u'usb': {}, u'tnl': {}, u'vnetwork': {}, u'nsx-controller': {}, u'dir': {}, u'delete': {}},), is_leaf=True, yang_name=\"enumList\", rest_name=\"enumList\", parent=self, choice=(u'cmdlist', u'container-cmds'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='enumeration', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"enumList must be of a type compatible with enumeration\"\"\",\n          'defined-type': \"brocade-aaa:enumeration\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'debug1': {}, u'system-monitor': {}, u'qos': {}, u'ag': {}, u'ip': {'value': 48}, u'mac-rebalance': {}, u'switch-attributes': {'value': 55}, u'python': {}, u'lacp': {}, u'unlock': {}, u'service': {}, u'port-profile': {}, u'tacacs-server': {}, u'mac-address-table': {}, u'vCenter': {}, u'terminal': {}, u'management': {}, u'monitor': {}, u'lccli': {}, u'snmp-server': {}, u'diag': {}, u'support': {}, u'firmware': {}, u'ldap-server': {}, u'radius-server': {}, u'prompt1': {}, u'nas': {}, u'prompt2': {}, u'role': {}, u'alias-config': {}, u'protocol': {}, u'fcsp': {}, u'nsx-controller-client': {}, u'fastboot': {}, u'password-attributes': {}, u'username': {}, u'cee-map': {}, u'configure': {}, u'df': {}, u'ntp': {}, u'vlan': {}, u'telnet': {}, u'debug': {}, u'mac': {}, u'oscmd': {}, u'ssh': {}, u'rmon': {}, u'logging': {}, u'no-operation': {}, u'banner': {}, u'fabric': {}, u'cidrecov': {}, u'vrf': {}, u'aaa': {}, u'license': {}, u'sflow': {}, u'reload': {}, u'vcs': {}, u'bp-rate-limit': {}, u'clock': {}, u'secpolicy': {}, u'rule': {}, u'dot1x': {}, u'ipv6': {}, u'rename': {}, u'filter-change-update-delay': {}, u'fcoe': {}, u'usb': {}, u'tnl': {}, u'vnetwork': {}, u'nsx-controller': {}, u'dir': {}, u'delete': {}},), is_leaf=True, yang_name=\"enumList\", rest_name=\"enumList\", parent=self, choice=(u'cmdlist', u'container-cmds'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='enumeration', is_config=True)\"\"\",\n        })\n\n    self.__enumList = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_interface_fe(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=interface_fe.interface_fe, is_container='container', presence=False, yang_name=\"interface-fe\", rest_name=\"\", parent=self, choice=(u'cmdlist', u'interface-t'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"interface_fe must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=interface_fe.interface_fe, is_container='container', presence=False, yang_name=\"interface-fe\", rest_name=\"\", parent=self, choice=(u'cmdlist', u'interface-t'), path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'cli-drop-node-name': None}}, namespace='urn:brocade.com:mgmt:brocade-aaa', defining_module='brocade-aaa', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__interface_fe = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the interface of the\n    based on the given interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_tx_queue(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=tx_queue.tx_queue, is_container='container', presence=False, yang_name=\"tx-queue\", rest_name=\"tx-queue\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Eegress Queue', u'callpoint': u'qos_transmit_queue', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"tx_queue must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=tx_queue.tx_queue, is_container='container', presence=False, yang_name=\"tx-queue\", rest_name=\"tx-queue\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Eegress Queue', u'callpoint': u'qos_transmit_queue', u'cli-incomplete-no': None}}, namespace='urn:brocade.com:mgmt:brocade-qos-mls', defining_module='brocade-qos-mls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__tx_queue = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the transmit queue of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the transport service of the", "response": "def _set_transport_service(self, v, load=False):\n    \"\"\"\n    Setter method for transport_service, mapped from YANG variable /interface_vlan/interface/vlan/transport_service (uint16)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_transport_service is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_transport_service() directly.\n\n    YANG Description: Transparent vlan\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=RestrictedClassType(base_type=int, restriction_dict={'range': ['0..65535']},int_size=16), restriction_dict={'range': [u'1..1000']}), is_leaf=True, yang_name=\"transport-service\", rest_name=\"transport-service\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' Set tlsid for Transparent vlan ', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_L2_TRANSPORT_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='uint16', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"transport_service must be of a type compatible with uint16\"\"\",\n          'defined-type': \"uint16\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=RestrictedClassType(base_type=int, restriction_dict={'range': ['0..65535']},int_size=16), restriction_dict={'range': [u'1..1000']}), is_leaf=True, yang_name=\"transport-service\", rest_name=\"transport-service\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u' Set tlsid for Transparent vlan ', u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_L2_TRANSPORT_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='uint16', is_config=True)\"\"\",\n        })\n\n    self.__transport_service = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the vlan name of the", "response": "def _set_vlan_name(self, v, load=False):\n    \"\"\"\n    Setter method for vlan_name, mapped from YANG variable /interface_vlan/interface/vlan/vlan_name (string)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_vlan_name is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_vlan_name() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1 .. 32']}), is_leaf=True, yang_name=\"vlan-name\", rest_name=\"name\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Alternative name for the VLAN', u'cli-multi-value': None, u'alt-name': u'name'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='string', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"vlan_name must be of a type compatible with string\"\"\",\n          'defined-type': \"string\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_dict={'length': [u'1 .. 32']}), is_leaf=True, yang_name=\"vlan-name\", rest_name=\"name\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Alternative name for the VLAN', u'cli-multi-value': None, u'alt-name': u'name'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='string', is_config=True)\"\"\",\n        })\n\n    self.__vlan_name = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the value of the private_vlan field in the order of the VLANs in the order they are assigned.", "response": "def _set_private_vlan(self, v, load=False):\n    \"\"\"\n    Setter method for private_vlan, mapped from YANG variable /interface_vlan/interface/vlan/private_vlan (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_private_vlan is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_private_vlan() directly.\n\n    YANG Description: Configure a Private Vlan\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=private_vlan.private_vlan, is_container='container', presence=False, yang_name=\"private-vlan\", rest_name=\"private-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure vlan as private vlan', u'cli-full-no': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_L2_PVLAN_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"private_vlan must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=private_vlan.private_vlan, is_container='container', presence=False, yang_name=\"private-vlan\", rest_name=\"private-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure vlan as private vlan', u'cli-full-no': None, u'sort-priority': u'RUNNCFG_INTERFACE_LEVEL_L2_PVLAN_CONFIG'}}, namespace='urn:brocade.com:mgmt:brocade-interface', defining_module='brocade-interface', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__private_vlan = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_remote_span(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGBool, is_leaf=True, yang_name=\"remote-span\", rest_name=\"rspan-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure the vlan as rspan vlan', u'alt-name': u'rspan-vlan', u'callpoint': u'interface_vlan'}}, namespace='urn:brocade.com:mgmt:brocade-span', defining_module='brocade-span', yang_type='empty', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"remote_span must be of a type compatible with empty\"\"\",\n          'defined-type': \"empty\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGBool, is_leaf=True, yang_name=\"remote-span\", rest_name=\"rspan-vlan\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure the vlan as rspan vlan', u'alt-name': u'rspan-vlan', u'callpoint': u'interface_vlan'}}, namespace='urn:brocade.com:mgmt:brocade-span', defining_module='brocade-span', yang_type='empty', is_config=True)\"\"\",\n        })\n\n    self.__remote_span = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Set the remote_span property of the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_exp_traffic_class(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"exp_traffic_class_map_name\",exp_traffic_class.exp_traffic_class, yang_name=\"exp-traffic-class\", rest_name=\"exp-traffic-class\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='exp-traffic-class-map-name', extensions={u'tailf-common': {u'info': u'Configure Exp traffic class', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCallpoint', u'cli-mode-name': u'exp-traffic-class-$(exp-traffic-class-map-name)'}}), is_container='list', yang_name=\"exp-traffic-class\", rest_name=\"exp-traffic-class\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Exp traffic class', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCallpoint', u'cli-mode-name': u'exp-traffic-class-$(exp-traffic-class-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"exp_traffic_class must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"exp_traffic_class_map_name\",exp_traffic_class.exp_traffic_class, yang_name=\"exp-traffic-class\", rest_name=\"exp-traffic-class\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='exp-traffic-class-map-name', extensions={u'tailf-common': {u'info': u'Configure Exp traffic class', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCallpoint', u'cli-mode-name': u'exp-traffic-class-$(exp-traffic-class-map-name)'}}), is_container='list', yang_name=\"exp-traffic-class\", rest_name=\"exp-traffic-class\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Exp traffic class', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCallpoint', u'cli-mode-name': u'exp-traffic-class-$(exp-traffic-class-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__exp_traffic_class = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the exp - traffic class of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of the Traffic Class Exp Map.", "response": "def _set_traffic_class_exp(self, v, load=False):\n    \"\"\"\n    Setter method for traffic_class_exp, mapped from YANG variable /qos_mpls/map/traffic_class_exp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_traffic_class_exp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_traffic_class_exp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"traffic_class_exp_map_name\",traffic_class_exp.traffic_class_exp, yang_name=\"traffic-class-exp\", rest_name=\"traffic-class-exp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='traffic-class-exp-map-name', extensions={u'tailf-common': {u'info': u'Configure Traffic class exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd2Callpoint', u'cli-mode-name': u'traffic-class-exp-$(traffic-class-exp-map-name)'}}), is_container='list', yang_name=\"traffic-class-exp\", rest_name=\"traffic-class-exp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic class exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd2Callpoint', u'cli-mode-name': u'traffic-class-exp-$(traffic-class-exp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"traffic_class_exp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"traffic_class_exp_map_name\",traffic_class_exp.traffic_class_exp, yang_name=\"traffic-class-exp\", rest_name=\"traffic-class-exp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='traffic-class-exp-map-name', extensions={u'tailf-common': {u'info': u'Configure Traffic class exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd2Callpoint', u'cli-mode-name': u'traffic-class-exp-$(traffic-class-exp-map-name)'}}), is_container='list', yang_name=\"traffic-class-exp\", rest_name=\"traffic-class-exp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Traffic class exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd2Callpoint', u'cli-mode-name': u'traffic-class-exp-$(traffic-class-exp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__traffic_class_exp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of dscp_exp mapped from QosMplsMap_dscp_exp_map_name to QosMplsMap_dscp_exp_map_name", "response": "def _set_dscp_exp(self, v, load=False):\n    \"\"\"\n    Setter method for dscp_exp, mapped from YANG variable /qos_mpls/map/dscp_exp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_dscp_exp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_dscp_exp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"dscp_exp_map_name\",dscp_exp.dscp_exp, yang_name=\"dscp-exp\", rest_name=\"dscp-exp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dscp-exp-map-name', extensions={u'tailf-common': {u'info': u'Configure Dscp exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd3Callpoint', u'cli-mode-name': u'dscp-exp-$(dscp-exp-map-name)'}}), is_container='list', yang_name=\"dscp-exp\", rest_name=\"dscp-exp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Dscp exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd3Callpoint', u'cli-mode-name': u'dscp-exp-$(dscp-exp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"dscp_exp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"dscp_exp_map_name\",dscp_exp.dscp_exp, yang_name=\"dscp-exp\", rest_name=\"dscp-exp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='dscp-exp-map-name', extensions={u'tailf-common': {u'info': u'Configure Dscp exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd3Callpoint', u'cli-mode-name': u'dscp-exp-$(dscp-exp-map-name)'}}), is_container='list', yang_name=\"dscp-exp\", rest_name=\"dscp-exp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Dscp exp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd3Callpoint', u'cli-mode-name': u'dscp-exp-$(dscp-exp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__dscp_exp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of exp_dscp mapped from QuantFigure map exp_dscp_map_name", "response": "def _set_exp_dscp(self, v, load=False):\n    \"\"\"\n    Setter method for exp_dscp, mapped from YANG variable /qos_mpls/map/exp_dscp (list)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_exp_dscp is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_exp_dscp() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"exp_dscp_map_name\",exp_dscp.exp_dscp, yang_name=\"exp-dscp\", rest_name=\"exp-dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='exp-dscp-map-name', extensions={u'tailf-common': {u'info': u'Configure Exp dscp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd4Callpoint', u'cli-mode-name': u'exp-dscp-$(exp-dscp-map-name)'}}), is_container='list', yang_name=\"exp-dscp\", rest_name=\"exp-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Exp dscp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd4Callpoint', u'cli-mode-name': u'exp-dscp-$(exp-dscp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"exp_dscp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"exp_dscp_map_name\",exp_dscp.exp_dscp, yang_name=\"exp-dscp\", rest_name=\"exp-dscp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='exp-dscp-map-name', extensions={u'tailf-common': {u'info': u'Configure Exp dscp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd4Callpoint', u'cli-mode-name': u'exp-dscp-$(exp-dscp-map-name)'}}), is_container='list', yang_name=\"exp-dscp\", rest_name=\"exp-dscp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Exp dscp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd4Callpoint', u'cli-mode-name': u'exp-dscp-$(exp-dscp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__exp_dscp = t\n    if hasattr(self, '_set'):\n      self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_inexp_outexp(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=YANGListType(\"inexp_outexp_map_name\",inexp_outexp.inexp_outexp, yang_name=\"inexp-outexp\", rest_name=\"inexp-outexp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='inexp-outexp-map-name', extensions={u'tailf-common': {u'info': u'Configure Inexp outexp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd5Callpoint', u'hidden': u'full', u'cli-mode-name': u'inexp-outexp-$(inexp-outexp-map-name)'}}), is_container='list', yang_name=\"inexp-outexp\", rest_name=\"inexp-outexp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Inexp outexp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd5Callpoint', u'hidden': u'full', u'cli-mode-name': u'inexp-outexp-$(inexp-outexp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"inexp_outexp must be of a type compatible with list\"\"\",\n          'defined-type': \"list\",\n          'generated-type': \"\"\"YANGDynClass(base=YANGListType(\"inexp_outexp_map_name\",inexp_outexp.inexp_outexp, yang_name=\"inexp-outexp\", rest_name=\"inexp-outexp\", parent=self, is_container='list', user_ordered=False, path_helper=self._path_helper, yang_keys='inexp-outexp-map-name', extensions={u'tailf-common': {u'info': u'Configure Inexp outexp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd5Callpoint', u'hidden': u'full', u'cli-mode-name': u'inexp-outexp-$(inexp-outexp-map-name)'}}), is_container='list', yang_name=\"inexp-outexp\", rest_name=\"inexp-outexp\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure Inexp outexp', u'cli-sequence-commands': None, u'callpoint': u'QosMplsCmd5Callpoint', u'hidden': u'full', u'cli-mode-name': u'inexp-outexp-$(inexp-outexp-map-name)'}}, namespace='urn:brocade.com:mgmt:brocade-qos-mpls', defining_module='brocade-qos-mpls', yang_type='list', is_config=True)\"\"\",\n        })\n\n    self.__inexp_outexp = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the inexp_outexp field in the internal representation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_computation_mode(self, v, load=False):\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'cspf-computation-mode-default': {'value': 1}, u'cspf-computation-mode-use-bypass-metric': {'value': 2}, u'cspf-computation-mode-use-igp-metric-global': {'value': 7}, u'cspf-computation-mode-use-igp-metric': {'value': 5}, u'cspf-computation-mode-use-te-metric': {'value': 4}, u'cspf-computation-mode-use-bypass-liberal': {'value': 3}, u'cspf-computation-mode-use-te-metric-global': {'value': 6}},), is_leaf=True, yang_name=\"computation-mode\", rest_name=\"computation-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='lsp-cspf-computation-mode', is_config=False)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"computation_mode must be of a type compatible with lsp-cspf-computation-mode\"\"\",\n          'defined-type': \"brocade-mpls-operational:lsp-cspf-computation-mode\",\n          'generated-type': \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode,                                     restriction_type=\"dict_key\",                                     restriction_arg={u'cspf-computation-mode-default': {'value': 1}, u'cspf-computation-mode-use-bypass-metric': {'value': 2}, u'cspf-computation-mode-use-igp-metric-global': {'value': 7}, u'cspf-computation-mode-use-igp-metric': {'value': 5}, u'cspf-computation-mode-use-te-metric': {'value': 4}, u'cspf-computation-mode-use-bypass-liberal': {'value': 3}, u'cspf-computation-mode-use-te-metric-global': {'value': 6}},), is_leaf=True, yang_name=\"computation-mode\", rest_name=\"computation-mode\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='urn:brocade.com:mgmt:brocade-mpls-operational', defining_module='brocade-mpls-operational', yang_type='lsp-cspf-computation-mode', is_config=False)\"\"\",\n        })\n\n    self.__computation_mode = t\n    if hasattr(self, '_set'):\n      self._set()", "response": "Sets the value of the lsp - cspf - computation - mode mapped from YANG variable"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of _map_apply mapped from QosMpls_Map_Apply", "response": "def _set_map_apply(self, v, load=False):\n    \"\"\"\n    Setter method for map_apply, mapped from YANG variable /qos_mpls/map_apply (container)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_map_apply is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_map_apply() directly.\n    \"\"\"\n    if hasattr(v, \"_utype\"):\n      v = v._utype(v)\n    try:\n      t = YANGDynClass(v,base=map_apply.map_apply, is_container='container', presence=False, yang_name=\"map-apply\", rest_name=\"map-apply\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure apply map', u'callpoint': u'ApplyQosMplsCallpoint', u'sort-priority': u'51'}}, namespace='urn:brocade.com:mgmt:brocade-apply-qos-mpls', defining_module='brocade-apply-qos-mpls', yang_type='container', is_config=True)\n    except (TypeError, ValueError):\n      raise ValueError({\n          'error-string': \"\"\"map_apply must be of a type compatible with container\"\"\",\n          'defined-type': \"container\",\n          'generated-type': \"\"\"YANGDynClass(base=map_apply.map_apply, is_container='container', presence=False, yang_name=\"map-apply\", rest_name=\"map-apply\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, extensions={u'tailf-common': {u'info': u'Configure apply map', u'callpoint': u'ApplyQosMplsCallpoint', u'sort-priority': u'51'}}, namespace='urn:brocade.com:mgmt:brocade-apply-qos-mpls', defining_module='brocade-apply-qos-mpls', yang_type='container', is_config=True)\"\"\",\n        })\n\n    self.__map_apply = t\n    if hasattr(self, '_set'):\n      self._set()"}
